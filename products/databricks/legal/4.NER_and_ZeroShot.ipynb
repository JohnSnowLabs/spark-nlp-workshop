{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
   ],
   "metadata": {
    "id": "db5f4f9a-7776-42b3-8758-85624d4c15ea",
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "c6776c60-ce1d-4720-b771-3fb35fde14b2",
     "inputWidgets": {},
     "title": ""
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Legal Named Entity Recognition (NER) and Zero-shot NER"
   ],
   "metadata": {
    "id": "6964d2b7",
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "083a7d43-9def-4ea5-937b-c006a0252046",
     "inputWidgets": {},
     "title": ""
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from johnsnowlabs import * "
   ],
   "metadata": {
    "id": "dmcB5zVBHZO8",
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "ee5be21d-ed52-4a20-b104-178c31bda107",
     "inputWidgets": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "user_tz": -120,
     "timestamp": 1665042921811,
     "elapsed": 109269,
     "status": "ok",
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     }
    },
    "outputId": "30aa1263-7978-4c29-ed99-9cbe4f180f8e"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "datasetInfos": [],
       "data": "<div class=\"ansiout\"></div>",
       "removedWidgets": [],
       "addedWidgets": {},
       "metadata": {},
       "type": "html",
       "arguments": {}
      }
     },
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"
      ]
     }
    }
   ],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "## NER Model Implementation in Spark NLP\n",
    "\n",
    "  The deep neural network architecture for NER model in Spark NLP is BiLSTM-CNN-Char framework. a slightly modified version of the architecture proposed by Jason PC Chiu and Eric Nichols ([Named Entity Recognition with Bidirectional LSTM-CNNs](https://arxiv.org/abs/1511.08308)). It is a neural network architecture that automatically detects word and character-level features using a hybrid bidirectional LSTM and CNN architecture, eliminating the need for most feature engineering steps.\n",
    "  \n",
    "  In the original framework, the CNN extracts a fixed length feature vector from character-level features. For each word, these vectors are concatenated and fed to the BLSTM network and then to the output layers. They employed a stacked bi-directional recurrent neural network with long short-term memory units to transform word features into named entity tag scores. The extracted features of each word are fed into a forward LSTM network and a backward LSTM network. The output of each network at each time step is decoded by a linear layer and a log-softmax layer into log-probabilities for each tag category. These two vectors are then simply added together to produce the final output. In the architecture of the proposed framework in the original paper, 50-dimensional pretrained word embeddings is used for word features, 25-dimension character embeddings is used for char features, and capitalization features (allCaps, upperInitial, lowercase, mixedCaps, noinfo) are used for case features."
   ],
   "metadata": {
    "id": "766fe57a-fcd5-4072-99d0-7626c7888493",
    "tags": [],
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "a807a4a1-467f-468a-8710-0ccfecb1f985",
     "inputWidgets": {},
     "title": ""
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Legal CuadNER Model\n",
    "\n",
    "This model uses Name Entity Recognition to extract DOC (Document Type), PARTY (An Entity signing a contract), ALIAS (the way a company is named later on in the document) and EFFDATE (Effective Date of the contract)."
   ],
   "metadata": {
    "id": "bee4b28c-dda1-4708-9240-edb6fe105013",
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "fd01fc58-cf7d-4c9a-a9eb-bdac0b462356",
     "inputWidgets": {},
     "title": ""
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "documentAssembler = nlp.DocumentAssembler()\\\n",
    "        .setInputCol(\"text\")\\\n",
    "        .setOutputCol(\"document\")\n",
    "\n",
    "sentenceDetector = nlp.SentenceDetectorDLModel.pretrained(\"sentence_detector_dl\",\"xx\")\\\n",
    "        .setInputCols([\"document\"])\\\n",
    "        .setOutputCol(\"sentence\")\n",
    "\n",
    "tokenizer = nlp.Tokenizer()\\\n",
    "        .setInputCols([\"sentence\"])\\\n",
    "        .setOutputCol(\"token\")\n",
    "\n",
    "embeddings = nlp.RoBertaEmbeddings.pretrained(\"roberta_embeddings_legal_roberta_base\", \"en\") \\\n",
    "        .setInputCols(\"sentence\", \"token\") \\\n",
    "        .setOutputCol(\"embeddings\")\\\n",
    "\n",
    "ner_model = legal.NerModel.pretrained(\"legner_contract_doc_parties\", \"en\", \"legal/models\")\\\n",
    "        .setInputCols([\"sentence\", \"token\", \"embeddings\"])\\\n",
    "        .setOutputCol(\"ner\")\n",
    "\n",
    "ner_converter = nlp.NerConverter()\\\n",
    "        .setInputCols([\"sentence\",\"token\",\"ner\"])\\\n",
    "        .setOutputCol(\"ner_chunk\")\n",
    "\n",
    "nlpPipeline = nlp.Pipeline(stages=[\n",
    "        documentAssembler,\n",
    "        sentenceDetector,\n",
    "        tokenizer,\n",
    "        embeddings,\n",
    "        ner_model,\n",
    "        ner_converter])\n",
    "\n",
    "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "model = nlpPipeline.fit(empty_data)"
   ],
   "metadata": {
    "tags": [],
    "id": "889067cf-a64c-4f3a-b27a-51fdca438599",
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "1dde100a-e52f-4284-8479-4824cf30838a",
     "inputWidgets": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "scrolled": true,
    "executionInfo": {
     "user_tz": -120,
     "timestamp": 1665043090071,
     "elapsed": 57982,
     "status": "ok",
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     }
    },
    "outputId": "d5515a7b-7bc4-49b9-e75c-c649d1e45b22"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "datasetInfos": [],
       "data": "<div class=\"ansiout\">sentence_detector_dl download started this may take some time.\nApproximate size to download 514.9 KB\n\r[ | ]\r[OK!]\nroberta_embeddings_legal_roberta_base download started this may take some time.\nApproximate size to download 447.2 MB\n\r[ | ]\r[OK!]\nlegner_contract_doc_parties download started this may take some time.\n\r[ | ]\r[ / ]\r[ — ]\r[OK!]\n</div>",
       "removedWidgets": [],
       "addedWidgets": {},
       "metadata": {},
       "type": "html",
       "arguments": {}
      }
     },
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">sentence_detector_dl download started this may take some time.\nApproximate size to download 514.9 KB\n\r[ | ]\r[OK!]\nroberta_embeddings_legal_roberta_base download started this may take some time.\nApproximate size to download 447.2 MB\n\r[ | ]\r[OK!]\nlegner_contract_doc_parties download started this may take some time.\n\r[ | ]\r[ / ]\r[ — ]\r[OK!]\n</div>"
      ]
     }
    }
   ],
   "execution_count": 0
  },
  {
   "cell_type": "code",
   "source": [
    "# you can see pipeline stages with this code\n",
    "\n",
    "model.stages"
   ],
   "metadata": {
    "id": "46fa5d8a-a5f0-4173-a21e-1df147d1b2e8",
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "1e191aa6-bd4a-4196-b184-3fec2b6d1b18",
     "inputWidgets": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "user_tz": -120,
     "timestamp": 1665043090072,
     "elapsed": 26,
     "status": "ok",
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     }
    },
    "outputId": "64b10986-3386-43a2-9fad-1cef4c8c17ff"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "datasetInfos": [],
       "data": "<div class=\"ansiout\">Out[3]: [DocumentAssembler_124332ae13ba,\n SentenceDetectorDLModel_8aaebf7e098e,\n REGEX_TOKENIZER_c12b3e1bc321,\n ROBERTA_EMBEDDINGS_b915dff90901,\n MedicalNerModel_93f728ff96e5,\n NerConverter_a7acb930e4a0]</div>",
       "removedWidgets": [],
       "addedWidgets": {},
       "metadata": {},
       "type": "html",
       "arguments": {}
      }
     },
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[3]: [DocumentAssembler_124332ae13ba,\n SentenceDetectorDLModel_8aaebf7e098e,\n REGEX_TOKENIZER_c12b3e1bc321,\n ROBERTA_EMBEDDINGS_b915dff90901,\n MedicalNerModel_93f728ff96e5,\n NerConverter_a7acb930e4a0]</div>"
      ]
     }
    }
   ],
   "execution_count": 0
  },
  {
   "cell_type": "code",
   "source": [
    "# With this code, you can see which labels your NER model has.\n",
    "\n",
    "ner_model.getClasses()"
   ],
   "metadata": {
    "id": "af5baafe-793a-4022-ac3c-95c5345ef606",
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "61a0c8d0-7386-4445-9fb6-3cdbe3e75611",
     "inputWidgets": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "user_tz": -120,
     "timestamp": 1665043090072,
     "elapsed": 20,
     "status": "ok",
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     }
    },
    "outputId": "c2fa764f-0e23-417a-9aaf-07178c3f1076"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "datasetInfos": [],
       "data": "<div class=\"ansiout\">Out[4]: [&#39;O&#39;,\n &#39;I-DOC&#39;,\n &#39;B-EFFDATE&#39;,\n &#39;B-ALIAS&#39;,\n &#39;I-ALIAS&#39;,\n &#39;B-PARTY&#39;,\n &#39;I-EFFDATE&#39;,\n &#39;I-PARTY&#39;,\n &#39;B-DOC&#39;]</div>",
       "removedWidgets": [],
       "addedWidgets": {},
       "metadata": {},
       "type": "html",
       "arguments": {}
      }
     },
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[4]: [&#39;O&#39;,\n &#39;I-DOC&#39;,\n &#39;B-EFFDATE&#39;,\n &#39;B-ALIAS&#39;,\n &#39;I-ALIAS&#39;,\n &#39;B-PARTY&#39;,\n &#39;I-EFFDATE&#39;,\n &#39;I-PARTY&#39;,\n &#39;B-DOC&#39;]</div>"
      ]
     }
    }
   ],
   "execution_count": 0
  },
  {
   "cell_type": "code",
   "source": [
    "ner_model.extractParamMap()\n",
    "\n",
    "# With extractParamMap() function, you can see the parameters of any annotators you are using."
   ],
   "metadata": {
    "id": "5954047c-ec79-47ec-98fa-44c74b492140",
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "75f77fae-c817-4ae3-95e7-e503dd98cb69",
     "inputWidgets": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "user_tz": -120,
     "timestamp": 1665043090073,
     "elapsed": 13,
     "status": "ok",
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     }
    },
    "outputId": "f2f18783-4a23-431b-cb73-79a2779d0707"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "datasetInfos": [],
       "data": "<div class=\"ansiout\">Out[5]: {Param(parent=&#39;MedicalNerModel_93f728ff96e5&#39;, name=&#39;inferenceBatchSize&#39;, doc=&#39;number of sentences to process in a single batch during inference&#39;): 1,\n Param(parent=&#39;MedicalNerModel_93f728ff96e5&#39;, name=&#39;labelCasing&#39;, doc=&#39;Setting all labels of the NER models upper/lower case. values upper|lower&#39;): &#39;&#39;,\n Param(parent=&#39;MedicalNerModel_93f728ff96e5&#39;, name=&#39;lazyAnnotator&#39;, doc=&#39;Whether this AnnotatorModel acts as lazy in RecursivePipelines&#39;): False,\n Param(parent=&#39;MedicalNerModel_93f728ff96e5&#39;, name=&#39;includeConfidence&#39;, doc=&#39;whether to include confidence scores in annotation metadata&#39;): True,\n Param(parent=&#39;MedicalNerModel_93f728ff96e5&#39;, name=&#39;includeAllConfidenceScores&#39;, doc=&#39;whether to include all confidence scores in annotation metadata or just the score of the predicted tag&#39;): False,\n Param(parent=&#39;MedicalNerModel_93f728ff96e5&#39;, name=&#39;batchSize&#39;, doc=&#39;Size of every batch&#39;): 256,\n Param(parent=&#39;MedicalNerModel_93f728ff96e5&#39;, name=&#39;classes&#39;, doc=&#39;get the tags used to trained this MedicalNerModel&#39;): [&#39;O&#39;,\n  &#39;I-DOC&#39;,\n  &#39;B-EFFDATE&#39;,\n  &#39;B-ALIAS&#39;,\n  &#39;I-ALIAS&#39;,\n  &#39;B-PARTY&#39;,\n  &#39;I-EFFDATE&#39;,\n  &#39;I-PARTY&#39;,\n  &#39;B-DOC&#39;],\n Param(parent=&#39;MedicalNerModel_93f728ff96e5&#39;, name=&#39;inputCols&#39;, doc=&#39;previous annotations columns, if renamed&#39;): [&#39;sentence&#39;,\n  &#39;token&#39;,\n  &#39;embeddings&#39;],\n Param(parent=&#39;MedicalNerModel_93f728ff96e5&#39;, name=&#39;outputCol&#39;, doc=&#39;output annotation column. can be left default.&#39;): &#39;ner&#39;,\n Param(parent=&#39;MedicalNerModel_93f728ff96e5&#39;, name=&#39;storageRef&#39;, doc=&#39;unique reference name for identification&#39;): &#39;roberta_embeddings_legal_roberta_base_en&#39;}</div>",
       "removedWidgets": [],
       "addedWidgets": {},
       "metadata": {},
       "type": "html",
       "arguments": {}
      }
     },
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[5]: {Param(parent=&#39;MedicalNerModel_93f728ff96e5&#39;, name=&#39;inferenceBatchSize&#39;, doc=&#39;number of sentences to process in a single batch during inference&#39;): 1,\n Param(parent=&#39;MedicalNerModel_93f728ff96e5&#39;, name=&#39;labelCasing&#39;, doc=&#39;Setting all labels of the NER models upper/lower case. values upper|lower&#39;): &#39;&#39;,\n Param(parent=&#39;MedicalNerModel_93f728ff96e5&#39;, name=&#39;lazyAnnotator&#39;, doc=&#39;Whether this AnnotatorModel acts as lazy in RecursivePipelines&#39;): False,\n Param(parent=&#39;MedicalNerModel_93f728ff96e5&#39;, name=&#39;includeConfidence&#39;, doc=&#39;whether to include confidence scores in annotation metadata&#39;): True,\n Param(parent=&#39;MedicalNerModel_93f728ff96e5&#39;, name=&#39;includeAllConfidenceScores&#39;, doc=&#39;whether to include all confidence scores in annotation metadata or just the score of the predicted tag&#39;): False,\n Param(parent=&#39;MedicalNerModel_93f728ff96e5&#39;, name=&#39;batchSize&#39;, doc=&#39;Size of every batch&#39;): 256,\n Param(parent=&#39;MedicalNerModel_93f728ff96e5&#39;, name=&#39;classes&#39;, doc=&#39;get the tags used to trained this MedicalNerModel&#39;): [&#39;O&#39;,\n  &#39;I-DOC&#39;,\n  &#39;B-EFFDATE&#39;,\n  &#39;B-ALIAS&#39;,\n  &#39;I-ALIAS&#39;,\n  &#39;B-PARTY&#39;,\n  &#39;I-EFFDATE&#39;,\n  &#39;I-PARTY&#39;,\n  &#39;B-DOC&#39;],\n Param(parent=&#39;MedicalNerModel_93f728ff96e5&#39;, name=&#39;inputCols&#39;, doc=&#39;previous annotations columns, if renamed&#39;): [&#39;sentence&#39;,\n  &#39;token&#39;,\n  &#39;embeddings&#39;],\n Param(parent=&#39;MedicalNerModel_93f728ff96e5&#39;, name=&#39;outputCol&#39;, doc=&#39;output annotation column. can be left default.&#39;): &#39;ner&#39;,\n Param(parent=&#39;MedicalNerModel_93f728ff96e5&#39;, name=&#39;storageRef&#39;, doc=&#39;unique reference name for identification&#39;): &#39;roberta_embeddings_legal_roberta_base_en&#39;}</div>"
      ]
     }
    }
   ],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### **Sample Text**"
   ],
   "metadata": {
    "id": "9e7d801c-fcc0-458c-9835-b6cbb0149f38",
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "5bd8766e-71ba-441b-ab5d-8338583e9239",
     "inputWidgets": {},
     "title": ""
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "text = \"\"\"EXCLUSIVE DISTRIBUTOR AGREEMENT (\" Agreement \") dated as April 15, 1994 by and between IMRS OPERATIONS INC., a Delaware corporation with its principal place of business at 777 Long Ridge Road, Stamford, Connecticut 06902, U.S.A. (hereinafter referred to as \" Developer \") and Delteq Pte Ltd, a Singapore company (and a subsidiary of Wuthelam Industries (S) Pte LTD ) with its principal place of business at 215 Henderson Road , #101-03 Henderson Industrial Park , Singapore 0315 ( hereinafter referred to as \" Distributor \").\"\"\"\n",
    "\n",
    "df = spark.createDataFrame([[text]]).toDF(\"text\")\n",
    "\n",
    "result = model.transform(df)"
   ],
   "metadata": {
    "executionInfo": {
     "user_tz": -120,
     "timestamp": 1665043090686,
     "elapsed": 621,
     "status": "ok",
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     }
    },
    "id": "00d74636-3490-4a24-9dc2-4f3f023c8909",
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "acda0d99-87c6-4e0b-b6d7-f742e370d0ba",
     "inputWidgets": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "datasetInfos": [],
       "data": "<div class=\"ansiout\"></div>",
       "removedWidgets": [],
       "addedWidgets": {},
       "metadata": {},
       "type": "html",
       "arguments": {}
      }
     },
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"
      ]
     }
    }
   ],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### **Getting Result**"
   ],
   "metadata": {
    "id": "4c7c211c-448e-494f-9f83-3274b9ca0aba",
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "34bcd65a-0442-4a69-b6cf-f41d1ad9f42a",
     "inputWidgets": {},
     "title": ""
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "result.select(F.explode(F.arrays_zip(result.token.result, \n",
    "                                     result.ner.result, \n",
    "                                     result.ner.metadata)).alias(\"cols\"))\\\n",
    "                  .select(F.expr(\"cols['0']\").alias(\"token\"),\n",
    "                          F.expr(\"cols['1']\").alias(\"ner_label\"),\n",
    "                          F.expr(\"cols['2']['confidence']\").alias(\"confidence\")).show(200, truncate=100)"
   ],
   "metadata": {
    "tags": [],
    "id": "ec9a99c6-4d22-4837-aed9-425b8f9efed6",
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "e44e0acc-0c6a-4a33-a0e7-ed52cc017a70",
     "inputWidgets": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "user_tz": -120,
     "timestamp": 1665043098952,
     "elapsed": 8269,
     "status": "ok",
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     }
    },
    "outputId": "192ef4c0-a12d-43e3-d691-1dd811a8c6ba"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "datasetInfos": [],
       "data": "<div class=\"ansiout\">+-----------+---------+----------+\n|      token|ner_label|confidence|\n+-----------+---------+----------+\n|  EXCLUSIVE|    B-DOC|     0.885|\n|DISTRIBUTOR|    I-DOC|    0.7397|\n|  AGREEMENT|    I-DOC|    0.9926|\n|         (&#34;|        O|    0.9998|\n|  Agreement|        O|    0.9964|\n|         &#34;)|        O|       1.0|\n|      dated|        O|       1.0|\n|         as|        O|    0.9985|\n|      April|B-EFFDATE|    0.9845|\n|         15|I-EFFDATE|     0.951|\n|          ,|I-EFFDATE|    0.9504|\n|       1994|I-EFFDATE|    0.8741|\n|         by|        O|       1.0|\n|        and|        O|       1.0|\n|    between|        O|       1.0|\n|       IMRS|  B-PARTY|    0.9898|\n| OPERATIONS|  I-PARTY|    0.9987|\n|        INC|  I-PARTY|    0.9995|\n|          .|        O|    0.9907|\n|          ,|        O|    0.9983|\n|          a|        O|       1.0|\n|   Delaware|        O|    0.9997|\n|corporation|        O|    0.9999|\n|       with|        O|       1.0|\n|        its|        O|       1.0|\n|  principal|        O|       1.0|\n|      place|        O|       1.0|\n|         of|        O|       1.0|\n|   business|        O|       1.0|\n|         at|        O|       1.0|\n|        777|        O|       1.0|\n|       Long|        O|    0.9999|\n|      Ridge|        O|    0.9999|\n|       Road|        O|       1.0|\n|          ,|        O|       1.0|\n|   Stamford|        O|    0.9997|\n|          ,|        O|       1.0|\n|Connecticut|        O|    0.9998|\n|      06902|        O|    0.9997|\n|          ,|        O|    0.9998|\n|      U.S.A|        O|    0.9919|\n|          .|        O|    0.9991|\n|          (|        O|    0.9999|\n|hereinafter|        O|       1.0|\n|   referred|        O|       1.0|\n|         to|        O|    0.9995|\n|         as|        O|    0.9994|\n|          &#34;|        O|    0.9959|\n|  Developer|  B-ALIAS|    0.9741|\n|         &#34;)|        O|    0.9972|\n|        and|        O|    0.9978|\n|     Delteq|  B-PARTY|    0.9257|\n|        Pte|  I-PARTY|    0.9525|\n|        Ltd|  I-PARTY|    0.9735|\n|          ,|        O|     0.983|\n|          a|        O|       1.0|\n|  Singapore|        O|    0.9984|\n|    company|        O|    0.9977|\n|          (|        O|       1.0|\n|        and|        O|       1.0|\n|          a|        O|       1.0|\n| subsidiary|        O|       1.0|\n|         of|        O|    0.9999|\n|   Wuthelam|        O|    0.9009|\n| Industries|        O|    0.9494|\n|          (|        O|    0.9384|\n|          S|        O|    0.9564|\n|          )|        O|    0.9981|\n|        Pte|        O|    0.9911|\n|        LTD|        O|    0.9893|\n|          )|        O|       1.0|\n|       with|        O|       1.0|\n|        its|        O|       1.0|\n|  principal|        O|       1.0|\n|      place|        O|       1.0|\n|         of|        O|       1.0|\n|   business|        O|       1.0|\n|         at|        O|       1.0|\n|        215|        O|       1.0|\n|  Henderson|        O|       1.0|\n|       Road|        O|       1.0|\n|          ,|        O|       1.0|\n|    #101-03|        O|       1.0|\n|  Henderson|        O|    0.9997|\n| Industrial|        O|    0.9997|\n|       Park|        O|    0.9998|\n|          ,|        O|       1.0|\n|  Singapore|        O|    0.9999|\n|       0315|        O|    0.9998|\n|          (|        O|       1.0|\n|hereinafter|        O|       1.0|\n|   referred|        O|       1.0|\n|         to|        O|    0.9999|\n|         as|        O|    0.9999|\n|          &#34;|        O|     0.999|\n|Distributor|  B-ALIAS|    0.9814|\n|        &#34;).|        O|    0.9926|\n+-----------+---------+----------+\n\n</div>",
       "removedWidgets": [],
       "addedWidgets": {},
       "metadata": {},
       "type": "html",
       "arguments": {}
      }
     },
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------+---------+----------+\n      token|ner_label|confidence|\n+-----------+---------+----------+\n  EXCLUSIVE|    B-DOC|     0.885|\nDISTRIBUTOR|    I-DOC|    0.7397|\n  AGREEMENT|    I-DOC|    0.9926|\n         (&#34;|        O|    0.9998|\n  Agreement|        O|    0.9964|\n         &#34;)|        O|       1.0|\n      dated|        O|       1.0|\n         as|        O|    0.9985|\n      April|B-EFFDATE|    0.9845|\n         15|I-EFFDATE|     0.951|\n          ,|I-EFFDATE|    0.9504|\n       1994|I-EFFDATE|    0.8741|\n         by|        O|       1.0|\n        and|        O|       1.0|\n    between|        O|       1.0|\n       IMRS|  B-PARTY|    0.9898|\n OPERATIONS|  I-PARTY|    0.9987|\n        INC|  I-PARTY|    0.9995|\n          .|        O|    0.9907|\n          ,|        O|    0.9983|\n          a|        O|       1.0|\n   Delaware|        O|    0.9997|\ncorporation|        O|    0.9999|\n       with|        O|       1.0|\n        its|        O|       1.0|\n  principal|        O|       1.0|\n      place|        O|       1.0|\n         of|        O|       1.0|\n   business|        O|       1.0|\n         at|        O|       1.0|\n        777|        O|       1.0|\n       Long|        O|    0.9999|\n      Ridge|        O|    0.9999|\n       Road|        O|       1.0|\n          ,|        O|       1.0|\n   Stamford|        O|    0.9997|\n          ,|        O|       1.0|\nConnecticut|        O|    0.9998|\n      06902|        O|    0.9997|\n          ,|        O|    0.9998|\n      U.S.A|        O|    0.9919|\n          .|        O|    0.9991|\n          (|        O|    0.9999|\nhereinafter|        O|       1.0|\n   referred|        O|       1.0|\n         to|        O|    0.9995|\n         as|        O|    0.9994|\n          &#34;|        O|    0.9959|\n  Developer|  B-ALIAS|    0.9741|\n         &#34;)|        O|    0.9972|\n        and|        O|    0.9978|\n     Delteq|  B-PARTY|    0.9257|\n        Pte|  I-PARTY|    0.9525|\n        Ltd|  I-PARTY|    0.9735|\n          ,|        O|     0.983|\n          a|        O|       1.0|\n  Singapore|        O|    0.9984|\n    company|        O|    0.9977|\n          (|        O|       1.0|\n        and|        O|       1.0|\n          a|        O|       1.0|\n subsidiary|        O|       1.0|\n         of|        O|    0.9999|\n   Wuthelam|        O|    0.9009|\n Industries|        O|    0.9494|\n          (|        O|    0.9384|\n          S|        O|    0.9564|\n          )|        O|    0.9981|\n        Pte|        O|    0.9911|\n        LTD|        O|    0.9893|\n          )|        O|       1.0|\n       with|        O|       1.0|\n        its|        O|       1.0|\n  principal|        O|       1.0|\n      place|        O|       1.0|\n         of|        O|       1.0|\n   business|        O|       1.0|\n         at|        O|       1.0|\n        215|        O|       1.0|\n  Henderson|        O|       1.0|\n       Road|        O|       1.0|\n          ,|        O|       1.0|\n    #101-03|        O|       1.0|\n  Henderson|        O|    0.9997|\n Industrial|        O|    0.9997|\n       Park|        O|    0.9998|\n          ,|        O|       1.0|\n  Singapore|        O|    0.9999|\n       0315|        O|    0.9998|\n          (|        O|       1.0|\nhereinafter|        O|       1.0|\n   referred|        O|       1.0|\n         to|        O|    0.9999|\n         as|        O|    0.9999|\n          &#34;|        O|     0.999|\nDistributor|  B-ALIAS|    0.9814|\n        &#34;).|        O|    0.9926|\n+-----------+---------+----------+\n\n</div>"
      ]
     }
    }
   ],
   "execution_count": 0
  },
  {
   "cell_type": "code",
   "source": [
    "result.select(F.explode(F.arrays_zip(result.ner_chunk.result, result.ner_chunk.metadata)).alias(\"cols\")) \\\n",
    "      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
    "              F.expr(\"cols['1']['entity']\").alias(\"ner_label\"),\n",
    "              F.expr(\"cols['1']['confidence']\").alias(\"confidence\")).show(truncate=False)"
   ],
   "metadata": {
    "id": "865dce29-ece0-45f6-8f5b-9028292523f0",
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "6556c682-fc88-4e35-b6b5-f1eaef5d841f",
     "inputWidgets": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "user_tz": -120,
     "timestamp": 1665043100733,
     "elapsed": 1788,
     "status": "ok",
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     }
    },
    "outputId": "16c7ddb6-1b88-4001-8538-8a5ef04243a2"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "datasetInfos": [],
       "data": "<div class=\"ansiout\">+-------------------------------+---------+----------+\n|chunk                          |ner_label|confidence|\n+-------------------------------+---------+----------+\n|EXCLUSIVE DISTRIBUTOR AGREEMENT|DOC      |0.87243336|\n|April 15, 1994                 |EFFDATE  |0.94      |\n|IMRS OPERATIONS INC            |PARTY    |0.996     |\n|Developer                      |ALIAS    |0.9741    |\n|Delteq Pte Ltd                 |PARTY    |0.9505667 |\n|Distributor                    |ALIAS    |0.9814    |\n+-------------------------------+---------+----------+\n\n</div>",
       "removedWidgets": [],
       "addedWidgets": {},
       "metadata": {},
       "type": "html",
       "arguments": {}
      }
     },
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------------------------------+---------+----------+\nchunk                          |ner_label|confidence|\n+-------------------------------+---------+----------+\nEXCLUSIVE DISTRIBUTOR AGREEMENT|DOC      |0.87243336|\nApril 15, 1994                 |EFFDATE  |0.94      |\nIMRS OPERATIONS INC            |PARTY    |0.996     |\nDeveloper                      |ALIAS    |0.9741    |\nDelteq Pte Ltd                 |PARTY    |0.9505667 |\nDistributor                    |ALIAS    |0.9814    |\n+-------------------------------+---------+----------+\n\n</div>"
      ]
     }
    }
   ],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### **Getting Result with LightPipeline**\n",
    "\n",
    "LightPipelines are Spark NLP specific Pipelines, equivalent to Spark ML Pipeline, but meant to deal with smaller amounts of data. They’re useful working with small datasets, debugging results, or when running either training or prediction from an API that serves one-off requests.\n",
    "\n",
    "Spark NLP LightPipelines are Spark ML pipelines converted into a single machine but the multi-threaded task, becoming more than 10x times faster for smaller amounts of data (small is relative, but 50k sentences are roughly a good maximum). To use them, we simply plug in a trained (fitted) pipeline and then annotate a plain text. We don't even need to convert the input text to DataFrame in order to feed it into a pipeline that's accepting DataFrame as an input in the first place. This feature would be quite useful when it comes to getting a prediction for a few lines of text from a trained ML model.\n",
    "\n",
    " **It is nearly 10x faster than using Spark ML Pipeline**\n",
    "\n",
    "For more details:\n",
    "[https://medium.com/spark-nlp/spark-nlp-101-lightpipeline-a544e93f20f1](https://medium.com/spark-nlp/spark-nlp-101-lightpipeline-a544e93f20f1)"
   ],
   "metadata": {
    "id": "b47e34e0-3633-4202-afdf-63a0f2475520",
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "8ca2ab93-5573-462f-80d0-3c93dd72a423",
     "inputWidgets": {},
     "title": ""
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "light_model = nlp.LightPipeline(model)\n",
    "\n",
    "light_result = light_model.fullAnnotate(text)\n",
    "\n",
    "\n",
    "chunks = []\n",
    "entities = []\n",
    "sentence= []\n",
    "begin = []\n",
    "end = []\n",
    "\n",
    "for n in light_result[0]['ner_chunk']:\n",
    "        \n",
    "    begin.append(n.begin)\n",
    "    end.append(n.end)\n",
    "    chunks.append(n.result)\n",
    "    entities.append(n.metadata['entity']) \n",
    "    sentence.append(n.metadata['sentence'])\n",
    "    \n",
    "    \n",
    "\n",
    "df = pd.DataFrame({'chunks':chunks, 'begin': begin, 'end':end, \n",
    "                   'sentence_id':sentence, 'entities':entities})\n",
    "\n",
    "df.head(20)"
   ],
   "metadata": {
    "id": "f22dd0c2-c63d-43c8-bc96-2f7cead3553b",
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "057701ca-8a68-4255-94bd-7abda3b4dfb4",
     "inputWidgets": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "executionInfo": {
     "user_tz": -120,
     "timestamp": 1665043103518,
     "elapsed": 2793,
     "status": "ok",
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     }
    },
    "outputId": "08609fde-cff6-448e-dc90-774c902fb469"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "datasetInfos": [],
       "data": "<div class=\"ansiout\">Out[9]: </div>",
       "removedWidgets": [],
       "addedWidgets": {},
       "metadata": {},
       "type": "html",
       "arguments": {}
      }
     },
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[9]: </div>"
      ]
     }
    },
    {
     "output_type": "display_data",
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "datasetInfos": [],
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>chunks</th>\n      <th>begin</th>\n      <th>end</th>\n      <th>sentence_id</th>\n      <th>entities</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>EXCLUSIVE DISTRIBUTOR AGREEMENT</td>\n      <td>0</td>\n      <td>30</td>\n      <td>0</td>\n      <td>DOC</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>April 15, 1994</td>\n      <td>57</td>\n      <td>70</td>\n      <td>0</td>\n      <td>EFFDATE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>IMRS OPERATIONS INC</td>\n      <td>87</td>\n      <td>105</td>\n      <td>0</td>\n      <td>PARTY</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Developer</td>\n      <td>259</td>\n      <td>267</td>\n      <td>1</td>\n      <td>ALIAS</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Delteq Pte Ltd</td>\n      <td>276</td>\n      <td>289</td>\n      <td>1</td>\n      <td>PARTY</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Distributor</td>\n      <td>510</td>\n      <td>520</td>\n      <td>1</td>\n      <td>ALIAS</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "textData": null,
       "removedWidgets": [],
       "addedWidgets": {},
       "metadata": {},
       "type": "htmlSandbox",
       "arguments": {}
      }
     },
     "data": {
      "text/html": [
       "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>chunks</th>\n      <th>begin</th>\n      <th>end</th>\n      <th>sentence_id</th>\n      <th>entities</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>EXCLUSIVE DISTRIBUTOR AGREEMENT</td>\n      <td>0</td>\n      <td>30</td>\n      <td>0</td>\n      <td>DOC</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>April 15, 1994</td>\n      <td>57</td>\n      <td>70</td>\n      <td>0</td>\n      <td>EFFDATE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>IMRS OPERATIONS INC</td>\n      <td>87</td>\n      <td>105</td>\n      <td>0</td>\n      <td>PARTY</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Developer</td>\n      <td>259</td>\n      <td>267</td>\n      <td>1</td>\n      <td>ALIAS</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Delteq Pte Ltd</td>\n      <td>276</td>\n      <td>289</td>\n      <td>1</td>\n      <td>PARTY</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Distributor</td>\n      <td>510</td>\n      <td>520</td>\n      <td>1</td>\n      <td>ALIAS</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
      ]
     }
    }
   ],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### NER Visualizer\n",
    "\n",
    "For saving the visualization result as html, provide `save_path` parameter in the display function."
   ],
   "metadata": {
    "id": "0e91726a-2fd2-4432-a3ff-fe5238b00e9d",
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "0b880ac2-dc5d-44b1-a837-df1e973f1061",
     "inputWidgets": {},
     "title": ""
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sparknlp_display import NerVisualizer\n",
    "\n",
    "visualiser = NerVisualizer()\n",
    "\n",
    "vis = visualiser.display(light_result[0], label_col='ner_chunk', document_col='document',return_html=True)\n",
    "\n",
    "displayHTML(vis)"
   ],
   "metadata": {
    "id": "1f9e05ec-1724-4d53-b4e2-68e454c4e3bb",
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "85f123b8-bc25-4847-a6c3-dfeecdf17892",
     "inputWidgets": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "executionInfo": {
     "user_tz": -120,
     "timestamp": 1665043103519,
     "elapsed": 21,
     "status": "ok",
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     }
    },
    "outputId": "2d81344b-2387-4751-bb5d-54d89c90edce"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "datasetInfos": [],
       "data": "\n<style>\n    @import url('https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700&display=swap');\n    @import url('https://fonts.googleapis.com/css2?family=Vistol Regular:wght@300;400;500;600;700&display=swap');\n    \n    .spark-nlp-display-scroll-entities {\n        border: 1px solid #E7EDF0;\n        border-radius: 3px;\n        text-align: justify;\n        \n    }\n    .spark-nlp-display-scroll-entities span {  \n        font-size: 14px;\n        line-height: 24px;\n        color: #536B76;\n        font-family: 'Montserrat', sans-serif !important;\n    }\n    \n    .spark-nlp-display-entity-wrapper{\n    \n        display: inline-grid;\n        text-align: center;\n        border-radius: 4px;\n        margin: 0 2px 5px 2px;\n        padding: 1px\n    }\n    .spark-nlp-display-entity-name{\n        font-size: 14px;\n        line-height: 24px;\n        font-family: 'Montserrat', sans-serif !important;\n        \n        background: #f1f2f3;\n        border-width: medium;\n        text-align: center;\n        \n        font-weight: 400;\n        \n        border-radius: 5px;\n        padding: 2px 5px;\n        display: block;\n        margin: 3px 2px;\n    \n    }\n    .spark-nlp-display-entity-type{\n        font-size: 14px;\n        line-height: 24px;\n        color: #ffffff;\n        font-family: 'Montserrat', sans-serif !important;\n        \n        text-transform: uppercase;\n        \n        font-weight: 500;\n\n        display: block;\n        padding: 3px 5px;\n    }\n    \n    .spark-nlp-display-entity-resolution{\n        font-size: 14px;\n        line-height: 24px;\n        color: #ffffff;\n        font-family: 'Vistol Regular', sans-serif !important;\n        \n        text-transform: uppercase;\n        \n        font-weight: 500;\n\n        display: block;\n        padding: 3px 5px;\n    }\n    \n    .spark-nlp-display-others{\n        font-size: 14px;\n        line-height: 24px;\n        font-family: 'Montserrat', sans-serif !important;\n        \n        font-weight: 400;\n    }\n\n</style>\n <span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #310F1B\"><span class=\"spark-nlp-display-entity-name\">EXCLUSIVE DISTRIBUTOR AGREEMENT </span><span class=\"spark-nlp-display-entity-type\">DOC</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> (\" Agreement \") dated as </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #A2B948\"><span class=\"spark-nlp-display-entity-name\">April 15, 1994 </span><span class=\"spark-nlp-display-entity-type\">EFFDATE</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> by and between </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #BD68B8\"><span class=\"spark-nlp-display-entity-name\">IMRS OPERATIONS INC </span><span class=\"spark-nlp-display-entity-type\">PARTY</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">., a Delaware corporation with its principal place of business at 777 Long Ridge Road, Stamford, Connecticut 06902, U.S.A. (hereinafter referred to as \" </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #2B7E78\"><span class=\"spark-nlp-display-entity-name\">Developer </span><span class=\"spark-nlp-display-entity-type\">ALIAS</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> \") and </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #BD68B8\"><span class=\"spark-nlp-display-entity-name\">Delteq Pte Ltd </span><span class=\"spark-nlp-display-entity-type\">PARTY</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, a Singapore company (and a subsidiary of Wuthelam Industries (S) Pte LTD ) with its principal place of business at 215 Henderson Road , #101-03 Henderson Industrial Park , Singapore 0315 ( hereinafter referred to as \" </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #2B7E78\"><span class=\"spark-nlp-display-entity-name\">Distributor </span><span class=\"spark-nlp-display-entity-type\">ALIAS</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> \").</span></div>",
       "textData": null,
       "removedWidgets": [],
       "addedWidgets": {},
       "metadata": {},
       "type": "htmlSandbox",
       "arguments": {}
      }
     },
     "data": {
      "text/html": [
       "\n<style>\n    @import url('https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700&display=swap');\n    @import url('https://fonts.googleapis.com/css2?family=Vistol Regular:wght@300;400;500;600;700&display=swap');\n    \n    .spark-nlp-display-scroll-entities {\n        border: 1px solid #E7EDF0;\n        border-radius: 3px;\n        text-align: justify;\n        \n    }\n    .spark-nlp-display-scroll-entities span {  \n        font-size: 14px;\n        line-height: 24px;\n        color: #536B76;\n        font-family: 'Montserrat', sans-serif !important;\n    }\n    \n    .spark-nlp-display-entity-wrapper{\n    \n        display: inline-grid;\n        text-align: center;\n        border-radius: 4px;\n        margin: 0 2px 5px 2px;\n        padding: 1px\n    }\n    .spark-nlp-display-entity-name{\n        font-size: 14px;\n        line-height: 24px;\n        font-family: 'Montserrat', sans-serif !important;\n        \n        background: #f1f2f3;\n        border-width: medium;\n        text-align: center;\n        \n        font-weight: 400;\n        \n        border-radius: 5px;\n        padding: 2px 5px;\n        display: block;\n        margin: 3px 2px;\n    \n    }\n    .spark-nlp-display-entity-type{\n        font-size: 14px;\n        line-height: 24px;\n        color: #ffffff;\n        font-family: 'Montserrat', sans-serif !important;\n        \n        text-transform: uppercase;\n        \n        font-weight: 500;\n\n        display: block;\n        padding: 3px 5px;\n    }\n    \n    .spark-nlp-display-entity-resolution{\n        font-size: 14px;\n        line-height: 24px;\n        color: #ffffff;\n        font-family: 'Vistol Regular', sans-serif !important;\n        \n        text-transform: uppercase;\n        \n        font-weight: 500;\n\n        display: block;\n        padding: 3px 5px;\n    }\n    \n    .spark-nlp-display-others{\n        font-size: 14px;\n        line-height: 24px;\n        font-family: 'Montserrat', sans-serif !important;\n        \n        font-weight: 400;\n    }\n\n</style>\n <span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #310F1B\"><span class=\"spark-nlp-display-entity-name\">EXCLUSIVE DISTRIBUTOR AGREEMENT </span><span class=\"spark-nlp-display-entity-type\">DOC</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> (\" Agreement \") dated as </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #A2B948\"><span class=\"spark-nlp-display-entity-name\">April 15, 1994 </span><span class=\"spark-nlp-display-entity-type\">EFFDATE</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> by and between </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #BD68B8\"><span class=\"spark-nlp-display-entity-name\">IMRS OPERATIONS INC </span><span class=\"spark-nlp-display-entity-type\">PARTY</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">., a Delaware corporation with its principal place of business at 777 Long Ridge Road, Stamford, Connecticut 06902, U.S.A. (hereinafter referred to as \" </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #2B7E78\"><span class=\"spark-nlp-display-entity-name\">Developer </span><span class=\"spark-nlp-display-entity-type\">ALIAS</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> \") and </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #BD68B8\"><span class=\"spark-nlp-display-entity-name\">Delteq Pte Ltd </span><span class=\"spark-nlp-display-entity-type\">PARTY</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, a Singapore company (and a subsidiary of Wuthelam Industries (S) Pte LTD ) with its principal place of business at 215 Henderson Road , #101-03 Henderson Industrial Park , Singapore 0315 ( hereinafter referred to as \" </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #2B7E78\"><span class=\"spark-nlp-display-entity-name\">Distributor </span><span class=\"spark-nlp-display-entity-type\">ALIAS</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> \").</span></div>"
      ]
     }
    }
   ],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Generic Pipeline for NerDL Models"
   ],
   "metadata": {
    "id": "95645147-7f43-4fc1-b668-3bb2317bb74f",
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "86224e18-6984-4da4-a407-5b516d84a72f",
     "inputWidgets": {},
     "title": ""
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def base_pipeline():\n",
    "    \n",
    "    documentAssembler = nlp.DocumentAssembler()\\\n",
    "        .setInputCol(\"text\")\\\n",
    "        .setOutputCol(\"document\")\n",
    "\n",
    "    sentenceDetector = nlp.SentenceDetector()\\\n",
    "        .setInputCols([\"document\"])\\\n",
    "        .setOutputCol(\"sentence\")\n",
    "\n",
    "    tokenizer = nlp.Tokenizer()\\\n",
    "        .setInputCols([\"sentence\"])\\\n",
    "        .setOutputCol(\"token\")\n",
    "    \n",
    "    pipeline = nlp.Pipeline(stages=[\n",
    "            documentAssembler,\n",
    "            sentenceDetector,\n",
    "            tokenizer])\n",
    "    \n",
    "    return pipeline"
   ],
   "metadata": {
    "executionInfo": {
     "user_tz": -120,
     "timestamp": 1665043103520,
     "elapsed": 16,
     "status": "ok",
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     }
    },
    "id": "da501a7a-aabd-477d-b19b-1e18b4ee7042",
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "30ca8e48-b03e-458b-ba65-da109f8d267d",
     "inputWidgets": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "datasetInfos": [],
       "data": "<div class=\"ansiout\"></div>",
       "removedWidgets": [],
       "addedWidgets": {},
       "metadata": {},
       "type": "html",
       "arguments": {}
      }
     },
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"
      ]
     }
    }
   ],
   "execution_count": 0
  },
  {
   "cell_type": "code",
   "source": [
    "def generic_ner_pipeline(model_name):\n",
    "    \n",
    "    embeddings = nlp.RoBertaEmbeddings.pretrained(\"roberta_embeddings_legal_roberta_base\", \"en\") \\\n",
    "            .setInputCols(\"sentence\", \"token\") \\\n",
    "            .setOutputCol(\"embeddings\")\\\n",
    "\n",
    "    ner_model = legal.NerModel.pretrained(model_name, \"en\", \"legal/models\")\\\n",
    "            .setInputCols([\"sentence\", \"token\", \"embeddings\"])\\\n",
    "            .setOutputCol(\"ner\")\n",
    "\n",
    "    ner_converter = nlp.NerConverter()\\\n",
    "            .setInputCols([\"sentence\",\"token\",\"ner\"])\\\n",
    "            .setOutputCol(\"ner_chunk\")\n",
    "\n",
    "    nlpPipeline = nlp.Pipeline(stages=[\n",
    "            base_pipeline(),\n",
    "            embeddings,\n",
    "            ner_model,\n",
    "            ner_converter])\n",
    "\n",
    "    empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "    model = nlpPipeline.fit(empty_data)\n",
    "    \n",
    "    return model"
   ],
   "metadata": {
    "executionInfo": {
     "user_tz": -120,
     "timestamp": 1665043103520,
     "elapsed": 15,
     "status": "ok",
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     }
    },
    "id": "6b050243-1a9d-4b9e-a7a8-3fc084e69d08",
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "b44e1888-df59-4b91-9145-5190284dd22c",
     "inputWidgets": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "datasetInfos": [],
       "data": "<div class=\"ansiout\"></div>",
       "removedWidgets": [],
       "addedWidgets": {},
       "metadata": {},
       "type": "html",
       "arguments": {}
      }
     },
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"
      ]
     }
    }
   ],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Generic Result Function"
   ],
   "metadata": {
    "id": "479103f2-1256-4b78-971a-55d81140d030",
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "88f62317-bdba-4d80-8fcf-b4507a5cceea",
     "inputWidgets": {},
     "title": ""
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def get_result(result):\n",
    "    result.select(F.explode(F.arrays_zip(result.ner_chunk.result, \n",
    "                                         result.ner_chunk.metadata)).alias(\"cols\")) \\\n",
    "          .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
    "                  F.expr(\"cols['1']['entity']\").alias(\"ner_label\")).show(50, truncate=False)"
   ],
   "metadata": {
    "executionInfo": {
     "user_tz": -120,
     "timestamp": 1665043103520,
     "elapsed": 14,
     "status": "ok",
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     }
    },
    "id": "19fac60f-f99a-4bf6-8668-0d40aa50a24d",
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "6bfb59b6-3248-49e9-a2e0-88fa9e54f14e",
     "inputWidgets": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "datasetInfos": [],
       "data": "<div class=\"ansiout\"></div>",
       "removedWidgets": [],
       "addedWidgets": {},
       "metadata": {},
       "type": "html",
       "arguments": {}
      }
     },
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"
      ]
     }
    }
   ],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Legal Cuad_NER_Header Model\n",
    "\n",
    "This model uses Name Entity Recognition to detect **HEADER** and **SUBHEADER** with aims to detect the different sections of a legal document."
   ],
   "metadata": {
    "id": "817a44c1-52a3-40b3-9bd2-bc7b67c4c7fe",
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "7e424bf7-bccc-415b-89d3-d4b323e47ef9",
     "inputWidgets": {},
     "title": ""
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "text = \"\"\"5. GRANT OF PATENT LICENSE\n",
    "5.1 Arizona Patent Grant. Subject to the terms and conditions of this Agreement, Arizona hereby grants to the Company a perpetual, non-exclusive, royalty-free license in, to and under the Arizona Licensed Patents for use in the Company Field throughout the world.\"\"\"\n",
    "\n",
    "model_name = \"legner_headers\"\n",
    "df = spark.createDataFrame([[text]]).toDF(\"text\")\n",
    "\n",
    "result = generic_ner_pipeline(model_name).transform(df)"
   ],
   "metadata": {
    "tags": [],
    "id": "3fa0104c-bdb7-4e4a-b3bb-f7e21f912964",
    "jupyter": {
     "outputs_hidden": true
    },
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "944728a4-d51e-4704-8831-75c70bcca132",
     "inputWidgets": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "user_tz": -120,
     "timestamp": 1665043113081,
     "elapsed": 9575,
     "status": "ok",
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     }
    },
    "outputId": "f74be03c-14db-4e90-e1c9-aee91a56af4b"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "datasetInfos": [],
       "data": "<div class=\"ansiout\">roberta_embeddings_legal_roberta_base download started this may take some time.\nApproximate size to download 447.2 MB\n\r[ | ]\r[OK!]\nlegner_headers download started this may take some time.\n\r[ | ]\r[OK!]\n</div>",
       "removedWidgets": [],
       "addedWidgets": {},
       "metadata": {},
       "type": "html",
       "arguments": {}
      }
     },
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">roberta_embeddings_legal_roberta_base download started this may take some time.\nApproximate size to download 447.2 MB\n\r[ | ]\r[OK!]\nlegner_headers download started this may take some time.\n\r[ | ]\r[OK!]\n</div>"
      ]
     }
    }
   ],
   "execution_count": 0
  },
  {
   "cell_type": "code",
   "source": [
    "get_result(result)"
   ],
   "metadata": {
    "id": "0c143057-ddfc-4823-947f-9e51506e50ce",
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "44e02cc1-e066-45a0-bc99-f474beed9128",
     "inputWidgets": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "user_tz": -120,
     "timestamp": 1665043114527,
     "elapsed": 1452,
     "status": "ok",
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     }
    },
    "outputId": "10944654-e5be-446a-fc00-ad1a74113ef0"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "datasetInfos": [],
       "data": "<div class=\"ansiout\">+--------------------------+---------+\n|chunk                     |ner_label|\n+--------------------------+---------+\n|5. GRANT OF PATENT LICENSE|HEADER   |\n|5.1 Arizona Patent Grant  |SUBHEADER|\n+--------------------------+---------+\n\n</div>",
       "removedWidgets": [],
       "addedWidgets": {},
       "metadata": {},
       "type": "html",
       "arguments": {}
      }
     },
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------------+---------+\nchunk                     |ner_label|\n+--------------------------+---------+\n5. GRANT OF PATENT LICENSE|HEADER   |\n5.1 Arizona Patent Grant  |SUBHEADER|\n+--------------------------+---------+\n\n</div>"
      ]
     }
    }
   ],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Legal Cuad_NER_Obligations Model\n",
    "\n",
    "Entities:\n",
    " - OBLIGATION_SUBJECT\n",
    " - OBLIGATION_ACTION\n",
    " - OBLIGATION\n",
    " - OBLIGATION_INDIRECT_OBJECT"
   ],
   "metadata": {
    "id": "aab56faa-0646-4c84-ac4e-e9710c0ba891",
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "1a19b03b-b40e-48a1-bff2-92771c1c12bb",
     "inputWidgets": {},
     "title": ""
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "tokenClassifier = legal.BertForTokenClassification.pretrained(\"legner_obligations\", \"en\", \"legal/models\")\\\n",
    "  .setInputCols(\"token\", \"sentence\")\\\n",
    "  .setOutputCol(\"ner\")\\\n",
    "  .setCaseSensitive(True)\n",
    "\n",
    "ner_converter = nlp.NerConverter()\\\n",
    "    .setInputCols([\"sentence\",\"token\",\"ner\"])\\\n",
    "    .setOutputCol(\"ner_chunk\")\n",
    "\n",
    "pipeline = nlp.Pipeline(stages=[\n",
    "    base_pipeline(), \n",
    "    tokenClassifier,\n",
    "    ner_converter])\n",
    "\n",
    "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "model = pipeline.fit(empty_data)"
   ],
   "metadata": {
    "id": "Bzup3rC83o-F",
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "e4780d54-a2be-472e-b72d-47971973395c",
     "inputWidgets": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "user_tz": -120,
     "timestamp": 1665043139728,
     "elapsed": 25214,
     "status": "ok",
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     }
    },
    "outputId": "ae53e3d7-e9c4-4016-b993-a40a5316ac59"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "datasetInfos": [],
       "data": "<div class=\"ansiout\">legner_obligations download started this may take some time.\n\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[OK!]\n</div>",
       "removedWidgets": [],
       "addedWidgets": {},
       "metadata": {},
       "type": "html",
       "arguments": {}
      }
     },
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">legner_obligations download started this may take some time.\n\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[OK!]\n</div>"
      ]
     }
    }
   ],
   "execution_count": 0
  },
  {
   "cell_type": "code",
   "source": [
    "# Sometimes models work better with lowercase, depending on the vocabulary of the uppercase items\n",
    "# Sometimes only uncased language models are present.\n",
    "# This one is mixed but works better with lowercase\n",
    "text = \"\"\"PPD may engage VS to perform imaging services\"\"\".lower()\n",
    "\n",
    "df = spark.createDataFrame([[text]]).toDF(\"text\")\n",
    "\n",
    "result = model.transform(df)\n"
   ],
   "metadata": {
    "tags": [],
    "id": "6e48a792-b252-42bd-8d0f-0e543240b289",
    "jupyter": {
     "outputs_hidden": true
    },
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "3d00c236-3478-4873-bbfb-a3ba0751f185",
     "inputWidgets": {},
     "title": ""
    },
    "executionInfo": {
     "user_tz": -120,
     "timestamp": 1665043140997,
     "elapsed": 1283,
     "status": "ok",
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     }
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "datasetInfos": [],
       "data": "<div class=\"ansiout\"></div>",
       "removedWidgets": [],
       "addedWidgets": {},
       "metadata": {},
       "type": "html",
       "arguments": {}
      }
     },
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"
      ]
     }
    }
   ],
   "execution_count": 0
  },
  {
   "cell_type": "code",
   "source": [
    "get_result(result)"
   ],
   "metadata": {
    "id": "56f94eaf-e394-4052-b33b-518ae5876ca1",
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "7e3fa958-97e4-46c4-b39f-079af746a2eb",
     "inputWidgets": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "user_tz": -120,
     "timestamp": 1665043143245,
     "elapsed": 2254,
     "status": "ok",
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     }
    },
    "outputId": "c3639f4a-3920-445f-d011-dad4a6ce4b9b"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "datasetInfos": [],
       "data": "<div class=\"ansiout\">+------------------+--------------------------+\n|chunk             |ner_label                 |\n+------------------+--------------------------+\n|PPD               |OBLIGATION_SUBJECT        |\n|may engage        |OBLIGATION_ACTION         |\n|VS                |OBLIGATION_INDIRECT_OBJECT|\n|to perform imaging|OBLIGATION                |\n+------------------+--------------------------+\n\n</div>",
       "removedWidgets": [],
       "addedWidgets": {},
       "metadata": {},
       "type": "html",
       "arguments": {}
      }
     },
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------------------+--------------------------+\nchunk             |ner_label                 |\n+------------------+--------------------------+\nPPD               |OBLIGATION_SUBJECT        |\nmay engage        |OBLIGATION_ACTION         |\nVS                |OBLIGATION_INDIRECT_OBJECT|\nto perform imaging|OBLIGATION                |\n+------------------+--------------------------+\n\n</div>"
      ]
     }
    }
   ],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Legal NER_Law_Money Spanish Model with RoBertaForTokenClassification\n",
    "\n",
    "Enities\n",
    " - LAW\n",
    " - MONEY"
   ],
   "metadata": {
    "id": "bd3aab70-a7e4-477c-9415-9ed845afb9c1",
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "777d9a6b-8922-416b-bd97-7d3c89f34ef6",
     "inputWidgets": {},
     "title": ""
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "tokenClassifier = nlp.RoBertaForTokenClassification.pretrained(\"legner_law_money\", \"es\", \"legal/models\") \\\n",
    "    .setInputCols([\"sentence\", \"token\"])\\\n",
    "    .setOutputCol(\"ner\")\n",
    "ner_converter = nlp.NerConverter()\\\n",
    "    .setInputCols([\"sentence\",\"token\",\"ner\"])\\\n",
    "    .setOutputCol(\"ner_chunk\")\n",
    "\n",
    "pipeline = nlp.Pipeline(stages=[\n",
    "    base_pipeline(), \n",
    "    tokenClassifier,\n",
    "    ner_converter])\n",
    "\n",
    "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "model = pipeline.fit(empty_data)"
   ],
   "metadata": {
    "id": "e350660c-4e30-42d9-8086-7f835036fa19",
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "4258d6b4-8ba5-46cc-b94f-b8e18183e3b4",
     "inputWidgets": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "user_tz": -120,
     "timestamp": 1665043181275,
     "elapsed": 38033,
     "status": "ok",
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     }
    },
    "outputId": "e6c7080c-fe38-45a2-882c-b819b96ac074"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "datasetInfos": [],
       "data": "<div class=\"ansiout\">legner_law_money download started this may take some time.\nApproximate size to download 395.1 MB\n\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[OK!]\n</div>",
       "removedWidgets": [],
       "addedWidgets": {},
       "metadata": {},
       "type": "html",
       "arguments": {}
      }
     },
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">legner_law_money download started this may take some time.\nApproximate size to download 395.1 MB\n\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[OK!]\n</div>"
      ]
     }
    }
   ],
   "execution_count": 0
  },
  {
   "cell_type": "code",
   "source": [
    "text = \"\"\"La recaudación del ministerio del interior fue de 20,000,000 euros así constatado por el artículo 24 de la Constitución Española.\"\"\"\n",
    "\n",
    "df = spark.createDataFrame([[text]]).toDF(\"text\")\n",
    "\n",
    "result = model.transform(df)"
   ],
   "metadata": {
    "executionInfo": {
     "user_tz": -120,
     "timestamp": 1665043181277,
     "elapsed": 14,
     "status": "ok",
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     }
    },
    "id": "ad62ed1d-7972-45dc-adf0-46318bfcdc4f",
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "e9994a19-0cbc-4994-a6f4-80979c339fef",
     "inputWidgets": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "datasetInfos": [],
       "data": "<div class=\"ansiout\"></div>",
       "removedWidgets": [],
       "addedWidgets": {},
       "metadata": {},
       "type": "html",
       "arguments": {}
      }
     },
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"
      ]
     }
    }
   ],
   "execution_count": 0
  },
  {
   "cell_type": "code",
   "source": [
    "get_result(result)"
   ],
   "metadata": {
    "id": "0cd698ee-0302-427b-bdf8-a43d878468cc",
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "0c7076d5-574e-4df7-b30a-00cbe8def021",
     "inputWidgets": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "user_tz": -120,
     "timestamp": 1665043184090,
     "elapsed": 2823,
     "status": "ok",
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     }
    },
    "outputId": "897f4849-8ee4-478d-a69f-79f63cc470fb"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "datasetInfos": [],
       "data": "<div class=\"ansiout\">+---------------------------------------+---------+\n|chunk                                  |ner_label|\n+---------------------------------------+---------+\n|20,000,000 euros                       |MONEY    |\n|artículo 24 de la Constitución Española|LAW      |\n+---------------------------------------+---------+\n\n</div>",
       "removedWidgets": [],
       "addedWidgets": {},
       "metadata": {},
       "type": "html",
       "arguments": {}
      }
     },
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------------------------------------+---------+\nchunk                                  |ner_label|\n+---------------------------------------+---------+\n20,000,000 euros                       |MONEY    |\nartículo 24 de la Constitución Española|LAW      |\n+---------------------------------------+---------+\n\n</div>"
      ]
     }
    }
   ],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Zero-shot Legal Example"
   ],
   "metadata": {
    "id": "bf944e21-f7e3-4282-b3c5-2bbeb04fe8a8",
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "5fe38052-a5a8-44a0-beec-b88154860212",
     "inputWidgets": {},
     "title": ""
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "`Zero-shot` is a new inference paradigm which allows us to use a model for prediction without any previous training step.\n",
    "\n",
    "For doing that, several examples (_hypotheses_) are provided and sent to the Language model, which will use `NLI (Natural Language Inference)` to check if the any information found in the text matches the examples (confirm the hypotheses).\n",
    "\n",
    "NLI usually works by trying to _confirm or reject an hypotheses_. The _hypotheses_ are the `prompts` or examples we are going to provide. If any piece of information confirm the constructed hypotheses (answer the examples we are given), then the hypotheses is confirmed and the Zero-shot is triggered.\n",
    "\n",
    "Let's see it  in action."
   ],
   "metadata": {
    "id": "dd10f5c5",
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "eb18c1c7-9fd4-4150-9af4-7dca2941314e",
     "inputWidgets": {},
     "title": ""
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# from sparknlp.base import *\n",
    "# from sparknlp.annotator import *\n",
    "# from pyspark.ml import Pipeline\n",
    "# from sparknlp_jsl.annotator import *\n",
    "\n",
    "documentAssembler = nlp.DocumentAssembler()\\\n",
    "  .setInputCol(\"text\")\\\n",
    "  .setOutputCol(\"document\")\n",
    "\n",
    "sen = nlp.SentenceDetector()\\\n",
    "  .setInputCols([\"document\"])\\\n",
    "  .setOutputCol(\"sentence\")\n",
    "\n",
    "sparktokenizer = nlp.Tokenizer()\\\n",
    "  .setInputCols(\"sentence\")\\\n",
    "  .setOutputCol(\"token\")\n",
    "\n",
    "zero_shot_ner = legal.ZeroShotNerModel.pretrained(\"legner_roberta_zeroshot\", \"en\", \"legal/models\")\\\n",
    "    .setInputCols([\"sentence\", \"token\"])\\\n",
    "    .setOutputCol(\"zero_shot_ner\")\\\n",
    "    .setEntityDefinitions(\n",
    "        {\n",
    "            \"DATE\": ['When was the company acquisition?', 'When was the company purchase agreement?', \"When was the agreement?\"],\n",
    "            \"ORG\": [\"Which company?\"],\n",
    "            \"STATE\": [\"Which state?\"],\n",
    "            \"AGREEMENT\": [\"What kind of agreement?\"],\n",
    "            \"LICENSE\": [\"What kind of license?\"],\n",
    "            \"LICENSE_RECIPIENT\": [\"To whom the license is granted?\"]\n",
    "        })\n",
    "    \n",
    "\n",
    "nerconverter = nlp.NerConverter()\\\n",
    "  .setInputCols([\"sentence\", \"token\", \"zero_shot_ner\"])\\\n",
    "  .setOutputCol(\"ner_chunk\")\n",
    "\n",
    "pipeline =  nlp.Pipeline(stages=[\n",
    "  documentAssembler,\n",
    "  sen,\n",
    "  sparktokenizer,\n",
    "  zero_shot_ner,\n",
    "  nerconverter,\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "id": "6610e9d9-0cd6-45ad-9fe4-e0d9ac3314e3",
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "5f2e3250-ec74-442c-a91a-01df4c64cbf6",
     "inputWidgets": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "user_tz": -120,
     "timestamp": 1665043217130,
     "elapsed": 33047,
     "status": "ok",
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     }
    },
    "outputId": "65005e84-102d-4933-f88d-1f851aac6777"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "datasetInfos": [],
       "data": "<div class=\"ansiout\">legner_roberta_zeroshot download started this may take some time.\n\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[OK!]\n</div>",
       "removedWidgets": [],
       "addedWidgets": {},
       "metadata": {},
       "type": "html",
       "arguments": {}
      }
     },
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">legner_roberta_zeroshot download started this may take some time.\n\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[OK!]\n</div>"
      ]
     }
    }
   ],
   "execution_count": 0
  },
  {
   "cell_type": "code",
   "source": [
    "from pyspark.sql.types import StructType,StructField, StringType\n",
    "sample_text = [\"In March 2012, as part of a longer-term strategy, the Company acquired Vertro, Inc., which owned and operated the ALOT product portfolio.\",\n",
    "              \"In February 2017, the Company entered into an asset purchase agreement with NetSeer, Inc.\",\n",
    "              \"This INTELLECTUAL PROPERTY AGREEMENT, dated as of December 31, 2018 (the 'Effective Date') is entered into by and between Armstrong Flooring, Inc., a Delaware corporation ('Seller') and AFI Licensing LLC, a Delaware company (the 'Licensee')\",\n",
    "              \"The Company hereby grants to Seller a perpetual, non- exclusive, royalty-free license\"]\n",
    "\n",
    "p_model = pipeline.fit(spark.createDataFrame([[\"\"]]).toDF(\"text\"))\n",
    "\n",
    "res = p_model.transform(spark.createDataFrame(sample_text, StringType()).toDF(\"text\"))"
   ],
   "metadata": {
    "executionInfo": {
     "user_tz": -120,
     "timestamp": 1665043217130,
     "elapsed": 3,
     "status": "ok",
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     }
    },
    "id": "9f49d722-71aa-488e-af32-6de899aa5b2a",
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "7dd45dcd-76a1-402b-a406-1d5d2a353aed",
     "inputWidgets": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "datasetInfos": [],
       "data": "<div class=\"ansiout\"></div>",
       "removedWidgets": [],
       "addedWidgets": {},
       "metadata": {},
       "type": "html",
       "arguments": {}
      }
     },
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"
      ]
     }
    }
   ],
   "execution_count": 0
  },
  {
   "cell_type": "code",
   "source": [
    "# from pyspark.sql import functions as F\n",
    "\n",
    "res.select(F.explode(F.arrays_zip(res.ner_chunk.result, res.ner_chunk.begin, res.ner_chunk.end, res.ner_chunk.metadata)).alias(\"cols\")) \\\n",
    "   .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
    "           F.expr(\"cols['3']['entity']\").alias(\"ner_label\"))\\\n",
    "   .filter(\"ner_label!='O'\")\\\n",
    "   .show(truncate=False)"
   ],
   "metadata": {
    "id": "233fd7d6-c84d-4240-9b57-9912f6256b71",
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "f79a2967-e5b9-4d61-ab5a-01b4e69c9bd5",
     "inputWidgets": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "user_tz": -120,
     "timestamp": 1665043228591,
     "elapsed": 11463,
     "status": "ok",
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     }
    },
    "outputId": "2c4fbc53-8c1b-4274-f504-c9a356723c79"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "datasetInfos": [],
       "data": "<div class=\"ansiout\"></div>",
       "removedWidgets": [],
       "addedWidgets": {},
       "metadata": {},
       "type": "html",
       "arguments": {}
      }
     },
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"
      ]
     }
    },
    {
     "output_type": "display_data",
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "data": "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">Py4JJavaError</span>                             Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3850215879366149&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-red-fg\"># from pyspark.sql import functions as F</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> \n<span class=\"ansi-green-fg\">----&gt; 3</span><span class=\"ansi-red-fg\"> </span>res<span class=\"ansi-blue-fg\">.</span>select<span class=\"ansi-blue-fg\">(</span>F<span class=\"ansi-blue-fg\">.</span>explode<span class=\"ansi-blue-fg\">(</span>F<span class=\"ansi-blue-fg\">.</span>arrays_zip<span class=\"ansi-blue-fg\">(</span>res<span class=\"ansi-blue-fg\">.</span>ner_chunk<span class=\"ansi-blue-fg\">.</span>result<span class=\"ansi-blue-fg\">,</span> res<span class=\"ansi-blue-fg\">.</span>ner_chunk<span class=\"ansi-blue-fg\">.</span>begin<span class=\"ansi-blue-fg\">,</span> res<span class=\"ansi-blue-fg\">.</span>ner_chunk<span class=\"ansi-blue-fg\">.</span>end<span class=\"ansi-blue-fg\">,</span> res<span class=\"ansi-blue-fg\">.</span>ner_chunk<span class=\"ansi-blue-fg\">.</span>metadata<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>alias<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;cols&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-red-fg\"> </span><span class=\"ansi-red-fg\">\\</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span>    .select(F.expr(&#34;cols[&#39;0&#39;]&#34;).alias(&#34;chunk&#34;),\n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span>            F.expr(&#34;cols[&#39;3&#39;][&#39;entity&#39;]&#34;).alias(&#34;ner_label&#34;))\\\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/dataframe.py</span> in <span class=\"ansi-cyan-fg\">show</span><span class=\"ansi-blue-fg\">(self, n, truncate, vertical)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    490</span>             print<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jdf<span class=\"ansi-blue-fg\">.</span>showString<span class=\"ansi-blue-fg\">(</span>n<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">20</span><span class=\"ansi-blue-fg\">,</span> vertical<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    491</span>         <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 492</span><span class=\"ansi-red-fg\">             </span>print<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jdf<span class=\"ansi-blue-fg\">.</span>showString<span class=\"ansi-blue-fg\">(</span>n<span class=\"ansi-blue-fg\">,</span> int<span class=\"ansi-blue-fg\">(</span>truncate<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> vertical<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    493</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    494</span>     <span class=\"ansi-green-fg\">def</span> __repr__<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1302</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">-&gt; 1304</span><span class=\"ansi-red-fg\">         return_value = get_return_value(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1305</span>             answer, self.gateway_client, self.target_id, self.name)\n<span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    115</span>     <span class=\"ansi-green-fg\">def</span> deco<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    116</span>         <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 117</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    118</span>         <span class=\"ansi-green-fg\">except</span> py4j<span class=\"ansi-blue-fg\">.</span>protocol<span class=\"ansi-blue-fg\">.</span>Py4JJavaError <span class=\"ansi-green-fg\">as</span> e<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    119</span>             converted <span class=\"ansi-blue-fg\">=</span> convert_exception<span class=\"ansi-blue-fg\">(</span>e<span class=\"ansi-blue-fg\">.</span>java_exception<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py</span> in <span class=\"ansi-cyan-fg\">get_return_value</span><span class=\"ansi-blue-fg\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    324</span>             value <span class=\"ansi-blue-fg\">=</span> OUTPUT_CONVERTER<span class=\"ansi-blue-fg\">[</span>type<span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">(</span>answer<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">2</span><span class=\"ansi-blue-fg\">:</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">,</span> gateway_client<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    325</span>             <span class=\"ansi-green-fg\">if</span> answer<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-blue-fg\">==</span> REFERENCE_TYPE<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 326</span><span class=\"ansi-red-fg\">                 raise Py4JJavaError(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    327</span>                     <span class=\"ansi-blue-fg\">&#34;An error occurred while calling {0}{1}{2}.\\n&#34;</span><span class=\"ansi-blue-fg\">.</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    328</span>                     format(target_id, &#34;.&#34;, name), value)\n\n<span class=\"ansi-red-fg\">Py4JJavaError</span>: An error occurred while calling o3575.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 12 in stage 213.0 failed 4 times, most recent failure: Lost task 12.3 in stage 213.0 (TID 1818) (10.139.64.6 executor 2): com.johnsnowlabs.license.exceptions.JslInvalidSparkContextException: Error checking Databricks permissions\n.Please make sure there&#39;s a valid Spark Context initialized.\n\tat com.johnsnowlabs.license.AbstractDatabricksPlatform.$anonfun$getSparkSession$3(Platforms.scala:161)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat com.johnsnowlabs.license.AbstractDatabricksPlatform.getSparkSession(Platforms.scala:161)\n\tat com.johnsnowlabs.license.DatabricksPlatform.checkValidLicense(Platforms.scala:209)\n\tat com.johnsnowlabs.license.CheckLicense.checkValidEnvironment(CheckLicense.scala:85)\n\tat com.johnsnowlabs.license.CheckLicense.checkValidEnvironment$(CheckLicense.scala:83)\n\tat com.johnsnowlabs.nlp.annotators.ner.ZeroShotNerModel.checkValidEnvironment(ZeroShotNerModel.scala:107)\n\tat com.johnsnowlabs.license.CheckLicense.checkValidScopesAndEnvironment(CheckLicense.scala:109)\n\tat com.johnsnowlabs.license.CheckLicense.checkValidScopesAndEnvironment$(CheckLicense.scala:107)\n\tat com.johnsnowlabs.nlp.annotators.ner.ZeroShotNerModel.checkValidScopesAndEnvironment(ZeroShotNerModel.scala:107)\n\tat com.johnsnowlabs.legal.token_classification.ner.ZeroShotNerModel.batchAnnotate(ZeroShotNerModel.scala:16)\n\tat com.johnsnowlabs.nlp.HasBatchedAnnotate.$anonfun$batchProcess$1(HasBatchedAnnotate.scala:59)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:757)\n\tat org.apache.spark.sql.execution.collect.UnsafeRowBatchUtils$.encodeUnsafeRows(UnsafeRowBatchUtils.scala:80)\n\tat org.apache.spark.sql.execution.collect.Collector.$anonfun$processFunc$1(Collector.scala:178)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$3(ResultTask.scala:75)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$1(ResultTask.scala:75)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:55)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:150)\n\tat org.apache.spark.scheduler.Task.$anonfun$run$1(Task.scala:119)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:91)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$13(Executor.scala:819)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1657)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:822)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:678)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2873)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2820)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2814)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2814)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1350)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1350)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1350)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3081)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3022)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3010)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1112)\n\tat org.apache.spark.SparkContext.runJobInternal(SparkContext.scala:2494)\n\tat org.apache.spark.sql.execution.collect.Collector.runSparkJobs(Collector.scala:289)\n\tat org.apache.spark.sql.execution.collect.Collector.collect(Collector.scala:299)\n\tat org.apache.spark.sql.execution.collect.Collector$.collect(Collector.scala:82)\n\tat org.apache.spark.sql.execution.collect.Collector$.collect(Collector.scala:88)\n\tat org.apache.spark.sql.execution.collect.InternalRowFormat$.collect(cachedSparkResults.scala:75)\n\tat org.apache.spark.sql.execution.collect.InternalRowFormat$.collect(cachedSparkResults.scala:62)\n\tat org.apache.spark.sql.execution.ResultCacheManager.$anonfun$getOrComputeResultInternal$1(ResultCacheManager.scala:510)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.execution.ResultCacheManager.getOrComputeResultInternal(ResultCacheManager.scala:509)\n\tat org.apache.spark.sql.execution.ResultCacheManager.getOrComputeResult(ResultCacheManager.scala:397)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollectResult(limit.scala:59)\n\tat org.apache.spark.sql.Dataset.collectResult(Dataset.scala:3041)\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3833)\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:2765)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3825)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$5(SQLExecution.scala:156)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:299)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:130)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:854)\n\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:103)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:249)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3823)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2765)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2972)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:317)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:354)\n\tat sun.reflect.GeneratedMethodAccessor456.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: com.johnsnowlabs.license.exceptions.JslInvalidSparkContextException: Error checking Databricks permissions\n.Please make sure there&#39;s a valid Spark Context initialized.\n\tat com.johnsnowlabs.license.AbstractDatabricksPlatform.$anonfun$getSparkSession$3(Platforms.scala:161)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat com.johnsnowlabs.license.AbstractDatabricksPlatform.getSparkSession(Platforms.scala:161)\n\tat com.johnsnowlabs.license.DatabricksPlatform.checkValidLicense(Platforms.scala:209)\n\tat com.johnsnowlabs.license.CheckLicense.checkValidEnvironment(CheckLicense.scala:85)\n\tat com.johnsnowlabs.license.CheckLicense.checkValidEnvironment$(CheckLicense.scala:83)\n\tat com.johnsnowlabs.nlp.annotators.ner.ZeroShotNerModel.checkValidEnvironment(ZeroShotNerModel.scala:107)\n\tat com.johnsnowlabs.license.CheckLicense.checkValidScopesAndEnvironment(CheckLicense.scala:109)\n\tat com.johnsnowlabs.license.CheckLicense.checkValidScopesAndEnvironment$(CheckLicense.scala:107)\n\tat com.johnsnowlabs.nlp.annotators.ner.ZeroShotNerModel.checkValidScopesAndEnvironment(ZeroShotNerModel.scala:107)\n\tat com.johnsnowlabs.legal.token_classification.ner.ZeroShotNerModel.batchAnnotate(ZeroShotNerModel.scala:16)\n\tat com.johnsnowlabs.nlp.HasBatchedAnnotate.$anonfun$batchProcess$1(HasBatchedAnnotate.scala:59)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:757)\n\tat org.apache.spark.sql.execution.collect.UnsafeRowBatchUtils$.encodeUnsafeRows(UnsafeRowBatchUtils.scala:80)\n\tat org.apache.spark.sql.execution.collect.Collector.$anonfun$processFunc$1(Collector.scala:178)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$3(ResultTask.scala:75)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$1(ResultTask.scala:75)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:55)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:150)\n\tat org.apache.spark.scheduler.Task.$anonfun$run$1(Task.scala:119)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:91)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$13(Executor.scala:819)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1657)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:822)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:678)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n</div>",
       "errorSummary": "org.apache.spark.SparkException: Job aborted due to stage failure: Task 12 in stage 213.0 failed 4 times, most recent failure: Lost task 12.3 in stage 213.0 (TID 1818) (10.139.64.6 executor 2): com.johnsnowlabs.license.exceptions.JslInvalidSparkContextException: Error checking Databricks permissions",
       "metadata": {},
       "errorTraceType": "html",
       "type": "ipynbError",
       "arguments": {}
      }
     },
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">Py4JJavaError</span>                             Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3850215879366149&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-red-fg\"># from pyspark.sql import functions as F</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> \n<span class=\"ansi-green-fg\">----&gt; 3</span><span class=\"ansi-red-fg\"> </span>res<span class=\"ansi-blue-fg\">.</span>select<span class=\"ansi-blue-fg\">(</span>F<span class=\"ansi-blue-fg\">.</span>explode<span class=\"ansi-blue-fg\">(</span>F<span class=\"ansi-blue-fg\">.</span>arrays_zip<span class=\"ansi-blue-fg\">(</span>res<span class=\"ansi-blue-fg\">.</span>ner_chunk<span class=\"ansi-blue-fg\">.</span>result<span class=\"ansi-blue-fg\">,</span> res<span class=\"ansi-blue-fg\">.</span>ner_chunk<span class=\"ansi-blue-fg\">.</span>begin<span class=\"ansi-blue-fg\">,</span> res<span class=\"ansi-blue-fg\">.</span>ner_chunk<span class=\"ansi-blue-fg\">.</span>end<span class=\"ansi-blue-fg\">,</span> res<span class=\"ansi-blue-fg\">.</span>ner_chunk<span class=\"ansi-blue-fg\">.</span>metadata<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>alias<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;cols&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-red-fg\"> </span><span class=\"ansi-red-fg\">\\</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span>    .select(F.expr(&#34;cols[&#39;0&#39;]&#34;).alias(&#34;chunk&#34;),\n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span>            F.expr(&#34;cols[&#39;3&#39;][&#39;entity&#39;]&#34;).alias(&#34;ner_label&#34;))\\\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/dataframe.py</span> in <span class=\"ansi-cyan-fg\">show</span><span class=\"ansi-blue-fg\">(self, n, truncate, vertical)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    490</span>             print<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jdf<span class=\"ansi-blue-fg\">.</span>showString<span class=\"ansi-blue-fg\">(</span>n<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">20</span><span class=\"ansi-blue-fg\">,</span> vertical<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    491</span>         <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 492</span><span class=\"ansi-red-fg\">             </span>print<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jdf<span class=\"ansi-blue-fg\">.</span>showString<span class=\"ansi-blue-fg\">(</span>n<span class=\"ansi-blue-fg\">,</span> int<span class=\"ansi-blue-fg\">(</span>truncate<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> vertical<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    493</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    494</span>     <span class=\"ansi-green-fg\">def</span> __repr__<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1302</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">-&gt; 1304</span><span class=\"ansi-red-fg\">         return_value = get_return_value(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1305</span>             answer, self.gateway_client, self.target_id, self.name)\n<span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    115</span>     <span class=\"ansi-green-fg\">def</span> deco<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    116</span>         <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 117</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    118</span>         <span class=\"ansi-green-fg\">except</span> py4j<span class=\"ansi-blue-fg\">.</span>protocol<span class=\"ansi-blue-fg\">.</span>Py4JJavaError <span class=\"ansi-green-fg\">as</span> e<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    119</span>             converted <span class=\"ansi-blue-fg\">=</span> convert_exception<span class=\"ansi-blue-fg\">(</span>e<span class=\"ansi-blue-fg\">.</span>java_exception<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py</span> in <span class=\"ansi-cyan-fg\">get_return_value</span><span class=\"ansi-blue-fg\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    324</span>             value <span class=\"ansi-blue-fg\">=</span> OUTPUT_CONVERTER<span class=\"ansi-blue-fg\">[</span>type<span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">(</span>answer<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">2</span><span class=\"ansi-blue-fg\">:</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">,</span> gateway_client<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    325</span>             <span class=\"ansi-green-fg\">if</span> answer<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-blue-fg\">==</span> REFERENCE_TYPE<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 326</span><span class=\"ansi-red-fg\">                 raise Py4JJavaError(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    327</span>                     <span class=\"ansi-blue-fg\">&#34;An error occurred while calling {0}{1}{2}.\\n&#34;</span><span class=\"ansi-blue-fg\">.</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    328</span>                     format(target_id, &#34;.&#34;, name), value)\n\n<span class=\"ansi-red-fg\">Py4JJavaError</span>: An error occurred while calling o3575.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 12 in stage 213.0 failed 4 times, most recent failure: Lost task 12.3 in stage 213.0 (TID 1818) (10.139.64.6 executor 2): com.johnsnowlabs.license.exceptions.JslInvalidSparkContextException: Error checking Databricks permissions\n.Please make sure there&#39;s a valid Spark Context initialized.\n\tat com.johnsnowlabs.license.AbstractDatabricksPlatform.$anonfun$getSparkSession$3(Platforms.scala:161)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat com.johnsnowlabs.license.AbstractDatabricksPlatform.getSparkSession(Platforms.scala:161)\n\tat com.johnsnowlabs.license.DatabricksPlatform.checkValidLicense(Platforms.scala:209)\n\tat com.johnsnowlabs.license.CheckLicense.checkValidEnvironment(CheckLicense.scala:85)\n\tat com.johnsnowlabs.license.CheckLicense.checkValidEnvironment$(CheckLicense.scala:83)\n\tat com.johnsnowlabs.nlp.annotators.ner.ZeroShotNerModel.checkValidEnvironment(ZeroShotNerModel.scala:107)\n\tat com.johnsnowlabs.license.CheckLicense.checkValidScopesAndEnvironment(CheckLicense.scala:109)\n\tat com.johnsnowlabs.license.CheckLicense.checkValidScopesAndEnvironment$(CheckLicense.scala:107)\n\tat com.johnsnowlabs.nlp.annotators.ner.ZeroShotNerModel.checkValidScopesAndEnvironment(ZeroShotNerModel.scala:107)\n\tat com.johnsnowlabs.legal.token_classification.ner.ZeroShotNerModel.batchAnnotate(ZeroShotNerModel.scala:16)\n\tat com.johnsnowlabs.nlp.HasBatchedAnnotate.$anonfun$batchProcess$1(HasBatchedAnnotate.scala:59)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:757)\n\tat org.apache.spark.sql.execution.collect.UnsafeRowBatchUtils$.encodeUnsafeRows(UnsafeRowBatchUtils.scala:80)\n\tat org.apache.spark.sql.execution.collect.Collector.$anonfun$processFunc$1(Collector.scala:178)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$3(ResultTask.scala:75)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$1(ResultTask.scala:75)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:55)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:150)\n\tat org.apache.spark.scheduler.Task.$anonfun$run$1(Task.scala:119)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:91)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$13(Executor.scala:819)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1657)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:822)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:678)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2873)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2820)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2814)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2814)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1350)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1350)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1350)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3081)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3022)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3010)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1112)\n\tat org.apache.spark.SparkContext.runJobInternal(SparkContext.scala:2494)\n\tat org.apache.spark.sql.execution.collect.Collector.runSparkJobs(Collector.scala:289)\n\tat org.apache.spark.sql.execution.collect.Collector.collect(Collector.scala:299)\n\tat org.apache.spark.sql.execution.collect.Collector$.collect(Collector.scala:82)\n\tat org.apache.spark.sql.execution.collect.Collector$.collect(Collector.scala:88)\n\tat org.apache.spark.sql.execution.collect.InternalRowFormat$.collect(cachedSparkResults.scala:75)\n\tat org.apache.spark.sql.execution.collect.InternalRowFormat$.collect(cachedSparkResults.scala:62)\n\tat org.apache.spark.sql.execution.ResultCacheManager.$anonfun$getOrComputeResultInternal$1(ResultCacheManager.scala:510)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.execution.ResultCacheManager.getOrComputeResultInternal(ResultCacheManager.scala:509)\n\tat org.apache.spark.sql.execution.ResultCacheManager.getOrComputeResult(ResultCacheManager.scala:397)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollectResult(limit.scala:59)\n\tat org.apache.spark.sql.Dataset.collectResult(Dataset.scala:3041)\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3833)\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:2765)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3825)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$5(SQLExecution.scala:156)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:299)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:130)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:854)\n\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:103)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:249)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3823)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2765)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2972)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:317)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:354)\n\tat sun.reflect.GeneratedMethodAccessor456.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: com.johnsnowlabs.license.exceptions.JslInvalidSparkContextException: Error checking Databricks permissions\n.Please make sure there&#39;s a valid Spark Context initialized.\n\tat com.johnsnowlabs.license.AbstractDatabricksPlatform.$anonfun$getSparkSession$3(Platforms.scala:161)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat com.johnsnowlabs.license.AbstractDatabricksPlatform.getSparkSession(Platforms.scala:161)\n\tat com.johnsnowlabs.license.DatabricksPlatform.checkValidLicense(Platforms.scala:209)\n\tat com.johnsnowlabs.license.CheckLicense.checkValidEnvironment(CheckLicense.scala:85)\n\tat com.johnsnowlabs.license.CheckLicense.checkValidEnvironment$(CheckLicense.scala:83)\n\tat com.johnsnowlabs.nlp.annotators.ner.ZeroShotNerModel.checkValidEnvironment(ZeroShotNerModel.scala:107)\n\tat com.johnsnowlabs.license.CheckLicense.checkValidScopesAndEnvironment(CheckLicense.scala:109)\n\tat com.johnsnowlabs.license.CheckLicense.checkValidScopesAndEnvironment$(CheckLicense.scala:107)\n\tat com.johnsnowlabs.nlp.annotators.ner.ZeroShotNerModel.checkValidScopesAndEnvironment(ZeroShotNerModel.scala:107)\n\tat com.johnsnowlabs.legal.token_classification.ner.ZeroShotNerModel.batchAnnotate(ZeroShotNerModel.scala:16)\n\tat com.johnsnowlabs.nlp.HasBatchedAnnotate.$anonfun$batchProcess$1(HasBatchedAnnotate.scala:59)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:757)\n\tat org.apache.spark.sql.execution.collect.UnsafeRowBatchUtils$.encodeUnsafeRows(UnsafeRowBatchUtils.scala:80)\n\tat org.apache.spark.sql.execution.collect.Collector.$anonfun$processFunc$1(Collector.scala:178)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$3(ResultTask.scala:75)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$1(ResultTask.scala:75)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:55)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:150)\n\tat org.apache.spark.scheduler.Task.$anonfun$run$1(Task.scala:119)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:91)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$13(Executor.scala:819)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1657)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:822)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:678)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n</div>"
      ]
     }
    }
   ],
   "execution_count": 0
  },
  {
   "cell_type": "code",
   "source": [
    "lp = nlp.LightPipeline(p_model)\n",
    "lp_res_1 = lp.fullAnnotate(sample_text[2])\n",
    "lp_res_2 = lp.fullAnnotate(sample_text[3])"
   ],
   "metadata": {
    "executionInfo": {
     "user_tz": -120,
     "timestamp": 1665043235582,
     "elapsed": 6998,
     "status": "ok",
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     }
    },
    "id": "06a23e24-2872-4bb2-8dd3-32f62bdb9423",
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "354e9217-7425-4b27-a2af-a0a0bc0c2938",
     "inputWidgets": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "datasetInfos": [],
       "data": "<div class=\"ansiout\"></div>",
       "removedWidgets": [],
       "addedWidgets": {},
       "metadata": {},
       "type": "html",
       "arguments": {}
      }
     },
     "data": {
      "text/html": [
       "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"
      ]
     }
    }
   ],
   "execution_count": 0
  },
  {
   "cell_type": "code",
   "source": [
    "from sparknlp_display import NerVisualizer\n",
    "\n",
    "visualiser = NerVisualizer()\n",
    "\n",
    "vis = visualiser.display(lp_res_1[0], label_col='ner_chunk', document_col='document',return_html=True)\n",
    "\n",
    "displayHTML(vis)"
   ],
   "metadata": {
    "id": "99fc9030-2dc5-4621-b25a-ea2467aa0ccb",
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "399b4fdd-95e4-448b-a292-548e5c93cf10",
     "inputWidgets": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 157
    },
    "executionInfo": {
     "user_tz": -120,
     "timestamp": 1665043235583,
     "elapsed": 13,
     "status": "ok",
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     }
    },
    "outputId": "bcb05e21-a707-4e46-c32d-26ab08328542"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "datasetInfos": [],
       "data": "\n<style>\n    @import url('https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700&display=swap');\n    @import url('https://fonts.googleapis.com/css2?family=Vistol Regular:wght@300;400;500;600;700&display=swap');\n    \n    .spark-nlp-display-scroll-entities {\n        border: 1px solid #E7EDF0;\n        border-radius: 3px;\n        text-align: justify;\n        \n    }\n    .spark-nlp-display-scroll-entities span {  \n        font-size: 14px;\n        line-height: 24px;\n        color: #536B76;\n        font-family: 'Montserrat', sans-serif !important;\n    }\n    \n    .spark-nlp-display-entity-wrapper{\n    \n        display: inline-grid;\n        text-align: center;\n        border-radius: 4px;\n        margin: 0 2px 5px 2px;\n        padding: 1px\n    }\n    .spark-nlp-display-entity-name{\n        font-size: 14px;\n        line-height: 24px;\n        font-family: 'Montserrat', sans-serif !important;\n        \n        background: #f1f2f3;\n        border-width: medium;\n        text-align: center;\n        \n        font-weight: 400;\n        \n        border-radius: 5px;\n        padding: 2px 5px;\n        display: block;\n        margin: 3px 2px;\n    \n    }\n    .spark-nlp-display-entity-type{\n        font-size: 14px;\n        line-height: 24px;\n        color: #ffffff;\n        font-family: 'Montserrat', sans-serif !important;\n        \n        text-transform: uppercase;\n        \n        font-weight: 500;\n\n        display: block;\n        padding: 3px 5px;\n    }\n    \n    .spark-nlp-display-entity-resolution{\n        font-size: 14px;\n        line-height: 24px;\n        color: #ffffff;\n        font-family: 'Vistol Regular', sans-serif !important;\n        \n        text-transform: uppercase;\n        \n        font-weight: 500;\n\n        display: block;\n        padding: 3px 5px;\n    }\n    \n    .spark-nlp-display-others{\n        font-size: 14px;\n        line-height: 24px;\n        font-family: 'Montserrat', sans-serif !important;\n        \n        font-weight: 400;\n    }\n\n</style>\n <span class=\"spark-nlp-display-others\" style=\"background-color: white\">This </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #405187\"><span class=\"spark-nlp-display-entity-name\">INTELLECTUAL PROPERTY </span><span class=\"spark-nlp-display-entity-type\">AGREEMENT</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> AGREEMENT, dated as of </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #a6b1e1\"><span class=\"spark-nlp-display-entity-name\">December 31, 2018 </span><span class=\"spark-nlp-display-entity-type\">DATE</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> (the 'Effective Date') is entered into by and between </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #235E7F\"><span class=\"spark-nlp-display-entity-name\">Armstrong Flooring </span><span class=\"spark-nlp-display-entity-type\">LICENSE_RECIPIENT</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, Inc., a </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #B99D47\"><span class=\"spark-nlp-display-entity-name\">Delaware </span><span class=\"spark-nlp-display-entity-type\">STATE</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> corporation ('Seller') and </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #235E7F\"><span class=\"spark-nlp-display-entity-name\">AFI Licensing LLC, a Delaware company </span><span class=\"spark-nlp-display-entity-type\">LICENSE_RECIPIENT</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> (the 'Licensee')</span></div>",
       "textData": null,
       "removedWidgets": [],
       "addedWidgets": {},
       "metadata": {},
       "type": "htmlSandbox",
       "arguments": {}
      }
     },
     "data": {
      "text/html": [
       "\n<style>\n    @import url('https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700&display=swap');\n    @import url('https://fonts.googleapis.com/css2?family=Vistol Regular:wght@300;400;500;600;700&display=swap');\n    \n    .spark-nlp-display-scroll-entities {\n        border: 1px solid #E7EDF0;\n        border-radius: 3px;\n        text-align: justify;\n        \n    }\n    .spark-nlp-display-scroll-entities span {  \n        font-size: 14px;\n        line-height: 24px;\n        color: #536B76;\n        font-family: 'Montserrat', sans-serif !important;\n    }\n    \n    .spark-nlp-display-entity-wrapper{\n    \n        display: inline-grid;\n        text-align: center;\n        border-radius: 4px;\n        margin: 0 2px 5px 2px;\n        padding: 1px\n    }\n    .spark-nlp-display-entity-name{\n        font-size: 14px;\n        line-height: 24px;\n        font-family: 'Montserrat', sans-serif !important;\n        \n        background: #f1f2f3;\n        border-width: medium;\n        text-align: center;\n        \n        font-weight: 400;\n        \n        border-radius: 5px;\n        padding: 2px 5px;\n        display: block;\n        margin: 3px 2px;\n    \n    }\n    .spark-nlp-display-entity-type{\n        font-size: 14px;\n        line-height: 24px;\n        color: #ffffff;\n        font-family: 'Montserrat', sans-serif !important;\n        \n        text-transform: uppercase;\n        \n        font-weight: 500;\n\n        display: block;\n        padding: 3px 5px;\n    }\n    \n    .spark-nlp-display-entity-resolution{\n        font-size: 14px;\n        line-height: 24px;\n        color: #ffffff;\n        font-family: 'Vistol Regular', sans-serif !important;\n        \n        text-transform: uppercase;\n        \n        font-weight: 500;\n\n        display: block;\n        padding: 3px 5px;\n    }\n    \n    .spark-nlp-display-others{\n        font-size: 14px;\n        line-height: 24px;\n        font-family: 'Montserrat', sans-serif !important;\n        \n        font-weight: 400;\n    }\n\n</style>\n <span class=\"spark-nlp-display-others\" style=\"background-color: white\">This </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #405187\"><span class=\"spark-nlp-display-entity-name\">INTELLECTUAL PROPERTY </span><span class=\"spark-nlp-display-entity-type\">AGREEMENT</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> AGREEMENT, dated as of </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #a6b1e1\"><span class=\"spark-nlp-display-entity-name\">December 31, 2018 </span><span class=\"spark-nlp-display-entity-type\">DATE</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> (the 'Effective Date') is entered into by and between </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #235E7F\"><span class=\"spark-nlp-display-entity-name\">Armstrong Flooring </span><span class=\"spark-nlp-display-entity-type\">LICENSE_RECIPIENT</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, Inc., a </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #B99D47\"><span class=\"spark-nlp-display-entity-name\">Delaware </span><span class=\"spark-nlp-display-entity-type\">STATE</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> corporation ('Seller') and </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #235E7F\"><span class=\"spark-nlp-display-entity-name\">AFI Licensing LLC, a Delaware company </span><span class=\"spark-nlp-display-entity-type\">LICENSE_RECIPIENT</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> (the 'Licensee')</span></div>"
      ]
     }
    }
   ],
   "execution_count": 0
  },
  {
   "cell_type": "code",
   "source": [
    "vis = visualiser.display(lp_res_2[0], label_col='ner_chunk', document_col='document',return_html=True)\n",
    "\n",
    "displayHTML(vis)"
   ],
   "metadata": {
    "id": "aed220b8-8aba-42bb-8e5a-b2ee3438834e",
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "fa9854f7-09ea-438f-8fb1-41b5b605372d",
     "inputWidgets": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "executionInfo": {
     "user_tz": -120,
     "timestamp": 1665043235583,
     "elapsed": 9,
     "status": "ok",
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     }
    },
    "outputId": "83eb07a6-4710-4651-e27d-62e736e69b75"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "datasetInfos": [],
       "data": "\n<style>\n    @import url('https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700&display=swap');\n    @import url('https://fonts.googleapis.com/css2?family=Vistol Regular:wght@300;400;500;600;700&display=swap');\n    \n    .spark-nlp-display-scroll-entities {\n        border: 1px solid #E7EDF0;\n        border-radius: 3px;\n        text-align: justify;\n        \n    }\n    .spark-nlp-display-scroll-entities span {  \n        font-size: 14px;\n        line-height: 24px;\n        color: #536B76;\n        font-family: 'Montserrat', sans-serif !important;\n    }\n    \n    .spark-nlp-display-entity-wrapper{\n    \n        display: inline-grid;\n        text-align: center;\n        border-radius: 4px;\n        margin: 0 2px 5px 2px;\n        padding: 1px\n    }\n    .spark-nlp-display-entity-name{\n        font-size: 14px;\n        line-height: 24px;\n        font-family: 'Montserrat', sans-serif !important;\n        \n        background: #f1f2f3;\n        border-width: medium;\n        text-align: center;\n        \n        font-weight: 400;\n        \n        border-radius: 5px;\n        padding: 2px 5px;\n        display: block;\n        margin: 3px 2px;\n    \n    }\n    .spark-nlp-display-entity-type{\n        font-size: 14px;\n        line-height: 24px;\n        color: #ffffff;\n        font-family: 'Montserrat', sans-serif !important;\n        \n        text-transform: uppercase;\n        \n        font-weight: 500;\n\n        display: block;\n        padding: 3px 5px;\n    }\n    \n    .spark-nlp-display-entity-resolution{\n        font-size: 14px;\n        line-height: 24px;\n        color: #ffffff;\n        font-family: 'Vistol Regular', sans-serif !important;\n        \n        text-transform: uppercase;\n        \n        font-weight: 500;\n\n        display: block;\n        padding: 3px 5px;\n    }\n    \n    .spark-nlp-display-others{\n        font-size: 14px;\n        line-height: 24px;\n        font-family: 'Montserrat', sans-serif !important;\n        \n        font-weight: 400;\n    }\n\n</style>\n <span class=\"spark-nlp-display-others\" style=\"background-color: white\">The Company hereby grants to </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #604055\"><span class=\"spark-nlp-display-entity-name\">Seller </span><span class=\"spark-nlp-display-entity-type\">LICENSE_RECIPIENT</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> a </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #1F3552\"><span class=\"spark-nlp-display-entity-name\">perpetual </span><span class=\"spark-nlp-display-entity-type\">LICENSE</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #1F3552\"><span class=\"spark-nlp-display-entity-name\">non- exclusive </span><span class=\"spark-nlp-display-entity-type\">LICENSE</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #1F3552\"><span class=\"spark-nlp-display-entity-name\">royalty-free </span><span class=\"spark-nlp-display-entity-type\">LICENSE</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> license</span></div>",
       "textData": null,
       "removedWidgets": [],
       "addedWidgets": {},
       "metadata": {},
       "type": "htmlSandbox",
       "arguments": {}
      }
     },
     "data": {
      "text/html": [
       "\n<style>\n    @import url('https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700&display=swap');\n    @import url('https://fonts.googleapis.com/css2?family=Vistol Regular:wght@300;400;500;600;700&display=swap');\n    \n    .spark-nlp-display-scroll-entities {\n        border: 1px solid #E7EDF0;\n        border-radius: 3px;\n        text-align: justify;\n        \n    }\n    .spark-nlp-display-scroll-entities span {  \n        font-size: 14px;\n        line-height: 24px;\n        color: #536B76;\n        font-family: 'Montserrat', sans-serif !important;\n    }\n    \n    .spark-nlp-display-entity-wrapper{\n    \n        display: inline-grid;\n        text-align: center;\n        border-radius: 4px;\n        margin: 0 2px 5px 2px;\n        padding: 1px\n    }\n    .spark-nlp-display-entity-name{\n        font-size: 14px;\n        line-height: 24px;\n        font-family: 'Montserrat', sans-serif !important;\n        \n        background: #f1f2f3;\n        border-width: medium;\n        text-align: center;\n        \n        font-weight: 400;\n        \n        border-radius: 5px;\n        padding: 2px 5px;\n        display: block;\n        margin: 3px 2px;\n    \n    }\n    .spark-nlp-display-entity-type{\n        font-size: 14px;\n        line-height: 24px;\n        color: #ffffff;\n        font-family: 'Montserrat', sans-serif !important;\n        \n        text-transform: uppercase;\n        \n        font-weight: 500;\n\n        display: block;\n        padding: 3px 5px;\n    }\n    \n    .spark-nlp-display-entity-resolution{\n        font-size: 14px;\n        line-height: 24px;\n        color: #ffffff;\n        font-family: 'Vistol Regular', sans-serif !important;\n        \n        text-transform: uppercase;\n        \n        font-weight: 500;\n\n        display: block;\n        padding: 3px 5px;\n    }\n    \n    .spark-nlp-display-others{\n        font-size: 14px;\n        line-height: 24px;\n        font-family: 'Montserrat', sans-serif !important;\n        \n        font-weight: 400;\n    }\n\n</style>\n <span class=\"spark-nlp-display-others\" style=\"background-color: white\">The Company hereby grants to </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #604055\"><span class=\"spark-nlp-display-entity-name\">Seller </span><span class=\"spark-nlp-display-entity-type\">LICENSE_RECIPIENT</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> a </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #1F3552\"><span class=\"spark-nlp-display-entity-name\">perpetual </span><span class=\"spark-nlp-display-entity-type\">LICENSE</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #1F3552\"><span class=\"spark-nlp-display-entity-name\">non- exclusive </span><span class=\"spark-nlp-display-entity-type\">LICENSE</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #1F3552\"><span class=\"spark-nlp-display-entity-name\">royalty-free </span><span class=\"spark-nlp-display-entity-type\">LICENSE</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> license</span></div>"
      ]
     }
    }
   ],
   "execution_count": 0
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "showTitle": false,
     "cellMetadata": {},
     "nuid": "e2b159b2-683e-4506-9d54-8cfbf1ab07fc",
     "inputWidgets": {},
     "title": ""
    }
   },
   "outputs": [],
   "execution_count": 0
  }
 ],
 "metadata": {
  "language_info": {
   "mimetype": "text/x-python",
   "name": "python",
   "pygments_lexer": "ipython3",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.9.5",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "application/vnd.databricks.v1+notebook": {
   "notebookName": "4.NER_and_ZeroShot",
   "dashboards": [],
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "language": "python",
   "widgets": {},
   "notebookOrigID": 3705761635714119
  },
  "vscode": {
   "interpreter": {
    "hash": "ca1c4b8877e01dec1d65bc94ac0771fb7b4e7d433b24c0ced0afdc05f796f65d"
   }
  },
  "gpuClass": "standard",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
