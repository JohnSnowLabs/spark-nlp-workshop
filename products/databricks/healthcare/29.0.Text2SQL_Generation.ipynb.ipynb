{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e8ef95e8-5870-4529-9015-844189b072b0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c61af834-3011-4520-bfde-295cdd9bc99d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# **Text2SQL Generation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aec3b939-0472-452e-9f64-c0b9c16f917a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The Text-to-SQL task, which involves automatically converting natural language questions into corresponding SQL queries, has seen significant advancements with the application of state-of-the-art models. In this direction, We are excited to introduce our new Text2SQL annotator. This powerful tool revolutionizes the way you interact with databases by effortlessly translating natural language text prompts into accurate and effective SQL queries. With the integration of a state-of-the-art LLM, this annotator opens new possibilities for enhanced data retrieval and manipulation, streamlining your workflow and boosting efficiency.\n",
    "\n",
    "Also we have a new text2sql_mimicsql model that is specifically finetuned on MIMIC-III dataset schema for enhancing the precision of SQL queries derived from medical natural language queries on MIMIC dataset.\n",
    "\n",
    "In addition, we introduced a model can generate SQL queries from natural questions and custom database schemas with a single table. It is based on a large-size LLM, which is finetuned by John Snow Labs on a dataset having schemas with single tables.\n",
    "\n",
    "\n",
    "Available models can be found at the [Models Hub](https://nlp.johnsnowlabs.com/models?annotator=Text2SQL).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ec056614-34d9-4ba0-aba4-28e5ceba54fb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 🔎 MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e19aa29-ed4b-437b-831e-b94e42004c6a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "| **Index** | **Text2SQL models**        |\n",
    "|---------------|----------------------|\n",
    "| 1        |  [text2sql_mimicsql](https://nlp.johnsnowlabs.com/2023/08/14/text2sql_mimicsql_en.html)     |\n",
    "  2       |   [text2sql_with_schema_single_table](https://nlp.johnsnowlabs.com/2023/09/02/text2sql_with_schema_single_table_en.html)   \n",
    "  3      | [text2sql_with_schema_single_table_augmented](https://nlp.johnsnowlabs.com/2023/09/25/text2sql_with_schema_single_table_augmented_en.html)\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0023d828-ca58-411c-a8c8-a63fe52ee3da",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from johnsnowlabs import nlp, medical\n",
    "\n",
    "# After uploading your license run this to install all licensed Python Wheels and pre-download Jars the Spark Session JVM\n",
    "#nlp.install()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7daa0c2-902d-40d1-9b1d-a179b152254c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP Version : 5.0.2\nSpark NLP_JSL Version : 5.0.2\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"/?o=7956323724731612#setting/sparkui/0913-163204-fxwn7480/driver-5803016776336043312\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://10.139.64.11:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Databricks Shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f9f12f57d60>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sparknlp\n",
    "import sparknlp_jsl\n",
    "from sparknlp.base import *\n",
    "from sparknlp.util import *\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp_jsl.annotator import *\n",
    "from sparknlp.pretrained import ResourceDownloader\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "import pyspark.sql.types as T\n",
    "import pyspark.sql as SQL\n",
    "from pyspark import keyword_only\n",
    "\n",
    "pd.set_option('max_colwidth', 100)\n",
    "pd.set_option('display.max_columns', 100)  \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "print(\"Spark NLP Version :\", sparknlp.version())\n",
    "print(\"Spark NLP_JSL Version :\", sparknlp_jsl.version())\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4246d1b9-a5b4-40e5-83b1-91ab7bd8dd00",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 📑  **Text2SQL_MIMICSQL**\n",
    "\n",
    "This model is based on the LLM FlanT5-Large, which is finetuned with a biomedical dataset (MIMICSQL) by John Snow Labs. It can generate SQL queries from medical natural language questions on MIMIC-III dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40b2718c-e114-4cd0-a578-3b8fe146ce0a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text2sql_mimicsql download started this may take some time.\n\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[OK!]\n"
     ]
    }
   ],
   "source": [
    "document_assembler = nlp.DocumentAssembler()\\\n",
    "    .setInputCol(\"prompt\")\\\n",
    "    .setOutputCol(\"document_prompt\")\n",
    "\n",
    "text2sql_mimicsql  = medical.Text2SQL.pretrained(\"text2sql_mimicsql\", \"en\", \"clinical/models\")\\\n",
    "    .setInputCols(\"document_prompt\")\\\n",
    "    .setOutputCol(\"sql_query\")\\\n",
    "\n",
    "pipeline = nlp.Pipeline(stages=[document_assembler, text2sql_mimicsql])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d39e7217-2335-449a-af02-9a8efde84371",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model = pipeline.fit(spark.createDataFrame([[\"\"]]).toDF(\"prompt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87f615e7-68e2-4ad8-8a3f-8055caee7d93",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|result                                                                                                                                                                                                                                                                   |\n+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|[SELECT AVG ( DEMOGRAPHIC.\"AGE\" ) FROM DEMOGRAPHIC INNER JOIN DIAGNOSES on DEMOGRAPHIC.HADM_ID = DIAGNOSES.HADM_ID INNER JOIN PRESCRIPTIONS on DEMOGRAPHIC.HADM_ID = PRESCRIPTIONS.HADM_ID WHERE DIAGNOSES.\"SHORT_TITLE\" = \"Specific hst\" AND PRESCRIPTIONS.\"DRUG\" = \"1\"]|\n|[SELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_ID\" ) FROM DEMOGRAPHIC INNER JOIN PROCEDURES on DEMOGRAPHIC.HADM_ID = PROCEDURES.HADM_ID WHERE PROCEDURES.\"SHORT_TITLE\" = \"1 int mam-cor art bypass\"]                                                                      |\n|[SELECT PRESCRIPTIONS.\"FORMULARY_DRUG_CD\",PRESCRIPTIONS.\"DRUG_DOSE\" FROM DEMOGRAPHIC INNER JOIN PRESCRIPTIONS on DEMOGRAPHIC.HADM_ID = PRESCRIPTIONS.HADM_ID WHERE DEMOGRAPHIC.\"NAME\" = \"Anna Johnson\"]                                                                  |\n|[SELECT MIN ( DEMOGRAPHIC.\"AGE\" ) FROM DEMOGRAPHIC WHERE DEMOGRAPHIC.\"MARITAL_STATUS\" = \"MARRIED\" AND DEMOGRAPHIC.\"ADMISSION_TYPE\" = \"ELECTIVE\"]                                                                                                                         |\n|[SELECT MAX ( DEMOGRAPHIC.\"AGE\" ) FROM DEMOGRAPHIC WHERE DEMOGRAPHIC.\"DAYS_STAY\" = \"20\" AND DEMOGRAPHIC.\"DOD_YEAR\" < \"2023.0\"]                                                                                                                                           |\n+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "text = [\"Find the average number of prescriptions per patient for patients with a specific diagnosis.\",\n",
    "        \"give me the number of patients who had single internal mammary-coronary artery bypass.\",\n",
    "        \"provide the drug code and drug dose for anna johnson.\",\n",
    "        \"calculate the minimum age of married patients who had elective type hospital admission.\",\n",
    "        \"What is the maximum age of patients who were hospitalized for 20 days and died before 2023 ?\"]\n",
    "\n",
    "data = spark.createDataFrame([(prompt,) for prompt in text], [\"prompt\"])\n",
    "\n",
    "result = model.transform(data)\n",
    "\n",
    "result.select(\"sql_query.result\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c38cc0c-fbaf-4c57-8984-9c12aa32e4b9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### **📍 LightPipelines**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51679b9c-4ecb-4015-8cc1-5bfd1e1857b7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "light_model = nlp.LightPipeline(model)\n",
    "light_result = light_model.annotate(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0e5413e-13ae-48ea-a55e-a1b9d4c19d90",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "➤ User query: 1: \nFind the average number of prescriptions per patient for patients with a specific diagnosis.\n\n\n➤ SQL query 1: \nSELECT AVG ( DEMOGRAPHIC.\"AGE\" ) FROM DEMOGRAPHIC INNER JOIN DIAGNOSES on DEMOGRAPHIC.HADM_ID = DIAGNOSES.HADM_ID INNER JOIN PRESCRIPTIONS on DEMOGRAPHIC.HADM_ID = PRESCRIPTIONS.HADM_ID WHERE DIAGNOSES.\"SHORT_TITLE\" = \"Specific hst\" AND PRESCRIPTIONS.\"DRUG\" = \"1\"\n\n\n➤ User query: 2: \ngive me the number of patients who had single internal mammary-coronary artery bypass.\n\n\n➤ SQL query 2: \nSELECT COUNT ( DISTINCT DEMOGRAPHIC.\"SUBJECT_ID\" ) FROM DEMOGRAPHIC INNER JOIN PROCEDURES on DEMOGRAPHIC.HADM_ID = PROCEDURES.HADM_ID WHERE PROCEDURES.\"SHORT_TITLE\" = \"1 int mam-cor art bypass\"\n\n\n➤ User query: 3: \nprovide the drug code and drug dose for anna johnson.\n\n\n➤ SQL query 3: \nSELECT PRESCRIPTIONS.\"FORMULARY_DRUG_CD\",PRESCRIPTIONS.\"DRUG_DOSE\" FROM DEMOGRAPHIC INNER JOIN PRESCRIPTIONS on DEMOGRAPHIC.HADM_ID = PRESCRIPTIONS.HADM_ID WHERE DEMOGRAPHIC.\"NAME\" = \"Anna Johnson\"\n\n\n➤ User query: 4: \ncalculate the minimum age of married patients who had elective type hospital admission.\n\n\n➤ SQL query 4: \nSELECT MIN ( DEMOGRAPHIC.\"AGE\" ) FROM DEMOGRAPHIC WHERE DEMOGRAPHIC.\"MARITAL_STATUS\" = \"MARRIED\" AND DEMOGRAPHIC.\"ADMISSION_TYPE\" = \"ELECTIVE\"\n\n\n➤ User query: 5: \nWhat is the maximum age of patients who were hospitalized for 20 days and died before 2023 ?\n\n\n➤ SQL query 5: \nSELECT MAX ( DEMOGRAPHIC.\"AGE\" ) FROM DEMOGRAPHIC WHERE DEMOGRAPHIC.\"DAYS_STAY\" = \"20\" AND DEMOGRAPHIC.\"DOD_YEAR\" < \"2023.0\"\n\n\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(light_result)):\n",
    "    document_text =light_result[i]['document_prompt'][0]\n",
    "    summary_text = light_result[i]['sql_query'][0]\n",
    "\n",
    "    print(\"➤ User query: {}: \\n{}\".format(i+1, document_text))\n",
    "    print(\"\\n\")\n",
    "    print(\"➤ SQL query {}: \\n{}\".format(i+1, summary_text))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "47751a1e-3b0c-4249-a04f-1b1b081b8ab0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<h1 style=\"color:red\">!!! Note: this section can be runned with johnsnowlabs version >= 5.1.1 </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c222c7b-c3df-4283-9fad-a751a4ba468e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 📑  **Text2SQL_With_Schema_Single_Table**\n",
    "\n",
    "This model can generate SQL queries from natural questions and custom database schemas with a single table. It is based on a large-size LLM, which is finetuned by John Snow Labs on a dataset having schemas with single tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "32ef2c75-2797-4c37-bde5-03b72605faec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query_schema = {\"patient\": [\"ID\",\"Name\",\"Age\",\"Gender\",\"BloodType\",\"Weight\",\"Height\",\"Address\",\"Email\",\"Phone\"] }\n",
    "\n",
    "text2sql_with_schema_single_table = medical.Text2SQL.pretrained(\"text2sql_with_schema_single_table\", \"en\", \"clinical/models\")\\\n",
    "    .setMaxNewTokens(200)\\\n",
    "    .setSchema(query_schema)\\\n",
    "    .setInputCols([\"document_prompt\"])\\\n",
    "    .setOutputCol(\"sql_query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6951eb5c-052b-4662-8c44-2ef33a1a060b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pipeline = nlp.Pipeline(stages=[document_assembler, text2sql_with_schema_single_table])\n",
    "\n",
    "model = pipeline.fit(spark.createDataFrame([[\"\"]]).toDF(\"prompt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d0c477b1-d696-42a6-87a8-2bb6af22dd4d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "text = [\"Calculate the average age of patients with blood type 'A-'\",\n",
    "        \"Retrieve the names and email addresses of patients with blood type 'B+'\",\n",
    "        \"Calculate the number of patients with blood type A- and weight above 100kg\"\n",
    "        ]\n",
    "\n",
    "data = spark.createDataFrame([(prompt,) for prompt in text], [\"prompt\"])\n",
    "\n",
    "result = model.transform(data)\n",
    "\n",
    "result.select(\"sql_query.result\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fb8d64f5-9862-48ff-86dc-d2486eed0331",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Let's test with another custom database schema:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2512f87f-ad18-43b9-8094-14745479b0fa",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### **📍 LightPipelines**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "56878640-487b-476d-8f2b-b71082233440",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "light_model = nlp.LightPipeline(model)\n",
    "light_result = light_model.annotate(text)\n",
    "\n",
    "for i in range(len(light_result)):\n",
    "    document_text = textwrap.fill(light_result[i]['document_prompt'][0], width=120)\n",
    "    summary_text = textwrap.fill(light_result[i]['sql_query'][0], width=120)\n",
    "\n",
    "    print(\"➤ User query: {}: \\n{}\".format(i+1, document_text))\n",
    "    print(\"\\n\")\n",
    "    print(\"➤ SQL query {}: \\n{}\".format(i+1, summary_text))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6b475496-016f-4518-b092-7f8da77f9435",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 📑  **Text2SQL_With_Schema_Single_Table_Augmented**\n",
    "\n",
    "\n",
    "This model is the State-of-the-Art (SOTA) for generating SQL queries from natural questions and custom database schemas with a single table. It is based on a large-size LLM, which is finetuned by John Snow Labs on an augmented dataset having schemas with single tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "49d4768d-693b-4a6c-9377-03da2ad81132",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<h1 style=\"color:red\">!!! Note: this section can be runned with johnsnowlabs version >= 5.1.1 </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "21ec6496-d2a1-4262-b3c2-ad2a6ef23a56",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# query_schema = {\n",
    "#     \"medical_treatment\": [\"patient_id\",\"patient_name\",\"age\",\"gender\",\"diagnosis\",\"treatment\",\"doctor_name\",\"hospital_name\",\"admission_date\",\"discharge_date\"]\n",
    "# }\n",
    "\n",
    "# text2sql_with_schema_single_table_augmented = medical.Text2SQL.pretrained(\"text2sql_with_schema_single_table_augmented\", \"en\", \"clinical/models\")\\\n",
    "#     .setMaxNewTokens(200)\\\n",
    "#     .setSchema(query_schema)\\\n",
    "#     .setInputCols([\"document_prompt\"])\\\n",
    "#     .setOutputCol(\"sql_query\")\n",
    "\n",
    "# pipeline = Pipeline(stages=[document_assembler, text2sql_with_schema_single_table_augmented])\n",
    "\n",
    "# model = pipeline.fit(spark.createDataFrame([[\"\"]]).toDF(\"prompt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9607bc33-21bc-4c4e-9a08-5929fd9658dc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# text = [\"Which patients were admitted in September 2023?\",\n",
    "#         \"What is the average age of female patients with 'Diabetes'?\",\n",
    "#         \"Who are the patients treated by 'Dr. Brown'?\"\n",
    "#         ]\n",
    "\n",
    "# data = spark.createDataFrame([(prompt,) for prompt in text], [\"prompt\"])\n",
    "\n",
    "# result = model.transform(data)\n",
    "\n",
    "# result.select(\"sql_query.result\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2178294c-2824-4351-b210-b896cb324692",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### **📍 LightPipelines**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "662db97a-ba5f-43ce-8d0c-17671b14b951",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# light_model = LightPipeline(model)\n",
    "# light_result = light_model.annotate(text)\n",
    "\n",
    "# for i in range(len(light_result)):\n",
    "#     document_text = textwrap.fill(light_result[i]['document_prompt'][0], width=120)\n",
    "#     summary_text = textwrap.fill(light_result[i]['sql_query'][0], width=120)\n",
    "\n",
    "#     print(\"➤ User query: {}: \\n{}\".format(i+1, document_text))\n",
    "#     print(\"\\n\")\n",
    "#     print(\"➤ SQL query {}: \\n{}\".format(i+1, summary_text))\n",
    "#     print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "29.0.Text2SQL_Generation.ipynb",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
