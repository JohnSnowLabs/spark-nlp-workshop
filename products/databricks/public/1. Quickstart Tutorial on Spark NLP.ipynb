{"cells":[{"cell_type":"markdown","source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f4148374-240f-43c6-81c5-c00232b33cb0","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["# 1.Quickstart Tutorial on Spark NLP - 1 hr\n\nThis is the 1 hr workshop version of the entire training notebooks : https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/tutorials/Certification_Trainings/Public"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c74afb51-e1f2-41f0-86db-1d238d4a6d1f","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["an intro article for Spark NLP:\n\nhttps://towardsdatascience.com/introduction-to-spark-nlp-foundations-and-basic-components-part-i-c83b7629ed59\n\nHow to start Spark NLP in 2 weeks:\n\nhttps://towardsdatascience.com/how-to-get-started-with-sparknlp-in-2-weeks-cb47b2ba994d\n\nhttps://towardsdatascience.com/how-to-wrap-your-head-around-spark-nlp-a6f6a968b7e8\n\nArticle for NER and text classification in Spark NLP\n\nhttps://towardsdatascience.com/named-entity-recognition-ner-with-bert-in-spark-nlp-874df20d1d77\n\nhttps://medium.com/spark-nlp/named-entity-recognition-for-healthcare-with-sparknlp-nerdl-and-nercrf-a7751b6ad571\n\nhttps://towardsdatascience.com/text-classification-in-spark-nlp-with-bert-and-universal-sentence-encoders-e644d618ca32\n\na webinar to show how to train a NER model from scratch (90 min)\n\nhttps://www.youtube.com/watch?v=djWX0MR2Ooo\n\nworkshop repo that you can start playing with Spark NLP in Colab:\n\nhttps://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/tutorials/Certification_Trainings\n\nDatabrikcs Notebooks: \n\nhttps://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/products/databricks"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"00bb9c3a-b73f-4df8-9125-af0b6e82b4af","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["## Coding ..."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"40de2a12-fb21-4eec-bc22-1f0f3965f12f","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["import sparknlp\n\nfrom sparknlp.base import *\nfrom sparknlp.annotator import *\n\nfrom pyspark.ml import Pipeline\n\nprint(\"Spark NLP version\", sparknlp.version())\n\nspark"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e5b28573-ba7b-4274-9d62-c47684494818","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Spark NLP version 4.2.4\nOut[1]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Spark NLP version 4.2.4\nOut[1]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=7956323724731612#setting/sparkui/0616-152819-zhyjt0vc/driver-2104587558324677836\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.1.2</code></dd>\n              <dt>Master</dt>\n                <dd><code>spark://10.139.64.5:7077</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=7956323724731612#setting/sparkui/0616-152819-zhyjt0vc/driver-2104587558324677836\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.1.2</code></dd>\n              <dt>Master</dt>\n                <dd><code>spark://10.139.64.5:7077</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "]}}],"execution_count":0},{"cell_type":"markdown","source":["## Using Pretrained Pipelines\n\nfor a more detailed notebook, see https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/1.SparkNLP_Basics.ipynb"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"936cd64a-ea63-430b-bfd2-9f56b80e51f2","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from sparknlp.pretrained import PretrainedPipeline\n\npipeline_dl = PretrainedPipeline('explain_document_dl', lang='en')\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"432291f2-1556-45cd-a098-e4371650ab28","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">explain_document_dl download started this may take some time.\nApprox size to download 169.4 MB\n\r[ | ]\r[OK!]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">explain_document_dl download started this may take some time.\nApprox size to download 169.4 MB\n\r[ | ]\r[OK!]\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["**Stages**\n- DocumentAssembler\n- SentenceDetector\n- Tokenizer\n- NER (NER with GloVe 100D embeddings, CoNLL2003 dataset)\n- Lemmatizer\n- Stemmer\n- Part of Speech\n- SpellChecker (Norvig)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0a0d09ae-7d47-430e-a208-68d2c1e3455f","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["testDoc = '''\nPeter Parker is a very good persn.\nMy life in Russia is very intersting.\nJohn and Peter are brthers. However they don't support each other that much.\nMercedes Benz is also working on a driverless car.\nEurope is very culture rich. There are huge churches! and big houses!\n'''\n\nresult = pipeline_dl.annotate(testDoc)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1ea6f47d-ab12-435a-bc42-e64b2b2bbfcc","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["result.keys()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4eb64450-5a27-4fae-93c4-ad724453c934","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[4]: dict_keys([&#39;entities&#39;, &#39;stem&#39;, &#39;checked&#39;, &#39;lemma&#39;, &#39;document&#39;, &#39;pos&#39;, &#39;token&#39;, &#39;ner&#39;, &#39;embeddings&#39;, &#39;sentence&#39;])</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[4]: dict_keys([&#39;entities&#39;, &#39;stem&#39;, &#39;checked&#39;, &#39;lemma&#39;, &#39;document&#39;, &#39;pos&#39;, &#39;token&#39;, &#39;ner&#39;, &#39;embeddings&#39;, &#39;sentence&#39;])</div>"]}}],"execution_count":0},{"cell_type":"code","source":["result['entities']"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e077c514-dcf7-43a6-af3c-2c21f70910b8","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[5]: [&#39;Peter Parker&#39;, &#39;Russia&#39;, &#39;John&#39;, &#39;Peter&#39;, &#39;Mercedes Benz&#39;, &#39;Europe&#39;]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[5]: [&#39;Peter Parker&#39;, &#39;Russia&#39;, &#39;John&#39;, &#39;Peter&#39;, &#39;Mercedes Benz&#39;, &#39;Europe&#39;]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["import pandas as pd\n\ndf = pd.DataFrame({'token':result['token'], 'ner_label':result['ner'],\n                      'spell_corrected':result['checked'], 'POS':result['pos'],\n                      'lemmas':result['lemma'], 'stems':result['stem']})\n\ndf"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"51852433-82d0-4318-aa47-f560af4f254f","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[6]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[6]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>token</th>\n      <th>ner_label</th>\n      <th>spell_corrected</th>\n      <th>POS</th>\n      <th>lemmas</th>\n      <th>stems</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Peter</td>\n      <td>B-PER</td>\n      <td>Peter</td>\n      <td>NNP</td>\n      <td>Peter</td>\n      <td>peter</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Parker</td>\n      <td>I-PER</td>\n      <td>Parker</td>\n      <td>NNP</td>\n      <td>Parker</td>\n      <td>parker</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>is</td>\n      <td>O</td>\n      <td>is</td>\n      <td>VBZ</td>\n      <td>be</td>\n      <td>i</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>a</td>\n      <td>O</td>\n      <td>a</td>\n      <td>DT</td>\n      <td>a</td>\n      <td>a</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>very</td>\n      <td>O</td>\n      <td>very</td>\n      <td>RB</td>\n      <td>very</td>\n      <td>veri</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>good</td>\n      <td>O</td>\n      <td>good</td>\n      <td>JJ</td>\n      <td>good</td>\n      <td>good</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>persn</td>\n      <td>O</td>\n      <td>person</td>\n      <td>NN</td>\n      <td>person</td>\n      <td>person</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>.</td>\n      <td>O</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>My</td>\n      <td>O</td>\n      <td>My</td>\n      <td>PRP$</td>\n      <td>My</td>\n      <td>my</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>life</td>\n      <td>O</td>\n      <td>life</td>\n      <td>NN</td>\n      <td>life</td>\n      <td>life</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>in</td>\n      <td>O</td>\n      <td>in</td>\n      <td>IN</td>\n      <td>in</td>\n      <td>in</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Russia</td>\n      <td>B-LOC</td>\n      <td>Russia</td>\n      <td>NNP</td>\n      <td>Russia</td>\n      <td>russia</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>is</td>\n      <td>O</td>\n      <td>is</td>\n      <td>VBZ</td>\n      <td>be</td>\n      <td>i</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>very</td>\n      <td>O</td>\n      <td>very</td>\n      <td>RB</td>\n      <td>very</td>\n      <td>veri</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>intersting</td>\n      <td>O</td>\n      <td>interesting</td>\n      <td>VBG</td>\n      <td>interest</td>\n      <td>interest</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>.</td>\n      <td>O</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>John</td>\n      <td>B-PER</td>\n      <td>John</td>\n      <td>NNP</td>\n      <td>John</td>\n      <td>john</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>and</td>\n      <td>O</td>\n      <td>and</td>\n      <td>CC</td>\n      <td>and</td>\n      <td>and</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Peter</td>\n      <td>B-PER</td>\n      <td>Peter</td>\n      <td>NNP</td>\n      <td>Peter</td>\n      <td>peter</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>are</td>\n      <td>O</td>\n      <td>are</td>\n      <td>VBP</td>\n      <td>be</td>\n      <td>ar</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>brthers</td>\n      <td>O</td>\n      <td>brothers</td>\n      <td>NNS</td>\n      <td>brother</td>\n      <td>brother</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>.</td>\n      <td>O</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>However</td>\n      <td>O</td>\n      <td>However</td>\n      <td>RB</td>\n      <td>However</td>\n      <td>howev</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>they</td>\n      <td>O</td>\n      <td>they</td>\n      <td>PRP</td>\n      <td>they</td>\n      <td>thei</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>don't</td>\n      <td>O</td>\n      <td>don't</td>\n      <td>VBP</td>\n      <td>don't</td>\n      <td>don't</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>support</td>\n      <td>O</td>\n      <td>support</td>\n      <td>VB</td>\n      <td>support</td>\n      <td>support</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>each</td>\n      <td>O</td>\n      <td>each</td>\n      <td>DT</td>\n      <td>each</td>\n      <td>each</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>other</td>\n      <td>O</td>\n      <td>other</td>\n      <td>JJ</td>\n      <td>other</td>\n      <td>other</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>that</td>\n      <td>O</td>\n      <td>that</td>\n      <td>IN</td>\n      <td>that</td>\n      <td>that</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>much</td>\n      <td>O</td>\n      <td>much</td>\n      <td>JJ</td>\n      <td>much</td>\n      <td>much</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>.</td>\n      <td>O</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>Mercedes</td>\n      <td>B-ORG</td>\n      <td>Mercedes</td>\n      <td>NNP</td>\n      <td>Mercedes</td>\n      <td>merced</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>Benz</td>\n      <td>I-ORG</td>\n      <td>Benz</td>\n      <td>NNP</td>\n      <td>Benz</td>\n      <td>benz</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>is</td>\n      <td>O</td>\n      <td>is</td>\n      <td>VBZ</td>\n      <td>be</td>\n      <td>i</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>also</td>\n      <td>O</td>\n      <td>also</td>\n      <td>RB</td>\n      <td>also</td>\n      <td>also</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>working</td>\n      <td>O</td>\n      <td>working</td>\n      <td>VBG</td>\n      <td>work</td>\n      <td>work</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>on</td>\n      <td>O</td>\n      <td>on</td>\n      <td>IN</td>\n      <td>on</td>\n      <td>on</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>a</td>\n      <td>O</td>\n      <td>a</td>\n      <td>DT</td>\n      <td>a</td>\n      <td>a</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>driverless</td>\n      <td>O</td>\n      <td>driverless</td>\n      <td>JJ</td>\n      <td>driverless</td>\n      <td>driverless</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>car</td>\n      <td>O</td>\n      <td>car</td>\n      <td>NN</td>\n      <td>car</td>\n      <td>car</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>.</td>\n      <td>O</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>Europe</td>\n      <td>B-LOC</td>\n      <td>Europe</td>\n      <td>NNP</td>\n      <td>Europe</td>\n      <td>europ</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>is</td>\n      <td>O</td>\n      <td>is</td>\n      <td>VBZ</td>\n      <td>be</td>\n      <td>i</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>very</td>\n      <td>O</td>\n      <td>very</td>\n      <td>RB</td>\n      <td>very</td>\n      <td>veri</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>culture</td>\n      <td>O</td>\n      <td>culture</td>\n      <td>RB</td>\n      <td>culture</td>\n      <td>cultur</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>rich</td>\n      <td>O</td>\n      <td>rich</td>\n      <td>JJ</td>\n      <td>rich</td>\n      <td>rich</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>.</td>\n      <td>O</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>There</td>\n      <td>O</td>\n      <td>There</td>\n      <td>EX</td>\n      <td>There</td>\n      <td>there</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>are</td>\n      <td>O</td>\n      <td>are</td>\n      <td>VBP</td>\n      <td>be</td>\n      <td>ar</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>huge</td>\n      <td>O</td>\n      <td>huge</td>\n      <td>JJ</td>\n      <td>huge</td>\n      <td>huge</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>churches</td>\n      <td>O</td>\n      <td>churches</td>\n      <td>NNS</td>\n      <td>church</td>\n      <td>church</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>!</td>\n      <td>O</td>\n      <td>!</td>\n      <td>.</td>\n      <td>!</td>\n      <td>!</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>and</td>\n      <td>O</td>\n      <td>and</td>\n      <td>CC</td>\n      <td>and</td>\n      <td>and</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>big</td>\n      <td>O</td>\n      <td>big</td>\n      <td>JJ</td>\n      <td>big</td>\n      <td>big</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>houses</td>\n      <td>O</td>\n      <td>houses</td>\n      <td>NNS</td>\n      <td>house</td>\n      <td>hous</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>!</td>\n      <td>O</td>\n      <td>!</td>\n      <td>.</td>\n      <td>!</td>\n      <td>!</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>token</th>\n      <th>ner_label</th>\n      <th>spell_corrected</th>\n      <th>POS</th>\n      <th>lemmas</th>\n      <th>stems</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Peter</td>\n      <td>B-PER</td>\n      <td>Peter</td>\n      <td>NNP</td>\n      <td>Peter</td>\n      <td>peter</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Parker</td>\n      <td>I-PER</td>\n      <td>Parker</td>\n      <td>NNP</td>\n      <td>Parker</td>\n      <td>parker</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>is</td>\n      <td>O</td>\n      <td>is</td>\n      <td>VBZ</td>\n      <td>be</td>\n      <td>i</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>a</td>\n      <td>O</td>\n      <td>a</td>\n      <td>DT</td>\n      <td>a</td>\n      <td>a</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>very</td>\n      <td>O</td>\n      <td>very</td>\n      <td>RB</td>\n      <td>very</td>\n      <td>veri</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>good</td>\n      <td>O</td>\n      <td>good</td>\n      <td>JJ</td>\n      <td>good</td>\n      <td>good</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>persn</td>\n      <td>O</td>\n      <td>person</td>\n      <td>NN</td>\n      <td>person</td>\n      <td>person</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>.</td>\n      <td>O</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>My</td>\n      <td>O</td>\n      <td>My</td>\n      <td>PRP$</td>\n      <td>My</td>\n      <td>my</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>life</td>\n      <td>O</td>\n      <td>life</td>\n      <td>NN</td>\n      <td>life</td>\n      <td>life</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>in</td>\n      <td>O</td>\n      <td>in</td>\n      <td>IN</td>\n      <td>in</td>\n      <td>in</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Russia</td>\n      <td>B-LOC</td>\n      <td>Russia</td>\n      <td>NNP</td>\n      <td>Russia</td>\n      <td>russia</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>is</td>\n      <td>O</td>\n      <td>is</td>\n      <td>VBZ</td>\n      <td>be</td>\n      <td>i</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>very</td>\n      <td>O</td>\n      <td>very</td>\n      <td>RB</td>\n      <td>very</td>\n      <td>veri</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>intersting</td>\n      <td>O</td>\n      <td>interesting</td>\n      <td>VBG</td>\n      <td>interest</td>\n      <td>interest</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>.</td>\n      <td>O</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>John</td>\n      <td>B-PER</td>\n      <td>John</td>\n      <td>NNP</td>\n      <td>John</td>\n      <td>john</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>and</td>\n      <td>O</td>\n      <td>and</td>\n      <td>CC</td>\n      <td>and</td>\n      <td>and</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Peter</td>\n      <td>B-PER</td>\n      <td>Peter</td>\n      <td>NNP</td>\n      <td>Peter</td>\n      <td>peter</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>are</td>\n      <td>O</td>\n      <td>are</td>\n      <td>VBP</td>\n      <td>be</td>\n      <td>ar</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>brthers</td>\n      <td>O</td>\n      <td>brothers</td>\n      <td>NNS</td>\n      <td>brother</td>\n      <td>brother</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>.</td>\n      <td>O</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>However</td>\n      <td>O</td>\n      <td>However</td>\n      <td>RB</td>\n      <td>However</td>\n      <td>howev</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>they</td>\n      <td>O</td>\n      <td>they</td>\n      <td>PRP</td>\n      <td>they</td>\n      <td>thei</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>don't</td>\n      <td>O</td>\n      <td>don't</td>\n      <td>VBP</td>\n      <td>don't</td>\n      <td>don't</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>support</td>\n      <td>O</td>\n      <td>support</td>\n      <td>VB</td>\n      <td>support</td>\n      <td>support</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>each</td>\n      <td>O</td>\n      <td>each</td>\n      <td>DT</td>\n      <td>each</td>\n      <td>each</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>other</td>\n      <td>O</td>\n      <td>other</td>\n      <td>JJ</td>\n      <td>other</td>\n      <td>other</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>that</td>\n      <td>O</td>\n      <td>that</td>\n      <td>IN</td>\n      <td>that</td>\n      <td>that</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>much</td>\n      <td>O</td>\n      <td>much</td>\n      <td>JJ</td>\n      <td>much</td>\n      <td>much</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>.</td>\n      <td>O</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>Mercedes</td>\n      <td>B-ORG</td>\n      <td>Mercedes</td>\n      <td>NNP</td>\n      <td>Mercedes</td>\n      <td>merced</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>Benz</td>\n      <td>I-ORG</td>\n      <td>Benz</td>\n      <td>NNP</td>\n      <td>Benz</td>\n      <td>benz</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>is</td>\n      <td>O</td>\n      <td>is</td>\n      <td>VBZ</td>\n      <td>be</td>\n      <td>i</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>also</td>\n      <td>O</td>\n      <td>also</td>\n      <td>RB</td>\n      <td>also</td>\n      <td>also</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>working</td>\n      <td>O</td>\n      <td>working</td>\n      <td>VBG</td>\n      <td>work</td>\n      <td>work</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>on</td>\n      <td>O</td>\n      <td>on</td>\n      <td>IN</td>\n      <td>on</td>\n      <td>on</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>a</td>\n      <td>O</td>\n      <td>a</td>\n      <td>DT</td>\n      <td>a</td>\n      <td>a</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>driverless</td>\n      <td>O</td>\n      <td>driverless</td>\n      <td>JJ</td>\n      <td>driverless</td>\n      <td>driverless</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>car</td>\n      <td>O</td>\n      <td>car</td>\n      <td>NN</td>\n      <td>car</td>\n      <td>car</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>.</td>\n      <td>O</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>Europe</td>\n      <td>B-LOC</td>\n      <td>Europe</td>\n      <td>NNP</td>\n      <td>Europe</td>\n      <td>europ</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>is</td>\n      <td>O</td>\n      <td>is</td>\n      <td>VBZ</td>\n      <td>be</td>\n      <td>i</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>very</td>\n      <td>O</td>\n      <td>very</td>\n      <td>RB</td>\n      <td>very</td>\n      <td>veri</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>culture</td>\n      <td>O</td>\n      <td>culture</td>\n      <td>RB</td>\n      <td>culture</td>\n      <td>cultur</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>rich</td>\n      <td>O</td>\n      <td>rich</td>\n      <td>JJ</td>\n      <td>rich</td>\n      <td>rich</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>.</td>\n      <td>O</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>There</td>\n      <td>O</td>\n      <td>There</td>\n      <td>EX</td>\n      <td>There</td>\n      <td>there</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>are</td>\n      <td>O</td>\n      <td>are</td>\n      <td>VBP</td>\n      <td>be</td>\n      <td>ar</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>huge</td>\n      <td>O</td>\n      <td>huge</td>\n      <td>JJ</td>\n      <td>huge</td>\n      <td>huge</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>churches</td>\n      <td>O</td>\n      <td>churches</td>\n      <td>NNS</td>\n      <td>church</td>\n      <td>church</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>!</td>\n      <td>O</td>\n      <td>!</td>\n      <td>.</td>\n      <td>!</td>\n      <td>!</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>and</td>\n      <td>O</td>\n      <td>and</td>\n      <td>CC</td>\n      <td>and</td>\n      <td>and</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>big</td>\n      <td>O</td>\n      <td>big</td>\n      <td>JJ</td>\n      <td>big</td>\n      <td>big</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>houses</td>\n      <td>O</td>\n      <td>houses</td>\n      <td>NNS</td>\n      <td>house</td>\n      <td>hous</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>!</td>\n      <td>O</td>\n      <td>!</td>\n      <td>.</td>\n      <td>!</td>\n      <td>!</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Using fullAnnotate to get more details"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d0c70708-d498-436a-86af-295cc0c77983","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["detailed_result = pipeline_dl.fullAnnotate(testDoc)\n\ndetailed_result[0]['entities']"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4b29ebba-3aa6-4034-b920-ef0f000cd7f3","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[7]: [Annotation(chunk, 1, 12, Peter Parker, {&#39;entity&#39;: &#39;PER&#39;, &#39;sentence&#39;: &#39;0&#39;, &#39;chunk&#39;: &#39;0&#39;}),\n Annotation(chunk, 47, 52, Russia, {&#39;entity&#39;: &#39;LOC&#39;, &#39;sentence&#39;: &#39;1&#39;, &#39;chunk&#39;: &#39;1&#39;}),\n Annotation(chunk, 74, 77, John, {&#39;entity&#39;: &#39;PER&#39;, &#39;sentence&#39;: &#39;2&#39;, &#39;chunk&#39;: &#39;2&#39;}),\n Annotation(chunk, 83, 87, Peter, {&#39;entity&#39;: &#39;PER&#39;, &#39;sentence&#39;: &#39;2&#39;, &#39;chunk&#39;: &#39;3&#39;}),\n Annotation(chunk, 151, 163, Mercedes Benz, {&#39;entity&#39;: &#39;ORG&#39;, &#39;sentence&#39;: &#39;4&#39;, &#39;chunk&#39;: &#39;4&#39;}),\n Annotation(chunk, 202, 207, Europe, {&#39;entity&#39;: &#39;LOC&#39;, &#39;sentence&#39;: &#39;5&#39;, &#39;chunk&#39;: &#39;5&#39;})]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[7]: [Annotation(chunk, 1, 12, Peter Parker, {&#39;entity&#39;: &#39;PER&#39;, &#39;sentence&#39;: &#39;0&#39;, &#39;chunk&#39;: &#39;0&#39;}),\n Annotation(chunk, 47, 52, Russia, {&#39;entity&#39;: &#39;LOC&#39;, &#39;sentence&#39;: &#39;1&#39;, &#39;chunk&#39;: &#39;1&#39;}),\n Annotation(chunk, 74, 77, John, {&#39;entity&#39;: &#39;PER&#39;, &#39;sentence&#39;: &#39;2&#39;, &#39;chunk&#39;: &#39;2&#39;}),\n Annotation(chunk, 83, 87, Peter, {&#39;entity&#39;: &#39;PER&#39;, &#39;sentence&#39;: &#39;2&#39;, &#39;chunk&#39;: &#39;3&#39;}),\n Annotation(chunk, 151, 163, Mercedes Benz, {&#39;entity&#39;: &#39;ORG&#39;, &#39;sentence&#39;: &#39;4&#39;, &#39;chunk&#39;: &#39;4&#39;}),\n Annotation(chunk, 202, 207, Europe, {&#39;entity&#39;: &#39;LOC&#39;, &#39;sentence&#39;: &#39;5&#39;, &#39;chunk&#39;: &#39;5&#39;})]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["chunks=[]\nentities=[]\nfor n in detailed_result[0]['entities']:\n        \n  chunks.append(n.result)\n  entities.append(n.metadata['entity']) \n    \ndf = pd.DataFrame({'chunks':chunks, 'entities':entities})\ndf    "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1910604c-166c-4220-ad51-de0e1fca50c9","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[8]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[8]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>chunks</th>\n      <th>entities</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Peter Parker</td>\n      <td>PER</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Russia</td>\n      <td>LOC</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>John</td>\n      <td>PER</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Peter</td>\n      <td>PER</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Mercedes Benz</td>\n      <td>ORG</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Europe</td>\n      <td>LOC</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>chunks</th>\n      <th>entities</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Peter Parker</td>\n      <td>PER</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Russia</td>\n      <td>LOC</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>John</td>\n      <td>PER</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Peter</td>\n      <td>PER</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Mercedes Benz</td>\n      <td>ORG</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Europe</td>\n      <td>LOC</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["tuples = []\n\nfor x,y,z in zip(detailed_result[0][\"token\"], detailed_result[0][\"pos\"], detailed_result[0][\"ner\"]):\n\n  tuples.append((int(x.metadata['sentence']), x.result, x.begin, x.end, y.result, z.result))\n\ndf = pd.DataFrame(tuples, columns=['sent_id','token','start','end','pos', 'ner'])\n\ndf\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b962ea37-86a4-4a10-866e-67a5726061d2","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[9]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[9]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sent_id</th>\n      <th>token</th>\n      <th>start</th>\n      <th>end</th>\n      <th>pos</th>\n      <th>ner</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Peter</td>\n      <td>1</td>\n      <td>5</td>\n      <td>NNP</td>\n      <td>B-PER</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>Parker</td>\n      <td>7</td>\n      <td>12</td>\n      <td>NNP</td>\n      <td>I-PER</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>is</td>\n      <td>14</td>\n      <td>15</td>\n      <td>VBZ</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>a</td>\n      <td>17</td>\n      <td>17</td>\n      <td>DT</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>very</td>\n      <td>19</td>\n      <td>22</td>\n      <td>RB</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>good</td>\n      <td>24</td>\n      <td>27</td>\n      <td>JJ</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>persn</td>\n      <td>29</td>\n      <td>33</td>\n      <td>NN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>.</td>\n      <td>34</td>\n      <td>34</td>\n      <td>.</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1</td>\n      <td>My</td>\n      <td>36</td>\n      <td>37</td>\n      <td>PRP$</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1</td>\n      <td>life</td>\n      <td>39</td>\n      <td>42</td>\n      <td>NN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1</td>\n      <td>in</td>\n      <td>44</td>\n      <td>45</td>\n      <td>IN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1</td>\n      <td>Russia</td>\n      <td>47</td>\n      <td>52</td>\n      <td>NNP</td>\n      <td>B-LOC</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1</td>\n      <td>is</td>\n      <td>54</td>\n      <td>55</td>\n      <td>VBZ</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>1</td>\n      <td>very</td>\n      <td>57</td>\n      <td>60</td>\n      <td>RB</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>1</td>\n      <td>intersting</td>\n      <td>62</td>\n      <td>71</td>\n      <td>VBG</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>1</td>\n      <td>.</td>\n      <td>72</td>\n      <td>72</td>\n      <td>.</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>2</td>\n      <td>John</td>\n      <td>74</td>\n      <td>77</td>\n      <td>NNP</td>\n      <td>B-PER</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>2</td>\n      <td>and</td>\n      <td>79</td>\n      <td>81</td>\n      <td>CC</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>2</td>\n      <td>Peter</td>\n      <td>83</td>\n      <td>87</td>\n      <td>NNP</td>\n      <td>B-PER</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>2</td>\n      <td>are</td>\n      <td>89</td>\n      <td>91</td>\n      <td>VBP</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>2</td>\n      <td>brthers</td>\n      <td>93</td>\n      <td>99</td>\n      <td>NNS</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>2</td>\n      <td>.</td>\n      <td>100</td>\n      <td>100</td>\n      <td>.</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>3</td>\n      <td>However</td>\n      <td>102</td>\n      <td>108</td>\n      <td>RB</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>3</td>\n      <td>they</td>\n      <td>110</td>\n      <td>113</td>\n      <td>PRP</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>3</td>\n      <td>don't</td>\n      <td>115</td>\n      <td>119</td>\n      <td>VBP</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>3</td>\n      <td>support</td>\n      <td>121</td>\n      <td>127</td>\n      <td>VB</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>3</td>\n      <td>each</td>\n      <td>129</td>\n      <td>132</td>\n      <td>DT</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>3</td>\n      <td>other</td>\n      <td>134</td>\n      <td>138</td>\n      <td>JJ</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>3</td>\n      <td>that</td>\n      <td>140</td>\n      <td>143</td>\n      <td>IN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>3</td>\n      <td>much</td>\n      <td>145</td>\n      <td>148</td>\n      <td>JJ</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>3</td>\n      <td>.</td>\n      <td>149</td>\n      <td>149</td>\n      <td>.</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>4</td>\n      <td>Mercedes</td>\n      <td>151</td>\n      <td>158</td>\n      <td>NNP</td>\n      <td>B-ORG</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>4</td>\n      <td>Benz</td>\n      <td>160</td>\n      <td>163</td>\n      <td>NNP</td>\n      <td>I-ORG</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>4</td>\n      <td>is</td>\n      <td>165</td>\n      <td>166</td>\n      <td>VBZ</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>4</td>\n      <td>also</td>\n      <td>168</td>\n      <td>171</td>\n      <td>RB</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>4</td>\n      <td>working</td>\n      <td>173</td>\n      <td>179</td>\n      <td>VBG</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>4</td>\n      <td>on</td>\n      <td>181</td>\n      <td>182</td>\n      <td>IN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>4</td>\n      <td>a</td>\n      <td>184</td>\n      <td>184</td>\n      <td>DT</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>4</td>\n      <td>driverless</td>\n      <td>186</td>\n      <td>195</td>\n      <td>JJ</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>4</td>\n      <td>car</td>\n      <td>197</td>\n      <td>199</td>\n      <td>NN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>4</td>\n      <td>.</td>\n      <td>200</td>\n      <td>200</td>\n      <td>.</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>5</td>\n      <td>Europe</td>\n      <td>202</td>\n      <td>207</td>\n      <td>NNP</td>\n      <td>B-LOC</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>5</td>\n      <td>is</td>\n      <td>209</td>\n      <td>210</td>\n      <td>VBZ</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>5</td>\n      <td>very</td>\n      <td>212</td>\n      <td>215</td>\n      <td>RB</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>5</td>\n      <td>culture</td>\n      <td>217</td>\n      <td>223</td>\n      <td>RB</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>5</td>\n      <td>rich</td>\n      <td>225</td>\n      <td>228</td>\n      <td>JJ</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>5</td>\n      <td>.</td>\n      <td>229</td>\n      <td>229</td>\n      <td>.</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>6</td>\n      <td>There</td>\n      <td>231</td>\n      <td>235</td>\n      <td>EX</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>6</td>\n      <td>are</td>\n      <td>237</td>\n      <td>239</td>\n      <td>VBP</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>6</td>\n      <td>huge</td>\n      <td>241</td>\n      <td>244</td>\n      <td>JJ</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>6</td>\n      <td>churches</td>\n      <td>246</td>\n      <td>253</td>\n      <td>NNS</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>6</td>\n      <td>!</td>\n      <td>254</td>\n      <td>254</td>\n      <td>.</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>7</td>\n      <td>and</td>\n      <td>256</td>\n      <td>258</td>\n      <td>CC</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>7</td>\n      <td>big</td>\n      <td>260</td>\n      <td>262</td>\n      <td>JJ</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>7</td>\n      <td>houses</td>\n      <td>264</td>\n      <td>269</td>\n      <td>NNS</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>7</td>\n      <td>!</td>\n      <td>270</td>\n      <td>270</td>\n      <td>.</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sent_id</th>\n      <th>token</th>\n      <th>start</th>\n      <th>end</th>\n      <th>pos</th>\n      <th>ner</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Peter</td>\n      <td>1</td>\n      <td>5</td>\n      <td>NNP</td>\n      <td>B-PER</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>Parker</td>\n      <td>7</td>\n      <td>12</td>\n      <td>NNP</td>\n      <td>I-PER</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>is</td>\n      <td>14</td>\n      <td>15</td>\n      <td>VBZ</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>a</td>\n      <td>17</td>\n      <td>17</td>\n      <td>DT</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>very</td>\n      <td>19</td>\n      <td>22</td>\n      <td>RB</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>good</td>\n      <td>24</td>\n      <td>27</td>\n      <td>JJ</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>persn</td>\n      <td>29</td>\n      <td>33</td>\n      <td>NN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>.</td>\n      <td>34</td>\n      <td>34</td>\n      <td>.</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1</td>\n      <td>My</td>\n      <td>36</td>\n      <td>37</td>\n      <td>PRP$</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1</td>\n      <td>life</td>\n      <td>39</td>\n      <td>42</td>\n      <td>NN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1</td>\n      <td>in</td>\n      <td>44</td>\n      <td>45</td>\n      <td>IN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1</td>\n      <td>Russia</td>\n      <td>47</td>\n      <td>52</td>\n      <td>NNP</td>\n      <td>B-LOC</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1</td>\n      <td>is</td>\n      <td>54</td>\n      <td>55</td>\n      <td>VBZ</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>1</td>\n      <td>very</td>\n      <td>57</td>\n      <td>60</td>\n      <td>RB</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>1</td>\n      <td>intersting</td>\n      <td>62</td>\n      <td>71</td>\n      <td>VBG</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>1</td>\n      <td>.</td>\n      <td>72</td>\n      <td>72</td>\n      <td>.</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>2</td>\n      <td>John</td>\n      <td>74</td>\n      <td>77</td>\n      <td>NNP</td>\n      <td>B-PER</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>2</td>\n      <td>and</td>\n      <td>79</td>\n      <td>81</td>\n      <td>CC</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>2</td>\n      <td>Peter</td>\n      <td>83</td>\n      <td>87</td>\n      <td>NNP</td>\n      <td>B-PER</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>2</td>\n      <td>are</td>\n      <td>89</td>\n      <td>91</td>\n      <td>VBP</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>2</td>\n      <td>brthers</td>\n      <td>93</td>\n      <td>99</td>\n      <td>NNS</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>2</td>\n      <td>.</td>\n      <td>100</td>\n      <td>100</td>\n      <td>.</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>3</td>\n      <td>However</td>\n      <td>102</td>\n      <td>108</td>\n      <td>RB</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>3</td>\n      <td>they</td>\n      <td>110</td>\n      <td>113</td>\n      <td>PRP</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>3</td>\n      <td>don't</td>\n      <td>115</td>\n      <td>119</td>\n      <td>VBP</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>3</td>\n      <td>support</td>\n      <td>121</td>\n      <td>127</td>\n      <td>VB</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>3</td>\n      <td>each</td>\n      <td>129</td>\n      <td>132</td>\n      <td>DT</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>3</td>\n      <td>other</td>\n      <td>134</td>\n      <td>138</td>\n      <td>JJ</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>3</td>\n      <td>that</td>\n      <td>140</td>\n      <td>143</td>\n      <td>IN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>3</td>\n      <td>much</td>\n      <td>145</td>\n      <td>148</td>\n      <td>JJ</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>3</td>\n      <td>.</td>\n      <td>149</td>\n      <td>149</td>\n      <td>.</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>4</td>\n      <td>Mercedes</td>\n      <td>151</td>\n      <td>158</td>\n      <td>NNP</td>\n      <td>B-ORG</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>4</td>\n      <td>Benz</td>\n      <td>160</td>\n      <td>163</td>\n      <td>NNP</td>\n      <td>I-ORG</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>4</td>\n      <td>is</td>\n      <td>165</td>\n      <td>166</td>\n      <td>VBZ</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>4</td>\n      <td>also</td>\n      <td>168</td>\n      <td>171</td>\n      <td>RB</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>4</td>\n      <td>working</td>\n      <td>173</td>\n      <td>179</td>\n      <td>VBG</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>4</td>\n      <td>on</td>\n      <td>181</td>\n      <td>182</td>\n      <td>IN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>4</td>\n      <td>a</td>\n      <td>184</td>\n      <td>184</td>\n      <td>DT</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>4</td>\n      <td>driverless</td>\n      <td>186</td>\n      <td>195</td>\n      <td>JJ</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>4</td>\n      <td>car</td>\n      <td>197</td>\n      <td>199</td>\n      <td>NN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>4</td>\n      <td>.</td>\n      <td>200</td>\n      <td>200</td>\n      <td>.</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>5</td>\n      <td>Europe</td>\n      <td>202</td>\n      <td>207</td>\n      <td>NNP</td>\n      <td>B-LOC</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>5</td>\n      <td>is</td>\n      <td>209</td>\n      <td>210</td>\n      <td>VBZ</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>5</td>\n      <td>very</td>\n      <td>212</td>\n      <td>215</td>\n      <td>RB</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>5</td>\n      <td>culture</td>\n      <td>217</td>\n      <td>223</td>\n      <td>RB</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>5</td>\n      <td>rich</td>\n      <td>225</td>\n      <td>228</td>\n      <td>JJ</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>5</td>\n      <td>.</td>\n      <td>229</td>\n      <td>229</td>\n      <td>.</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>6</td>\n      <td>There</td>\n      <td>231</td>\n      <td>235</td>\n      <td>EX</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>6</td>\n      <td>are</td>\n      <td>237</td>\n      <td>239</td>\n      <td>VBP</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>6</td>\n      <td>huge</td>\n      <td>241</td>\n      <td>244</td>\n      <td>JJ</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>6</td>\n      <td>churches</td>\n      <td>246</td>\n      <td>253</td>\n      <td>NNS</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>6</td>\n      <td>!</td>\n      <td>254</td>\n      <td>254</td>\n      <td>.</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>7</td>\n      <td>and</td>\n      <td>256</td>\n      <td>258</td>\n      <td>CC</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>7</td>\n      <td>big</td>\n      <td>260</td>\n      <td>262</td>\n      <td>JJ</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>7</td>\n      <td>houses</td>\n      <td>264</td>\n      <td>269</td>\n      <td>NNS</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>7</td>\n      <td>!</td>\n      <td>270</td>\n      <td>270</td>\n      <td>.</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Sentiment Analysis"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d63258a6-b353-4898-8529-f8cb7aec8ad4","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["sentiment = PretrainedPipeline('analyze_sentiment', lang='en')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4db14b24-457c-412f-ba70-ecece070cf07","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">analyze_sentiment download started this may take some time.\nApprox size to download 4.9 MB\n\r[ | ]\r[OK!]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">analyze_sentiment download started this may take some time.\nApprox size to download 4.9 MB\n\r[ | ]\r[OK!]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["result = sentiment.annotate(\"The movie I watched today was not a good one\")\n\nresult['sentiment']"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2f51ca76-8870-47e8-95d1-8a564a966efc","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[11]: [&#39;negative&#39;]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[11]: [&#39;negative&#39;]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["sentiment_imdb_glove = PretrainedPipeline('analyze_sentimentdl_glove_imdb', lang='en')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ccfccb82-f510-41db-9793-2b09b06b4b02","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">analyze_sentimentdl_glove_imdb download started this may take some time.\nApprox size to download 155.3 MB\n\r[ | ]\r[OK!]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">analyze_sentimentdl_glove_imdb download started this may take some time.\nApprox size to download 155.3 MB\n\r[ | ]\r[OK!]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["comment = '''\nIt's a very scary film but what impressed me was how true the film sticks to the original's tricks; it isn't filled with loud in-your-face jump scares, in fact, a lot of what makes this film scary is the slick cinematography and intricate shadow play. The use of lighting and creation of atmosphere is what makes this film so tense, which is why it's perfectly suited for those who like Horror movies but without the obnoxious gore.\n'''\nresult = sentiment_imdb_glove.annotate(comment)\n\nresult['sentiment']"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4909f93a-48e6-48e5-abf6-96725735b501","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[13]: [&#39;pos&#39;]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[13]: [&#39;pos&#39;]</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Using the modules in a pipeline for custom tasks\n\nfor a more detailed notebook, see https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a816a594-3d4a-4822-8371-eaae6f325339","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/examples/python/annotation/text/english/spark-nlp-basics/sample-sentences-en.txt\n  \ndbutils.fs.cp(\"file:/databricks/driver/sample-sentences-en.txt\", \"dbfs:/\") "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3476bce3-2f31-43d6-b3af-805e1593b548","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[14]: True</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[14]: True</div>"]}}],"execution_count":0},{"cell_type":"code","source":["with open('sample-sentences-en.txt') as f:\n  print (f.read())"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b28bbd12-90b7-4122-be7a-852c647172b6","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Peter is a very good person.\nMy life in Russia is very interesting.\nJohn and Peter are brothers. However they don&#39;t support each other that much.\nLucas Nogal Dunbercker is no longer happy. He has a good car though.\nEurope is very culture rich. There are huge churches! and big houses!\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Peter is a very good person.\nMy life in Russia is very interesting.\nJohn and Peter are brothers. However they don&#39;t support each other that much.\nLucas Nogal Dunbercker is no longer happy. He has a good car though.\nEurope is very culture rich. There are huge churches! and big houses!\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["spark_df = spark.read.text('/sample-sentences-en.txt').toDF('text')\n\nspark_df.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5f4fd704-3e77-4a22-89c8-0c21198118ba","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-----------------------------------------------------------------------------+\n|text                                                                         |\n+-----------------------------------------------------------------------------+\n|Peter is a very good person.                                                 |\n|My life in Russia is very interesting.                                       |\n|John and Peter are brothers. However they don&#39;t support each other that much.|\n|Lucas Nogal Dunbercker is no longer happy. He has a good car though.         |\n|Europe is very culture rich. There are huge churches! and big houses!        |\n+-----------------------------------------------------------------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------------------------------------------------------------------------+\ntext                                                                         |\n+-----------------------------------------------------------------------------+\nPeter is a very good person.                                                 |\nMy life in Russia is very interesting.                                       |\nJohn and Peter are brothers. However they don&#39;t support each other that much.|\nLucas Nogal Dunbercker is no longer happy. He has a good car though.         |\nEurope is very culture rich. There are huge churches! and big houses!        |\n+-----------------------------------------------------------------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["textFiles = spark.sparkContext.wholeTextFiles(\"/sample-sentences-en.txt\",4) # or/*.txt\n    \nspark_df_folder = textFiles.toDF(schema=['path','text'])\n\nspark_df_folder.show(truncate=30)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e023fa78-fd8a-4c9e-8a06-c3427d7f1c60","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-----------------------------+------------------------------+\n|                         path|                          text|\n+-----------------------------+------------------------------+\n|dbfs:/sample-sentences-en.txt|Peter is a very good person...|\n+-----------------------------+------------------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------------------------+------------------------------+\n                         path|                          text|\n+-----------------------------+------------------------------+\ndbfs:/sample-sentences-en.txt|Peter is a very good person...|\n+-----------------------------+------------------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["documentAssembler = DocumentAssembler()\\\n    .setInputCol(\"text\")\\\n    .setOutputCol(\"document\")\n\nsentenceDetector = SentenceDetector()\\\n    .setInputCols(['document'])\\\n    .setOutputCol('sentences')\n\ntokenizer = Tokenizer() \\\n    .setInputCols([\"sentences\"]) \\\n    .setOutputCol(\"token\")\n\nnlpPipeline = Pipeline(stages=[\n     documentAssembler, \n     sentenceDetector,\n     tokenizer\n ])\n\nempty_df = spark.createDataFrame([['']]).toDF(\"text\")\n\npipelineModel = nlpPipeline.fit(empty_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"68d04392-c165-48b2-b535-d46513a0466a","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["result = pipelineModel.transform(spark_df)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"183a2d9e-b743-4c74-8868-692b1b825f15","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["result.show(truncate=20)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"dfdd55a7-d082-45a4-989c-757f95d34a07","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+--------------------+--------------------+--------------------+--------------------+\n|                text|            document|           sentences|               token|\n+--------------------+--------------------+--------------------+--------------------+\n|Peter is a very g...|[{document, 0, 27...|[{document, 0, 27...|[{token, 0, 4, Pe...|\n|My life in Russia...|[{document, 0, 37...|[{document, 0, 37...|[{token, 0, 1, My...|\n|John and Peter ar...|[{document, 0, 76...|[{document, 0, 27...|[{token, 0, 3, Jo...|\n|Lucas Nogal Dunbe...|[{document, 0, 67...|[{document, 0, 41...|[{token, 0, 4, Lu...|\n|Europe is very cu...|[{document, 0, 68...|[{document, 0, 27...|[{token, 0, 5, Eu...|\n+--------------------+--------------------+--------------------+--------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+--------------------+--------------------+--------------------+\n                text|            document|           sentences|               token|\n+--------------------+--------------------+--------------------+--------------------+\nPeter is a very g...|[{document, 0, 27...|[{document, 0, 27...|[{token, 0, 4, Pe...|\nMy life in Russia...|[{document, 0, 37...|[{document, 0, 37...|[{token, 0, 1, My...|\nJohn and Peter ar...|[{document, 0, 76...|[{document, 0, 27...|[{token, 0, 3, Jo...|\nLucas Nogal Dunbe...|[{document, 0, 67...|[{document, 0, 41...|[{token, 0, 4, Lu...|\nEurope is very cu...|[{document, 0, 68...|[{document, 0, 27...|[{token, 0, 5, Eu...|\n+--------------------+--------------------+--------------------+--------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["result.printSchema()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"fcdad4b5-d786-40ee-8899-a8de17fc2529","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">root\n |-- text: string (nullable = true)\n |-- document: array (nullable = true)\n |    |-- element: struct (containsNull = true)\n |    |    |-- annotatorType: string (nullable = true)\n |    |    |-- begin: integer (nullable = false)\n |    |    |-- end: integer (nullable = false)\n |    |    |-- result: string (nullable = true)\n |    |    |-- metadata: map (nullable = true)\n |    |    |    |-- key: string\n |    |    |    |-- value: string (valueContainsNull = true)\n |    |    |-- embeddings: array (nullable = true)\n |    |    |    |-- element: float (containsNull = false)\n |-- sentences: array (nullable = true)\n |    |-- element: struct (containsNull = true)\n |    |    |-- annotatorType: string (nullable = true)\n |    |    |-- begin: integer (nullable = false)\n |    |    |-- end: integer (nullable = false)\n |    |    |-- result: string (nullable = true)\n |    |    |-- metadata: map (nullable = true)\n |    |    |    |-- key: string\n |    |    |    |-- value: string (valueContainsNull = true)\n |    |    |-- embeddings: array (nullable = true)\n |    |    |    |-- element: float (containsNull = false)\n |-- token: array (nullable = true)\n |    |-- element: struct (containsNull = true)\n |    |    |-- annotatorType: string (nullable = true)\n |    |    |-- begin: integer (nullable = false)\n |    |    |-- end: integer (nullable = false)\n |    |    |-- result: string (nullable = true)\n |    |    |-- metadata: map (nullable = true)\n |    |    |    |-- key: string\n |    |    |    |-- value: string (valueContainsNull = true)\n |    |    |-- embeddings: array (nullable = true)\n |    |    |    |-- element: float (containsNull = false)\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- text: string (nullable = true)\n-- document: array (nullable = true)\n    |-- element: struct (containsNull = true)\n    |    |-- annotatorType: string (nullable = true)\n    |    |-- begin: integer (nullable = false)\n    |    |-- end: integer (nullable = false)\n    |    |-- result: string (nullable = true)\n    |    |-- metadata: map (nullable = true)\n    |    |    |-- key: string\n    |    |    |-- value: string (valueContainsNull = true)\n    |    |-- embeddings: array (nullable = true)\n    |    |    |-- element: float (containsNull = false)\n-- sentences: array (nullable = true)\n    |-- element: struct (containsNull = true)\n    |    |-- annotatorType: string (nullable = true)\n    |    |-- begin: integer (nullable = false)\n    |    |-- end: integer (nullable = false)\n    |    |-- result: string (nullable = true)\n    |    |-- metadata: map (nullable = true)\n    |    |    |-- key: string\n    |    |    |-- value: string (valueContainsNull = true)\n    |    |-- embeddings: array (nullable = true)\n    |    |    |-- element: float (containsNull = false)\n-- token: array (nullable = true)\n    |-- element: struct (containsNull = true)\n    |    |-- annotatorType: string (nullable = true)\n    |    |-- begin: integer (nullable = false)\n    |    |-- end: integer (nullable = false)\n    |    |-- result: string (nullable = true)\n    |    |-- metadata: map (nullable = true)\n    |    |    |-- key: string\n    |    |    |-- value: string (valueContainsNull = true)\n    |    |-- embeddings: array (nullable = true)\n    |    |    |-- element: float (containsNull = false)\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["result.select('sentences.result').take(3)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ce43ca85-f41d-49d4-a509-b70bd93a68c3","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[22]: [Row(result=[&#39;Peter is a very good person.&#39;]),\n Row(result=[&#39;My life in Russia is very interesting.&#39;]),\n Row(result=[&#39;John and Peter are brothers.&#39;, &#34;However they don&#39;t support each other that much.&#34;])]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[22]: [Row(result=[&#39;Peter is a very good person.&#39;]),\n Row(result=[&#39;My life in Russia is very interesting.&#39;]),\n Row(result=[&#39;John and Peter are brothers.&#39;, &#34;However they don&#39;t support each other that much.&#34;])]</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### StopWords Cleaner"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c763342d-92ad-48ad-b3b0-9ea8ec9b37b6","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["This annotator excludes from a sequence of strings (e.g. the output of a Tokenizer, Normalizer, Lemmatizer, and Stemmer) and drops all the stop words from the input sequences.\n\n**Functions**:\n\n\n\n- **setStopWords**      : The words to be filtered out. Array[String]\n\n- **setCaseSensitive**   : Whether to do a case sensitive comparison over the stop words."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3a625740-bbbe-4c29-a7d9-c861792ca2ca","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["stopwords_cleaner = StopWordsCleaner()\\\n      .setInputCols(\"token\")\\\n      .setOutputCol(\"cleanTokens\")\\\n      .setCaseSensitive(False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e7b1b9a0-fcff-49c4-9c6a-c7b722078665","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["stopwords_cleaner.getStopWords()[:10]"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"11fdf513-a612-48c5-b570-0951c168f535","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[24]: [&#39;i&#39;, &#39;me&#39;, &#39;my&#39;, &#39;myself&#39;, &#39;we&#39;, &#39;our&#39;, &#39;ours&#39;, &#39;ourselves&#39;, &#39;you&#39;, &#39;your&#39;]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[24]: [&#39;i&#39;, &#39;me&#39;, &#39;my&#39;, &#39;myself&#39;, &#39;we&#39;, &#39;our&#39;, &#39;ours&#39;, &#39;ourselves&#39;, &#39;you&#39;, &#39;your&#39;]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["documentAssembler = DocumentAssembler()\\\n    .setInputCol(\"text\")\\\n    .setOutputCol(\"document\")\n\ntokenizer = Tokenizer() \\\n    .setInputCols([\"document\"]) \\\n    .setOutputCol(\"token\")\n\nnlpPipeline = Pipeline(stages=[\n     documentAssembler, \n     tokenizer,\n     stopwords_cleaner\n ])\n\nempty_df = spark.createDataFrame([['']]).toDF(\"text\")\n\npipelineModel = nlpPipeline.fit(empty_df)\n\nresult = pipelineModel.transform(spark_df)\n\nresult.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"90343127-7ab2-4ee9-a1db-7147b8deffbd","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+--------------------+--------------------+--------------------+--------------------+\n|                text|            document|               token|         cleanTokens|\n+--------------------+--------------------+--------------------+--------------------+\n|Peter is a very g...|[{document, 0, 27...|[{token, 0, 4, Pe...|[{token, 0, 4, Pe...|\n|My life in Russia...|[{document, 0, 37...|[{token, 0, 1, My...|[{token, 3, 6, li...|\n|John and Peter ar...|[{document, 0, 76...|[{token, 0, 3, Jo...|[{token, 0, 3, Jo...|\n|Lucas Nogal Dunbe...|[{document, 0, 67...|[{token, 0, 4, Lu...|[{token, 0, 4, Lu...|\n|Europe is very cu...|[{document, 0, 68...|[{token, 0, 5, Eu...|[{token, 0, 5, Eu...|\n+--------------------+--------------------+--------------------+--------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+--------------------+--------------------+--------------------+\n                text|            document|               token|         cleanTokens|\n+--------------------+--------------------+--------------------+--------------------+\nPeter is a very g...|[{document, 0, 27...|[{token, 0, 4, Pe...|[{token, 0, 4, Pe...|\nMy life in Russia...|[{document, 0, 37...|[{token, 0, 1, My...|[{token, 3, 6, li...|\nJohn and Peter ar...|[{document, 0, 76...|[{token, 0, 3, Jo...|[{token, 0, 3, Jo...|\nLucas Nogal Dunbe...|[{document, 0, 67...|[{token, 0, 4, Lu...|[{token, 0, 4, Lu...|\nEurope is very cu...|[{document, 0, 68...|[{token, 0, 5, Eu...|[{token, 0, 5, Eu...|\n+--------------------+--------------------+--------------------+--------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["result.select('cleanTokens.result').take(1)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ac339a2c-0905-4f2c-ac78-be97a2113d15","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[26]: [Row(result=[&#39;Peter&#39;, &#39;good&#39;, &#39;person&#39;, &#39;.&#39;])]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[26]: [Row(result=[&#39;Peter&#39;, &#39;good&#39;, &#39;person&#39;, &#39;.&#39;])]</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Text Matcher"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d586db6c-b47a-4aeb-8682-0fd4338dcf63","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["Annotator to match entire phrases (by token) provided in a file against a Document\n\nFunctions:\n\n`setEntities(path, format, options)`: Provides a file with phrases to match. Default: Looks up path in configuration.\n\n`path`: a path to a file that contains the entities in the specified format.\n\n`readAs`: the format of the file, can be one of {ReadAs.LINE_BY_LINE, ReadAs.SPARK_DATASET}. Defaults to LINE_BY_LINE.\n\n`options`: a map of additional parameters. Defaults to {“format”: “text”}.\n\n`entityValue` : Value for the entity metadata field to indicate which chunk comes from which textMatcher when there are multiple textMatchers. \n\n`mergeOverlapping` : whether to merge overlapping matched chunks. Defaults false\n\n`caseSensitive` : whether to match regardless of case. Defaults true"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9444a643-ed5d-460b-b842-32a811ccecb5","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["! wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/data/news_category_train.csv\n  \ndbutils.fs.cp(\"file:/databricks/driver/news_category_train.csv\", \"dbfs:/\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c2100067-e02a-4777-8c36-eba2c8e76941","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[27]: True</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[27]: True</div>"]}}],"execution_count":0},{"cell_type":"code","source":["news_df = spark.read \\\n      .option(\"header\", True) \\\n      .csv(\"/news_category_train.csv\")\n\n\nnews_df.show(5, truncate=50)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"90b52805-217a-4c8f-8895-494cc7e16a67","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+--------+--------------------------------------------------+\n|category|                                       description|\n+--------+--------------------------------------------------+\n|Business| Short sellers, Wall Street&#39;s dwindling band of...|\n|Business| Private investment firm Carlyle Group, which h...|\n|Business| Soaring crude prices plus worries about the ec...|\n|Business| Authorities have halted oil export flows from ...|\n|Business| Tearaway world oil prices, toppling records an...|\n+--------+--------------------------------------------------+\nonly showing top 5 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+--------------------------------------------------+\ncategory|                                       description|\n+--------+--------------------------------------------------+\nBusiness| Short sellers, Wall Street&#39;s dwindling band of...|\nBusiness| Private investment firm Carlyle Group, which h...|\nBusiness| Soaring crude prices plus worries about the ec...|\nBusiness| Authorities have halted oil export flows from ...|\nBusiness| Tearaway world oil prices, toppling records an...|\n+--------+--------------------------------------------------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["entities = ['Wall Street', 'USD', 'stock', 'NYSE']\nwith open ('financial_entities.txt', 'w') as f:\n    for i in entities:\n        f.write(i+'\\n')\n\n\nentities = ['soccer', 'world cup', 'Messi', 'FC Barcelona']\nwith open ('sport_entities.txt', 'w') as f:\n    for i in entities:\n        f.write(i+'\\n')\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2a9bac6e-3570-4c69-8ced-91bf318b1415","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["dbutils.fs.cp(\"file:/databricks/driver/financial_entities.txt\", \"dbfs:/\")\ndbutils.fs.cp(\"file:/databricks/driver/sport_entities.txt\", \"dbfs:/\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7eb198c8-fe4b-40ce-bb46-08c549904c9a","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[30]: True</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[30]: True</div>"]}}],"execution_count":0},{"cell_type":"code","source":["documentAssembler = DocumentAssembler()\\\n    .setInputCol(\"description\")\\\n    .setOutputCol(\"document\")\n\ntokenizer = Tokenizer() \\\n    .setInputCols([\"document\"]) \\\n    .setOutputCol(\"token\")\n\nfinancial_entity_extractor = TextMatcher() \\\n    .setInputCols([\"document\",'token'])\\\n    .setOutputCol(\"financial_entities\")\\\n    .setEntities(\"file:/databricks/driver/financial_entities.txt\")\\\n    .setCaseSensitive(False)\\\n    .setEntityValue('financial_entity')\n\nsport_entity_extractor = TextMatcher() \\\n    .setInputCols([\"document\",'token'])\\\n    .setOutputCol(\"sport_entities\")\\\n    .setEntities(\"file:/databricks/driver/sport_entities.txt\")\\\n    .setCaseSensitive(False)\\\n    .setEntityValue('sport_entity')\n\n\nnlpPipeline = Pipeline(stages=[\n     documentAssembler, \n     tokenizer,\n     financial_entity_extractor,\n     sport_entity_extractor\n ])\n\nempty_df = spark.createDataFrame([['']]).toDF(\"description\")\n\npipelineModel = nlpPipeline.fit(empty_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a46bfc65-0d9b-4017-833c-60c1f32e3720","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["result = pipelineModel.transform(news_df)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4d9c7be8-0d53-493f-9094-4dff6e91864e","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["result.select('financial_entities.result','sport_entities.result').take(2)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"85cb542f-43b8-40e7-9c49-3627e28f93c6","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[33]: [Row(result=[], result=[]), Row(result=[], result=[])]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[33]: [Row(result=[], result=[]), Row(result=[], result=[])]</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["This means there are no financial and sport entities in the first two lines."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"cd437292-4a94-4bb4-931d-68fc071da854","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.sql import functions as F\n\nresult.select('description','financial_entities.result','sport_entities.result')\\\n      .toDF('text','financial_matches','sport_matches')\\\n      .filter((F.size('financial_matches')>1) | (F.size('sport_matches')>1))\\\n      .show(truncate=70)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"09bdca39-877d-4118-8017-ebadd6cff957","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+----------------------------------------------------------------------+----------------------------------+-------------------+\n|                                                                  text|                 financial_matches|      sport_matches|\n+----------------------------------------------------------------------+----------------------------------+-------------------+\n|&#34;Company launched the biggest electronic auction of stock in Wall S...|              [stock, Wall Street]|                 []|\n|Google, Inc. significantly cut the expected share price for its ini...|                    [stock, stock]|                 []|\n|Google, Inc. significantly cut the expected share price this mornin...|                    [stock, stock]|                 []|\n| Shares of Air Canada  (AC.TO) fell by more than half on Wednesday,...|                    [Stock, stock]|                 []|\n|Stock prices are lower in moderate trading. The Dow Jones Industria...|                    [Stock, Stock]|                 []|\n|The bad news just keeps pouring in for mutual fund manager Janus Ca...|                      [NYSE, NYSE]|                 []|\n|  Shaun Wright Phillips scored in his international debut as Englan...|                                []|[soccer, World Cup]|\n|NEWCASTLE, ENGLAND - England deservedly beat Ukraine 3-0 today in t...|                                []|[soccer, World Cup]|\n|MONTREAL (Reuters) - Shares of Air Canada (AC.TO: Quote, Profile, R...|                    [Stock, stock]|                 []|\n|&#34;SAN JOSE, California - On the cusp of its voyage into public tradi...|[stock, Wall Street, stock, Stock]|                 []|\n|&#34;Shortly before noon today, Google Inc. stock began trading under t...|                    [stock, stock]|                 []|\n|roundup Plus: EA to take World Cup soccer to Xbox...IBM chalks up t...|                                []|[World Cup, soccer]|\n|The U.S. Securities and Exchange Commission yesterday approved Goog...|                    [stock, stock]|                 []|\n|After a bumpy ride toward becoming a publicly traded company, Googl...|                    [stock, stock]|                 []|\n|In the most highly anticipated Wall Street debut since the heady da...|              [Wall Street, stock]|                 []|\n|NEW YORK Despite voluble skepticism among investors, Google #39;s s...|                    [stock, stock]|                 []|\n|If only the rest of my investments worked out this way. One week ag...|                    [stock, stock]|                 []|\n| U.S. stocks to watch: GOOGLE INC. (GOOG.O) Google shares jumped 18...|                    [stock, stock]|                 []|\n|&#34; U.S. stocks to watch: GOOGLE INC.  &amp;lt;A HREF=&#34;&#34;http://www.invest...|                    [stock, stock]|                 []|\n|roundup Plus: KDE updates Linux desktop...EA to take World Cup socc...|                                []|[World Cup, soccer]|\n+----------------------------------------------------------------------+----------------------------------+-------------------+\nonly showing top 20 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------------------------------------------------------------------+----------------------------------+-------------------+\n                                                                  text|                 financial_matches|      sport_matches|\n+----------------------------------------------------------------------+----------------------------------+-------------------+\n&#34;Company launched the biggest electronic auction of stock in Wall S...|              [stock, Wall Street]|                 []|\nGoogle, Inc. significantly cut the expected share price for its ini...|                    [stock, stock]|                 []|\nGoogle, Inc. significantly cut the expected share price this mornin...|                    [stock, stock]|                 []|\n Shares of Air Canada  (AC.TO) fell by more than half on Wednesday,...|                    [Stock, stock]|                 []|\nStock prices are lower in moderate trading. The Dow Jones Industria...|                    [Stock, Stock]|                 []|\nThe bad news just keeps pouring in for mutual fund manager Janus Ca...|                      [NYSE, NYSE]|                 []|\n  Shaun Wright Phillips scored in his international debut as Englan...|                                []|[soccer, World Cup]|\nNEWCASTLE, ENGLAND - England deservedly beat Ukraine 3-0 today in t...|                                []|[soccer, World Cup]|\nMONTREAL (Reuters) - Shares of Air Canada (AC.TO: Quote, Profile, R...|                    [Stock, stock]|                 []|\n&#34;SAN JOSE, California - On the cusp of its voyage into public tradi...|[stock, Wall Street, stock, Stock]|                 []|\n&#34;Shortly before noon today, Google Inc. stock began trading under t...|                    [stock, stock]|                 []|\nroundup Plus: EA to take World Cup soccer to Xbox...IBM chalks up t...|                                []|[World Cup, soccer]|\nThe U.S. Securities and Exchange Commission yesterday approved Goog...|                    [stock, stock]|                 []|\nAfter a bumpy ride toward becoming a publicly traded company, Googl...|                    [stock, stock]|                 []|\nIn the most highly anticipated Wall Street debut since the heady da...|              [Wall Street, stock]|                 []|\nNEW YORK Despite voluble skepticism among investors, Google #39;s s...|                    [stock, stock]|                 []|\nIf only the rest of my investments worked out this way. One week ag...|                    [stock, stock]|                 []|\n U.S. stocks to watch: GOOGLE INC. (GOOG.O) Google shares jumped 18...|                    [stock, stock]|                 []|\n&#34; U.S. stocks to watch: GOOGLE INC.  &amp;lt;A HREF=&#34;&#34;http://www.invest...|                    [stock, stock]|                 []|\nroundup Plus: KDE updates Linux desktop...EA to take World Cup socc...|                                []|[World Cup, soccer]|\n+----------------------------------------------------------------------+----------------------------------+-------------------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Using the pipeline in a LightPipeline"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5cfabadc-d722-4b3c-8929-01bf9883038c","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["light_model = LightPipeline(pipelineModel)\n\nlight_result = light_model.fullAnnotate(\"Google, Inc. significantly cut the expected share price for its stock at Wall Street\")\n\nlight_result[0]['financial_entities']"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"35d76dcf-1ffc-4c12-979e-02928adc9392","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[35]: [Annotation(chunk, 64, 68, stock, {&#39;entity&#39;: &#39;financial_entity&#39;, &#39;sentence&#39;: &#39;0&#39;, &#39;chunk&#39;: &#39;0&#39;}),\n Annotation(chunk, 73, 83, Wall Street, {&#39;entity&#39;: &#39;financial_entity&#39;, &#39;sentence&#39;: &#39;0&#39;, &#39;chunk&#39;: &#39;1&#39;})]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[35]: [Annotation(chunk, 64, 68, stock, {&#39;entity&#39;: &#39;financial_entity&#39;, &#39;sentence&#39;: &#39;0&#39;, &#39;chunk&#39;: &#39;0&#39;}),\n Annotation(chunk, 73, 83, Wall Street, {&#39;entity&#39;: &#39;financial_entity&#39;, &#39;sentence&#39;: &#39;0&#39;, &#39;chunk&#39;: &#39;1&#39;})]</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Pretrained Models"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"32d547ce-58de-42cf-ac1d-0950931431f5","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["Spark NLP offers the following pre-trained models in around **200+ languages** and all you need to do is to load the pre-trained model into your disk by specifying the model name and then configuring the model parameters as per your use case and dataset. Then you will not need to worry about training a new model from scratch and will be able to enjoy the pre-trained SOTA algorithms directly applied to your own data with transform().\n\nIn the official documentation, you can find detailed information regarding how these models are trained by using which algorithms and datasets.\n\nhttps://github.com/JohnSnowLabs/spark-nlp-models"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"18994261-03bb-48eb-828b-cce3ed6dab61","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["for a more detailed notebook, see https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/3.SparkNLP_Pretrained_Models.ipynb"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"97c3453a-75df-490f-9401-1fe210e15f7a","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["### LemmatizerModel and ContextSpellCheckerModel"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"989f4646-45d7-4a6e-aebe-3502798e7c8f","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["documentAssembler = DocumentAssembler()\\\n    .setInputCol(\"text\")\\\n    .setOutputCol(\"document\")\n\ntokenizer = Tokenizer() \\\n    .setInputCols([\"document\"]) \\\n    .setOutputCol(\"token\")\n\nspellModel = ContextSpellCheckerModel\\\n    .pretrained('spellcheck_dl')\\\n    .setInputCols(\"token\")\\\n    .setOutputCol(\"checked\")\n\nlemmatizer = LemmatizerModel.pretrained('lemma_antbnc', 'en') \\\n    .setInputCols([\"checked\"]) \\\n    .setOutputCol(\"lemma\")\n\npipeline = Pipeline(stages = [\n    documentAssembler,\n    tokenizer,\n    spellModel,\n    lemmatizer\n  ])\n\nempty_ds = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n\nsc_model = pipeline.fit(empty_ds)\n\nlp = LightPipeline(sc_model)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4e8ab7e7-8f6f-487e-8f38-3391c29ef9af","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">spellcheck_dl download started this may take some time.\nApproximate size to download 95.1 MB\n\r[ | ]\r[OK!]\nlemma_antbnc download started this may take some time.\nApproximate size to download 907.6 KB\n\r[ | ]\r[OK!]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">spellcheck_dl download started this may take some time.\nApproximate size to download 95.1 MB\n\r[ | ]\r[OK!]\nlemma_antbnc download started this may take some time.\nApproximate size to download 907.6 KB\n\r[ | ]\r[OK!]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["result = lp.annotate(\"Plaese alliow me tao introdduce myhelf, I am a man of waelth und tiaste and he just knows that\")\n\nlist(zip(result['token'],result['checked'],result['lemma']))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0fdab1dc-f0bf-4ec0-8164-23aafe140c09","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[37]: [(&#39;Plaese&#39;, &#39;Please&#39;, &#39;Please&#39;),\n (&#39;alliow&#39;, &#39;allow&#39;, &#39;allow&#39;),\n (&#39;me&#39;, &#39;me&#39;, &#39;i&#39;),\n (&#39;tao&#39;, &#39;to&#39;, &#39;to&#39;),\n (&#39;introdduce&#39;, &#39;introduce&#39;, &#39;introduce&#39;),\n (&#39;myhelf&#39;, &#39;myself&#39;, &#39;myself&#39;),\n (&#39;,&#39;, &#39;,&#39;, &#39;,&#39;),\n (&#39;I&#39;, &#39;I&#39;, &#39;I&#39;),\n (&#39;am&#39;, &#39;am&#39;, &#39;be&#39;),\n (&#39;a&#39;, &#39;a&#39;, &#39;a&#39;),\n (&#39;man&#39;, &#39;man&#39;, &#39;man&#39;),\n (&#39;of&#39;, &#39;of&#39;, &#39;of&#39;),\n (&#39;waelth&#39;, &#39;wealth&#39;, &#39;wealth&#39;),\n (&#39;und&#39;, &#39;and&#39;, &#39;and&#39;),\n (&#39;tiaste&#39;, &#39;taste&#39;, &#39;taste&#39;),\n (&#39;and&#39;, &#39;and&#39;, &#39;and&#39;),\n (&#39;he&#39;, &#39;he&#39;, &#39;he&#39;),\n (&#39;just&#39;, &#39;just&#39;, &#39;just&#39;),\n (&#39;knows&#39;, &#39;knows&#39;, &#39;know&#39;),\n (&#39;that&#39;, &#39;that&#39;, &#39;that&#39;)]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[37]: [(&#39;Plaese&#39;, &#39;Please&#39;, &#39;Please&#39;),\n (&#39;alliow&#39;, &#39;allow&#39;, &#39;allow&#39;),\n (&#39;me&#39;, &#39;me&#39;, &#39;i&#39;),\n (&#39;tao&#39;, &#39;to&#39;, &#39;to&#39;),\n (&#39;introdduce&#39;, &#39;introduce&#39;, &#39;introduce&#39;),\n (&#39;myhelf&#39;, &#39;myself&#39;, &#39;myself&#39;),\n (&#39;,&#39;, &#39;,&#39;, &#39;,&#39;),\n (&#39;I&#39;, &#39;I&#39;, &#39;I&#39;),\n (&#39;am&#39;, &#39;am&#39;, &#39;be&#39;),\n (&#39;a&#39;, &#39;a&#39;, &#39;a&#39;),\n (&#39;man&#39;, &#39;man&#39;, &#39;man&#39;),\n (&#39;of&#39;, &#39;of&#39;, &#39;of&#39;),\n (&#39;waelth&#39;, &#39;wealth&#39;, &#39;wealth&#39;),\n (&#39;und&#39;, &#39;and&#39;, &#39;and&#39;),\n (&#39;tiaste&#39;, &#39;taste&#39;, &#39;taste&#39;),\n (&#39;and&#39;, &#39;and&#39;, &#39;and&#39;),\n (&#39;he&#39;, &#39;he&#39;, &#39;he&#39;),\n (&#39;just&#39;, &#39;just&#39;, &#39;just&#39;),\n (&#39;knows&#39;, &#39;knows&#39;, &#39;know&#39;),\n (&#39;that&#39;, &#39;that&#39;, &#39;that&#39;)]</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Word and Sentence Embeddings"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a90df922-02e1-495c-b38e-354cc6001619","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["#### Word Embeddings"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"166b4680-8ba3-4ef9-bf94-0abb87c83edd","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["glove_embeddings = WordEmbeddingsModel.pretrained('glove_100d')\\\n      .setInputCols([\"document\", \"token\"])\\\n      .setOutputCol(\"embeddings\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b8834d73-d9e4-4263-9a62-78c3bc7ce790","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">glove_100d download started this may take some time.\nApproximate size to download 145.3 MB\n\r[ | ]\r[OK!]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">glove_100d download started this may take some time.\nApproximate size to download 145.3 MB\n\r[ | ]\r[OK!]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["documentAssembler = DocumentAssembler()\\\n    .setInputCol(\"description\")\\\n    .setOutputCol(\"document\")\n\ntokenizer = Tokenizer() \\\n    .setInputCols([\"document\"]) \\\n    .setOutputCol(\"token\")\n\nnlpPipeline = Pipeline(stages=[\n     documentAssembler, \n     tokenizer,\n     glove_embeddings\n ])\n\nempty_df = spark.createDataFrame([['']]).toDF(\"description\")\npipelineModel = nlpPipeline.fit(empty_df)\n\nresult = pipelineModel.transform(news_df.limit(1))\n\noutput = result.select('token.result','embeddings.embeddings').limit(1).rdd.flatMap(lambda x: x).collect()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b3773331-6a53-4fff-9e65-54b360ae96d7","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["pd.DataFrame({'token':output[0],'embeddings':output[1]})"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0a17a82b-8ce3-44d9-9e3e-8b85cffd2145","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[40]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[40]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>token</th>\n      <th>embeddings</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Short</td>\n      <td>[-0.4308899939060211, -0.023907000198960304, -...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>sellers</td>\n      <td>[0.1458200067281723, 0.2753300070762634, -0.20...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>,</td>\n      <td>[-0.10767000168561935, 0.11052999645471573, 0....</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Wall</td>\n      <td>[0.21383999288082123, 0.22098000347614288, 0.0...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Street's</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>dwindling</td>\n      <td>[-0.5611299872398376, 1.1217999458312988, 0.65...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>band</td>\n      <td>[-0.12160000205039978, -0.24347999691963196, 0...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>of</td>\n      <td>[-0.15289999544620514, -0.24278999865055084, 0...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>ultra</td>\n      <td>[-0.3504500091075897, -0.27733999490737915, 0....</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>cynics</td>\n      <td>[-0.06557200103998184, 0.45271000266075134, 0....</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>,</td>\n      <td>[-0.10767000168561935, 0.11052999645471573, 0....</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>are</td>\n      <td>[-0.5153300166130066, 0.8318600058555603, 0.22...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>seeing</td>\n      <td>[0.22673000395298004, 0.1282999962568283, 0.29...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>green</td>\n      <td>[-0.679069995880127, 0.34907999634742737, -0.2...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>again</td>\n      <td>[0.0938429981470108, -0.2028300017118454, 0.34...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>.</td>\n      <td>[-0.3397899866104126, 0.20940999686717987, 0.4...</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>token</th>\n      <th>embeddings</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Short</td>\n      <td>[-0.4308899939060211, -0.023907000198960304, -...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>sellers</td>\n      <td>[0.1458200067281723, 0.2753300070762634, -0.20...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>,</td>\n      <td>[-0.10767000168561935, 0.11052999645471573, 0....</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Wall</td>\n      <td>[0.21383999288082123, 0.22098000347614288, 0.0...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Street's</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>dwindling</td>\n      <td>[-0.5611299872398376, 1.1217999458312988, 0.65...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>band</td>\n      <td>[-0.12160000205039978, -0.24347999691963196, 0...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>of</td>\n      <td>[-0.15289999544620514, -0.24278999865055084, 0...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>ultra</td>\n      <td>[-0.3504500091075897, -0.27733999490737915, 0....</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>cynics</td>\n      <td>[-0.06557200103998184, 0.45271000266075134, 0....</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>,</td>\n      <td>[-0.10767000168561935, 0.11052999645471573, 0....</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>are</td>\n      <td>[-0.5153300166130066, 0.8318600058555603, 0.22...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>seeing</td>\n      <td>[0.22673000395298004, 0.1282999962568283, 0.29...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>green</td>\n      <td>[-0.679069995880127, 0.34907999634742737, -0.2...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>again</td>\n      <td>[0.0938429981470108, -0.2028300017118454, 0.34...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>.</td>\n      <td>[-0.3397899866104126, 0.20940999686717987, 0.4...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["result = pipelineModel.transform(news_df.limit(10))\n\nresult_df = result.select(F.explode(F.arrays_zip(result.token.result, result.embeddings.embeddings)).alias(\"cols\")) \\\n                  .select(F.expr(\"cols['0']\").alias(\"token\"),\n                          F.expr(\"cols['1']\").alias(\"embeddings\"))\n\nresult_df.show(10, truncate=100)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2989d850-5662-41c7-ada2-69f5c7e2d0ee","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+---------+----------------------------------------------------------------------------------------------------+\n|    token|                                                                                          embeddings|\n+---------+----------------------------------------------------------------------------------------------------+\n|    Short|[-0.43089, -0.023907, -0.081875, 0.044522, 0.33741, -0.23081, -0.35145, 0.33043, -0.92222, -0.220...|\n|  sellers|[0.14582, 0.27533, -0.20703, -0.30671, 0.54408, -0.18303, -0.38876, -0.52166, 0.3569, -1.085, 0.1...|\n|        ,|[-0.10767, 0.11053, 0.59812, -0.54361, 0.67396, 0.10663, 0.038867, 0.35481, 0.06351, -0.094189, 0...|\n|     Wall|[0.21384, 0.22098, 0.037105, -0.29186, -0.030131, -0.16247, -1.1043, -0.88436, -0.078059, -0.6353...|\n| Street&#39;s|[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...|\n|dwindling|[-0.56113, 1.1218, 0.65823, 0.2699, 0.12404, -0.12759, -1.0287, -0.64777, 0.59677, -0.12182, -0.8...|\n|     band|[-0.1216, -0.24348, 0.030226, -1.2775, 0.62423, 0.39206, 0.065402, 0.20421, -0.53397, 0.13893, 0....|\n|       of|[-0.1529, -0.24279, 0.89837, 0.16996, 0.53516, 0.48784, -0.58826, -0.17982, -1.3581, 0.42541, 0.1...|\n|    ultra|[-0.35045, -0.27734, 0.090996, -0.042283, -0.09996, 0.076031, 0.062637, -0.082518, -0.63601, 1.12...|\n|   cynics|[-0.065572, 0.45271, 0.60628, -0.48585, -0.84455, 0.029453, -0.35357, -0.56636, 0.34111, -0.07019...|\n+---------+----------------------------------------------------------------------------------------------------+\nonly showing top 10 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------+----------------------------------------------------------------------------------------------------+\n    token|                                                                                          embeddings|\n+---------+----------------------------------------------------------------------------------------------------+\n    Short|[-0.43089, -0.023907, -0.081875, 0.044522, 0.33741, -0.23081, -0.35145, 0.33043, -0.92222, -0.220...|\n  sellers|[0.14582, 0.27533, -0.20703, -0.30671, 0.54408, -0.18303, -0.38876, -0.52166, 0.3569, -1.085, 0.1...|\n        ,|[-0.10767, 0.11053, 0.59812, -0.54361, 0.67396, 0.10663, 0.038867, 0.35481, 0.06351, -0.094189, 0...|\n     Wall|[0.21384, 0.22098, 0.037105, -0.29186, -0.030131, -0.16247, -1.1043, -0.88436, -0.078059, -0.6353...|\n Street&#39;s|[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...|\ndwindling|[-0.56113, 1.1218, 0.65823, 0.2699, 0.12404, -0.12759, -1.0287, -0.64777, 0.59677, -0.12182, -0.8...|\n     band|[-0.1216, -0.24348, 0.030226, -1.2775, 0.62423, 0.39206, 0.065402, 0.20421, -0.53397, 0.13893, 0....|\n       of|[-0.1529, -0.24279, 0.89837, 0.16996, 0.53516, 0.48784, -0.58826, -0.17982, -1.3581, 0.42541, 0.1...|\n    ultra|[-0.35045, -0.27734, 0.090996, -0.042283, -0.09996, 0.076031, 0.062637, -0.082518, -0.63601, 1.12...|\n   cynics|[-0.065572, 0.45271, 0.60628, -0.48585, -0.84455, 0.029453, -0.35357, -0.56636, 0.34111, -0.07019...|\n+---------+----------------------------------------------------------------------------------------------------+\nonly showing top 10 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Bert Embeddings"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c4d19a46-6477-4e70-af78-00adb4d085b0","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["bert_embeddings = BertEmbeddings.pretrained('bert_base_cased')\\\n      .setInputCols([\"document\", \"token\"])\\\n      .setOutputCol(\"embeddings\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0c492ac1-d752-4b5f-b7ec-9b160030ed5b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">bert_base_cased download started this may take some time.\nApproximate size to download 389.1 MB\n\r[ | ]\r[OK!]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">bert_base_cased download started this may take some time.\nApproximate size to download 389.1 MB\n\r[ | ]\r[OK!]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["documentAssembler = DocumentAssembler()\\\n    .setInputCol(\"description\")\\\n    .setOutputCol(\"document\")\n\ntokenizer = Tokenizer() \\\n    .setInputCols([\"document\"]) \\\n    .setOutputCol(\"token\")\n\n \nnlpPipeline = Pipeline(stages=[\n     documentAssembler, \n     tokenizer,\n     bert_embeddings\n ])\n\nempty_df = spark.createDataFrame([['']]).toDF(\"description\")\n\npipelineModel = nlpPipeline.fit(empty_df)\n\nresult = pipelineModel.transform(news_df.limit(10))\n\nresult_df = result.select(F.explode(F.arrays_zip(result.token.result, result.embeddings.embeddings)).alias(\"cols\")) \\\n                  .select(F.expr(\"cols['0']\").alias(\"token\"),\n                          F.expr(\"cols['1']\").alias(\"bert_embeddings\"))\n\nresult_df.show(truncate=100)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ba680faa-c466-4c3a-9d3c-3828dc28ea7b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+----------+----------------------------------------------------------------------------------------------------+\n|     token|                                                                                     bert_embeddings|\n+----------+----------------------------------------------------------------------------------------------------+\n|     Short|[0.49818483, -0.3331852, 0.45259982, -0.29747552, -0.37543702, 0.31528342, 0.27503866, -0.0785038...|\n|   sellers|[0.30120668, 0.60389084, 0.043556854, -0.083134115, 0.15532492, 0.19738051, 0.32395983, 0.2538229...|\n|         ,|[-0.06041675, 0.16640486, -0.13490139, 0.14198671, -0.022981357, 0.021920532, 0.54551727, 0.43710...|\n|      Wall|[-0.13157815, 0.43838108, -0.38766366, -0.33669645, 0.14921406, 0.030721106, 0.1554359, -0.070619...|\n|  Street&#39;s|[0.35614696, 0.41715145, -0.022471193, -0.18717085, 0.45731312, 0.2509821, 0.20012417, 0.35113996...|\n| dwindling|[0.5994897, -0.11001092, -0.19151862, -0.41372263, 0.40886638, -0.4010115, 0.39736944, 0.4646725,...|\n|      band|[0.38114592, -0.36783955, 0.05478254, -0.37785518, -0.20230591, 0.003892865, 0.058304705, 0.54343...|\n|        of|[-0.0870162, 0.15868896, -0.23511443, 0.4945267, 0.41217533, -0.23503186, 0.1724385, 0.64682746, ...|\n|     ultra|[0.05894129, -0.2769129, 0.11804846, 0.03615056, -0.1212608, -0.0689318, 0.11812906, 0.0435234, -...|\n|    cynics|[0.308178, 0.50474554, 6.7128614E-4, -0.08443627, 0.58279175, -0.5385556, 0.20441197, 1.2300129, ...|\n|         ,|[0.22573915, 0.7028286, 0.5402879, 0.059806008, 0.578962, 0.1097455, 0.47140864, 0.67936754, -0.7...|\n|       are|[0.21133757, 0.19332775, 0.06412536, 0.1632013, 0.7104581, 0.07372876, 0.4100115, 0.011539731, -0...|\n|    seeing|[0.09032729, 0.010032464, 0.18926853, 0.008258104, 0.15169653, 0.05071322, 0.39171842, -0.0855152...|\n|     green|[0.15449734, 0.13028544, 0.19091597, 0.18432857, -0.18943375, 0.32863376, 0.09580539, 0.18395072,...|\n|     again|[-0.009291217, 0.118453965, -0.35919952, 0.23789594, 0.20325667, -0.2951973, 0.039237943, 0.21457...|\n|         .|[0.69319904, 0.13296725, 0.09412593, 0.38704526, 0.011296114, -0.20226017, -0.3490868, 0.11724714...|\n|   Private|[0.3962593, -0.2044377, 0.26834077, -0.11349306, -0.48581505, 0.26813355, 0.19422276, 0.033243142...|\n|investment|[0.44329366, 0.49842113, -0.013835583, 0.3266698, -0.026564963, 0.22005695, -0.0020434186, 0.5129...|\n|      firm|[-0.29247504, 0.03376401, -0.18367523, 0.017875534, 0.25998113, 0.19098213, -0.12764199, 0.435801...|\n|   Carlyle|[0.53605425, 0.27315557, -0.22559032, -0.09160382, 0.45161322, -0.043090746, 0.61375695, 0.296126...|\n+----------+----------------------------------------------------------------------------------------------------+\nonly showing top 20 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+----------------------------------------------------------------------------------------------------+\n     token|                                                                                     bert_embeddings|\n+----------+----------------------------------------------------------------------------------------------------+\n     Short|[0.49818483, -0.3331852, 0.45259982, -0.29747552, -0.37543702, 0.31528342, 0.27503866, -0.0785038...|\n   sellers|[0.30120668, 0.60389084, 0.043556854, -0.083134115, 0.15532492, 0.19738051, 0.32395983, 0.2538229...|\n         ,|[-0.06041675, 0.16640486, -0.13490139, 0.14198671, -0.022981357, 0.021920532, 0.54551727, 0.43710...|\n      Wall|[-0.13157815, 0.43838108, -0.38766366, -0.33669645, 0.14921406, 0.030721106, 0.1554359, -0.070619...|\n  Street&#39;s|[0.35614696, 0.41715145, -0.022471193, -0.18717085, 0.45731312, 0.2509821, 0.20012417, 0.35113996...|\n dwindling|[0.5994897, -0.11001092, -0.19151862, -0.41372263, 0.40886638, -0.4010115, 0.39736944, 0.4646725,...|\n      band|[0.38114592, -0.36783955, 0.05478254, -0.37785518, -0.20230591, 0.003892865, 0.058304705, 0.54343...|\n        of|[-0.0870162, 0.15868896, -0.23511443, 0.4945267, 0.41217533, -0.23503186, 0.1724385, 0.64682746, ...|\n     ultra|[0.05894129, -0.2769129, 0.11804846, 0.03615056, -0.1212608, -0.0689318, 0.11812906, 0.0435234, -...|\n    cynics|[0.308178, 0.50474554, 6.7128614E-4, -0.08443627, 0.58279175, -0.5385556, 0.20441197, 1.2300129, ...|\n         ,|[0.22573915, 0.7028286, 0.5402879, 0.059806008, 0.578962, 0.1097455, 0.47140864, 0.67936754, -0.7...|\n       are|[0.21133757, 0.19332775, 0.06412536, 0.1632013, 0.7104581, 0.07372876, 0.4100115, 0.011539731, -0...|\n    seeing|[0.09032729, 0.010032464, 0.18926853, 0.008258104, 0.15169653, 0.05071322, 0.39171842, -0.0855152...|\n     green|[0.15449734, 0.13028544, 0.19091597, 0.18432857, -0.18943375, 0.32863376, 0.09580539, 0.18395072,...|\n     again|[-0.009291217, 0.118453965, -0.35919952, 0.23789594, 0.20325667, -0.2951973, 0.039237943, 0.21457...|\n         .|[0.69319904, 0.13296725, 0.09412593, 0.38704526, 0.011296114, -0.20226017, -0.3490868, 0.11724714...|\n   Private|[0.3962593, -0.2044377, 0.26834077, -0.11349306, -0.48581505, 0.26813355, 0.19422276, 0.033243142...|\ninvestment|[0.44329366, 0.49842113, -0.013835583, 0.3266698, -0.026564963, 0.22005695, -0.0020434186, 0.5129...|\n      firm|[-0.29247504, 0.03376401, -0.18367523, 0.017875534, 0.25998113, 0.19098213, -0.12764199, 0.435801...|\n   Carlyle|[0.53605425, 0.27315557, -0.22559032, -0.09160382, 0.45161322, -0.043090746, 0.61375695, 0.296126...|\n+----------+----------------------------------------------------------------------------------------------------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Bert Sentence Embeddings"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6c7c2ead-1c50-48b1-bd94-e81157ab9b41","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["bert_sentence_embeddings = BertSentenceEmbeddings.pretrained('sent_small_bert_L6_128')\\\n    .setInputCols([\"document\"])\\\n    .setOutputCol(\"bert_sent_embeddings\")\n\n\nnlpPipeline = Pipeline(stages=[\n     documentAssembler, \n     bert_sentence_embeddings\n ])\n\n\nempty_df = spark.createDataFrame([['']]).toDF(\"description\")\n\npipelineModel = nlpPipeline.fit(empty_df)\n\nresult = pipelineModel.transform(news_df.limit(10))\n\nresult_df = result.select(F.explode(F.arrays_zip(result.document.result, result.bert_sent_embeddings.embeddings)).alias(\"cols\"))\\\n                  .select(F.expr(\"cols['0']\").alias(\"document\"),\n                          F.expr(\"cols['1']\").alias(\"bert_sent_embeddings\"))\n\nresult_df.show(truncate=100)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e61ee255-1e0c-4170-a9bb-e2b1fd924750","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">sent_small_bert_L6_128 download started this may take some time.\nApproximate size to download 19 MB\n\r[ | ]\r[OK!]\n+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+\n|                                                                                            document|                                                                                bert_sent_embeddings|\n+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+\n|                Short sellers, Wall Street&#39;s dwindling band of ultra cynics, are seeing green again.|[-0.41675937, 0.5293154, -0.49145287, 0.37030974, -1.2797567, -1.4873856, 0.77664876, 0.6182901, ...|\n| Private investment firm Carlyle Group, which has a reputation for making well timed and occasion...|[-0.7241612, 0.26396877, -0.09912901, -0.31469417, -1.7490373, -2.4093583, 1.0729092, -0.03699272...|\n| Soaring crude prices plus worries about the economy and the outlook for earnings are expected to...|[-1.2664676, -0.096879356, 0.4716698, 0.56874573, -1.4044636, -2.349665, 0.9649328, -0.24027611, ...|\n| Authorities have halted oil export flows from the main pipeline in southern Iraq after intellige...|[-1.1788416, 0.484571, 0.105041526, -0.31525448, -1.3312116, -2.1511004, 0.77638364, 0.35118315, ...|\n| Tearaway world oil prices, toppling records and straining wallets, present a new economic menace...|[-0.58497596, 0.21366586, 0.3028639, -0.22787014, -1.6377766, -2.5154274, 0.80840546, 0.27834576,...|\n| Stocks ended slightly higher on Friday but stayed near lows for the year as oil prices surged pa...|[-0.8924513, 0.024222406, 0.19888614, 0.39349273, -1.1477064, -3.1600404, 0.9122887, 0.06095158, ...|\n| Assets of the nation&#39;s retail money market mutual funds fell by  #36;1.17 billion in the latest ...|[-0.8281481, 0.42437613, 0.054953203, 0.12704752, -1.4470572, -3.1488242, 1.0984502, -0.45984516,...|\n| Retail sales bounced back a bit in July, and new claims for jobless benefits fell last week, the...|[-0.7293257, 0.56641984, 0.072779804, -0.036559496, -1.768339, -2.374348, 1.1184818, 0.20761971, ...|\n|&#34; After earning a PH.D. in Sociology, Danny Bazil Riley started to work as the general manager at...|[-0.951015, -0.08099435, 0.16685183, 2.9863138E-4, -1.6403106, -2.466724, 1.0859858, -0.21772286,...|\n|               Short sellers, Wall Street&#39;s dwindling  band of ultra cynics, are seeing green again.|[-0.31763077, 0.052906923, -0.28047657, 0.43761775, -1.5268981, -1.5332798, 0.7739702, 0.62022483...|\n+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">sent_small_bert_L6_128 download started this may take some time.\nApproximate size to download 19 MB\n\r[ | ]\r[OK!]\n+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+\n                                                                                            document|                                                                                bert_sent_embeddings|\n+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+\n                Short sellers, Wall Street&#39;s dwindling band of ultra cynics, are seeing green again.|[-0.41675937, 0.5293154, -0.49145287, 0.37030974, -1.2797567, -1.4873856, 0.77664876, 0.6182901, ...|\n Private investment firm Carlyle Group, which has a reputation for making well timed and occasion...|[-0.7241612, 0.26396877, -0.09912901, -0.31469417, -1.7490373, -2.4093583, 1.0729092, -0.03699272...|\n Soaring crude prices plus worries about the economy and the outlook for earnings are expected to...|[-1.2664676, -0.096879356, 0.4716698, 0.56874573, -1.4044636, -2.349665, 0.9649328, -0.24027611, ...|\n Authorities have halted oil export flows from the main pipeline in southern Iraq after intellige...|[-1.1788416, 0.484571, 0.105041526, -0.31525448, -1.3312116, -2.1511004, 0.77638364, 0.35118315, ...|\n Tearaway world oil prices, toppling records and straining wallets, present a new economic menace...|[-0.58497596, 0.21366586, 0.3028639, -0.22787014, -1.6377766, -2.5154274, 0.80840546, 0.27834576,...|\n Stocks ended slightly higher on Friday but stayed near lows for the year as oil prices surged pa...|[-0.8924513, 0.024222406, 0.19888614, 0.39349273, -1.1477064, -3.1600404, 0.9122887, 0.06095158, ...|\n Assets of the nation&#39;s retail money market mutual funds fell by  #36;1.17 billion in the latest ...|[-0.8281481, 0.42437613, 0.054953203, 0.12704752, -1.4470572, -3.1488242, 1.0984502, -0.45984516,...|\n Retail sales bounced back a bit in July, and new claims for jobless benefits fell last week, the...|[-0.7293257, 0.56641984, 0.072779804, -0.036559496, -1.768339, -2.374348, 1.1184818, 0.20761971, ...|\n&#34; After earning a PH.D. in Sociology, Danny Bazil Riley started to work as the general manager at...|[-0.951015, -0.08099435, 0.16685183, 2.9863138E-4, -1.6403106, -2.466724, 1.0859858, -0.21772286,...|\n               Short sellers, Wall Street&#39;s dwindling  band of ultra cynics, are seeing green again.|[-0.31763077, 0.052906923, -0.28047657, 0.43761775, -1.5268981, -1.5332798, 0.7739702, 0.62022483...|\n+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Universal Sentence Encoder"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b08f8c03-5927-4094-97ef-6b6630149f03","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# no need for token columns \nuse_embeddings = UniversalSentenceEncoder.pretrained('tfhub_use')\\\n    .setInputCols([\"document\"])\\\n    .setOutputCol(\"sentence_embeddings\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8eef39ab-8046-4d06-a196-23e1b16269f6","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">tfhub_use download started this may take some time.\nApproximate size to download 923.7 MB\n\r[ | ]\r[OK!]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">tfhub_use download started this may take some time.\nApproximate size to download 923.7 MB\n\r[ | ]\r[OK!]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql import functions as F\n\ndocumentAssembler = DocumentAssembler()\\\n    .setInputCol(\"description\")\\\n    .setOutputCol(\"document\")\n\nnlpPipeline = Pipeline(stages=[\n     documentAssembler, \n     use_embeddings\n   ])\n\nempty_df = spark.createDataFrame([['']]).toDF(\"description\")\n\npipelineModel = nlpPipeline.fit(empty_df)\n\nresult = pipelineModel.transform(news_df.limit(10))\n\nresult_df = result.select(F.explode(F.arrays_zip(result.document.result, result.sentence_embeddings.embeddings)).alias(\"cols\"))\\\n                  .select(F.expr(\"cols['0']\").alias(\"document\"),\n                          F.expr(\"cols['1']\").alias(\"USE_embeddings\"))\n\nresult_df.show(truncate=100)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d82915fc-adcd-43f8-aca0-0f66babeaf5f","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+\n|                                                                                            document|                                                                                      USE_embeddings|\n+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+\n|                Short sellers, Wall Street&#39;s dwindling band of ultra cynics, are seeing green again.|[0.04415017, -6.5326475E-4, -0.013665826, -0.060485892, -0.07109088, 0.048674487, 0.08480666, -0....|\n| Private investment firm Carlyle Group, which has a reputation for making well timed and occasion...|[0.08444513, 0.03535444, -0.0398393, 0.021572154, -0.09528031, 0.06693117, 0.08432242, 0.03179448...|\n| Soaring crude prices plus worries about the economy and the outlook for earnings are expected to...|[0.042664703, 0.023801483, -0.00903941, -0.03274944, -0.046533488, -0.020040143, 0.083063215, 0.0...|\n| Authorities have halted oil export flows from the main pipeline in southern Iraq after intellige...|[0.0068348483, -0.026235892, -0.040894095, 0.041971933, -0.0052266596, 0.039967872, 0.072752714, ...|\n| Tearaway world oil prices, toppling records and straining wallets, present a new economic menace...|[0.01975775, 0.03287937, -0.009231378, 0.049207438, -0.064149044, -0.043107536, 0.08950389, -0.01...|\n| Stocks ended slightly higher on Friday but stayed near lows for the year as oil prices surged pa...|[0.05472721, 0.046188872, -0.030876318, 0.049301375, -0.052396327, -0.019601379, 0.08263386, -0.0...|\n| Assets of the nation&#39;s retail money market mutual funds fell by  #36;1.17 billion in the latest ...|[0.03859763, 0.029694065, -0.028027907, 0.041099597, -0.056200057, 0.009426447, 0.08219276, -0.02...|\n| Retail sales bounced back a bit in July, and new claims for jobless benefits fell last week, the...|[0.019924711, 0.06581009, 7.1992836E-4, 0.016005162, -0.022610273, -0.055379022, 0.079486564, -0....|\n|&#34; After earning a PH.D. in Sociology, Danny Bazil Riley started to work as the general manager at...|[0.060242545, 0.043736562, -0.027734566, 0.008369135, -0.064489506, 0.02077207, 0.051990625, 0.01...|\n|               Short sellers, Wall Street&#39;s dwindling  band of ultra cynics, are seeing green again.|[0.04415017, -6.5326475E-4, -0.013665826, -0.060485892, -0.07109088, 0.048674487, 0.08480666, -0....|\n+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+\n                                                                                            document|                                                                                      USE_embeddings|\n+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+\n                Short sellers, Wall Street&#39;s dwindling band of ultra cynics, are seeing green again.|[0.04415017, -6.5326475E-4, -0.013665826, -0.060485892, -0.07109088, 0.048674487, 0.08480666, -0....|\n Private investment firm Carlyle Group, which has a reputation for making well timed and occasion...|[0.08444513, 0.03535444, -0.0398393, 0.021572154, -0.09528031, 0.06693117, 0.08432242, 0.03179448...|\n Soaring crude prices plus worries about the economy and the outlook for earnings are expected to...|[0.042664703, 0.023801483, -0.00903941, -0.03274944, -0.046533488, -0.020040143, 0.083063215, 0.0...|\n Authorities have halted oil export flows from the main pipeline in southern Iraq after intellige...|[0.0068348483, -0.026235892, -0.040894095, 0.041971933, -0.0052266596, 0.039967872, 0.072752714, ...|\n Tearaway world oil prices, toppling records and straining wallets, present a new economic menace...|[0.01975775, 0.03287937, -0.009231378, 0.049207438, -0.064149044, -0.043107536, 0.08950389, -0.01...|\n Stocks ended slightly higher on Friday but stayed near lows for the year as oil prices surged pa...|[0.05472721, 0.046188872, -0.030876318, 0.049301375, -0.052396327, -0.019601379, 0.08263386, -0.0...|\n Assets of the nation&#39;s retail money market mutual funds fell by  #36;1.17 billion in the latest ...|[0.03859763, 0.029694065, -0.028027907, 0.041099597, -0.056200057, 0.009426447, 0.08219276, -0.02...|\n Retail sales bounced back a bit in July, and new claims for jobless benefits fell last week, the...|[0.019924711, 0.06581009, 7.1992836E-4, 0.016005162, -0.022610273, -0.055379022, 0.079486564, -0....|\n&#34; After earning a PH.D. in Sociology, Danny Bazil Riley started to work as the general manager at...|[0.060242545, 0.043736562, -0.027734566, 0.008369135, -0.064489506, 0.02077207, 0.051990625, 0.01...|\n               Short sellers, Wall Street&#39;s dwindling  band of ultra cynics, are seeing green again.|[0.04415017, -6.5326475E-4, -0.013665826, -0.060485892, -0.07109088, 0.048674487, 0.08480666, -0....|\n+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Named Entity Recognition (NER) Models"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8e7fd105-4db1-40d2-a86f-4a817b8f598b","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["for a detailed notebbok, see https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/4.NERDL_Training.ipynb"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3017e91d-ac8e-4081-8201-781865ac226a","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["documentAssembler = DocumentAssembler()\\\n    .setInputCol(\"description\")\\\n    .setOutputCol(\"document\")\n\ntokenizer = Tokenizer() \\\n    .setInputCols([\"document\"]) \\\n    .setOutputCol(\"token\")\n\nglove_embeddings = WordEmbeddingsModel.pretrained('glove_100d')\\\n      .setInputCols([\"document\", \"token\"])\\\n      .setOutputCol(\"embeddings\")\n\nonto_ner = NerDLModel.pretrained(\"onto_100\", 'en') \\\n      .setInputCols([\"document\", \"token\", \"embeddings\"]) \\\n      .setOutputCol(\"ner\")\n\nner_converter = NerConverter() \\\n      .setInputCols([\"document\", \"token\", \"ner\"]) \\\n      .setOutputCol(\"ner_chunk\")\n\n\nnlpPipeline = Pipeline(stages=[\n       documentAssembler, \n       tokenizer,\n       glove_embeddings,\n       onto_ner,\n       ner_converter\n ])\n\nempty_df = spark.createDataFrame([['']]).toDF(\"description\")\n\npipelineModel = nlpPipeline.fit(empty_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b19dc9a7-2005-436d-813b-efa6d34abb98","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">glove_100d download started this may take some time.\nApproximate size to download 145.3 MB\n\r[ | ]\r[OK!]\nonto_100 download started this may take some time.\nApproximate size to download 13.5 MB\n\r[ | ]\r[OK!]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">glove_100d download started this may take some time.\nApproximate size to download 145.3 MB\n\r[ | ]\r[OK!]\nonto_100 download started this may take some time.\nApproximate size to download 13.5 MB\n\r[ | ]\r[OK!]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["result = pipelineModel.transform(news_df.limit(10))\n\nresult.select(F.explode(F.arrays_zip(result.ner_chunk.result, result.ner_chunk.metadata)).alias(\"cols\")) \\\n      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n              F.expr(\"cols['1']['entity']\").alias(\"ner_label\")).show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"fb8eddc8-05b0-4634-8f3f-34e046b0c33a","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+--------------------------------+---------+\n|chunk                           |ner_label|\n+--------------------------------+---------+\n|Carlyle Group                   |ORG      |\n|next week                       |DATE     |\n|summer                          |DATE     |\n|Iraq                            |GPE      |\n|Saturday                        |DATE     |\n|three months                    |DATE     |\n|US                              |GPE      |\n|Friday                          |DATE     |\n|the year                        |DATE     |\n|#36;46                          |CARDINAL |\n|Dell Inc                        |ORG      |\n|#36;1.17 billion                |CARDINAL |\n|the latest week                 |DATE     |\n|#36;849.98 trillion             |CARDINAL |\n|the Investment Company Institute|ORG      |\n|Thursday                        |DATE     |\n|July                            |DATE     |\n|last week                       |DATE     |\n|Thursday                        |DATE     |\n|midsummer                       |DATE     |\n+--------------------------------+---------+\nonly showing top 20 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------------------+---------+\nchunk                           |ner_label|\n+--------------------------------+---------+\nCarlyle Group                   |ORG      |\nnext week                       |DATE     |\nsummer                          |DATE     |\nIraq                            |GPE      |\nSaturday                        |DATE     |\nthree months                    |DATE     |\nUS                              |GPE      |\nFriday                          |DATE     |\nthe year                        |DATE     |\n#36;46                          |CARDINAL |\nDell Inc                        |ORG      |\n#36;1.17 billion                |CARDINAL |\nthe latest week                 |DATE     |\n#36;849.98 trillion             |CARDINAL |\nthe Investment Company Institute|ORG      |\nThursday                        |DATE     |\nJuly                            |DATE     |\nlast week                       |DATE     |\nThursday                        |DATE     |\nmidsummer                       |DATE     |\n+--------------------------------+---------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["light_model = LightPipeline(pipelineModel)\n\nlight_result = light_model.fullAnnotate('Peter Parker is a nice persn and lives in New York. Bruce Wayne is also a nice guy and lives in Gotham City.')\n\n\nchunks = []\nentities = []\n\nfor n in light_result[0]['ner_chunk']:\n        \n    chunks.append(n.result)\n    entities.append(n.metadata['entity']) \n    \n    \nimport pandas as pd\n\ndf = pd.DataFrame({'chunks':chunks, 'entities':entities})\n\ndf"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"650ceca1-3ae4-4742-b442-305fb549d58a","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[49]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[49]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>chunks</th>\n      <th>entities</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Peter Parker</td>\n      <td>PERSON</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>New York</td>\n      <td>GPE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Bruce Wayne</td>\n      <td>PERSON</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Gotham City</td>\n      <td>GPE</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>chunks</th>\n      <th>entities</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Peter Parker</td>\n      <td>PERSON</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>New York</td>\n      <td>GPE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Bruce Wayne</td>\n      <td>PERSON</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Gotham City</td>\n      <td>GPE</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Train a NER model"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"94ba36fb-bb2d-41b4-8e7a-33fefd680443","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["**To train a new NER from scratch, check out**\n\nhttps://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/4.NERDL_Training.ipynb"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4363be3c-806d-4ac6-8619-f387a9d3c1c4","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/src/test/resources/conll2003/eng.train\n\n#dbutils.fs.cp(\"file:/databricks/driver/sample-sentences-en.txt\", \"dbfs:/\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"dc5399b8-4974-440b-ab1f-888741236dbd","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["from sparknlp.training import CoNLL\n\ntraining_data = CoNLL().readDataset(spark, 'file:/databricks/driver/eng.train')\n\ntraining_data.show(3)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"02fb1d1b-3d38-4ecd-b08e-5e2b3969c23c","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n|                text|            document|            sentence|               token|                 pos|               label|\n+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n|EU rejects German...|[{document, 0, 47...|[{document, 0, 47...|[{token, 0, 1, EU...|[{pos, 0, 1, NNP,...|[{named_entity, 0...|\n|     Peter Blackburn|[{document, 0, 14...|[{document, 0, 14...|[{token, 0, 4, Pe...|[{pos, 0, 4, NNP,...|[{named_entity, 0...|\n| BRUSSELS 1996-08-22|[{document, 0, 18...|[{document, 0, 18...|[{token, 0, 7, BR...|[{pos, 0, 7, NNP,...|[{named_entity, 0...|\n+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\nonly showing top 3 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n                text|            document|            sentence|               token|                 pos|               label|\n+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\nEU rejects German...|[{document, 0, 47...|[{document, 0, 47...|[{token, 0, 1, EU...|[{pos, 0, 1, NNP,...|[{named_entity, 0...|\n     Peter Blackburn|[{document, 0, 14...|[{document, 0, 14...|[{token, 0, 4, Pe...|[{pos, 0, 4, NNP,...|[{named_entity, 0...|\n BRUSSELS 1996-08-22|[{document, 0, 18...|[{document, 0, 18...|[{token, 0, 7, BR...|[{pos, 0, 7, NNP,...|[{named_entity, 0...|\n+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\nonly showing top 3 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["training_data.select(F.explode(F.arrays_zip(training_data.token.result, training_data.label.result)).alias(\"cols\"))\\\n              .select(F.expr(\"cols['0']\").alias(\"token\"),\n                      F.expr(\"cols['1']\").alias(\"ground_truth\"))\\\n              .groupBy('ground_truth').count().orderBy('count', ascending=False).show(100,truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"48bde700-3773-4080-9601-d8d8ade3f025","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+------------+------+\n|ground_truth|count |\n+------------+------+\n|O           |169578|\n|B-LOC       |7140  |\n|B-PER       |6600  |\n|B-ORG       |6321  |\n|I-PER       |4528  |\n|I-ORG       |3704  |\n|B-MISC      |3438  |\n|I-LOC       |1157  |\n|I-MISC      |1155  |\n+------------+------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------------+------+\nground_truth|count |\n+------------+------+\nO           |169578|\nB-LOC       |7140  |\nB-PER       |6600  |\nB-ORG       |6321  |\nI-PER       |4528  |\nI-ORG       |3704  |\nB-MISC      |3438  |\nI-LOC       |1157  |\nI-MISC      |1155  |\n+------------+------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# You can use any word embeddings you want (Glove, Elmo, Bert, custom etc.)\n\nglove_embeddings = WordEmbeddingsModel.pretrained('glove_100d')\\\n          .setInputCols([\"document\", \"token\"])\\\n          .setOutputCol(\"embeddings\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"95175ff9-980e-4720-8869-c5da9626dfc9","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">glove_100d download started this may take some time.\nApproximate size to download 145.3 MB\n\r[ | ]\r[OK!]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">glove_100d download started this may take some time.\nApproximate size to download 145.3 MB\n\r[ | ]\r[OK!]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%fs mkdirs dbfs:/ner_logs"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7835b633-ce71-49bc-820b-da86776faaf4","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">res0: Boolean = true\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">res0: Boolean = true\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["nerTagger = NerDLApproach()\\\n  .setInputCols([\"sentence\", \"token\", \"embeddings\"])\\\n  .setLabelColumn(\"label\")\\\n  .setOutputCol(\"ner\")\\\n  .setMaxEpochs(2)\\\n  .setLr(0.003)\\\n  .setPo(0.05)\\\n  .setBatchSize(32)\\\n  .setRandomSeed(0)\\\n  .setVerbose(1)\\\n  .setValidationSplit(0.2)\\\n  .setEvaluationLogExtended(True) \\\n  .setEnableOutputLogs(True)\\\n  .setIncludeConfidence(True)\\\n  .setOutputLogsPath('dbfs:/ner_logs') # if not set, logs will be written to ~/annotator_logs\n #.setGraphFolder('graphs') >> put your graph file (pb) under this folder if you are using a custom graph generated thru NerDL-Graph\n    \n    \nner_pipeline = Pipeline(stages=[\n          glove_embeddings,\n          nerTagger\n ])"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"01ad1fac-2ce7-4d03-8623-bf136e3609f3","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# remove the existing logs\n\n!rm -r /dbfs/ner_logs/*"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"dc60f868-c144-44a7-8e21-4a41d20275e5","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["ner_model = ner_pipeline.fit(training_data)\n\n# 1 epoch takes around 2.5 min with batch size=32\n# if you get an error for incompatible TF graph, use NERDL Graph script to generate the necessary TF graph at the end of this notebook"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c329622f-c564-41bc-9c11-28330530bc83","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sh cd /dbfs/ner_logs && pwd && ls -l"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d17e011f-f47a-434e-9fec-a3d6b29a0f69","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">/dbfs/ner_logs\ntotal 2\n-rwxrwxrwx 1 root root 1844 Jan 17 20:02 NerDLApproach_b8d98379503c.log\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/dbfs/ner_logs\ntotal 2\n-rwxrwxrwx 1 root root 1844 Jan 17 20:02 NerDLApproach_b8d98379503c.log\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sh head -n 45 /dbfs/ner_logs/NerDLApproach_*"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4a1f7d7a-6551-4ad6-b99a-bb23d20bb4d8","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Name of the selected graph: ner-dl/blstm_10_100_128_120.pb\nTraining started - total epochs: 2 - lr: 0.003 - batch size: 32 - labels: 9 - chars: 84 - training examples: 11207\n\n\nEpoch 1/2 started, lr: 0.003, dataset size: 11207\n\n\nEpoch 1/2 - 30.92s - loss: 1474.4053 - batches: 354\nQuality on validation dataset (20.0%), validation examples = 2241\ntime to finish evaluation: 2.65s\nlabel\t tp\t fp\t fn\t prec\t rec\t f1\nB-LOC\t 1315\t 147\t 115\t 0.8994528\t 0.9195804\t 0.9094053\nI-ORG\t 600\t 139\t 164\t 0.811908\t 0.7853403\t 0.7984032\nI-MISC\t 110\t 13\t 132\t 0.8943089\t 0.45454547\t 0.6027397\nI-LOC\t 138\t 21\t 91\t 0.8679245\t 0.60262007\t 0.7113402\nI-PER\t 931\t 46\t 13\t 0.9529171\t 0.9862288\t 0.96928686\nB-MISC\t 547\t 51\t 191\t 0.9147157\t 0.7411924\t 0.81886226\nB-ORG\t 1064\t 188\t 187\t 0.8498403\t 0.8505196\t 0.8501798\nB-PER\t 1311\t 107\t 56\t 0.9245416\t 0.9590344\t 0.94147223\ntp: 6016 fp: 712 fn: 949 labels: 8\nMacro-average\t prec: 0.8894511, rec: 0.7873827, f1: 0.83531046\nMicro-average\t prec: 0.8941736, rec: 0.8637473, f1: 0.87869716\n\n\nEpoch 2/2 started, lr: 0.002857143, dataset size: 11207\n\n\nEpoch 2/2 - 29.67s - loss: 448.14264 - batches: 354\nQuality on validation dataset (20.0%), validation examples = 2241\ntime to finish evaluation: 2.27s\nlabel\t tp\t fp\t fn\t prec\t rec\t f1\nB-LOC\t 1353\t 119\t 77\t 0.9191576\t 0.9461538\t 0.93246037\nI-ORG\t 659\t 123\t 105\t 0.842711\t 0.86256546\t 0.8525226\nI-MISC\t 167\t 29\t 75\t 0.8520408\t 0.69008267\t 0.762557\nI-LOC\t 173\t 23\t 56\t 0.88265306\t 0.75545853\t 0.8141176\nI-PER\t 925\t 24\t 19\t 0.9747102\t 0.9798729\t 0.9772847\nB-MISC\t 638\t 46\t 100\t 0.93274856\t 0.8644986\t 0.89732766\nB-ORG\t 1116\t 151\t 135\t 0.8808208\t 0.8920863\t 0.8864178\nB-PER\t 1308\t 53\t 59\t 0.961058\t 0.9568398\t 0.95894426\ntp: 6339 fp: 568 fn: 626 labels: 8\nMacro-average\t prec: 0.9057375, rec: 0.8684448, f1: 0.88669926\nMicro-average\t prec: 0.9177646, rec: 0.91012204, f1: 0.9139274\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Name of the selected graph: ner-dl/blstm_10_100_128_120.pb\nTraining started - total epochs: 2 - lr: 0.003 - batch size: 32 - labels: 9 - chars: 84 - training examples: 11207\n\n\nEpoch 1/2 started, lr: 0.003, dataset size: 11207\n\n\nEpoch 1/2 - 30.92s - loss: 1474.4053 - batches: 354\nQuality on validation dataset (20.0%), validation examples = 2241\ntime to finish evaluation: 2.65s\nlabel\t tp\t fp\t fn\t prec\t rec\t f1\nB-LOC\t 1315\t 147\t 115\t 0.8994528\t 0.9195804\t 0.9094053\nI-ORG\t 600\t 139\t 164\t 0.811908\t 0.7853403\t 0.7984032\nI-MISC\t 110\t 13\t 132\t 0.8943089\t 0.45454547\t 0.6027397\nI-LOC\t 138\t 21\t 91\t 0.8679245\t 0.60262007\t 0.7113402\nI-PER\t 931\t 46\t 13\t 0.9529171\t 0.9862288\t 0.96928686\nB-MISC\t 547\t 51\t 191\t 0.9147157\t 0.7411924\t 0.81886226\nB-ORG\t 1064\t 188\t 187\t 0.8498403\t 0.8505196\t 0.8501798\nB-PER\t 1311\t 107\t 56\t 0.9245416\t 0.9590344\t 0.94147223\ntp: 6016 fp: 712 fn: 949 labels: 8\nMacro-average\t prec: 0.8894511, rec: 0.7873827, f1: 0.83531046\nMicro-average\t prec: 0.8941736, rec: 0.8637473, f1: 0.87869716\n\n\nEpoch 2/2 started, lr: 0.002857143, dataset size: 11207\n\n\nEpoch 2/2 - 29.67s - loss: 448.14264 - batches: 354\nQuality on validation dataset (20.0%), validation examples = 2241\ntime to finish evaluation: 2.27s\nlabel\t tp\t fp\t fn\t prec\t rec\t f1\nB-LOC\t 1353\t 119\t 77\t 0.9191576\t 0.9461538\t 0.93246037\nI-ORG\t 659\t 123\t 105\t 0.842711\t 0.86256546\t 0.8525226\nI-MISC\t 167\t 29\t 75\t 0.8520408\t 0.69008267\t 0.762557\nI-LOC\t 173\t 23\t 56\t 0.88265306\t 0.75545853\t 0.8141176\nI-PER\t 925\t 24\t 19\t 0.9747102\t 0.9798729\t 0.9772847\nB-MISC\t 638\t 46\t 100\t 0.93274856\t 0.8644986\t 0.89732766\nB-ORG\t 1116\t 151\t 135\t 0.8808208\t 0.8920863\t 0.8864178\nB-PER\t 1308\t 53\t 59\t 0.961058\t 0.9568398\t 0.95894426\ntp: 6339 fp: 568 fn: 626 labels: 8\nMacro-average\t prec: 0.9057375, rec: 0.8684448, f1: 0.88669926\nMicro-average\t prec: 0.9177646, rec: 0.91012204, f1: 0.9139274\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%fs mkdirs dbfs:/models"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8d15410d-0c01-4c6c-bc5d-4aa5e1fc08df","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">res1: Boolean = true\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">res1: Boolean = true\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["ner_model.stages[1].write().overwrite().save('dbfs:/models/NER_glove_e2_b32')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ef0584a5-4658-4b2a-b64e-f3e325f43617","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sh cd /dbfs/models/ && pwd && ls -l"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c45fc02b-3e48-468c-9e27-2e63484f0b36","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">/dbfs/models\ntotal 8\ndrwxrwxrwx 2 root root 4096 Jan 17 18:51 NER_glove_e1_b32\ndrwxrwxrwx 2 root root 4096 Jan 17 18:51 NER_glove_e2_b32\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/dbfs/models\ntotal 8\ndrwxrwxrwx 2 root root 4096 Jan 17 18:51 NER_glove_e1_b32\ndrwxrwxrwx 2 root root 4096 Jan 17 18:51 NER_glove_e2_b32\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Load saved model"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"434fa8c1-7115-4674-8cd6-f50ca6c4a98e","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["document = DocumentAssembler()\\\n        .setInputCol(\"text\")\\\n        .setOutputCol(\"document\")\n\nsentence = SentenceDetector()\\\n        .setInputCols(['document'])\\\n        .setOutputCol('sentence')\n\ntoken = Tokenizer()\\\n        .setInputCols(['sentence'])\\\n        .setOutputCol('token')\n\nglove_embeddings = WordEmbeddingsModel.pretrained('glove_100d')\\\n        .setInputCols([\"document\", \"token\"])\\\n        .setOutputCol(\"embeddings\")\n  \n# load back and use in any pipeline\nloaded_ner_model = NerDLModel.load(\"dbfs:/models/NER_glove_e2_b32\")\\\n        .setInputCols([\"sentence\", \"token\", \"embeddings\"])\\\n        .setOutputCol(\"ner\")\n\nconverter = NerConverter()\\\n        .setInputCols([\"document\", \"token\", \"ner\"])\\\n        .setOutputCol(\"ner_span\")\n\nner_prediction_pipeline = Pipeline(stages = [\n        document,\n        sentence,\n        token,\n        glove_embeddings,\n        loaded_ner_model,\n        converter\n])"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6b48c3a2-b406-4917-8a9d-1c4ed0dee3bb","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">glove_100d download started this may take some time.\nApproximate size to download 145.3 MB\n\r[ | ]\r[OK!]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">glove_100d download started this may take some time.\nApproximate size to download 145.3 MB\n\r[ | ]\r[OK!]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["empty_data = spark.createDataFrame([['']]).toDF(\"text\")\n\nprediction_model = ner_prediction_pipeline.fit(empty_data)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"29d02a92-66ae-40ee-9c6c-45b9cc211e09","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["text = \"Peter Parker is a nice guy and lives in New York.\"\n\nsample_data = spark.createDataFrame([[text]]).toDF(\"text\")\n\nsample_data.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"bce25a29-c66b-42b0-9920-81fdf5e0d9af","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-------------------------------------------------+\n|text                                             |\n+-------------------------------------------------+\n|Peter Parker is a nice guy and lives in New York.|\n+-------------------------------------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------------------------------------------------+\ntext                                             |\n+-------------------------------------------------+\nPeter Parker is a nice guy and lives in New York.|\n+-------------------------------------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["preds = prediction_model.transform(sample_data)\n\npreds.select(F.explode(F.arrays_zip(preds.ner_span.result,preds.ner_span.metadata)).alias(\"entities\")) \\\n      .select(F.expr(\"entities['0']\").alias(\"chunk\"),\n              F.expr(\"entities['1'].entity\").alias(\"entity\")).show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7b749652-df0e-4fba-bd18-f351e8b021e9","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+------------+------+\n|chunk       |entity|\n+------------+------+\n|Peter Parker|PER   |\n|New York    |LOC   |\n+------------+------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------------+------+\nchunk       |entity|\n+------------+------+\nPeter Parker|PER   |\nNew York    |LOC   |\n+------------+------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Train a model with Graph Builder"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"612fcfa7-8f9d-45e2-bdaa-d7f666f71b9a","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["We will use `TFNerDLGraphBuilder` annotator to create a graph in the model training pipeline. This annotator inspects the data and creates the proper graph if a suitable version of TensorFlow (<= 2.7 ) is available. The graph is stored in the defined folder and loaded by the approach.\n\n**ATTENTION:** Do not forget to play with the parameters of this annotator, it may affect the model performance that you want to train."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d55e80c8-3930-4e14-882a-d3e2be4cb9e6","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%fs mkdirs dbfs:/ner_logs_custom_graph"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8630dc45-62ea-4a05-b227-bb1c9a8e2185","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">res2: Boolean = true\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">res2: Boolean = true\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%fs mkdirs dbfs:/custom_ner_graphs"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7aafd9c7-e9f2-4fd3-974f-c35046052acf","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">res3: Boolean = true\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">res3: Boolean = true\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["graph_folder = \"dbfs:/custom_ner_graphs\""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5b5bb7ad-85bd-44c9-bcb1-f51c2b287430","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["graph_builder = TFNerDLGraphBuilder()\\\n              .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n              .setLabelColumn(\"label\")\\\n              .setGraphFile(\"auto\")\\\n              .setGraphFolder(graph_folder)\\\n              .setHiddenUnitsNumber(20)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"fb7bbcd9-10fc-49b6-80c3-0471720c83e6","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["nerTagger = NerDLApproach()\\\n              .setInputCols([\"sentence\", \"token\", \"embeddings\"])\\\n              .setLabelColumn(\"label\")\\\n              .setOutputCol(\"ner\")\\\n              .setMaxEpochs(3)\\\n              .setLr(0.003)\\\n              .setBatchSize(32)\\\n              .setRandomSeed(0)\\\n              .setVerbose(1)\\\n              .setValidationSplit(0.2)\\\n              .setEvaluationLogExtended(True) \\\n              .setEnableOutputLogs(True)\\\n              .setIncludeConfidence(True)\\\n              .setGraphFolder(graph_folder)\\\n              .setOutputLogsPath('dbfs:/ner_logs_custom_graph') # if not set, logs will be written to ~/annotator_logs\n          #   .setEnableMemoryOptimizer(True) # if not set, logs will be written to ~/annotator_logs\n    \nner_pipeline = Pipeline(stages=[glove_embeddings,\n                                graph_builder,\n                                nerTagger])"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"bbc54ebb-458d-481c-a4af-da53af90565b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["ner_model = ner_pipeline.fit(training_data)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7907360c-dd49-4fea-9613-ea9c7a0358f1","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">/databricks/python/lib/python3.8/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.9.0 and strictly below 2.12.0 (nightly versions are not supported). \n The versions of TensorFlow you are currently using is 2.7.0 and is not supported. \nSome things might work, some things might not.\nIf you were to encounter a bug, do not file an issue.\nIf you want to make sure you&#39;re using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons&#39;s version. \nYou can find the compatibility matrix in TensorFlow Addon&#39;s readme:\nhttps://github.com/tensorflow/addons\n  warnings.warn(\nNer DL Graph Builder configuration:\nGraph folder: dbfs:/custom_ner_graphs\nGraph file name: auto\nBuild params: {&#39;ntags&#39;: 9, &#39;embeddings_dim&#39;: 100, &#39;nchars&#39;: 85, &#39;lstm_size&#39;: 20}\nWARNING:tensorflow:From /databricks/python/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\nInstructions for updating:\nnon-resource variables are not supported in the long term\nWARNING:tensorflow:From /databricks/python/lib/python3.8/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nCall initializer instance with the dtype argument instead of passing it to the constructor\nWARNING:tensorflow:From /databricks/python/lib/python3.8/site-packages/tensorflow/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nCall initializer instance with the dtype argument instead of passing it to the constructor\nWARNING:tensorflow:From /databricks/python/lib/python3.8/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nCall initializer instance with the dtype argument instead of passing it to the constructor\n/databricks/python/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1702: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n  warnings.warn(&#39;`layer.add_variable` is deprecated and &#39;\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/python/lib/python3.8/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.9.0 and strictly below 2.12.0 (nightly versions are not supported). \n The versions of TensorFlow you are currently using is 2.7.0 and is not supported. \nSome things might work, some things might not.\nIf you were to encounter a bug, do not file an issue.\nIf you want to make sure you&#39;re using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons&#39;s version. \nYou can find the compatibility matrix in TensorFlow Addon&#39;s readme:\nhttps://github.com/tensorflow/addons\n  warnings.warn(\nNer DL Graph Builder configuration:\nGraph folder: dbfs:/custom_ner_graphs\nGraph file name: auto\nBuild params: {&#39;ntags&#39;: 9, &#39;embeddings_dim&#39;: 100, &#39;nchars&#39;: 85, &#39;lstm_size&#39;: 20}\nWARNING:tensorflow:From /databricks/python/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\nInstructions for updating:\nnon-resource variables are not supported in the long term\nWARNING:tensorflow:From /databricks/python/lib/python3.8/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nCall initializer instance with the dtype argument instead of passing it to the constructor\nWARNING:tensorflow:From /databricks/python/lib/python3.8/site-packages/tensorflow/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nCall initializer instance with the dtype argument instead of passing it to the constructor\nWARNING:tensorflow:From /databricks/python/lib/python3.8/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nCall initializer instance with the dtype argument instead of passing it to the constructor\n/databricks/python/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1702: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n  warnings.warn(&#39;`layer.add_variable` is deprecated and &#39;\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sh cd /dbfs/ner_logs_custom_graph && pwd && ls -l"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f204749d-604d-4ae0-ab11-9c24695bdf23","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">/dbfs/ner_logs_custom_graph\ntotal 18\n-rwxrwxrwx 1 root root 2721 Jan 17 19:17 NerDLApproach_02af959c09e2.log\n-rwxrwxrwx 1 root root 2700 Jan 17 15:46 NerDLApproach_530714c05aac.log\n-rwxrwxrwx 1 root root 2720 Jan  8 18:01 NerDLApproach_7abfb04110b3.log\n-rwxrwxrwx 1 root root 2706 Jan 17 20:04 NerDLApproach_802ffe0a8566.log\n-rwxrwxrwx 1 root root 5429 Oct 10 17:23 NerDLApproach_d0f59843b5b5.log\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/dbfs/ner_logs_custom_graph\ntotal 18\n-rwxrwxrwx 1 root root 2721 Jan 17 19:17 NerDLApproach_02af959c09e2.log\n-rwxrwxrwx 1 root root 2700 Jan 17 15:46 NerDLApproach_530714c05aac.log\n-rwxrwxrwx 1 root root 2720 Jan  8 18:01 NerDLApproach_7abfb04110b3.log\n-rwxrwxrwx 1 root root 2706 Jan 17 20:04 NerDLApproach_802ffe0a8566.log\n-rwxrwxrwx 1 root root 5429 Oct 10 17:23 NerDLApproach_d0f59843b5b5.log\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sh head -n 45 /dbfs/ner_logs_custom_graph/NerDLApproach_*"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ef347ca5-314c-4e93-abc3-655aef9e26b0","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">==&gt; /dbfs/ner_logs_custom_graph/NerDLApproach_02af959c09e2.log &lt;==\nName of the selected graph: /dbfs/custom_ner_graphs/blstm_9_100_20_85.pb\nTraining started - total epochs: 3 - lr: 0.003 - batch size: 32 - labels: 9 - chars: 84 - training examples: 11209\n\n\nEpoch 1/3 started, lr: 0.003, dataset size: 11209\n\n\nEpoch 1/3 - 15.34s - loss: 1632.9963 - batches: 353\nQuality on validation dataset (20.0%), validation examples = 2241\ntime to finish evaluation: 1.53s\nlabel\t tp\t fp\t fn\t prec\t rec\t f1\nB-LOC\t 1307\t 292\t 126\t 0.81738585\t 0.9120726\t 0.8621372\nI-ORG\t 538\t 127\t 231\t 0.80902255\t 0.6996099\t 0.7503487\nI-MISC\t 69\t 41\t 146\t 0.6272727\t 0.32093024\t 0.42461538\nI-LOC\t 150\t 106\t 73\t 0.5859375\t 0.67264575\t 0.6263048\nI-PER\t 901\t 99\t 23\t 0.901\t 0.9751082\t 0.9365905\nB-MISC\t 516\t 139\t 199\t 0.78778625\t 0.7216783\t 0.7532847\nB-ORG\t 926\t 207\t 372\t 0.8172992\t 0.71340525\t 0.76182634\nB-PER\t 1284\t 156\t 89\t 0.89166665\t 0.93517846\t 0.9129043\ntp: 5691 fp: 1167 fn: 1259 labels: 8\nMacro-average\t prec: 0.77967143, rec: 0.74382854, f1: 0.76132834\nMicro-average\t prec: 0.82983375, rec: 0.8188489, f1: 0.82430476\n\n\nEpoch 2/3 started, lr: 0.0029850747, dataset size: 11209\n\n\nEpoch 2/3 - 13.65s - loss: 703.6633 - batches: 353\nQuality on validation dataset (20.0%), validation examples = 2241\ntime to finish evaluation: 1.15s\nlabel\t tp\t fp\t fn\t prec\t rec\t f1\nB-LOC\t 1316\t 175\t 117\t 0.8826291\t 0.9183531\t 0.90013677\nI-ORG\t 587\t 126\t 182\t 0.8232819\t 0.76332897\t 0.79217273\nI-MISC\t 119\t 68\t 96\t 0.6363636\t 0.5534884\t 0.5920398\nI-LOC\t 172\t 64\t 51\t 0.7288136\t 0.77130044\t 0.7494554\nI-PER\t 901\t 50\t 23\t 0.94742376\t 0.9751082\t 0.96106666\nB-MISC\t 575\t 124\t 140\t 0.8226037\t 0.8041958\t 0.8132956\nB-ORG\t 1033\t 204\t 265\t 0.83508486\t 0.7958397\t 0.8149901\nB-PER\t 1300\t 110\t 73\t 0.9219858\t 0.94683176\t 0.9342436\ntp: 6003 fp: 921 fn: 947 labels: 8\nMacro-average\t prec: 0.8247733, rec: 0.8160558, f1: 0.82039136\nMicro-average\t prec: 0.8669844, rec: 0.863741, f1: 0.86535966\n\n\nEpoch 3/3 started, lr: 0.0029702971, dataset size: 11209\n\n==&gt; /dbfs/ner_logs_custom_graph/NerDLApproach_530714c05aac.log &lt;==\nName of the selected graph: /dbfs/custom_ner_graphs/blstm_9_100_20_85.pb\nTraining started - total epochs: 3 - lr: 0.003 - batch size: 32 - labels: 9 - chars: 84 - training examples: 11198\n\n\nEpoch 1/3 started, lr: 0.003, dataset size: 11198\n\n\nEpoch 1/3 - 19.03s - loss: 1960.0465 - batches: 352\nQuality on validation dataset (20.0%), validation examples = 2239\ntime to finish evaluation: 2.01s\nlabel\t tp\t fp\t fn\t prec\t rec\t f1\nB-LOC\t 1211\t 218\t 229\t 0.8474458\t 0.84097224\t 0.8441966\nI-ORG\t 491\t 200\t 216\t 0.7105644\t 0.69448376\t 0.70243204\nI-MISC\t 72\t 10\t 145\t 0.8780488\t 0.33179724\t 0.48160535\nI-LOC\t 81\t 5\t 169\t 0.94186044\t 0.324\t 0.48214287\nI-PER\t 879\t 84\t 31\t 0.9127726\t 0.96593404\t 0.93860114\nB-MISC\t 487\t 62\t 245\t 0.8870674\t 0.66530055\t 0.76034343\nB-ORG\t 900\t 324\t 305\t 0.7352941\t 0.746888\t 0.7410458\nB-PER\t 1288\t 130\t 104\t 0.90832156\t 0.92528737\t 0.916726\ntp: 5409 fp: 1033 fn: 1444 labels: 8\nMacro-average\t prec: 0.85267186, rec: 0.6868329, f1: 0.76082015\nMicro-average\t prec: 0.8396461, rec: 0.78928936, f1: 0.81368935\n\n\nEpoch 2/3 started, lr: 0.0029850747, dataset size: 11198\n\n\nEpoch 2/3 - 17.45s - loss: 738.6029 - batches: 352\nQuality on validation dataset (20.0%), validation examples = 2239\ntime to finish evaluation: 1.90s\nlabel\t tp\t fp\t fn\t prec\t rec\t f1\nB-LOC\t 1305\t 152\t 135\t 0.8956761\t 0.90625\t 0.90093195\nI-ORG\t 502\t 114\t 205\t 0.8149351\t 0.7100424\t 0.7588814\nI-MISC\t 119\t 55\t 98\t 0.68390805\t 0.5483871\t 0.6086956\nI-LOC\t 168\t 29\t 82\t 0.8527919\t 0.672\t 0.7516778\nI-PER\t 885\t 66\t 25\t 0.9305994\t 0.97252744\t 0.9511016\nB-MISC\t 584\t 178\t 148\t 0.7664042\t 0.7978142\t 0.78179383\nB-ORG\t 908\t 136\t 297\t 0.8697318\t 0.753527\t 0.80746996\nB-PER\t 1311\t 108\t 81\t 0.92389005\t 0.94181037\t 0.9327641\ntp: 5782 fp: 838 fn: 1071 labels: 8\nMacro-average\t prec: 0.84224206, rec: 0.7877948, f1: 0.81410915\nMicro-average\t prec: 0.8734139, rec: 0.84371805, f1: 0.8583092\n\n\nEpoch 3/3 started, lr: 0.0029702971, dataset size: 11198\n\n==&gt; /dbfs/ner_logs_custom_graph/NerDLApproach_7abfb04110b3.log &lt;==\nName of the selected graph: /dbfs/custom_ner_graphs/blstm_9_100_20_85.pb\nTraining started - total epochs: 3 - lr: 0.003 - batch size: 32 - labels: 9 - chars: 84 - training examples: 11207\n\n\nEpoch 1/3 started, lr: 0.003, dataset size: 11207\n\n\nEpoch 1/3 - 14.66s - loss: 1894.7733 - batches: 353\nQuality on validation dataset (20.0%), validation examples = 2241\ntime to finish evaluation: 1.46s\nlabel\t tp\t fp\t fn\t prec\t rec\t f1\nB-LOC\t 1286\t 201\t 213\t 0.8648285\t 0.85790527\t 0.86135304\nI-ORG\t 503\t 176\t 224\t 0.7407953\t 0.69188446\t 0.71550494\nI-MISC\t 65\t 12\t 192\t 0.84415585\t 0.25291827\t 0.38922152\nI-LOC\t 142\t 31\t 119\t 0.82080925\t 0.5440613\t 0.6543779\nI-PER\t 883\t 76\t 40\t 0.9207508\t 0.9566631\t 0.93836343\nB-MISC\t 522\t 139\t 229\t 0.78971255\t 0.69507325\t 0.7393768\nB-ORG\t 891\t 257\t 367\t 0.7761324\t 0.7082671\t 0.7406483\nB-PER\t 1272\t 192\t 84\t 0.86885244\t 0.9380531\t 0.9021276\ntp: 5564 fp: 1084 fn: 1468 labels: 8\nMacro-average\t prec: 0.82825464, rec: 0.70560324, f1: 0.7620252\nMicro-average\t prec: 0.83694345, rec: 0.79124004, f1: 0.8134503\n\n\nEpoch 2/3 started, lr: 0.0029850747, dataset size: 11207\n\n\nEpoch 2/3 - 13.39s - loss: 752.4661 - batches: 353\nQuality on validation dataset (20.0%), validation examples = 2241\ntime to finish evaluation: 1.40s\nlabel\t tp\t fp\t fn\t prec\t rec\t f1\nB-LOC\t 1338\t 124\t 161\t 0.9151847\t 0.89259505\t 0.9037487\nI-ORG\t 574\t 243\t 153\t 0.7025704\t 0.7895461\t 0.74352336\nI-MISC\t 137\t 69\t 120\t 0.66504854\t 0.5330739\t 0.5917926\nI-LOC\t 173\t 23\t 88\t 0.88265306\t 0.66283524\t 0.75711155\nI-PER\t 894\t 49\t 29\t 0.94803816\t 0.9685807\t 0.9581994\nB-MISC\t 608\t 122\t 143\t 0.83287674\t 0.80958724\t 0.82106686\nB-ORG\t 1041\t 286\t 217\t 0.7844763\t 0.827504\t 0.80541587\nB-PER\t 1271\t 100\t 85\t 0.92706054\t 0.93731564\t 0.9321599\ntp: 6036 fp: 1016 fn: 996 labels: 8\nMacro-average\t prec: 0.83223855, rec: 0.80262977, f1: 0.817166\nMicro-average\t prec: 0.8559274, rec: 0.8583618, f1: 0.85714287\n\n\nEpoch 3/3 started, lr: 0.0029702971, dataset size: 11207\n\n==&gt; /dbfs/ner_logs_custom_graph/NerDLApproach_802ffe0a8566.log &lt;==\nName of the selected graph: /dbfs/custom_ner_graphs/blstm_9_100_20_85.pb\nTraining started - total epochs: 3 - lr: 0.003 - batch size: 32 - labels: 9 - chars: 83 - training examples: 11182\n\n\nEpoch 1/3 started, lr: 0.003, dataset size: 11182\n\n\nEpoch 1/3 - 15.44s - loss: 1952.1289 - batches: 352\nQuality on validation dataset (20.0%), validation examples = 2236\ntime to finish evaluation: 1.52s\nlabel\t tp\t fp\t fn\t prec\t rec\t f1\nB-LOC\t 1148\t 155\t 267\t 0.88104373\t 0.81130743\t 0.8447388\nI-ORG\t 576\t 257\t 196\t 0.6914766\t 0.746114\t 0.717757\nI-MISC\t 47\t 19\t 161\t 0.7121212\t 0.22596154\t 0.34306568\nI-LOC\t 90\t 26\t 139\t 0.7758621\t 0.3930131\t 0.5217391\nI-PER\t 963\t 82\t 44\t 0.9215311\t 0.95630586\t 0.9385965\nB-MISC\t 456\t 117\t 200\t 0.79581153\t 0.69512194\t 0.74206674\nB-ORG\t 1042\t 447\t 250\t 0.6997985\t 0.80650157\t 0.74937075\nB-PER\t 1321\t 163\t 81\t 0.89016175\t 0.9422254\t 0.9154539\ntp: 5643 fp: 1266 fn: 1338 labels: 8\nMacro-average\t prec: 0.7959758, rec: 0.69706887, f1: 0.7432464\nMicro-average\t prec: 0.8167607, rec: 0.8083369, f1: 0.81252694\n\n\nEpoch 2/3 started, lr: 0.0029850747, dataset size: 11182\n\n\nEpoch 2/3 - 14.02s - loss: 765.2538 - batches: 352\nQuality on validation dataset (20.0%), validation examples = 2236\ntime to finish evaluation: 1.18s\nlabel\t tp\t fp\t fn\t prec\t rec\t f1\nB-LOC\t 1264\t 161\t 151\t 0.88701755\t 0.8932862\t 0.8901409\nI-ORG\t 613\t 187\t 159\t 0.76625\t 0.79404145\t 0.77989817\nI-MISC\t 96\t 28\t 112\t 0.7741935\t 0.46153846\t 0.5783133\nI-LOC\t 156\t 45\t 73\t 0.7761194\t 0.68122274\t 0.7255814\nI-PER\t 990\t 48\t 17\t 0.9537572\t 0.9831182\t 0.96821517\nB-MISC\t 498\t 78\t 158\t 0.8645833\t 0.75914633\t 0.8084415\nB-ORG\t 1114\t 314\t 178\t 0.780112\t 0.8622291\t 0.81911767\nB-PER\t 1317\t 81\t 85\t 0.9420601\t 0.9393723\t 0.94071424\ntp: 6048 fp: 942 fn: 933 labels: 8\nMacro-average\t prec: 0.8430117, rec: 0.79674435, f1: 0.8192253\nMicro-average\t prec: 0.86523604, rec: 0.86635154, f1: 0.8657934\n\n\nEpoch 3/3 started, lr: 0.0029702971, dataset size: 11182\n\n==&gt; /dbfs/ner_logs_custom_graph/NerDLApproach_d0f59843b5b5.log &lt;==\nName of the selected graph: /dbfs/custom_ner_graphs/blstm_9_100_20_85.pb\nTraining started - total epochs: 3 - lr: 0.003 - batch size: 32 - labels: 9 - chars: 83 - training examples: 11215\n\n\nEpoch 1/3 started, lr: 0.003, dataset size: 11215\n\n\nEpoch 1/3 - 15.81s - loss: 1863.2142 - batches: 352\nQuality on validation dataset (20.0%), validation examples = 2243\ntime to finish evaluation: 1.57s\nlabel\t tp\t fp\t fn\t prec\t rec\t f1\nB-LOC\t 1227\t 227\t 178\t 0.8438789\t 0.8733096\t 0.858342\nI-ORG\t 574\t 223\t 172\t 0.7202008\t 0.769437\t 0.7440052\nI-MISC\t 61\t 6\t 207\t 0.9104478\t 0.22761194\t 0.3641791\nI-LOC\t 87\t 20\t 134\t 0.8130841\t 0.39366516\t 0.53048784\nI-PER\t 876\t 67\t 35\t 0.92895013\t 0.9615807\t 0.94498384\nB-MISC\t 488\t 104\t 215\t 0.8243243\t 0.69416785\t 0.7536679\nB-ORG\t 1020\t 306\t 246\t 0.7692308\t 0.8056872\t 0.787037\nB-PER\t 1260\t 148\t 78\t 0.8948864\t 0.94170403\t 0.9176985\ntp: 5593 fp: 1101 fn: 1265 labels: 8\nMacro-average\t prec: 0.8381254, rec: 0.7083955, f1: 0.7678192\nMicro-average\t prec: 0.8355243, rec: 0.8155439, f1: 0.82541317\n\n\nEpoch 2/3 started, lr: 0.0029850747, dataset size: 11215\n\n\nEpoch 2/3 - 16.13s - loss: 740.24817 - batches: 352\nQuality on validation dataset (20.0%), validation examples = 2243\ntime to finish evaluation: 1.20s\nlabel\t tp\t fp\t fn\t prec\t rec\t f1\nB-LOC\t 1279\t 101\t 126\t 0.9268116\t 0.9103203\t 0.91849196\nI-ORG\t 581\t 185\t 165\t 0.7584856\t 0.7788204\t 0.76851845\nI-MISC\t 166\t 80\t 102\t 0.67479676\t 0.619403\t 0.64591444\nI-LOC\t 149\t 28\t 72\t 0.8418079\t 0.67420816\t 0.7487438\nI-PER\t 885\t 37\t 26\t 0.95986986\t 0.9714599\t 0.9656301\nB-MISC\t 567\t 76\t 136\t 0.88180405\t 0.8065434\t 0.8424963\nB-ORG\t 1098\t 250\t 168\t 0.8145401\t 0.8672986\t 0.8400918\nB-PER\t 1253\t 79\t 85\t 0.9406907\t 0.93647236\t 0.9385768\ntp: 5978 fp: 836 fn: 880 labels: 8\nMacro-average\t prec: 0.8498508, rec: 0.82056576, f1: 0.8349515\nMicro-average\t prec: 0.8773114, rec: 0.8716827, f1: 0.874488\n\n\nEpoch 3/3 started, lr: 0.0029702971, dataset size: 11215\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">==&gt; /dbfs/ner_logs_custom_graph/NerDLApproach_02af959c09e2.log &lt;==\nName of the selected graph: /dbfs/custom_ner_graphs/blstm_9_100_20_85.pb\nTraining started - total epochs: 3 - lr: 0.003 - batch size: 32 - labels: 9 - chars: 84 - training examples: 11209\n\n\nEpoch 1/3 started, lr: 0.003, dataset size: 11209\n\n\nEpoch 1/3 - 15.34s - loss: 1632.9963 - batches: 353\nQuality on validation dataset (20.0%), validation examples = 2241\ntime to finish evaluation: 1.53s\nlabel\t tp\t fp\t fn\t prec\t rec\t f1\nB-LOC\t 1307\t 292\t 126\t 0.81738585\t 0.9120726\t 0.8621372\nI-ORG\t 538\t 127\t 231\t 0.80902255\t 0.6996099\t 0.7503487\nI-MISC\t 69\t 41\t 146\t 0.6272727\t 0.32093024\t 0.42461538\nI-LOC\t 150\t 106\t 73\t 0.5859375\t 0.67264575\t 0.6263048\nI-PER\t 901\t 99\t 23\t 0.901\t 0.9751082\t 0.9365905\nB-MISC\t 516\t 139\t 199\t 0.78778625\t 0.7216783\t 0.7532847\nB-ORG\t 926\t 207\t 372\t 0.8172992\t 0.71340525\t 0.76182634\nB-PER\t 1284\t 156\t 89\t 0.89166665\t 0.93517846\t 0.9129043\ntp: 5691 fp: 1167 fn: 1259 labels: 8\nMacro-average\t prec: 0.77967143, rec: 0.74382854, f1: 0.76132834\nMicro-average\t prec: 0.82983375, rec: 0.8188489, f1: 0.82430476\n\n\nEpoch 2/3 started, lr: 0.0029850747, dataset size: 11209\n\n\nEpoch 2/3 - 13.65s - loss: 703.6633 - batches: 353\nQuality on validation dataset (20.0%), validation examples = 2241\ntime to finish evaluation: 1.15s\nlabel\t tp\t fp\t fn\t prec\t rec\t f1\nB-LOC\t 1316\t 175\t 117\t 0.8826291\t 0.9183531\t 0.90013677\nI-ORG\t 587\t 126\t 182\t 0.8232819\t 0.76332897\t 0.79217273\nI-MISC\t 119\t 68\t 96\t 0.6363636\t 0.5534884\t 0.5920398\nI-LOC\t 172\t 64\t 51\t 0.7288136\t 0.77130044\t 0.7494554\nI-PER\t 901\t 50\t 23\t 0.94742376\t 0.9751082\t 0.96106666\nB-MISC\t 575\t 124\t 140\t 0.8226037\t 0.8041958\t 0.8132956\nB-ORG\t 1033\t 204\t 265\t 0.83508486\t 0.7958397\t 0.8149901\nB-PER\t 1300\t 110\t 73\t 0.9219858\t 0.94683176\t 0.9342436\ntp: 6003 fp: 921 fn: 947 labels: 8\nMacro-average\t prec: 0.8247733, rec: 0.8160558, f1: 0.82039136\nMicro-average\t prec: 0.8669844, rec: 0.863741, f1: 0.86535966\n\n\nEpoch 3/3 started, lr: 0.0029702971, dataset size: 11209\n\n==&gt; /dbfs/ner_logs_custom_graph/NerDLApproach_530714c05aac.log &lt;==\nName of the selected graph: /dbfs/custom_ner_graphs/blstm_9_100_20_85.pb\nTraining started - total epochs: 3 - lr: 0.003 - batch size: 32 - labels: 9 - chars: 84 - training examples: 11198\n\n\nEpoch 1/3 started, lr: 0.003, dataset size: 11198\n\n\nEpoch 1/3 - 19.03s - loss: 1960.0465 - batches: 352\nQuality on validation dataset (20.0%), validation examples = 2239\ntime to finish evaluation: 2.01s\nlabel\t tp\t fp\t fn\t prec\t rec\t f1\nB-LOC\t 1211\t 218\t 229\t 0.8474458\t 0.84097224\t 0.8441966\nI-ORG\t 491\t 200\t 216\t 0.7105644\t 0.69448376\t 0.70243204\nI-MISC\t 72\t 10\t 145\t 0.8780488\t 0.33179724\t 0.48160535\nI-LOC\t 81\t 5\t 169\t 0.94186044\t 0.324\t 0.48214287\nI-PER\t 879\t 84\t 31\t 0.9127726\t 0.96593404\t 0.93860114\nB-MISC\t 487\t 62\t 245\t 0.8870674\t 0.66530055\t 0.76034343\nB-ORG\t 900\t 324\t 305\t 0.7352941\t 0.746888\t 0.7410458\nB-PER\t 1288\t 130\t 104\t 0.90832156\t 0.92528737\t 0.916726\ntp: 5409 fp: 1033 fn: 1444 labels: 8\nMacro-average\t prec: 0.85267186, rec: 0.6868329, f1: 0.76082015\nMicro-average\t prec: 0.8396461, rec: 0.78928936, f1: 0.81368935\n\n\nEpoch 2/3 started, lr: 0.0029850747, dataset size: 11198\n\n\nEpoch 2/3 - 17.45s - loss: 738.6029 - batches: 352\nQuality on validation dataset (20.0%), validation examples = 2239\ntime to finish evaluation: 1.90s\nlabel\t tp\t fp\t fn\t prec\t rec\t f1\nB-LOC\t 1305\t 152\t 135\t 0.8956761\t 0.90625\t 0.90093195\nI-ORG\t 502\t 114\t 205\t 0.8149351\t 0.7100424\t 0.7588814\nI-MISC\t 119\t 55\t 98\t 0.68390805\t 0.5483871\t 0.6086956\nI-LOC\t 168\t 29\t 82\t 0.8527919\t 0.672\t 0.7516778\nI-PER\t 885\t 66\t 25\t 0.9305994\t 0.97252744\t 0.9511016\nB-MISC\t 584\t 178\t 148\t 0.7664042\t 0.7978142\t 0.78179383\nB-ORG\t 908\t 136\t 297\t 0.8697318\t 0.753527\t 0.80746996\nB-PER\t 1311\t 108\t 81\t 0.92389005\t 0.94181037\t 0.9327641\ntp: 5782 fp: 838 fn: 1071 labels: 8\nMacro-average\t prec: 0.84224206, rec: 0.7877948, f1: 0.81410915\nMicro-average\t prec: 0.8734139, rec: 0.84371805, f1: 0.8583092\n\n\nEpoch 3/3 started, lr: 0.0029702971, dataset size: 11198\n\n==&gt; /dbfs/ner_logs_custom_graph/NerDLApproach_7abfb04110b3.log &lt;==\nName of the selected graph: /dbfs/custom_ner_graphs/blstm_9_100_20_85.pb\nTraining started - total epochs: 3 - lr: 0.003 - batch size: 32 - labels: 9 - chars: 84 - training examples: 11207\n\n\nEpoch 1/3 started, lr: 0.003, dataset size: 11207\n\n\nEpoch 1/3 - 14.66s - loss: 1894.7733 - batches: 353\nQuality on validation dataset (20.0%), validation examples = 2241\ntime to finish evaluation: 1.46s\nlabel\t tp\t fp\t fn\t prec\t rec\t f1\nB-LOC\t 1286\t 201\t 213\t 0.8648285\t 0.85790527\t 0.86135304\nI-ORG\t 503\t 176\t 224\t 0.7407953\t 0.69188446\t 0.71550494\nI-MISC\t 65\t 12\t 192\t 0.84415585\t 0.25291827\t 0.38922152\nI-LOC\t 142\t 31\t 119\t 0.82080925\t 0.5440613\t 0.6543779\nI-PER\t 883\t 76\t 40\t 0.9207508\t 0.9566631\t 0.93836343\nB-MISC\t 522\t 139\t 229\t 0.78971255\t 0.69507325\t 0.7393768\nB-ORG\t 891\t 257\t 367\t 0.7761324\t 0.7082671\t 0.7406483\nB-PER\t 1272\t 192\t 84\t 0.86885244\t 0.9380531\t 0.9021276\ntp: 5564 fp: 1084 fn: 1468 labels: 8\nMacro-average\t prec: 0.82825464, rec: 0.70560324, f1: 0.7620252\nMicro-average\t prec: 0.83694345, rec: 0.79124004, f1: 0.8134503\n\n\nEpoch 2/3 started, lr: 0.0029850747, dataset size: 11207\n\n\nEpoch 2/3 - 13.39s - loss: 752.4661 - batches: 353\nQuality on validation dataset (20.0%), validation examples = 2241\ntime to finish evaluation: 1.40s\nlabel\t tp\t fp\t fn\t prec\t rec\t f1\nB-LOC\t 1338\t 124\t 161\t 0.9151847\t 0.89259505\t 0.9037487\nI-ORG\t 574\t 243\t 153\t 0.7025704\t 0.7895461\t 0.74352336\nI-MISC\t 137\t 69\t 120\t 0.66504854\t 0.5330739\t 0.5917926\nI-LOC\t 173\t 23\t 88\t 0.88265306\t 0.66283524\t 0.75711155\nI-PER\t 894\t 49\t 29\t 0.94803816\t 0.9685807\t 0.9581994\nB-MISC\t 608\t 122\t 143\t 0.83287674\t 0.80958724\t 0.82106686\nB-ORG\t 1041\t 286\t 217\t 0.7844763\t 0.827504\t 0.80541587\nB-PER\t 1271\t 100\t 85\t 0.92706054\t 0.93731564\t 0.9321599\ntp: 6036 fp: 1016 fn: 996 labels: 8\nMacro-average\t prec: 0.83223855, rec: 0.80262977, f1: 0.817166\nMicro-average\t prec: 0.8559274, rec: 0.8583618, f1: 0.85714287\n\n\nEpoch 3/3 started, lr: 0.0029702971, dataset size: 11207\n\n==&gt; /dbfs/ner_logs_custom_graph/NerDLApproach_802ffe0a8566.log &lt;==\nName of the selected graph: /dbfs/custom_ner_graphs/blstm_9_100_20_85.pb\nTraining started - total epochs: 3 - lr: 0.003 - batch size: 32 - labels: 9 - chars: 83 - training examples: 11182\n\n\nEpoch 1/3 started, lr: 0.003, dataset size: 11182\n\n\nEpoch 1/3 - 15.44s - loss: 1952.1289 - batches: 352\nQuality on validation dataset (20.0%), validation examples = 2236\ntime to finish evaluation: 1.52s\nlabel\t tp\t fp\t fn\t prec\t rec\t f1\nB-LOC\t 1148\t 155\t 267\t 0.88104373\t 0.81130743\t 0.8447388\nI-ORG\t 576\t 257\t 196\t 0.6914766\t 0.746114\t 0.717757\nI-MISC\t 47\t 19\t 161\t 0.7121212\t 0.22596154\t 0.34306568\nI-LOC\t 90\t 26\t 139\t 0.7758621\t 0.3930131\t 0.5217391\nI-PER\t 963\t 82\t 44\t 0.9215311\t 0.95630586\t 0.9385965\nB-MISC\t 456\t 117\t 200\t 0.79581153\t 0.69512194\t 0.74206674\nB-ORG\t 1042\t 447\t 250\t 0.6997985\t 0.80650157\t 0.74937075\nB-PER\t 1321\t 163\t 81\t 0.89016175\t 0.9422254\t 0.9154539\ntp: 5643 fp: 1266 fn: 1338 labels: 8\nMacro-average\t prec: 0.7959758, rec: 0.69706887, f1: 0.7432464\nMicro-average\t prec: 0.8167607, rec: 0.8083369, f1: 0.81252694\n\n\nEpoch 2/3 started, lr: 0.0029850747, dataset size: 11182\n\n\nEpoch 2/3 - 14.02s - loss: 765.2538 - batches: 352\nQuality on validation dataset (20.0%), validation examples = 2236\ntime to finish evaluation: 1.18s\nlabel\t tp\t fp\t fn\t prec\t rec\t f1\nB-LOC\t 1264\t 161\t 151\t 0.88701755\t 0.8932862\t 0.8901409\nI-ORG\t 613\t 187\t 159\t 0.76625\t 0.79404145\t 0.77989817\nI-MISC\t 96\t 28\t 112\t 0.7741935\t 0.46153846\t 0.5783133\nI-LOC\t 156\t 45\t 73\t 0.7761194\t 0.68122274\t 0.7255814\nI-PER\t 990\t 48\t 17\t 0.9537572\t 0.9831182\t 0.96821517\nB-MISC\t 498\t 78\t 158\t 0.8645833\t 0.75914633\t 0.8084415\nB-ORG\t 1114\t 314\t 178\t 0.780112\t 0.8622291\t 0.81911767\nB-PER\t 1317\t 81\t 85\t 0.9420601\t 0.9393723\t 0.94071424\ntp: 6048 fp: 942 fn: 933 labels: 8\nMacro-average\t prec: 0.8430117, rec: 0.79674435, f1: 0.8192253\nMicro-average\t prec: 0.86523604, rec: 0.86635154, f1: 0.8657934\n\n\nEpoch 3/3 started, lr: 0.0029702971, dataset size: 11182\n\n==&gt; /dbfs/ner_logs_custom_graph/NerDLApproach_d0f59843b5b5.log &lt;==\nName of the selected graph: /dbfs/custom_ner_graphs/blstm_9_100_20_85.pb\nTraining started - total epochs: 3 - lr: 0.003 - batch size: 32 - labels: 9 - chars: 83 - training examples: 11215\n\n\nEpoch 1/3 started, lr: 0.003, dataset size: 11215\n\n\nEpoch 1/3 - 15.81s - loss: 1863.2142 - batches: 352\nQuality on validation dataset (20.0%), validation examples = 2243\ntime to finish evaluation: 1.57s\nlabel\t tp\t fp\t fn\t prec\t rec\t f1\nB-LOC\t 1227\t 227\t 178\t 0.8438789\t 0.8733096\t 0.858342\nI-ORG\t 574\t 223\t 172\t 0.7202008\t 0.769437\t 0.7440052\nI-MISC\t 61\t 6\t 207\t 0.9104478\t 0.22761194\t 0.3641791\nI-LOC\t 87\t 20\t 134\t 0.8130841\t 0.39366516\t 0.53048784\nI-PER\t 876\t 67\t 35\t 0.92895013\t 0.9615807\t 0.94498384\nB-MISC\t 488\t 104\t 215\t 0.8243243\t 0.69416785\t 0.7536679\nB-ORG\t 1020\t 306\t 246\t 0.7692308\t 0.8056872\t 0.787037\nB-PER\t 1260\t 148\t 78\t 0.8948864\t 0.94170403\t 0.9176985\ntp: 5593 fp: 1101 fn: 1265 labels: 8\nMacro-average\t prec: 0.8381254, rec: 0.7083955, f1: 0.7678192\nMicro-average\t prec: 0.8355243, rec: 0.8155439, f1: 0.82541317\n\n\nEpoch 2/3 started, lr: 0.0029850747, dataset size: 11215\n\n\nEpoch 2/3 - 16.13s - loss: 740.24817 - batches: 352\nQuality on validation dataset (20.0%), validation examples = 2243\ntime to finish evaluation: 1.20s\nlabel\t tp\t fp\t fn\t prec\t rec\t f1\nB-LOC\t 1279\t 101\t 126\t 0.9268116\t 0.9103203\t 0.91849196\nI-ORG\t 581\t 185\t 165\t 0.7584856\t 0.7788204\t 0.76851845\nI-MISC\t 166\t 80\t 102\t 0.67479676\t 0.619403\t 0.64591444\nI-LOC\t 149\t 28\t 72\t 0.8418079\t 0.67420816\t 0.7487438\nI-PER\t 885\t 37\t 26\t 0.95986986\t 0.9714599\t 0.9656301\nB-MISC\t 567\t 76\t 136\t 0.88180405\t 0.8065434\t 0.8424963\nB-ORG\t 1098\t 250\t 168\t 0.8145401\t 0.8672986\t 0.8400918\nB-PER\t 1253\t 79\t 85\t 0.9406907\t 0.93647236\t 0.9385768\ntp: 5978 fp: 836 fn: 880 labels: 8\nMacro-average\t prec: 0.8498508, rec: 0.82056576, f1: 0.8349515\nMicro-average\t prec: 0.8773114, rec: 0.8716827, f1: 0.874488\n\n\nEpoch 3/3 started, lr: 0.0029702971, dataset size: 11215\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Text Classification\n\nfor a detailed notebook, see https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/5.Text_Classification_with_ClassifierDL.ipynb"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d48cd6cd-76e4-437f-935c-c26c728611f3","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["! wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/data/news_category_test.csv\n  \ndbutils.fs.cp(\"file:/databricks/driver/news_category_test.csv\", \"dbfs:/\") "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"11a1cd58-680e-4611-bf39-dda0d4fe6499","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[71]: True</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[71]: True</div>"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import col\n\ntrainDataset = spark.read \\\n      .option(\"header\", True) \\\n      .csv(\"/news_category_train.csv\")\n\ntrainDataset.groupBy(\"category\") \\\n    .count() \\\n    .orderBy(col(\"count\").desc()) \\\n    .show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9788f4af-d1bf-40b0-ba4b-2bc37dd56740","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+--------+-----+\n|category|count|\n+--------+-----+\n|   World|30000|\n|Sci/Tech|30000|\n|  Sports|30000|\n|Business|30000|\n+--------+-----+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+-----+\ncategory|count|\n+--------+-----+\n   World|30000|\nSci/Tech|30000|\n  Sports|30000|\nBusiness|30000|\n+--------+-----+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["testDataset = spark.read \\\n      .option(\"header\", True) \\\n      .csv(\"/news_category_test.csv\")\n\n\ntestDataset.groupBy(\"category\") \\\n    .count() \\\n    .orderBy(col(\"count\").desc()) \\\n    .show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1aeff354-d681-4e07-9ae5-4f6acfba0d7c","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+--------+-----+\n|category|count|\n+--------+-----+\n|   World| 1900|\n|Sci/Tech| 1900|\n|  Sports| 1900|\n|Business| 1900|\n+--------+-----+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+-----+\ncategory|count|\n+--------+-----+\n   World| 1900|\nSci/Tech| 1900|\n  Sports| 1900|\nBusiness| 1900|\n+--------+-----+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%fs mkdirs dbfs:/clf_dl_logs"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1ced0b20-0f14-4281-85ee-b2e2adb19b90","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">res4: Boolean = true\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">res4: Boolean = true\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# actual content is inside description column\ndocument = DocumentAssembler()\\\n    .setInputCol(\"description\")\\\n    .setOutputCol(\"document\")\n    \n# we can also use sentece detector here if we want to train on and get predictions for each sentence\n\nuse_embeddings = UniversalSentenceEncoder.pretrained('tfhub_use')\\\n    .setInputCols([\"document\"])\\\n    .setOutputCol(\"sentence_embeddings\")\n\n# the classes/labels/categories are in category column\nclasssifierdl = ClassifierDLApproach()\\\n    .setInputCols([\"sentence_embeddings\"])\\\n    .setOutputCol(\"class\")\\\n    .setLabelColumn(\"category\")\\\n    .setMaxEpochs(5)\\\n    .setBatchSize(8)\\\n    .setLr(0.001)\\\n    .setEnableOutputLogs(True)\\\n    .setOutputLogsPath('dbfs:/clf_dl_logs') \n\nuse_clf_pipeline = Pipeline(\n    stages = [\n        document,\n        use_embeddings,\n        classsifierdl\n    ])"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"aa8089e2-5ead-4d4d-9712-57d1d655a77e","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">tfhub_use download started this may take some time.\nApproximate size to download 923.7 MB\n\r[ | ]\r[OK!]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">tfhub_use download started this may take some time.\nApproximate size to download 923.7 MB\n\r[ | ]\r[OK!]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# remove the existing logs\n\n! rm -r /dbfs/clf_dl_logs/*"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c6c73b72-2527-495a-a3a2-2fa97346faad","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["use_pipelineModel = use_clf_pipeline.fit(trainDataset)\n# 5 epochs takes around 3 min"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b3d40e77-e4c6-42cd-8612-49ed315be79d","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sh cd /dbfs/clf_dl_logs/ && ls -lt"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e6433499-ab62-465f-ab25-e785a1d31581","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">total 1\n-rwxrwxrwx 1 root root 460 Jan 17 20:08 ClassifierDLApproach_1eb3ca84b5f4.log\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">total 1\n-rwxrwxrwx 1 root root 460 Jan 17 20:08 ClassifierDLApproach_1eb3ca84b5f4.log\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sh cat  /dbfs/clf_dl_logs/ClassifierDLApproach*\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1c688ed8-96fc-4f93-ada8-f3c93818653a","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Training started - epochs: 5 - learning_rate: 0.001 - batch_size: 8 - training_examples: 120000 - classes: 4\nEpoch 0/5 - 33.38s - loss: 12909.78 - acc: 0.88241667 - batches: 15000\nEpoch 1/5 - 33.62s - loss: 12767.149 - acc: 0.89109164 - batches: 15000\nEpoch 2/5 - 33.41s - loss: 12703.246 - acc: 0.896 - batches: 15000\nEpoch 3/5 - 32.84s - loss: 12665.412 - acc: 0.89918333 - batches: 15000\nEpoch 4/5 - 33.13s - loss: 12636.854 - acc: 0.90165 - batches: 15000\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Training started - epochs: 5 - learning_rate: 0.001 - batch_size: 8 - training_examples: 120000 - classes: 4\nEpoch 0/5 - 33.38s - loss: 12909.78 - acc: 0.88241667 - batches: 15000\nEpoch 1/5 - 33.62s - loss: 12767.149 - acc: 0.89109164 - batches: 15000\nEpoch 2/5 - 33.41s - loss: 12703.246 - acc: 0.896 - batches: 15000\nEpoch 3/5 - 32.84s - loss: 12665.412 - acc: 0.89918333 - batches: 15000\nEpoch 4/5 - 33.13s - loss: 12636.854 - acc: 0.90165 - batches: 15000\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["from sparknlp.base import LightPipeline\n\nlight_model = LightPipeline(use_pipelineModel)\n\ntext='''\nFearing the fate of Italy, the centre-right government has threatened to be merciless with those who flout tough restrictions. \nAs of Wednesday it will also include all shops being closed across Greece, with the exception of supermarkets. Banks, pharmacies, pet-stores, mobile phone stores, opticians, bakers, mini-markets, couriers and food delivery outlets are among the few that will also be allowed to remain open.\n'''\nresult = light_model.annotate(text)\n\nresult['class']"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9f88bec0-930c-4a18-b5c1-e1f5e965d70f","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[79]: [&#39;Business&#39;]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[79]: [&#39;Business&#39;]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["light_model.annotate('the soccer games will be postponed.')\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2e4ae633-ee42-4cbb-894e-3679cfa55f3f","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[80]: {&#39;document&#39;: [&#39;the soccer games will be postponed.&#39;],\n &#39;sentence_embeddings&#39;: [&#39;the soccer games will be postponed.&#39;],\n &#39;class&#39;: [&#39;Sports&#39;]}</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[80]: {&#39;document&#39;: [&#39;the soccer games will be postponed.&#39;],\n &#39;sentence_embeddings&#39;: [&#39;the soccer games will be postponed.&#39;],\n &#39;class&#39;: [&#39;Sports&#39;]}</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["End of Notebook #"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d323163c-6777-4362-b402-5f8aadf65ad4","inputWidgets":{},"title":""}}}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.8.3","nbconvert_exporter":"python","file_extension":".py"},"application/vnd.databricks.v1+notebook":{"notebookName":"1. Quickstart Tutorial on Spark NLP","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2,"mostRecentlyExecutedCommandWithImplicitDF":{"commandId":3344645093452413,"dataframes":["_sqldf"]}},"language":"python","widgets":{},"notebookOrigID":3344645093452300}},"nbformat":4,"nbformat_minor":0}
