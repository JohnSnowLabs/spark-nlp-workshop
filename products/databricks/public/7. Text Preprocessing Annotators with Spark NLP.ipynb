{"cells":[{"cell_type":"markdown","source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"83c1ea98-bc26-4c13-a514-62b4d3462931","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["# 7. Text Preprocessing Annotators with Spark NLP"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d8290bca-6607-42d6-95b2-1c814f91d5b5","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["import sparknlp\nimport pandas as pd\n\nprint(\"Spark NLP version\", sparknlp.version())\n\nprint(\"Apache Spark version:\", spark.version)\n\nspark"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a9c612ac-aa41-47bc-aa00-dac43bb6ef21","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Spark NLP version 4.2.4\nApache Spark version: 3.1.2\nOut[2]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Spark NLP version 4.2.4\nApache Spark version: 3.1.2\nOut[2]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=7956323724731612#setting/sparkui/0616-152819-zhyjt0vc/driver-2656290554115927016\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.1.2</code></dd>\n              <dt>Master</dt>\n                <dd><code>spark://10.139.64.5:7077</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=7956323724731612#setting/sparkui/0616-152819-zhyjt0vc/driver-2656290554115927016\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.1.2</code></dd>\n              <dt>Master</dt>\n                <dd><code>spark://10.139.64.5:7077</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "]}}],"execution_count":0},{"cell_type":"code","source":["from sparknlp.base import *\nfrom sparknlp.annotator import *"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"be8b89a5-4afe-4ec2-b697-a3b9dfe49b96","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["**Note** Read this article if you want to understand the basic concepts in Spark NLP.\n\nhttps://towardsdatascience.com/introduction-to-spark-nlp-foundations-and-basic-components-part-i-c83b7629ed59"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4c4f42b2-9b7b-4c61-86d9-559e2cf062a3","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["## Annotators and Transformer Concepts"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"fa5fdc91-a422-42ae-b74f-19062d629e60","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["In Spark NLP, all Annotators are either Estimators or Transformers as we see in Spark ML. An Estimator in Spark ML is an algorithm which can be fit on a DataFrame to produce a Transformer. E.g., a learning algorithm is an Estimator which trains on a DataFrame and produces a model. A Transformer is an algorithm which can transform one DataFrame into another DataFrame. E.g., an ML model is a Transformer that transforms a DataFrame with features into a DataFrame with predictions.\nIn Spark NLP, there are two types of annotators: AnnotatorApproach and AnnotatorModel\nAnnotatorApproach extends Estimators from Spark ML, which are meant to be trained through fit(), and AnnotatorModel extends Transformers which are meant to transform data frames through transform().\nSome of Spark NLP annotators have a Model suffix and some do not. The model suffix is explicitly stated when the annotator is the result of a training process. Some annotators, such as Tokenizer are transformers but do not contain the suffix Model since they are not trained, annotators. Model annotators have a pre-trained() on its static object, to retrieve the public pre-trained version of a model.\nLong story short, if it trains on a DataFrame and produces a model, it’s an AnnotatorApproach; and if it transforms one DataFrame into another DataFrame through some models, it’s an AnnotatorModel (e.g. WordEmbeddingsModel) and it doesn’t take Model suffix if it doesn’t rely on a pre-trained annotator while transforming a DataFrame (e.g. Tokenizer)."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"22290061-5150-4307-a842-9aeb848033da","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["!wget -q https://gist.githubusercontent.com/vkocaman/e091605f012ffc1efc0fcda170919602/raw/fae33d25bd026375b2aaf1194b68b9da559c4ac4/annotators.csv\n\ndbutils.fs.cp(\"file:/databricks/driver/annotators.csv\", \"dbfs:/\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c58d8fd3-02bd-40fb-84b7-da8873a65d93","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[4]: True</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[4]: True</div>"]}}],"execution_count":0},{"cell_type":"code","source":["import pandas as pd\n\ndf = pd.read_csv(\"annotators.csv\")\n\ndisplay(df)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b4758ee1-ca82-4636-af9e-595fca0496d7","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">/databricks/spark/python/pyspark/sql/pandas/conversion.py:499: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  arrow_data = [[(c, t) for (_, c), t in zip(pdf_slice.iteritems(), arrow_types)]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/spark/python/pyspark/sql/pandas/conversion.py:499: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  arrow_data = [[(c, t) for (_, c), t in zip(pdf_slice.iteritems(), arrow_types)]\n</div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["Tokenizer*","Identifies tokens with tokenization open standards","Opensource","-","+"],["Normalizer*","Removes all dirty characters from text","Opensource","-","+"],["Stemmer*","Returns hard'-stems out of words with the objective of retrieving the meaningful part of the word","Opensource","+","-"],["Lemmatizer*","Retrieves lemmas out of words with the objective of returning a base dictionary word","Opensource","-","+"],["RegexMatcher*","Uses a reference file to match a set of regular expressions and put them inside a provided key.","Opensource","+","+"],["TextMatcher*","Annotator to match entire phrases (by token) provided in a file against a Document","Opensource","+","+"],["Chunker*","Matches a pattern of part'-of'-speech tags in order to return meaningful phrases from document","Opensource","+","-"],["DateMatcher*","Reads from different forms of date and time expressions and converts them to a provided date format","Opensource","+","-"],["SentenceDetector*","Finds sentence bounds in raw text. Applies rules from Pragmatic Segmenter","Opensource","+","-"],["DeepSentenceDetector*","Finds sentence bounds in raw text. Applies a Named Entity Recognition DL model","Opensource","+","-"],["POSTagger","Sets a Part'-Of'-Speech tag to each word within a sentence.","Opensource","+","+"],["ViveknSentimentDetector","Scores a sentence for a sentiment","Opensource","+","+"],["SentimentDetector*","Scores a sentence for a sentiment","Opensource","+","+"],["WordEmbeddings*","Word Embeddings lookup annotator that maps tokens to vectors","Opensource","+","+"],["BertEmbeddings*","Bert Embeddings that maps tokens to vectors in a bidirectional way","Opensource","+","-"],["NerCrf","Named Entity recognition annotator allows for a generic model to be trained by utilizing a CRF machine learning algorithm","Opensource","+","+"],["NerDL","This Named Entity recognition annotator allows to train generic NER model based on Neural Networks by utilizing Char CNNs '- BiLSTM '- CRF architecture that achieves state'-of'-the'-art in most datasets.","Opensource","+","+"],["NorvigSweeting","This annotator retrieves tokens and makes corrections automatically if not found in an English dictionary","Opensource","+","+"],["SymmetricDelete","This spell checker is inspired on Symmetric Delete algorithm","Opensource","+","+"],["ContextSpellChecker","Utilizes tensorflow to do context based spell checking","Opensource","+","+"],["DependencyParser","Unlabeled parser that finds a grammatical relation between two words in a sentence","Opensource","+","+"],["TypedDependencyParser","Labeled parser that finds a grammatical relation between two words in a sentence","Opensource","+","+"],["AssertionLogReg","It will classify each clinically relevant named entity into its assertion type: “present”, “absent”, “hypothetical”, etc.","Licensed","+","+"],["AssertionDL","It will classify each clinically relevant named entity into its assertion type: “present”, “absent”, “hypothetical”, etc.","Licensed","+","+"],["EntityResolver","Assigns a ICD10 (International Classification of Diseases version 10) code to chunks identified as “PROBLEMS” by the NER Clinical Model","Licensed","+","+"],["DeIdentification","Identifies potential pieces of content with personal information about patients and remove them by replacing with semantic tags.","Licensed","+","+"]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":[],"pivotAggregation":null,"xColumns":[],"yColumns":[]},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"Annotator","type":"\"string\"","metadata":"{}"},{"name":"Description","type":"\"string\"","metadata":"{}"},{"name":"Version","type":"\"string\"","metadata":"{}"},{"name":"Annotator Approach","type":"\"string\"","metadata":"{}"},{"name":"Annotator Model","type":"\"string\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Annotator</th><th>Description</th><th>Version</th><th>Annotator Approach</th><th>Annotator Model</th></tr></thead><tbody><tr><td>Tokenizer*</td><td>Identifies tokens with tokenization open standards</td><td>Opensource</td><td>-</td><td>+</td></tr><tr><td>Normalizer*</td><td>Removes all dirty characters from text</td><td>Opensource</td><td>-</td><td>+</td></tr><tr><td>Stemmer*</td><td>Returns hard'-stems out of words with the objective of retrieving the meaningful part of the word</td><td>Opensource</td><td>+</td><td>-</td></tr><tr><td>Lemmatizer*</td><td>Retrieves lemmas out of words with the objective of returning a base dictionary word</td><td>Opensource</td><td>-</td><td>+</td></tr><tr><td>RegexMatcher*</td><td>Uses a reference file to match a set of regular expressions and put them inside a provided key.</td><td>Opensource</td><td>+</td><td>+</td></tr><tr><td>TextMatcher*</td><td>Annotator to match entire phrases (by token) provided in a file against a Document</td><td>Opensource</td><td>+</td><td>+</td></tr><tr><td>Chunker*</td><td>Matches a pattern of part'-of'-speech tags in order to return meaningful phrases from document</td><td>Opensource</td><td>+</td><td>-</td></tr><tr><td>DateMatcher*</td><td>Reads from different forms of date and time expressions and converts them to a provided date format</td><td>Opensource</td><td>+</td><td>-</td></tr><tr><td>SentenceDetector*</td><td>Finds sentence bounds in raw text. Applies rules from Pragmatic Segmenter</td><td>Opensource</td><td>+</td><td>-</td></tr><tr><td>DeepSentenceDetector*</td><td>Finds sentence bounds in raw text. Applies a Named Entity Recognition DL model</td><td>Opensource</td><td>+</td><td>-</td></tr><tr><td>POSTagger</td><td>Sets a Part'-Of'-Speech tag to each word within a sentence.</td><td>Opensource</td><td>+</td><td>+</td></tr><tr><td>ViveknSentimentDetector</td><td>Scores a sentence for a sentiment</td><td>Opensource</td><td>+</td><td>+</td></tr><tr><td>SentimentDetector*</td><td>Scores a sentence for a sentiment</td><td>Opensource</td><td>+</td><td>+</td></tr><tr><td>WordEmbeddings*</td><td>Word Embeddings lookup annotator that maps tokens to vectors</td><td>Opensource</td><td>+</td><td>+</td></tr><tr><td>BertEmbeddings*</td><td>Bert Embeddings that maps tokens to vectors in a bidirectional way</td><td>Opensource</td><td>+</td><td>-</td></tr><tr><td>NerCrf</td><td>Named Entity recognition annotator allows for a generic model to be trained by utilizing a CRF machine learning algorithm</td><td>Opensource</td><td>+</td><td>+</td></tr><tr><td>NerDL</td><td>This Named Entity recognition annotator allows to train generic NER model based on Neural Networks by utilizing Char CNNs '- BiLSTM '- CRF architecture that achieves state'-of'-the'-art in most datasets.</td><td>Opensource</td><td>+</td><td>+</td></tr><tr><td>NorvigSweeting</td><td>This annotator retrieves tokens and makes corrections automatically if not found in an English dictionary</td><td>Opensource</td><td>+</td><td>+</td></tr><tr><td>SymmetricDelete</td><td>This spell checker is inspired on Symmetric Delete algorithm</td><td>Opensource</td><td>+</td><td>+</td></tr><tr><td>ContextSpellChecker</td><td>Utilizes tensorflow to do context based spell checking</td><td>Opensource</td><td>+</td><td>+</td></tr><tr><td>DependencyParser</td><td>Unlabeled parser that finds a grammatical relation between two words in a sentence</td><td>Opensource</td><td>+</td><td>+</td></tr><tr><td>TypedDependencyParser</td><td>Labeled parser that finds a grammatical relation between two words in a sentence</td><td>Opensource</td><td>+</td><td>+</td></tr><tr><td>AssertionLogReg</td><td>It will classify each clinically relevant named entity into its assertion type: “present”, “absent”, “hypothetical”, etc.</td><td>Licensed</td><td>+</td><td>+</td></tr><tr><td>AssertionDL</td><td>It will classify each clinically relevant named entity into its assertion type: “present”, “absent”, “hypothetical”, etc.</td><td>Licensed</td><td>+</td><td>+</td></tr><tr><td>EntityResolver</td><td>Assigns a ICD10 (International Classification of Diseases version 10) code to chunks identified as “PROBLEMS” by the NER Clinical Model</td><td>Licensed</td><td>+</td><td>+</td></tr><tr><td>DeIdentification</td><td>Identifies potential pieces of content with personal information about patients and remove them by replacing with semantic tags.</td><td>Licensed</td><td>+</td><td>+</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["By convention, there are three possible names:\n\nApproach — Trainable annotator\n\nModel — Trained annotator\n\nnothing — Either a non-trainable annotator with pre-processing\nstep or shorthand for a model\n\nSo for example, Stemmer doesn’t say Approach nor Model, however, it is a Model. On the other hand, Tokenizer doesn’t say Approach nor Model, but it has a TokenizerModel(). Because it is not “training” anything, but it is doing some preprocessing before converting into a Model.\nWhen in doubt, please refer to official documentation and API reference.\nEven though we will do many hands-on practices in the following articles, let us give you a glimpse to let you understand the difference between AnnotatorApproach and AnnotatorModel.\nAs stated above, Tokenizer is an AnnotatorModel. So we need to call fit() and then transform()."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4a5efe03-26d5-42f1-927f-4ef864e533b4","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["Now let’s see how this can be done in Spark NLP using Annotators and Transformers. Assume that we have the following steps that need to be applied one by one on a data frame.\n\n- Split text into sentences\n- Tokenize\n- Normalize\n- Get word embeddings"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2b27c9f4-074b-4225-9cd2-51616c73a2f9","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["What’s actually happening under the hood?\n\nWhen we fit() on the pipeline with Spark data frame (df), its text column is fed into DocumentAssembler() transformer at first and then a new column “document” is created in Document type (AnnotatorType). As we mentioned before, this transformer is basically the initial entry point to Spark NLP for any Spark data frame. Then its document column is fed into SentenceDetector() (AnnotatorApproach) and the text is split into an array of sentences and a new column “sentences” in Document type is created. Then “sentences” column is fed into Tokenizer() (AnnotatorModel) and each sentence is tokenized and a new column “token” in Token type is created. And so on."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f825a023-af10-4d45-9e4b-11f593a8ab8a","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["### Create Spark Dataframe"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4178dda5-1331-41e6-a5c4-ca13fb427d66","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["text = 'Peter Parker is a nice guy and lives in New York'\n\nspark_df = spark.createDataFrame([[text]]).toDF(\"text\")\n\nspark_df.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"441e51b3-9864-4427-b6ed-c7e129ec2884","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+------------------------------------------------+\n|text                                            |\n+------------------------------------------------+\n|Peter Parker is a nice guy and lives in New York|\n+------------------------------------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------------------------------------------------+\ntext                                            |\n+------------------------------------------------+\nPeter Parker is a nice guy and lives in New York|\n+------------------------------------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.types import StringType, IntegerType\n\n# if you want to create a spark datafarme from a list of strings\n\ntext_list = ['Peter Parker is a nice guy and lives in New York.', 'Bruce Wayne is also a nice guy and lives in Gotham City.']\n\nspark.createDataFrame(text_list, StringType()).toDF(\"text\").show(truncate=80)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7ed2e5ab-d29a-4f34-96bd-3537d254c646","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+--------------------------------------------------------+\n|                                                    text|\n+--------------------------------------------------------+\n|       Peter Parker is a nice guy and lives in New York.|\n|Bruce Wayne is also a nice guy and lives in Gotham City.|\n+--------------------------------------------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------------------------------------------+\n                                                    text|\n+--------------------------------------------------------+\n       Peter Parker is a nice guy and lives in New York.|\nBruce Wayne is also a nice guy and lives in Gotham City.|\n+--------------------------------------------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql import Row\n\nspark.createDataFrame(list(map(lambda x: Row(text=x), text_list))).show(truncate=80)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"aaab5ae4-4ab2-4163-950f-6f1f9fc3a0e1","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+--------------------------------------------------------+\n|                                                    text|\n+--------------------------------------------------------+\n|       Peter Parker is a nice guy and lives in New York.|\n|Bruce Wayne is also a nice guy and lives in Gotham City.|\n+--------------------------------------------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------------------------------------------+\n                                                    text|\n+--------------------------------------------------------+\n       Peter Parker is a nice guy and lives in New York.|\nBruce Wayne is also a nice guy and lives in Gotham City.|\n+--------------------------------------------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/examples/python/annotation/text/english/spark-nlp-basics/sample-sentences-en.txt\n  \ndbutils.fs.cp(\"file:/databricks/driver/sample-sentences-en.txt\", \"dbfs:/\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ed0ece6a-4f79-4ffc-bd67-49ed30e65fa4","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[9]: True</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[9]: True</div>"]}}],"execution_count":0},{"cell_type":"code","source":["with open('sample-sentences-en.txt') as f:\n  print (f.read())"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4b5f3cef-5e21-4c82-ac9f-7383826813f5","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Peter is a very good person.\nMy life in Russia is very interesting.\nJohn and Peter are brothers. However they don&#39;t support each other that much.\nLucas Nogal Dunbercker is no longer happy. He has a good car though.\nEurope is very culture rich. There are huge churches! and big houses!\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Peter is a very good person.\nMy life in Russia is very interesting.\nJohn and Peter are brothers. However they don&#39;t support each other that much.\nLucas Nogal Dunbercker is no longer happy. He has a good car though.\nEurope is very culture rich. There are huge churches! and big houses!\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["spark_df = spark.read.text('/sample-sentences-en.txt').toDF('text')\n\nspark_df.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1035abd9-f941-464f-946d-f06a2cdafefb","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-----------------------------------------------------------------------------+\n|text                                                                         |\n+-----------------------------------------------------------------------------+\n|Peter is a very good person.                                                 |\n|My life in Russia is very interesting.                                       |\n|John and Peter are brothers. However they don&#39;t support each other that much.|\n|Lucas Nogal Dunbercker is no longer happy. He has a good car though.         |\n|Europe is very culture rich. There are huge churches! and big houses!        |\n+-----------------------------------------------------------------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------------------------------------------------------------------------+\ntext                                                                         |\n+-----------------------------------------------------------------------------+\nPeter is a very good person.                                                 |\nMy life in Russia is very interesting.                                       |\nJohn and Peter are brothers. However they don&#39;t support each other that much.|\nLucas Nogal Dunbercker is no longer happy. He has a good car though.         |\nEurope is very culture rich. There are huge churches! and big houses!        |\n+-----------------------------------------------------------------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["spark_df.select('text').show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1e23cf62-5fb7-4d6a-afd7-8b0e0e147726","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-----------------------------------------------------------------------------+\n|text                                                                         |\n+-----------------------------------------------------------------------------+\n|Peter is a very good person.                                                 |\n|My life in Russia is very interesting.                                       |\n|John and Peter are brothers. However they don&#39;t support each other that much.|\n|Lucas Nogal Dunbercker is no longer happy. He has a good car though.         |\n|Europe is very culture rich. There are huge churches! and big houses!        |\n+-----------------------------------------------------------------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------------------------------------------------------------------------+\ntext                                                                         |\n+-----------------------------------------------------------------------------+\nPeter is a very good person.                                                 |\nMy life in Russia is very interesting.                                       |\nJohn and Peter are brothers. However they don&#39;t support each other that much.|\nLucas Nogal Dunbercker is no longer happy. He has a good car though.         |\nEurope is very culture rich. There are huge churches! and big houses!        |\n+-----------------------------------------------------------------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# or we can even create a spark dataframe from pandas dataframe\ntemp_spark_df = spark.createDataFrame(df)\n\ntemp_spark_df.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1e5faeec-e860-47b6-a4c2-d238c36d8e1c","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+--------------------+--------------------+----------+------------------+---------------+\n|           Annotator|         Description|   Version|Annotator Approach|Annotator Model|\n+--------------------+--------------------+----------+------------------+---------------+\n|          Tokenizer*|Identifies tokens...|Opensource|                 -|              +|\n|         Normalizer*|Removes all dirty...|Opensource|                 -|              +|\n|            Stemmer*|Returns hard&#39;-ste...|Opensource|                 +|              -|\n|         Lemmatizer*|Retrieves lemmas ...|Opensource|                 -|              +|\n|       RegexMatcher*|Uses a reference ...|Opensource|                 +|              +|\n|        TextMatcher*|Annotator to matc...|Opensource|                 +|              +|\n|            Chunker*|Matches a pattern...|Opensource|                 +|              -|\n|        DateMatcher*|Reads from differ...|Opensource|                 +|              -|\n|   SentenceDetector*|Finds sentence bo...|Opensource|                 +|              -|\n|DeepSentenceDetec...|Finds sentence bo...|Opensource|                 +|              -|\n|           POSTagger|Sets a Part&#39;-Of&#39;-...|Opensource|                 +|              +|\n|ViveknSentimentDe...|Scores a sentence...|Opensource|                 +|              +|\n|  SentimentDetector*|Scores a sentence...|Opensource|                 +|              +|\n|     WordEmbeddings*|Word Embeddings l...|Opensource|                 +|              +|\n|     BertEmbeddings*|Bert Embeddings t...|Opensource|                 +|              -|\n|              NerCrf|Named Entity reco...|Opensource|                 +|              +|\n|               NerDL|This Named Entity...|Opensource|                 +|              +|\n|      NorvigSweeting|This annotator re...|Opensource|                 +|              +|\n|     SymmetricDelete|This spell checke...|Opensource|                 +|              +|\n| ContextSpellChecker|Utilizes tensorfl...|Opensource|                 +|              +|\n+--------------------+--------------------+----------+------------------+---------------+\nonly showing top 20 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+--------------------+----------+------------------+---------------+\n           Annotator|         Description|   Version|Annotator Approach|Annotator Model|\n+--------------------+--------------------+----------+------------------+---------------+\n          Tokenizer*|Identifies tokens...|Opensource|                 -|              +|\n         Normalizer*|Removes all dirty...|Opensource|                 -|              +|\n            Stemmer*|Returns hard&#39;-ste...|Opensource|                 +|              -|\n         Lemmatizer*|Retrieves lemmas ...|Opensource|                 -|              +|\n       RegexMatcher*|Uses a reference ...|Opensource|                 +|              +|\n        TextMatcher*|Annotator to matc...|Opensource|                 +|              +|\n            Chunker*|Matches a pattern...|Opensource|                 +|              -|\n        DateMatcher*|Reads from differ...|Opensource|                 +|              -|\n   SentenceDetector*|Finds sentence bo...|Opensource|                 +|              -|\nDeepSentenceDetec...|Finds sentence bo...|Opensource|                 +|              -|\n           POSTagger|Sets a Part&#39;-Of&#39;-...|Opensource|                 +|              +|\nViveknSentimentDe...|Scores a sentence...|Opensource|                 +|              +|\n  SentimentDetector*|Scores a sentence...|Opensource|                 +|              +|\n     WordEmbeddings*|Word Embeddings l...|Opensource|                 +|              +|\n     BertEmbeddings*|Bert Embeddings t...|Opensource|                 +|              -|\n              NerCrf|Named Entity reco...|Opensource|                 +|              +|\n               NerDL|This Named Entity...|Opensource|                 +|              +|\n      NorvigSweeting|This annotator re...|Opensource|                 +|              +|\n     SymmetricDelete|This spell checke...|Opensource|                 +|              +|\n ContextSpellChecker|Utilizes tensorfl...|Opensource|                 +|              +|\n+--------------------+--------------------+----------+------------------+---------------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["temp_spark_df.createOrReplaceTempView(\"table1\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c01c4ae6-f7d3-4f88-a0da-f06eed0a387a","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%scala\n\nvar scalaDF = spark.sql(\"select * from table1\")\n\nscalaDF.show(2)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"470c6993-4631-4d7b-a6f7-45e3df3aa5f2","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"scalaDF","typeStr":"org.apache.spark.sql.DataFrame","schema":{"type":"struct","fields":[{"name":"Annotator","type":"string","nullable":true,"metadata":{}},{"name":"Description","type":"string","nullable":true,"metadata":{}},{"name":"Version","type":"string","nullable":true,"metadata":{}},{"name":"Annotator Approach","type":"string","nullable":true,"metadata":{}},{"name":"Annotator Model","type":"string","nullable":true,"metadata":{}}]},"tableIdentifier":null}],"data":"<div class=\"ansiout\">+-----------+--------------------+----------+------------------+---------------+\n|  Annotator|         Description|   Version|Annotator Approach|Annotator Model|\n+-----------+--------------------+----------+------------------+---------------+\n| Tokenizer*|Identifies tokens...|Opensource|                 -|              +|\n|Normalizer*|Removes all dirty...|Opensource|                 -|              +|\n+-----------+--------------------+----------+------------------+---------------+\nonly showing top 2 rows\n\nscalaDF: org.apache.spark.sql.DataFrame = [Annotator: string, Description: string ... 3 more fields]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------+--------------------+----------+------------------+---------------+\n  Annotator|         Description|   Version|Annotator Approach|Annotator Model|\n+-----------+--------------------+----------+------------------+---------------+\n Tokenizer*|Identifies tokens...|Opensource|                 -|              +|\nNormalizer*|Removes all dirty...|Opensource|                 -|              +|\n+-----------+--------------------+----------+------------------+---------------+\nonly showing top 2 rows\n\nscalaDF: org.apache.spark.sql.DataFrame = [Annotator: string, Description: string ... 3 more fields]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["pythonDF = spark.sql(\"select * from table1\")\n\npythonDF.show(3)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c240affb-c520-4f7b-b77c-6b523b2b6b4c","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-----------+--------------------+----------+------------------+---------------+\n|  Annotator|         Description|   Version|Annotator Approach|Annotator Model|\n+-----------+--------------------+----------+------------------+---------------+\n| Tokenizer*|Identifies tokens...|Opensource|                 -|              +|\n|Normalizer*|Removes all dirty...|Opensource|                 -|              +|\n|   Stemmer*|Returns hard&#39;-ste...|Opensource|                 +|              -|\n+-----------+--------------------+----------+------------------+---------------+\nonly showing top 3 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------+--------------------+----------+------------------+---------------+\n  Annotator|         Description|   Version|Annotator Approach|Annotator Model|\n+-----------+--------------------+----------+------------------+---------------+\n Tokenizer*|Identifies tokens...|Opensource|                 -|              +|\nNormalizer*|Removes all dirty...|Opensource|                 -|              +|\n   Stemmer*|Returns hard&#39;-ste...|Opensource|                 +|              -|\n+-----------+--------------------+----------+------------------+---------------+\nonly showing top 3 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["textFiles = spark.sparkContext.wholeTextFiles(\"./*.txt\",4)\n    \nspark_df_folder = textFiles.toDF(schema=['path','text'])\n\nspark_df_folder.show(truncate=15)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b1afe0d3-c576-42a3-bdc0-dcb3d75fb932","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+---------------+---------------+\n|           path|           text|\n+---------------+---------------+\n|  dbfs:/400.txt|FOREWORD\nEle...|\n|dbfs:/ADE-NE...|6460590 NEG ...|\n|dbfs:/AntBNC...|aaah\t-&gt;\taaah...|\n|dbfs:/AskAPa...|108367008\tDi...|\n|dbfs:/AskAPa...|108367008\tDi...|\n|dbfs:/AskAPa...|267032009\tTi...|\n|dbfs:/NER_NC...|-DOCSTART- -...|\n|dbfs:/NER_NC...|-DOCSTART- -...|\n|dbfs:/augmen...|-DOCSTART- -...|\n|dbfs:/custom...|NUMBER ([0-9...|\n|dbfs:/female...|she\nher\ngirl...|\n|dbfs:/financ...|Wall Street\n...|\n|dbfs:/hipaa-...|PATIENT\tDOB\t...|\n|dbfs:/holmes...|THE ADVENTUR...|\n|dbfs:/mt_onc...|Sample Type ...|\n|dbfs:/obfusc...|Marvin MARSH...|\n|dbfs:/obfusc...|Will Perry#P...|\n|dbfs:/regex_...|\nrenal\\s\\w+,...|\n|dbfs:/sample...|Peter is a v...|\n|dbfs:/sport_...|soccer\nworld...|\n+---------------+---------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------------+---------------+\n           path|           text|\n+---------------+---------------+\n  dbfs:/400.txt|FOREWORD\nEle...|\ndbfs:/ADE-NE...|6460590 NEG ...|\ndbfs:/AntBNC...|aaah\t-&gt;\taaah...|\ndbfs:/AskAPa...|108367008\tDi...|\ndbfs:/AskAPa...|108367008\tDi...|\ndbfs:/AskAPa...|267032009\tTi...|\ndbfs:/NER_NC...|-DOCSTART- -...|\ndbfs:/NER_NC...|-DOCSTART- -...|\ndbfs:/augmen...|-DOCSTART- -...|\ndbfs:/custom...|NUMBER ([0-9...|\ndbfs:/female...|she\nher\ngirl...|\ndbfs:/financ...|Wall Street\n...|\ndbfs:/hipaa-...|PATIENT\tDOB\t...|\ndbfs:/holmes...|THE ADVENTUR...|\ndbfs:/mt_onc...|Sample Type ...|\ndbfs:/obfusc...|Marvin MARSH...|\ndbfs:/obfusc...|Will Perry#P...|\ndbfs:/regex_...|\nrenal\\s\\w+,...|\ndbfs:/sample...|Peter is a v...|\ndbfs:/sport_...|soccer\nworld...|\n+---------------+---------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["spark_df_folder.select('text').take(1)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"fceaeb3d-8167-46f3-9009-2feb21a474ee","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[17]: [Row(text=&#34;FOREWORD\\nElectronic design engineers are the true idea men of the electronic\\nindustries. They create ideas and use them in their designs, they stimu-\\nlate ideas in other designers, and they borrow and adapt ideas from\\nothers. One could almost say they feed on and grow on ideas.\\n\\nELECTRONIC DESIGN has recognized this need and its edi-\\ntorial content has reflected this awareness. Each issue is literally a col-\\nlection of useful ideas. In one section, however, special attention has\\nbeen devoted to providing a forum for the exchange of ideas between\\nreaders—a section called “Ideas For Design.” Here are presented clever,\\nunique, ingenious, and often very simple ideas that readers have found\\nuseful, sometimes as parts of larger designs and sometimes as aids in\\nmeasuring the parameters or testing the effectiveness of their designs.\\nMany are quite simple “little” ideas, but experienced designers know\\nthat good little ideas make the good large design possible.\\n\\nTo encourage this exchange of ideas, ELECTRONIC DESIGN\\nhas been sponsoring an IFD Award program. Readers are asked to\\nvote on the ideas they find most useful in the IFD section of\\nELECTRONIC DESIGN. Awards are made to the idea getting the\\nmost votes in an issue, and from the issue winners a grand prize of\\n$1.000 is awarded for the best “Idea of the Year.”\\n\\nFor the past four years, we have been selecting 100 of the best\\nideas and making them available in an annual booklet, arranged by\\ncategory for the convenience of readers. Four volumes have appeared\\nin this series, and now, in response to many requests we have com-\\nbined these four volumes into a convenient, more durable book. The\\nideas have been rearranged under specific categories, making for a very\\nhandy reference book, suitable for a desk or library shelf.\\n\\nIt is diflicult to categorize ideas for designers; they are often\\nuseable in situations not originally considered by the user (or the cate-\\ngorizer ). Therefore, the reader may not agree with our choice, or worse\\nstill, he may miss a good idea because it did not appear under the cate-\\ngory to which he felt it belonged. If the former be the case, we wel-\\ncome comments and suggestions for arrangement of future volumes.\\nTo avoid the latter possibility, we suggest at least cursory perusal of\\nall categories—you may be pleasantly surprised at what you find.\\n\\nFebruary 1964\\nNew York \\n\\nEDWARD E. GRAZDA\\nEditorial Director\\nELECTRONIC DESIGN\\n\\n\\n\\n\\n[&#39;A .&#39;,\\n &#39;Record date : &lt;DATE&gt;  , &lt;DOCTOR&gt; , M.D .&#39;,\\n &#39;, Name : &lt;PATIENT&gt; , &lt;PATIENT&gt; MR .&#39;,\\n &#39;# &lt;MEDICALRECORD&gt; Date : &lt;DATE&gt; PCP : &lt;DOCTOR&gt; , 25 month years-old , Record date : &lt;DATE&gt; .&#39;,\\n &#39;&lt;HOSPITAL&gt; .&#39;,\\n &#39;&lt;STREET&gt;&#39;]\\n&#34;)]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[17]: [Row(text=&#34;FOREWORD\\nElectronic design engineers are the true idea men of the electronic\\nindustries. They create ideas and use them in their designs, they stimu-\\nlate ideas in other designers, and they borrow and adapt ideas from\\nothers. One could almost say they feed on and grow on ideas.\\n\\nELECTRONIC DESIGN has recognized this need and its edi-\\ntorial content has reflected this awareness. Each issue is literally a col-\\nlection of useful ideas. In one section, however, special attention has\\nbeen devoted to providing a forum for the exchange of ideas between\\nreaders—a section called “Ideas For Design.” Here are presented clever,\\nunique, ingenious, and often very simple ideas that readers have found\\nuseful, sometimes as parts of larger designs and sometimes as aids in\\nmeasuring the parameters or testing the effectiveness of their designs.\\nMany are quite simple “little” ideas, but experienced designers know\\nthat good little ideas make the good large design possible.\\n\\nTo encourage this exchange of ideas, ELECTRONIC DESIGN\\nhas been sponsoring an IFD Award program. Readers are asked to\\nvote on the ideas they find most useful in the IFD section of\\nELECTRONIC DESIGN. Awards are made to the idea getting the\\nmost votes in an issue, and from the issue winners a grand prize of\\n$1.000 is awarded for the best “Idea of the Year.”\\n\\nFor the past four years, we have been selecting 100 of the best\\nideas and making them available in an annual booklet, arranged by\\ncategory for the convenience of readers. Four volumes have appeared\\nin this series, and now, in response to many requests we have com-\\nbined these four volumes into a convenient, more durable book. The\\nideas have been rearranged under specific categories, making for a very\\nhandy reference book, suitable for a desk or library shelf.\\n\\nIt is diflicult to categorize ideas for designers; they are often\\nuseable in situations not originally considered by the user (or the cate-\\ngorizer ). Therefore, the reader may not agree with our choice, or worse\\nstill, he may miss a good idea because it did not appear under the cate-\\ngory to which he felt it belonged. If the former be the case, we wel-\\ncome comments and suggestions for arrangement of future volumes.\\nTo avoid the latter possibility, we suggest at least cursory perusal of\\nall categories—you may be pleasantly surprised at what you find.\\n\\nFebruary 1964\\nNew York \\n\\nEDWARD E. GRAZDA\\nEditorial Director\\nELECTRONIC DESIGN\\n\\n\\n\\n\\n[&#39;A .&#39;,\\n &#39;Record date : &lt;DATE&gt;  , &lt;DOCTOR&gt; , M.D .&#39;,\\n &#39;, Name : &lt;PATIENT&gt; , &lt;PATIENT&gt; MR .&#39;,\\n &#39;# &lt;MEDICALRECORD&gt; Date : &lt;DATE&gt; PCP : &lt;DOCTOR&gt; , 25 month years-old , Record date : &lt;DATE&gt; .&#39;,\\n &#39;&lt;HOSPITAL&gt; .&#39;,\\n &#39;&lt;STREET&gt;&#39;]\\n&#34;)]</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Transformers"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a1698c43-5e14-4554-859f-85cbde02e950","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["What are we going to do if our DataFrame doesn’t have columns in those type? Here comes transformers. In Spark NLP, we have five different transformers that are mainly used for getting the data in or transform the data from one AnnotatorType to another. Here is the list of transformers:\n\n`DocumentAssembler`: To get through the NLP process, we need to get raw data annotated. This is a special transformer that does this for us; it creates the first annotation of type Document which may be used by annotators down the road.\n\n`TokenAssembler`: This transformer reconstructs a Document type annotation from tokens, usually after these have been, lemmatized, normalized, spell checked, etc, to use this document annotation in further annotators.\n\n`Doc2Chunk`: Converts DOCUMENT type annotations into CHUNK type with the contents of a chunkCol.\n\n`Chunk2Doc` : Converts a CHUNK type column back into DOCUMENT. Useful when trying to re-tokenize or do further analysis on a CHUNK result.\n\n`Finisher`: Once we have our NLP pipeline ready to go, we might want to use our annotation results somewhere else where it is easy to use. The Finisher outputs annotation(s) values into a string."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e341e9fa-bc2b-48e7-bf93-e3111e944a7a","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["each annotator accepts certain types of columns and outputs new columns in another type (we call this AnnotatorType).\n\nIn Spark NLP, we have the following types: \n\n`Document`, `token`, `chunk`, `pos`, `word_embeddings`, `date`, `entity`, `sentiment`, `named_entity`, `dependency`, `labeled_dependency`. \n\nThat is, the DataFrame you have needs to have a column from one of these types if that column will be fed into an annotator; otherwise, you’d need to use one of the Spark NLP transformers."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"21249bdd-ab61-4808-a6d1-b9afc2efaec7","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["## Document Assembler"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"37f7d22b-e223-4631-b9a6-a44fcfa34a13","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["In Spark NLP, we have five different transformers that are mainly used for getting the data in or transform the data from one AnnotatorType to another."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1faa3027-3ff6-47ae-90cc-5427cbe34a68","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["That is, the DataFrame you have needs to have a column from one of these types if that column will be fed into an annotator; otherwise, you’d need to use one of the Spark NLP transformers. Here is the list of transformers: DocumentAssembler, TokenAssembler, Doc2Chunk, Chunk2Doc, and the Finisher.\n\nSo, let’s start with DocumentAssembler(), an entry point to Spark NLP annotators."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1d4da2d2-dd47-4a1a-bae4-7ebc8f6a6126","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["To get through the process in Spark NLP, we need to get raw data transformed into Document type at first. \n\nDocumentAssembler() is a special transformer that does this for us; it creates the first annotation of type Document which may be used by annotators down the road.\n\nDocumentAssembler() comes from sparknlp.base class and has the following settable parameters. See the full list here and the source code here.\n\n`setInputCol()` -> the name of the column that will be converted. We can specify only one column here. It can read either a String column or an Array[String]\n\n`setOutputCol()` -> optional : the name of the column in Document type that is generated. We can specify only one column here. Default is ‘document’\n\n`setIdCol()` -> optional: String type column with id information\n\n`setMetadataCol()` -> optional: Map type column with metadata information\n\n`setCleanupMode()` -> optional: Cleaning up options, \n\npossible values:\n```\ndisabled: Source kept as original. This is a default.\ninplace: removes new lines and tabs.\ninplace_full: removes new lines and tabs but also those which were converted to strings (i.e. \\n)\nshrink: removes new lines and tabs, plus merging multiple spaces and blank lines to a single space.\nshrink_full: remove new lines and tabs, including stringified values, plus shrinking spaces and blank lines.\n```"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"81481bba-c77a-4d87-91b4-a01471781351","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["spark_df.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"27e5489c-021c-43e9-909e-2ca24b4ca717","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-----------------------------------------------------------------------------+\n|text                                                                         |\n+-----------------------------------------------------------------------------+\n|Peter is a very good person.                                                 |\n|My life in Russia is very interesting.                                       |\n|John and Peter are brothers. However they don&#39;t support each other that much.|\n|Lucas Nogal Dunbercker is no longer happy. He has a good car though.         |\n|Europe is very culture rich. There are huge churches! and big houses!        |\n+-----------------------------------------------------------------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------------------------------------------------------------------------+\ntext                                                                         |\n+-----------------------------------------------------------------------------+\nPeter is a very good person.                                                 |\nMy life in Russia is very interesting.                                       |\nJohn and Peter are brothers. However they don&#39;t support each other that much.|\nLucas Nogal Dunbercker is no longer happy. He has a good car though.         |\nEurope is very culture rich. There are huge churches! and big houses!        |\n+-----------------------------------------------------------------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["from sparknlp.base import *\n\ndocumentAssembler = DocumentAssembler()\\\n  .setInputCol(\"text\")\\\n  .setOutputCol(\"document\")\\\n  .setCleanupMode(\"shrink\")\n\ndoc_df = documentAssembler.transform(spark_df)\n\ndoc_df.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7d114d6e-4a18-4328-bde7-07457e7d5cfa","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-----------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------+\n|text                                                                         |document                                                                                                               |\n+-----------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------+\n|Peter is a very good person.                                                 |[{document, 0, 27, Peter is a very good person., {sentence -&gt; 0}, []}]                                                 |\n|My life in Russia is very interesting.                                       |[{document, 0, 37, My life in Russia is very interesting., {sentence -&gt; 0}, []}]                                       |\n|John and Peter are brothers. However they don&#39;t support each other that much.|[{document, 0, 76, John and Peter are brothers. However they don&#39;t support each other that much., {sentence -&gt; 0}, []}]|\n|Lucas Nogal Dunbercker is no longer happy. He has a good car though.         |[{document, 0, 67, Lucas Nogal Dunbercker is no longer happy. He has a good car though., {sentence -&gt; 0}, []}]         |\n|Europe is very culture rich. There are huge churches! and big houses!        |[{document, 0, 68, Europe is very culture rich. There are huge churches! and big houses!, {sentence -&gt; 0}, []}]        |\n+-----------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------+\ntext                                                                         |document                                                                                                               |\n+-----------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------+\nPeter is a very good person.                                                 |[{document, 0, 27, Peter is a very good person., {sentence -&gt; 0}, []}]                                                 |\nMy life in Russia is very interesting.                                       |[{document, 0, 37, My life in Russia is very interesting., {sentence -&gt; 0}, []}]                                       |\nJohn and Peter are brothers. However they don&#39;t support each other that much.|[{document, 0, 76, John and Peter are brothers. However they don&#39;t support each other that much., {sentence -&gt; 0}, []}]|\nLucas Nogal Dunbercker is no longer happy. He has a good car though.         |[{document, 0, 67, Lucas Nogal Dunbercker is no longer happy. He has a good car though., {sentence -&gt; 0}, []}]         |\nEurope is very culture rich. There are huge churches! and big houses!        |[{document, 0, 68, Europe is very culture rich. There are huge churches! and big houses!, {sentence -&gt; 0}, []}]        |\n+-----------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["At first, we define DocumentAssembler with desired parameters and then transform the data frame with it. The most important point to pay attention to here is that you need to use a String or String[Array] type column in .setInputCol(). So it doesn’t have to be named as text. You just use the column name as it is."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"cf4610a4-52c9-4b88-9cee-18f4b85a5f70","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["doc_df.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4fab2c15-c99c-47c5-b7df-cf7929ef04a2","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">root\n |-- text: string (nullable = true)\n |-- document: array (nullable = true)\n |    |-- element: struct (containsNull = true)\n |    |    |-- annotatorType: string (nullable = true)\n |    |    |-- begin: integer (nullable = false)\n |    |    |-- end: integer (nullable = false)\n |    |    |-- result: string (nullable = true)\n |    |    |-- metadata: map (nullable = true)\n |    |    |    |-- key: string\n |    |    |    |-- value: string (valueContainsNull = true)\n |    |    |-- embeddings: array (nullable = true)\n |    |    |    |-- element: float (containsNull = false)\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- text: string (nullable = true)\n-- document: array (nullable = true)\n    |-- element: struct (containsNull = true)\n    |    |-- annotatorType: string (nullable = true)\n    |    |-- begin: integer (nullable = false)\n    |    |-- end: integer (nullable = false)\n    |    |-- result: string (nullable = true)\n    |    |-- metadata: map (nullable = true)\n    |    |    |-- key: string\n    |    |    |-- value: string (valueContainsNull = true)\n    |    |-- embeddings: array (nullable = true)\n    |    |    |-- element: float (containsNull = false)\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["doc_df.select('document.result','document.begin','document.end').show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"935ed9c0-d651-4fdf-8e51-33058a091a7b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-------------------------------------------------------------------------------+-----+----+\n|result                                                                         |begin|end |\n+-------------------------------------------------------------------------------+-----+----+\n|[Peter is a very good person.]                                                 |[0]  |[27]|\n|[My life in Russia is very interesting.]                                       |[0]  |[37]|\n|[John and Peter are brothers. However they don&#39;t support each other that much.]|[0]  |[76]|\n|[Lucas Nogal Dunbercker is no longer happy. He has a good car though.]         |[0]  |[67]|\n|[Europe is very culture rich. There are huge churches! and big houses!]        |[0]  |[68]|\n+-------------------------------------------------------------------------------+-----+----+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------------------------------------------------------------------------------+-----+----+\nresult                                                                         |begin|end |\n+-------------------------------------------------------------------------------+-----+----+\n[Peter is a very good person.]                                                 |[0]  |[27]|\n[My life in Russia is very interesting.]                                       |[0]  |[37]|\n[John and Peter are brothers. However they don&#39;t support each other that much.]|[0]  |[76]|\n[Lucas Nogal Dunbercker is no longer happy. He has a good car though.]         |[0]  |[67]|\n[Europe is very culture rich. There are huge churches! and big houses!]        |[0]  |[68]|\n+-------------------------------------------------------------------------------+-----+----+\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["The new column is in an array of struct type and has the parameters shown above. The annotators and transformers all come with universal metadata that would be filled down the road depending on the annotators being used. Unless you want to append other Spark NLP annotators to DocumentAssembler(), you don’t need to know what all these parameters mean for now. So we will talk about them in the following articles. You can access all these parameters with {column name}.{parameter name}.\n\nLet’s print out the first item’s result."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9a49d269-cb03-4a75-b53a-ac6e5cfd63f3","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["doc_df.select(\"document.result\").take(1)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b04729d6-880e-49e9-b4b1-9d5da6b72f35","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[22]: [Row(result=[&#39;Peter is a very good person.&#39;])]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[22]: [Row(result=[&#39;Peter is a very good person.&#39;])]</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["If we would like to flatten the document column, we can do as follows."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d4665e32-9eed-4391-be36-93c08d702f78","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["import pyspark.sql.functions as F\n\ndoc_df.withColumn(\n    \"tmp\", \n    F.explode(\"document\"))\\\n    .select(\"tmp.*\")\\\n    .show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7233eacd-3dce-4b79-8066-96d533739863","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-------------+-----+---+-----------------------------------------------------------------------------+---------------+----------+\n|annotatorType|begin|end|result                                                                       |metadata       |embeddings|\n+-------------+-----+---+-----------------------------------------------------------------------------+---------------+----------+\n|document     |0    |27 |Peter is a very good person.                                                 |{sentence -&gt; 0}|[]        |\n|document     |0    |37 |My life in Russia is very interesting.                                       |{sentence -&gt; 0}|[]        |\n|document     |0    |76 |John and Peter are brothers. However they don&#39;t support each other that much.|{sentence -&gt; 0}|[]        |\n|document     |0    |67 |Lucas Nogal Dunbercker is no longer happy. He has a good car though.         |{sentence -&gt; 0}|[]        |\n|document     |0    |68 |Europe is very culture rich. There are huge churches! and big houses!        |{sentence -&gt; 0}|[]        |\n+-------------+-----+---+-----------------------------------------------------------------------------+---------------+----------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------------+-----+---+-----------------------------------------------------------------------------+---------------+----------+\nannotatorType|begin|end|result                                                                       |metadata       |embeddings|\n+-------------+-----+---+-----------------------------------------------------------------------------+---------------+----------+\ndocument     |0    |27 |Peter is a very good person.                                                 |{sentence -&gt; 0}|[]        |\ndocument     |0    |37 |My life in Russia is very interesting.                                       |{sentence -&gt; 0}|[]        |\ndocument     |0    |76 |John and Peter are brothers. However they don&#39;t support each other that much.|{sentence -&gt; 0}|[]        |\ndocument     |0    |67 |Lucas Nogal Dunbercker is no longer happy. He has a good car though.         |{sentence -&gt; 0}|[]        |\ndocument     |0    |68 |Europe is very culture rich. There are huge churches! and big houses!        |{sentence -&gt; 0}|[]        |\n+-------------+-----+---+-----------------------------------------------------------------------------+---------------+----------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Sentence Detector"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"fdbcde6c-785c-4050-9adf-5d6748af4358","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["Finds sentence bounds in raw text."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d462f297-0501-4f88-8dea-d839cf684cc5","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["`setCustomBounds(string)`: Custom sentence separator text e.g. `[\"\\n\"]`\n\n`setUseCustomOnly(bool)`: Use only custom bounds without considering those of Pragmatic Segmenter. Defaults to false. Needs customBounds.\n\n`setUseAbbreviations(bool)`: Whether to consider abbreviation strategies for better accuracy but slower performance. Defaults to true.\n\n`setExplodeSentences(bool)`: Whether to split sentences into different Dataset rows. Useful for higher parallelism in fat rows. Defaults to false."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"636758df-8118-4bb2-bfd9-df890d0ad89a","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from sparknlp.annotator import *\n\n# we feed the document column coming from Document Assembler\n\nsentenceDetector = SentenceDetector()\\\n    .setInputCols(['document'])\\\n    .setOutputCol('sentences')\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"51602eca-0169-44e1-b9b3-96d1f19a859c","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["sentenceDetector.extractParamMap()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d98058e6-d71b-4849-8c8d-0fe828f8ee03","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[25]: {Param(parent=&#39;SentenceDetector_82d361a265b8&#39;, name=&#39;lazyAnnotator&#39;, doc=&#39;Whether this AnnotatorModel acts as lazy in RecursivePipelines&#39;): False,\n Param(parent=&#39;SentenceDetector_82d361a265b8&#39;, name=&#39;useAbbreviations&#39;, doc=&#39;whether to apply abbreviations at sentence detection&#39;): True,\n Param(parent=&#39;SentenceDetector_82d361a265b8&#39;, name=&#39;detectLists&#39;, doc=&#39;whether detect lists during sentence detection&#39;): True,\n Param(parent=&#39;SentenceDetector_82d361a265b8&#39;, name=&#39;useCustomBoundsOnly&#39;, doc=&#39;Only utilize custom bounds in sentence detection&#39;): False,\n Param(parent=&#39;SentenceDetector_82d361a265b8&#39;, name=&#39;customBounds&#39;, doc=&#39;characters used to explicitly mark sentence bounds&#39;): [],\n Param(parent=&#39;SentenceDetector_82d361a265b8&#39;, name=&#39;customBoundsStrategy&#39;, doc=&#39;How to return matched custom bounds&#39;): &#39;none&#39;,\n Param(parent=&#39;SentenceDetector_82d361a265b8&#39;, name=&#39;explodeSentences&#39;, doc=&#39;whether to explode each sentence into a different row, for better parallelization. Defaults to false.&#39;): False,\n Param(parent=&#39;SentenceDetector_82d361a265b8&#39;, name=&#39;minLength&#39;, doc=&#39;Set the minimum allowed length for each sentence.&#39;): 0,\n Param(parent=&#39;SentenceDetector_82d361a265b8&#39;, name=&#39;maxLength&#39;, doc=&#39;Set the maximum allowed length for each sentence&#39;): 99999,\n Param(parent=&#39;SentenceDetector_82d361a265b8&#39;, name=&#39;inputCols&#39;, doc=&#39;previous annotations columns, if renamed&#39;): [&#39;document&#39;],\n Param(parent=&#39;SentenceDetector_82d361a265b8&#39;, name=&#39;outputCol&#39;, doc=&#39;output annotation column. can be left default.&#39;): &#39;sentences&#39;}</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[25]: {Param(parent=&#39;SentenceDetector_82d361a265b8&#39;, name=&#39;lazyAnnotator&#39;, doc=&#39;Whether this AnnotatorModel acts as lazy in RecursivePipelines&#39;): False,\n Param(parent=&#39;SentenceDetector_82d361a265b8&#39;, name=&#39;useAbbreviations&#39;, doc=&#39;whether to apply abbreviations at sentence detection&#39;): True,\n Param(parent=&#39;SentenceDetector_82d361a265b8&#39;, name=&#39;detectLists&#39;, doc=&#39;whether detect lists during sentence detection&#39;): True,\n Param(parent=&#39;SentenceDetector_82d361a265b8&#39;, name=&#39;useCustomBoundsOnly&#39;, doc=&#39;Only utilize custom bounds in sentence detection&#39;): False,\n Param(parent=&#39;SentenceDetector_82d361a265b8&#39;, name=&#39;customBounds&#39;, doc=&#39;characters used to explicitly mark sentence bounds&#39;): [],\n Param(parent=&#39;SentenceDetector_82d361a265b8&#39;, name=&#39;customBoundsStrategy&#39;, doc=&#39;How to return matched custom bounds&#39;): &#39;none&#39;,\n Param(parent=&#39;SentenceDetector_82d361a265b8&#39;, name=&#39;explodeSentences&#39;, doc=&#39;whether to explode each sentence into a different row, for better parallelization. Defaults to false.&#39;): False,\n Param(parent=&#39;SentenceDetector_82d361a265b8&#39;, name=&#39;minLength&#39;, doc=&#39;Set the minimum allowed length for each sentence.&#39;): 0,\n Param(parent=&#39;SentenceDetector_82d361a265b8&#39;, name=&#39;maxLength&#39;, doc=&#39;Set the maximum allowed length for each sentence&#39;): 99999,\n Param(parent=&#39;SentenceDetector_82d361a265b8&#39;, name=&#39;inputCols&#39;, doc=&#39;previous annotations columns, if renamed&#39;): [&#39;document&#39;],\n Param(parent=&#39;SentenceDetector_82d361a265b8&#39;, name=&#39;outputCol&#39;, doc=&#39;output annotation column. can be left default.&#39;): &#39;sentences&#39;}</div>"]}}],"execution_count":0},{"cell_type":"code","source":["sent_df = sentenceDetector.transform(doc_df)\n\nsent_df.show(truncate=50)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b1b6854e-6ebe-4188-aa3f-ce33cc0fc59d","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n|                                              text|                                          document|                                         sentences|\n+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n|                      Peter is a very good person.|[{document, 0, 27, Peter is a very good person....|[{document, 0, 27, Peter is a very good person....|\n|            My life in Russia is very interesting.|[{document, 0, 37, My life in Russia is very in...|[{document, 0, 37, My life in Russia is very in...|\n|John and Peter are brothers. However they don&#39;t...|[{document, 0, 76, John and Peter are brothers....|[{document, 0, 27, John and Peter are brothers....|\n|Lucas Nogal Dunbercker is no longer happy. He h...|[{document, 0, 67, Lucas Nogal Dunbercker is no...|[{document, 0, 41, Lucas Nogal Dunbercker is no...|\n|Europe is very culture rich. There are huge chu...|[{document, 0, 68, Europe is very culture rich....|[{document, 0, 27, Europe is very culture rich....|\n+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n                                              text|                                          document|                                         sentences|\n+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n                      Peter is a very good person.|[{document, 0, 27, Peter is a very good person....|[{document, 0, 27, Peter is a very good person....|\n            My life in Russia is very interesting.|[{document, 0, 37, My life in Russia is very in...|[{document, 0, 37, My life in Russia is very in...|\nJohn and Peter are brothers. However they don&#39;t...|[{document, 0, 76, John and Peter are brothers....|[{document, 0, 27, John and Peter are brothers....|\nLucas Nogal Dunbercker is no longer happy. He h...|[{document, 0, 67, Lucas Nogal Dunbercker is no...|[{document, 0, 41, Lucas Nogal Dunbercker is no...|\nEurope is very culture rich. There are huge chu...|[{document, 0, 68, Europe is very culture rich....|[{document, 0, 27, Europe is very culture rich....|\n+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["sent_df.select('sentences').take(3)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ea255770-5d50-4dc0-a29c-e9a5dbd92392","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[27]: [Row(sentences=[Row(annotatorType=&#39;document&#39;, begin=0, end=27, result=&#39;Peter is a very good person.&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[])]),\n Row(sentences=[Row(annotatorType=&#39;document&#39;, begin=0, end=37, result=&#39;My life in Russia is very interesting.&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[])]),\n Row(sentences=[Row(annotatorType=&#39;document&#39;, begin=0, end=27, result=&#39;John and Peter are brothers.&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;document&#39;, begin=29, end=76, result=&#34;However they don&#39;t support each other that much.&#34;, metadata={&#39;sentence&#39;: &#39;1&#39;}, embeddings=[])])]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[27]: [Row(sentences=[Row(annotatorType=&#39;document&#39;, begin=0, end=27, result=&#39;Peter is a very good person.&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[])]),\n Row(sentences=[Row(annotatorType=&#39;document&#39;, begin=0, end=37, result=&#39;My life in Russia is very interesting.&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[])]),\n Row(sentences=[Row(annotatorType=&#39;document&#39;, begin=0, end=27, result=&#39;John and Peter are brothers.&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;document&#39;, begin=29, end=76, result=&#34;However they don&#39;t support each other that much.&#34;, metadata={&#39;sentence&#39;: &#39;1&#39;}, embeddings=[])])]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["text ='The patient was prescribed 1 capsule of Advil for 5 days. He was seen by the endocrinology service and she was discharged on 40 units of insulin glargine at night, 12 units of insulin lispro with meals, and metformin 1000 mg two times a day. It was determined that all SGLT2 inhibitors should be discontinued indefinitely fro 3 months.'\ntext\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3f6a6e0a-3b49-46b4-b59f-d963bd42de2e","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[28]: &#39;The patient was prescribed 1 capsule of Advil for 5 days. He was seen by the endocrinology service and she was discharged on 40 units of insulin glargine at night, 12 units of insulin lispro with meals, and metformin 1000 mg two times a day. It was determined that all SGLT2 inhibitors should be discontinued indefinitely fro 3 months.&#39;</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[28]: &#39;The patient was prescribed 1 capsule of Advil for 5 days. He was seen by the endocrinology service and she was discharged on 40 units of insulin glargine at night, 12 units of insulin lispro with meals, and metformin 1000 mg two times a day. It was determined that all SGLT2 inhibitors should be discontinued indefinitely fro 3 months.&#39;</div>"]}}],"execution_count":0},{"cell_type":"code","source":["spark_df = spark.createDataFrame([[text]]).toDF(\"text\")\n\nspark_df.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b91a6f48-de9e-4713-b9e6-5f86b9ee4bd4","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|text                                                                                                                                                                                                                                                                                                                                           |\n+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|The patient was prescribed 1 capsule of Advil for 5 days. He was seen by the endocrinology service and she was discharged on 40 units of insulin glargine at night, 12 units of insulin lispro with meals, and metformin 1000 mg two times a day. It was determined that all SGLT2 inhibitors should be discontinued indefinitely fro 3 months.|\n+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\ntext                                                                                                                                                                                                                                                                                                                                           |\n+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\nThe patient was prescribed 1 capsule of Advil for 5 days. He was seen by the endocrinology service and she was discharged on 40 units of insulin glargine at night, 12 units of insulin lispro with meals, and metformin 1000 mg two times a day. It was determined that all SGLT2 inhibitors should be discontinued indefinitely fro 3 months.|\n+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["spark_df.show(truncate=100)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"bcead8bf-d5a1-4442-9637-e14ecb4aae83","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+----------------------------------------------------------------------------------------------------+\n|                                                                                                text|\n+----------------------------------------------------------------------------------------------------+\n|The patient was prescribed 1 capsule of Advil for 5 days. He was seen by the endocrinology servic...|\n+----------------------------------------------------------------------------------------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------------------------------------------------------------------------------------------------+\n                                                                                                text|\n+----------------------------------------------------------------------------------------------------+\nThe patient was prescribed 1 capsule of Advil for 5 days. He was seen by the endocrinology servic...|\n+----------------------------------------------------------------------------------------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["doc_df = documentAssembler.transform(spark_df)\n\nsent_df = sentenceDetector.transform(doc_df)\n\nsent_df.show(truncate=50)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"bec84776-b53f-4550-a408-6fd91ad23963","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n|                                              text|                                          document|                                         sentences|\n+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n|The patient was prescribed 1 capsule of Advil f...|[{document, 0, 334, The patient was prescribed ...|[{document, 0, 56, The patient was prescribed 1...|\n+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n                                              text|                                          document|                                         sentences|\n+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\nThe patient was prescribed 1 capsule of Advil f...|[{document, 0, 334, The patient was prescribed ...|[{document, 0, 56, The patient was prescribed 1...|\n+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["sent_df.select('sentences.result').take(1)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7877d2ba-ba32-4d70-a176-ae3f18476979","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[32]: [Row(result=[&#39;The patient was prescribed 1 capsule of Advil for 5 days.&#39;, &#39;He was seen by the endocrinology service and she was discharged on 40 units of insulin glargine at night, 12 units of insulin lispro with meals, and metformin 1000 mg two times a day.&#39;, &#39;It was determined that all SGLT2 inhibitors should be discontinued indefinitely fro 3 months.&#39;])]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[32]: [Row(result=[&#39;The patient was prescribed 1 capsule of Advil for 5 days.&#39;, &#39;He was seen by the endocrinology service and she was discharged on 40 units of insulin glargine at night, 12 units of insulin lispro with meals, and metformin 1000 mg two times a day.&#39;, &#39;It was determined that all SGLT2 inhibitors should be discontinued indefinitely fro 3 months.&#39;])]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["sentenceDetector.setExplodeSentences(True)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6693944c-4d63-4146-80c4-8106e259daa7","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[33]: SentenceDetector_82d361a265b8</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[33]: SentenceDetector_82d361a265b8</div>"]}}],"execution_count":0},{"cell_type":"code","source":["sent_df = sentenceDetector.transform(doc_df)\n\nsent_df.show(truncate=50)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8d9b279e-9f63-4ecd-b3b7-11519a7b2922","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n|                                              text|                                          document|                                         sentences|\n+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n|The patient was prescribed 1 capsule of Advil f...|[{document, 0, 334, The patient was prescribed ...|[{document, 0, 56, The patient was prescribed 1...|\n|The patient was prescribed 1 capsule of Advil f...|[{document, 0, 334, The patient was prescribed ...|[{document, 58, 240, He was seen by the endocri...|\n|The patient was prescribed 1 capsule of Advil f...|[{document, 0, 334, The patient was prescribed ...|[{document, 242, 334, It was determined that al...|\n+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n                                              text|                                          document|                                         sentences|\n+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\nThe patient was prescribed 1 capsule of Advil f...|[{document, 0, 334, The patient was prescribed ...|[{document, 0, 56, The patient was prescribed 1...|\nThe patient was prescribed 1 capsule of Advil f...|[{document, 0, 334, The patient was prescribed ...|[{document, 58, 240, He was seen by the endocri...|\nThe patient was prescribed 1 capsule of Advil f...|[{document, 0, 334, The patient was prescribed ...|[{document, 242, 334, It was determined that al...|\n+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["**`.setCustomBounds([r\"\\\\.\", \";\"])`**\n\n**`.setCustomBoundsStrategy(\"append\")`**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ff79aff6-d082-4111-bb7c-bf3efe9f7edb","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["text = [\n    [\"Peter is a very good person.\"],\n    [\"My life in Russia is very interesting.\"], \n    [\"John and Peter are brothers. However; they don't support each other that much.\"],\n    [\"Lucas Nogal Dunbercker is no longer happy. He has a good car though.\"],\n    [\"Europe is very culture rich. There are huge churches! and big houses!\"]\n    ]"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"df3b745f-b1fa-4523-8b15-836e319c275c","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["spark_df = spark.createDataFrame(text).toDF(\"text\")\nspark_df.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f33379da-c159-47c0-894a-611b6a6192e7","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+------------------------------------------------------------------------------+\n|text                                                                          |\n+------------------------------------------------------------------------------+\n|Peter is a very good person.                                                  |\n|My life in Russia is very interesting.                                        |\n|John and Peter are brothers. However; they don&#39;t support each other that much.|\n|Lucas Nogal Dunbercker is no longer happy. He has a good car though.          |\n|Europe is very culture rich. There are huge churches! and big houses!         |\n+------------------------------------------------------------------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------------------------------------------------------------------------------+\ntext                                                                          |\n+------------------------------------------------------------------------------+\nPeter is a very good person.                                                  |\nMy life in Russia is very interesting.                                        |\nJohn and Peter are brothers. However; they don&#39;t support each other that much.|\nLucas Nogal Dunbercker is no longer happy. He has a good car though.          |\nEurope is very culture rich. There are huge churches! and big houses!         |\n+------------------------------------------------------------------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["doc_df = documentAssembler.transform(spark_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b9cdcbdd-9ef6-42ae-a7c4-c03d8a5d4c2f","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["sent_df.select('sentences.result').take(5)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6288903c-91d0-4046-b4c9-083859522da9","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[127]: [Row(result=[&#39;The patient was prescribed 1 capsule of Advil for 5 days.&#39;]),\n Row(result=[&#39;He was seen by the endocrinology service and she was discharged on 40 units of insulin glargine at night, 12 units of insulin lispro with meals, and metformin 1000 mg two times a day.&#39;]),\n Row(result=[&#39;It was determined that all SGLT2 inhibitors should be discontinued indefinitely fro 3 months.&#39;])]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[127]: [Row(result=[&#39;The patient was prescribed 1 capsule of Advil for 5 days.&#39;]),\n Row(result=[&#39;He was seen by the endocrinology service and she was discharged on 40 units of insulin glargine at night, 12 units of insulin lispro with meals, and metformin 1000 mg two times a day.&#39;]),\n Row(result=[&#39;It was determined that all SGLT2 inhibitors should be discontinued indefinitely fro 3 months.&#39;])]</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["**`.setCustomBoundsStrategy(\"prepend\")`**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f29640ea-fde4-4d1c-9af0-dce26fe74bdc","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["sentenceDetector = SentenceDetector()\\\n      .setInputCols(['document'])\\\n      .setOutputCol('sentences')\\\n      .setCustomBounds([r\"\\.\", \";\", \"!\"])\\\n      .setCustomBoundsStrategy(\"prepend\")\n\nsent_df = sentenceDetector.transform(doc_df)\nsent_df.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"da27dc67-ca23-4967-8e42-580ffbecde7f","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|text                                                                          |document                                                                                                                |sentences                                                                                                                                                                                                                                                                                                                                    |\n+------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|Peter is a very good person.                                                  |[{document, 0, 27, Peter is a very good person., {sentence -&gt; 0}, []}]                                                  |[{document, 0, 26, Peter is a very good person, {sentence -&gt; 0}, []}, {document, 27, 27, ., {sentence -&gt; 1}, []}]                                                                                                                                                                                                                            |\n|My life in Russia is very interesting.                                        |[{document, 0, 37, My life in Russia is very interesting., {sentence -&gt; 0}, []}]                                        |[{document, 0, 36, My life in Russia is very interesting, {sentence -&gt; 0}, []}, {document, 37, 37, ., {sentence -&gt; 1}, []}]                                                                                                                                                                                                                  |\n|John and Peter are brothers. However; they don&#39;t support each other that much.|[{document, 0, 77, John and Peter are brothers. However; they don&#39;t support each other that much., {sentence -&gt; 0}, []}]|[{document, 0, 26, John and Peter are brothers, {sentence -&gt; 0}, []}, {document, 27, 27, ., {sentence -&gt; 1}, []}, {document, 29, 35, However, {sentence -&gt; 2}, []}, {document, 36, 36, ;, {sentence -&gt; 3}, []}, {document, 38, 76, they don&#39;t support each other that much, {sentence -&gt; 4}, []}, {document, 77, 77, ., {sentence -&gt; 5}, []}]|\n|Lucas Nogal Dunbercker is no longer happy. He has a good car though.          |[{document, 0, 67, Lucas Nogal Dunbercker is no longer happy. He has a good car though., {sentence -&gt; 0}, []}]          |[{document, 0, 40, Lucas Nogal Dunbercker is no longer happy, {sentence -&gt; 0}, []}, {document, 41, 41, ., {sentence -&gt; 1}, []}, {document, 43, 66, He has a good car though, {sentence -&gt; 2}, []}, {document, 67, 67, ., {sentence -&gt; 3}, []}]                                                                                               |\n|Europe is very culture rich. There are huge churches! and big houses!         |[{document, 0, 68, Europe is very culture rich. There are huge churches! and big houses!, {sentence -&gt; 0}, []}]         |[{document, 0, 26, Europe is very culture rich, {sentence -&gt; 0}, []}, {document, 27, 27, ., {sentence -&gt; 1}, []}, {document, 29, 51, There are huge churches, {sentence -&gt; 2}, []}, {document, 52, 52, !, {sentence -&gt; 3}, []}, {document, 54, 67, and big houses, {sentence -&gt; 4}, []}, {document, 68, 68, !, {sentence -&gt; 5}, []}]         |\n+------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\ntext                                                                          |document                                                                                                                |sentences                                                                                                                                                                                                                                                                                                                                    |\n+------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\nPeter is a very good person.                                                  |[{document, 0, 27, Peter is a very good person., {sentence -&gt; 0}, []}]                                                  |[{document, 0, 26, Peter is a very good person, {sentence -&gt; 0}, []}, {document, 27, 27, ., {sentence -&gt; 1}, []}]                                                                                                                                                                                                                            |\nMy life in Russia is very interesting.                                        |[{document, 0, 37, My life in Russia is very interesting., {sentence -&gt; 0}, []}]                                        |[{document, 0, 36, My life in Russia is very interesting, {sentence -&gt; 0}, []}, {document, 37, 37, ., {sentence -&gt; 1}, []}]                                                                                                                                                                                                                  |\nJohn and Peter are brothers. However; they don&#39;t support each other that much.|[{document, 0, 77, John and Peter are brothers. However; they don&#39;t support each other that much., {sentence -&gt; 0}, []}]|[{document, 0, 26, John and Peter are brothers, {sentence -&gt; 0}, []}, {document, 27, 27, ., {sentence -&gt; 1}, []}, {document, 29, 35, However, {sentence -&gt; 2}, []}, {document, 36, 36, ;, {sentence -&gt; 3}, []}, {document, 38, 76, they don&#39;t support each other that much, {sentence -&gt; 4}, []}, {document, 77, 77, ., {sentence -&gt; 5}, []}]|\nLucas Nogal Dunbercker is no longer happy. He has a good car though.          |[{document, 0, 67, Lucas Nogal Dunbercker is no longer happy. He has a good car though., {sentence -&gt; 0}, []}]          |[{document, 0, 40, Lucas Nogal Dunbercker is no longer happy, {sentence -&gt; 0}, []}, {document, 41, 41, ., {sentence -&gt; 1}, []}, {document, 43, 66, He has a good car though, {sentence -&gt; 2}, []}, {document, 67, 67, ., {sentence -&gt; 3}, []}]                                                                                               |\nEurope is very culture rich. There are huge churches! and big houses!         |[{document, 0, 68, Europe is very culture rich. There are huge churches! and big houses!, {sentence -&gt; 0}, []}]         |[{document, 0, 26, Europe is very culture rich, {sentence -&gt; 0}, []}, {document, 27, 27, ., {sentence -&gt; 1}, []}, {document, 29, 51, There are huge churches, {sentence -&gt; 2}, []}, {document, 52, 52, !, {sentence -&gt; 3}, []}, {document, 54, 67, and big houses, {sentence -&gt; 4}, []}, {document, 68, 68, !, {sentence -&gt; 5}, []}]         |\n+------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["sent_df.select('sentences.result').take(5)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"18328943-16e8-44e6-8feb-b4c4c55af1b3","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[129]: [Row(result=[&#39;Peter is a very good person&#39;, &#39;.&#39;]),\n Row(result=[&#39;My life in Russia is very interesting&#39;, &#39;.&#39;]),\n Row(result=[&#39;John and Peter are brothers&#39;, &#39;.&#39;, &#39;However&#39;, &#39;;&#39;, &#34;they don&#39;t support each other that much&#34;, &#39;.&#39;]),\n Row(result=[&#39;Lucas Nogal Dunbercker is no longer happy&#39;, &#39;.&#39;, &#39;He has a good car though&#39;, &#39;.&#39;]),\n Row(result=[&#39;Europe is very culture rich&#39;, &#39;.&#39;, &#39;There are huge churches&#39;, &#39;!&#39;, &#39;and big houses&#39;, &#39;!&#39;])]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[129]: [Row(result=[&#39;Peter is a very good person&#39;, &#39;.&#39;]),\n Row(result=[&#39;My life in Russia is very interesting&#39;, &#39;.&#39;]),\n Row(result=[&#39;John and Peter are brothers&#39;, &#39;.&#39;, &#39;However&#39;, &#39;;&#39;, &#34;they don&#39;t support each other that much&#34;, &#39;.&#39;]),\n Row(result=[&#39;Lucas Nogal Dunbercker is no longer happy&#39;, &#39;.&#39;, &#39;He has a good car though&#39;, &#39;.&#39;]),\n Row(result=[&#39;Europe is very culture rich&#39;, &#39;.&#39;, &#39;There are huge churches&#39;, &#39;!&#39;, &#39;and big houses&#39;, &#39;!&#39;])]</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["The separation of the sentences is determined according to the characters we set with custom bound. When we use append, sentences are differentiated according to the characters, if prepend is used, it also determines the characters as separate sentences."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"29a9f689-f221-421d-bca1-b230b4c7dab2","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["### Sentence Detector DL"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2637ac02-a310-48ee-838e-6305e764e130","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["text ='The patient was prescribed 1 capsule of Advil for 5 days. He was seen by the endocrinology service and she was discharged on 40 units of insulin glargine at night, 12 units of insulin lispro with meals, and metformin 1000 mg two times a day. It was determined that all SGLT2 inhibitors should be discontinued indefinitely from 3 months.'\n\nspark_df = spark.createDataFrame([[text]]).toDF(\"text\")\n\ndoc_df = documentAssembler.transform(spark_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"41047b79-49ee-408d-b756-80b81c203597","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["sentencerDL = SentenceDetectorDLModel\\\n    .pretrained(\"sentence_detector_dl\", \"en\") \\\n    .setInputCols([\"document\"]) \\\n    .setOutputCol(\"sentences\")\n\nsent_dl_df = sentencerDL.transform(doc_df)\n\nsent_dl_df.select(F.explode('sentences.result')).show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"afb4d447-c30b-4b52-a134-00b9cc25eb29","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">sentence_detector_dl download started this may take some time.\nApproximate size to download 354.6 KB\n\r[ | ]\r[OK!]\n+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|col                                                                                                                                                                                    |\n+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|The patient was prescribed 1 capsule of Advil for 5 days.                                                                                                                              |\n|He was seen by the endocrinology service and she was discharged on 40 units of insulin glargine at night, 12 units of insulin lispro with meals, and metformin 1000 mg two times a day.|\n|It was determined that all SGLT2 inhibitors should be discontinued indefinitely from 3 months.                                                                                         |\n+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">sentence_detector_dl download started this may take some time.\nApproximate size to download 354.6 KB\n\r[ | ]\r[OK!]\n+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\ncol                                                                                                                                                                                    |\n+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\nThe patient was prescribed 1 capsule of Advil for 5 days.                                                                                                                              |\nHe was seen by the endocrinology service and she was discharged on 40 units of insulin glargine at night, 12 units of insulin lispro with meals, and metformin 1000 mg two times a day.|\nIt was determined that all SGLT2 inhibitors should be discontinued indefinitely from 3 months.                                                                                         |\n+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["documenter = DocumentAssembler()\\\n    .setInputCol(\"text\")\\\n    .setOutputCol(\"document\")\n\nsentenceDetector = SentenceDetector()\\\n    .setInputCols(['document'])\\\n    .setOutputCol('sentences')\n    \nsentencerDL = SentenceDetectorDLModel\\\n    .pretrained(\"sentence_detector_dl\", \"en\") \\\n    .setInputCols([\"document\"]) \\\n    .setOutputCol(\"sentences\")\n\nsd_pipeline = PipelineModel(stages=[documenter, sentenceDetector])\n\nsd_model = LightPipeline(sd_pipeline)\n\n# DL version\nsd_dl_pipeline = PipelineModel(stages=[documenter, sentencerDL])\n\nsd_dl_model = LightPipeline(sd_dl_pipeline)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"56e67e59-5027-4ca1-9a20-e01d2388e5f2","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">sentence_detector_dl download started this may take some time.\nApproximate size to download 354.6 KB\n\r[ | ]\r[OK!]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">sentence_detector_dl download started this may take some time.\nApproximate size to download 354.6 KB\n\r[ | ]\r[OK!]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["text = \"\"\"John loves Mary.Mary loves Peter\nPeter loves Helen .Helen loves John; \nTotal: four people involved.\"\"\"\n\nfor anno in sd_model.fullAnnotate(text)[0][\"sentences\"]:\n    print(\"{}\\t{}\\t{}\\t{}\".format(\n        anno.metadata[\"sentence\"], anno.begin, anno.end, anno.result))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3a6e0168-3739-48ce-9916-bca13bb76637","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">0\t0\t51\tJohn loves Mary.Mary loves Peter\nPeter loves Helen .\n1\t52\t68\tHelen loves John;\n2\t71\t98\tTotal: four people involved.\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">0\t0\t51\tJohn loves Mary.Mary loves Peter\nPeter loves Helen .\n1\t52\t68\tHelen loves John;\n2\t71\t98\tTotal: four people involved.\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["for anno in sd_dl_model.fullAnnotate(text)[0][\"sentences\"]:\n    print(\"{}\\t{}\\t{}\\t{}\".format(\n        anno.metadata[\"sentence\"], anno.begin, anno.end, anno.result))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d5e9c00c-4af5-484c-b968-ce61b7b54208","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">0\t0\t15\tJohn loves Mary.\n1\t16\t31\tMary loves Peter\n2\t33\t51\tPeter loves Helen .\n3\t52\t68\tHelen loves John;\n4\t71\t98\tTotal: four people involved.\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">0\t0\t15\tJohn loves Mary.\n1\t16\t31\tMary loves Peter\n2\t33\t51\tPeter loves Helen .\n3\t52\t68\tHelen loves John;\n4\t71\t98\tTotal: four people involved.\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Tokenizer"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e51ef60b-828d-4fe7-9bed-4d48022bb73d","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["Identifies tokens with tokenization open standards. It is an **Annotator Approach, so it requires .fit()**.\n\nA few rules will help customizing it if defaults do not fit user needs.\n\nsetExceptions(StringArray): List of tokens to not alter at all. Allows composite tokens like two worded tokens that the user may not want to split.\n\n`addException(String)`: Add a single exception\n\n`setExceptionsPath(String)`: Path to txt file with list of token exceptions\n\n`caseSensitiveExceptions(bool)`: Whether to follow case sensitiveness for matching exceptions in text\n\n`contextChars(StringArray)`: List of 1 character string to rip off from tokens, such as parenthesis or question marks. Ignored if using prefix, infix or suffix patterns.\n\n`splitChars(StringArray)`: List of 1 character string to split tokens inside, such as hyphens. Ignored if using infix, prefix or suffix patterns.\n\n`splitPattern (String)`: pattern to separate from the inside of tokens. takes priority over splitChars.\nsetTargetPattern: Basic regex rule to identify a candidate for tokenization. Defaults to \\\\S+ which means anything not a space\n\n`setSuffixPattern`: Regex to identify subtokens that are in the end of the token. Regex has to end with \\\\z and must contain groups (). Each group will become a separate token within the prefix. Defaults to non-letter characters. e.g. quotes or parenthesis\n\n`setPrefixPattern`: Regex to identify subtokens that come in the beginning of the token. Regex has to start with \\\\A and must contain groups (). Each group will become a separate token within the prefix. Defaults to non-letter characters. e.g. quotes or parenthesis\n\n`addInfixPattern`: Add an extension pattern regex with groups to the top of the rules (will target first, from more specific to the more general).\n\n`minLength`: Set the minimum allowed legth for each token\n\n`maxLength`: Set the maximum allowed legth for each token"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3f1954c2-4e89-4103-8d60-273ce7c98ce4","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["tokenizer = Tokenizer() \\\n    .setInputCols([\"document\"]) \\\n    .setOutputCol(\"token\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"65f5a81d-44bd-43cc-826a-028db41575fd","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["tokenizer.extractParamMap()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f03f9461-4c51-4cd1-9678-5da193b127c0","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[134]: {Param(parent=&#39;Tokenizer_d784ff65cbfc&#39;, name=&#39;lazyAnnotator&#39;, doc=&#39;Whether this AnnotatorModel acts as lazy in RecursivePipelines&#39;): False,\n Param(parent=&#39;Tokenizer_d784ff65cbfc&#39;, name=&#39;targetPattern&#39;, doc=&#39;pattern to grab from text as token candidates. Defaults \\\\S+&#39;): &#39;\\\\S+&#39;,\n Param(parent=&#39;Tokenizer_d784ff65cbfc&#39;, name=&#39;contextChars&#39;, doc=&#39;character list used to separate from token boundaries&#39;): [&#39;.&#39;,\n  &#39;,&#39;,\n  &#39;;&#39;,\n  &#39;:&#39;,\n  &#39;!&#39;,\n  &#39;?&#39;,\n  &#39;*&#39;,\n  &#39;-&#39;,\n  &#39;(&#39;,\n  &#39;)&#39;,\n  &#39;&#34;&#39;,\n  &#34;&#39;&#34;],\n Param(parent=&#39;Tokenizer_d784ff65cbfc&#39;, name=&#39;caseSensitiveExceptions&#39;, doc=&#39;Whether to care for case sensitiveness in exceptions&#39;): True,\n Param(parent=&#39;Tokenizer_d784ff65cbfc&#39;, name=&#39;minLength&#39;, doc=&#39;Set the minimum allowed length for each token&#39;): 0,\n Param(parent=&#39;Tokenizer_d784ff65cbfc&#39;, name=&#39;maxLength&#39;, doc=&#39;Set the maximum allowed length for each token&#39;): 99999,\n Param(parent=&#39;Tokenizer_d784ff65cbfc&#39;, name=&#39;inputCols&#39;, doc=&#39;previous annotations columns, if renamed&#39;): [&#39;document&#39;],\n Param(parent=&#39;Tokenizer_d784ff65cbfc&#39;, name=&#39;outputCol&#39;, doc=&#39;output annotation column. can be left default.&#39;): &#39;token&#39;}</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[134]: {Param(parent=&#39;Tokenizer_d784ff65cbfc&#39;, name=&#39;lazyAnnotator&#39;, doc=&#39;Whether this AnnotatorModel acts as lazy in RecursivePipelines&#39;): False,\n Param(parent=&#39;Tokenizer_d784ff65cbfc&#39;, name=&#39;targetPattern&#39;, doc=&#39;pattern to grab from text as token candidates. Defaults \\\\S+&#39;): &#39;\\\\S+&#39;,\n Param(parent=&#39;Tokenizer_d784ff65cbfc&#39;, name=&#39;contextChars&#39;, doc=&#39;character list used to separate from token boundaries&#39;): [&#39;.&#39;,\n  &#39;,&#39;,\n  &#39;;&#39;,\n  &#39;:&#39;,\n  &#39;!&#39;,\n  &#39;?&#39;,\n  &#39;*&#39;,\n  &#39;-&#39;,\n  &#39;(&#39;,\n  &#39;)&#39;,\n  &#39;&#34;&#39;,\n  &#34;&#39;&#34;],\n Param(parent=&#39;Tokenizer_d784ff65cbfc&#39;, name=&#39;caseSensitiveExceptions&#39;, doc=&#39;Whether to care for case sensitiveness in exceptions&#39;): True,\n Param(parent=&#39;Tokenizer_d784ff65cbfc&#39;, name=&#39;minLength&#39;, doc=&#39;Set the minimum allowed length for each token&#39;): 0,\n Param(parent=&#39;Tokenizer_d784ff65cbfc&#39;, name=&#39;maxLength&#39;, doc=&#39;Set the maximum allowed length for each token&#39;): 99999,\n Param(parent=&#39;Tokenizer_d784ff65cbfc&#39;, name=&#39;inputCols&#39;, doc=&#39;previous annotations columns, if renamed&#39;): [&#39;document&#39;],\n Param(parent=&#39;Tokenizer_d784ff65cbfc&#39;, name=&#39;outputCol&#39;, doc=&#39;output annotation column. can be left default.&#39;): &#39;token&#39;}</div>"]}}],"execution_count":0},{"cell_type":"code","source":["text = 'Peter Parker (Spiderman) is a nice guy and lives in New York but has no e-mail!'\n\nspark_df = spark.createDataFrame([[text]]).toDF(\"text\")\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8346fed8-5d81-4d91-872a-b56f28039d31","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["doc_df = documentAssembler.transform(spark_df)\n\ntoken_df = tokenizer.fit(doc_df).transform(doc_df)\n\ntoken_df.show(truncate=50)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"efbfc338-bbde-48df-9935-8dfd56284df8","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n|                                              text|                                          document|                                             token|\n+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n|Peter Parker (Spiderman) is a nice guy and live...|[{document, 0, 78, Peter Parker (Spiderman) is ...|[{token, 0, 4, Peter, {sentence -&gt; 0}, []}, {to...|\n+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n                                              text|                                          document|                                             token|\n+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\nPeter Parker (Spiderman) is a nice guy and live...|[{document, 0, 78, Peter Parker (Spiderman) is ...|[{token, 0, 4, Peter, {sentence -&gt; 0}, []}, {to...|\n+--------------------------------------------------+--------------------------------------------------+--------------------------------------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["token_df.select('token.result').take(1)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3c8ea348-b8f7-4981-ae6b-2b60a5a93327","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[44]: [Row(result=[&#39;Peter&#39;, &#39;Parker&#39;, &#39;(&#39;, &#39;Spiderman&#39;, &#39;)&#39;, &#39;is&#39;, &#39;a&#39;, &#39;nice&#39;, &#39;guy&#39;, &#39;and&#39;, &#39;lives&#39;, &#39;in&#39;, &#39;New&#39;, &#39;York&#39;, &#39;but&#39;, &#39;has&#39;, &#39;no&#39;, &#39;e-mail&#39;, &#39;!&#39;])]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[44]: [Row(result=[&#39;Peter&#39;, &#39;Parker&#39;, &#39;(&#39;, &#39;Spiderman&#39;, &#39;)&#39;, &#39;is&#39;, &#39;a&#39;, &#39;nice&#39;, &#39;guy&#39;, &#39;and&#39;, &#39;lives&#39;, &#39;in&#39;, &#39;New&#39;, &#39;York&#39;, &#39;but&#39;, &#39;has&#39;, &#39;no&#39;, &#39;e-mail&#39;, &#39;!&#39;])]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["tokenizer = Tokenizer()\\\n    .setInputCols([\"document\"])\\\n    .setOutputCol(\"token\")\\\n    .setSplitChars(['-'])\\\n    .setContextChars(['?', '!', '('])\\\n    .addException(\"New York\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"bd873cb6-8dfa-4710-8929-01af041c67d2","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["token_df = tokenizer.fit(doc_df).transform(doc_df)\n\ntoken_df.select('token.result').take(1)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4a3ac2fc-3fee-4f1b-be68-f53f78d56f41","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[46]: [Row(result=[&#39;Peter&#39;, &#39;Parker&#39;, &#39;(&#39;, &#39;Spiderman)&#39;, &#39;is&#39;, &#39;a&#39;, &#39;nice&#39;, &#39;guy&#39;, &#39;and&#39;, &#39;lives&#39;, &#39;in&#39;, &#39;New York&#39;, &#39;but&#39;, &#39;has&#39;, &#39;no&#39;, &#39;e&#39;, &#39;mail&#39;, &#39;!&#39;])]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[46]: [Row(result=[&#39;Peter&#39;, &#39;Parker&#39;, &#39;(&#39;, &#39;Spiderman)&#39;, &#39;is&#39;, &#39;a&#39;, &#39;nice&#39;, &#39;guy&#39;, &#39;and&#39;, &#39;lives&#39;, &#39;in&#39;, &#39;New York&#39;, &#39;but&#39;, &#39;has&#39;, &#39;no&#39;, &#39;e&#39;, &#39;mail&#39;, &#39;!&#39;])]</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Regex Tokenizer"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a9ec30ed-dd3f-4e6a-857d-3994504ec4a3","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.sql.types import StringType\n\ncontent = \"1. T1-T2 DATE**[12/24/13] $1.99 () (10/12), ph+ 90%\"\npattern = \"\\\\s+|(?=[-.:;*+,$&%\\\\[\\\\]])|(?<=[-.:;*+,$&%\\\\[\\\\]])\"\n\ndf = spark.createDataFrame([content], StringType()).withColumnRenamed(\"value\", \"text\")\n\ndocumenter = DocumentAssembler()\\\n    .setInputCol(\"text\")\\\n    .setOutputCol(\"document\")\n\nsentenceDetector = SentenceDetector()\\\n    .setInputCols(['document'])\\\n    .setOutputCol('sentence')\n\nregexTokenizer = RegexTokenizer() \\\n    .setInputCols([\"sentence\"]) \\\n    .setOutputCol(\"regexToken\") \\\n    .setPattern(pattern) \\\n    .setPositionalMask(False)\n\ndocPatternRemoverPipeline = Pipeline().setStages([\n        documenter,\n        sentenceDetector,\n        regexTokenizer])\n\nresult = docPatternRemoverPipeline.fit(df).transform(df)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"66ae6b55-7ed2-4a4e-b7be-77d76eaadaf4","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["result.show(10,30)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"589c559c-ad93-4795-adb1-c5a2513c76f0","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+------------------------------+------------------------------+------------------------------+------------------------------+\n|                          text|                      document|                      sentence|                    regexToken|\n+------------------------------+------------------------------+------------------------------+------------------------------+\n|1. T1-T2 DATE**[12/24/13] $...|[{document, 0, 50, 1. T1-T2...|[{document, 0, 50, 1. T1-T2...|[{token, 0, 0, 1, {sentence...|\n+------------------------------+------------------------------+------------------------------+------------------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------------------------------+------------------------------+------------------------------+------------------------------+\n                          text|                      document|                      sentence|                    regexToken|\n+------------------------------+------------------------------+------------------------------+------------------------------+\n1. T1-T2 DATE**[12/24/13] $...|[{document, 0, 50, 1. T1-T2...|[{document, 0, 50, 1. T1-T2...|[{token, 0, 0, 1, {sentence...|\n+------------------------------+------------------------------+------------------------------+------------------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["import pyspark.sql.functions as F\n\nresult_df = result.select(F.explode('regexToken.result').alias('regexToken')).toPandas()\nresult_df"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7fc00b44-d665-4c0d-a42a-802f377c3542","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[49]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[49]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>regexToken</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>T1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>T2</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>DATE</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>*</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>*</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>[</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>12/24/13</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>]</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>$</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>.</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>99</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>()</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>(10/12)</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>,</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>ph</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>90</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>%</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>regexToken</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>T1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>T2</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>DATE</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>*</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>*</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>[</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>12/24/13</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>]</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>$</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>.</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>99</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>()</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>(10/12)</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>,</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>ph</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>90</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>%</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Stacking Spark NLP Annotators in Spark ML Pipeline"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2173234d-6b4b-4b8a-a686-ca95ba128505","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["Spark NLP provides an easy API to integrate with Spark ML Pipelines and all the Spark NLP annotators and transformers can be used within Spark ML Pipelines. So, it’s better to explain Pipeline concept through Spark ML official documentation.\n\nWhat is a Pipeline anyway? In machine learning, it is common to run a sequence of algorithms to process and learn from data. \n\nApache Spark ML represents such a workflow as a Pipeline, which consists of a sequence of PipelineStages (Transformers and Estimators) to be run in a specific order.\n\nIn simple terms, a pipeline chains multiple Transformers and Estimators together to specify an ML workflow. We use Pipeline to chain multiple Transformers and Estimators together to specify our machine learning workflow.\n\nThe figure below is for the training time usage of a Pipeline."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"38d817ef-8da6-4fbb-b79d-9aea8d093b0b","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["A Pipeline is specified as a sequence of stages, and each stage is either a Transformer or an Estimator. These stages are run in order, and the input DataFrame is transformed as it passes through each stage. That is, the data are passed through the fitted pipeline in order. Each stage’s transform() method updates the dataset and passes it to the next stage. With the help of Pipelines, we can ensure that training and test data go through identical feature processing steps.\n\nNow let’s see how this can be done in Spark NLP using Annotators and Transformers. Assume that we have the following steps that need to be applied one by one on a data frame.\n\n- Split text into sentences\n- Tokenize\n\nAnd here is how we code this pipeline up in Spark NLP."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"de662b8f-8bd2-4a82-bd7e-4da79b32f19d","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.ml import Pipeline\n\ndocumentAssembler = DocumentAssembler()\\\n    .setInputCol(\"text\")\\\n    .setOutputCol(\"document\")\n\nsentenceDetector = SentenceDetector()\\\n    .setInputCols(['document'])\\\n    .setOutputCol('sentences')\n\ntokenizer = Tokenizer() \\\n    .setInputCols([\"sentences\"]) \\\n    .setOutputCol(\"token\")\n\nnlpPipeline = Pipeline(stages=[\n     documentAssembler, \n     sentenceDetector,\n     tokenizer\n ])\n\nempty_df = spark.createDataFrame([['']]).toDF(\"text\")\n\npipelineModel = nlpPipeline.fit(empty_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ad6d45a0-f43f-488b-97f9-6b50955e4c1b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["spark_df = spark.read.text('/sample-sentences-en.txt').toDF('text')\n\nspark_df.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1cf7b856-a09a-460a-9b9d-da3cbf9d6f66","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-----------------------------------------------------------------------------+\n|text                                                                         |\n+-----------------------------------------------------------------------------+\n|Peter is a very good person.                                                 |\n|My life in Russia is very interesting.                                       |\n|John and Peter are brothers. However they don&#39;t support each other that much.|\n|Lucas Nogal Dunbercker is no longer happy. He has a good car though.         |\n|Europe is very culture rich. There are huge churches! and big houses!        |\n+-----------------------------------------------------------------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------------------------------------------------------------------------+\ntext                                                                         |\n+-----------------------------------------------------------------------------+\nPeter is a very good person.                                                 |\nMy life in Russia is very interesting.                                       |\nJohn and Peter are brothers. However they don&#39;t support each other that much.|\nLucas Nogal Dunbercker is no longer happy. He has a good car though.         |\nEurope is very culture rich. There are huge churches! and big houses!        |\n+-----------------------------------------------------------------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["result = pipelineModel.transform(spark_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b387387e-9366-4bf2-9c9d-d6175fc9fb22","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["result.show(truncate=20)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a4efe029-9836-435c-8a58-fa8b99041a51","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+--------------------+--------------------+--------------------+--------------------+\n|                text|            document|           sentences|               token|\n+--------------------+--------------------+--------------------+--------------------+\n|Peter is a very g...|[{document, 0, 27...|[{document, 0, 27...|[{token, 0, 4, Pe...|\n|My life in Russia...|[{document, 0, 37...|[{document, 0, 37...|[{token, 0, 1, My...|\n|John and Peter ar...|[{document, 0, 76...|[{document, 0, 27...|[{token, 0, 3, Jo...|\n|Lucas Nogal Dunbe...|[{document, 0, 67...|[{document, 0, 41...|[{token, 0, 4, Lu...|\n|Europe is very cu...|[{document, 0, 68...|[{document, 0, 27...|[{token, 0, 5, Eu...|\n+--------------------+--------------------+--------------------+--------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+--------------------+--------------------+--------------------+\n                text|            document|           sentences|               token|\n+--------------------+--------------------+--------------------+--------------------+\nPeter is a very g...|[{document, 0, 27...|[{document, 0, 27...|[{token, 0, 4, Pe...|\nMy life in Russia...|[{document, 0, 37...|[{document, 0, 37...|[{token, 0, 1, My...|\nJohn and Peter ar...|[{document, 0, 76...|[{document, 0, 27...|[{token, 0, 3, Jo...|\nLucas Nogal Dunbe...|[{document, 0, 67...|[{document, 0, 41...|[{token, 0, 4, Lu...|\nEurope is very cu...|[{document, 0, 68...|[{document, 0, 27...|[{token, 0, 5, Eu...|\n+--------------------+--------------------+--------------------+--------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["result.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"53306690-28e3-4bdb-a5fd-237e06920b4b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">root\n |-- text: string (nullable = true)\n |-- document: array (nullable = true)\n |    |-- element: struct (containsNull = true)\n |    |    |-- annotatorType: string (nullable = true)\n |    |    |-- begin: integer (nullable = false)\n |    |    |-- end: integer (nullable = false)\n |    |    |-- result: string (nullable = true)\n |    |    |-- metadata: map (nullable = true)\n |    |    |    |-- key: string\n |    |    |    |-- value: string (valueContainsNull = true)\n |    |    |-- embeddings: array (nullable = true)\n |    |    |    |-- element: float (containsNull = false)\n |-- sentences: array (nullable = true)\n |    |-- element: struct (containsNull = true)\n |    |    |-- annotatorType: string (nullable = true)\n |    |    |-- begin: integer (nullable = false)\n |    |    |-- end: integer (nullable = false)\n |    |    |-- result: string (nullable = true)\n |    |    |-- metadata: map (nullable = true)\n |    |    |    |-- key: string\n |    |    |    |-- value: string (valueContainsNull = true)\n |    |    |-- embeddings: array (nullable = true)\n |    |    |    |-- element: float (containsNull = false)\n |-- token: array (nullable = true)\n |    |-- element: struct (containsNull = true)\n |    |    |-- annotatorType: string (nullable = true)\n |    |    |-- begin: integer (nullable = false)\n |    |    |-- end: integer (nullable = false)\n |    |    |-- result: string (nullable = true)\n |    |    |-- metadata: map (nullable = true)\n |    |    |    |-- key: string\n |    |    |    |-- value: string (valueContainsNull = true)\n |    |    |-- embeddings: array (nullable = true)\n |    |    |    |-- element: float (containsNull = false)\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- text: string (nullable = true)\n-- document: array (nullable = true)\n    |-- element: struct (containsNull = true)\n    |    |-- annotatorType: string (nullable = true)\n    |    |-- begin: integer (nullable = false)\n    |    |-- end: integer (nullable = false)\n    |    |-- result: string (nullable = true)\n    |    |-- metadata: map (nullable = true)\n    |    |    |-- key: string\n    |    |    |-- value: string (valueContainsNull = true)\n    |    |-- embeddings: array (nullable = true)\n    |    |    |-- element: float (containsNull = false)\n-- sentences: array (nullable = true)\n    |-- element: struct (containsNull = true)\n    |    |-- annotatorType: string (nullable = true)\n    |    |-- begin: integer (nullable = false)\n    |    |-- end: integer (nullable = false)\n    |    |-- result: string (nullable = true)\n    |    |-- metadata: map (nullable = true)\n    |    |    |-- key: string\n    |    |    |-- value: string (valueContainsNull = true)\n    |    |-- embeddings: array (nullable = true)\n    |    |    |-- element: float (containsNull = false)\n-- token: array (nullable = true)\n    |-- element: struct (containsNull = true)\n    |    |-- annotatorType: string (nullable = true)\n    |    |-- begin: integer (nullable = false)\n    |    |-- end: integer (nullable = false)\n    |    |-- result: string (nullable = true)\n    |    |-- metadata: map (nullable = true)\n    |    |    |-- key: string\n    |    |    |-- value: string (valueContainsNull = true)\n    |    |-- embeddings: array (nullable = true)\n    |    |    |-- element: float (containsNull = false)\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["result.select('sentences.result').take(3)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e13d8428-17d0-40a2-a0ee-040e97856e38","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[55]: [Row(result=[&#39;Peter is a very good person.&#39;]),\n Row(result=[&#39;My life in Russia is very interesting.&#39;]),\n Row(result=[&#39;John and Peter are brothers.&#39;, &#34;However they don&#39;t support each other that much.&#34;])]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[55]: [Row(result=[&#39;Peter is a very good person.&#39;]),\n Row(result=[&#39;My life in Russia is very interesting.&#39;]),\n Row(result=[&#39;John and Peter are brothers.&#39;, &#34;However they don&#39;t support each other that much.&#34;])]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["result.select('token').take(3)[2]"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"45244802-e534-4f40-baf0-2b2f3841ce8b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[56]: Row(token=[Row(annotatorType=&#39;token&#39;, begin=0, end=3, result=&#39;John&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=5, end=7, result=&#39;and&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=9, end=13, result=&#39;Peter&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=15, end=17, result=&#39;are&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=19, end=26, result=&#39;brothers&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=27, end=27, result=&#39;.&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=29, end=35, result=&#39;However&#39;, metadata={&#39;sentence&#39;: &#39;1&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=37, end=40, result=&#39;they&#39;, metadata={&#39;sentence&#39;: &#39;1&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=42, end=46, result=&#34;don&#39;t&#34;, metadata={&#39;sentence&#39;: &#39;1&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=48, end=54, result=&#39;support&#39;, metadata={&#39;sentence&#39;: &#39;1&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=56, end=59, result=&#39;each&#39;, metadata={&#39;sentence&#39;: &#39;1&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=61, end=65, result=&#39;other&#39;, metadata={&#39;sentence&#39;: &#39;1&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=67, end=70, result=&#39;that&#39;, metadata={&#39;sentence&#39;: &#39;1&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=72, end=75, result=&#39;much&#39;, metadata={&#39;sentence&#39;: &#39;1&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=76, end=76, result=&#39;.&#39;, metadata={&#39;sentence&#39;: &#39;1&#39;}, embeddings=[])])</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[56]: Row(token=[Row(annotatorType=&#39;token&#39;, begin=0, end=3, result=&#39;John&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=5, end=7, result=&#39;and&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=9, end=13, result=&#39;Peter&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=15, end=17, result=&#39;are&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=19, end=26, result=&#39;brothers&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=27, end=27, result=&#39;.&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=29, end=35, result=&#39;However&#39;, metadata={&#39;sentence&#39;: &#39;1&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=37, end=40, result=&#39;they&#39;, metadata={&#39;sentence&#39;: &#39;1&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=42, end=46, result=&#34;don&#39;t&#34;, metadata={&#39;sentence&#39;: &#39;1&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=48, end=54, result=&#39;support&#39;, metadata={&#39;sentence&#39;: &#39;1&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=56, end=59, result=&#39;each&#39;, metadata={&#39;sentence&#39;: &#39;1&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=61, end=65, result=&#39;other&#39;, metadata={&#39;sentence&#39;: &#39;1&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=67, end=70, result=&#39;that&#39;, metadata={&#39;sentence&#39;: &#39;1&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=72, end=75, result=&#39;much&#39;, metadata={&#39;sentence&#39;: &#39;1&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=76, end=76, result=&#39;.&#39;, metadata={&#39;sentence&#39;: &#39;1&#39;}, embeddings=[])])</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Normalizer"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e2cd9251-310f-44fe-873a-c8ae690431c1","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["Removes all dirty characters from text following a regex pattern and transforms words based on a provided dictionary\n\n`setCleanupPatterns(patterns)`: Regular expressions list for normalization, defaults [^A-Za-z]\n\n`setLowercase(value)`: lowercase tokens, default false\n\n`setSlangDictionary(path)`: txt file with delimited words to be transformed into something else"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c55d1c55-69d9-480f-80e7-32103be3fcd7","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["import string\nstring.punctuation"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b33157cf-156f-4b47-a6e0-ac8a42a174ec","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[57]: &#39;!&#34;#$%&amp;\\&#39;()*+,-./:;&lt;=&gt;?@[\\\\]^_`{|}~&#39;</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[57]: &#39;!&#34;#$%&amp;\\&#39;()*+,-./:;&lt;=&gt;?@[\\\\]^_`{|}~&#39;</div>"]}}],"execution_count":0},{"cell_type":"code","source":["documentAssembler = DocumentAssembler()\\\n    .setInputCol(\"text\")\\\n    .setOutputCol(\"document\")\n\ntokenizer = Tokenizer() \\\n    .setInputCols([\"document\"]) \\\n    .setOutputCol(\"token\")\n    \nnormalizer = Normalizer() \\\n    .setInputCols([\"token\"]) \\\n    .setOutputCol(\"normalized\")\\\n    .setLowercase(True)\\\n    .setCleanupPatterns([\"[^\\w\\d\\s]\"]) # remove punctuations (keep alphanumeric chars)\n    # if we don't set CleanupPatterns, it will only keep alphabet letters ([^A-Za-z])\n\n\nnlpPipeline = Pipeline(stages=[\n     documentAssembler, \n     tokenizer,\n     normalizer])\n\nempty_df = spark.createDataFrame([['']]).toDF(\"text\")\n\npipelineModel = nlpPipeline.fit(empty_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b5bff50f-b163-4fe2-9a77-3b05661ce968","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["pipelineModel.stages"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"193245f2-2a58-440b-a8ef-1d0eee68ae9c","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[59]: [DocumentAssembler_fc63766af97a,\n REGEX_TOKENIZER_cdc1cdd0eebc,\n NORMALIZER_e63510e4430e]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[59]: [DocumentAssembler_fc63766af97a,\n REGEX_TOKENIZER_cdc1cdd0eebc,\n NORMALIZER_e63510e4430e]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["result = pipelineModel.transform(spark_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"68490423-96d4-4c14-9a6a-560a7932a945","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["result.show(truncate=20)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f7b6d42b-ea24-4e5c-b306-d14d57daa668","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+--------------------+--------------------+--------------------+--------------------+\n|                text|            document|               token|          normalized|\n+--------------------+--------------------+--------------------+--------------------+\n|Peter is a very g...|[{document, 0, 27...|[{token, 0, 4, Pe...|[{token, 0, 4, pe...|\n|My life in Russia...|[{document, 0, 37...|[{token, 0, 1, My...|[{token, 0, 1, my...|\n|John and Peter ar...|[{document, 0, 76...|[{token, 0, 3, Jo...|[{token, 0, 3, jo...|\n|Lucas Nogal Dunbe...|[{document, 0, 67...|[{token, 0, 4, Lu...|[{token, 0, 4, lu...|\n|Europe is very cu...|[{document, 0, 68...|[{token, 0, 5, Eu...|[{token, 0, 5, eu...|\n+--------------------+--------------------+--------------------+--------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+--------------------+--------------------+--------------------+\n                text|            document|               token|          normalized|\n+--------------------+--------------------+--------------------+--------------------+\nPeter is a very g...|[{document, 0, 27...|[{token, 0, 4, Pe...|[{token, 0, 4, pe...|\nMy life in Russia...|[{document, 0, 37...|[{token, 0, 1, My...|[{token, 0, 1, my...|\nJohn and Peter ar...|[{document, 0, 76...|[{token, 0, 3, Jo...|[{token, 0, 3, jo...|\nLucas Nogal Dunbe...|[{document, 0, 67...|[{token, 0, 4, Lu...|[{token, 0, 4, lu...|\nEurope is very cu...|[{document, 0, 68...|[{token, 0, 5, Eu...|[{token, 0, 5, eu...|\n+--------------------+--------------------+--------------------+--------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["result.select('token').take(3)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7c603748-1235-452c-afef-0d987622ba34","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[62]: [Row(token=[Row(annotatorType=&#39;token&#39;, begin=0, end=4, result=&#39;Peter&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=6, end=7, result=&#39;is&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=9, end=9, result=&#39;a&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=11, end=14, result=&#39;very&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=16, end=19, result=&#39;good&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=21, end=26, result=&#39;person&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=27, end=27, result=&#39;.&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[])]),\n Row(token=[Row(annotatorType=&#39;token&#39;, begin=0, end=1, result=&#39;My&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=3, end=6, result=&#39;life&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=8, end=9, result=&#39;in&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=11, end=16, result=&#39;Russia&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=18, end=19, result=&#39;is&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=21, end=24, result=&#39;very&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=26, end=36, result=&#39;interesting&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=37, end=37, result=&#39;.&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[])]),\n Row(token=[Row(annotatorType=&#39;token&#39;, begin=0, end=3, result=&#39;John&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=5, end=7, result=&#39;and&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=9, end=13, result=&#39;Peter&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=15, end=17, result=&#39;are&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=19, end=26, result=&#39;brothers&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=27, end=27, result=&#39;.&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=29, end=35, result=&#39;However&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=37, end=40, result=&#39;they&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=42, end=46, result=&#34;don&#39;t&#34;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=48, end=54, result=&#39;support&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=56, end=59, result=&#39;each&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=61, end=65, result=&#39;other&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=67, end=70, result=&#39;that&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=72, end=75, result=&#39;much&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=76, end=76, result=&#39;.&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[])])]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[62]: [Row(token=[Row(annotatorType=&#39;token&#39;, begin=0, end=4, result=&#39;Peter&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=6, end=7, result=&#39;is&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=9, end=9, result=&#39;a&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=11, end=14, result=&#39;very&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=16, end=19, result=&#39;good&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=21, end=26, result=&#39;person&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=27, end=27, result=&#39;.&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[])]),\n Row(token=[Row(annotatorType=&#39;token&#39;, begin=0, end=1, result=&#39;My&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=3, end=6, result=&#39;life&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=8, end=9, result=&#39;in&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=11, end=16, result=&#39;Russia&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=18, end=19, result=&#39;is&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=21, end=24, result=&#39;very&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=26, end=36, result=&#39;interesting&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=37, end=37, result=&#39;.&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[])]),\n Row(token=[Row(annotatorType=&#39;token&#39;, begin=0, end=3, result=&#39;John&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=5, end=7, result=&#39;and&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=9, end=13, result=&#39;Peter&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=15, end=17, result=&#39;are&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=19, end=26, result=&#39;brothers&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=27, end=27, result=&#39;.&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=29, end=35, result=&#39;However&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=37, end=40, result=&#39;they&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=42, end=46, result=&#34;don&#39;t&#34;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=48, end=54, result=&#39;support&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=56, end=59, result=&#39;each&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=61, end=65, result=&#39;other&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=67, end=70, result=&#39;that&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=72, end=75, result=&#39;much&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=76, end=76, result=&#39;.&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[])])]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["result.select('normalized.result').take(2)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"befba439-67c8-450c-b7b8-bd3e311c839e","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[63]: [Row(result=[&#39;peter&#39;, &#39;is&#39;, &#39;a&#39;, &#39;very&#39;, &#39;good&#39;, &#39;person&#39;]),\n Row(result=[&#39;my&#39;, &#39;life&#39;, &#39;in&#39;, &#39;russia&#39;, &#39;is&#39;, &#39;very&#39;, &#39;interesting&#39;])]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[63]: [Row(result=[&#39;peter&#39;, &#39;is&#39;, &#39;a&#39;, &#39;very&#39;, &#39;good&#39;, &#39;person&#39;]),\n Row(result=[&#39;my&#39;, &#39;life&#39;, &#39;in&#39;, &#39;russia&#39;, &#39;is&#39;, &#39;very&#39;, &#39;interesting&#39;])]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["result.select('normalized').take(2)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0b890b23-04b9-4b6e-8c86-139a822ecabb","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[64]: [Row(normalized=[Row(annotatorType=&#39;token&#39;, begin=0, end=4, result=&#39;peter&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=6, end=7, result=&#39;is&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=9, end=9, result=&#39;a&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=11, end=14, result=&#39;very&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=16, end=19, result=&#39;good&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=21, end=26, result=&#39;person&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[])]),\n Row(normalized=[Row(annotatorType=&#39;token&#39;, begin=0, end=1, result=&#39;my&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=3, end=6, result=&#39;life&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=8, end=9, result=&#39;in&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=11, end=16, result=&#39;russia&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=18, end=19, result=&#39;is&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=21, end=24, result=&#39;very&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=26, end=36, result=&#39;interesting&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[])])]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[64]: [Row(normalized=[Row(annotatorType=&#39;token&#39;, begin=0, end=4, result=&#39;peter&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=6, end=7, result=&#39;is&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=9, end=9, result=&#39;a&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=11, end=14, result=&#39;very&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=16, end=19, result=&#39;good&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=21, end=26, result=&#39;person&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[])]),\n Row(normalized=[Row(annotatorType=&#39;token&#39;, begin=0, end=1, result=&#39;my&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=3, end=6, result=&#39;life&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=8, end=9, result=&#39;in&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=11, end=16, result=&#39;russia&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=18, end=19, result=&#39;is&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=21, end=24, result=&#39;very&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[]), Row(annotatorType=&#39;token&#39;, begin=26, end=36, result=&#39;interesting&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[])])]</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Document Normalizer"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"73324c77-c998-4bba-9f3b-5c90292f0110","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["The DocumentNormalizer is an annotator that can be used after the DocumentAssembler to narmalize documents once that they have been processed and indexed .\nIt takes in input annotated documents of type Array AnnotatorType.DOCUMENT and gives as output annotated document of type AnnotatorType.DOCUMENT .\n\nParameters are:  \n- inputCol: input column name string which targets a column of type Array(AnnotatorType.DOCUMENT).   \n- outputCol: output column name string which targets a column of type AnnotatorType.DOCUMENT.  \n- action: action string to perform applying regex patterns, i.e. (clean | extract). Default is \"clean\".  \n- cleanupPatterns: normalization regex patterns which match will be removed from document. Default is \"<[^>]*>\" (e.g., it removes all HTML tags).  \n- replacement: replacement string to apply when regexes match. Default is \" \".  \n- lowercase: whether to convert strings to lowercase. Default is False.  \n- removalPolicy: removalPolicy to remove patterns from text with a given policy. Valid policy values are: \"all\", \"pretty_all\", \"first\", \"pretty_first\". Defaults is \"pretty_all\".  \n- encoding: file encoding to apply on normalized documents. Supported encodings are: UTF_8, UTF_16, US_ASCII, ISO-8859-1, UTF-16BE, UTF-16LE. Default is \"UTF-8\"."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b190b712-9b9d-4985-a8f5-1460f9acf6b9","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["text = '''\n  <div id=\"theworldsgreatest\" class='my-right my-hide-small my-wide toptext' style=\"font-family:'Segoe UI',Arial,sans-serif\">\n    THE WORLD'S LARGEST WEB DEVELOPER SITE\n    <h1 style=\"font-size:300%;\">THE WORLD'S LARGEST WEB DEVELOPER SITE</h1>\n    <p style=\"font-size:160%;\">Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum..</p>\n  </div>\n\n</div>'''"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7841718d-c77e-49fd-810c-43a74289c066","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["spark_df = spark.createDataFrame([[text]]).toDF(\"text\")\n\nspark_df.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9648ec65-bac0-4c6a-807a-b104400d86fe","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|\n  &lt;div id=&#34;theworldsgreatest&#34; class=&#39;my-right my-hide-small my-wide toptext&#39; style=&#34;font-family:&#39;Segoe UI&#39;,Arial,sans-serif&#34;&gt;\n    THE WORLD&#39;S LARGEST WEB DEVELOPER SITE\n    &lt;h1 style=&#34;font-size:300%;&#34;&gt;THE WORLD&#39;S LARGEST WEB DEVELOPER SITE&lt;/h1&gt;\n    &lt;p style=&#34;font-size:160%;&#34;&gt;Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry&#39;s standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum..&lt;/p&gt;\n  &lt;/div&gt;\n\n&lt;/div&gt;|\n+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\ntext                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n  &lt;div id=&#34;theworldsgreatest&#34; class=&#39;my-right my-hide-small my-wide toptext&#39; style=&#34;font-family:&#39;Segoe UI&#39;,Arial,sans-serif&#34;&gt;\n    THE WORLD&#39;S LARGEST WEB DEVELOPER SITE\n    &lt;h1 style=&#34;font-size:300%;&#34;&gt;THE WORLD&#39;S LARGEST WEB DEVELOPER SITE&lt;/h1&gt;\n    &lt;p style=&#34;font-size:160%;&#34;&gt;Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry&#39;s standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum..&lt;/p&gt;\n  &lt;/div&gt;\n\n&lt;/div&gt;|\n+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["documentNormalizer = DocumentNormalizer() \\\n    .setInputCols(\"document\") \\\n    .setOutputCol(\"normalizedDocument\")\n\ndocumentNormalizer.extractParamMap()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5ccc6e22-4075-44aa-9b7c-fbb26d063f02","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[67]: {Param(parent=&#39;DocumentNormalizer_adbdbd13bf35&#39;, name=&#39;lazyAnnotator&#39;, doc=&#39;Whether this AnnotatorModel acts as lazy in RecursivePipelines&#39;): False,\n Param(parent=&#39;DocumentNormalizer_adbdbd13bf35&#39;, name=&#39;action&#39;, doc=&#39;action to perform applying regex patterns on text&#39;): &#39;clean&#39;,\n Param(parent=&#39;DocumentNormalizer_adbdbd13bf35&#39;, name=&#39;patterns&#39;, doc=&#39;normalization regex patterns which match will be removed from document. Defaults is &lt;[^&gt;]*&gt;&#39;): [&#39;&lt;[^&gt;]*&gt;&#39;],\n Param(parent=&#39;DocumentNormalizer_adbdbd13bf35&#39;, name=&#39;replacement&#39;, doc=&#39;replacement string to apply when regexes match&#39;): &#39; &#39;,\n Param(parent=&#39;DocumentNormalizer_adbdbd13bf35&#39;, name=&#39;lowercase&#39;, doc=&#39;whether to convert strings to lowercase&#39;): False,\n Param(parent=&#39;DocumentNormalizer_adbdbd13bf35&#39;, name=&#39;policy&#39;, doc=&#39;policy to remove pattern from text&#39;): &#39;pretty_all&#39;,\n Param(parent=&#39;DocumentNormalizer_adbdbd13bf35&#39;, name=&#39;encoding&#39;, doc=&#39;file encoding to apply on normalized documents&#39;): &#39;UTF-8&#39;,\n Param(parent=&#39;DocumentNormalizer_adbdbd13bf35&#39;, name=&#39;inputCols&#39;, doc=&#39;previous annotations columns, if renamed&#39;): [&#39;document&#39;],\n Param(parent=&#39;DocumentNormalizer_adbdbd13bf35&#39;, name=&#39;outputCol&#39;, doc=&#39;output annotation column. can be left default.&#39;): &#39;normalizedDocument&#39;}</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[67]: {Param(parent=&#39;DocumentNormalizer_adbdbd13bf35&#39;, name=&#39;lazyAnnotator&#39;, doc=&#39;Whether this AnnotatorModel acts as lazy in RecursivePipelines&#39;): False,\n Param(parent=&#39;DocumentNormalizer_adbdbd13bf35&#39;, name=&#39;action&#39;, doc=&#39;action to perform applying regex patterns on text&#39;): &#39;clean&#39;,\n Param(parent=&#39;DocumentNormalizer_adbdbd13bf35&#39;, name=&#39;patterns&#39;, doc=&#39;normalization regex patterns which match will be removed from document. Defaults is &lt;[^&gt;]*&gt;&#39;): [&#39;&lt;[^&gt;]*&gt;&#39;],\n Param(parent=&#39;DocumentNormalizer_adbdbd13bf35&#39;, name=&#39;replacement&#39;, doc=&#39;replacement string to apply when regexes match&#39;): &#39; &#39;,\n Param(parent=&#39;DocumentNormalizer_adbdbd13bf35&#39;, name=&#39;lowercase&#39;, doc=&#39;whether to convert strings to lowercase&#39;): False,\n Param(parent=&#39;DocumentNormalizer_adbdbd13bf35&#39;, name=&#39;policy&#39;, doc=&#39;policy to remove pattern from text&#39;): &#39;pretty_all&#39;,\n Param(parent=&#39;DocumentNormalizer_adbdbd13bf35&#39;, name=&#39;encoding&#39;, doc=&#39;file encoding to apply on normalized documents&#39;): &#39;UTF-8&#39;,\n Param(parent=&#39;DocumentNormalizer_adbdbd13bf35&#39;, name=&#39;inputCols&#39;, doc=&#39;previous annotations columns, if renamed&#39;): [&#39;document&#39;],\n Param(parent=&#39;DocumentNormalizer_adbdbd13bf35&#39;, name=&#39;outputCol&#39;, doc=&#39;output annotation column. can be left default.&#39;): &#39;normalizedDocument&#39;}</div>"]}}],"execution_count":0},{"cell_type":"code","source":["documentAssembler = DocumentAssembler() \\\n    .setInputCol('text') \\\n    .setOutputCol('document')\n\n#default\ncleanUpPatterns = [\"<[^>]*>\"]\n\ndocumentNormalizer = DocumentNormalizer() \\\n    .setInputCols(\"document\") \\\n    .setOutputCol(\"normalizedDocument\") \\\n    .setAction(\"clean\") \\\n    .setPatterns(cleanUpPatterns) \\\n    .setReplacement(\" \") \\\n    .setPolicy(\"pretty_all\") \\\n    .setLowercase(True)\n\ndocPatternRemoverPipeline = Pipeline() \\\n    .setStages([\n        documentAssembler,\n        documentNormalizer])\n    \n\npipelineModel = docPatternRemoverPipeline.fit(spark_df).transform(spark_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0fb4fda8-30b0-4512-84b0-93e37d72a29c","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["pipelineModel.select('normalizedDocument.result').show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c31adf33-a2c1-4849-9430-906a00ab9735","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|result                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|[ the world&#39;s largest web developer site the world&#39;s largest web developer site lorem ipsum is simply dummy text of the printing and typesetting industry. lorem ipsum has been the industry&#39;s standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. it has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. it was popularised in the 1960s with the release of letraset sheets containing lorem ipsum passages, and more recently with desktop publishing software like aldus pagemaker including versions of lorem ipsum..]|\n+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\nresult                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n[ the world&#39;s largest web developer site the world&#39;s largest web developer site lorem ipsum is simply dummy text of the printing and typesetting industry. lorem ipsum has been the industry&#39;s standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. it has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. it was popularised in the 1960s with the release of letraset sheets containing lorem ipsum passages, and more recently with desktop publishing software like aldus pagemaker including versions of lorem ipsum..]|\n+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["for more examples : https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/annotation/english/document-normalizer/document_normalizer_notebook.ipynb"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"df4f86a8-383c-4bb4-a2cf-c745863498b5","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["## Stopwords Cleaner"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f5df9b65-c8ac-44f9-af68-1b9de1a9df7b","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["This annotator excludes from a sequence of strings (e.g. the output of a Tokenizer, Normalizer, Lemmatizer, and Stemmer) and drops all the stop words from the input sequences."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5f8d048a-296c-45e7-a7f2-ab169a28674f","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["Functions:\n\n`setStopWords`: The words to be filtered out. Array[String]\n\n`setCaseSensitive`: Whether to do a case sensitive comparison over the stop words."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"139001f8-51d6-4f59-aa43-c61219cb5c9e","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["stopwords_cleaner = StopWordsCleaner()\\\n      .setInputCols(\"token\")\\\n      .setOutputCol(\"cleanTokens\")\\\n      .setCaseSensitive(False)\\\n      #.setStopWords([\"no\", \"without\"]) (e.g. read a list of words from a txt)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9b4ac841-174f-4949-b3c8-7598aec661d4","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["stopwords_cleaner.getStopWords()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6bb1fc7c-4fdb-4e92-9bc3-f62ce004cd26","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[71]: [&#39;i&#39;,\n &#39;me&#39;,\n &#39;my&#39;,\n &#39;myself&#39;,\n &#39;we&#39;,\n &#39;our&#39;,\n &#39;ours&#39;,\n &#39;ourselves&#39;,\n &#39;you&#39;,\n &#39;your&#39;,\n &#39;yours&#39;,\n &#39;yourself&#39;,\n &#39;yourselves&#39;,\n &#39;he&#39;,\n &#39;him&#39;,\n &#39;his&#39;,\n &#39;himself&#39;,\n &#39;she&#39;,\n &#39;her&#39;,\n &#39;hers&#39;,\n &#39;herself&#39;,\n &#39;it&#39;,\n &#39;its&#39;,\n &#39;itself&#39;,\n &#39;they&#39;,\n &#39;them&#39;,\n &#39;their&#39;,\n &#39;theirs&#39;,\n &#39;themselves&#39;,\n &#39;what&#39;,\n &#39;which&#39;,\n &#39;who&#39;,\n &#39;whom&#39;,\n &#39;this&#39;,\n &#39;that&#39;,\n &#39;these&#39;,\n &#39;those&#39;,\n &#39;am&#39;,\n &#39;is&#39;,\n &#39;are&#39;,\n &#39;was&#39;,\n &#39;were&#39;,\n &#39;be&#39;,\n &#39;been&#39;,\n &#39;being&#39;,\n &#39;have&#39;,\n &#39;has&#39;,\n &#39;had&#39;,\n &#39;having&#39;,\n &#39;do&#39;,\n &#39;does&#39;,\n &#39;did&#39;,\n &#39;doing&#39;,\n &#39;a&#39;,\n &#39;an&#39;,\n &#39;the&#39;,\n &#39;and&#39;,\n &#39;but&#39;,\n &#39;if&#39;,\n &#39;or&#39;,\n &#39;because&#39;,\n &#39;as&#39;,\n &#39;until&#39;,\n &#39;while&#39;,\n &#39;of&#39;,\n &#39;at&#39;,\n &#39;by&#39;,\n &#39;for&#39;,\n &#39;with&#39;,\n &#39;about&#39;,\n &#39;against&#39;,\n &#39;between&#39;,\n &#39;into&#39;,\n &#39;through&#39;,\n &#39;during&#39;,\n &#39;before&#39;,\n &#39;after&#39;,\n &#39;above&#39;,\n &#39;below&#39;,\n &#39;to&#39;,\n &#39;from&#39;,\n &#39;up&#39;,\n &#39;down&#39;,\n &#39;in&#39;,\n &#39;out&#39;,\n &#39;on&#39;,\n &#39;off&#39;,\n &#39;over&#39;,\n &#39;under&#39;,\n &#39;again&#39;,\n &#39;further&#39;,\n &#39;then&#39;,\n &#39;once&#39;,\n &#39;here&#39;,\n &#39;there&#39;,\n &#39;when&#39;,\n &#39;where&#39;,\n &#39;why&#39;,\n &#39;how&#39;,\n &#39;all&#39;,\n &#39;any&#39;,\n &#39;both&#39;,\n &#39;each&#39;,\n &#39;few&#39;,\n &#39;more&#39;,\n &#39;most&#39;,\n &#39;other&#39;,\n &#39;some&#39;,\n &#39;such&#39;,\n &#39;no&#39;,\n &#39;nor&#39;,\n &#39;not&#39;,\n &#39;only&#39;,\n &#39;own&#39;,\n &#39;same&#39;,\n &#39;so&#39;,\n &#39;than&#39;,\n &#39;too&#39;,\n &#39;very&#39;,\n &#39;s&#39;,\n &#39;t&#39;,\n &#39;can&#39;,\n &#39;will&#39;,\n &#39;just&#39;,\n &#39;don&#39;,\n &#39;should&#39;,\n &#39;now&#39;,\n &#34;i&#39;ll&#34;,\n &#34;you&#39;ll&#34;,\n &#34;he&#39;ll&#34;,\n &#34;she&#39;ll&#34;,\n &#34;we&#39;ll&#34;,\n &#34;they&#39;ll&#34;,\n &#34;i&#39;d&#34;,\n &#34;you&#39;d&#34;,\n &#34;he&#39;d&#34;,\n &#34;she&#39;d&#34;,\n &#34;we&#39;d&#34;,\n &#34;they&#39;d&#34;,\n &#34;i&#39;m&#34;,\n &#34;you&#39;re&#34;,\n &#34;he&#39;s&#34;,\n &#34;she&#39;s&#34;,\n &#34;it&#39;s&#34;,\n &#34;we&#39;re&#34;,\n &#34;they&#39;re&#34;,\n &#34;i&#39;ve&#34;,\n &#34;we&#39;ve&#34;,\n &#34;you&#39;ve&#34;,\n &#34;they&#39;ve&#34;,\n &#34;isn&#39;t&#34;,\n &#34;aren&#39;t&#34;,\n &#34;wasn&#39;t&#34;,\n &#34;weren&#39;t&#34;,\n &#34;haven&#39;t&#34;,\n &#34;hasn&#39;t&#34;,\n &#34;hadn&#39;t&#34;,\n &#34;don&#39;t&#34;,\n &#34;doesn&#39;t&#34;,\n &#34;didn&#39;t&#34;,\n &#34;won&#39;t&#34;,\n &#34;wouldn&#39;t&#34;,\n &#34;shan&#39;t&#34;,\n &#34;shouldn&#39;t&#34;,\n &#34;mustn&#39;t&#34;,\n &#34;can&#39;t&#34;,\n &#34;couldn&#39;t&#34;,\n &#39;cannot&#39;,\n &#39;could&#39;,\n &#34;here&#39;s&#34;,\n &#34;how&#39;s&#34;,\n &#34;let&#39;s&#34;,\n &#39;ought&#39;,\n &#34;that&#39;s&#34;,\n &#34;there&#39;s&#34;,\n &#34;what&#39;s&#34;,\n &#34;when&#39;s&#34;,\n &#34;where&#39;s&#34;,\n &#34;who&#39;s&#34;,\n &#34;why&#39;s&#34;,\n &#39;would&#39;]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[71]: [&#39;i&#39;,\n &#39;me&#39;,\n &#39;my&#39;,\n &#39;myself&#39;,\n &#39;we&#39;,\n &#39;our&#39;,\n &#39;ours&#39;,\n &#39;ourselves&#39;,\n &#39;you&#39;,\n &#39;your&#39;,\n &#39;yours&#39;,\n &#39;yourself&#39;,\n &#39;yourselves&#39;,\n &#39;he&#39;,\n &#39;him&#39;,\n &#39;his&#39;,\n &#39;himself&#39;,\n &#39;she&#39;,\n &#39;her&#39;,\n &#39;hers&#39;,\n &#39;herself&#39;,\n &#39;it&#39;,\n &#39;its&#39;,\n &#39;itself&#39;,\n &#39;they&#39;,\n &#39;them&#39;,\n &#39;their&#39;,\n &#39;theirs&#39;,\n &#39;themselves&#39;,\n &#39;what&#39;,\n &#39;which&#39;,\n &#39;who&#39;,\n &#39;whom&#39;,\n &#39;this&#39;,\n &#39;that&#39;,\n &#39;these&#39;,\n &#39;those&#39;,\n &#39;am&#39;,\n &#39;is&#39;,\n &#39;are&#39;,\n &#39;was&#39;,\n &#39;were&#39;,\n &#39;be&#39;,\n &#39;been&#39;,\n &#39;being&#39;,\n &#39;have&#39;,\n &#39;has&#39;,\n &#39;had&#39;,\n &#39;having&#39;,\n &#39;do&#39;,\n &#39;does&#39;,\n &#39;did&#39;,\n &#39;doing&#39;,\n &#39;a&#39;,\n &#39;an&#39;,\n &#39;the&#39;,\n &#39;and&#39;,\n &#39;but&#39;,\n &#39;if&#39;,\n &#39;or&#39;,\n &#39;because&#39;,\n &#39;as&#39;,\n &#39;until&#39;,\n &#39;while&#39;,\n &#39;of&#39;,\n &#39;at&#39;,\n &#39;by&#39;,\n &#39;for&#39;,\n &#39;with&#39;,\n &#39;about&#39;,\n &#39;against&#39;,\n &#39;between&#39;,\n &#39;into&#39;,\n &#39;through&#39;,\n &#39;during&#39;,\n &#39;before&#39;,\n &#39;after&#39;,\n &#39;above&#39;,\n &#39;below&#39;,\n &#39;to&#39;,\n &#39;from&#39;,\n &#39;up&#39;,\n &#39;down&#39;,\n &#39;in&#39;,\n &#39;out&#39;,\n &#39;on&#39;,\n &#39;off&#39;,\n &#39;over&#39;,\n &#39;under&#39;,\n &#39;again&#39;,\n &#39;further&#39;,\n &#39;then&#39;,\n &#39;once&#39;,\n &#39;here&#39;,\n &#39;there&#39;,\n &#39;when&#39;,\n &#39;where&#39;,\n &#39;why&#39;,\n &#39;how&#39;,\n &#39;all&#39;,\n &#39;any&#39;,\n &#39;both&#39;,\n &#39;each&#39;,\n &#39;few&#39;,\n &#39;more&#39;,\n &#39;most&#39;,\n &#39;other&#39;,\n &#39;some&#39;,\n &#39;such&#39;,\n &#39;no&#39;,\n &#39;nor&#39;,\n &#39;not&#39;,\n &#39;only&#39;,\n &#39;own&#39;,\n &#39;same&#39;,\n &#39;so&#39;,\n &#39;than&#39;,\n &#39;too&#39;,\n &#39;very&#39;,\n &#39;s&#39;,\n &#39;t&#39;,\n &#39;can&#39;,\n &#39;will&#39;,\n &#39;just&#39;,\n &#39;don&#39;,\n &#39;should&#39;,\n &#39;now&#39;,\n &#34;i&#39;ll&#34;,\n &#34;you&#39;ll&#34;,\n &#34;he&#39;ll&#34;,\n &#34;she&#39;ll&#34;,\n &#34;we&#39;ll&#34;,\n &#34;they&#39;ll&#34;,\n &#34;i&#39;d&#34;,\n &#34;you&#39;d&#34;,\n &#34;he&#39;d&#34;,\n &#34;she&#39;d&#34;,\n &#34;we&#39;d&#34;,\n &#34;they&#39;d&#34;,\n &#34;i&#39;m&#34;,\n &#34;you&#39;re&#34;,\n &#34;he&#39;s&#34;,\n &#34;she&#39;s&#34;,\n &#34;it&#39;s&#34;,\n &#34;we&#39;re&#34;,\n &#34;they&#39;re&#34;,\n &#34;i&#39;ve&#34;,\n &#34;we&#39;ve&#34;,\n &#34;you&#39;ve&#34;,\n &#34;they&#39;ve&#34;,\n &#34;isn&#39;t&#34;,\n &#34;aren&#39;t&#34;,\n &#34;wasn&#39;t&#34;,\n &#34;weren&#39;t&#34;,\n &#34;haven&#39;t&#34;,\n &#34;hasn&#39;t&#34;,\n &#34;hadn&#39;t&#34;,\n &#34;don&#39;t&#34;,\n &#34;doesn&#39;t&#34;,\n &#34;didn&#39;t&#34;,\n &#34;won&#39;t&#34;,\n &#34;wouldn&#39;t&#34;,\n &#34;shan&#39;t&#34;,\n &#34;shouldn&#39;t&#34;,\n &#34;mustn&#39;t&#34;,\n &#34;can&#39;t&#34;,\n &#34;couldn&#39;t&#34;,\n &#39;cannot&#39;,\n &#39;could&#39;,\n &#34;here&#39;s&#34;,\n &#34;how&#39;s&#34;,\n &#34;let&#39;s&#34;,\n &#39;ought&#39;,\n &#34;that&#39;s&#34;,\n &#34;there&#39;s&#34;,\n &#34;what&#39;s&#34;,\n &#34;when&#39;s&#34;,\n &#34;where&#39;s&#34;,\n &#34;who&#39;s&#34;,\n &#34;why&#39;s&#34;,\n &#39;would&#39;]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["documentAssembler = DocumentAssembler()\\\n      .setInputCol(\"text\")\\\n      .setOutputCol(\"document\")\n\ntokenizer = Tokenizer() \\\n      .setInputCols([\"document\"]) \\\n      .setOutputCol(\"token\")\n\nstopwords_cleaner = StopWordsCleaner()\\\n      .setInputCols(\"token\")\\\n      .setOutputCol(\"cleanTokens\")\\\n      .setCaseSensitive(False)\\\n\nnlpPipeline = Pipeline(stages=[\n documentAssembler, \n tokenizer,\n stopwords_cleaner\n ])\n\nspark_df = spark.read.text('/sample-sentences-en.txt').toDF('text')\n\nresult = nlpPipeline.fit(spark_df).transform(spark_df)\n\nresult.show(40)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"752d0ab1-4969-4caf-810c-772f522f8903","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+--------------------+--------------------+--------------------+--------------------+\n|                text|            document|               token|         cleanTokens|\n+--------------------+--------------------+--------------------+--------------------+\n|Peter is a very g...|[{document, 0, 27...|[{token, 0, 4, Pe...|[{token, 0, 4, Pe...|\n|My life in Russia...|[{document, 0, 37...|[{token, 0, 1, My...|[{token, 3, 6, li...|\n|John and Peter ar...|[{document, 0, 76...|[{token, 0, 3, Jo...|[{token, 0, 3, Jo...|\n|Lucas Nogal Dunbe...|[{document, 0, 67...|[{token, 0, 4, Lu...|[{token, 0, 4, Lu...|\n|Europe is very cu...|[{document, 0, 68...|[{token, 0, 5, Eu...|[{token, 0, 5, Eu...|\n+--------------------+--------------------+--------------------+--------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+--------------------+--------------------+--------------------+\n                text|            document|               token|         cleanTokens|\n+--------------------+--------------------+--------------------+--------------------+\nPeter is a very g...|[{document, 0, 27...|[{token, 0, 4, Pe...|[{token, 0, 4, Pe...|\nMy life in Russia...|[{document, 0, 37...|[{token, 0, 1, My...|[{token, 3, 6, li...|\nJohn and Peter ar...|[{document, 0, 76...|[{token, 0, 3, Jo...|[{token, 0, 3, Jo...|\nLucas Nogal Dunbe...|[{document, 0, 67...|[{token, 0, 4, Lu...|[{token, 0, 4, Lu...|\nEurope is very cu...|[{document, 0, 68...|[{token, 0, 5, Eu...|[{token, 0, 5, Eu...|\n+--------------------+--------------------+--------------------+--------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["result.select('cleanTokens.result').take(1)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9289b548-8516-4576-a13a-f13e0ebed5e9","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[73]: [Row(result=[&#39;Peter&#39;, &#39;good&#39;, &#39;person&#39;, &#39;.&#39;])]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[73]: [Row(result=[&#39;Peter&#39;, &#39;good&#39;, &#39;person&#39;, &#39;.&#39;])]</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Token Assembler"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4eaf8d13-a400-4836-908f-86c6ef7042a2","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["documentAssembler = DocumentAssembler()\\\n    .setInputCol(\"text\")\\\n    .setOutputCol(\"document\")\n\nsentenceDetector = SentenceDetector()\\\n    .setInputCols(['document'])\\\n    .setOutputCol('sentences')\n\ntokenizer = Tokenizer() \\\n    .setInputCols([\"sentences\"]) \\\n    .setOutputCol(\"token\")\n\nnormalizer = Normalizer() \\\n    .setInputCols([\"token\"]) \\\n    .setOutputCol(\"normalized\")\\\n    .setLowercase(False)\\\n\nstopwords_cleaner = StopWordsCleaner()\\\n    .setInputCols(\"normalized\")\\\n    .setOutputCol(\"cleanTokens\")\\\n    .setCaseSensitive(False)\\\n\ntokenassembler = TokenAssembler()\\\n    .setInputCols([\"sentences\", \"cleanTokens\"]) \\\n    .setOutputCol(\"clean_text\")\n\n\nnlpPipeline = Pipeline(stages=[\n     documentAssembler,\n     sentenceDetector,\n     tokenizer,\n     normalizer,\n     stopwords_cleaner,\n     tokenassembler\n ])\n\nresult = nlpPipeline.fit(spark_df).transform(spark_df)\n\nresult.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d8190cdf-30da-4013-9e17-75302b66d086","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n|                text|            document|           sentences|               token|          normalized|         cleanTokens|          clean_text|\n+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n|Peter is a very g...|[{document, 0, 27...|[{document, 0, 27...|[{token, 0, 4, Pe...|[{token, 0, 4, Pe...|[{token, 0, 4, Pe...|[{document, 0, 16...|\n|My life in Russia...|[{document, 0, 37...|[{document, 0, 37...|[{token, 0, 1, My...|[{token, 0, 1, My...|[{token, 3, 6, li...|[{document, 0, 22...|\n|John and Peter ar...|[{document, 0, 76...|[{document, 0, 27...|[{token, 0, 3, Jo...|[{token, 0, 3, Jo...|[{token, 0, 3, Jo...|[{document, 0, 18...|\n|Lucas Nogal Dunbe...|[{document, 0, 67...|[{document, 0, 41...|[{token, 0, 4, Lu...|[{token, 0, 4, Lu...|[{token, 0, 4, Lu...|[{document, 0, 34...|\n|Europe is very cu...|[{document, 0, 68...|[{document, 0, 27...|[{token, 0, 5, Eu...|[{token, 0, 5, Eu...|[{token, 0, 5, Eu...|[{document, 0, 18...|\n+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n                text|            document|           sentences|               token|          normalized|         cleanTokens|          clean_text|\n+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\nPeter is a very g...|[{document, 0, 27...|[{document, 0, 27...|[{token, 0, 4, Pe...|[{token, 0, 4, Pe...|[{token, 0, 4, Pe...|[{document, 0, 16...|\nMy life in Russia...|[{document, 0, 37...|[{document, 0, 37...|[{token, 0, 1, My...|[{token, 0, 1, My...|[{token, 3, 6, li...|[{document, 0, 22...|\nJohn and Peter ar...|[{document, 0, 76...|[{document, 0, 27...|[{token, 0, 3, Jo...|[{token, 0, 3, Jo...|[{token, 0, 3, Jo...|[{document, 0, 18...|\nLucas Nogal Dunbe...|[{document, 0, 67...|[{document, 0, 41...|[{token, 0, 4, Lu...|[{token, 0, 4, Lu...|[{token, 0, 4, Lu...|[{document, 0, 34...|\nEurope is very cu...|[{document, 0, 68...|[{document, 0, 27...|[{token, 0, 5, Eu...|[{token, 0, 5, Eu...|[{token, 0, 5, Eu...|[{document, 0, 18...|\n+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["result.select('clean_text').take(1)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c851e449-96da-4ec9-847e-efed42b1a699","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[75]: [Row(clean_text=[Row(annotatorType=&#39;document&#39;, begin=0, end=16, result=&#39;Peter good person&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[])])]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[75]: [Row(clean_text=[Row(annotatorType=&#39;document&#39;, begin=0, end=16, result=&#39;Peter good person&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[])])]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# if we use TokenAssembler().setPreservePosition(True), the original borders will be preserved (dropped & unwanted chars will be replaced by spaces)\n\nresult.select('clean_text').take(1)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f4e39abd-85ba-46ca-b846-95b789c13f9c","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[76]: [Row(clean_text=[Row(annotatorType=&#39;document&#39;, begin=0, end=16, result=&#39;Peter good person&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[])])]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[76]: [Row(clean_text=[Row(annotatorType=&#39;document&#39;, begin=0, end=16, result=&#39;Peter good person&#39;, metadata={&#39;sentence&#39;: &#39;0&#39;}, embeddings=[])])]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["result.select('text', F.explode('clean_text.result').alias('clean_text')).show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6b147593-8c32-4d5f-b7c8-b1bc3a6bc121","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-----------------------------------------------------------------------------+-----------------------------------+\n|text                                                                         |clean_text                         |\n+-----------------------------------------------------------------------------+-----------------------------------+\n|Peter is a very good person.                                                 |Peter good person                  |\n|My life in Russia is very interesting.                                       |life Russia interesting            |\n|John and Peter are brothers. However they don&#39;t support each other that much.|John Peter brothers                |\n|John and Peter are brothers. However they don&#39;t support each other that much.|However dont support much          |\n|Lucas Nogal Dunbercker is no longer happy. He has a good car though.         |Lucas Nogal Dunbercker longer happy|\n|Lucas Nogal Dunbercker is no longer happy. He has a good car though.         |good car though                    |\n|Europe is very culture rich. There are huge churches! and big houses!        |Europe culture rich                |\n|Europe is very culture rich. There are huge churches! and big houses!        |huge churches                      |\n|Europe is very culture rich. There are huge churches! and big houses!        |big houses                         |\n+-----------------------------------------------------------------------------+-----------------------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------------------------------------------------------------------------+-----------------------------------+\ntext                                                                         |clean_text                         |\n+-----------------------------------------------------------------------------+-----------------------------------+\nPeter is a very good person.                                                 |Peter good person                  |\nMy life in Russia is very interesting.                                       |life Russia interesting            |\nJohn and Peter are brothers. However they don&#39;t support each other that much.|John Peter brothers                |\nJohn and Peter are brothers. However they don&#39;t support each other that much.|However dont support much          |\nLucas Nogal Dunbercker is no longer happy. He has a good car though.         |Lucas Nogal Dunbercker longer happy|\nLucas Nogal Dunbercker is no longer happy. He has a good car though.         |good car though                    |\nEurope is very culture rich. There are huge churches! and big houses!        |Europe culture rich                |\nEurope is very culture rich. There are huge churches! and big houses!        |huge churches                      |\nEurope is very culture rich. There are huge churches! and big houses!        |big houses                         |\n+-----------------------------------------------------------------------------+-----------------------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["import pyspark.sql.functions as F\n\nresult.withColumn(\n    \"tmp\", \n    F.explode(\"clean_text\")) \\\n    .select(\"tmp.*\").select(\"begin\",\"end\",\"result\",\"metadata.sentence\").show(truncate = False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b2c25178-daf8-4a24-9142-ffbd48e70377","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-----+---+-----------------------------------+--------+\n|begin|end|result                             |sentence|\n+-----+---+-----------------------------------+--------+\n|0    |16 |Peter good person                  |0       |\n|0    |22 |life Russia interesting            |0       |\n|0    |18 |John Peter brothers                |0       |\n|29   |53 |However dont support much          |1       |\n|0    |34 |Lucas Nogal Dunbercker longer happy|0       |\n|43   |57 |good car though                    |1       |\n|0    |18 |Europe culture rich                |0       |\n|29   |41 |huge churches                      |1       |\n|54   |63 |big houses                         |2       |\n+-----+---+-----------------------------------+--------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+---+-----------------------------------+--------+\nbegin|end|result                             |sentence|\n+-----+---+-----------------------------------+--------+\n0    |16 |Peter good person                  |0       |\n0    |22 |life Russia interesting            |0       |\n0    |18 |John Peter brothers                |0       |\n29   |53 |However dont support much          |1       |\n0    |34 |Lucas Nogal Dunbercker longer happy|0       |\n43   |57 |good car though                    |1       |\n0    |18 |Europe culture rich                |0       |\n29   |41 |huge churches                      |1       |\n54   |63 |big houses                         |2       |\n+-----+---+-----------------------------------+--------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["result.select('text', F.explode('clean_text.result').alias('clean_text')).toPandas()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0ac98e0a-a1b9-4167-89dd-f7531dfa6e73","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[79]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[79]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>clean_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Peter is a very good person.</td>\n      <td>Peter good person</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>My life in Russia is very interesting.</td>\n      <td>life Russia interesting</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>John and Peter are brothers. However they don'...</td>\n      <td>John Peter brothers</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>John and Peter are brothers. However they don'...</td>\n      <td>However dont support much</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Lucas Nogal Dunbercker is no longer happy. He ...</td>\n      <td>Lucas Nogal Dunbercker longer happy</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Lucas Nogal Dunbercker is no longer happy. He ...</td>\n      <td>good car though</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Europe is very culture rich. There are huge ch...</td>\n      <td>Europe culture rich</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Europe is very culture rich. There are huge ch...</td>\n      <td>huge churches</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Europe is very culture rich. There are huge ch...</td>\n      <td>big houses</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>clean_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Peter is a very good person.</td>\n      <td>Peter good person</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>My life in Russia is very interesting.</td>\n      <td>life Russia interesting</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>John and Peter are brothers. However they don'...</td>\n      <td>John Peter brothers</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>John and Peter are brothers. However they don'...</td>\n      <td>However dont support much</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Lucas Nogal Dunbercker is no longer happy. He ...</td>\n      <td>Lucas Nogal Dunbercker longer happy</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Lucas Nogal Dunbercker is no longer happy. He ...</td>\n      <td>good car though</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Europe is very culture rich. There are huge ch...</td>\n      <td>Europe culture rich</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Europe is very culture rich. There are huge ch...</td>\n      <td>huge churches</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Europe is very culture rich. There are huge ch...</td>\n      <td>big houses</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# if we hadn't used Sentence Detector, this would be what we got. (tokenizer gets document instead of sentences column)\n\ntokenizer = Tokenizer() \\\n    .setInputCols([\"document\"]) \\\n    .setOutputCol(\"token\")\n\ntokenassembler = TokenAssembler()\\\n    .setInputCols([\"document\", \"cleanTokens\"]) \\\n    .setOutputCol(\"clean_text\")\n\nnlpPipeline = Pipeline(stages=[\n     documentAssembler,\n     tokenizer,\n     normalizer,\n     stopwords_cleaner,\n     tokenassembler\n ])\n\nempty_df = spark.createDataFrame([['']]).toDF(\"text\")\n\npipelineModel = nlpPipeline.fit(empty_df)\n\nresult = pipelineModel.transform(spark_df)\n\nresult.select('text', 'clean_text.result').show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b64bbe0f-2796-461c-acc8-dda7a8206785","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-----------------------------------------------------------------------------+-----------------------------------------------------+\n|text                                                                         |result                                               |\n+-----------------------------------------------------------------------------+-----------------------------------------------------+\n|Peter is a very good person.                                                 |[Peter good person]                                  |\n|My life in Russia is very interesting.                                       |[life Russia interesting]                            |\n|John and Peter are brothers. However they don&#39;t support each other that much.|[John Peter brothers However dont support much]      |\n|Lucas Nogal Dunbercker is no longer happy. He has a good car though.         |[Lucas Nogal Dunbercker longer happy good car though]|\n|Europe is very culture rich. There are huge churches! and big houses!        |[Europe culture rich huge churches big houses]       |\n+-----------------------------------------------------------------------------+-----------------------------------------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------------------------------------------------------------------------+-----------------------------------------------------+\ntext                                                                         |result                                               |\n+-----------------------------------------------------------------------------+-----------------------------------------------------+\nPeter is a very good person.                                                 |[Peter good person]                                  |\nMy life in Russia is very interesting.                                       |[life Russia interesting]                            |\nJohn and Peter are brothers. However they don&#39;t support each other that much.|[John Peter brothers However dont support much]      |\nLucas Nogal Dunbercker is no longer happy. He has a good car though.         |[Lucas Nogal Dunbercker longer happy good car though]|\nEurope is very culture rich. There are huge churches! and big houses!        |[Europe culture rich huge churches big houses]       |\n+-----------------------------------------------------------------------------+-----------------------------------------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["result.withColumn(\n    \"tmp\", \n    F.explode(\"clean_text\")) \\\n    .select(\"tmp.*\").select(\"begin\",\"end\",\"result\",\"metadata.sentence\").show(truncate = False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"bd67a439-994b-4129-a404-ae938f67dfba","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-----+---+---------------------------------------------------+--------+\n|begin|end|result                                             |sentence|\n+-----+---+---------------------------------------------------+--------+\n|0    |16 |Peter good person                                  |0       |\n|0    |22 |life Russia interesting                            |0       |\n|0    |44 |John Peter brothers However dont support much      |0       |\n|0    |50 |Lucas Nogal Dunbercker longer happy good car though|0       |\n|0    |43 |Europe culture rich huge churches big houses       |0       |\n+-----+---+---------------------------------------------------+--------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+---+---------------------------------------------------+--------+\nbegin|end|result                                             |sentence|\n+-----+---+---------------------------------------------------+--------+\n0    |16 |Peter good person                                  |0       |\n0    |22 |life Russia interesting                            |0       |\n0    |44 |John Peter brothers However dont support much      |0       |\n0    |50 |Lucas Nogal Dunbercker longer happy good car though|0       |\n0    |43 |Europe culture rich huge churches big houses       |0       |\n+-----+---+---------------------------------------------------+--------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["**IMPORTANT NOTE:**\n\nIf you have some other steps & annotators in your pipeline that will need to use the tokens from cleaned text (assembled tokens), you will need to tokenize the processed text again as the original text is probably changed completely."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"61ea7dad-7090-4972-ad9b-0760aefc10fa","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["## Stemmer"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2c97f60c-d34d-4f46-8a6c-171bbed12917","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["Returns hard-stems out of words with the objective of retrieving the meaningful part of the word"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"da6e00c8-7673-4dfb-9f17-24234bbe79d1","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["stemmer = Stemmer() \\\n    .setInputCols([\"token\"]) \\\n    .setOutputCol(\"stem\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"955e8d19-b379-438c-a6a0-b25691c58341","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["documentAssembler = DocumentAssembler()\\\n    .setInputCol(\"text\")\\\n    .setOutputCol(\"document\")\n\ntokenizer = Tokenizer() \\\n    .setInputCols([\"document\"]) \\\n    .setOutputCol(\"token\")\n\nnlpPipeline = Pipeline(stages=[\n     documentAssembler, \n     tokenizer,\n     stemmer\n ])\n\nresult = nlpPipeline.fit(spark_df).transform(spark_df)\n\nresult.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a018531d-aeb0-49fb-b250-2870ebfbac3a","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+--------------------+--------------------+--------------------+--------------------+\n|                text|            document|               token|                stem|\n+--------------------+--------------------+--------------------+--------------------+\n|Peter is a very g...|[{document, 0, 27...|[{token, 0, 4, Pe...|[{token, 0, 4, pe...|\n|My life in Russia...|[{document, 0, 37...|[{token, 0, 1, My...|[{token, 0, 1, my...|\n|John and Peter ar...|[{document, 0, 76...|[{token, 0, 3, Jo...|[{token, 0, 3, jo...|\n|Lucas Nogal Dunbe...|[{document, 0, 67...|[{token, 0, 4, Lu...|[{token, 0, 4, lu...|\n|Europe is very cu...|[{document, 0, 68...|[{token, 0, 5, Eu...|[{token, 0, 5, eu...|\n+--------------------+--------------------+--------------------+--------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+--------------------+--------------------+--------------------+\n                text|            document|               token|                stem|\n+--------------------+--------------------+--------------------+--------------------+\nPeter is a very g...|[{document, 0, 27...|[{token, 0, 4, Pe...|[{token, 0, 4, pe...|\nMy life in Russia...|[{document, 0, 37...|[{token, 0, 1, My...|[{token, 0, 1, my...|\nJohn and Peter ar...|[{document, 0, 76...|[{token, 0, 3, Jo...|[{token, 0, 3, jo...|\nLucas Nogal Dunbe...|[{document, 0, 67...|[{token, 0, 4, Lu...|[{token, 0, 4, lu...|\nEurope is very cu...|[{document, 0, 68...|[{token, 0, 5, Eu...|[{token, 0, 5, eu...|\n+--------------------+--------------------+--------------------+--------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["result.select('stem.result').show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1941f1c0-fcbb-46fa-9bbe-14d0fc33671b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-------------------------------------------------------------------------------------------+\n|result                                                                                     |\n+-------------------------------------------------------------------------------------------+\n|[peter, i, a, veri, good, person, .]                                                       |\n|[my, life, in, russia, i, veri, interest, .]                                               |\n|[john, and, peter, ar, brother, ., howev, thei, don&#39;t, support, each, other, that, much, .]|\n|[luca, nogal, dunberck, i, no, longer, happi, ., he, ha, a, good, car, though, .]          |\n|[europ, i, veri, cultur, rich, ., there, ar, huge, church, !, and, big, hous, !]           |\n+-------------------------------------------------------------------------------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------------------------------------------------------------------------------------------+\nresult                                                                                     |\n+-------------------------------------------------------------------------------------------+\n[peter, i, a, veri, good, person, .]                                                       |\n[my, life, in, russia, i, veri, interest, .]                                               |\n[john, and, peter, ar, brother, ., howev, thei, don&#39;t, support, each, other, that, much, .]|\n[luca, nogal, dunberck, i, no, longer, happi, ., he, ha, a, good, car, though, .]          |\n[europ, i, veri, cultur, rich, ., there, ar, huge, church, !, and, big, hous, !]           |\n+-------------------------------------------------------------------------------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["import pyspark.sql.functions as F\n\nresult_df = result.select(F.explode(F.arrays_zip(result.token.result, result.stem.result)).alias(\"cols\")) \\\n                  .select(F.expr(\"cols['0']\").alias(\"token\"),\n                          F.expr(\"cols['1']\").alias(\"stem\")).toPandas()\n\nresult_df.head(10)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"77f6f18d-6b97-49e9-a312-89e930e799e3","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[85]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[85]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>token</th>\n      <th>stem</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Peter</td>\n      <td>peter</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>is</td>\n      <td>i</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a</td>\n      <td>a</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>very</td>\n      <td>veri</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>good</td>\n      <td>good</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>person</td>\n      <td>person</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>.</td>\n      <td>.</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>My</td>\n      <td>my</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>life</td>\n      <td>life</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>in</td>\n      <td>in</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>token</th>\n      <th>stem</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Peter</td>\n      <td>peter</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>is</td>\n      <td>i</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a</td>\n      <td>a</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>very</td>\n      <td>veri</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>good</td>\n      <td>good</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>person</td>\n      <td>person</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>.</td>\n      <td>.</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>My</td>\n      <td>my</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>life</td>\n      <td>life</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>in</td>\n      <td>in</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Lemmatizer"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"977a78c4-4fb8-47b8-822c-49879c4d36af","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["|index|model|index|model|index|model|index|model|\n|-----:|:-----|-----:|:-----|-----:|:-----|-----:|:-----|\n| 1| [lemma_antbnc](https://nlp.johnsnowlabs.com/2021/11/22/lemma_antbnc_en.html)  | 2| [lemma_atis](https://nlp.johnsnowlabs.com/2022/03/31/lemma_atis_en_3_0.html)  | 3| [lemma_esl](https://nlp.johnsnowlabs.com/2022/03/31/lemma_esl_en_3_0.html)  | 4| [lemma_ewt](https://nlp.johnsnowlabs.com/2022/05/01/lemma_ewt_en_3_0.html)  |\n| 5| [lemma_gum](https://nlp.johnsnowlabs.com/2022/03/31/lemma_gum_en_3_0.html)  | 6| [lemma_lines](https://nlp.johnsnowlabs.com/2022/05/01/lemma_lines_en_3_0.html)  | 7| [lemma_partut](https://nlp.johnsnowlabs.com/2022/03/31/lemma_partut_en_3_0.html)  | 8| [lemma_spacylookup](https://nlp.johnsnowlabs.com/2022/03/08/lemma_spacylookup_en_3_0.html)  |"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f542d2b3-d41f-4a52-a889-b3f712690b21","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["Retrieves lemmas out of words with the objective of returning a base dictionary word"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"237e8d97-38b4-43d2-a129-b88c1467b80d","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["!wget -q https://raw.githubusercontent.com/mahavivo/vocabulary/master/lemmas/AntBNC_lemmas_ver_001.txt\n  \ndbutils.fs.cp(\"file:/databricks/driver/AntBNC_lemmas_ver_001.txt\", \"dbfs:/\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9df584d5-0f47-4ece-ae92-6f7015b5a3f5","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[86]: True</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[86]: True</div>"]}}],"execution_count":0},{"cell_type":"code","source":["lemmatizer = Lemmatizer() \\\n    .setInputCols([\"token\"]) \\\n    .setOutputCol(\"lemma\") \\\n    .setDictionary(\"dbfs:/AntBNC_lemmas_ver_001.txt\", value_delimiter =\"\\t\", key_delimiter = \"->\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c9f61716-a28c-4260-842c-1079c6133fe3","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["documentAssembler = DocumentAssembler()\\\n    .setInputCol(\"text\")\\\n    .setOutputCol(\"document\")\n\ntokenizer = Tokenizer() \\\n    .setInputCols([\"document\"]) \\\n    .setOutputCol(\"token\")\n\nstemmer = Stemmer() \\\n    .setInputCols([\"token\"]) \\\n    .setOutputCol(\"stem\")\n\nnlpPipeline = Pipeline(stages=[\n     documentAssembler, \n     tokenizer,\n     stemmer,\n     lemmatizer\n ])\n\nresult = nlpPipeline.fit(spark_df).transform(spark_df)\nresult.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ea94e671-ac29-40ec-85e8-620a671c8991","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+--------------------+--------------------+--------------------+--------------------+--------------------+\n|                text|            document|               token|                stem|               lemma|\n+--------------------+--------------------+--------------------+--------------------+--------------------+\n|Peter is a very g...|[{document, 0, 27...|[{token, 0, 4, Pe...|[{token, 0, 4, pe...|[{token, 0, 4, Pe...|\n|My life in Russia...|[{document, 0, 37...|[{token, 0, 1, My...|[{token, 0, 1, my...|[{token, 0, 1, My...|\n|John and Peter ar...|[{document, 0, 76...|[{token, 0, 3, Jo...|[{token, 0, 3, jo...|[{token, 0, 3, Jo...|\n|Lucas Nogal Dunbe...|[{document, 0, 67...|[{token, 0, 4, Lu...|[{token, 0, 4, lu...|[{token, 0, 4, Lu...|\n|Europe is very cu...|[{document, 0, 68...|[{token, 0, 5, Eu...|[{token, 0, 5, eu...|[{token, 0, 5, Eu...|\n+--------------------+--------------------+--------------------+--------------------+--------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+--------------------+--------------------+--------------------+--------------------+\n                text|            document|               token|                stem|               lemma|\n+--------------------+--------------------+--------------------+--------------------+--------------------+\nPeter is a very g...|[{document, 0, 27...|[{token, 0, 4, Pe...|[{token, 0, 4, pe...|[{token, 0, 4, Pe...|\nMy life in Russia...|[{document, 0, 37...|[{token, 0, 1, My...|[{token, 0, 1, my...|[{token, 0, 1, My...|\nJohn and Peter ar...|[{document, 0, 76...|[{token, 0, 3, Jo...|[{token, 0, 3, jo...|[{token, 0, 3, Jo...|\nLucas Nogal Dunbe...|[{document, 0, 67...|[{token, 0, 4, Lu...|[{token, 0, 4, lu...|[{token, 0, 4, Lu...|\nEurope is very cu...|[{document, 0, 68...|[{token, 0, 5, Eu...|[{token, 0, 5, eu...|[{token, 0, 5, Eu...|\n+--------------------+--------------------+--------------------+--------------------+--------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["result.select('lemma.result').show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"dfeac277-b573-449c-b2c9-efca655233bb","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+---------------------------------------------------------------------------------------------+\n|result                                                                                       |\n+---------------------------------------------------------------------------------------------+\n|[Peter, be, a, very, good, person, .]                                                        |\n|[My, life, in, Russia, be, very, interest, .]                                                |\n|[John, and, Peter, be, brother, ., However, they, don&#39;t, support, each, other, that, much, .]|\n|[Lucas, Nogal, Dunbercker, be, no, long, happy, ., He, have, a, good, car, though, .]        |\n|[Europe, be, very, culture, rich, ., There, be, huge, church, !, and, big, house, !]         |\n+---------------------------------------------------------------------------------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------------------------------------------------------------------------------------------+\nresult                                                                                       |\n+---------------------------------------------------------------------------------------------+\n[Peter, be, a, very, good, person, .]                                                        |\n[My, life, in, Russia, be, very, interest, .]                                                |\n[John, and, Peter, be, brother, ., However, they, don&#39;t, support, each, other, that, much, .]|\n[Lucas, Nogal, Dunbercker, be, no, long, happy, ., He, have, a, good, car, though, .]        |\n[Europe, be, very, culture, rich, ., There, be, huge, church, !, and, big, house, !]         |\n+---------------------------------------------------------------------------------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["result_df = result.select(F.explode(F.arrays_zip(result.token.result, result.stem.result, result.lemma.result)).alias(\"cols\")) \\\n                  .select(F.expr(\"cols['0']\").alias(\"token\"),\n                          F.expr(\"cols['1']\").alias(\"stem\"),\n                          F.expr(\"cols['2']\").alias(\"lemma\")).toPandas()\n\nresult_df.head(10)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"33a9aad9-5cf2-4691-b798-c62e2e6bdc58","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[90]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[90]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>token</th>\n      <th>stem</th>\n      <th>lemma</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Peter</td>\n      <td>peter</td>\n      <td>Peter</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>is</td>\n      <td>i</td>\n      <td>be</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a</td>\n      <td>a</td>\n      <td>a</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>very</td>\n      <td>veri</td>\n      <td>very</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>good</td>\n      <td>good</td>\n      <td>good</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>person</td>\n      <td>person</td>\n      <td>person</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>My</td>\n      <td>my</td>\n      <td>My</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>life</td>\n      <td>life</td>\n      <td>life</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>in</td>\n      <td>in</td>\n      <td>in</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>token</th>\n      <th>stem</th>\n      <th>lemma</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Peter</td>\n      <td>peter</td>\n      <td>Peter</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>is</td>\n      <td>i</td>\n      <td>be</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a</td>\n      <td>a</td>\n      <td>a</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>very</td>\n      <td>veri</td>\n      <td>very</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>good</td>\n      <td>good</td>\n      <td>good</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>person</td>\n      <td>person</td>\n      <td>person</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>.</td>\n      <td>.</td>\n      <td>.</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>My</td>\n      <td>my</td>\n      <td>My</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>life</td>\n      <td>life</td>\n      <td>life</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>in</td>\n      <td>in</td>\n      <td>in</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## NGram Generator"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b621358f-f88d-4b2a-8b1f-cbe8a35781a9","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["NGramGenerator annotator takes as input a sequence of strings (e.g. the output of a `Tokenizer`, `Normalizer`, `Stemmer`, `Lemmatizer`, and `StopWordsCleaner`). \n\nThe parameter n is used to determine the number of terms in each n-gram. The output will consist of a sequence of n-grams where each n-gram is represented by a space-delimited string of n consecutive words with annotatorType `CHUNK` same as the Chunker annotator.\n\nFunctions:\n\n`setN:` number elements per n-gram (>=1)\n\n`setEnableCumulative:` whether to calculate just the actual n-grams or all n-grams from 1 through n\n\n`setDelimiter:` Glue character used to join the tokens"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ff8094e6-b451-417e-a3b0-4ec3fd97269c","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["ngrams_cum = NGramGenerator() \\\n            .setInputCols([\"token\"]) \\\n            .setOutputCol(\"ngrams\") \\\n            .setN(3) \\\n            .setEnableCumulative(True)\\\n            .setDelimiter(\"_\") # Default is space\n    \n# .setN(3) means, take bigrams and trigrams.\n\nnlpPipeline = Pipeline(stages=[\n     documentAssembler, \n     tokenizer,\n     ngrams_cum])\n\nresult = nlpPipeline.fit(spark_df).transform(spark_df)\nresult.select('ngrams.result').show(truncate=150)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"71452e5b-c6c4-4078-8e10-f969543b1122","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+------------------------------------------------------------------------------------------------------------------------------------------------------+\n|                                                                                                                                                result|\n+------------------------------------------------------------------------------------------------------------------------------------------------------+\n|[Peter, is, a, very, good, person, ., Peter_is, is_a, a_very, very_good, good_person, person_., Peter_is_a, is_a_very, a_very_good, very_good_perso...|\n|[My, life, in, Russia, is, very, interesting, ., My_life, life_in, in_Russia, Russia_is, is_very, very_interesting, interesting_., My_life_in, life...|\n|[John, and, Peter, are, brothers, ., However, they, don&#39;t, support, each, other, that, much, ., John_and, and_Peter, Peter_are, are_brothers, broth...|\n|[Lucas, Nogal, Dunbercker, is, no, longer, happy, ., He, has, a, good, car, though, ., Lucas_Nogal, Nogal_Dunbercker, Dunbercker_is, is_no, no_long...|\n|[Europe, is, very, culture, rich, ., There, are, huge, churches, !, and, big, houses, !, Europe_is, is_very, very_culture, culture_rich, rich_., ._...|\n+------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------------------------------------------------------------------------------------------------------------------------------------------------------+\n                                                                                                                                                result|\n+------------------------------------------------------------------------------------------------------------------------------------------------------+\n[Peter, is, a, very, good, person, ., Peter_is, is_a, a_very, very_good, good_person, person_., Peter_is_a, is_a_very, a_very_good, very_good_perso...|\n[My, life, in, Russia, is, very, interesting, ., My_life, life_in, in_Russia, Russia_is, is_very, very_interesting, interesting_., My_life_in, life...|\n[John, and, Peter, are, brothers, ., However, they, don&#39;t, support, each, other, that, much, ., John_and, and_Peter, Peter_are, are_brothers, broth...|\n[Lucas, Nogal, Dunbercker, is, no, longer, happy, ., He, has, a, good, car, though, ., Lucas_Nogal, Nogal_Dunbercker, Dunbercker_is, is_no, no_long...|\n[Europe, is, very, culture, rich, ., There, are, huge, churches, !, and, big, houses, !, Europe_is, is_very, very_culture, culture_rich, rich_., ._...|\n+------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["ngrams_nonCum = NGramGenerator() \\\n            .setInputCols([\"token\"]) \\\n            .setOutputCol(\"ngrams_v2\") \\\n            .setN(3) \\\n            .setEnableCumulative(False)\\\n            .setDelimiter(\"_\") # Default is space\n    \nngrams_nonCum.transform(result).select('ngrams_v2.result').show(truncate=150)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"cc34dd5e-94ce-435e-9134-f877b1a74734","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+------------------------------------------------------------------------------------------------------------------------------------------------------+\n|                                                                                                                                                result|\n+------------------------------------------------------------------------------------------------------------------------------------------------------+\n|                                                                                 [Peter_is_a, is_a_very, a_very_good, very_good_person, good_person_.]|\n|                                                   [My_life_in, life_in_Russia, in_Russia_is, Russia_is_very, is_very_interesting, very_interesting_.]|\n|[John_and_Peter, and_Peter_are, Peter_are_brothers, are_brothers_., brothers_._However, ._However_they, However_they_don&#39;t, they_don&#39;t_support, don...|\n|[Lucas_Nogal_Dunbercker, Nogal_Dunbercker_is, Dunbercker_is_no, is_no_longer, no_longer_happy, longer_happy_., happy_._He, ._He_has, He_has_a, has_...|\n|[Europe_is_very, is_very_culture, very_culture_rich, culture_rich_., rich_._There, ._There_are, There_are_huge, are_huge_churches, huge_churches_!,...|\n+------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------------------------------------------------------------------------------------------------------------------------------------------------------+\n                                                                                                                                                result|\n+------------------------------------------------------------------------------------------------------------------------------------------------------+\n                                                                                 [Peter_is_a, is_a_very, a_very_good, very_good_person, good_person_.]|\n                                                   [My_life_in, life_in_Russia, in_Russia_is, Russia_is_very, is_very_interesting, very_interesting_.]|\n[John_and_Peter, and_Peter_are, Peter_are_brothers, are_brothers_., brothers_._However, ._However_they, However_they_don&#39;t, they_don&#39;t_support, don...|\n[Lucas_Nogal_Dunbercker, Nogal_Dunbercker_is, Dunbercker_is_no, is_no_longer, no_longer_happy, longer_happy_., happy_._He, ._He_has, He_has_a, has_...|\n[Europe_is_very, is_very_culture, very_culture_rich, culture_rich_., rich_._There, ._There_are, There_are_huge, are_huge_churches, huge_churches_!,...|\n+------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## TextMatcher"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"11f195c3-7f63-494b-aff6-3a93e5be7b33","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["Annotator to match entire phrases (by token) provided in a file against a Document\n\nFunctions:\n\n`setEntities(path, format, options)`: Provides a file with phrases to match. Default: Looks up path in configuration.\n\n`path`: a path to a file that contains the entities in the specified format.\n\n`readAs`: the format of the file, can be one of {ReadAs.LINE_BY_LINE, ReadAs.SPARK_DATASET}. Defaults to LINE_BY_LINE.\n\n`options`: a map of additional parameters. Defaults to {“format”: “text”}.\n\n`entityValue` : Value for the entity metadata field to indicate which chunk comes from which textMatcher when there are multiple textMatchers. \n\n`mergeOverlapping` : whether to merge overlapping matched chunks. Defaults false\n\n`caseSensitive` : whether to match regardless of case. Defaults true"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1e42e00d-8f89-4d12-b91e-cd2b8eaf60d1","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/data/news_category_train.csv\n\ndbutils.fs.cp(\"file:/databricks/driver/news_category_train.csv\", \"dbfs:/\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"887ded9d-b002-4570-8111-fcb6726a885a","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[93]: True</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[93]: True</div>"]}}],"execution_count":0},{"cell_type":"code","source":["news_df = spark.read \\\n      .option(\"header\", True) \\\n      .csv(\"/news_category_train.csv\")\n\nnews_df.show(5, truncate=50)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8d0fdb5d-9c59-4b50-a1cf-850eb95aed1e","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+--------+--------------------------------------------------+\n|category|                                       description|\n+--------+--------------------------------------------------+\n|Business| Short sellers, Wall Street&#39;s dwindling band of...|\n|Business| Private investment firm Carlyle Group, which h...|\n|Business| Soaring crude prices plus worries about the ec...|\n|Business| Authorities have halted oil export flows from ...|\n|Business| Tearaway world oil prices, toppling records an...|\n+--------+--------------------------------------------------+\nonly showing top 5 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+--------------------------------------------------+\ncategory|                                       description|\n+--------+--------------------------------------------------+\nBusiness| Short sellers, Wall Street&#39;s dwindling band of...|\nBusiness| Private investment firm Carlyle Group, which h...|\nBusiness| Soaring crude prices plus worries about the ec...|\nBusiness| Authorities have halted oil export flows from ...|\nBusiness| Tearaway world oil prices, toppling records an...|\n+--------+--------------------------------------------------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# write the target entities to txt file \n\nentities = ['Wall Street', 'USD', 'stock', 'NYSE']\nwith open ('financial_entities.txt', 'w') as f:\n    for i in entities:\n        f.write(i+'\\n')\n\n\nentities = ['soccer', 'world cup', 'Messi', 'FC Barcelona']\nwith open ('sport_entities.txt', 'w') as f:\n    for i in entities:\n        f.write(i+'\\n')\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"45fff651-b7c3-4c00-a3ce-810dbe2f896a","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["dbutils.fs.cp(\"file:/databricks/driver/financial_entities.txt\", \"dbfs:/\")\ndbutils.fs.cp(\"file:/databricks/driver/sport_entities.txt\", \"dbfs:/\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"21e4b216-9f70-4352-bf4b-7155aa1b420c","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[96]: True</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[96]: True</div>"]}}],"execution_count":0},{"cell_type":"code","source":["documentAssembler = DocumentAssembler()\\\n    .setInputCol(\"description\")\\\n    .setOutputCol(\"document\")\n\ntokenizer = Tokenizer() \\\n    .setInputCols([\"document\"]) \\\n    .setOutputCol(\"token\")\n\nfinancial_entity_extractor = TextMatcher() \\\n    .setInputCols([\"document\",'token'])\\\n    .setOutputCol(\"financial_entities\")\\\n    .setEntities(\"file:/databricks/driver/financial_entities.txt\")\\\n    .setCaseSensitive(False)\\\n    .setEntityValue('financial_entity')\n\nsport_entity_extractor = TextMatcher() \\\n    .setInputCols([\"document\",'token'])\\\n    .setOutputCol(\"sport_entities\")\\\n    .setEntities(\"file:/databricks/driver/sport_entities.txt\")\\\n    .setCaseSensitive(False)\\\n    .setEntityValue('sport_entity')\n\n\nnlpPipeline = Pipeline(stages=[\n     documentAssembler, \n     tokenizer,\n     financial_entity_extractor,\n     sport_entity_extractor\n ])\n\nresult = nlpPipeline.fit(news_df).transform(news_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9a6df1f5-05cc-43cc-8fa2-5bed97fc083c","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["result.select('financial_entities.result','sport_entities.result').take(2)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"804aabcc-24bf-4aaa-8386-08b86d498197","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[98]: [Row(result=[], result=[]), Row(result=[], result=[])]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[98]: [Row(result=[], result=[]), Row(result=[], result=[])]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["result.select('description','financial_entities.result','sport_entities.result')\\\n      .toDF('text','financial_matches','sport_matches').filter((F.size('financial_matches')>1) | (F.size('sport_matches')>1))\\\n      .show(truncate=70)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"fa8ba972-3687-4c0a-874b-ef97df2c5cab","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+----------------------------------------------------------------------+----------------------------------+-------------------+\n|                                                                  text|                 financial_matches|      sport_matches|\n+----------------------------------------------------------------------+----------------------------------+-------------------+\n|&#34;Company launched the biggest electronic auction of stock in Wall S...|              [stock, Wall Street]|                 []|\n|Google, Inc. significantly cut the expected share price for its ini...|                    [stock, stock]|                 []|\n|Google, Inc. significantly cut the expected share price this mornin...|                    [stock, stock]|                 []|\n| Shares of Air Canada  (AC.TO) fell by more than half on Wednesday,...|                    [Stock, stock]|                 []|\n|Stock prices are lower in moderate trading. The Dow Jones Industria...|                    [Stock, Stock]|                 []|\n|The bad news just keeps pouring in for mutual fund manager Janus Ca...|                      [NYSE, NYSE]|                 []|\n|  Shaun Wright Phillips scored in his international debut as Englan...|                                []|[soccer, World Cup]|\n|NEWCASTLE, ENGLAND - England deservedly beat Ukraine 3-0 today in t...|                                []|[soccer, World Cup]|\n|MONTREAL (Reuters) - Shares of Air Canada (AC.TO: Quote, Profile, R...|                    [Stock, stock]|                 []|\n|&#34;SAN JOSE, California - On the cusp of its voyage into public tradi...|[stock, Wall Street, stock, Stock]|                 []|\n|&#34;Shortly before noon today, Google Inc. stock began trading under t...|                    [stock, stock]|                 []|\n|roundup Plus: EA to take World Cup soccer to Xbox...IBM chalks up t...|                                []|[World Cup, soccer]|\n|The U.S. Securities and Exchange Commission yesterday approved Goog...|                    [stock, stock]|                 []|\n|After a bumpy ride toward becoming a publicly traded company, Googl...|                    [stock, stock]|                 []|\n|In the most highly anticipated Wall Street debut since the heady da...|              [Wall Street, stock]|                 []|\n|NEW YORK Despite voluble skepticism among investors, Google #39;s s...|                    [stock, stock]|                 []|\n|If only the rest of my investments worked out this way. One week ag...|                    [stock, stock]|                 []|\n| U.S. stocks to watch: GOOGLE INC. (GOOG.O) Google shares jumped 18...|                    [stock, stock]|                 []|\n|&#34; U.S. stocks to watch: GOOGLE INC.  &amp;lt;A HREF=&#34;&#34;http://www.invest...|                    [stock, stock]|                 []|\n|roundup Plus: KDE updates Linux desktop...EA to take World Cup socc...|                                []|[World Cup, soccer]|\n+----------------------------------------------------------------------+----------------------------------+-------------------+\nonly showing top 20 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------------------------------------------------------------------+----------------------------------+-------------------+\n                                                                  text|                 financial_matches|      sport_matches|\n+----------------------------------------------------------------------+----------------------------------+-------------------+\n&#34;Company launched the biggest electronic auction of stock in Wall S...|              [stock, Wall Street]|                 []|\nGoogle, Inc. significantly cut the expected share price for its ini...|                    [stock, stock]|                 []|\nGoogle, Inc. significantly cut the expected share price this mornin...|                    [stock, stock]|                 []|\n Shares of Air Canada  (AC.TO) fell by more than half on Wednesday,...|                    [Stock, stock]|                 []|\nStock prices are lower in moderate trading. The Dow Jones Industria...|                    [Stock, Stock]|                 []|\nThe bad news just keeps pouring in for mutual fund manager Janus Ca...|                      [NYSE, NYSE]|                 []|\n  Shaun Wright Phillips scored in his international debut as Englan...|                                []|[soccer, World Cup]|\nNEWCASTLE, ENGLAND - England deservedly beat Ukraine 3-0 today in t...|                                []|[soccer, World Cup]|\nMONTREAL (Reuters) - Shares of Air Canada (AC.TO: Quote, Profile, R...|                    [Stock, stock]|                 []|\n&#34;SAN JOSE, California - On the cusp of its voyage into public tradi...|[stock, Wall Street, stock, Stock]|                 []|\n&#34;Shortly before noon today, Google Inc. stock began trading under t...|                    [stock, stock]|                 []|\nroundup Plus: EA to take World Cup soccer to Xbox...IBM chalks up t...|                                []|[World Cup, soccer]|\nThe U.S. Securities and Exchange Commission yesterday approved Goog...|                    [stock, stock]|                 []|\nAfter a bumpy ride toward becoming a publicly traded company, Googl...|                    [stock, stock]|                 []|\nIn the most highly anticipated Wall Street debut since the heady da...|              [Wall Street, stock]|                 []|\nNEW YORK Despite voluble skepticism among investors, Google #39;s s...|                    [stock, stock]|                 []|\nIf only the rest of my investments worked out this way. One week ag...|                    [stock, stock]|                 []|\n U.S. stocks to watch: GOOGLE INC. (GOOG.O) Google shares jumped 18...|                    [stock, stock]|                 []|\n&#34; U.S. stocks to watch: GOOGLE INC.  &amp;lt;A HREF=&#34;&#34;http://www.invest...|                    [stock, stock]|                 []|\nroundup Plus: KDE updates Linux desktop...EA to take World Cup socc...|                                []|[World Cup, soccer]|\n+----------------------------------------------------------------------+----------------------------------+-------------------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["result_df = result.select(F.explode(F.arrays_zip(result.financial_entities.result, \n                                                 result.financial_entities.begin, \n                                                 result.financial_entities.end)).alias(\"cols\")) \\\n                  .select(F.expr(\"cols['0']\").alias(\"clinical_entities\"),\n                          F.expr(\"cols['1']\").alias(\"begin\"),\n                          F.expr(\"cols['2']\").alias(\"end\")).toPandas()\n\nresult_df.head(10)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"643d962a-8143-427c-a3bf-f078216e0e00","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[100]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[100]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>clinical_entities</th>\n      <th>begin</th>\n      <th>end</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>stock</td>\n      <td>112</td>\n      <td>116</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>stock</td>\n      <td>114</td>\n      <td>118</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>stock</td>\n      <td>45</td>\n      <td>49</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>stock</td>\n      <td>126</td>\n      <td>130</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>stock</td>\n      <td>188</td>\n      <td>192</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>stock</td>\n      <td>52</td>\n      <td>56</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Wall Street</td>\n      <td>61</td>\n      <td>71</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>stock</td>\n      <td>70</td>\n      <td>74</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>stock</td>\n      <td>143</td>\n      <td>147</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>stock</td>\n      <td>294</td>\n      <td>298</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>clinical_entities</th>\n      <th>begin</th>\n      <th>end</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>stock</td>\n      <td>112</td>\n      <td>116</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>stock</td>\n      <td>114</td>\n      <td>118</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>stock</td>\n      <td>45</td>\n      <td>49</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>stock</td>\n      <td>126</td>\n      <td>130</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>stock</td>\n      <td>188</td>\n      <td>192</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>stock</td>\n      <td>52</td>\n      <td>56</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Wall Street</td>\n      <td>61</td>\n      <td>71</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>stock</td>\n      <td>70</td>\n      <td>74</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>stock</td>\n      <td>143</td>\n      <td>147</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>stock</td>\n      <td>294</td>\n      <td>298</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## RegexMatcher"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e16edc30-6fab-488f-a007-cea10d981f8e","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["! wget -q https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/pubmed/pubmed-sample.csv\n\ndbutils.fs.cp(\"file:/databricks/driver/pubmed-sample.csv\", \"dbfs:/\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ddb75086-1f9a-46d8-a6d7-267df8799689","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[101]: True</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[101]: True</div>"]}}],"execution_count":0},{"cell_type":"code","source":["pubMedDF = spark.read\\\n                .option(\"header\", \"true\")\\\n                .csv(\"/pubmed-sample.csv\")\\\n                .filter(\"AB IS NOT null\")\\\n                .withColumnRenamed(\"AB\", \"text\")\\\n                .drop(\"TI\")\n\npubMedDF.show(truncate=50)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"800b8a3a-9409-4217-94ba-0b244fd40021","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+--------------------------------------------------+\n|                                              text|\n+--------------------------------------------------+\n|The human KCNJ9 (Kir 3.3, GIRK3) is a member of...|\n|BACKGROUND: At present, it is one of the most i...|\n|OBJECTIVE: To investigate the relationship betw...|\n|Combined EEG/fMRI recording has been used to lo...|\n|Kohlschutter syndrome is a rare neurodegenerati...|\n|Statistical analysis of neuroimages is commonly...|\n|The synthetic DOX-LNA conjugate was characteriz...|\n|Our objective was to compare three different me...|\n|We conducted a phase II study to assess the eff...|\n|&#34;Monomeric sarcosine oxidase (MSOX) is a flavoe...|\n|We presented the tachinid fly Exorista japonica...|\n|The literature dealing with the water conductin...|\n|A novel approach to synthesize chitosan-O-isopr...|\n|An HPLC-ESI-MS-MS method has been developed for...|\n|The localizing and lateralizing values of eye a...|\n|OBJECTIVE: To evaluate the effectiveness and ac...|\n|For the construction of new combinatorial libra...|\n|We report the results of a screen for genetic a...|\n|Intraparenchymal pericatheter cyst is rarely re...|\n|It is known that patients with Klinefelter&#39;s sy...|\n+--------------------------------------------------+\nonly showing top 20 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------------------------------------+\n                                              text|\n+--------------------------------------------------+\nThe human KCNJ9 (Kir 3.3, GIRK3) is a member of...|\nBACKGROUND: At present, it is one of the most i...|\nOBJECTIVE: To investigate the relationship betw...|\nCombined EEG/fMRI recording has been used to lo...|\nKohlschutter syndrome is a rare neurodegenerati...|\nStatistical analysis of neuroimages is commonly...|\nThe synthetic DOX-LNA conjugate was characteriz...|\nOur objective was to compare three different me...|\nWe conducted a phase II study to assess the eff...|\n&#34;Monomeric sarcosine oxidase (MSOX) is a flavoe...|\nWe presented the tachinid fly Exorista japonica...|\nThe literature dealing with the water conductin...|\nA novel approach to synthesize chitosan-O-isopr...|\nAn HPLC-ESI-MS-MS method has been developed for...|\nThe localizing and lateralizing values of eye a...|\nOBJECTIVE: To evaluate the effectiveness and ac...|\nFor the construction of new combinatorial libra...|\nWe report the results of a screen for genetic a...|\nIntraparenchymal pericatheter cyst is rarely re...|\nIt is known that patients with Klinefelter&#39;s sy...|\n+--------------------------------------------------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["**setExternalRules**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0bca589e-fb2c-496a-a498-92d2bd09716c","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["rules = '''\nrenal\\s\\w+, started with 'renal'\ncardiac\\s\\w+, started with 'cardiac'\n\\w*ly\\b, ending with 'ly'\n\\S*\\d+\\S*, match any word that contains numbers\n(\\d+).?(\\d*)\\s*(mg|ml|g), match medication metrics\n'''\n\nwith open('regex_rules.txt', 'w') as f:\n    \n    f.write(rules)\n\ndbutils.fs.cp(\"file:/databricks/driver/regex_rules.txt\", \"dbfs:/\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1acb9284-72e5-41af-9fa1-7e9ccefcede1","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[103]: True</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[103]: True</div>"]}}],"execution_count":0},{"cell_type":"code","source":["RegexMatcher().extractParamMap()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e669a4af-209c-4497-b89b-fa0b3be03613","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[104]: {Param(parent=&#39;RegexMatcher_b748de42eee3&#39;, name=&#39;lazyAnnotator&#39;, doc=&#39;Whether this AnnotatorModel acts as lazy in RecursivePipelines&#39;): False,\n Param(parent=&#39;RegexMatcher_b748de42eee3&#39;, name=&#39;strategy&#39;, doc=&#39;MATCH_FIRST|MATCH_ALL|MATCH_COMPLETE&#39;): &#39;MATCH_ALL&#39;}</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[104]: {Param(parent=&#39;RegexMatcher_b748de42eee3&#39;, name=&#39;lazyAnnotator&#39;, doc=&#39;Whether this AnnotatorModel acts as lazy in RecursivePipelines&#39;): False,\n Param(parent=&#39;RegexMatcher_b748de42eee3&#39;, name=&#39;strategy&#39;, doc=&#39;MATCH_FIRST|MATCH_ALL|MATCH_COMPLETE&#39;): &#39;MATCH_ALL&#39;}</div>"]}}],"execution_count":0},{"cell_type":"code","source":["documentAssembler = DocumentAssembler()\\\n    .setInputCol(\"text\")\\\n    .setOutputCol(\"document\")\n\nregex_matcher = RegexMatcher()\\\n    .setInputCols('document')\\\n    .setStrategy(\"MATCH_ALL\")\\\n    .setOutputCol(\"regex_matches\")\\\n    .setExternalRules(path=\"file:/databricks/driver/regex_rules.txt\", delimiter=',')\n    \nnlpPipeline = Pipeline(stages=[\n     documentAssembler, \n     regex_matcher\n ])\n\n\nmatch_df = nlpPipeline.fit(pubMedDF).transform(pubMedDF)\nmatch_df.select('regex_matches.result').take(3)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5b47399e-7459-4006-831d-5d4898b3ab5e","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[105]: [Row(result=[&#39;inwardly&#39;, &#39;family&#39;, &#39;spansapproximately&#39;, &#39;byapproximately&#39;, &#39;approximately&#39;, &#39;respectively&#39;, &#39;poly&#39;, &#39;KCNJ9&#39;, &#39;3.3,&#39;, &#39;GIRK3)&#39;, &#39;KCNJ9&#39;, &#39;1q21-23&#39;, &#39;7.6&#39;, &#39;2.2&#39;, &#39;2.6&#39;, &#39;identified14&#39;, &#39;aVal366Ala&#39;, &#39;8&#39;, &#39;KCNJ9&#39;, &#39;KCNJ9&#39;, &#39;9 g&#39;]),\n Row(result=[&#39;previously&#39;, &#39;previously&#39;, &#39;intravenously&#39;, &#39;previously&#39;, &#39;25&#39;, &#39;mg/m(2)&#39;, &#39;1&#39;, &#39;8&#39;, &#39;a3&#39;, &#39;50&#39;, &#39;20.0%&#39;, &#39;(10&#39;, &#39;50;&#39;, &#39;95%&#39;, &#39;interval,10.0-33.7%).&#39;, &#39;58.0%&#39;, &#39;[10&#39;, &#39;18&#39;, &#39;50].&#39;, &#39;(50%&#39;, &#39;115.0&#39;, &#39;17.3%&#39;, &#39;52).&#39;, &#39;25 mg&#39;]),\n Row(result=[&#39;renal failure&#39;, &#39;cardiac surgery&#39;, &#39;cardiac surgery&#39;, &#39;cardiac surgical&#39;, &#39;early&#39;, &#39;statistically&#39;, &#39;analy&#39;, &#39;1995&#39;, &#39;2005&#39;, &#39;=9796).&#39;, &#39;2.9&#39;, &#39;11years).&#39;, &#39;11.3%&#39;, &#39;1105),&#39;, &#39;7.2%&#39;, &#39;30%&#39;, &#39;0.0001),&#39;, &#39;1.55,95%&#39;, &#39;1.42-1.70,&#39;, &#39;0.0001).&#39;])]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[105]: [Row(result=[&#39;inwardly&#39;, &#39;family&#39;, &#39;spansapproximately&#39;, &#39;byapproximately&#39;, &#39;approximately&#39;, &#39;respectively&#39;, &#39;poly&#39;, &#39;KCNJ9&#39;, &#39;3.3,&#39;, &#39;GIRK3)&#39;, &#39;KCNJ9&#39;, &#39;1q21-23&#39;, &#39;7.6&#39;, &#39;2.2&#39;, &#39;2.6&#39;, &#39;identified14&#39;, &#39;aVal366Ala&#39;, &#39;8&#39;, &#39;KCNJ9&#39;, &#39;KCNJ9&#39;, &#39;9 g&#39;]),\n Row(result=[&#39;previously&#39;, &#39;previously&#39;, &#39;intravenously&#39;, &#39;previously&#39;, &#39;25&#39;, &#39;mg/m(2)&#39;, &#39;1&#39;, &#39;8&#39;, &#39;a3&#39;, &#39;50&#39;, &#39;20.0%&#39;, &#39;(10&#39;, &#39;50;&#39;, &#39;95%&#39;, &#39;interval,10.0-33.7%).&#39;, &#39;58.0%&#39;, &#39;[10&#39;, &#39;18&#39;, &#39;50].&#39;, &#39;(50%&#39;, &#39;115.0&#39;, &#39;17.3%&#39;, &#39;52).&#39;, &#39;25 mg&#39;]),\n Row(result=[&#39;renal failure&#39;, &#39;cardiac surgery&#39;, &#39;cardiac surgery&#39;, &#39;cardiac surgical&#39;, &#39;early&#39;, &#39;statistically&#39;, &#39;analy&#39;, &#39;1995&#39;, &#39;2005&#39;, &#39;=9796).&#39;, &#39;2.9&#39;, &#39;11years).&#39;, &#39;11.3%&#39;, &#39;1105),&#39;, &#39;7.2%&#39;, &#39;30%&#39;, &#39;0.0001),&#39;, &#39;1.55,95%&#39;, &#39;1.42-1.70,&#39;, &#39;0.0001).&#39;])]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["match_df.select('text','regex_matches.result')\\\n        .toDF('text','matches').filter(F.size('matches')>1)\\\n        .show(truncate=70)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d156f59a-4c1b-4634-8f22-ea30698cc94b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+----------------------------------------------------------------------+----------------------------------------------------------------------+\n|                                                                  text|                                                               matches|\n+----------------------------------------------------------------------+----------------------------------------------------------------------+\n|The human KCNJ9 (Kir 3.3, GIRK3) is a member of the G-protein-activ...|[inwardly, family, spansapproximately, byapproximately, approximate...|\n|BACKGROUND: At present, it is one of the most important issues for ...|[previously, previously, intravenously, previously, 25, mg/m(2), 1,...|\n|OBJECTIVE: To investigate the relationship between preoperative atr...|[renal failure, cardiac surgery, cardiac surgery, cardiac surgical,...|\n|Combined EEG/fMRI recording has been used to localize the generator...|[normally, significantly, effectively, analy, only, considerably, 2...|\n|Statistical analysis of neuroimages is commonly approached with int...|[analy, commonly, overly, normally, thatsuccessfully, recently, ana...|\n|The synthetic DOX-LNA conjugate was characterized by proton nuclear...|                                             [wasanaly, substantially]|\n|Our objective was to compare three different methods of blood press...|[daily, only, Conversely, Hourly, hourly, Hourly, hourly, hourly, h...|\n|We conducted a phase II study to assess the efficacy and tolerabili...|[analy, respectively, generally, 5-fluorouracil, (5-FU)-, 5-FU-base...|\n|&#34;Monomeric sarcosine oxidase (MSOX) is a flavoenzyme that catalyzes...|[cataly, methylgly, gly, ethylgly, dimethylgly, spectrally, practic...|\n|We presented the tachinid fly Exorista japonica with moving host mo...|                                             [fly, fly, fly, fly, fly]|\n|The literature dealing with the water conducting properties of sapw...|                               [generally, mathematically, especially]|\n|A novel approach to synthesize chitosan-O-isopropyl-5&#39;-O-d4T monoph...|[efficiently, poly, chitosan-O-isopropyl-5&#39;-O-d4T, Chitosan-d4T, 1....|\n|An HPLC-ESI-MS-MS method has been developed for the quantitative de...|[chromatographically, respectively, successfully, C18, (n=5), 95.0%...|\n|The localizing and lateralizing values of eye and head ictal deviat...|                                                        [early, early]|\n|OBJECTIVE: To evaluate the effectiveness and acceptability of expec...|[weekly, respectively, theanaly, 2006, 2007,, 2, 66, 1), 30patients...|\n|We report the results of a screen for genetic association with urin...|[poly, threepoly, significantly, analy, actually, anextremely, only...|\n|Intraparenchymal pericatheter cyst is rarely reported. Obstruction ...|                                  [rarely, possibly, unusually, Early]|\n|PURPOSE: To compare the effectiveness, potential advantages and com...|[analy, comparatively, wassignificantly, respectively, a7-year, 155...|\n|We have demonstrated a new type of all-optical 2 x 2 switch by usin...|[approximately, fully, approximately, approximately, approximately,...|\n|Physalis peruviana (PP) is a widely used medicinal herb for treatin...|[widely, (20,, 40,, 60,, 80, 95%, 100, 95%, (82.3%), onFeCl2-ascorb...|\n+----------------------------------------------------------------------+----------------------------------------------------------------------+\nonly showing top 20 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------------------------------------------------------------------+----------------------------------------------------------------------+\n                                                                  text|                                                               matches|\n+----------------------------------------------------------------------+----------------------------------------------------------------------+\nThe human KCNJ9 (Kir 3.3, GIRK3) is a member of the G-protein-activ...|[inwardly, family, spansapproximately, byapproximately, approximate...|\nBACKGROUND: At present, it is one of the most important issues for ...|[previously, previously, intravenously, previously, 25, mg/m(2), 1,...|\nOBJECTIVE: To investigate the relationship between preoperative atr...|[renal failure, cardiac surgery, cardiac surgery, cardiac surgical,...|\nCombined EEG/fMRI recording has been used to localize the generator...|[normally, significantly, effectively, analy, only, considerably, 2...|\nStatistical analysis of neuroimages is commonly approached with int...|[analy, commonly, overly, normally, thatsuccessfully, recently, ana...|\nThe synthetic DOX-LNA conjugate was characterized by proton nuclear...|                                             [wasanaly, substantially]|\nOur objective was to compare three different methods of blood press...|[daily, only, Conversely, Hourly, hourly, Hourly, hourly, hourly, h...|\nWe conducted a phase II study to assess the efficacy and tolerabili...|[analy, respectively, generally, 5-fluorouracil, (5-FU)-, 5-FU-base...|\n&#34;Monomeric sarcosine oxidase (MSOX) is a flavoenzyme that catalyzes...|[cataly, methylgly, gly, ethylgly, dimethylgly, spectrally, practic...|\nWe presented the tachinid fly Exorista japonica with moving host mo...|                                             [fly, fly, fly, fly, fly]|\nThe literature dealing with the water conducting properties of sapw...|                               [generally, mathematically, especially]|\nA novel approach to synthesize chitosan-O-isopropyl-5&#39;-O-d4T monoph...|[efficiently, poly, chitosan-O-isopropyl-5&#39;-O-d4T, Chitosan-d4T, 1....|\nAn HPLC-ESI-MS-MS method has been developed for the quantitative de...|[chromatographically, respectively, successfully, C18, (n=5), 95.0%...|\nThe localizing and lateralizing values of eye and head ictal deviat...|                                                        [early, early]|\nOBJECTIVE: To evaluate the effectiveness and acceptability of expec...|[weekly, respectively, theanaly, 2006, 2007,, 2, 66, 1), 30patients...|\nWe report the results of a screen for genetic association with urin...|[poly, threepoly, significantly, analy, actually, anextremely, only...|\nIntraparenchymal pericatheter cyst is rarely reported. Obstruction ...|                                  [rarely, possibly, unusually, Early]|\nPURPOSE: To compare the effectiveness, potential advantages and com...|[analy, comparatively, wassignificantly, respectively, a7-year, 155...|\nWe have demonstrated a new type of all-optical 2 x 2 switch by usin...|[approximately, fully, approximately, approximately, approximately,...|\nPhysalis peruviana (PP) is a widely used medicinal herb for treatin...|[widely, (20,, 40,, 60,, 80, 95%, 100, 95%, (82.3%), onFeCl2-ascorb...|\n+----------------------------------------------------------------------+----------------------------------------------------------------------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## MultiDateMatcher"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"979a88e0-7851-4e06-ac0c-d2f79115aac8","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["Extract exact & normalize dates from relative date-time phrases. The default anchor date will be the date the code is run."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1d63498a-869d-49b2-9cb1-6f328ab62944","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["MultiDateMatcher().extractParamMap()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e394bf1c-c99f-4dc8-b574-007ac624d83e","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[107]: {Param(parent=&#39;MultiDateMatcher_78590451284d&#39;, name=&#39;lazyAnnotator&#39;, doc=&#39;Whether this AnnotatorModel acts as lazy in RecursivePipelines&#39;): False,\n Param(parent=&#39;MultiDateMatcher_78590451284d&#39;, name=&#39;inputFormats&#39;, doc=&#39;input formats list of patterns to match&#39;): [&#39;&#39;],\n Param(parent=&#39;MultiDateMatcher_78590451284d&#39;, name=&#39;outputFormat&#39;, doc=&#39;desired output format for dates extracted&#39;): &#39;yyyy/MM/dd&#39;,\n Param(parent=&#39;MultiDateMatcher_78590451284d&#39;, name=&#39;readMonthFirst&#39;, doc=&#39;Whether to parse july 07/05/2015 or as 05/07/2015&#39;): True,\n Param(parent=&#39;MultiDateMatcher_78590451284d&#39;, name=&#39;defaultDayWhenMissing&#39;, doc=&#39;which day to set when it is missing from parsed input&#39;): 1}</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[107]: {Param(parent=&#39;MultiDateMatcher_78590451284d&#39;, name=&#39;lazyAnnotator&#39;, doc=&#39;Whether this AnnotatorModel acts as lazy in RecursivePipelines&#39;): False,\n Param(parent=&#39;MultiDateMatcher_78590451284d&#39;, name=&#39;inputFormats&#39;, doc=&#39;input formats list of patterns to match&#39;): [&#39;&#39;],\n Param(parent=&#39;MultiDateMatcher_78590451284d&#39;, name=&#39;outputFormat&#39;, doc=&#39;desired output format for dates extracted&#39;): &#39;yyyy/MM/dd&#39;,\n Param(parent=&#39;MultiDateMatcher_78590451284d&#39;, name=&#39;readMonthFirst&#39;, doc=&#39;Whether to parse july 07/05/2015 or as 05/07/2015&#39;): True,\n Param(parent=&#39;MultiDateMatcher_78590451284d&#39;, name=&#39;defaultDayWhenMissing&#39;, doc=&#39;which day to set when it is missing from parsed input&#39;): 1}</div>"]}}],"execution_count":0},{"cell_type":"code","source":["documentAssembler = DocumentAssembler()\\\n    .setInputCol(\"text\")\\\n    .setOutputCol(\"document\")\n\ndate_matcher = MultiDateMatcher() \\\n    .setInputCols('document') \\\n    .setOutputCol(\"date\") \\\n    .setOutputFormat(\"yyyy/MM/dd\")\\\n    .setSourceLanguage(\"en\")\n        \ndate_pipeline = PipelineModel(stages=[\n     documentAssembler, \n     date_matcher\n ])\n\nsample_df = spark.createDataFrame([['I saw him yesterday and he told me that he will visit us next week']]).toDF(\"text\")\n\nresult = date_pipeline.transform(sample_df)\n\nresult.select('date.result').show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5cb17b0b-1c62-4d8f-8e49-348c03c8f4ea","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+------------------------+\n|result                  |\n+------------------------+\n|[2023/01/24, 2023/01/16]|\n+------------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------------------------+\nresult                  |\n+------------------------+\n[2023/01/24, 2023/01/16]|\n+------------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Let's set the Input Format and Output Format to specific formatLet's set the Input Format and Output Format to specific format"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d09f413c-65a0-4859-8edc-d968c4bd5ea8","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["documentAssembler = DocumentAssembler()\\\n    .setInputCol(\"text\")\\\n    .setOutputCol(\"document\")\n\ndate_matcher = MultiDateMatcher() \\\n    .setInputCols('document') \\\n    .setOutputCol(\"date\")\\\n    .setInputFormats([\"dd/MM/yyyy\"])\\\n    .setOutputFormat(\"yyyy/MM/dd\")\\\n    .setSourceLanguage(\"en\")\n\ndate_pipeline = PipelineModel(stages=[\n     documentAssembler, \n     date_matcher\n ])\n\nsample_df = spark.createDataFrame([[\"the last payment date of this invoice is 21/05/2022\"]]).toDF(\"text\")\n\nresult = date_pipeline.transform(sample_df)\n\nresult.select('date.result').show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"778ef7a4-cd68-4925-a38d-3596d7904c80","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+------------+\n|result      |\n+------------+\n|[2022/05/21]|\n+------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------------+\nresult      |\n+------------+\n[2022/05/21]|\n+------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Text Cleaning with UDF"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"573a2b5a-d233-40ce-b9d3-77979983e4c7","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["text = '<h1 style=\"color: #5e9ca0;\">Have a great <span  style=\"color: #2b2301;\">birth</span> day!</h1>'\n\ntext_df = spark.createDataFrame([[text]]).toDF(\"text\")\n\nimport re\nfrom pyspark.sql.functions import udf\nfrom pyspark.sql.types import StringType, IntegerType\n\nclean_text = lambda s: re.sub(r'<[^>]*>', '', s)\n\ntext_df.withColumn('cleaned', udf(clean_text, StringType())('text')).select('text','cleaned').show(truncate= False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b976839f-997a-4ed7-bb56-50cfaadb8026","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+----------------------------------------------------------------------------------------------+-----------------------+\n|text                                                                                          |cleaned                |\n+----------------------------------------------------------------------------------------------+-----------------------+\n|&lt;h1 style=&#34;color: #5e9ca0;&#34;&gt;Have a great &lt;span  style=&#34;color: #2b2301;&#34;&gt;birth&lt;/span&gt; day!&lt;/h1&gt;|Have a great birth day!|\n+----------------------------------------------------------------------------------------------+-----------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------------------------------------------------------------------------------------------+-----------------------+\ntext                                                                                          |cleaned                |\n+----------------------------------------------------------------------------------------------+-----------------------+\n&lt;h1 style=&#34;color: #5e9ca0;&#34;&gt;Have a great &lt;span  style=&#34;color: #2b2301;&#34;&gt;birth&lt;/span&gt; day!&lt;/h1&gt;|Have a great birth day!|\n+----------------------------------------------------------------------------------------------+-----------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["find_not_alnum_count = lambda s: len([i for i in s if not i.isalnum() and i!=' '])\n\nfind_not_alnum_count(\"it's your birth day!\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d0cd3190-2067-4f72-bd2c-0a8333786cdc","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[111]: 2</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[111]: 2</div>"]}}],"execution_count":0},{"cell_type":"code","source":["text = '<h1 style=\"color: #5e9ca0;\">Have a great <span  style=\"color: #2b2301;\">birth</span> day!</h1>'\n\nfind_not_alnum_count(text)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"87e28ec7-b37d-4d92-a33a-3817900457a3","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[112]: 23</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[112]: 23</div>"]}}],"execution_count":0},{"cell_type":"code","source":["text_df.withColumn('cleaned', udf(find_not_alnum_count, IntegerType())('text')).select('text','cleaned').show(truncate= False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"abec629a-eee9-4f5d-9f6e-b6748987204c","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+----------------------------------------------------------------------------------------------+-------+\n|text                                                                                          |cleaned|\n+----------------------------------------------------------------------------------------------+-------+\n|&lt;h1 style=&#34;color: #5e9ca0;&#34;&gt;Have a great &lt;span  style=&#34;color: #2b2301;&#34;&gt;birth&lt;/span&gt; day!&lt;/h1&gt;|23     |\n+----------------------------------------------------------------------------------------------+-------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------------------------------------------------------------------------------------------+-------+\ntext                                                                                          |cleaned|\n+----------------------------------------------------------------------------------------------+-------+\n&lt;h1 style=&#34;color: #5e9ca0;&#34;&gt;Have a great &lt;span  style=&#34;color: #2b2301;&#34;&gt;birth&lt;/span&gt; day!&lt;/h1&gt;|23     |\n+----------------------------------------------------------------------------------------------+-------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Finisher"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d2e1dd3c-d47f-4f90-a3f7-c0c0f3154d87","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["***Finisher:*** Once we have our NLP pipeline ready to go, we might want to use our annotation results somewhere else where it is easy to use. The Finisher outputs annotation(s) values into a string.\n\nIf we just want the desired output column in the final dataframe, we can use Finisher to drop previous stages in the final output and get the `result` from the process.\n\nThis is very handy when you want to use the output from Spark NLP annotator as an input to another Spark ML transformer.\n\nSettable parameters are:\n\n`setInputCols()`\n\n`setOutputCols()`\n\n`setCleanAnnotations(True)` -> Whether to remove intermediate annotations\n\n`setValueSplitSymbol(“#”)` -> split values within an annotation character\n\n`setAnnotationSplitSymbol(“@”)` -> split values between annotations character\n\n`setIncludeMetadata(False)` -> Whether to include metadata keys. Sometimes useful in some annotations.\n\n`setOutputAsArray(False)` -> Whether to output as Array. Useful as input for other Spark transformers."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ee905adc-3f3a-4aa0-95ab-2da6cbb1b5b7","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["finisher = Finisher() \\\n    .setInputCols([\"regex_matches\"]) \\\n    .setIncludeMetadata(False) # set to False to remove metadata\n\nnlpPipeline = Pipeline(stages=[\n     documentAssembler, \n     regex_matcher,\n     finisher\n ])\n\nmatch_df = nlpPipeline.fit(pubMedDF).transform(pubMedDF)\nmatch_df.show(truncate = 50)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"14af4d1c-a8c3-403b-9011-6d84be469dc6","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+--------------------------------------------------+--------------------------------------------------+\n|                                              text|                            finished_regex_matches|\n+--------------------------------------------------+--------------------------------------------------+\n|The human KCNJ9 (Kir 3.3, GIRK3) is a member of...|[inwardly, family, spansapproximately, byapprox...|\n|BACKGROUND: At present, it is one of the most i...|[previously, previously, intravenously, previou...|\n|OBJECTIVE: To investigate the relationship betw...|[renal failure, cardiac surgery, cardiac surger...|\n|Combined EEG/fMRI recording has been used to lo...|[normally, significantly, effectively, analy, o...|\n|Kohlschutter syndrome is a rare neurodegenerati...|                                          [family]|\n|Statistical analysis of neuroimages is commonly...|[analy, commonly, overly, normally, thatsuccess...|\n|The synthetic DOX-LNA conjugate was characteriz...|                         [wasanaly, substantially]|\n|Our objective was to compare three different me...|[daily, only, Conversely, Hourly, hourly, Hourl...|\n|We conducted a phase II study to assess the eff...|[analy, respectively, generally, 5-fluorouracil...|\n|&#34;Monomeric sarcosine oxidase (MSOX) is a flavoe...|[cataly, methylgly, gly, ethylgly, dimethylgly,...|\n|We presented the tachinid fly Exorista japonica...|                         [fly, fly, fly, fly, fly]|\n|The literature dealing with the water conductin...|           [generally, mathematically, especially]|\n|A novel approach to synthesize chitosan-O-isopr...|[efficiently, poly, chitosan-O-isopropyl-5&#39;-O-d...|\n|An HPLC-ESI-MS-MS method has been developed for...|[chromatographically, respectively, successfull...|\n|The localizing and lateralizing values of eye a...|                                    [early, early]|\n|OBJECTIVE: To evaluate the effectiveness and ac...|[weekly, respectively, theanaly, 2006, 2007,, 2...|\n|For the construction of new combinatorial libra...|                                           [newly]|\n|We report the results of a screen for genetic a...|[poly, threepoly, significantly, analy, actuall...|\n|Intraparenchymal pericatheter cyst is rarely re...|              [rarely, possibly, unusually, Early]|\n|It is known that patients with Klinefelter&#39;s sy...|                                                []|\n+--------------------------------------------------+--------------------------------------------------+\nonly showing top 20 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------------------------------------+--------------------------------------------------+\n                                              text|                            finished_regex_matches|\n+--------------------------------------------------+--------------------------------------------------+\nThe human KCNJ9 (Kir 3.3, GIRK3) is a member of...|[inwardly, family, spansapproximately, byapprox...|\nBACKGROUND: At present, it is one of the most i...|[previously, previously, intravenously, previou...|\nOBJECTIVE: To investigate the relationship betw...|[renal failure, cardiac surgery, cardiac surger...|\nCombined EEG/fMRI recording has been used to lo...|[normally, significantly, effectively, analy, o...|\nKohlschutter syndrome is a rare neurodegenerati...|                                          [family]|\nStatistical analysis of neuroimages is commonly...|[analy, commonly, overly, normally, thatsuccess...|\nThe synthetic DOX-LNA conjugate was characteriz...|                         [wasanaly, substantially]|\nOur objective was to compare three different me...|[daily, only, Conversely, Hourly, hourly, Hourl...|\nWe conducted a phase II study to assess the eff...|[analy, respectively, generally, 5-fluorouracil...|\n&#34;Monomeric sarcosine oxidase (MSOX) is a flavoe...|[cataly, methylgly, gly, ethylgly, dimethylgly,...|\nWe presented the tachinid fly Exorista japonica...|                         [fly, fly, fly, fly, fly]|\nThe literature dealing with the water conductin...|           [generally, mathematically, especially]|\nA novel approach to synthesize chitosan-O-isopr...|[efficiently, poly, chitosan-O-isopropyl-5&#39;-O-d...|\nAn HPLC-ESI-MS-MS method has been developed for...|[chromatographically, respectively, successfull...|\nThe localizing and lateralizing values of eye a...|                                    [early, early]|\nOBJECTIVE: To evaluate the effectiveness and ac...|[weekly, respectively, theanaly, 2006, 2007,, 2...|\nFor the construction of new combinatorial libra...|                                           [newly]|\nWe report the results of a screen for genetic a...|[poly, threepoly, significantly, analy, actuall...|\nIntraparenchymal pericatheter cyst is rarely re...|              [rarely, possibly, unusually, Early]|\nIt is known that patients with Klinefelter&#39;s sy...|                                                []|\n+--------------------------------------------------+--------------------------------------------------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["match_df.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4f375408-0f1a-4e25-b890-cff84b504dac","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">root\n |-- text: string (nullable = true)\n |-- finished_regex_matches: array (nullable = true)\n |    |-- element: string (containsNull = true)\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- text: string (nullable = true)\n-- finished_regex_matches: array (nullable = true)\n    |-- element: string (containsNull = true)\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["match_df.filter(F.size('finished_regex_matches')>2).show(truncate = 50)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6c4d07ff-6234-4775-921e-8adffd77cf00","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+--------------------------------------------------+--------------------------------------------------+\n|                                              text|                            finished_regex_matches|\n+--------------------------------------------------+--------------------------------------------------+\n|The human KCNJ9 (Kir 3.3, GIRK3) is a member of...|[inwardly, family, spansapproximately, byapprox...|\n|BACKGROUND: At present, it is one of the most i...|[previously, previously, intravenously, previou...|\n|OBJECTIVE: To investigate the relationship betw...|[renal failure, cardiac surgery, cardiac surger...|\n|Combined EEG/fMRI recording has been used to lo...|[normally, significantly, effectively, analy, o...|\n|Statistical analysis of neuroimages is commonly...|[analy, commonly, overly, normally, thatsuccess...|\n|Our objective was to compare three different me...|[daily, only, Conversely, Hourly, hourly, Hourl...|\n|We conducted a phase II study to assess the eff...|[analy, respectively, generally, 5-fluorouracil...|\n|&#34;Monomeric sarcosine oxidase (MSOX) is a flavoe...|[cataly, methylgly, gly, ethylgly, dimethylgly,...|\n|We presented the tachinid fly Exorista japonica...|                         [fly, fly, fly, fly, fly]|\n|The literature dealing with the water conductin...|           [generally, mathematically, especially]|\n|A novel approach to synthesize chitosan-O-isopr...|[efficiently, poly, chitosan-O-isopropyl-5&#39;-O-d...|\n|An HPLC-ESI-MS-MS method has been developed for...|[chromatographically, respectively, successfull...|\n|OBJECTIVE: To evaluate the effectiveness and ac...|[weekly, respectively, theanaly, 2006, 2007,, 2...|\n|We report the results of a screen for genetic a...|[poly, threepoly, significantly, analy, actuall...|\n|Intraparenchymal pericatheter cyst is rarely re...|              [rarely, possibly, unusually, Early]|\n|PURPOSE: To compare the effectiveness, potentia...|[analy, comparatively, wassignificantly, respec...|\n|We have demonstrated a new type of all-optical ...|[approximately, fully, approximately, approxima...|\n|Physalis peruviana (PP) is a widely used medici...|[widely, (20,, 40,, 60,, 80, 95%, 100, 95%, (82...|\n|We report the discovery of a series of substitu...|[highly, potentially, highly, respectively, tub...|\n|The purpose of this study was to identify and c...|[family, Nearly, only, 43, 10, 44%, 32%, 64%, 4...|\n+--------------------------------------------------+--------------------------------------------------+\nonly showing top 20 rows\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------------------------------------+--------------------------------------------------+\n                                              text|                            finished_regex_matches|\n+--------------------------------------------------+--------------------------------------------------+\nThe human KCNJ9 (Kir 3.3, GIRK3) is a member of...|[inwardly, family, spansapproximately, byapprox...|\nBACKGROUND: At present, it is one of the most i...|[previously, previously, intravenously, previou...|\nOBJECTIVE: To investigate the relationship betw...|[renal failure, cardiac surgery, cardiac surger...|\nCombined EEG/fMRI recording has been used to lo...|[normally, significantly, effectively, analy, o...|\nStatistical analysis of neuroimages is commonly...|[analy, commonly, overly, normally, thatsuccess...|\nOur objective was to compare three different me...|[daily, only, Conversely, Hourly, hourly, Hourl...|\nWe conducted a phase II study to assess the eff...|[analy, respectively, generally, 5-fluorouracil...|\n&#34;Monomeric sarcosine oxidase (MSOX) is a flavoe...|[cataly, methylgly, gly, ethylgly, dimethylgly,...|\nWe presented the tachinid fly Exorista japonica...|                         [fly, fly, fly, fly, fly]|\nThe literature dealing with the water conductin...|           [generally, mathematically, especially]|\nA novel approach to synthesize chitosan-O-isopr...|[efficiently, poly, chitosan-O-isopropyl-5&#39;-O-d...|\nAn HPLC-ESI-MS-MS method has been developed for...|[chromatographically, respectively, successfull...|\nOBJECTIVE: To evaluate the effectiveness and ac...|[weekly, respectively, theanaly, 2006, 2007,, 2...|\nWe report the results of a screen for genetic a...|[poly, threepoly, significantly, analy, actuall...|\nIntraparenchymal pericatheter cyst is rarely re...|              [rarely, possibly, unusually, Early]|\nPURPOSE: To compare the effectiveness, potentia...|[analy, comparatively, wassignificantly, respec...|\nWe have demonstrated a new type of all-optical ...|[approximately, fully, approximately, approxima...|\nPhysalis peruviana (PP) is a widely used medici...|[widely, (20,, 40,, 60,, 80, 95%, 100, 95%, (82...|\nWe report the discovery of a series of substitu...|[highly, potentially, highly, respectively, tub...|\nThe purpose of this study was to identify and c...|[family, Nearly, only, 43, 10, 44%, 32%, 64%, 4...|\n+--------------------------------------------------+--------------------------------------------------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## LightPipeline\n\nhttps://medium.com/spark-nlp/spark-nlp-101-lightpipeline-a544e93f20f1"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"de4b6d0f-1ab9-4007-926b-8c727946c5aa","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["LightPipelines are Spark NLP specific Pipelines, equivalent to Spark ML Pipeline, but meant to deal with smaller amounts of data. They’re useful working with small datasets, debugging results, or when running either training or prediction from an API that serves one-off requests.\n\nSpark NLP LightPipelines are Spark ML pipelines converted into a single machine but the multi-threaded task, becoming more than 10x times faster for smaller amounts of data (small is relative, but 50k sentences are roughly a good maximum). To use them, we simply plug in a trained (fitted) pipeline and then annotate a plain text. We don't even need to convert the input text to DataFrame in order to feed it into a pipeline that's accepting DataFrame as an input in the first place. This feature would be quite useful when it comes to getting a prediction for a few lines of text from a trained ML model.\n\n **It is nearly 10x faster than using Spark ML Pipeline**\n\n`LightPipeline(someTrainedPipeline).annotate(someStringOrArray)`"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5b3535a7-4e3d-4b34-b0b3-948150d5ce55","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["documentAssembler = DocumentAssembler()\\\n    .setInputCol(\"text\")\\\n    .setOutputCol(\"document\")\n\ntokenizer = Tokenizer() \\\n    .setInputCols([\"document\"]) \\\n    .setOutputCol(\"token\")\n\nstemmer = Stemmer() \\\n    .setInputCols([\"token\"]) \\\n    .setOutputCol(\"stem\")\n\nlemmatizer = Lemmatizer() \\\n    .setInputCols([\"token\"]) \\\n    .setOutputCol(\"lemma\") \\\n    .setDictionary(\"dbfs:/AntBNC_lemmas_ver_001.txt\", value_delimiter =\"\\t\", key_delimiter = \"->\")\n\nnlpPipeline = Pipeline(stages=[\n     documentAssembler, \n     tokenizer,\n     stemmer,\n     lemmatizer\n ])\n\nempty_df = spark.createDataFrame([['']]).toDF(\"text\")\n\npipelineModel = nlpPipeline.fit(empty_df)\n\npipelineModel.transform(spark_df).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7a50ac78-e1fe-48d9-99a4-dbf22bfcb483","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+--------------------+--------------------+--------------------+--------------------+--------------------+\n|                text|            document|               token|                stem|               lemma|\n+--------------------+--------------------+--------------------+--------------------+--------------------+\n|Peter is a very g...|[{document, 0, 27...|[{token, 0, 4, Pe...|[{token, 0, 4, pe...|[{token, 0, 4, Pe...|\n|My life in Russia...|[{document, 0, 37...|[{token, 0, 1, My...|[{token, 0, 1, my...|[{token, 0, 1, My...|\n|John and Peter ar...|[{document, 0, 76...|[{token, 0, 3, Jo...|[{token, 0, 3, jo...|[{token, 0, 3, Jo...|\n|Lucas Nogal Dunbe...|[{document, 0, 67...|[{token, 0, 4, Lu...|[{token, 0, 4, lu...|[{token, 0, 4, Lu...|\n|Europe is very cu...|[{document, 0, 68...|[{token, 0, 5, Eu...|[{token, 0, 5, eu...|[{token, 0, 5, Eu...|\n+--------------------+--------------------+--------------------+--------------------+--------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+--------------------+--------------------+--------------------+--------------------+\n                text|            document|               token|                stem|               lemma|\n+--------------------+--------------------+--------------------+--------------------+--------------------+\nPeter is a very g...|[{document, 0, 27...|[{token, 0, 4, Pe...|[{token, 0, 4, pe...|[{token, 0, 4, Pe...|\nMy life in Russia...|[{document, 0, 37...|[{token, 0, 1, My...|[{token, 0, 1, my...|[{token, 0, 1, My...|\nJohn and Peter ar...|[{document, 0, 76...|[{token, 0, 3, Jo...|[{token, 0, 3, jo...|[{token, 0, 3, Jo...|\nLucas Nogal Dunbe...|[{document, 0, 67...|[{token, 0, 4, Lu...|[{token, 0, 4, lu...|[{token, 0, 4, Lu...|\nEurope is very cu...|[{document, 0, 68...|[{token, 0, 5, Eu...|[{token, 0, 5, eu...|[{token, 0, 5, Eu...|\n+--------------------+--------------------+--------------------+--------------------+--------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["from sparknlp.base import LightPipeline\n\nlight_model = LightPipeline(pipelineModel)\n\nlight_result = light_model.annotate(\"John and Peter are brothers. However they don't support each other that much.\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a9f974e6-2e42-430a-8daa-3fbff06fecf7","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["light_result.keys()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"63656c1f-fb62-4ab0-8e56-0e2f50579786","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[119]: dict_keys([&#39;document&#39;, &#39;token&#39;, &#39;stem&#39;, &#39;lemma&#39;])</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[119]: dict_keys([&#39;document&#39;, &#39;token&#39;, &#39;stem&#39;, &#39;lemma&#39;])</div>"]}}],"execution_count":0},{"cell_type":"code","source":["list(zip(light_result['token'], light_result['stem'], light_result['lemma']))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"45166c74-9d76-4c11-9c3c-a5a028c54100","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[120]: [(&#39;John&#39;, &#39;john&#39;, &#39;John&#39;),\n (&#39;and&#39;, &#39;and&#39;, &#39;and&#39;),\n (&#39;Peter&#39;, &#39;peter&#39;, &#39;Peter&#39;),\n (&#39;are&#39;, &#39;ar&#39;, &#39;be&#39;),\n (&#39;brothers&#39;, &#39;brother&#39;, &#39;brother&#39;),\n (&#39;.&#39;, &#39;.&#39;, &#39;.&#39;),\n (&#39;However&#39;, &#39;howev&#39;, &#39;However&#39;),\n (&#39;they&#39;, &#39;thei&#39;, &#39;they&#39;),\n (&#34;don&#39;t&#34;, &#34;don&#39;t&#34;, &#34;don&#39;t&#34;),\n (&#39;support&#39;, &#39;support&#39;, &#39;support&#39;),\n (&#39;each&#39;, &#39;each&#39;, &#39;each&#39;),\n (&#39;other&#39;, &#39;other&#39;, &#39;other&#39;),\n (&#39;that&#39;, &#39;that&#39;, &#39;that&#39;),\n (&#39;much&#39;, &#39;much&#39;, &#39;much&#39;),\n (&#39;.&#39;, &#39;.&#39;, &#39;.&#39;)]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[120]: [(&#39;John&#39;, &#39;john&#39;, &#39;John&#39;),\n (&#39;and&#39;, &#39;and&#39;, &#39;and&#39;),\n (&#39;Peter&#39;, &#39;peter&#39;, &#39;Peter&#39;),\n (&#39;are&#39;, &#39;ar&#39;, &#39;be&#39;),\n (&#39;brothers&#39;, &#39;brother&#39;, &#39;brother&#39;),\n (&#39;.&#39;, &#39;.&#39;, &#39;.&#39;),\n (&#39;However&#39;, &#39;howev&#39;, &#39;However&#39;),\n (&#39;they&#39;, &#39;thei&#39;, &#39;they&#39;),\n (&#34;don&#39;t&#34;, &#34;don&#39;t&#34;, &#34;don&#39;t&#34;),\n (&#39;support&#39;, &#39;support&#39;, &#39;support&#39;),\n (&#39;each&#39;, &#39;each&#39;, &#39;each&#39;),\n (&#39;other&#39;, &#39;other&#39;, &#39;other&#39;),\n (&#39;that&#39;, &#39;that&#39;, &#39;that&#39;),\n (&#39;much&#39;, &#39;much&#39;, &#39;much&#39;),\n (&#39;.&#39;, &#39;.&#39;, &#39;.&#39;)]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["light_result = light_model.fullAnnotate(\"John and Peter are brothers. However they don't support each other that much.\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e1e5cbc5-5a2e-4651-bec7-71d2d3cbe350","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["light_result"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"47e66689-5d60-4e86-81b4-7d0ea320bc11","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[122]: [{&#39;document&#39;: [Annotation(document, 0, 76, John and Peter are brothers. However they don&#39;t support each other that much., {})],\n  &#39;token&#39;: [Annotation(token, 0, 3, John, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 5, 7, and, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 9, 13, Peter, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 15, 17, are, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 19, 26, brothers, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 27, 27, ., {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 29, 35, However, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 37, 40, they, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 42, 46, don&#39;t, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 48, 54, support, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 56, 59, each, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 61, 65, other, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 67, 70, that, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 72, 75, much, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 76, 76, ., {&#39;sentence&#39;: &#39;0&#39;})],\n  &#39;stem&#39;: [Annotation(token, 0, 3, john, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 5, 7, and, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 9, 13, peter, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 15, 17, ar, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 19, 26, brother, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 27, 27, ., {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 29, 35, howev, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 37, 40, thei, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 42, 46, don&#39;t, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 48, 54, support, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 56, 59, each, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 61, 65, other, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 67, 70, that, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 72, 75, much, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 76, 76, ., {&#39;sentence&#39;: &#39;0&#39;})],\n  &#39;lemma&#39;: [Annotation(token, 0, 3, John, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 5, 7, and, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 9, 13, Peter, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 15, 17, be, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 19, 26, brother, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 27, 27, ., {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 29, 35, However, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 37, 40, they, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 42, 46, don&#39;t, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 48, 54, support, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 56, 59, each, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 61, 65, other, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 67, 70, that, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 72, 75, much, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 76, 76, ., {&#39;sentence&#39;: &#39;0&#39;})]}]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[122]: [{&#39;document&#39;: [Annotation(document, 0, 76, John and Peter are brothers. However they don&#39;t support each other that much., {})],\n  &#39;token&#39;: [Annotation(token, 0, 3, John, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 5, 7, and, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 9, 13, Peter, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 15, 17, are, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 19, 26, brothers, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 27, 27, ., {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 29, 35, However, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 37, 40, they, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 42, 46, don&#39;t, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 48, 54, support, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 56, 59, each, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 61, 65, other, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 67, 70, that, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 72, 75, much, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 76, 76, ., {&#39;sentence&#39;: &#39;0&#39;})],\n  &#39;stem&#39;: [Annotation(token, 0, 3, john, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 5, 7, and, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 9, 13, peter, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 15, 17, ar, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 19, 26, brother, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 27, 27, ., {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 29, 35, howev, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 37, 40, thei, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 42, 46, don&#39;t, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 48, 54, support, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 56, 59, each, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 61, 65, other, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 67, 70, that, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 72, 75, much, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 76, 76, ., {&#39;sentence&#39;: &#39;0&#39;})],\n  &#39;lemma&#39;: [Annotation(token, 0, 3, John, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 5, 7, and, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 9, 13, Peter, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 15, 17, be, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 19, 26, brother, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 27, 27, ., {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 29, 35, However, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 37, 40, they, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 42, 46, don&#39;t, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 48, 54, support, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 56, 59, each, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 61, 65, other, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 67, 70, that, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 72, 75, much, {&#39;sentence&#39;: &#39;0&#39;}),\n   Annotation(token, 76, 76, ., {&#39;sentence&#39;: &#39;0&#39;})]}]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["text_list= [\"How did serfdom develop in and then leave Russia ?\",\n\"There will be some exciting breakthroughs in NLP this year.\"]\n\nlight_model.annotate(text_list)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"af2a1445-1bba-45be-a39b-bb65d979053e","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[123]: [{&#39;document&#39;: [&#39;How did serfdom develop in and then leave Russia ?&#39;],\n  &#39;token&#39;: [&#39;How&#39;,\n   &#39;did&#39;,\n   &#39;serfdom&#39;,\n   &#39;develop&#39;,\n   &#39;in&#39;,\n   &#39;and&#39;,\n   &#39;then&#39;,\n   &#39;leave&#39;,\n   &#39;Russia&#39;,\n   &#39;?&#39;],\n  &#39;stem&#39;: [&#39;how&#39;,\n   &#39;did&#39;,\n   &#39;serfdom&#39;,\n   &#39;develop&#39;,\n   &#39;in&#39;,\n   &#39;and&#39;,\n   &#39;then&#39;,\n   &#39;leav&#39;,\n   &#39;russia&#39;,\n   &#39;?&#39;],\n  &#39;lemma&#39;: [&#39;How&#39;,\n   &#39;do&#39;,\n   &#39;serfdom&#39;,\n   &#39;develop&#39;,\n   &#39;in&#39;,\n   &#39;and&#39;,\n   &#39;then&#39;,\n   &#39;leave&#39;,\n   &#39;Russia&#39;,\n   &#39;?&#39;]},\n {&#39;document&#39;: [&#39;There will be some exciting breakthroughs in NLP this year.&#39;],\n  &#39;token&#39;: [&#39;There&#39;,\n   &#39;will&#39;,\n   &#39;be&#39;,\n   &#39;some&#39;,\n   &#39;exciting&#39;,\n   &#39;breakthroughs&#39;,\n   &#39;in&#39;,\n   &#39;NLP&#39;,\n   &#39;this&#39;,\n   &#39;year&#39;,\n   &#39;.&#39;],\n  &#39;stem&#39;: [&#39;there&#39;,\n   &#39;will&#39;,\n   &#39;be&#39;,\n   &#39;some&#39;,\n   &#39;excit&#39;,\n   &#39;breakthrough&#39;,\n   &#39;in&#39;,\n   &#39;nlp&#39;,\n   &#39;thi&#39;,\n   &#39;year&#39;,\n   &#39;.&#39;],\n  &#39;lemma&#39;: [&#39;There&#39;,\n   &#39;will&#39;,\n   &#39;be&#39;,\n   &#39;some&#39;,\n   &#39;exciting&#39;,\n   &#39;breakthrough&#39;,\n   &#39;in&#39;,\n   &#39;NLP&#39;,\n   &#39;this&#39;,\n   &#39;year&#39;,\n   &#39;.&#39;]}]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[123]: [{&#39;document&#39;: [&#39;How did serfdom develop in and then leave Russia ?&#39;],\n  &#39;token&#39;: [&#39;How&#39;,\n   &#39;did&#39;,\n   &#39;serfdom&#39;,\n   &#39;develop&#39;,\n   &#39;in&#39;,\n   &#39;and&#39;,\n   &#39;then&#39;,\n   &#39;leave&#39;,\n   &#39;Russia&#39;,\n   &#39;?&#39;],\n  &#39;stem&#39;: [&#39;how&#39;,\n   &#39;did&#39;,\n   &#39;serfdom&#39;,\n   &#39;develop&#39;,\n   &#39;in&#39;,\n   &#39;and&#39;,\n   &#39;then&#39;,\n   &#39;leav&#39;,\n   &#39;russia&#39;,\n   &#39;?&#39;],\n  &#39;lemma&#39;: [&#39;How&#39;,\n   &#39;do&#39;,\n   &#39;serfdom&#39;,\n   &#39;develop&#39;,\n   &#39;in&#39;,\n   &#39;and&#39;,\n   &#39;then&#39;,\n   &#39;leave&#39;,\n   &#39;Russia&#39;,\n   &#39;?&#39;]},\n {&#39;document&#39;: [&#39;There will be some exciting breakthroughs in NLP this year.&#39;],\n  &#39;token&#39;: [&#39;There&#39;,\n   &#39;will&#39;,\n   &#39;be&#39;,\n   &#39;some&#39;,\n   &#39;exciting&#39;,\n   &#39;breakthroughs&#39;,\n   &#39;in&#39;,\n   &#39;NLP&#39;,\n   &#39;this&#39;,\n   &#39;year&#39;,\n   &#39;.&#39;],\n  &#39;stem&#39;: [&#39;there&#39;,\n   &#39;will&#39;,\n   &#39;be&#39;,\n   &#39;some&#39;,\n   &#39;excit&#39;,\n   &#39;breakthrough&#39;,\n   &#39;in&#39;,\n   &#39;nlp&#39;,\n   &#39;thi&#39;,\n   &#39;year&#39;,\n   &#39;.&#39;],\n  &#39;lemma&#39;: [&#39;There&#39;,\n   &#39;will&#39;,\n   &#39;be&#39;,\n   &#39;some&#39;,\n   &#39;exciting&#39;,\n   &#39;breakthrough&#39;,\n   &#39;in&#39;,\n   &#39;NLP&#39;,\n   &#39;this&#39;,\n   &#39;year&#39;,\n   &#39;.&#39;]}]</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["**important note:** When you use Finisher in your pipeline, regardless of setting `cleanAnnotations` to False or True, LightPipeline will only return the finished columns."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b63c7abc-5591-4971-9d90-0a0073d344e2","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["End of Notebook #"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"edc724a7-36d2-4005-b4b1-a47b789f10ac","inputWidgets":{},"title":""}}}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.8.3","nbconvert_exporter":"python","file_extension":".py"},"application/vnd.databricks.v1+notebook":{"notebookName":"7. Text Preprocessing Annotators with Spark NLP","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":557198484821803}},"nbformat":4,"nbformat_minor":0}
