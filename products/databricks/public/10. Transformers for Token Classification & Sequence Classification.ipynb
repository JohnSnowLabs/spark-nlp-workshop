{"cells":[{"cell_type":"markdown","source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d8769aeb-3269-4327-ad36-6a4dee9c4911","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["# 10.  Transformers for Token Classification & Sequence  Classification"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4e702a48-dafe-42dc-8f9f-7c7e2556062e","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["import sparknlp\nfrom sparknlp.base import *\nfrom sparknlp.annotator import *\nfrom pyspark.sql import functions as F\nimport pandas as pd\n\nprint(\"Spark NLP version\", sparknlp.version())\n\nprint(\"Apache Spark version:\", spark.version)\n\nspark"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"30bb1ab1-0b39-4038-8267-57cf365501ac","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Spark NLP version 4.2.4\nApache Spark version: 3.1.2\nOut[1]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Spark NLP version 4.2.4\nApache Spark version: 3.1.2\nOut[1]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=7956323724731612#setting/sparkui/0616-152819-zhyjt0vc/driver-5469149884947606742\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.1.2</code></dd>\n              <dt>Master</dt>\n                <dd><code>spark://10.139.64.6:7077</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=7956323724731612#setting/sparkui/0616-152819-zhyjt0vc/driver-5469149884947606742\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.1.2</code></dd>\n              <dt>Master</dt>\n                <dd><code>spark://10.139.64.6:7077</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "]}}],"execution_count":0},{"cell_type":"markdown","source":["# Transformers for Token Classification in Spark NLP"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5ff26fbc-0389-4caf-946e-a9b1b3dd826b","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["**BertForTokenClassification** can load Bert Models with a token classification head on top (a linear layer on top of the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks.\n\nPretrained models can be loaded with `pretrained()` of the companion object. The default model is `\"bert_base_token_classifier_conll03\"`, if no name is provided. <br/><br/>\n\n\n### **Here are Bert Based Token Classification models available in Spark NLP**\n<br/>\n\n| Title                                                                                                                        | Name                                          | Language   |\n|:-----------------------------------------------------------------------------------------------------------------------------|:----------------------------------------------|:-----------|\n| BERT Token Classification - NER CoNLL (bert_base_token_classifier_conll03)                                                   | bert_base_token_classifier_conll03            | en         |\n| BERT Token Classification - NER OntoNotes (bert_base_token_classifier_ontonote)                                              | bert_base_token_classifier_ontonote           | en         |\n| BERT Token Classification Large - NER CoNLL (bert_large_token_classifier_conll03)                                            | bert_large_token_classifier_conll03           | en         |\n| BERT Token Classification Large - NER OntoNotes (bert_large_token_classifier_ontonote)                                       | bert_large_token_classifier_ontonote          | en         |\n| BERT Token Classification - ParsBERT for Persian Language Understanding (bert_token_classifier_parsbert_armanner)            | bert_token_classifier_parsbert_armanner       | fa         |\n| BERT Token Classification - ParsBERT for Persian Language Understanding (bert_token_classifier_parsbert_ner)                 | bert_token_classifier_parsbert_ner            | fa         |\n| BERT Token Classification - ParsBERT for Persian Language Understanding (bert_token_classifier_parsbert_peymaner)            | bert_token_classifier_parsbert_peymaner       | fa         |\n| BERT Token Classification - BETO Spanish Language Understanding (bert_token_classifier_spanish_ner)                          | bert_token_classifier_spanish_ner             | es         |\n| BERT Token Classification - Swedish Language Understanding (bert_token_classifier_swedish_ner)                               | bert_token_classifier_swedish_ner             | sv         |\n| BERT Token Classification - Turkish Language Understanding (bert_token_classifier_turkish_ner)                               | bert_token_classifier_turkish_ner             | tr         |\n| DistilBERT Token Classification - NER CoNLL (distilbert_base_token_classifier_conll03)                                       | distilbert_base_token_classifier_conll03      | en         |\n| DistilBERT Token Classification - NER OntoNotes (distilbert_base_token_classifier_ontonotes)                                 | distilbert_base_token_classifier_ontonotes    | en         |\n| DistilBERT Token Classification - DistilbertNER for Persian Language Understanding (distilbert_token_classifier_persian_ner) | distilbert_token_classifier_persian_ner       | fa         |\n| BERT Token Classification -  Few-NERD (bert_base_token_classifier_few_nerd)                                                  | bert_base_token_classifier_few_nerd           | en         |\n| DistilBERT Token Classification -  Few-NERD (distilbert_base_token_classifier_few_nerd)                                      | distilbert_base_token_classifier_few_nerd     | en         |\n| Named Entity Recognition for Japanese (BertForTokenClassification)                                                           | bert_token_classifier_ner_ud_gsd              | ja         |\n| Detect PHI for Deidentification (BertForTokenClassifier)                                                                     | bert_token_classifier_ner_deid                | en         |\n| Detect Clinical Entities (BertForTokenClassifier)                                                                            | bert_token_classifier_ner_jsl                 | en         |\n| Detect Drug Chemicals (BertForTokenClassifier)                                                                               | bert_token_classifier_ner_drugs               | en         |\n| Detect Clinical Entities (Slim version, BertForTokenClassifier)                                                              | bert_token_classifier_ner_jsl_slim            | en         |\n| ALBERT Token Classification Base - NER CoNLL (albert_base_token_classifier_conll03)                                          | albert_base_token_classifier_conll03          | en         |\n| ALBERT Token Classification Large - NER CoNLL (albert_large_token_classifier_conll03)                                        | albert_large_token_classifier_conll03         | en         |\n| ALBERT Token Classification XLarge - NER CoNLL (albert_xlarge_token_classifier_conll03)                                      | albert_xlarge_token_classifier_conll03        | en         |\n| DistilRoBERTa Token Classification - NER OntoNotes (distilroberta_base_token_classifier_ontonotes)                           | distilroberta_base_token_classifier_ontonotes | en         |\n| RoBERTa Token Classification Base - NER CoNLL (roberta_base_token_classifier_conll03)                                        | roberta_base_token_classifier_conll03         | en         |\n| RoBERTa Token Classification Base - NER OntoNotes (roberta_base_token_classifier_ontonotes)                                  | roberta_base_token_classifier_ontonotes       | en         |\n| RoBERTa Token Classification Large - NER CoNLL (roberta_large_token_classifier_conll03)                                      | roberta_large_token_classifier_conll03        | en         |\n| RoBERTa Token Classification Large - NER OntoNotes (roberta_large_token_classifier_ontonotes)                                | roberta_large_token_classifier_ontonotes      | en         |\n| RoBERTa Token Classification For Persian (roberta_token_classifier_zwnj_base_ner)                                            | roberta_token_classifier_zwnj_base_ner        | fa         |\n| XLM-RoBERTa Token Classification Base - NER XTREME (xlm_roberta_token_classifier_ner_40_lang)                                | xlm_roberta_token_classifier_ner_40_lang      | xx         |\n| XLNet Token Classification Base - NER CoNLL (xlnet_base_token_classifier_conll03)                                            | xlnet_base_token_classifier_conll03           | en         |\n| XLNet Token Classification Large - NER CoNLL (xlnet_large_token_classifier_conll03)                                          | xlnet_large_token_classifier_conll03          | en         |\n| Detect Adverse Drug Events (BertForTokenClassification)                                                                      | bert_token_classifier_ner_ade                 | en         |\n| Detect Anatomical Regions (BertForTokenClassification)                                                                       | bert_token_classifier_ner_anatomy             | en         |\n| Detect Bacterial Species (BertForTokenClassification)                                                                        | bert_token_classifier_ner_bacteria            | en         |\n| XLM-RoBERTa Token Classification Base - NER CoNLL (xlm_roberta_base_token_classifier_conll03)                                | xlm_roberta_base_token_classifier_conll03     | en         |\n| XLM-RoBERTa Token Classification Base - NER OntoNotes (xlm_roberta_base_token_classifier_ontonotes)                          | xlm_roberta_base_token_classifier_ontonotes   | en         |\n| Longformer Token Classification Base - NER CoNLL (longformer_base_token_classifier_conll03)                                  | longformer_base_token_classifier_conll03      | en         |\n| Longformer Token Classification Base - NER CoNLL (longformer_large_token_classifier_conll03)                                 | longformer_large_token_classifier_conll03     | en         |\n| Detect Chemicals in Medical text (BertForTokenClassification)                                                                | bert_token_classifier_ner_chemicals           | en         |\n| Detect Chemical Compounds and Genes (BertForTokenClassifier)                                                                 | bert_token_classifier_ner_chemprot            | en         |\n| Detect Cancer Genetics (BertForTokenClassification)                                                                          | bert_token_classifier_ner_bionlp              | en         |\n| Detect Cellular/Molecular Biology Entities (BertForTokenClassification)                                                      | bert_token_classifier_ner_cellular            | en         |\n| Detect concepts in drug development trials (BertForTokenClassification)                                                      | bert_token_classifier_drug_development_trials | en         |\n| Detect Cancer Genetics (BertForTokenClassification)                                                                          | bert_token_classifier_ner_bionlp              | en         |\n| Detect Adverse Drug Events (BertForTokenClassification)                                                                      | bert_token_classifier_ner_ade                 | en         |\n| Detect Anatomical Regions (MedicalBertForTokenClassifier)                                                                    | bert_token_classifier_ner_anatomy             | en         |\n| Detect Cellular/Molecular Biology Entities (BertForTokenClassification)                                                      | bert_token_classifier_ner_cellular            | en         |\n| Detect Chemicals in Medical text (BertForTokenClassification)                                                                | bert_token_classifier_ner_chemicals           | en         |\n| Detect Chemical Compounds and Genes (BertForTokenClassifier)                                                                 | bert_token_classifier_ner_chemprot            | en         |\n| Detect PHI for Deidentification (BertForTokenClassifier)                                                                     | bert_token_classifier_ner_deid                | en         |\n| Detect Drug Chemicals (BertForTokenClassifier)                                                                               | bert_token_classifier_ner_drugs               | en         |\n| Detect Clinical Entities (BertForTokenClassifier)                                                                            | bert_token_classifier_ner_jsl                 | en         |\n| Detect Clinical Entities (Slim version, BertForTokenClassifier)                                                              | bert_token_classifier_ner_jsl_slim            | en         |\n| Detect Bacterial Species (BertForTokenClassification)                                                                        | bert_token_classifier_ner_bacteria            | en         |"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f5551c77-820b-4c01-9a17-d1c4ad396945","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["You can also import any models trained with the transformers library into Spark NLP for greater inference speed & scalability. Access our tutorials to do so in [this discussion thread](https://github.com/JohnSnowLabs/spark-nlp/discussions/5669). You will find notebooks like [this one](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/transformers/HuggingFace%20in%20Spark%20NLP%20-%20BertForTokenClassification.ipynb) to import BertForTokenClassification models. The process is very straightforward and can be done in a few lines of code. Once you've downloaded the model and extracted its contents as described in the notebooks, it's as simple as running the following snippet:"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f9cf8231-cfe3-47b7-bf01-d26af8a5ce9e","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["```\ntokenClassifier = BertForTokenClassification.loadSavedModel(\n     '{}/saved_model/1'.format(MODEL_NAME), spark)\\\n .setInputCols([\"document\",'token'])\\\n .setOutputCol(\"ner\")\\\n .setCaseSensitive(True)\\\n .setMaxSentenceLength(128)\n\ntokenClassifier.write().overwrite().save(\"./{}_spark_nlp\".format(MODEL_NAME))\n```"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c10caf1c-019b-4061-9b21-92e43c70a0cd","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["## BertForTokenClassification Pipeline"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7c2f4415-bb31-463d-8c2e-3352847a2a0c","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["Now, let's create a Spark NLP Pipeline with `bert_base_token_classifier_conll03` model and check the results. <br/>"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"55a6ac5c-552b-44f5-837a-e8c4c3398538","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["document_assembler = DocumentAssembler() \\\n    .setInputCol('text') \\\n    .setOutputCol('document')\n\ntokenizer = Tokenizer() \\\n    .setInputCols(['document']) \\\n    .setOutputCol('token')\n\ntokenClassifier = BertForTokenClassification \\\n    .pretrained('bert_base_token_classifier_conll03', 'en') \\\n    .setInputCols(['token', 'document']) \\\n    .setOutputCol('ner') \\\n    .setCaseSensitive(True) \\\n    .setMaxSentenceLength(512)\n\n# since output column is IOB/IOB2 style, NerConverter can extract entities\nner_converter = NerConverter() \\\n    .setInputCols(['document', 'token', 'ner']) \\\n    .setOutputCol('entities')\n\npipeline = Pipeline(stages=[\n    document_assembler, \n    tokenizer,\n    tokenClassifier,\n    ner_converter\n])\n\nexample = spark.createDataFrame([['My name is John Parker! I live in New York and I am a member of the New York Road Runners.']]).toDF(\"text\")\nmodel = pipeline.fit(example)\nresult= model.transform(example)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"cfeabb9e-0809-43f3-89f8-1499b13f3e02","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">bert_base_token_classifier_conll03 download started this may take some time.\nApproximate size to download 385.4 MB\n\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[OK!]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">bert_base_token_classifier_conll03 download started this may take some time.\nApproximate size to download 385.4 MB\n\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[OK!]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["model.stages"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4cd079b8-7c95-463a-b542-da0645ec1306","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[3]: [DocumentAssembler_9901b2425e67,\n REGEX_TOKENIZER_b5dbdf23cfdb,\n BERT_FOR_TOKEN_CLASSIFICATION_675a6a750b89,\n NerConverter_770e1bc9c280]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[3]: [DocumentAssembler_9901b2425e67,\n REGEX_TOKENIZER_b5dbdf23cfdb,\n BERT_FOR_TOKEN_CLASSIFICATION_675a6a750b89,\n NerConverter_770e1bc9c280]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["tokenClassifier.getClasses()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e4aa3d5f-e1b8-4023-878b-7ddde1c76da0","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[4]: [&#39;B-LOC&#39;, &#39;I-ORG&#39;, &#39;I-MISC&#39;, &#39;I-LOC&#39;, &#39;I-PER&#39;, &#39;B-MISC&#39;, &#39;B-ORG&#39;, &#39;O&#39;, &#39;B-PER&#39;]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[4]: [&#39;B-LOC&#39;, &#39;I-ORG&#39;, &#39;I-MISC&#39;, &#39;I-LOC&#39;, &#39;I-PER&#39;, &#39;B-MISC&#39;, &#39;B-ORG&#39;, &#39;O&#39;, &#39;B-PER&#39;]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["result.columns"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"38e0722e-00eb-42e8-861f-c79cb577a7a2","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[5]: [&#39;text&#39;, &#39;document&#39;, &#39;token&#39;, &#39;ner&#39;, &#39;entities&#39;]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[5]: [&#39;text&#39;, &#39;document&#39;, &#39;token&#39;, &#39;ner&#39;, &#39;entities&#39;]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["result_df = result.select(F.explode(F.arrays_zip(result.token.result, result.ner.result, result.entities.result)).alias(\"cols\"))\\\n                  .select(F.expr(\"cols['0']\").alias(\"token\"),\n                          F.expr(\"cols['1']\").alias(\"ner_label\"))\n\nresult_df.show(50, truncate=100)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"54f4bb4d-2c52-4255-a93e-72e023c29771","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-------+---------+\n|  token|ner_label|\n+-------+---------+\n|     My|        O|\n|   name|        O|\n|     is|        O|\n|   John|    B-PER|\n| Parker|    I-PER|\n|      !|        O|\n|      I|        O|\n|   live|        O|\n|     in|        O|\n|    New|    B-LOC|\n|   York|    I-LOC|\n|    and|        O|\n|      I|        O|\n|     am|        O|\n|      a|        O|\n| member|        O|\n|     of|        O|\n|    the|        O|\n|    New|    B-ORG|\n|   York|    I-ORG|\n|   Road|    I-ORG|\n|Runners|    I-ORG|\n|      .|        O|\n+-------+---------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+---------+\n  token|ner_label|\n+-------+---------+\n     My|        O|\n   name|        O|\n     is|        O|\n   John|    B-PER|\n Parker|    I-PER|\n      !|        O|\n      I|        O|\n   live|        O|\n     in|        O|\n    New|    B-LOC|\n   York|    I-LOC|\n    and|        O|\n      I|        O|\n     am|        O|\n      a|        O|\n member|        O|\n     of|        O|\n    the|        O|\n    New|    B-ORG|\n   York|    I-ORG|\n   Road|    I-ORG|\nRunners|    I-ORG|\n      .|        O|\n+-------+---------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["result_df_1= result.select(F.explode(F.arrays_zip(result.entities.result, result.entities.begin, result.entities.end, result.entities.metadata)).alias(\"col\"))\\\n                   .select(F.expr(\"col['0']\").alias(\"entities\"),\n                            F.expr(\"col['1']\").alias(\"begin\"),\n                            F.expr(\"col['2']\").alias(\"end\"),\n                            F.expr(\"col['3']['entity']\").alias(\"ner_label\"))\nresult_df_1.show(50, truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"eae749f5-928e-4a12-a8ab-53446c090f31","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+---------------------+-----+---+---------+\n|entities             |begin|end|ner_label|\n+---------------------+-----+---+---------+\n|John Parker          |11   |21 |PER      |\n|New York             |34   |41 |LOC      |\n|New York Road Runners|68   |88 |ORG      |\n+---------------------+-----+---+---------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------------------+-----+---+---------+\nentities             |begin|end|ner_label|\n+---------------------+-----+---+---------+\nJohn Parker          |11   |21 |PER      |\nNew York             |34   |41 |LOC      |\nNew York Road Runners|68   |88 |ORG      |\n+---------------------+-----+---+---------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["##  BertForTokenClassification By Using LightPipeline"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"916f60e8-4d85-4b7e-8ace-429a2bedda12","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["Now,  we will use the `bert_large_token_classifier_ontonote` model with LightPipeline and fullAnnotate it with sample data."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"58a5f8dd-9199-4136-b715-ec852ffbd933","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["document_assembler = DocumentAssembler() \\\n    .setInputCol('text') \\\n    .setOutputCol('document')\n\ntokenizer = Tokenizer() \\\n    .setInputCols(['document']) \\\n    .setOutputCol('token')\n\ntokenClassifier = BertForTokenClassification \\\n    .pretrained('bert_large_token_classifier_ontonote', 'en') \\\n    .setInputCols(['token', 'document']) \\\n    .setOutputCol('ner') \\\n    .setCaseSensitive(True) \\\n    .setMaxSentenceLength(512)\n\n# since output column is IOB/IOB2 style, NerConverter can extract entities\nner_converter = NerConverter() \\\n    .setInputCols(['document', 'token', 'ner']) \\\n    .setOutputCol('entities')\n\npipeline = Pipeline(stages=[\n    document_assembler, \n    tokenizer,\n    tokenClassifier,\n    ner_converter\n])\n\nempty_df = spark.createDataFrame([['']]).toDF(\"text\")\nmodel = pipeline.fit(example)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ec7c0adf-126e-4b6c-849f-6b3789680c26","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">bert_large_token_classifier_ontonote download started this may take some time.\nApproximate size to download 1.2 GB\n\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[OK!]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">bert_large_token_classifier_ontonote download started this may take some time.\nApproximate size to download 1.2 GB\n\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[OK!]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["light_model= LightPipeline(model)\nlight_result= light_model.fullAnnotate(\"Steven Rothery is the original guitarist and the longest continuous member of the British rock band Marillion.\")[0]"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ea0b240d-2bea-4a84-b39d-596997a47cac","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Let's check the classes that `bert_large_token_classifier_ontonote` model can predict"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ff1999fd-8aef-4966-9024-783055703086","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["tokenClassifier.getClasses()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"89a937a8-2d47-426d-a295-810593d4592e","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[10]: [&#39;I-TIME&#39;,\n &#39;B-PERSON&#39;,\n &#39;B-GPE&#39;,\n &#39;B-LAW&#39;,\n &#39;B-NORP&#39;,\n &#39;B-LOC&#39;,\n &#39;I-ORG&#39;,\n &#39;I-QUANTITY&#39;,\n &#39;B-DATE&#39;,\n &#39;B-PRODUCT&#39;,\n &#39;B-FAC&#39;,\n &#39;I-DATE&#39;,\n &#39;I-WORK_OF_ART&#39;,\n &#39;B-TIME&#39;,\n &#39;B-QUANTITY&#39;,\n &#39;I-PERCENT&#39;,\n &#39;I-LAW&#39;,\n &#39;I-GPE&#39;,\n &#39;I-NORP&#39;,\n &#39;I-ORDINAL&#39;,\n &#39;I-EVENT&#39;,\n &#39;I-LOC&#39;,\n &#39;B-EVENT&#39;,\n &#39;I-FAC&#39;,\n &#39;B-ORDINAL&#39;,\n &#39;B-LANGUAGE&#39;,\n &#39;B-MONEY&#39;,\n &#39;B-PERCENT&#39;,\n &#39;I-LANGUAGE&#39;,\n &#39;B-ORG&#39;,\n &#39;I-MONEY&#39;,\n &#39;I-PRODUCT&#39;,\n &#39;O&#39;,\n &#39;B-WORK_OF_ART&#39;,\n &#39;I-CARDINAL&#39;,\n &#39;I-PERSON&#39;,\n &#39;B-CARDINAL&#39;]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[10]: [&#39;I-TIME&#39;,\n &#39;B-PERSON&#39;,\n &#39;B-GPE&#39;,\n &#39;B-LAW&#39;,\n &#39;B-NORP&#39;,\n &#39;B-LOC&#39;,\n &#39;I-ORG&#39;,\n &#39;I-QUANTITY&#39;,\n &#39;B-DATE&#39;,\n &#39;B-PRODUCT&#39;,\n &#39;B-FAC&#39;,\n &#39;I-DATE&#39;,\n &#39;I-WORK_OF_ART&#39;,\n &#39;B-TIME&#39;,\n &#39;B-QUANTITY&#39;,\n &#39;I-PERCENT&#39;,\n &#39;I-LAW&#39;,\n &#39;I-GPE&#39;,\n &#39;I-NORP&#39;,\n &#39;I-ORDINAL&#39;,\n &#39;I-EVENT&#39;,\n &#39;I-LOC&#39;,\n &#39;B-EVENT&#39;,\n &#39;I-FAC&#39;,\n &#39;B-ORDINAL&#39;,\n &#39;B-LANGUAGE&#39;,\n &#39;B-MONEY&#39;,\n &#39;B-PERCENT&#39;,\n &#39;I-LANGUAGE&#39;,\n &#39;B-ORG&#39;,\n &#39;I-MONEY&#39;,\n &#39;I-PRODUCT&#39;,\n &#39;O&#39;,\n &#39;B-WORK_OF_ART&#39;,\n &#39;I-CARDINAL&#39;,\n &#39;I-PERSON&#39;,\n &#39;B-CARDINAL&#39;]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["light_result.keys()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6599c65b-d858-493a-8a7b-b1a8015281af","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[11]: dict_keys([&#39;document&#39;, &#39;token&#39;, &#39;ner&#39;, &#39;entities&#39;])</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[11]: dict_keys([&#39;document&#39;, &#39;token&#39;, &#39;ner&#39;, &#39;entities&#39;])</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Checking the ner labels of each token"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"05f20012-fca0-4996-b18e-f8068615030b","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["tokens= []\nner_labels= []\n\nfor i, k in list(zip(light_result[\"token\"], light_result[\"ner\"])):\n  tokens.append(i.result)\n  ner_labels.append(k.result)\n\nresult_df= pd.DataFrame({\"tokens\": tokens, \"ner_labels\": ner_labels})\nresult_df.head(20)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0c701769-8fe6-4070-a73d-1e5c7a1a6f9d","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[12]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[12]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tokens</th>\n      <th>ner_labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Steven</td>\n      <td>B-PERSON</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Rothery</td>\n      <td>I-PERSON</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>is</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>the</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>original</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>guitarist</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>and</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>the</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>longest</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>continuous</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>member</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>of</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>the</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>British</td>\n      <td>B-NORP</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>rock</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>band</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Marillion</td>\n      <td>B-ORG</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>.</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tokens</th>\n      <th>ner_labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Steven</td>\n      <td>B-PERSON</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Rothery</td>\n      <td>I-PERSON</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>is</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>the</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>original</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>guitarist</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>and</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>the</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>longest</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>continuous</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>member</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>of</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>the</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>British</td>\n      <td>B-NORP</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>rock</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>band</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Marillion</td>\n      <td>B-ORG</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>.</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Let's check the chunk results"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a2a54733-84f4-43ef-9cc3-36c92a58cdb7","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["chunks= []\nbegin= []\nend= []\nner_label= []\n\nfor i in light_result[\"entities\"]:\n  chunks.append(i.result)\n  begin.append(i.begin)\n  end.append(i.end)\n  ner_label.append(i.metadata[\"entity\"])\n\nresult_df= pd.DataFrame({\"chunks\": chunks, \"begin\": begin, \"end\": end, \"ner_label\": ner_label})\nresult_df.head(20)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"da1f74f6-12b5-47a1-a685-a95d417dd259","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[13]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[13]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>chunks</th>\n      <th>begin</th>\n      <th>end</th>\n      <th>ner_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Steven Rothery</td>\n      <td>0</td>\n      <td>13</td>\n      <td>PERSON</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>British</td>\n      <td>82</td>\n      <td>88</td>\n      <td>NORP</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Marillion</td>\n      <td>100</td>\n      <td>108</td>\n      <td>ORG</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>chunks</th>\n      <th>begin</th>\n      <th>end</th>\n      <th>ner_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Steven Rothery</td>\n      <td>0</td>\n      <td>13</td>\n      <td>PERSON</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>British</td>\n      <td>82</td>\n      <td>88</td>\n      <td>NORP</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Marillion</td>\n      <td>100</td>\n      <td>108</td>\n      <td>ORG</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# BertForSequenceClassification"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"09dabad7-e542-4cd6-8441-0e5c0719e2a7","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["BertForSequenceClassification can load Bert Models with sequence classification/regression head on top (a linear layer on top of the pooled output) e.g. for multi-class document classification tasks.\n\nPretrained models can be loaded with `pretrained()` of the companion object.\n<br/><br/>\n\n### **Here are Bert Based Sequence Classification models available in Spark NLP**\n<br/>\n\n\n| title                                                                                                        | name                                                 | language   |\n|:-------------------------------------------------------------------------------------------------------------|:-----------------------------------------------------|:-----------|\n| BERT Sequence Classification Base - DBpedia14 (bert_base_sequence_classifier_dbpedia_14)                     | bert_base_sequence_classifier_dbpedia_14             | en         |\n| BERT Sequence Classification Base - IMDB (bert_base_sequence_classifier_imdb)                                | bert_base_sequence_classifier_imdb                   | en         |\n| BERT Sequence Classification Large - IMDB (bert_large_sequence_classifier_imdb)                              | bert_large_sequence_classifier_imdb                  | en         |\n| BERT Sequence Classification Multilingual - AlloCine (bert_multilingual_sequence_classifier_allocine)        | bert_multilingual_sequence_classifier_allocine       | fr         |\n| BERT Sequence Classification Base - AG News (bert_base_sequence_classifier_ag_news)                          | bert_base_sequence_classifier_ag_news                | en         |\n| BERT Sequence Classification - Spanish Emotion Analysis (bert_sequence_classifier_beto_emotion_analysis)     | bert_sequence_classifier_beto_emotion_analysis       | es         |\n| BERT Sequence Classification - Spanish Sentiment Analysis (bert_sequence_classifier_beto_sentiment_analysis) | bert_sequence_classifier_beto_sentiment_analysis     | es         |\n| BERT Sequence Classification - Detecting Hate Speech (bert_sequence_classifier_dehatebert_mono)              | bert_sequence_classifier_dehatebert_mono             | en         |\n| BERT Sequence Classification - Financial Sentiment Analysis (bert_sequence_classifier_finbert)               | bert_sequence_classifier_finbert                     | en         |\n| BERT Sequence Classification - Japanese Sentiment (bert_sequence_classifier_japanese_sentiment)              | bert_sequence_classifier_japanese_sentiment          | ja         |\n| BERT Sequence Classification Multilingual Sentiment                                                          | bert_sequence_classifier_multilingual_sentiment      | xx         |\n| BERT Sequence Classification - Russian Sentiment Analysis (bert_sequence_classifier_rubert_sentiment)        | bert_sequence_classifier_rubert_sentiment            | ru         |\n| BERT Sequence Classification - German Sentiment Analysis (bert_sequence_classifier_sentiment)                | bert_sequence_classifier_sentiment                   | de         |\n| BERT Sequence Classification - Turkish Sentiment (bert_sequence_classifier_turkish_sentiment)                | bert_sequence_classifier_turkish_sentiment           | tr         |\n| Bert for Sequence Classification (Question vs Statement)                                                     | bert_sequence_classifier_question_statement          | en         |\n| Bert for Sequence Classification (Clinical Question vs Statement)                                            | bert_sequence_classifier_question_statement_clinical | en         |\n| BERT Sequence Classification - Identify Antisemitic texts                                                    | bert_sequence_classifier_antisemitism                | en         |\n| BERT Sequence Classification - Detecting Hate Speech (bert_sequence_classifier_hatexplain)                   | bert_sequence_classifier_hatexplain                  | en         |\n| BERT Sequence Classification - Identify Trec Data Classes                                                    | bert_sequence_classifier_trec_coarse                 | en         |\n| BERT Sequence Classification - Classify into News Categories                                                 | bert_sequence_classifier_age_news                    | en         |\n| BERT Sequence Classification - Classify Banking-Related texts                                                | bert_sequence_classifier_banking77                   | en         |\n| BERT Sequence Classification - Detect Spam SMS                                                               | bert_sequence_classifier_sms_spam                    | en         |\n| BERT Sequence Classifier - Classify the Music Genre                                                          | bert_sequence_classifier_song_lyrics                 | en         |\n| DistilBERT Sequence Classification Base - AG News (distilbert_base_sequence_classifier_ag_news)              | distilbert_base_sequence_classifier_ag_news          | en         |\n| DistilBERT Sequence Classification - Amazon Polarity (distilbert_base_sequence_classifier_amazon_polarity)   | distilbert_base_sequence_classifier_amazon_polarity  | en         |\n| DistilBERT Sequence Classification - IMDB (distilbert_base_sequence_classifier_imdb)                         | distilbert_base_sequence_classifier_imdb             | en         |\n| DistilBERT Sequence Classification - Urdu IMDB (distilbert_base_sequence_classifier_imdb)                    | distilbert_base_sequence_classifier_imdb             | ur         |\n| DistilBERT Sequence Classification French - AlloCine (distilbert_multilingual_sequence_classifier_allocine)  | distilbert_multilingual_sequence_classifier_allocine | fr         |\n| DistilBERT Sequence Classification - Banking77 (distilbert_sequence_classifier_banking77)                    | distilbert_sequence_classifier_banking77             | en         |\n| DistilBERT Sequence Classification - Emotion (distilbert_sequence_classifier_emotion)                        | distilbert_sequence_classifier_emotion               | en         |\n| DistilBERT Sequence Classification - Industry (distilbert_sequence_classifier_industry)                      | distilbert_sequence_classifier_industry              | en         |\n| DistilBERT Sequence Classification - Policy (distilbert_sequence_classifier_policy)                          | distilbert_sequence_classifier_policy                | en         |\n| DistilBERT Sequence Classification - SST-2 (distilbert_sequence_classifier_sst2)                             | distilbert_sequence_classifier_sst2                  | en         |\n| ALBERT Sequence Classification Base - AG News (albert_base_sequence_classifier_ag_news)                      | albert_base_sequence_classifier_ag_news              | en         |\n| ALBERT Sequence Classification Base - IMDB (albert_base_sequence_classifier_imdb)                            | albert_base_sequence_classifier_imdb                 | en         |\n| Longformer Sequence Classification Base - AG News (longformer_base_sequence_classifier_ag_news)              | longformer_base_sequence_classifier_ag_news          | en         |\n| Longformer Sequence Classification Base - IMDB (longformer_base_sequence_classifier_imdb)                    | longformer_base_sequence_classifier_imdb             | en         |\n| RoBERTa Sequence Classification Base - AG News (roberta_base_sequence_classifier_ag_news)                    | roberta_base_sequence_classifier_ag_news             | en         |\n| RoBERTa Sequence Classification Base - IMDB (roberta_base_sequence_classifier_imdb)                          | roberta_base_sequence_classifier_imdb                | en         |\n| XLM-RoBERTa Sequence Classification Base - AG News (xlm_roberta_base_sequence_classifier_ag_news)            | xlm_roberta_base_sequence_classifier_ag_news         | en         |\n| XLM-RoBERTa Sequence Classification Multilingual - AlloCine (xlm_roberta_base_sequence_classifier_allocine)  | xlm_roberta_base_sequence_classifier_allocine        | fr         |\n| XLM-RoBERTa Sequence Classification Base - IMDB (xlm_roberta_base_sequence_classifier_imdb)                  | xlm_roberta_base_sequence_classifier_imdb            | en         |\n| XLNet Sequence Classification Base - AG News (xlnet_base_sequence_classifier_ag_news)                        | xlnet_base_sequence_classifier_ag_news               | en         |\n| XLNet Sequence Classification Base - IMDB (xlnet_base_sequence_classifier_imdb)                              | xlnet_base_sequence_classifier_imdb                  | en         |"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"dd2e9128-dde5-48ab-b899-86d05ba5d66b","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["## BertForSequenceClassification Pipeline"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6803c7e7-26f8-4035-825b-b827309b3e3b","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["Now, let's create a Spark NLP Pipeline with `bert_base_sequence_classifier_imdb` model and check the results. \n\nThis model is a fine-tuned BERT model that is ready to be used for Sequence Classification tasks such as sentiment analysis or multi-class text classification and it achieves state-of-the-art performance.\n\nThis model has been trained to recognize two types of entities: negative (neg), positive (pos)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d7c2a763-788e-44fc-8a0b-b54fadc37651","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["document_assembler = DocumentAssembler() \\\n    .setInputCol('text') \\\n    .setOutputCol('document')\n\ntokenizer = Tokenizer() \\\n    .setInputCols(['document']) \\\n    .setOutputCol('token')\n\nsequenceClassifier = BertForSequenceClassification \\\n    .pretrained('bert_base_sequence_classifier_imdb', 'en') \\\n    .setInputCols(['token', 'document']) \\\n    .setOutputCol('pred_class') \\\n    .setCaseSensitive(True) \\\n    .setMaxSentenceLength(512)\n\npipeline = Pipeline(stages=[\n    document_assembler,\n    tokenizer,\n    sequenceClassifier\n])\n\nsample_text= [[\"I really liked that movie!\"], [\"The last movie I watched was awful!\"]]\nsample_df= spark.createDataFrame(sample_text).toDF(\"text\")\nmodel = pipeline.fit(sample_df)\nresult= model.transform(sample_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b7a065f8-3804-4d62-a7e0-6082cdaab0a2","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">bert_base_sequence_classifier_imdb download started this may take some time.\nApproximate size to download 387.6 MB\n\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[OK!]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">bert_base_sequence_classifier_imdb download started this may take some time.\nApproximate size to download 387.6 MB\n\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[OK!]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["model.stages"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"769e3d09-ca40-4b05-b0c5-e09a9019e729","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[15]: [DocumentAssembler_bf572983e01e,\n REGEX_TOKENIZER_ff6e89f4db78,\n BERT_FOR_SEQUENCE_CLASSIFICATION_41f87e548530]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[15]: [DocumentAssembler_bf572983e01e,\n REGEX_TOKENIZER_ff6e89f4db78,\n BERT_FOR_SEQUENCE_CLASSIFICATION_41f87e548530]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["sequenceClassifier.getClasses()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"093b34a8-a8b9-4cd5-809f-82ecaf1523f5","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[16]: [&#39;neg&#39;, &#39;pos&#39;]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[16]: [&#39;neg&#39;, &#39;pos&#39;]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["result.columns"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"75a02f0e-b576-48b1-a092-4503855f7b66","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[17]: [&#39;text&#39;, &#39;document&#39;, &#39;token&#39;, &#39;pred_class&#39;]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[17]: [&#39;text&#39;, &#39;document&#39;, &#39;token&#39;, &#39;pred_class&#39;]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["result_df= result.select(F.explode(F.arrays_zip(result.document.result, result.pred_class.result)).alias(\"col\"))\\\n                 .select(F.expr(\"col['0']\").alias(\"sentence\"),\n                         F.expr(\"col['1']\").alias(\"prediction\"))\n                  \nresult_df.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b62d1ad0-7137-40b7-9049-ef7f690e8902","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-----------------------------------+----------+\n|sentence                           |prediction|\n+-----------------------------------+----------+\n|I really liked that movie!         |pos       |\n|The last movie I watched was awful!|neg       |\n+-----------------------------------+----------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------------------------------+----------+\nsentence                           |prediction|\n+-----------------------------------+----------+\nI really liked that movie!         |pos       |\nThe last movie I watched was awful!|neg       |\n+-----------------------------------+----------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## DistilBertForSequenceClassification By Using LightPipeline"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4c85c4f4-0b74-433a-bdd5-d83fafaa6d7a","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["Now, we will use distilbert_base_sequence_classifier_ag_news model with LightPipeline and fullAnnotate it with sample data."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b628d171-83a8-4ab4-a2b1-42d9675c7c09","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["document_assembler = DocumentAssembler() \\\n    .setInputCol('text') \\\n    .setOutputCol('document')\n\ntokenizer = Tokenizer() \\\n    .setInputCols(['document']) \\\n    .setOutputCol('token')\n\nsequenceClassifier = DistilBertForSequenceClassification \\\n      .pretrained('distilbert_base_sequence_classifier_ag_news', 'en') \\\n      .setInputCols(['token', 'document']) \\\n      .setOutputCol('class') \\\n      .setCaseSensitive(True) \\\n      .setMaxSentenceLength(512)\n\npipeline = Pipeline(stages=[\n    document_assembler, \n    tokenizer,\n    sequenceClassifier    \n])\n\nempty_data= spark.createDataFrame([[\"\"]]).toDF(\"text\")\nmodel = pipeline.fit(empty_data)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7ec89302-79c2-45fe-95c8-5b59dce8e396","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">distilbert_base_sequence_classifier_ag_news download started this may take some time.\nApproximate size to download 234.9 MB\n\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[OK!]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">distilbert_base_sequence_classifier_ag_news download started this may take some time.\nApproximate size to download 234.9 MB\n\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[OK!]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["light_model= LightPipeline(model)\nlight_result= light_model.fullAnnotate(\"Manchester United forward Cristiano Ronaldo on Saturday made his 181st appearance for Portugal.\")[0]"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b20da84c-6640-435e-ba37-42017e821c32","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Let's check the classes that distilbert_base_sequence_classifier_ag_news model can predict"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"04cf61ab-ed6f-4aba-998a-e5e45e6bab74","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["sequenceClassifier.getClasses()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"77fcd2b8-604b-46b5-ba81-ddbd1fe3053d","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[21]: [&#39;World&#39;, &#39;Sports&#39;, &#39;Business&#39;, &#39;Sci/Tech&#39;]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[21]: [&#39;World&#39;, &#39;Sports&#39;, &#39;Business&#39;, &#39;Sci/Tech&#39;]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["light_result.keys()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b3d6eeed-28d2-40ab-b459-7736315e4e13","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[22]: dict_keys([&#39;document&#39;, &#39;token&#39;, &#39;class&#39;])</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[22]: dict_keys([&#39;document&#39;, &#39;token&#39;, &#39;class&#39;])</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Let's check the prediction"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9f78d74e-0685-4f19-8af6-baed4188bf26","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["pd.set_option('display.max_colwidth', None)\n\ntext= []\npred= []\n\nfor i, k in list(zip(light_result[\"document\"], light_result[\"class\"])):\n  text.append(i.result)\n  pred.append(k.result)\n\nresult_df= pd.DataFrame({\"text\": text, \"prediction\": pred})\nresult_df.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"efab67c9-327b-46e6-af61-066df7e8b55a","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[23]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[23]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Manchester United forward Cristiano Ronaldo on Saturday made his 181st appearance for Portugal.</td>\n      <td>Sports</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Manchester United forward Cristiano Ronaldo on Saturday made his 181st appearance for Portugal.</td>\n      <td>Sports</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["End of Notebook #"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"42df2f5d-b5ba-4ffa-8d38-bc4ab81a96c1","inputWidgets":{},"title":""}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"10. Transformers for Token Classification & Sequence Classification","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":557198484822027}},"nbformat":4,"nbformat_minor":0}
