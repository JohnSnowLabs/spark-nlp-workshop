{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I08sFJYCxR0Z"
   },
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Niy3mZAjoayg"
   },
   "source": [
    "# Clinical Assertion Status Model \n",
    "\n",
    "\n",
    "The deep neural network architecture for assertion status detection in Spark NLP is based on a Bi-LSTM framework, and is a modified version of the architecture proposed by Federico Fancellu, Adam Lopez and Bonnie Webber ([Neural Networks For Negation Scope Detection](https://aclanthology.org/P16-1047.pdf)). Its goal is to classify the assertions made on given medical concepts as being present, absent, or possible in the patient, conditionally present in the patient under certain circumstances,\n",
    "hypothetically present in the patient at some future point, and\n",
    "mentioned in the patient report but associated with someoneelse.\n",
    "In the proposed implementation, input units depend on the\n",
    "target tokens (a named entity) and the neighboring words that\n",
    "are explicitly encoded as a sequence using word embeddings.\n",
    "Similar to paper mentioned above,  it is observed that that 95% of the scope tokens (neighboring words) fall in a window of 9 tokens to the left and 15\n",
    "to the right of the target tokens in the same dataset. Therefore, the same window size was implemented and it following parameters were used: learning\n",
    "rate 0.0012, dropout 0.05, batch size 64 and a maximum sentence length 250. The model has been implemented within\n",
    "Spark NLP as an annotator called AssertionDLModel. After\n",
    "training 20 epoch and measuring accuracy on the official test\n",
    "set, this implementation exceeds the latest state-of-the-art\n",
    "accuracy benchmarks as summarized as following table:\n",
    "\n",
    "|Assertion Label|Spark NLP|Latest Best|\n",
    "|-|-|-|\n",
    "|Absent       |0.944 |0.937|\n",
    "|Someone-else |0.904|0.869|\n",
    "|Conditional  |0.441|0.422|\n",
    "|Hypothetical |0.862|0.890|\n",
    "|Possible     |0.680|0.630|\n",
    "|Present      |0.953|0.957|\n",
    "|micro F1     |0.939|0.934|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Healthcare NLP for Data Scientists Course\n",
    "\n",
    "If you are not familiar with the components in this notebook, you can check [Healthcare NLP for Data Scientists Udemy Course](https://www.udemy.com/course/healthcare-nlp-for-data-scientists/) and the [MOOC Notebooks](https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP) for each components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "okhT7AcXxben"
   },
   "source": [
    "**Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Session already created, some configs may not take.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-5-79.ec2.internal:4043\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>John-Snow-Labs-Spark-Session 🚀 with Jars for: 🚀Spark-NLP==5.5.1, 💊Spark-Healthcare==5.5.1, 🕶Spark-OCR==5.4.2, running on ⚡ PySpark==3.4.0</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f4117bc30a0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml import Pipeline,PipelineModel\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "from johnsnowlabs import nlp, medical\n",
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "spark = start_spark()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AMU4sAJQ0Rhs"
   },
   "source": [
    "# Clinical Assertion Models (with pretrained models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kql2KmQ35H7H"
   },
   "source": [
    "|    | model_name              |Predicted Entities|\n",
    "|---:|:------------------------|-|\n",
    "|  1 | [assertion_dl](https://nlp.johnsnowlabs.com/2021/01/26/assertion_dl_en.html)            |Present, Absent, Possible, conditional, hypothetical, associated_with_someone_else|\n",
    "|  2 | [assertion_dl_biobert](https://nlp.johnsnowlabs.com/2021/01/26/assertion_dl_biobert_en.html)    |Present, Absent, Possible, conditional, hypothetical, associated_with_someone_else|\n",
    "|  3 | [assertion_dl_healthcare](https://nlp.johnsnowlabs.com/2020/09/23/assertion_dl_healthcare_en.html) |Present, Absent, Possible, conditional, hypothetical, associated_with_someone_else|\n",
    "|  4 | [assertion_dl_large](https://nlp.johnsnowlabs.com/2020/05/21/assertion_dl_large_en.html)      |Present, Absent, Possible, conditional, hypothetical, associated_with_someone_else|\n",
    "|  5 | [assertion_dl_radiology](https://nlp.johnsnowlabs.com/2021/03/18/assertion_dl_radiology_en.html)   |Confirmed, Suspected, Negative|\n",
    "|  6 | [assertion_jsl](https://nlp.johnsnowlabs.com/2021/07/24/assertion_jsl_en.html)           |Present, Absent, Possible, Planned, Someoneelse, Past, Family, Hypotetical|\n",
    "|  7 | [assertion_jsl_large](https://nlp.johnsnowlabs.com/2021/07/24/assertion_jsl_large_en.html)     |present, absent, possible, planned, someoneelse, past, hypothetical|\n",
    "|  8 |  [assertion_ml](https://nlp.johnsnowlabs.com/2020/01/30/assertion_ml_en.html) |Hypothetical, Present, Absent, Possible, Conditional, Associated_with_someone_else|\n",
    "|  9 | [assertion_dl_scope_L10R10](https://nlp.johnsnowlabs.com/2022/03/17/assertion_dl_scope_L10R10_en_3_0.html)| hypothetical, associated_with_someone_else, conditional, possible, absent, present|\n",
    "| 10 | [assertion_dl_biobert_scope_L10R10](https://nlp.johnsnowlabs.com/2022/03/24/assertion_dl_biobert_scope_L10R10_en_2_4.html)| hypothetical, associated_with_someone_else, conditional, possible, absent, present|\n",
    "| 11 | [assertion_jsl_augmented](https://nlp.johnsnowlabs.com/2022/09/15/assertion_jsl_augmented_en.html)| Present, Absent, Possible, Planned, Past, Family, Hypotetical, SomeoneElse|\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "voZj8-NSbe4j"
   },
   "source": [
    "### Pretrained `assertion_jsl_augmented` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 81250,
     "status": "ok",
     "timestamp": 1662533938957,
     "user": {
      "displayName": "Merve Ertas Uslu",
      "userId": "01451729557099986551"
     },
     "user_tz": -120
    },
    "id": "DEa5SITBxmY0",
    "outputId": "27161324-cd9f-4eb7-a67a-026d9a0b97c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[OK!]\n",
      "ner_jsl download started this may take some time.\n",
      "[OK!]\n",
      "assertion_jsl_augmented download started this may take some time.\n",
      "\n",
      "OK!]"
     ]
    }
   ],
   "source": [
    "# Annotator that transforms a text column from dataframe into an Annotation ready for NLP\n",
    "\n",
    "documentAssembler = nlp.DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "# Sentence Detector annotator, processes various sentences per line\n",
    "sentenceDetector = nlp.SentenceDetector()\\\n",
    "    .setInputCols([\"document\"])\\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "# Tokenizer splits words in a relevant format for NLP\n",
    "tokenizer = nlp.Tokenizer()\\\n",
    "    .setInputCols([\"sentence\"])\\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "# Clinical word embeddings trained on PubMED dataset\n",
    "word_embeddings = nlp.WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n",
    "    .setInputCols([\"sentence\", \"token\"])\\\n",
    "    .setOutputCol(\"embeddings\")\n",
    "\n",
    "# NER model trained on i2b2 (sampled from MIMIC) dataset\n",
    "clinical_ner = medical.NerModel.pretrained(\"ner_jsl\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"ner\")\\\n",
    "    #.setIncludeAllConfidenceScores(False)\n",
    "\n",
    "ner_converter = medical.NerConverterInternal() \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"ner\"]) \\\n",
    "    .setOutputCol(\"ner_chunk\")\\\n",
    "    .setWhiteList([\"SYMPTOM\",\"VS_FINDING\",\"DISEASE_SYNDROME_DISORDER\",\"ADMISSION_DISCHARGE\",\"PROCEDURE\"])\n",
    "\n",
    "# Assertion model trained on i2b2 (sampled from MIMIC) dataset\n",
    "clinical_assertion = medical.AssertionDLModel.pretrained(\"assertion_jsl_augmented\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\", \"ner_chunk\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"assertion\")\n",
    "\n",
    "nlpPipeline = nlp.Pipeline(\n",
    "    stages=[\n",
    "        documentAssembler,\n",
    "        sentenceDetector,\n",
    "        tokenizer,\n",
    "        word_embeddings,\n",
    "        clinical_ner,\n",
    "        ner_converter,\n",
    "        clinical_assertion\n",
    "])\n",
    "\n",
    "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "model = nlpPipeline.fit(empty_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 206,
     "status": "ok",
     "timestamp": 1662533942646,
     "user": {
      "displayName": "Merve Ertas Uslu",
      "userId": "01451729557099986551"
     },
     "user_tz": -120
    },
    "id": "-Z232ubQeyTu",
    "outputId": "85c37914-4404-40bb-ef2a-56ec981fbfe2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='AssertionDLApproach_5f35da648442', name='lazyAnnotator', doc='Whether this AnnotatorModel acts as lazy in RecursivePipelines'): False,\n",
       " Param(parent='AssertionDLApproach_5f35da648442', name='label', doc='Column with one label per document'): 'label',\n",
       " Param(parent='AssertionDLApproach_5f35da648442', name='batchSize', doc='Size for each batch in the optimization process'): 64,\n",
       " Param(parent='AssertionDLApproach_5f35da648442', name='epochs', doc='Number of epochs for the optimization process'): 5,\n",
       " Param(parent='AssertionDLApproach_5f35da648442', name='learningRate', doc='Learning rate for the optimization process'): 0.0012,\n",
       " Param(parent='AssertionDLApproach_5f35da648442', name='dropout', doc='Dropout at the output of each layer'): 0.05,\n",
       " Param(parent='AssertionDLApproach_5f35da648442', name='maxSentLen', doc='Max length for an input sentence.'): 250,\n",
       " Param(parent='AssertionDLApproach_5f35da648442', name='includeConfidence', doc='whether to include confidence scores in annotation metadata'): True,\n",
       " Param(parent='AssertionDLApproach_5f35da648442', name='scopeWindow', doc='The scope window of the assertion expression'): [9,\n",
       "  15]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medical.AssertionDLApproach().extractParamMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SMzVzklLw7B3"
   },
   "outputs": [],
   "source": [
    "# we also have a LogReg based Assertion Model.\n",
    "'''\n",
    "clinical_assertion_ml = AssertionLogRegModel.pretrained(\"assertion_ml\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\", \"ner_chunk\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"assertion\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "executionInfo": {
     "elapsed": 1817,
     "status": "ok",
     "timestamp": 1662533950069,
     "user": {
      "displayName": "Merve Ertas Uslu",
      "userId": "01451729557099986551"
     },
     "user_tz": -120
    },
    "id": "f2RPZMmbVeN3",
    "outputId": "24e6998c-4ad0-4693-d82e-533ec28cd796"
   },
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "GENERAL: He is an elderly gentleman in no acute distress. He is sitting up in bed eating his breakfast. He is alert and oriented and answering questions appropriately.\n",
    "HEENT: Sclerae showed mild arcus senilis in the right. Left was clear. Pupils are equally round and reactive to light. Extraocular movements are intact. Oropharynx is clear.\n",
    "NECK: Supple. Trachea is midline. No jugular venous pressure distention is noted. No adenopathy in the cervical, supraclavicular, or axillary areas.\n",
    "ABDOMEN: Soft and not tender. There may be some fullness in the left upper quadrant, although I do not appreciate a true spleen with inspiration.\n",
    "EXTREMITIES: There is some edema, but no cyanosis and clubbing .\n",
    "IMPRESSION: At this time is refractory anemia, which is transfusion dependent. He is on B12, iron, folic acid, and Procrit. There are no sign or symptom of blood loss and the previous esophagogastroduodenoscopy was negative. His creatinine was 1.\n",
    "  My impression at this time is that he probably has an underlying myelodysplastic syndrome or bone marrow failure. His creatinine on this hospitalization was up slightly to 1.6 and this may contribute to his anemia.\n",
    "  At this time, my recommendation for the patient is that he should undergo a bone marrow aspiration.\n",
    "  I have discussed the procedure in detail which the patient. I have discussed the risks, benefits, and successes of that treatment and usefulness of the bone marrow and predicting his cause of refractory anemia and further therapeutic interventions, which might be beneficial to him.\n",
    "  He is willing to proceed with the studies I have described to him. We will order an ultrasound of his abdomen because of the possible fullness of the spleen.\n",
    "  As always, we greatly appreciate being able to participate in the care of your patient. We appreciate the consultation of the patient.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunks</th>\n",
       "      <th>entities</th>\n",
       "      <th>assertion</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>distress</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Absent</td>\n",
       "      <td>0.9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arcus senilis</td>\n",
       "      <td>Disease_Syndrome_Disorder</td>\n",
       "      <td>Past</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jugular venous pressure distention</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adenopathy</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tender</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fullness</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Possible</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>edema</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Present</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cyanosis</td>\n",
       "      <td>VS_Finding</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>clubbing</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>anemia</td>\n",
       "      <td>Disease_Syndrome_Disorder</td>\n",
       "      <td>Hypothetical</td>\n",
       "      <td>0.9758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>blood loss</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>esophagogastroduodenoscopy</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>Past</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>myelodysplastic syndrome</td>\n",
       "      <td>Disease_Syndrome_Disorder</td>\n",
       "      <td>Possible</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bone marrow failure</td>\n",
       "      <td>Disease_Syndrome_Disorder</td>\n",
       "      <td>Possible</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hospitalization</td>\n",
       "      <td>Admission_Discharge</td>\n",
       "      <td>Past</td>\n",
       "      <td>0.9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>anemia</td>\n",
       "      <td>Disease_Syndrome_Disorder</td>\n",
       "      <td>Hypothetical</td>\n",
       "      <td>0.9966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bone marrow aspiration</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>Hypothetical</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>anemia</td>\n",
       "      <td>Disease_Syndrome_Disorder</td>\n",
       "      <td>Hypothetical</td>\n",
       "      <td>0.9961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>fullness of the spleen</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Possible</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                chunks                   entities  \\\n",
       "0                             distress                    Symptom   \n",
       "1                        arcus senilis  Disease_Syndrome_Disorder   \n",
       "2   jugular venous pressure distention                    Symptom   \n",
       "3                           adenopathy                    Symptom   \n",
       "4                               tender                    Symptom   \n",
       "5                             fullness                    Symptom   \n",
       "6                                edema                    Symptom   \n",
       "7                             cyanosis                 VS_Finding   \n",
       "8                             clubbing                    Symptom   \n",
       "9                               anemia  Disease_Syndrome_Disorder   \n",
       "10                          blood loss                    Symptom   \n",
       "11          esophagogastroduodenoscopy                  Procedure   \n",
       "12            myelodysplastic syndrome  Disease_Syndrome_Disorder   \n",
       "13                 bone marrow failure  Disease_Syndrome_Disorder   \n",
       "14                     hospitalization        Admission_Discharge   \n",
       "15                              anemia  Disease_Syndrome_Disorder   \n",
       "16              bone marrow aspiration                  Procedure   \n",
       "17                              anemia  Disease_Syndrome_Disorder   \n",
       "18              fullness of the spleen                    Symptom   \n",
       "\n",
       "       assertion confidence  \n",
       "0         Absent     0.9999  \n",
       "1           Past        1.0  \n",
       "2         Absent        1.0  \n",
       "3         Absent        1.0  \n",
       "4         Absent        1.0  \n",
       "5       Possible        1.0  \n",
       "6        Present        1.0  \n",
       "7         Absent        1.0  \n",
       "8         Absent        1.0  \n",
       "9   Hypothetical     0.9758  \n",
       "10        Absent        1.0  \n",
       "11          Past        1.0  \n",
       "12      Possible        1.0  \n",
       "13      Possible        1.0  \n",
       "14          Past     0.9999  \n",
       "15  Hypothetical     0.9966  \n",
       "16  Hypothetical        1.0  \n",
       "17  Hypothetical     0.9961  \n",
       "18      Possible        1.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "light_model = nlp.LightPipeline(model)\n",
    "\n",
    "light_result = light_model.fullAnnotate(text)[0]\n",
    "\n",
    "chunks=[]\n",
    "entities=[]\n",
    "status=[]\n",
    "confidence=[]\n",
    "\n",
    "for n,m in zip(light_result['ner_chunk'],light_result['assertion']):\n",
    "\n",
    "    chunks.append(n.result)\n",
    "    entities.append(n.metadata['entity'])\n",
    "    status.append(m.result)\n",
    "    confidence.append(m.metadata['confidence'])\n",
    "\n",
    "df = pd.DataFrame({'chunks':chunks, 'entities':entities, 'assertion':status, 'confidence':confidence})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    @import url('https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700&display=swap');\n",
       "    @import url('https://fonts.googleapis.com/css2?family=Vistol Regular:wght@300;400;500;600;700&display=swap');\n",
       "    \n",
       "    .spark-nlp-display-scroll-entities {\n",
       "        border: 1px solid #E7EDF0;\n",
       "        border-radius: 3px;\n",
       "        text-align: justify;\n",
       "        \n",
       "    }\n",
       "    .spark-nlp-display-scroll-entities span {  \n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        color: #536B76;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "    }\n",
       "    \n",
       "    .spark-nlp-display-entity-wrapper{\n",
       "    \n",
       "        display: inline-grid;\n",
       "        text-align: center;\n",
       "        border-radius: 4px;\n",
       "        margin: 0 2px 5px 2px;\n",
       "        padding: 1px\n",
       "    }\n",
       "    .spark-nlp-display-entity-name{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "        \n",
       "        background: #f1f2f3;\n",
       "        border-width: medium;\n",
       "        text-align: center;\n",
       "        \n",
       "        font-weight: 400;\n",
       "        \n",
       "        border-radius: 5px;\n",
       "        padding: 2px 5px;\n",
       "        display: block;\n",
       "        margin: 3px 2px;\n",
       "    \n",
       "    }\n",
       "    .spark-nlp-display-entity-type{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        color: #ffffff;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "        \n",
       "        text-transform: uppercase;\n",
       "        \n",
       "        font-weight: 500;\n",
       "\n",
       "        display: block;\n",
       "        padding: 3px 5px;\n",
       "    }\n",
       "    \n",
       "    .spark-nlp-display-entity-resolution{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        color: #ffffff;\n",
       "        font-family: 'Vistol Regular', sans-serif !important;\n",
       "        \n",
       "        text-transform: uppercase;\n",
       "        \n",
       "        font-weight: 500;\n",
       "\n",
       "        display: block;\n",
       "        padding: 3px 5px;\n",
       "    }\n",
       "    \n",
       "    .spark-nlp-display-others{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "        \n",
       "        font-weight: 400;\n",
       "    }\n",
       "\n",
       "</style>\n",
       " <span class=\"spark-nlp-display-others\" style=\"background-color: white\"><br>GENERAL: He is an elderly gentleman in no acute </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #1F911FB3\"><span class=\"spark-nlp-display-entity-name\">distress </span><span class=\"spark-nlp-display-entity-type\">Symptom</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #1F911FFF\">Absent </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">. He is sitting up in bed eating his breakfast. He is alert and oriented and answering questions appropriately.<br>HEENT: Sclerae showed mild </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #360858B3\"><span class=\"spark-nlp-display-entity-name\">arcus senilis </span><span class=\"spark-nlp-display-entity-type\">Disease_Syndrome_Disorder</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #360858FF\">Past </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> in the right. Left was clear. Pupils are equally round and reactive to light. Extraocular movements are intact. Oropharynx is clear.<br>NECK: Supple. Trachea is midline. No </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #1F911FB3\"><span class=\"spark-nlp-display-entity-name\">jugular venous pressure distention </span><span class=\"spark-nlp-display-entity-type\">Symptom</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #1F911FFF\">Absent </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> is noted. No </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #1F911FB3\"><span class=\"spark-nlp-display-entity-name\">adenopathy </span><span class=\"spark-nlp-display-entity-type\">Symptom</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #1F911FFF\">Absent </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> in the cervical, supraclavicular, or axillary areas.<br>ABDOMEN: Soft and not </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #1F911FB3\"><span class=\"spark-nlp-display-entity-name\">tender </span><span class=\"spark-nlp-display-entity-type\">Symptom</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #1F911FFF\">Absent </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">. There may be some </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #1F911FB3\"><span class=\"spark-nlp-display-entity-name\">fullness </span><span class=\"spark-nlp-display-entity-type\">Symptom</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #1F911FFF\">Possible </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> in the left upper quadrant, although I do not appreciate a true spleen with inspiration.<br>EXTREMITIES: There is some </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #1F911FB3\"><span class=\"spark-nlp-display-entity-name\">edema </span><span class=\"spark-nlp-display-entity-type\">Symptom</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #1F911FFF\">Present </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, but no </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #7B960FB3\"><span class=\"spark-nlp-display-entity-name\">cyanosis </span><span class=\"spark-nlp-display-entity-type\">VS_Finding</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #7B960FFF\">Absent </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> and </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #1F911FB3\"><span class=\"spark-nlp-display-entity-name\">clubbing </span><span class=\"spark-nlp-display-entity-type\">Symptom</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #1F911FFF\">Absent </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> .<br>IMPRESSION: At this time is refractory </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #360858B3\"><span class=\"spark-nlp-display-entity-name\">anemia </span><span class=\"spark-nlp-display-entity-type\">Disease_Syndrome_Disorder</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #360858FF\">Hypothetical </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, which is transfusion dependent. He is on B12, iron, folic acid, and Procrit. There are no sign or symptom of </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #1F911FB3\"><span class=\"spark-nlp-display-entity-name\">blood loss </span><span class=\"spark-nlp-display-entity-type\">Symptom</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #1F911FFF\">Absent </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> and the previous </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #4F09BBB3\"><span class=\"spark-nlp-display-entity-name\">esophagogastroduodenoscopy </span><span class=\"spark-nlp-display-entity-type\">Procedure</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #4F09BBFF\">Past </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> was negative. His creatinine was 1.<br>  My impression at this time is that he probably has an underlying </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #360858B3\"><span class=\"spark-nlp-display-entity-name\">myelodysplastic syndrome </span><span class=\"spark-nlp-display-entity-type\">Disease_Syndrome_Disorder</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #360858FF\">Possible </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> or </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #360858B3\"><span class=\"spark-nlp-display-entity-name\">bone marrow failure </span><span class=\"spark-nlp-display-entity-type\">Disease_Syndrome_Disorder</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #360858FF\">Possible </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">. His creatinine on this </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #76AC3BB3\"><span class=\"spark-nlp-display-entity-name\">hospitalization </span><span class=\"spark-nlp-display-entity-type\">Admission_Discharge</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #76AC3BFF\">Past </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> was up slightly to 1.6 and this may contribute to his </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #360858B3\"><span class=\"spark-nlp-display-entity-name\">anemia </span><span class=\"spark-nlp-display-entity-type\">Disease_Syndrome_Disorder</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #360858FF\">Hypothetical </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">.<br>  At this time, my recommendation for the patient is that he should undergo a </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #4F09BBB3\"><span class=\"spark-nlp-display-entity-name\">bone marrow aspiration </span><span class=\"spark-nlp-display-entity-type\">Procedure</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #4F09BBFF\">Hypothetical </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">.<br>  I have discussed the procedure in detail which the patient. I have discussed the risks, benefits, and successes of that treatment and usefulness of the bone marrow and predicting his cause of refractory </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #360858B3\"><span class=\"spark-nlp-display-entity-name\">anemia </span><span class=\"spark-nlp-display-entity-type\">Disease_Syndrome_Disorder</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #360858FF\">Hypothetical </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> and further therapeutic interventions, which might be beneficial to him.<br>  He is willing to proceed with the studies I have described to him. We will order an ultrasound of his abdomen because of the possible </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #1F911FB3\"><span class=\"spark-nlp-display-entity-name\">fullness of the spleen </span><span class=\"spark-nlp-display-entity-type\">Symptom</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #1F911FFF\">Possible </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">.<br>  As always, we greatly appreciate being able to participate in the care of your patient. We appreciate the consultation of the patient.<br></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "light_model = nlp.LightPipeline(model)\n",
    "\n",
    "light_result = light_model.fullAnnotate(text)[0]\n",
    "\n",
    "vis = nlp.viz.AssertionVisualizer()\n",
    "\n",
    "vis.display(light_result, 'ner_chunk', 'assertion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PipelineTracer and PipelineOutputParser\n",
    "####  Automating Pipeline Tracing and Analysis with `PipelineTracer` to Help Return Structured JSONs from Pretrained Pipelines Via the `PipelineOuputParser` module\n",
    "\n",
    "- `PipelineTracer` is a flexible class that tracks every stage of a pipeline. It provides detailed information about entities, assertions, de-identification, classification and relationships. This class also helps to build parser dictionaries to create a `PipelineOutputParser`. Some of the central functionality includes printing the pipeline schema, creating parser dictionaries, and retrieving possible assertions, relationships, and entities. Provide easy access to parser dictionaries and existing pipeline diagrams. Please see [PipelineTracer and PipelineOutputParser Notebook](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/11.4.PipelineTracer_and_PipelineOutputParser.ipynb) for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparknlp_jsl.pipeline_tracer import PipelineTracer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'document_identifier': 'assertion_jsl_augmented',\n",
       " 'document_text': 'document',\n",
       " 'entities': ['ner_chunk'],\n",
       " 'assertions': ['assertion'],\n",
       " 'resolutions': [],\n",
       " 'relations': [],\n",
       " 'summaries': [],\n",
       " 'deidentifications': [],\n",
       " 'classifications': []}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_tracer = PipelineTracer(model)\n",
    "\n",
    "column_maps = pipeline_tracer.createParserDictionary()\n",
    "column_maps.update({\"document_identifier\": \"assertion_jsl_augmented\"})\n",
    "column_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities:  ['Admission_Discharge', 'VS_Finding', 'Symptom', 'Disease_Syndrome_Disorder', 'Procedure']\n",
      "Assertions:  ['Family', 'Past', 'Hypothetical', 'Possible', 'SomeoneElse', 'Planned', 'Absent', 'Present']\n"
     ]
    }
   ],
   "source": [
    "print(\"Entities: \" , pipeline_tracer.getPossibleEntities())\n",
    "\n",
    "print(\"Assertions: \",  pipeline_tracer.getPossibleAssertions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "light_model = nlp.LightPipeline(model)\n",
    "light_result = light_model.fullAnnotate(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'document_identifier': 'assertion_jsl_augmented',\n",
       " 'document_id': 0,\n",
       " 'document_text': ['\\nGENERAL: He is an elderly gentleman in no acute distress. He is sitting up in bed eating his breakfast. He is alert and oriented and answering questions appropriately.\\nHEENT: Sclerae showed mild arcus senilis in the right. Left was clear. Pupils are equally round and reactive to light. Extraocular movements are intact. Oropharynx is clear.\\nNECK: Supple. Trachea is midline. No jugular venous pressure distention is noted. No adenopathy in the cervical, supraclavicular, or axillary areas.\\nABDOMEN: Soft and not tender. There may be some fullness in the left upper quadrant, although I do not appreciate a true spleen with inspiration.\\nEXTREMITIES: There is some edema, but no cyanosis and clubbing .\\nIMPRESSION: At this time is refractory anemia, which is transfusion dependent. He is on B12, iron, folic acid, and Procrit. There are no sign or symptom of blood loss and the previous esophagogastroduodenoscopy was negative. His creatinine was 1.\\n  My impression at this time is that he probably has an underlying myelodysplastic syndrome or bone marrow failure. His creatinine on this hospitalization was up slightly to 1.6 and this may contribute to his anemia.\\n  At this time, my recommendation for the patient is that he should undergo a bone marrow aspiration.\\n  I have discussed the procedure in detail which the patient. I have discussed the risks, benefits, and successes of that treatment and usefulness of the bone marrow and predicting his cause of refractory anemia and further therapeutic interventions, which might be beneficial to him.\\n  He is willing to proceed with the studies I have described to him. We will order an ultrasound of his abdomen because of the possible fullness of the spleen.\\n  As always, we greatly appreciate being able to participate in the care of your patient. We appreciate the consultation of the patient.\\n'],\n",
       " 'entities': [{'chunk_id': '68e2305b',\n",
       "   'chunk': 'distress',\n",
       "   'begin': 49,\n",
       "   'end': 56,\n",
       "   'ner_label': 'Symptom',\n",
       "   'ner_source': 'ner_chunk',\n",
       "   'ner_confidence': '0.9441'},\n",
       "  {'chunk_id': '18de06c2',\n",
       "   'chunk': 'arcus senilis',\n",
       "   'begin': 196,\n",
       "   'end': 208,\n",
       "   'ner_label': 'Disease_Syndrome_Disorder',\n",
       "   'ner_source': 'ner_chunk',\n",
       "   'ner_confidence': '0.43245'},\n",
       "  {'chunk_id': '6100d87d',\n",
       "   'chunk': 'jugular venous pressure distention',\n",
       "   'begin': 380,\n",
       "   'end': 413,\n",
       "   'ner_label': 'Symptom',\n",
       "   'ner_source': 'ner_chunk',\n",
       "   'ner_confidence': '0.45412502'},\n",
       "  {'chunk_id': 'dd7b2694',\n",
       "   'chunk': 'adenopathy',\n",
       "   'begin': 428,\n",
       "   'end': 437,\n",
       "   'ner_label': 'Symptom',\n",
       "   'ner_source': 'ner_chunk',\n",
       "   'ner_confidence': '0.9938'},\n",
       "  {'chunk_id': 'c6f560b3',\n",
       "   'chunk': 'tender',\n",
       "   'begin': 514,\n",
       "   'end': 519,\n",
       "   'ner_label': 'Symptom',\n",
       "   'ner_source': 'ner_chunk',\n",
       "   'ner_confidence': '0.9851'},\n",
       "  {'chunk_id': 'b3ef7e62',\n",
       "   'chunk': 'fullness',\n",
       "   'begin': 540,\n",
       "   'end': 547,\n",
       "   'ner_label': 'Symptom',\n",
       "   'ner_source': 'ner_chunk',\n",
       "   'ner_confidence': '0.9096'},\n",
       "  {'chunk_id': '3f80f545',\n",
       "   'chunk': 'edema',\n",
       "   'begin': 665,\n",
       "   'end': 669,\n",
       "   'ner_label': 'Symptom',\n",
       "   'ner_source': 'ner_chunk',\n",
       "   'ner_confidence': '0.9807'},\n",
       "  {'chunk_id': '5b55524b',\n",
       "   'chunk': 'cyanosis',\n",
       "   'begin': 679,\n",
       "   'end': 686,\n",
       "   'ner_label': 'VS_Finding',\n",
       "   'ner_source': 'ner_chunk',\n",
       "   'ner_confidence': '0.9196'},\n",
       "  {'chunk_id': '88599138',\n",
       "   'chunk': 'clubbing',\n",
       "   'begin': 692,\n",
       "   'end': 699,\n",
       "   'ner_label': 'Symptom',\n",
       "   'ner_source': 'ner_chunk',\n",
       "   'ner_confidence': '0.9959'},\n",
       "  {'chunk_id': '10a57d45',\n",
       "   'chunk': 'anemia',\n",
       "   'begin': 742,\n",
       "   'end': 747,\n",
       "   'ner_label': 'Disease_Syndrome_Disorder',\n",
       "   'ner_source': 'ner_chunk',\n",
       "   'ner_confidence': '0.9904'},\n",
       "  {'chunk_id': '486bbf4b',\n",
       "   'chunk': 'blood loss',\n",
       "   'begin': 859,\n",
       "   'end': 868,\n",
       "   'ner_label': 'Symptom',\n",
       "   'ner_source': 'ner_chunk',\n",
       "   'ner_confidence': '0.7923'},\n",
       "  {'chunk_id': 'ca29280e',\n",
       "   'chunk': 'esophagogastroduodenoscopy',\n",
       "   'begin': 887,\n",
       "   'end': 912,\n",
       "   'ner_label': 'Procedure',\n",
       "   'ner_source': 'ner_chunk',\n",
       "   'ner_confidence': '0.9817'},\n",
       "  {'chunk_id': '7bb7efc7',\n",
       "   'chunk': 'myelodysplastic syndrome',\n",
       "   'begin': 1017,\n",
       "   'end': 1040,\n",
       "   'ner_label': 'Disease_Syndrome_Disorder',\n",
       "   'ner_source': 'ner_chunk',\n",
       "   'ner_confidence': '0.8687'},\n",
       "  {'chunk_id': 'f34cbfd3',\n",
       "   'chunk': 'bone marrow failure',\n",
       "   'begin': 1045,\n",
       "   'end': 1063,\n",
       "   'ner_label': 'Disease_Syndrome_Disorder',\n",
       "   'ner_source': 'ner_chunk',\n",
       "   'ner_confidence': '0.7242333'},\n",
       "  {'chunk_id': '5e4b84c3',\n",
       "   'chunk': 'hospitalization',\n",
       "   'begin': 1089,\n",
       "   'end': 1103,\n",
       "   'ner_label': 'Admission_Discharge',\n",
       "   'ner_source': 'ner_chunk',\n",
       "   'ner_confidence': '0.8531'},\n",
       "  {'chunk_id': '0d280d0a',\n",
       "   'chunk': 'anemia',\n",
       "   'begin': 1159,\n",
       "   'end': 1164,\n",
       "   'ner_label': 'Disease_Syndrome_Disorder',\n",
       "   'ner_source': 'ner_chunk',\n",
       "   'ner_confidence': '0.9923'},\n",
       "  {'chunk_id': 'edd22509',\n",
       "   'chunk': 'bone marrow aspiration',\n",
       "   'begin': 1245,\n",
       "   'end': 1266,\n",
       "   'ner_label': 'Procedure',\n",
       "   'ner_source': 'ner_chunk',\n",
       "   'ner_confidence': '0.5545333'},\n",
       "  {'chunk_id': '9602b33f',\n",
       "   'chunk': 'anemia',\n",
       "   'begin': 1474,\n",
       "   'end': 1479,\n",
       "   'ner_label': 'Disease_Syndrome_Disorder',\n",
       "   'ner_source': 'ner_chunk',\n",
       "   'ner_confidence': '0.9856'},\n",
       "  {'chunk_id': 'd39e5953',\n",
       "   'chunk': 'fullness of the spleen',\n",
       "   'begin': 1690,\n",
       "   'end': 1711,\n",
       "   'ner_label': 'Symptom',\n",
       "   'ner_source': 'ner_chunk',\n",
       "   'ner_confidence': '0.422'}],\n",
       " 'assertions': [{'chunk_id': '68e2305b',\n",
       "   'chunk': 'distress',\n",
       "   'assertion': 'Absent',\n",
       "   'assertion_confidence': '0.9999',\n",
       "   'assertion_source': 'assertion'},\n",
       "  {'chunk_id': '18de06c2',\n",
       "   'chunk': 'arcus senilis',\n",
       "   'assertion': 'Past',\n",
       "   'assertion_confidence': '1.0',\n",
       "   'assertion_source': 'assertion'},\n",
       "  {'chunk_id': '6100d87d',\n",
       "   'chunk': 'jugular venous pressure distention',\n",
       "   'assertion': 'Absent',\n",
       "   'assertion_confidence': '1.0',\n",
       "   'assertion_source': 'assertion'},\n",
       "  {'chunk_id': 'dd7b2694',\n",
       "   'chunk': 'adenopathy',\n",
       "   'assertion': 'Absent',\n",
       "   'assertion_confidence': '1.0',\n",
       "   'assertion_source': 'assertion'},\n",
       "  {'chunk_id': 'c6f560b3',\n",
       "   'chunk': 'tender',\n",
       "   'assertion': 'Absent',\n",
       "   'assertion_confidence': '1.0',\n",
       "   'assertion_source': 'assertion'},\n",
       "  {'chunk_id': 'b3ef7e62',\n",
       "   'chunk': 'fullness',\n",
       "   'assertion': 'Possible',\n",
       "   'assertion_confidence': '1.0',\n",
       "   'assertion_source': 'assertion'},\n",
       "  {'chunk_id': '3f80f545',\n",
       "   'chunk': 'edema',\n",
       "   'assertion': 'Present',\n",
       "   'assertion_confidence': '1.0',\n",
       "   'assertion_source': 'assertion'},\n",
       "  {'chunk_id': '5b55524b',\n",
       "   'chunk': 'cyanosis',\n",
       "   'assertion': 'Absent',\n",
       "   'assertion_confidence': '1.0',\n",
       "   'assertion_source': 'assertion'},\n",
       "  {'chunk_id': '88599138',\n",
       "   'chunk': 'clubbing',\n",
       "   'assertion': 'Absent',\n",
       "   'assertion_confidence': '1.0',\n",
       "   'assertion_source': 'assertion'},\n",
       "  {'chunk_id': '10a57d45',\n",
       "   'chunk': 'anemia',\n",
       "   'assertion': 'Hypothetical',\n",
       "   'assertion_confidence': '0.9758',\n",
       "   'assertion_source': 'assertion'},\n",
       "  {'chunk_id': '486bbf4b',\n",
       "   'chunk': 'blood loss',\n",
       "   'assertion': 'Absent',\n",
       "   'assertion_confidence': '1.0',\n",
       "   'assertion_source': 'assertion'},\n",
       "  {'chunk_id': 'ca29280e',\n",
       "   'chunk': 'esophagogastroduodenoscopy',\n",
       "   'assertion': 'Past',\n",
       "   'assertion_confidence': '1.0',\n",
       "   'assertion_source': 'assertion'},\n",
       "  {'chunk_id': '7bb7efc7',\n",
       "   'chunk': 'myelodysplastic syndrome',\n",
       "   'assertion': 'Possible',\n",
       "   'assertion_confidence': '1.0',\n",
       "   'assertion_source': 'assertion'},\n",
       "  {'chunk_id': 'f34cbfd3',\n",
       "   'chunk': 'bone marrow failure',\n",
       "   'assertion': 'Possible',\n",
       "   'assertion_confidence': '1.0',\n",
       "   'assertion_source': 'assertion'},\n",
       "  {'chunk_id': '5e4b84c3',\n",
       "   'chunk': 'hospitalization',\n",
       "   'assertion': 'Past',\n",
       "   'assertion_confidence': '0.9999',\n",
       "   'assertion_source': 'assertion'},\n",
       "  {'chunk_id': '0d280d0a',\n",
       "   'chunk': 'anemia',\n",
       "   'assertion': 'Hypothetical',\n",
       "   'assertion_confidence': '0.9966',\n",
       "   'assertion_source': 'assertion'},\n",
       "  {'chunk_id': 'edd22509',\n",
       "   'chunk': 'bone marrow aspiration',\n",
       "   'assertion': 'Hypothetical',\n",
       "   'assertion_confidence': '1.0',\n",
       "   'assertion_source': 'assertion'},\n",
       "  {'chunk_id': '9602b33f',\n",
       "   'chunk': 'anemia',\n",
       "   'assertion': 'Hypothetical',\n",
       "   'assertion_confidence': '0.9961',\n",
       "   'assertion_source': 'assertion'},\n",
       "  {'chunk_id': 'd39e5953',\n",
       "   'chunk': 'fullness of the spleen',\n",
       "   'assertion': 'Possible',\n",
       "   'assertion_confidence': '1.0',\n",
       "   'assertion_source': 'assertion'}],\n",
       " 'resolutions': [],\n",
       " 'relations': [],\n",
       " 'summaries': [],\n",
       " 'deidentifications': [],\n",
       " 'classifications': []}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_parser = medical.PipelineOutputParser(column_maps)\n",
    "result = pipeline_parser.run(light_result)\n",
    "\n",
    "result['result'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>chunk</th>\n",
       "      <th>begin</th>\n",
       "      <th>end</th>\n",
       "      <th>ner_label</th>\n",
       "      <th>ner_source</th>\n",
       "      <th>ner_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68e2305b</td>\n",
       "      <td>distress</td>\n",
       "      <td>49</td>\n",
       "      <td>56</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.9441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18de06c2</td>\n",
       "      <td>arcus senilis</td>\n",
       "      <td>196</td>\n",
       "      <td>208</td>\n",
       "      <td>Disease_Syndrome_Disorder</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.43245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6100d87d</td>\n",
       "      <td>jugular venous pressure distention</td>\n",
       "      <td>380</td>\n",
       "      <td>413</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.45412502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dd7b2694</td>\n",
       "      <td>adenopathy</td>\n",
       "      <td>428</td>\n",
       "      <td>437</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.9938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c6f560b3</td>\n",
       "      <td>tender</td>\n",
       "      <td>514</td>\n",
       "      <td>519</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.9851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b3ef7e62</td>\n",
       "      <td>fullness</td>\n",
       "      <td>540</td>\n",
       "      <td>547</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.9096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3f80f545</td>\n",
       "      <td>edema</td>\n",
       "      <td>665</td>\n",
       "      <td>669</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.9807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5b55524b</td>\n",
       "      <td>cyanosis</td>\n",
       "      <td>679</td>\n",
       "      <td>686</td>\n",
       "      <td>VS_Finding</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.9196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>88599138</td>\n",
       "      <td>clubbing</td>\n",
       "      <td>692</td>\n",
       "      <td>699</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.9959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10a57d45</td>\n",
       "      <td>anemia</td>\n",
       "      <td>742</td>\n",
       "      <td>747</td>\n",
       "      <td>Disease_Syndrome_Disorder</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.9904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>486bbf4b</td>\n",
       "      <td>blood loss</td>\n",
       "      <td>859</td>\n",
       "      <td>868</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.7923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ca29280e</td>\n",
       "      <td>esophagogastroduodenoscopy</td>\n",
       "      <td>887</td>\n",
       "      <td>912</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.9817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7bb7efc7</td>\n",
       "      <td>myelodysplastic syndrome</td>\n",
       "      <td>1017</td>\n",
       "      <td>1040</td>\n",
       "      <td>Disease_Syndrome_Disorder</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.8687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>f34cbfd3</td>\n",
       "      <td>bone marrow failure</td>\n",
       "      <td>1045</td>\n",
       "      <td>1063</td>\n",
       "      <td>Disease_Syndrome_Disorder</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.7242333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5e4b84c3</td>\n",
       "      <td>hospitalization</td>\n",
       "      <td>1089</td>\n",
       "      <td>1103</td>\n",
       "      <td>Admission_Discharge</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.8531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0d280d0a</td>\n",
       "      <td>anemia</td>\n",
       "      <td>1159</td>\n",
       "      <td>1164</td>\n",
       "      <td>Disease_Syndrome_Disorder</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.9923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>edd22509</td>\n",
       "      <td>bone marrow aspiration</td>\n",
       "      <td>1245</td>\n",
       "      <td>1266</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.5545333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9602b33f</td>\n",
       "      <td>anemia</td>\n",
       "      <td>1474</td>\n",
       "      <td>1479</td>\n",
       "      <td>Disease_Syndrome_Disorder</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.9856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>d39e5953</td>\n",
       "      <td>fullness of the spleen</td>\n",
       "      <td>1690</td>\n",
       "      <td>1711</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    chunk_id                               chunk  begin   end  \\\n",
       "0   68e2305b                            distress     49    56   \n",
       "1   18de06c2                       arcus senilis    196   208   \n",
       "2   6100d87d  jugular venous pressure distention    380   413   \n",
       "3   dd7b2694                          adenopathy    428   437   \n",
       "4   c6f560b3                              tender    514   519   \n",
       "5   b3ef7e62                            fullness    540   547   \n",
       "6   3f80f545                               edema    665   669   \n",
       "7   5b55524b                            cyanosis    679   686   \n",
       "8   88599138                            clubbing    692   699   \n",
       "9   10a57d45                              anemia    742   747   \n",
       "10  486bbf4b                          blood loss    859   868   \n",
       "11  ca29280e          esophagogastroduodenoscopy    887   912   \n",
       "12  7bb7efc7            myelodysplastic syndrome   1017  1040   \n",
       "13  f34cbfd3                 bone marrow failure   1045  1063   \n",
       "14  5e4b84c3                     hospitalization   1089  1103   \n",
       "15  0d280d0a                              anemia   1159  1164   \n",
       "16  edd22509              bone marrow aspiration   1245  1266   \n",
       "17  9602b33f                              anemia   1474  1479   \n",
       "18  d39e5953              fullness of the spleen   1690  1711   \n",
       "\n",
       "                    ner_label ner_source ner_confidence  \n",
       "0                     Symptom  ner_chunk         0.9441  \n",
       "1   Disease_Syndrome_Disorder  ner_chunk        0.43245  \n",
       "2                     Symptom  ner_chunk     0.45412502  \n",
       "3                     Symptom  ner_chunk         0.9938  \n",
       "4                     Symptom  ner_chunk         0.9851  \n",
       "5                     Symptom  ner_chunk         0.9096  \n",
       "6                     Symptom  ner_chunk         0.9807  \n",
       "7                  VS_Finding  ner_chunk         0.9196  \n",
       "8                     Symptom  ner_chunk         0.9959  \n",
       "9   Disease_Syndrome_Disorder  ner_chunk         0.9904  \n",
       "10                    Symptom  ner_chunk         0.7923  \n",
       "11                  Procedure  ner_chunk         0.9817  \n",
       "12  Disease_Syndrome_Disorder  ner_chunk         0.8687  \n",
       "13  Disease_Syndrome_Disorder  ner_chunk      0.7242333  \n",
       "14        Admission_Discharge  ner_chunk         0.8531  \n",
       "15  Disease_Syndrome_Disorder  ner_chunk         0.9923  \n",
       "16                  Procedure  ner_chunk      0.5545333  \n",
       "17  Disease_Syndrome_Disorder  ner_chunk         0.9856  \n",
       "18                    Symptom  ner_chunk          0.422  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities_df = pd.DataFrame.from_dict(result[\"result\"][0][\"entities\"])\n",
    "entities_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>chunk</th>\n",
       "      <th>assertion</th>\n",
       "      <th>assertion_confidence</th>\n",
       "      <th>assertion_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68e2305b</td>\n",
       "      <td>distress</td>\n",
       "      <td>Absent</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18de06c2</td>\n",
       "      <td>arcus senilis</td>\n",
       "      <td>Past</td>\n",
       "      <td>1.0</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6100d87d</td>\n",
       "      <td>jugular venous pressure distention</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dd7b2694</td>\n",
       "      <td>adenopathy</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c6f560b3</td>\n",
       "      <td>tender</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b3ef7e62</td>\n",
       "      <td>fullness</td>\n",
       "      <td>Possible</td>\n",
       "      <td>1.0</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3f80f545</td>\n",
       "      <td>edema</td>\n",
       "      <td>Present</td>\n",
       "      <td>1.0</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5b55524b</td>\n",
       "      <td>cyanosis</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>88599138</td>\n",
       "      <td>clubbing</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10a57d45</td>\n",
       "      <td>anemia</td>\n",
       "      <td>Hypothetical</td>\n",
       "      <td>0.9758</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>486bbf4b</td>\n",
       "      <td>blood loss</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ca29280e</td>\n",
       "      <td>esophagogastroduodenoscopy</td>\n",
       "      <td>Past</td>\n",
       "      <td>1.0</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7bb7efc7</td>\n",
       "      <td>myelodysplastic syndrome</td>\n",
       "      <td>Possible</td>\n",
       "      <td>1.0</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>f34cbfd3</td>\n",
       "      <td>bone marrow failure</td>\n",
       "      <td>Possible</td>\n",
       "      <td>1.0</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5e4b84c3</td>\n",
       "      <td>hospitalization</td>\n",
       "      <td>Past</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0d280d0a</td>\n",
       "      <td>anemia</td>\n",
       "      <td>Hypothetical</td>\n",
       "      <td>0.9966</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>edd22509</td>\n",
       "      <td>bone marrow aspiration</td>\n",
       "      <td>Hypothetical</td>\n",
       "      <td>1.0</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9602b33f</td>\n",
       "      <td>anemia</td>\n",
       "      <td>Hypothetical</td>\n",
       "      <td>0.9961</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>d39e5953</td>\n",
       "      <td>fullness of the spleen</td>\n",
       "      <td>Possible</td>\n",
       "      <td>1.0</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    chunk_id                               chunk     assertion  \\\n",
       "0   68e2305b                            distress        Absent   \n",
       "1   18de06c2                       arcus senilis          Past   \n",
       "2   6100d87d  jugular venous pressure distention        Absent   \n",
       "3   dd7b2694                          adenopathy        Absent   \n",
       "4   c6f560b3                              tender        Absent   \n",
       "5   b3ef7e62                            fullness      Possible   \n",
       "6   3f80f545                               edema       Present   \n",
       "7   5b55524b                            cyanosis        Absent   \n",
       "8   88599138                            clubbing        Absent   \n",
       "9   10a57d45                              anemia  Hypothetical   \n",
       "10  486bbf4b                          blood loss        Absent   \n",
       "11  ca29280e          esophagogastroduodenoscopy          Past   \n",
       "12  7bb7efc7            myelodysplastic syndrome      Possible   \n",
       "13  f34cbfd3                 bone marrow failure      Possible   \n",
       "14  5e4b84c3                     hospitalization          Past   \n",
       "15  0d280d0a                              anemia  Hypothetical   \n",
       "16  edd22509              bone marrow aspiration  Hypothetical   \n",
       "17  9602b33f                              anemia  Hypothetical   \n",
       "18  d39e5953              fullness of the spleen      Possible   \n",
       "\n",
       "   assertion_confidence assertion_source  \n",
       "0                0.9999        assertion  \n",
       "1                   1.0        assertion  \n",
       "2                   1.0        assertion  \n",
       "3                   1.0        assertion  \n",
       "4                   1.0        assertion  \n",
       "5                   1.0        assertion  \n",
       "6                   1.0        assertion  \n",
       "7                   1.0        assertion  \n",
       "8                   1.0        assertion  \n",
       "9                0.9758        assertion  \n",
       "10                  1.0        assertion  \n",
       "11                  1.0        assertion  \n",
       "12                  1.0        assertion  \n",
       "13                  1.0        assertion  \n",
       "14               0.9999        assertion  \n",
       "15               0.9966        assertion  \n",
       "16                  1.0        assertion  \n",
       "17               0.9961        assertion  \n",
       "18                  1.0        assertion  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assertion_df = pd.DataFrame.from_dict(result[\"result\"][0][\"assertions\"])\n",
    "assertion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk</th>\n",
       "      <th>begin</th>\n",
       "      <th>end</th>\n",
       "      <th>ner_label</th>\n",
       "      <th>ner_source</th>\n",
       "      <th>ner_confidence</th>\n",
       "      <th>assertion</th>\n",
       "      <th>assertion_confidence</th>\n",
       "      <th>assertion_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>distress</td>\n",
       "      <td>49</td>\n",
       "      <td>56</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.9441</td>\n",
       "      <td>Absent</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arcus senilis</td>\n",
       "      <td>196</td>\n",
       "      <td>208</td>\n",
       "      <td>Disease_Syndrome_Disorder</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.43245</td>\n",
       "      <td>Past</td>\n",
       "      <td>1.0</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jugular venous pressure distention</td>\n",
       "      <td>380</td>\n",
       "      <td>413</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.45412502</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adenopathy</td>\n",
       "      <td>428</td>\n",
       "      <td>437</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.9938</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tender</td>\n",
       "      <td>514</td>\n",
       "      <td>519</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.9851</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fullness</td>\n",
       "      <td>540</td>\n",
       "      <td>547</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.9096</td>\n",
       "      <td>Possible</td>\n",
       "      <td>1.0</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>edema</td>\n",
       "      <td>665</td>\n",
       "      <td>669</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.9807</td>\n",
       "      <td>Present</td>\n",
       "      <td>1.0</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cyanosis</td>\n",
       "      <td>679</td>\n",
       "      <td>686</td>\n",
       "      <td>VS_Finding</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.9196</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>clubbing</td>\n",
       "      <td>692</td>\n",
       "      <td>699</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.9959</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>anemia</td>\n",
       "      <td>742</td>\n",
       "      <td>747</td>\n",
       "      <td>Disease_Syndrome_Disorder</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.9904</td>\n",
       "      <td>Hypothetical</td>\n",
       "      <td>0.9758</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>blood loss</td>\n",
       "      <td>859</td>\n",
       "      <td>868</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.7923</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>esophagogastroduodenoscopy</td>\n",
       "      <td>887</td>\n",
       "      <td>912</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.9817</td>\n",
       "      <td>Past</td>\n",
       "      <td>1.0</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>myelodysplastic syndrome</td>\n",
       "      <td>1017</td>\n",
       "      <td>1040</td>\n",
       "      <td>Disease_Syndrome_Disorder</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.8687</td>\n",
       "      <td>Possible</td>\n",
       "      <td>1.0</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bone marrow failure</td>\n",
       "      <td>1045</td>\n",
       "      <td>1063</td>\n",
       "      <td>Disease_Syndrome_Disorder</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.7242333</td>\n",
       "      <td>Possible</td>\n",
       "      <td>1.0</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hospitalization</td>\n",
       "      <td>1089</td>\n",
       "      <td>1103</td>\n",
       "      <td>Admission_Discharge</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.8531</td>\n",
       "      <td>Past</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>anemia</td>\n",
       "      <td>1159</td>\n",
       "      <td>1164</td>\n",
       "      <td>Disease_Syndrome_Disorder</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.9923</td>\n",
       "      <td>Hypothetical</td>\n",
       "      <td>0.9966</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bone marrow aspiration</td>\n",
       "      <td>1245</td>\n",
       "      <td>1266</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.5545333</td>\n",
       "      <td>Hypothetical</td>\n",
       "      <td>1.0</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>anemia</td>\n",
       "      <td>1474</td>\n",
       "      <td>1479</td>\n",
       "      <td>Disease_Syndrome_Disorder</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.9856</td>\n",
       "      <td>Hypothetical</td>\n",
       "      <td>0.9961</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>fullness of the spleen</td>\n",
       "      <td>1690</td>\n",
       "      <td>1711</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.422</td>\n",
       "      <td>Possible</td>\n",
       "      <td>1.0</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 chunk  begin   end  \\\n",
       "0                             distress     49    56   \n",
       "1                        arcus senilis    196   208   \n",
       "2   jugular venous pressure distention    380   413   \n",
       "3                           adenopathy    428   437   \n",
       "4                               tender    514   519   \n",
       "5                             fullness    540   547   \n",
       "6                                edema    665   669   \n",
       "7                             cyanosis    679   686   \n",
       "8                             clubbing    692   699   \n",
       "9                               anemia    742   747   \n",
       "10                          blood loss    859   868   \n",
       "11          esophagogastroduodenoscopy    887   912   \n",
       "12            myelodysplastic syndrome   1017  1040   \n",
       "13                 bone marrow failure   1045  1063   \n",
       "14                     hospitalization   1089  1103   \n",
       "15                              anemia   1159  1164   \n",
       "16              bone marrow aspiration   1245  1266   \n",
       "17                              anemia   1474  1479   \n",
       "18              fullness of the spleen   1690  1711   \n",
       "\n",
       "                    ner_label ner_source ner_confidence     assertion  \\\n",
       "0                     Symptom  ner_chunk         0.9441        Absent   \n",
       "1   Disease_Syndrome_Disorder  ner_chunk        0.43245          Past   \n",
       "2                     Symptom  ner_chunk     0.45412502        Absent   \n",
       "3                     Symptom  ner_chunk         0.9938        Absent   \n",
       "4                     Symptom  ner_chunk         0.9851        Absent   \n",
       "5                     Symptom  ner_chunk         0.9096      Possible   \n",
       "6                     Symptom  ner_chunk         0.9807       Present   \n",
       "7                  VS_Finding  ner_chunk         0.9196        Absent   \n",
       "8                     Symptom  ner_chunk         0.9959        Absent   \n",
       "9   Disease_Syndrome_Disorder  ner_chunk         0.9904  Hypothetical   \n",
       "10                    Symptom  ner_chunk         0.7923        Absent   \n",
       "11                  Procedure  ner_chunk         0.9817          Past   \n",
       "12  Disease_Syndrome_Disorder  ner_chunk         0.8687      Possible   \n",
       "13  Disease_Syndrome_Disorder  ner_chunk      0.7242333      Possible   \n",
       "14        Admission_Discharge  ner_chunk         0.8531          Past   \n",
       "15  Disease_Syndrome_Disorder  ner_chunk         0.9923  Hypothetical   \n",
       "16                  Procedure  ner_chunk      0.5545333  Hypothetical   \n",
       "17  Disease_Syndrome_Disorder  ner_chunk         0.9856  Hypothetical   \n",
       "18                    Symptom  ner_chunk          0.422      Possible   \n",
       "\n",
       "   assertion_confidence assertion_source  \n",
       "0                0.9999        assertion  \n",
       "1                   1.0        assertion  \n",
       "2                   1.0        assertion  \n",
       "3                   1.0        assertion  \n",
       "4                   1.0        assertion  \n",
       "5                   1.0        assertion  \n",
       "6                   1.0        assertion  \n",
       "7                   1.0        assertion  \n",
       "8                   1.0        assertion  \n",
       "9                0.9758        assertion  \n",
       "10                  1.0        assertion  \n",
       "11                  1.0        assertion  \n",
       "12                  1.0        assertion  \n",
       "13                  1.0        assertion  \n",
       "14               0.9999        assertion  \n",
       "15               0.9966        assertion  \n",
       "16                  1.0        assertion  \n",
       "17               0.9961        assertion  \n",
       "18                  1.0        assertion  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.merge(entities_df, assertion_df,  on=['chunk_id', 'chunk']).drop(columns='chunk_id')\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Downloading sample datasets.\n",
    "!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Healthcare/data/mt_samples_10.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- index: long (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mt_samples_df = spark.createDataFrame(pd.read_csv(\"mt_samples_10.csv\", sep=',', index_col=[\"index\"]).reset_index())\n",
    "\n",
    "mt_samples_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:04:34, INFO Error while sending or receiving.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/py4j/clientserver.py\", line 503, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "17:04:34, INFO Closing down clientserver connection\n",
      "17:04:34, INFO Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/py4j/clientserver.py\", line 503, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/py4j/clientserver.py\", line 506, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "17:04:34, INFO Closing down clientserver connection\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|index|                text|\n",
      "+-----+--------------------+\n",
      "|    0|Sample Type / Med...|\n",
      "|    1|Sample Type / Med...|\n",
      "|    2|Sample Type / Med...|\n",
      "|    3|Sample Type / Med...|\n",
      "|    4|Sample Type / Med...|\n",
      "|    5|Sample Type / Med...|\n",
      "|    6|Sample Type / Med...|\n",
      "|    7|Sample Type / Med...|\n",
      "|    8|Sample Type / Med...|\n",
      "|    9|Sample Type / Med...|\n",
      "+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mt_samples_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.transform(mt_samples_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|index|                text|            document|            sentence|               token|          embeddings|                 ner|           ner_chunk|           assertion|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|    0|Sample Type / Med...|[{document, 0, 54...|[{document, 0, 24...|[{token, 0, 5, Sa...|[{word_embeddings...|[{named_entity, 0...|[{chunk, 68, 76, ...|[{assertion, 68, ...|\n",
      "|    1|Sample Type / Med...|[{document, 0, 32...|[{document, 0, 26...|[{token, 0, 5, Sa...|[{word_embeddings...|[{named_entity, 0...|[{chunk, 68, 92, ...|[{assertion, 68, ...|\n",
      "|    2|Sample Type / Med...|[{document, 0, 42...|[{document, 0, 14...|[{token, 0, 5, Sa...|[{word_embeddings...|[{named_entity, 0...|[{chunk, 68, 73, ...|[{assertion, 68, ...|\n",
      "|    3|Sample Type / Med...|[{document, 0, 20...|[{document, 0, 29...|[{token, 0, 5, Sa...|[{word_embeddings...|[{named_entity, 0...|                  []|                  []|\n",
      "|    4|Sample Type / Med...|[{document, 0, 34...|[{document, 0, 11...|[{token, 0, 5, Sa...|[{word_embeddings...|[{named_entity, 0...|[{chunk, 68, 82, ...|[{assertion, 68, ...|\n",
      "|    5|Sample Type / Med...|[{document, 0, 15...|[{document, 0, 28...|[{token, 0, 5, Sa...|[{word_embeddings...|[{named_entity, 0...|[{chunk, 1399, 14...|[{assertion, 1399...|\n",
      "|    6|Sample Type / Med...|[{document, 0, 25...|[{document, 0, 15...|[{token, 0, 5, Sa...|[{word_embeddings...|[{named_entity, 0...|[{chunk, 68, 73, ...|[{assertion, 68, ...|\n",
      "|    7|Sample Type / Med...|[{document, 0, 93...|[{document, 0, 19...|[{token, 0, 5, Sa...|[{word_embeddings...|[{named_entity, 0...|[{chunk, 1063, 10...|[{assertion, 1063...|\n",
      "|    8|Sample Type / Med...|[{document, 0, 20...|[{document, 0, 15...|[{token, 0, 5, Sa...|[{word_embeddings...|[{named_entity, 0...|[{chunk, 363, 372...|[{assertion, 363,...|\n",
      "|    9|Sample Type / Med...|[{document, 0, 19...|[{document, 0, 15...|[{token, 0, 5, Sa...|[{word_embeddings...|[{named_entity, 0...|[{chunk, 79, 95, ...|[{assertion, 79, ...|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(result=['Sample Type / Medical Specialty:\\nHematology - Oncology\\nSample Name:\\nDischarge Summary - Mesothelioma - 1\\nDescription:\\nMesothelioma, pleural effusion, atrial fibrillation, anemia, ascites, esophageal reflux, and history of deep venous thrombosis.', '(Medical Transcription Sample Report)\\nPRINCIPAL DIAGNOSIS:\\nMesothelioma.', 'SECONDARY DIAGNOSES:\\nPleural effusion, atrial fibrillation, anemia, ascites, esophageal reflux, and history of deep venous thrombosis.', 'PROCEDURES', '1. On August 24, 2007, decortication of the lung with pleural biopsy and transpleural fluoroscopy.', '2. On August 20, 2007, thoracentesis.', '3. On August 31, 2007, Port-A-Cath placement.', 'HISTORY AND PHYSICAL:\\nThe patient is a 41-year-old Vietnamese female with a nonproductive cough that started last week.', 'She has had right-sided chest pain radiating to her back with fever starting yesterday.', 'She has a history of pericarditis and pericardectomy in May 2006 and developed cough with right-sided chest pain, and went to an urgent care center.', 'Chest x-ray revealed right-sided pleural effusion.', 'PAST MEDICAL HISTORY', '1. Pericardectomy.', '2. Pericarditis.', '2. Atrial fibrillation.', '4. RNCA with intracranial thrombolytic treatment.', '5 PTA of MCA.', '6. Mesenteric venous thrombosis.', '7. Pericardial window.', '8. Cholecystectomy.', '9. Left thoracentesis.', 'FAMILY HISTORY:\\nNo family history of coronary artery disease, CVA, diabetes, CHF or MI.', 'The patient has one family member, a sister, with history of cancer.', 'SOCIAL HISTORY:\\nShe is married.', 'Employed with the US Post Office.', 'She is a mother of three.', 'Denies tobacco, alcohol or illicit drug use.', 'MEDICATIONS', '1. Coumadin 1 mg daily.', 'Last INR was on Tuesday, August 14, 2007, and her INR was 2.3.', '2. Amiodarone 100 mg p.o. daily.', 'REVIEW OF SYSTEMS:\\nComplete review of systems negative except as in pulmonary as noted above.', 'The patient also reports occasional numbness and tingling of her left arm.', 'PHYSICAL EXAMINATION\\nVITAL SIGNS: Blood pressure 123/95, heart rate 83, respirations 20, temperature 97, and oxygen saturation 97%.', 'GENERAL: Positive nonproductive cough and pain with coughing.', 'HEENT: Pupils are equal and reactive to light and accommodation.', 'Tympanic membranes are clear.', 'NECK: Supple.', 'No lymphadenopathy.', 'No masses.', 'RESPIRATORY: Pleural friction rub is noted.', 'GI: Soft, nondistended, and nontender.', 'Positive bowel sounds.', 'No organomegaly.', 'EXTREMITIES: No edema, no clubbing, no cyanosis, no tenderness.', 'Full range of motion.', 'Normal pulses in all extremities.', 'SKIN: No breakdown or lesions.', 'No ulcers.', 'NEUROLOGIC: Grossly intact.', 'No focal deficits.', 'Awake, alert, and oriented to person, place, and time.', 'LABORATORY DATA:\\nLabs are pending.', 'HOSPITAL COURSE:\\nThe patient was admitted for a right-sided pleural effusion for thoracentesis on Monday by Dr. X. Her Coumadin was placed on hold.', 'A repeat echocardiogram was checked.', 'She was started on prophylaxis for DVT with Lovenox 40 mg subcutaneously.', 'Her history dated back to March 2005 when she first sought medical attention for evidence of pericarditis, which was treated with pericardial window in an outside hospital, at that time she was also found to have mesenteric pain and thrombosis, is now anticoagulated.', 'Her pericardial fluid was accumulated and she was seen by Dr. Y. At that time, she was recommended for pericardectomy, which was performed by Dr. Z. Review of her CT scan from March 2006 prior to her pericardectomy, already shows bilateral plural effusions.', 'The patient improved clinically after the pericardectomy with resolution of her symptoms.', 'Recently, she was readmitted to the hospital with chest pain and found to have bilateral pleural effusion, the right greater than the left.', 'CT of the chest also revealed a large mediastinal lymph node.', 'We reviewed the pathology obtained from the pericardectomy in March 2006, which was diagnostic of mesothelioma.', 'At this time, chest tube placement for drainage of the fluid occurred and thoracoscopy with fluid biopsies, which were performed, which revealed epithelioid malignant mesothelioma.', 'The patient was then stained with a PET CT, which showed extensive uptake in the chest, bilateral pleural pericardial effusions, and lymphadenopathy.', 'She also had acidic fluid, pectoral and intramammary lymph nodes and uptake in L4 with SUV of', '4. This was consistent with stage III disease.', 'Her repeat echocardiogram showed an ejection fraction of 45% to 49%.', 'She was transferred to Oncology service and started on chemotherapy on September 1, 2007 with cisplatin 75 mg/centimeter squared equaling 109 mg IV piggyback over 2 hours on September 1, 2007, Alimta 500 mg/ centimeter squared equaling 730 mg IV piggyback over 10 minutes.', 'This was all initiated after a Port-A-Cath was placed.', 'The chemotherapy was well tolerated and the patient was discharged the following day after discontinuing IV fluid and IV.', 'Her Port-A-Cath was packed with heparin according to protocol.', 'DISCHARGE MEDICATIONS:\\nZofran, Phenergan, Coumadin, and Lovenox, and Vicodin\\nDISCHARGE INSTRUCTIONS:\\nShe was instructed to followup with Dr. XYZ in the office to check her INR on Tuesday.', 'She was instructed to call if she had any other questions or concerns in the interim.', 'Keywords:\\nhematology - oncology, mesothelioma, pleural effusion, atrial fibrillation, anemia, ascites, esophageal reflux, deep venous thrombosis, port-a-cath placement, port a cath, iv piggyback, venous thrombosis, atrial, thrombosis, pericardial, lymphadenopathy, fluid, pericardectomy, chest, pleural,'])]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.select('sentence.result').take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+-----+---+-------------------------+-------+------------+----------+\n",
      "|chunk                    |begin|end|ner_label                |sent_id|assertion   |confidence|\n",
      "+-------------------------+-----+---+-------------------------+-------+------------+----------+\n",
      "|Discharge                |68   |76 |Admission_Discharge      |0      |Past        |0.991     |\n",
      "|pleural effusion         |132  |147|Disease_Syndrome_Disorder|0      |Present     |1.0       |\n",
      "|anemia                   |171  |176|Disease_Syndrome_Disorder|0      |Family      |1.0       |\n",
      "|ascites                  |179  |185|Disease_Syndrome_Disorder|0      |Hypothetical|0.9782    |\n",
      "|esophageal reflux        |188  |204|Disease_Syndrome_Disorder|0      |Family      |1.0       |\n",
      "|deep venous thrombosis   |222  |243|Disease_Syndrome_Disorder|0      |Family      |1.0       |\n",
      "|Pleural effusion         |340  |355|Disease_Syndrome_Disorder|2      |Present     |1.0       |\n",
      "|anemia                   |379  |384|Disease_Syndrome_Disorder|2      |Present     |1.0       |\n",
      "|ascites                  |387  |393|Disease_Syndrome_Disorder|2      |Present     |1.0       |\n",
      "|esophageal reflux        |396  |412|Disease_Syndrome_Disorder|2      |Present     |1.0       |\n",
      "|deep venous thrombosis   |430  |451|Disease_Syndrome_Disorder|2      |Past        |0.9962    |\n",
      "|decortication of the lung|488  |512|Procedure                |4      |Past        |1.0       |\n",
      "|pleural biopsy           |519  |532|Procedure                |4      |Past        |1.0       |\n",
      "|thoracentesis            |587  |599|Procedure                |5      |Past        |1.0       |\n",
      "|Port-A-Cath placement    |625  |645|Procedure                |6      |Past        |1.0       |\n",
      "|cough                    |738  |742|Symptom                  |7      |SomeoneElse |0.8521    |\n",
      "|chest pain               |792  |801|Symptom                  |8      |Past        |1.0       |\n",
      "|fever                    |830  |834|VS_Finding               |8      |Present     |0.9997    |\n",
      "|pericarditis             |877  |888|Disease_Syndrome_Disorder|9      |Present     |0.9491    |\n",
      "|pericardectomy           |894  |907|Procedure                |9      |Past        |1.0       |\n",
      "+-------------------------+-----+---+-------------------------+-------+------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "result.select(F.explode(F.arrays_zip(result.ner_chunk.result,\n",
    "                                     result.ner_chunk.begin,\n",
    "                                     result.ner_chunk.end,\n",
    "                                     result.ner_chunk.metadata,\n",
    "                                     result.assertion.result,\n",
    "                                     result.assertion.metadata)).alias(\"cols\")) \\\n",
    "      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
    "              F.expr(\"cols['1']\").alias(\"begin\"),\n",
    "              F.expr(\"cols['2']\").alias(\"end\"),\n",
    "              F.expr(\"cols['3']['entity']\").alias(\"ner_label\"),\n",
    "              F.expr(\"cols['3']['sentence']\").alias(\"sent_id\"),\n",
    "              F.expr(\"cols['4']\").alias(\"assertion\"),\n",
    "              F.expr(\"cols['5']['confidence']\").alias(\"confidence\") ).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dYN97Es2be4p"
   },
   "source": [
    "### Pretrained `assertion_dl_radiology` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YMl2QAeNbe4p",
    "outputId": "cdcf11f8-4561-4873-8128-63c16b4527cf",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence_detector_dl_healthcare download started this may take some time.\n",
      "Approximate size to download 367.3 KB\n",
      "sentence_detector_dl_healthcare download started this may take some time.\n",
      "Approximate size to download 367.3 KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/02 17:01:32 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n",
      "25/01/02 17:01:32 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n",
      "25/01/02 17:01:32 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download done! Loading the resource.\n",
      "[OK!]\n",
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[ | ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/02 17:01:35 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK!]\n",
      "ner_radiology download started this may take some time.\n",
      "ner_radiology download started this may take some time.\n",
      "Approximate size to download 13.9 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/02 17:01:37 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n",
      "25/01/02 17:01:37 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download done! Loading the resource.\n",
      "[OK!]\n",
      "assertion_dl_radiology download started this may take some time.\n",
      "assertion_dl_radiology download started this may take some time.\n",
      "Approximate size to download 2.4 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/02 17:01:40 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n",
      "25/01/02 17:01:40 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download done! Loading the resource.\n",
      "\n",
      "OK!]"
     ]
    }
   ],
   "source": [
    "documentAssembler = nlp.DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "# Sentence Detector annotator, processes various sentences per line\n",
    "sentenceDetector = nlp.SentenceDetectorDLModel\\\n",
    "    .pretrained(\"sentence_detector_dl_healthcare\",\"en\",\"clinical/models\") \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "# Tokenizer splits words in a relevant format for NLP\n",
    "tokenizer = nlp.Tokenizer()\\\n",
    "    .setInputCols([\"sentence\"])\\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "# Clinical word embeddings trained on PubMED dataset\n",
    "word_embeddings = nlp.WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n",
    "    .setInputCols([\"sentence\", \"token\"])\\\n",
    "    .setOutputCol(\"embeddings\")\n",
    "\n",
    "# NER model for radiology\n",
    "radiology_ner = medical.NerModel.pretrained(\"ner_radiology\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"ner\")\\\n",
    "    #.setIncludeAllConfidenceScores(False)\n",
    "\n",
    "ner_converter = medical.NerConverterInternal() \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"ner\"]) \\\n",
    "    .setOutputCol(\"ner_chunk\")\\\n",
    "    .setWhiteList([\"ImagingFindings\"])\n",
    "\n",
    "# Assertion model trained on radiology dataset\n",
    "radiology_assertion = medical.AssertionDLModel.pretrained(\"assertion_dl_radiology\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\", \"ner_chunk\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"assertion\")\n",
    "\n",
    "nlpPipeline = nlp.Pipeline(stages=[\n",
    "    documentAssembler, \n",
    "    sentenceDetector,\n",
    "    tokenizer,\n",
    "    word_embeddings,\n",
    "    radiology_ner,\n",
    "    ner_converter,\n",
    "    radiology_assertion\n",
    "    ])\n",
    "\n",
    "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "radiologyAssertion_model = nlpPipeline.fit(empty_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Confirmed', 'Suspected', 'Negative']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "radiology_assertion.getClasses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Ehm7WwJrbe4r"
   },
   "outputs": [],
   "source": [
    "# A sample text from a radiology report\n",
    "\n",
    "text = \"\"\"No right-sided pleural effusion or pneumothorax is definitively seen and there are mildly displaced fractures of the left lateral 8th and likely 9th ribs.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "_1iCxtKjbe4s"
   },
   "outputs": [],
   "source": [
    "data = spark.createDataFrame([[text]]).toDF(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "lSpEvzDObe4s"
   },
   "outputs": [],
   "source": [
    "result = radiologyAssertion_model.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fGxRCsusbe4s",
    "outputId": "f7d576c2-24e5-4db6-9d74-1b1bb9b5f145"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 28:======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------------+-------+---------+\n",
      "|chunk              |ner_label      |sent_id|assertion|\n",
      "+-------------------+---------------+-------+---------+\n",
      "|effusion           |ImagingFindings|0      |Negative |\n",
      "|pneumothorax       |ImagingFindings|0      |Negative |\n",
      "|displaced fractures|ImagingFindings|0      |Confirmed|\n",
      "+-------------------+---------------+-------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "result.select(F.explode(F.arrays_zip(result.ner_chunk.result, \n",
    "                                     result.ner_chunk.metadata, \n",
    "                                     result.assertion.result)).alias(\"cols\")) \\\n",
    "      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
    "              F.expr(\"cols['1']['entity']\").alias(\"ner_label\"),\n",
    "              F.expr(\"cols['1']['sentence']\").alias(\"sent_id\"),\n",
    "              F.expr(\"cols['2']\").alias(\"assertion\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0vWIDpk50QfG"
   },
   "source": [
    "# **Writing a generic Assertion + NER function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "ltGPQYr60F6G"
   },
   "outputs": [],
   "source": [
    "def get_base_pipeline (embeddings = 'embeddings_clinical'):\n",
    "\n",
    "    documentAssembler = nlp.DocumentAssembler()\\\n",
    "        .setInputCol(\"text\")\\\n",
    "        .setOutputCol(\"document\")\n",
    "\n",
    "  # Sentence Detector annotator, processes various sentences per line\n",
    "    sentenceDetector = nlp.SentenceDetector()\\\n",
    "        .setInputCols([\"document\"])\\\n",
    "        .setOutputCol(\"sentence\")\n",
    "\n",
    "  # Tokenizer splits words in a relevant format for NLP\n",
    "    tokenizer = nlp.Tokenizer()\\\n",
    "        .setInputCols([\"sentence\"])\\\n",
    "        .setOutputCol(\"token\")\n",
    "\n",
    "  # Clinical word embeddings trained on PubMED dataset\n",
    "    word_embeddings = nlp.WordEmbeddingsModel.pretrained(embeddings, \"en\", \"clinical/models\")\\\n",
    "        .setInputCols([\"sentence\", \"token\"])\\\n",
    "        .setOutputCol(\"embeddings\")\n",
    "\n",
    "    base_pipeline = nlp.Pipeline(stages=[\n",
    "                        documentAssembler,\n",
    "                        sentenceDetector,\n",
    "                        tokenizer,\n",
    "                        word_embeddings])\n",
    "\n",
    "    return base_pipeline\n",
    "\n",
    "\n",
    "\n",
    "def get_clinical_assertion (embeddings, spark_df, nrows = 100, ner_model_name = 'ner_clinical', assertion_model_name=\"assertion_dl\"):\n",
    "\n",
    "  # NER model trained on i2b2 (sampled from MIMIC) dataset\n",
    "    loaded_ner_model = medical.NerModel.pretrained(ner_model_name, \"en\", \"clinical/models\") \\\n",
    "        .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "        .setOutputCol(\"ner\")\n",
    "\n",
    "    ner_converter = medical.NerConverterInternal() \\\n",
    "        .setInputCols([\"sentence\", \"token\", \"ner\"]) \\\n",
    "        .setOutputCol(\"ner_chunk\")\n",
    "\n",
    "  # Assertion model trained on i2b2 (sampled from MIMIC) dataset\n",
    "  # coming from sparknlp_jsl.annotator !!\n",
    "    clinical_assertion = medical.AssertionDLModel.pretrained(assertion_model_name, \"en\", \"clinical/models\") \\\n",
    "        .setInputCols([\"sentence\", \"ner_chunk\", \"embeddings\"]) \\\n",
    "        .setOutputCol(\"assertion\")\n",
    "      \n",
    "\n",
    "    base_model = get_base_pipeline (embeddings)\n",
    "\n",
    "    nlpPipeline = nlp.Pipeline(stages=[\n",
    "        base_model,\n",
    "        loaded_ner_model,\n",
    "        ner_converter,\n",
    "        clinical_assertion])\n",
    "\n",
    "    empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "    model = nlpPipeline.fit(empty_data)\n",
    "\n",
    "    result = model.transform(spark_df.limit(nrows))\n",
    "\n",
    "    result = result.withColumn(\"id\", F.monotonically_increasing_id())\n",
    "\n",
    "    result_df = result.select(F.explode(F.arrays_zip(result.ner_chunk.result, \n",
    "                                                     result.ner_chunk.metadata, \n",
    "                                                     result.assertion.result,\n",
    "                                                     result.assertion.metadata)).alias(\"cols\")) \\\n",
    "                      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
    "                              F.expr(\"cols['1']['entity']\").alias(\"ner_label\"),\n",
    "                              F.expr(\"cols['2']\").alias(\"assertion\"),\n",
    "                              F.expr(\"cols['3']['confidence']\").alias(\"confidence\"))\\\n",
    "                      .filter(\"ner_label!='O'\")\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V81zaAe13qLU",
    "outputId": "5f22e5f9-6ad0-4274-d82c-e927d5593c0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_clinical_large download started this may take some time.\n",
      "ner_clinical_large download started this may take some time.\n",
      "Approximate size to download 13.9 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/02 17:04:45 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n",
      "25/01/02 17:04:45 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download done! Loading the resource.\n",
      "[OK!]\n",
      "assertion_dl download started this may take some time.\n",
      "assertion_dl download started this may take some time.\n",
      "Approximate size to download 1.3 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/02 17:04:47 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n",
      "25/01/02 17:04:47 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download done! Loading the resource.\n",
      "[OK!]\n",
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[ | ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/02 17:04:50 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OK!]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 31:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+---------+---------+----------+\n",
      "|                       chunk|ner_label|assertion|confidence|\n",
      "+----------------------------+---------+---------+----------+\n",
      "|                Mesothelioma|  PROBLEM|  present|    0.9996|\n",
      "|                Mesothelioma|  PROBLEM|  present|    0.9996|\n",
      "|            pleural effusion|  PROBLEM|  present|    0.9998|\n",
      "|         atrial fibrillation|  PROBLEM|  present|       1.0|\n",
      "|                      anemia|  PROBLEM|  present|    0.9999|\n",
      "|                     ascites|  PROBLEM|  present|    0.9999|\n",
      "|           esophageal reflux|  PROBLEM|  present|    0.9999|\n",
      "|      deep venous thrombosis|  PROBLEM|  present|    0.8533|\n",
      "|                Mesothelioma|  PROBLEM|  present|    0.9992|\n",
      "|            Pleural effusion|  PROBLEM|  present|    0.9999|\n",
      "|         atrial fibrillation|  PROBLEM|  present|       1.0|\n",
      "|                      anemia|  PROBLEM|  present|    0.9999|\n",
      "|                     ascites|  PROBLEM|  present|    0.9998|\n",
      "|           esophageal reflux|  PROBLEM|  present|    0.9999|\n",
      "|      deep venous thrombosis|  PROBLEM|  present|    0.8612|\n",
      "|   decortication of the lung|TREATMENT|  present|       1.0|\n",
      "|              pleural biopsy|     TEST|  present|    0.9924|\n",
      "|    transpleural fluoroscopy|     TEST|  present|    0.9945|\n",
      "|               thoracentesis|TREATMENT|  present|    0.9998|\n",
      "|       Port-A-Cath placement|TREATMENT|  present|       1.0|\n",
      "|       a nonproductive cough|  PROBLEM|  present|    0.9985|\n",
      "|      right-sided chest pain|  PROBLEM|  present|    0.9998|\n",
      "|                       fever|  PROBLEM|  present|    0.9997|\n",
      "|                pericarditis|  PROBLEM|  present|    0.9998|\n",
      "|              pericardectomy|TREATMENT|  present|    0.9999|\n",
      "|                       cough|  PROBLEM|  present|    0.9999|\n",
      "|      right-sided chest pain|  PROBLEM|  present|    0.9999|\n",
      "|                 Chest x-ray|     TEST|  present|    0.9999|\n",
      "|right-sided pleural effusion|  PROBLEM|  present|    0.9999|\n",
      "|              Pericardectomy|TREATMENT|  present|    0.9985|\n",
      "+----------------------------+---------+---------+----------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "embeddings = 'embeddings_clinical'\n",
    "\n",
    "ner_model_name = 'ner_clinical_large'\n",
    "\n",
    "nrows = 100\n",
    "\n",
    "ner_df = get_clinical_assertion (embeddings, mt_samples_df, nrows, ner_model_name)\n",
    "\n",
    "ner_df.show(30,truncate=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LmLPlfCw5hh-",
    "outputId": "87c83656-5714-440f-d4ff-f73f6ed73907"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_posology download started this may take some time.\n",
      "[ | ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/02 17:04:58 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n",
      "25/01/02 17:04:58 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_posology download started this may take some time.\n",
      "Approximate size to download 13.8 MB\n",
      "Download done! Loading the resource.\n",
      "[OK!]\n",
      "assertion_dl download started this may take some time.\n",
      "[OK!]\n",
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[ | ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/02 17:05:04 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OK!]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 38:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+------------+----------+\n",
      "|           chunk|ner_label|   assertion|confidence|\n",
      "+----------------+---------+------------+----------+\n",
      "|        Coumadin|     DRUG|hypothetical|    0.8709|\n",
      "|            1 mg| STRENGTH| conditional|    0.7772|\n",
      "|           daily|FREQUENCY| conditional|    0.5086|\n",
      "|      Amiodarone|     DRUG|hypothetical|    0.8589|\n",
      "|          100 mg| STRENGTH|hypothetical|    0.6143|\n",
      "|             p.o|    ROUTE|hypothetical|    0.7991|\n",
      "|           daily|FREQUENCY|     present|    0.9074|\n",
      "|        Coumadin|     DRUG|     present|    0.9999|\n",
      "|         Lovenox|     DRUG|     present|    0.9994|\n",
      "|           40 mg| STRENGTH|     present|    0.9982|\n",
      "|  subcutaneously|    ROUTE|     present|    0.9302|\n",
      "|    chemotherapy|     DRUG|     present|    0.9994|\n",
      "|       cisplatin|     DRUG|     present|    0.9995|\n",
      "|75 mg/centimeter| STRENGTH|     present|    0.9998|\n",
      "|          109 mg| STRENGTH|     present|    0.9999|\n",
      "|              IV|    ROUTE|     present|    0.9956|\n",
      "|       piggyback|     DRUG|     present|    0.9823|\n",
      "|    over 2 hours| DURATION|     present|       1.0|\n",
      "|       September|     DRUG|     present|    0.9531|\n",
      "|          Alimta|     DRUG|     present|    0.8248|\n",
      "+----------------+---------+------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "embeddings = 'embeddings_clinical'\n",
    "\n",
    "ner_model_name = 'ner_posology'\n",
    "\n",
    "nrows = 100\n",
    "\n",
    "ner_df = get_clinical_assertion (embeddings, mt_samples_df, nrows, ner_model_name)\n",
    "\n",
    "ner_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cQ9xeS3kwClE",
    "outputId": "b050b44f-fbd1-48ee-d013-b903b64d70e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_posology_greedy download started this may take some time.\n",
      "[ | ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/02 17:05:11 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n",
      "25/01/02 17:05:11 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_posology_greedy download started this may take some time.\n",
      "Approximate size to download 13.9 MB\n",
      "Download done! Loading the resource.\n",
      "[OK!]\n",
      "assertion_dl download started this may take some time.\n",
      "[OK!]\n",
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[ | ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/02 17:05:16 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+----------------+---------+---------+----------+\n",
      "|           chunk|ner_label|assertion|confidence|\n",
      "+----------------+---------+---------+----------+\n",
      "|capsule of Advil|     DRUG|   absent|    0.9855|\n",
      "+----------------+---------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embeddings = 'embeddings_clinical'\n",
    "\n",
    "ner_model_name = 'ner_posology_greedy'\n",
    "\n",
    "entry_data = spark.createDataFrame([[\"The patient did not take a capsule of Advil.\"]]).toDF(\"text\")\n",
    "\n",
    "ner_df = get_clinical_assertion (embeddings, entry_data, nrows, ner_model_name)\n",
    "\n",
    "ner_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "djV_FKNtYcoP",
    "outputId": "71ee07b2-e8a2-419c-fce2-8e44a01295e8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_clinical download started this may take some time.\n",
      "ner_clinical download started this may take some time.\n",
      "Approximate size to download 13.9 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/02 17:05:20 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n",
      "25/01/02 17:05:20 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download done! Loading the resource.\n",
      "[OK!]\n",
      "assertion_dl download started this may take some time.\n",
      "[OK!]\n",
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[ | ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/02 17:05:25 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+-----+---------+---------+----------+\n",
      "|chunk|ner_label|assertion|confidence|\n",
      "+-----+---------+---------+----------+\n",
      "|fever|  PROBLEM|   absent|     0.998|\n",
      "+-----+---------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embeddings = 'embeddings_clinical'\n",
    "\n",
    "ner_model_name = 'ner_clinical'\n",
    "\n",
    "entry_data = spark.createDataFrame([[\"The patient has no fever\"]]).toDF(\"text\")\n",
    "\n",
    "ner_df = get_clinical_assertion (embeddings, entry_data, nrows, ner_model_name)\n",
    "\n",
    "ner_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_text = \"\"\"\n",
    "Patient with severe fever and sore throat.\n",
    "He shows no stomach pain and he maintained on an epidural and PCA for pain control.\n",
    "He also became short of breath with climbing a flight of stairs.\n",
    "After CT, lung tumor located at the right lower lobe. Father with Alzheimer.\n",
    "\"\"\"\n",
    "light_model = nlp.LightPipeline(model)\n",
    "\n",
    "light_result = light_model.fullAnnotate(clinical_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk</th>\n",
       "      <th>begin</th>\n",
       "      <th>end</th>\n",
       "      <th>ner_label</th>\n",
       "      <th>ner_source</th>\n",
       "      <th>ner_confidence</th>\n",
       "      <th>assertion</th>\n",
       "      <th>assertion_confidence</th>\n",
       "      <th>assertion_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fever</td>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "      <td>VS_Finding</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.9943</td>\n",
       "      <td>Present</td>\n",
       "      <td>1.0</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sore throat</td>\n",
       "      <td>31</td>\n",
       "      <td>41</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.69635</td>\n",
       "      <td>Present</td>\n",
       "      <td>1.0</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stomach pain</td>\n",
       "      <td>56</td>\n",
       "      <td>67</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.85885</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pain</td>\n",
       "      <td>114</td>\n",
       "      <td>117</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.9864</td>\n",
       "      <td>Hypothetical</td>\n",
       "      <td>1.0</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>short of breath</td>\n",
       "      <td>143</td>\n",
       "      <td>157</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.6305</td>\n",
       "      <td>Present</td>\n",
       "      <td>1.0</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>climbing a flight of stairs</td>\n",
       "      <td>164</td>\n",
       "      <td>190</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.54858005</td>\n",
       "      <td>Present</td>\n",
       "      <td>0.9434</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Alzheimer</td>\n",
       "      <td>259</td>\n",
       "      <td>267</td>\n",
       "      <td>Disease_Syndrome_Disorder</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.9796</td>\n",
       "      <td>Family</td>\n",
       "      <td>0.8136</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         chunk  begin  end                  ner_label  \\\n",
       "0                        fever     21   25                 VS_Finding   \n",
       "1                  sore throat     31   41                    Symptom   \n",
       "2                 stomach pain     56   67                    Symptom   \n",
       "3                         pain    114  117                    Symptom   \n",
       "4              short of breath    143  157                    Symptom   \n",
       "5  climbing a flight of stairs    164  190                    Symptom   \n",
       "6                    Alzheimer    259  267  Disease_Syndrome_Disorder   \n",
       "\n",
       "  ner_source ner_confidence     assertion assertion_confidence  \\\n",
       "0  ner_chunk         0.9943       Present                  1.0   \n",
       "1  ner_chunk        0.69635       Present                  1.0   \n",
       "2  ner_chunk        0.85885        Absent                  1.0   \n",
       "3  ner_chunk         0.9864  Hypothetical                  1.0   \n",
       "4  ner_chunk         0.6305       Present                  1.0   \n",
       "5  ner_chunk     0.54858005       Present               0.9434   \n",
       "6  ner_chunk         0.9796        Family               0.8136   \n",
       "\n",
       "  assertion_source  \n",
       "0        assertion  \n",
       "1        assertion  \n",
       "2        assertion  \n",
       "3        assertion  \n",
       "4        assertion  \n",
       "5        assertion  \n",
       "6        assertion  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_maps = {\n",
    "    'document_identifier': 'ner_clinical_pipeline',\n",
    "    'document_text': 'document',\n",
    "    'entities': ['ner_chunk'],\n",
    "    'assertions': ['assertion']\n",
    "}\n",
    "\n",
    "pipeline_parser = medical.PipelineOutputParser(column_maps,)\n",
    "result = pipeline_parser.run(light_result) #light_result is defined above\n",
    "\n",
    "assertions_df = pd.DataFrame(result['result'][0]['assertions'])\n",
    "entities_df = pd.DataFrame(result['result'][0]['entities'])\n",
    "\n",
    "merged_df = pd.merge(entities_df, assertions_df,  on=['chunk_id', 'chunk']).drop(columns='chunk_id')\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replace Assertion Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_clinical_large download started this may take some time.\n",
      "ner_clinical_large download started this may take some time.\n",
      "Approximate size to download 13.9 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/30 16:06:17 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n",
      "24/12/30 16:06:17 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download done! Loading the resource.\n",
      "[OK!]\n",
      "assertion_jsl_augmented download started this may take some time.\n",
      "\n",
      "OK!]"
     ]
    }
   ],
   "source": [
    "# NER model trained on i2b2 (sampled from MIMIC) dataset\n",
    "clinical_ner = medical.NerModel.pretrained(\"ner_clinical_large\",\"en\",\"clinical/models\")\\\n",
    "    .setInputCols([\"sentence\",\"token\",\"embeddings\"])\\\n",
    "    .setOutputCol(\"ner\")\n",
    "\n",
    "ner_converter = medical.NerConverterInternal()\\\n",
    "    .setInputCols([\"sentence\",\"token\",\"ner\"])\\\n",
    "    .setOutputCol(\"ner_chunk\")\n",
    "\n",
    "# Assertion model trained on i2b2 (sampled from MIMIC) dataset\n",
    "clinical_replaced_assertion = medical.AssertionDLModel.pretrained(\"assertion_jsl_augmented\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\", \"ner_chunk\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"replaced_assertion\") \\\n",
    "    .setIncludeConfidence(True) \\\n",
    "    .setReplaceLabels({\"Present\":\"Exist\",\n",
    "                       \"Absent\": \"None\",\n",
    "                       \"Conditional\": \"Possible\",\n",
    "                       \"Hypothetical\": \"Possible\"})\n",
    "\n",
    "nlpPipeline = nlp.Pipeline(stages=[\n",
    "    documentAssembler,\n",
    "    sentenceDetector,\n",
    "    tokenizer,\n",
    "    word_embeddings,\n",
    "    clinical_ner,\n",
    "    ner_converter,\n",
    "    clinical_replaced_assertion\n",
    "    ])\n",
    "\n",
    "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "model = nlpPipeline.fit(empty_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunks</th>\n",
       "      <th>entities</th>\n",
       "      <th>replaced_assertion</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>severe fever</td>\n",
       "      <td>PROBLEM</td>\n",
       "      <td>Exist</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sore throat</td>\n",
       "      <td>PROBLEM</td>\n",
       "      <td>Exist</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stomach pain</td>\n",
       "      <td>PROBLEM</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>an epidural</td>\n",
       "      <td>TREATMENT</td>\n",
       "      <td>Exist</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PCA</td>\n",
       "      <td>TREATMENT</td>\n",
       "      <td>Past</td>\n",
       "      <td>0.9978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pain control</td>\n",
       "      <td>PROBLEM</td>\n",
       "      <td>Possible</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>short of breath</td>\n",
       "      <td>PROBLEM</td>\n",
       "      <td>Exist</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CT</td>\n",
       "      <td>TEST</td>\n",
       "      <td>Past</td>\n",
       "      <td>0.9963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lung tumor</td>\n",
       "      <td>PROBLEM</td>\n",
       "      <td>Exist</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Alzheimer</td>\n",
       "      <td>PROBLEM</td>\n",
       "      <td>Family</td>\n",
       "      <td>0.8136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            chunks   entities replaced_assertion confidence\n",
       "0     severe fever    PROBLEM              Exist        1.0\n",
       "1      sore throat    PROBLEM              Exist        1.0\n",
       "2     stomach pain    PROBLEM               None        1.0\n",
       "3      an epidural  TREATMENT              Exist        1.0\n",
       "4              PCA  TREATMENT               Past     0.9978\n",
       "5     pain control    PROBLEM           Possible        1.0\n",
       "6  short of breath    PROBLEM              Exist        1.0\n",
       "7               CT       TEST               Past     0.9963\n",
       "8       lung tumor    PROBLEM              Exist        1.0\n",
       "9        Alzheimer    PROBLEM             Family     0.8136"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Patient with severe fever and sore throat.\n",
    "He shows no stomach pain and he maintained on an epidural and PCA for pain control.\n",
    "He also became short of breath with climbing a flight of stairs.\n",
    "After CT, lung tumor located at the right lower lobe. Father with Alzheimer.\n",
    "\"\"\"\n",
    "\n",
    "light_model = nlp.LightPipeline(model)\n",
    "light_result = light_model.fullAnnotate(text)\n",
    "\n",
    "chunks=[]\n",
    "entities=[]\n",
    "confidence=[]\n",
    "status=[]\n",
    "\n",
    "for assertion_row in light_result[0][\"replaced_assertion\"]:\n",
    "  chunk_id = assertion_row.metadata[\"chunk\"]\n",
    "  for chunk_row in light_result[0][\"ner_chunk\"]:\n",
    "    if chunk_id == chunk_row.metadata[\"chunk\"]:\n",
    "        chunks.append(chunk_row.result)\n",
    "        entities.append(chunk_row.metadata['entity'])\n",
    "        status.append(assertion_row.result)\n",
    "        confidence.append(assertion_row.metadata['confidence'])\n",
    "\n",
    "df = pd.DataFrame({'chunks':chunks, 'entities':entities, 'replaced_assertion':status, 'confidence':confidence})\n",
    "df     # \"Present\" replaced with \"Exist\", \"Absent\" replaces with \"None\", and \"Hypotetical\" replaced with \"Possible\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity Type Constraints\r\n",
    "\r\n",
    "\r\n",
    "You can effortlessly constrain assertions based on specific entity types using a convenient dictionary format: `{\"entity\": [assertion_label1, assertion_label2, .. assertion_labelN]}`. When an entity is not found in the dictionary, no constraints are applied, ensuring flexibility in your data processing. With the `setEntityAssertionCaseSensitive` parameter, you can control the case sensitivity for both entities and assertion labels. Unleash the full potential of your NLP model with these cutting-edge additions to the AssertionDLModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_clinical_large download started this may take some time.\n",
      "[OK!]\n",
      "assertion_jsl_augmented download started this may take some time.\n",
      "\n",
      "OK!]"
     ]
    }
   ],
   "source": [
    "# NER model trained on i2b2 (sampled from MIMIC) dataset\n",
    "clinical_ner = medical.NerModel.pretrained(\"ner_clinical_large\",\"en\",\"clinical/models\")\\\n",
    "    .setInputCols([\"sentence\",\"token\",\"embeddings\"])\\\n",
    "    .setOutputCol(\"ner\")\n",
    "\n",
    "ner_converter = medical.NerConverterInternal()\\\n",
    "    .setInputCols([\"sentence\",\"token\",\"ner\"])\\\n",
    "    .setOutputCol(\"ner_chunk\")\n",
    "\n",
    "# Assertion model trained on i2b2 (sampled from MIMIC) dataset\n",
    "clinical_assertion = medical.AssertionDLModel.pretrained(\"assertion_jsl_augmented\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\", \"ner_chunk\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"assertion\")\\\n",
    "    .setEntityAssertionCaseSensitive(False)\\\n",
    "    .setEntityAssertion({\n",
    "        \"PROBLEM\": [\"hypothetical\", \"absent\"],\n",
    "        \"treAtment\": [\"present\"],\n",
    "        \"TEST\": [\"Possible\"],\n",
    "    })\n",
    "\n",
    "nlpPipeline = nlp.Pipeline(\n",
    "    stages=[\n",
    "        documentAssembler,\n",
    "        sentenceDetector,\n",
    "        tokenizer,\n",
    "        word_embeddings,\n",
    "        clinical_ner,\n",
    "        ner_converter,\n",
    "        clinical_assertion\n",
    "])\n",
    "\n",
    "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "model = nlpPipeline.fit(empty_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''\n",
    "A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus (T2DM), one prior episode of HTG-induced pancreatitis three years prior to presentation, and associated with an acute hepatitis, presented with a one-week history of polyuria, poor appetite, and vomiting.\n",
    "She was on metformin, glipizide, and dapagliflozin for T2DM and atorvastatin and gemfibrozil for HTG. She had been on dapagliflozin for six months at the time of presentation.\n",
    "Physical examination on presentation was significant for dry oral mucosa ; significantly , her abdominal examination was benign with no tenderness, guarding, or rigidity. Pertinent laboratory findings on admission were: serum glucose 111 mg/dl,  creatinine 0.4 mg/dL, triglycerides 508 mg/dL, total cholesterol 122 mg/dL, and venous pH 7.27.\n",
    "'''\n",
    "light_model = nlp.LightPipeline(model)\n",
    "\n",
    "light_result = light_model.fullAnnotate(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['document_identifier', 'document_id', 'document_text', 'entities', 'assertions', 'resolutions', 'relations', 'summaries', 'deidentifications', 'classifications'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_tracer = PipelineTracer(model)\n",
    "\n",
    "column_maps = pipeline_tracer.createParserDictionary()\n",
    "column_maps.update({\"document_identifier\": \"assertion_jsl_replaced_label\"})\n",
    "\n",
    "pipeline_parser = medical.PipelineOutputParser(column_maps)\n",
    "result = pipeline_parser.run(light_result)\n",
    "\n",
    "result['result'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk</th>\n",
       "      <th>begin</th>\n",
       "      <th>end</th>\n",
       "      <th>ner_label</th>\n",
       "      <th>ner_source</th>\n",
       "      <th>ner_confidence</th>\n",
       "      <th>assertion</th>\n",
       "      <th>assertion_confidence</th>\n",
       "      <th>assertion_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>metformin</td>\n",
       "      <td>372</td>\n",
       "      <td>380</td>\n",
       "      <td>TREATMENT</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>Present</td>\n",
       "      <td>0.5364</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>glipizide</td>\n",
       "      <td>383</td>\n",
       "      <td>391</td>\n",
       "      <td>TREATMENT</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>Present</td>\n",
       "      <td>0.9993</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dapagliflozin</td>\n",
       "      <td>398</td>\n",
       "      <td>410</td>\n",
       "      <td>TREATMENT</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Present</td>\n",
       "      <td>1.0</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HTG</td>\n",
       "      <td>458</td>\n",
       "      <td>460</td>\n",
       "      <td>PROBLEM</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>Hypothetical</td>\n",
       "      <td>1.0</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Physical examination</td>\n",
       "      <td>537</td>\n",
       "      <td>556</td>\n",
       "      <td>TEST</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.9448</td>\n",
       "      <td>Possible</td>\n",
       "      <td>0.943</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tenderness</td>\n",
       "      <td>673</td>\n",
       "      <td>682</td>\n",
       "      <td>PROBLEM</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>guarding</td>\n",
       "      <td>685</td>\n",
       "      <td>692</td>\n",
       "      <td>PROBLEM</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.9989</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rigidity</td>\n",
       "      <td>698</td>\n",
       "      <td>705</td>\n",
       "      <td>PROBLEM</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.9986</td>\n",
       "      <td>Hypothetical</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  chunk  begin  end  ner_label ner_source ner_confidence  \\\n",
       "0             metformin    372  380  TREATMENT  ner_chunk         0.9998   \n",
       "1             glipizide    383  391  TREATMENT  ner_chunk         0.9999   \n",
       "2         dapagliflozin    398  410  TREATMENT  ner_chunk            1.0   \n",
       "3                   HTG    458  460    PROBLEM  ner_chunk         0.9994   \n",
       "4  Physical examination    537  556       TEST  ner_chunk         0.9448   \n",
       "5            tenderness    673  682    PROBLEM  ner_chunk         0.9996   \n",
       "6              guarding    685  692    PROBLEM  ner_chunk         0.9989   \n",
       "7              rigidity    698  705    PROBLEM  ner_chunk         0.9986   \n",
       "\n",
       "      assertion assertion_confidence assertion_source  \n",
       "0       Present               0.5364        assertion  \n",
       "1       Present               0.9993        assertion  \n",
       "2       Present                  1.0        assertion  \n",
       "3  Hypothetical                  1.0        assertion  \n",
       "4      Possible                0.943        assertion  \n",
       "5        Absent                  1.0        assertion  \n",
       "6        Absent                  1.0        assertion  \n",
       "7  Hypothetical               0.9999        assertion  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assertions_df = pd.DataFrame(result['result'][0]['assertions'])\n",
    "entities_df = pd.DataFrame(result['result'][0]['entities'])\n",
    "\n",
    "merged_df = pd.merge(entities_df, assertions_df,  on=['chunk_id', 'chunk']).drop(columns='chunk_id')\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assertion Filterer\r\n",
    "AssertionFilterer will allow you to filter out the named entities by the list of acceptable assertion statuses by using method `setWhiteList()` or to exlude some entityes by using `.setBlackList()` method. This annotator would be quite handy if you want to set a white list / black list for the acceptable assertion statuses like present or conditional; or  put into black list if you dont want absent conditions get out of your pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[ | ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/02 17:23:30 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK!]\n",
      "ner_clinical download started this may take some time.\n",
      "[OK!]\n",
      "assertion_jsl download started this may take some time.\n",
      "\n",
      "OK!]"
     ]
    }
   ],
   "source": [
    "# Annotator that transforms a text column from dataframe into an Annotation ready for NLP\n",
    "\n",
    "documentAssembler = nlp.DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "# Sentence Detector annotator, processes various sentences per line\n",
    "sentenceDetector = nlp.SentenceDetector()\\\n",
    "    .setInputCols([\"document\"])\\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "# Tokenizer splits words in a relevant format for NLP\n",
    "tokenizer = nlp.Tokenizer()\\\n",
    "    .setInputCols([\"sentence\"])\\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "# Clinical word embeddings trained on PubMED dataset\n",
    "word_embeddings = nlp.WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n",
    "    .setInputCols([\"sentence\", \"token\"])\\\n",
    "    .setOutputCol(\"embeddings\")\n",
    "\n",
    "clinical_ner = medical.NerModel.pretrained(\"ner_clinical\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"ner\")\\\n",
    "    #.setIncludeAllConfidenceScores(False)\n",
    "\n",
    "ner_converter = medical.NerConverterInternal() \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"ner\"]) \\\n",
    "    .setOutputCol(\"ner_chunk\")\\\n",
    "    .setWhiteList([\"PROBLEM\", \"TEST\",\"TREATMENT\"])\n",
    "\n",
    "clinical_assertion = medical.AssertionDLModel.pretrained(\"assertion_jsl\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\", \"ner_chunk\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"assertion\")\n",
    "\n",
    "assertion_filterer = medical.AssertionFilterer()\\\n",
    "    .setInputCols(\"sentence\",\"ner_chunk\",\"assertion\")\\\n",
    "    .setOutputCol(\"assertion_filtered\")\\\n",
    "    .setCaseSensitive(False)\\\n",
    "    .setWhiteList([\"Present\"])\n",
    "#or .setBlackList([[\"absent\"]])\n",
    "\n",
    "nlpPipeline = nlp.Pipeline(\n",
    "    stages=[\n",
    "        documentAssembler,\n",
    "        sentenceDetector,\n",
    "        tokenizer,\n",
    "        word_embeddings,\n",
    "        clinical_ner,\n",
    "        ner_converter,\n",
    "        clinical_assertion,\n",
    "        assertion_filterer\n",
    "])\n",
    "\n",
    "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "assertionFilter_model = nlpPipeline.fit(empty_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['assertion_filtered', 'document', 'ner_chunk', 'assertion', 'token', 'ner', 'embeddings', 'sentence'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Patient has a headache for the last 2 weeks, needs to get a head CT, and appears anxious when she walks fast. Alopecia noted. She denies pain.'\n",
    "\n",
    "light_model = nlp.LightPipeline(assertionFilter_model)\n",
    "light_result = light_model.fullAnnotate(text)\n",
    "\n",
    "light_result[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Present']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assertion_filterer.getWhiteList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>chunk</th>\n",
       "      <th>assertion</th>\n",
       "      <th>assertion_confidence</th>\n",
       "      <th>assertion_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e926d14d</td>\n",
       "      <td>a headache</td>\n",
       "      <td>Present</td>\n",
       "      <td>null</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0bf1e911</td>\n",
       "      <td>a head CT</td>\n",
       "      <td>Hypothetical</td>\n",
       "      <td>null</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d7134a98</td>\n",
       "      <td>anxious</td>\n",
       "      <td>Possible</td>\n",
       "      <td>null</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bb8100fe</td>\n",
       "      <td>Alopecia</td>\n",
       "      <td>Present</td>\n",
       "      <td>null</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cb5d4145</td>\n",
       "      <td>pain</td>\n",
       "      <td>Absent</td>\n",
       "      <td>null</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chunk_id       chunk     assertion assertion_confidence assertion_source\n",
       "0  e926d14d  a headache       Present                 null        assertion\n",
       "1  0bf1e911   a head CT  Hypothetical                 null        assertion\n",
       "2  d7134a98     anxious      Possible                 null        assertion\n",
       "3  bb8100fe    Alopecia       Present                 null        assertion\n",
       "4  cb5d4145        pain        Absent                 null        assertion"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_maps = {\n",
    "    'document_identifier': 'assertion_filterer_pipeline',\n",
    "    'document_text': 'document',\n",
    "    'entities': ['assertion_filtered'],\n",
    "    'assertions': ['assertion'],\n",
    "    'resolutions': [],\n",
    "    'relations': [],\n",
    "    'summaries': [],\n",
    "    'deidentifications': [],\n",
    "    'classifications': []\n",
    "}\n",
    "\n",
    "pipeline_parser = medical.PipelineOutputParser(column_maps)\n",
    "result = pipeline_parser.run(light_result ) #light_result is defined above\n",
    "\n",
    "assertions_df = pd.DataFrame(result['result'][0]['assertions'])\n",
    "assertions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>chunk</th>\n",
       "      <th>begin</th>\n",
       "      <th>end</th>\n",
       "      <th>ner_label</th>\n",
       "      <th>ner_source</th>\n",
       "      <th>ner_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e926d14d</td>\n",
       "      <td>a headache</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>PROBLEM</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.97150004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bb8100fe</td>\n",
       "      <td>Alopecia</td>\n",
       "      <td>110</td>\n",
       "      <td>117</td>\n",
       "      <td>PROBLEM</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.9949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chunk_id       chunk  begin  end ner_label ner_source ner_confidence\n",
       "0  e926d14d  a headache     12   21   PROBLEM  ner_chunk     0.97150004\n",
       "1  bb8100fe    Alopecia    110  117   PROBLEM  ner_chunk         0.9949"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities_df = pd.DataFrame(result['result'][0]['entities'])\n",
    "entities_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk</th>\n",
       "      <th>begin</th>\n",
       "      <th>end</th>\n",
       "      <th>ner_label</th>\n",
       "      <th>ner_source</th>\n",
       "      <th>ner_confidence</th>\n",
       "      <th>assertion</th>\n",
       "      <th>assertion_confidence</th>\n",
       "      <th>assertion_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a headache</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>PROBLEM</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.97150004</td>\n",
       "      <td>Present</td>\n",
       "      <td>null</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alopecia</td>\n",
       "      <td>110</td>\n",
       "      <td>117</td>\n",
       "      <td>PROBLEM</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.9949</td>\n",
       "      <td>Present</td>\n",
       "      <td>null</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        chunk  begin  end ner_label ner_source ner_confidence assertion  \\\n",
       "0  a headache     12   21   PROBLEM  ner_chunk     0.97150004   Present   \n",
       "1    Alopecia    110  117   PROBLEM  ner_chunk         0.9949   Present   \n",
       "\n",
       "  assertion_confidence assertion_source  \n",
       "0                 null        assertion  \n",
       "1                 null        assertion  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assertions_df = pd.DataFrame(result['result'][0]['assertions'])\n",
    "\n",
    "merged_df = pd.merge(entities_df, assertions_df,  on=['chunk_id', 'chunk']).drop(columns='chunk_id')\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see, there is no \"pain\" chunk since it has \"absent\" assertion label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oncological Assertion Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oncology Assertion Models\n",
    "\n",
    "|    | model_name              |Predicted Entities|\n",
    "|---:|:------------------------|-|\n",
    "| 1 | [assertion_oncology_wip](https://nlp.johnsnowlabs.com/2022/10/11/assertion_oncology_wip_en.html) | Medical_History, Family_History, Possible, Hypothetical_Or_Absent|\n",
    "| 2 | [assertion_oncology_problem_wip](https://nlp.johnsnowlabs.com/2022/10/11/assertion_oncology_problem_wip_en.html) |Present, Possible, Hypothetical, Absent, Family|\n",
    "| 3 | [assertion_oncology_treatment_wip](https://nlp.johnsnowlabs.com/2022/10/11/assertion_oncology_treatment_binary_wip_en.html) |Present, Planned, Past, Hypothetical, Absent|\n",
    "| 3 | [assertion_oncology_treatment_wip]() |Present, Planned, Past, Hypothetical, Absent|\n",
    "| 4 | [assertion_oncology_response_to_treatment_wip](https://nlp.johnsnowlabs.com/2022/10/11/assertion_oncology_response_to_treatment_wip_en.html) |Present_Or_Past, Hypothetical_Or_Absent|\n",
    "| 5 | [assertion_oncology_test_binary_wip](https://nlp.johnsnowlabs.com/2022/10/01/assertion_oncology_test_binary_wip_en.html) |Present_Or_Past, Hypothetical_Or_Absent|\n",
    "| 6 | [assertion_oncology_smoking_status_wip](https://nlp.johnsnowlabs.com/2022/10/11/assertion_oncology_smoking_status_wip_en.html) |Absent, Past, Present|\n",
    "| 7 | [assertion_oncology_family_history_wip](https://nlp.johnsnowlabs.com/2022/10/11/assertion_oncology_family_history_wip_en.html) |Family_History, Other|\n",
    "| 8 | [assertion_oncology_demographic_binary_wip](https://nlp.johnsnowlabs.com/2022/10/11/assertion_oncology_demographic_binary_wip_en.html) |Patient, Someone_Else|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_oncology_wip download started this may take some time.\n",
      "[ | ]ner_oncology_wip download started this may take some time.\n",
      "Approximate size to download 969.3 KB\n",
      "Download done! Loading the resource.\n",
      "[OK!]\n",
      "assertion_oncology_wip download started this may take some time.\n",
      "[ | ]assertion_oncology_wip download started this may take some time.\n",
      "Approximate size to download 1.4 MB\n",
      "Download done! Loading the resource.\n",
      "[OK!]\n",
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[OK!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 74:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+--------------------+------------+----------+\n",
      "|chunk                   |ner_label           |assertion   |confidence|\n",
      "+------------------------+--------------------+------------+----------+\n",
      "|Mesothelioma            |Cancer_Dx           |Present     |0.9885    |\n",
      "|Mesothelioma            |Cancer_Dx           |Hypothetical|0.981     |\n",
      "|August 24, 2007         |Date                |Past        |0.9726    |\n",
      "|decortication           |Cancer_Surgery      |Past        |0.994     |\n",
      "|lung                    |Site_Lung           |Past        |0.9453    |\n",
      "|pleural                 |Site_Other_Body_Part|Past        |0.9624    |\n",
      "|biopsy                  |Pathology_Test      |Past        |0.9979    |\n",
      "|transpleural fluoroscopy|Imaging_Test        |Past        |0.9979    |\n",
      "|August 20, 2007         |Date                |Past        |0.956     |\n",
      "|August 31, 2007         |Date                |Past        |0.9925    |\n",
      "|41-year-old             |Gender              |Present     |0.9986    |\n",
      "|Vietnamese              |Race_Ethnicity      |Present     |0.8024    |\n",
      "|female                  |Gender              |Present     |0.9772    |\n",
      "|started last week       |Relative_Date       |Present     |0.9831    |\n",
      "|She                     |Gender              |Present     |0.9992    |\n",
      "|her                     |Gender              |Present     |0.9944    |\n",
      "|She                     |Gender              |Present     |0.9993    |\n",
      "|pericardectomy          |Cancer_Surgery      |Past        |0.997     |\n",
      "|May 2006                |Date                |Past        |0.9971    |\n",
      "|Chest x-ray             |Imaging_Test        |Past        |0.9984    |\n",
      "+------------------------+--------------------+------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "embeddings = 'embeddings_clinical'\n",
    "\n",
    "ner_model_name = 'ner_oncology_wip'\n",
    "\n",
    "assertion_model_name='assertion_oncology_wip'\n",
    "\n",
    "nrows = 100\n",
    "\n",
    "ner_df = get_clinical_assertion (embeddings, mt_samples_df, nrows, ner_model_name,assertion_model_name )\n",
    "\n",
    "ner_df.show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voice of Patient Assertion Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\r\n",
    "\r\n",
    "|    | model_name              |Predicted Entities|\r\n",
    "|---:|:------------------------|-|\r\n",
    "| 1        | [assertion_vop_clinical](https://nlp.johnsnowlabs.com/2023/08/17/assertion_vop_clinical_en.html)     | Hypothetical_Or_Absent, Present_Or_Past, SomeoneElse |\r\n",
    "| 2          | [assertion_vop_clinical_medium](https://nlp.johnsnowlabs.com/2023/08/17/assertion_vop_clinical_medium_en.html)       | Hypothetical_Or_Absent, Present_Or_Past, SomeoneElse |\r\n",
    "| 3          | [assertion_vop_clinical_large](https://nlp.johnsnowlabs.com/2023/08/17/assertion_vop_clinical_large_en.html)       | Hypothetical_Or_Absent, Present_Or_Past, SomeoneElse |\r\n",
    "|||\r\n",
    "\r\n",
    "\r\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Assertion status model](https://nlp.johnsnowlabs.com/2023/08/17/assertion_vop_clinical_en.html) used to predict if an NER chunk refers to a positive finding from the patient (Present_Or_Past), or if it refers to a family member or another person (SomeoneElse) or if it is mentioned but not as something present (Hypothetical_Or_Absent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence_detector_dl_healthcare download started this may take some time.\n",
      "Approximate size to download 367.3 KB\n",
      "[OK!]\n",
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[OK!]\n",
      "ner_vop download started this may take some time.\n",
      "[ | ]ner_vop download started this may take some time.\n",
      "Approximate size to download 3.7 MB\n",
      "Download done! Loading the resource.\n",
      "[OK!]\n",
      "assertion_vop_clinical download started this may take some time.\n",
      "[ | ]assertion_vop_clinical download started this may take some time.\n",
      "Approximate size to download 919.9 KB\n",
      "Download done! Loading the resource.\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "document_assembler = nlp.DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "sentence_detector = nlp.SentenceDetectorDLModel.pretrained(\"sentence_detector_dl_healthcare\", \"en\", \"clinical/models\")\\\n",
    "    .setInputCols([\"document\"])\\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "tokenizer = nlp.Tokenizer() \\\n",
    "    .setInputCols([\"sentence\"]) \\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "word_embeddings = nlp.WordEmbeddingsModel().pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n",
    "    .setInputCols([\"sentence\", \"token\"]) \\\n",
    "    .setOutputCol(\"embeddings\")\n",
    "\n",
    "ner = medical.NerModel.pretrained(\"ner_vop\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"ner\")\n",
    "\n",
    "ner_converter = medical.NerConverterInternal() \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"ner\"]) \\\n",
    "    .setOutputCol(\"ner_chunk\")\\\n",
    "    .setBlackList(['DATETIME',  'GENDER', 'AGE', 'SUBSTANCEQUANTITY','FORM', 'ADMISSIONDISCHARGE', 'TESTRESULT', 'TEST',\n",
    "                  'MEDICALDEVICE','CLINICALDEPT','DRUG', 'ROUTE', 'DURATION',\"DOSAGE\",'FREQUENCY', 'BODYPART',\n",
    "                   ])\n",
    "\n",
    "assertion = medical.AssertionDLModel.pretrained(\"assertion_vop_clinical\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\", \"ner_chunk\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"assertion\")\n",
    "\n",
    "pipeline = nlp.Pipeline(\n",
    "    stages=[document_assembler,\n",
    "    sentence_detector,\n",
    "    tokenizer,\n",
    "    word_embeddings,\n",
    "    ner,\n",
    "    ner_converter,\n",
    "    assertion\n",
    "])\n",
    "\n",
    "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "vop_pipeline_model = pipeline.fit(empty_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hypothetical_Or_Absent', 'Present_Or_Past', 'SomeoneElse']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assertion.getClasses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = '''Hello, I am a 20-year-old woman who was diagnosed with hyperthyroidism around a month ago. For approximately four months, I've been experiencing symptoms such as feeling light-headed, battling poor digestion, dealing with anxiety attacks, depression, a sharp pain on my left side chest, an elevated heart rate, and a significant loss of weight. Due to these conditions, I was admitted to the hospital and just got discharged recently. During my hospital stay, a number of different tests were carried out by various physicians who initially struggled to pinpoint my actual medical condition. These tests included numerous blood tests, a brain MRI, an ultrasound scan, and an endoscopy. At long last, I was examined by a homeopathic doctor who finally diagnosed me with hyperthyroidism, indicating my TSH level was at a low 0.15 while my T3 and T4 levels were normal. Additionally, I was found to be deficient in vitamins B12 and D. Hence, I've been on a regimen of vitamin D supplements once a week and a daily dose of 1000 mcg of vitamin B12. I've been undergoing homeopathic treatment for the last 40 days and underwent a second test after a month which showed my TSH level increased to 0.5. While I'm noticing a slight improvement in my feelings of weakness and depression, over the last week, I've encountered two new challenges: difficulty breathing and a dramatically increased heart rate. I'm now at a crossroads where I am unsure if I should switch to allopathic treatment or continue with homeopathy. I understand that thyroid conditions take a while to improve, but I'm wondering if both treatments would require the same duration for recovery. Several of my acquaintances have recommended transitioning to allopathy and warn against taking risks, given the potential of developing severe complications. Please forgive any errors in my English and thank you for your understanding.'''\n",
    "\n",
    "light_model = nlp.LightPipeline(vop_pipeline_model)\n",
    "\n",
    "light_result = light_model.fullAnnotate(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    @import url('https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700&display=swap');\n",
       "    @import url('https://fonts.googleapis.com/css2?family=Vistol Regular:wght@300;400;500;600;700&display=swap');\n",
       "    \n",
       "    .spark-nlp-display-scroll-entities {\n",
       "        border: 1px solid #E7EDF0;\n",
       "        border-radius: 3px;\n",
       "        text-align: justify;\n",
       "        \n",
       "    }\n",
       "    .spark-nlp-display-scroll-entities span {  \n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        color: #536B76;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "    }\n",
       "    \n",
       "    .spark-nlp-display-entity-wrapper{\n",
       "    \n",
       "        display: inline-grid;\n",
       "        text-align: center;\n",
       "        border-radius: 4px;\n",
       "        margin: 0 2px 5px 2px;\n",
       "        padding: 1px\n",
       "    }\n",
       "    .spark-nlp-display-entity-name{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "        \n",
       "        background: #f1f2f3;\n",
       "        border-width: medium;\n",
       "        text-align: center;\n",
       "        \n",
       "        font-weight: 400;\n",
       "        \n",
       "        border-radius: 5px;\n",
       "        padding: 2px 5px;\n",
       "        display: block;\n",
       "        margin: 3px 2px;\n",
       "    \n",
       "    }\n",
       "    .spark-nlp-display-entity-type{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        color: #ffffff;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "        \n",
       "        text-transform: uppercase;\n",
       "        \n",
       "        font-weight: 500;\n",
       "\n",
       "        display: block;\n",
       "        padding: 3px 5px;\n",
       "    }\n",
       "    \n",
       "    .spark-nlp-display-entity-resolution{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        color: #ffffff;\n",
       "        font-family: 'Vistol Regular', sans-serif !important;\n",
       "        \n",
       "        text-transform: uppercase;\n",
       "        \n",
       "        font-weight: 500;\n",
       "\n",
       "        display: block;\n",
       "        padding: 3px 5px;\n",
       "    }\n",
       "    \n",
       "    .spark-nlp-display-others{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "        \n",
       "        font-weight: 400;\n",
       "    }\n",
       "\n",
       "</style>\n",
       " <span class=\"spark-nlp-display-others\" style=\"background-color: white\">Hello, I am a 20-year-old woman who was diagnosed with </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #A5AD20B3\"><span class=\"spark-nlp-display-entity-name\">hyperthyroidism </span><span class=\"spark-nlp-display-entity-type\">Disease</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #A5AD20FF\">Present_Or_Past </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> around a month ago. For approximately four months, I've been experiencing symptoms such as feeling </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #445F5BB3\"><span class=\"spark-nlp-display-entity-name\">light-headed </span><span class=\"spark-nlp-display-entity-type\">Symptom</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #445F5BFF\">Present_Or_Past </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, battling poor digestion, dealing with </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #3CA356B3\"><span class=\"spark-nlp-display-entity-name\">anxiety attacks </span><span class=\"spark-nlp-display-entity-type\">PsychologicalCondition</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #3CA356FF\">Present_Or_Past </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #3CA356B3\"><span class=\"spark-nlp-display-entity-name\">depression </span><span class=\"spark-nlp-display-entity-type\">PsychologicalCondition</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #3CA356FF\">Present_Or_Past </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, a </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #8B475DB3\"><span class=\"spark-nlp-display-entity-name\">sharp </span><span class=\"spark-nlp-display-entity-type\">Modifier</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #8B475DFF\">Present_Or_Past </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #445F5BB3\"><span class=\"spark-nlp-display-entity-name\">pain </span><span class=\"spark-nlp-display-entity-type\">Symptom</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #445F5BFF\">Present_Or_Past </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> on my </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #7A889CB3\"><span class=\"spark-nlp-display-entity-name\">left side </span><span class=\"spark-nlp-display-entity-type\">Laterality</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #7A889CFF\">Present_Or_Past </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> chest, an elevated </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #B1202BB3\"><span class=\"spark-nlp-display-entity-name\">heart rate </span><span class=\"spark-nlp-display-entity-type\">VitalTest</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #B1202BFF\">Present_Or_Past </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, and a </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #8B475DB3\"><span class=\"spark-nlp-display-entity-name\">significant </span><span class=\"spark-nlp-display-entity-type\">Modifier</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #8B475DFF\">Present_Or_Past </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #445F5BB3\"><span class=\"spark-nlp-display-entity-name\">loss of weight </span><span class=\"spark-nlp-display-entity-type\">Symptom</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #445F5BFF\">Hypothetical_Or_Absent </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">. Due to these conditions, I was admitted to the hospital and just got discharged recently. During my hospital stay, a number of different tests were carried out by various </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #7F3C9AB3\"><span class=\"spark-nlp-display-entity-name\">physicians </span><span class=\"spark-nlp-display-entity-type\">Employment</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #7F3C9AFF\">SomeoneElse </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> who initially struggled to pinpoint my actual medical condition. These tests included numerous blood tests, a brain MRI, an ultrasound scan, and an </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #7A3A81B3\"><span class=\"spark-nlp-display-entity-name\">endoscopy </span><span class=\"spark-nlp-display-entity-type\">Procedure</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #7A3A81FF\">Present_Or_Past </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">. At long last, I was examined by a </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #7F3C9AB3\"><span class=\"spark-nlp-display-entity-name\">homeopathic doctor </span><span class=\"spark-nlp-display-entity-type\">Employment</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #7F3C9AFF\">SomeoneElse </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> who finally diagnosed me with </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #A5AD20B3\"><span class=\"spark-nlp-display-entity-name\">hyperthyroidism </span><span class=\"spark-nlp-display-entity-type\">Disease</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #A5AD20FF\">Present_Or_Past </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, indicating my TSH level was at a low 0.15 while my T3 and T4 levels were normal. Additionally, I was found to be </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #A5AD20B3\"><span class=\"spark-nlp-display-entity-name\">deficient </span><span class=\"spark-nlp-display-entity-type\">Disease</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #A5AD20FF\">Hypothetical_Or_Absent </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> in vitamins B12 and D. Hence, I've been on a regimen of vitamin D supplements once a week and a daily dose of 1000 mcg of vitamin B12. I've been undergoing </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #8b6673B3\"><span class=\"spark-nlp-display-entity-name\">homeopathic treatment </span><span class=\"spark-nlp-display-entity-type\">Treatment</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #8b6673FF\">Present_Or_Past </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> for the last 40 days and underwent a second test after a month which showed my TSH level increased to 0.5. While I'm noticing a slight improvement in my feelings of </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #445F5BB3\"><span class=\"spark-nlp-display-entity-name\">weakness </span><span class=\"spark-nlp-display-entity-type\">Symptom</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #445F5BFF\">Present_Or_Past </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> and </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #3CA356B3\"><span class=\"spark-nlp-display-entity-name\">depression </span><span class=\"spark-nlp-display-entity-type\">PsychologicalCondition</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #3CA356FF\">Present_Or_Past </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, over the last week, I've encountered two new challenges: </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #445F5BB3\"><span class=\"spark-nlp-display-entity-name\">difficulty breathing </span><span class=\"spark-nlp-display-entity-type\">Symptom</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #445F5BFF\">Present_Or_Past </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> and a dramatically increased </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #B1202BB3\"><span class=\"spark-nlp-display-entity-name\">heart rate </span><span class=\"spark-nlp-display-entity-type\">VitalTest</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #B1202BFF\">Present_Or_Past </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">. I'm now at a crossroads where I am unsure if I should switch to </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #8b6673B3\"><span class=\"spark-nlp-display-entity-name\">allopathic treatment </span><span class=\"spark-nlp-display-entity-type\">Treatment</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #8b6673FF\">Hypothetical_Or_Absent </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> or continue with </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #8b6673B3\"><span class=\"spark-nlp-display-entity-name\">homeopathy </span><span class=\"spark-nlp-display-entity-type\">Treatment</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #8b6673FF\">Hypothetical_Or_Absent </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">. I understand that thyroid conditions take a while to improve, but I'm wondering if both treatments would require the same duration for recovery. Several of my acquaintances have recommended transitioning to allopathy and warn against taking risks, given the potential of developing severe complications. Please forgive any errors in my English and thank you for your understanding.</span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vis = nlp.viz.AssertionVisualizer()\n",
    "\n",
    "vis.display(light_result[0], 'ner_chunk', 'assertion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social Determinant of Health Assertion Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\r\n",
    "\r\n",
    "|    | model_name              |Predicted Entities|\r\n",
    "|---------------|----------------------|---|\r\n",
    "| 1        | [assertion_sdoh_wip](https://nlp.johnsnowlabs.com/2023/08/13/assertion_sdoh_wip_en.html)     | `Present`, `Absent`, `Someone_Else`, `Past`, `Hypothetical`, `Possible` |\r\n",
    "\r\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence_detector_dl download started this may take some time.\n",
      "Approximate size to download 354.6 KB\n",
      "[ | ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/02 17:29:21 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK!]\n",
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[ | ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/02 17:29:23 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK!]\n",
      "ner_sdoh download started this may take some time.\n",
      "[OK!]\n",
      "assertion_sdoh_wip download started this may take some time.\n",
      "\n",
      "OK!]"
     ]
    }
   ],
   "source": [
    "document_assembler = nlp.DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "sentence_detector = nlp.SentenceDetectorDLModel.pretrained(\"sentence_detector_dl\", \"en\")\\\n",
    "    .setInputCols([\"document\"])\\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "tokenizer = nlp.Tokenizer()\\\n",
    "    .setInputCols([\"sentence\"])\\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "clinical_embeddings = nlp.WordEmbeddingsModel.pretrained('embeddings_clinical', \"en\", \"clinical/models\")\\\n",
    "    .setInputCols([\"sentence\", \"token\"])\\\n",
    "    .setOutputCol(\"embeddings\")\n",
    "\n",
    "ner_model = medical.NerModel.pretrained(\"ner_sdoh\", \"en\", \"clinical/models\")\\\n",
    "    .setInputCols([\"sentence\", \"token\",\"embeddings\"])\\\n",
    "    .setOutputCol(\"ner\")\n",
    "\n",
    "ner_converter = medical.NerConverterInternal()\\\n",
    "    .setInputCols(['sentence', 'token', 'ner'])\\\n",
    "    .setOutputCol('ner_chunk')\\\n",
    "    .setBlackList(['Age','Gender','Language','Healthcare_Institution'])   # I dont need these assertion of entities\n",
    "\n",
    "assertion = medical.AssertionDLModel.pretrained(\"assertion_sdoh_wip\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\", \"ner_chunk\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"assertion\")\n",
    "\n",
    "pipeline = nlp.Pipeline(\n",
    "    stages=[\n",
    "        document_assembler,\n",
    "        sentence_detector,\n",
    "        tokenizer,\n",
    "        clinical_embeddings,\n",
    "        ner_model,\n",
    "        ner_converter,\n",
    "        assertion\n",
    "])\n",
    "\n",
    "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "model = pipeline.fit(empty_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Absent', 'Present', 'Someone_Else', 'Past', 'Hypothetical', 'Possible']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assertion.getClasses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['document', 'ner_chunk', 'assertion', 'token', 'ner', 'embeddings', 'sentence'])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text= [\n",
    "\"\"\"Smith works as a cleaning assistant and does not have access to health insurance or paid sick leave.\n",
    "But she has generally housing problems. She lives in a apartment now.  She has long history of EtOH abuse, beginning in her teens.\n",
    "She is aware she needs to attend Rehab Programs. She had DUI back in April and was due to be in court this week.\n",
    "Her partner is an alcoholic and a drug abuser for the last 5 years.\n",
    "She also mentioned feeling socially isolated and lack of a strong support system.\n",
    "\"\"\"\n",
    "]\n",
    "\n",
    "light_model = nlp.LightPipeline(model)\n",
    "light_result = light_model.fullAnnotate(sample_text)\n",
    "\n",
    "light_result[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_tracer = PipelineTracer(model)\n",
    "\n",
    "column_maps = pipeline_tracer.createParserDictionary()\n",
    "column_maps.update({\"document_identifier\": \"assertion_sdoh\"})\n",
    "\n",
    "pipeline_parser = medical.PipelineOutputParser(column_maps)\n",
    "result = pipeline_parser.run(light_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk</th>\n",
       "      <th>begin</th>\n",
       "      <th>end</th>\n",
       "      <th>ner_label</th>\n",
       "      <th>ner_source</th>\n",
       "      <th>ner_confidence</th>\n",
       "      <th>assertion</th>\n",
       "      <th>assertion_confidence</th>\n",
       "      <th>assertion_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cleaning assistant</td>\n",
       "      <td>17</td>\n",
       "      <td>34</td>\n",
       "      <td>Employment</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.76975</td>\n",
       "      <td>Present</td>\n",
       "      <td>0.7926</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>health insurance</td>\n",
       "      <td>64</td>\n",
       "      <td>79</td>\n",
       "      <td>Insurance_Status</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.6325</td>\n",
       "      <td>Absent</td>\n",
       "      <td>0.5072</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apartment</td>\n",
       "      <td>156</td>\n",
       "      <td>164</td>\n",
       "      <td>Housing</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.9575</td>\n",
       "      <td>Present</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EtOH abuse</td>\n",
       "      <td>196</td>\n",
       "      <td>205</td>\n",
       "      <td>Alcohol</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.8286</td>\n",
       "      <td>Past</td>\n",
       "      <td>0.6054</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rehab Programs</td>\n",
       "      <td>265</td>\n",
       "      <td>278</td>\n",
       "      <td>Access_To_Care</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.6292</td>\n",
       "      <td>Hypothetical</td>\n",
       "      <td>0.5861</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DUI</td>\n",
       "      <td>289</td>\n",
       "      <td>291</td>\n",
       "      <td>Legal_Issues</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.9603</td>\n",
       "      <td>Past</td>\n",
       "      <td>0.5037</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>alcoholic</td>\n",
       "      <td>363</td>\n",
       "      <td>371</td>\n",
       "      <td>Alcohol</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.997</td>\n",
       "      <td>Someone_Else</td>\n",
       "      <td>0.9868</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>drug abuser</td>\n",
       "      <td>379</td>\n",
       "      <td>389</td>\n",
       "      <td>Substance_Use</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.89475</td>\n",
       "      <td>Someone_Else</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>last 5 years</td>\n",
       "      <td>399</td>\n",
       "      <td>410</td>\n",
       "      <td>Substance_Duration</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.5945</td>\n",
       "      <td>Someone_Else</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>socially isolated</td>\n",
       "      <td>440</td>\n",
       "      <td>456</td>\n",
       "      <td>Social_Exclusion</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.64390004</td>\n",
       "      <td>Present</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>strong support</td>\n",
       "      <td>472</td>\n",
       "      <td>485</td>\n",
       "      <td>Social_Support</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.3522</td>\n",
       "      <td>Absent</td>\n",
       "      <td>0.9597</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 chunk  begin  end           ner_label ner_source  \\\n",
       "0   cleaning assistant     17   34          Employment  ner_chunk   \n",
       "1     health insurance     64   79    Insurance_Status  ner_chunk   \n",
       "2            apartment    156  164             Housing  ner_chunk   \n",
       "3           EtOH abuse    196  205             Alcohol  ner_chunk   \n",
       "4       Rehab Programs    265  278      Access_To_Care  ner_chunk   \n",
       "5                  DUI    289  291        Legal_Issues  ner_chunk   \n",
       "6            alcoholic    363  371             Alcohol  ner_chunk   \n",
       "7          drug abuser    379  389       Substance_Use  ner_chunk   \n",
       "8         last 5 years    399  410  Substance_Duration  ner_chunk   \n",
       "9    socially isolated    440  456    Social_Exclusion  ner_chunk   \n",
       "10      strong support    472  485      Social_Support  ner_chunk   \n",
       "\n",
       "   ner_confidence     assertion assertion_confidence assertion_source  \n",
       "0         0.76975       Present               0.7926        assertion  \n",
       "1          0.6325        Absent               0.5072        assertion  \n",
       "2          0.9575       Present               0.9956        assertion  \n",
       "3          0.8286          Past               0.6054        assertion  \n",
       "4          0.6292  Hypothetical               0.5861        assertion  \n",
       "5          0.9603          Past               0.5037        assertion  \n",
       "6           0.997  Someone_Else               0.9868        assertion  \n",
       "7         0.89475  Someone_Else               0.9996        assertion  \n",
       "8          0.5945  Someone_Else               0.9951        assertion  \n",
       "9      0.64390004       Present               0.9673        assertion  \n",
       "10         0.3522        Absent               0.9597        assertion  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assertions_df = pd.DataFrame(result['result'][0]['assertions'])\n",
    "entities_df = pd.DataFrame(result['result'][0]['entities'])\n",
    "\n",
    "merged_df = pd.merge(entities_df, assertions_df,  on=['chunk_id', 'chunk']).drop(columns='chunk_id')\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    @import url('https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700&display=swap');\n",
       "    @import url('https://fonts.googleapis.com/css2?family=Vistol Regular:wght@300;400;500;600;700&display=swap');\n",
       "    \n",
       "    .spark-nlp-display-scroll-entities {\n",
       "        border: 1px solid #E7EDF0;\n",
       "        border-radius: 3px;\n",
       "        text-align: justify;\n",
       "        \n",
       "    }\n",
       "    .spark-nlp-display-scroll-entities span {  \n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        color: #536B76;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "    }\n",
       "    \n",
       "    .spark-nlp-display-entity-wrapper{\n",
       "    \n",
       "        display: inline-grid;\n",
       "        text-align: center;\n",
       "        border-radius: 4px;\n",
       "        margin: 0 2px 5px 2px;\n",
       "        padding: 1px\n",
       "    }\n",
       "    .spark-nlp-display-entity-name{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "        \n",
       "        background: #f1f2f3;\n",
       "        border-width: medium;\n",
       "        text-align: center;\n",
       "        \n",
       "        font-weight: 400;\n",
       "        \n",
       "        border-radius: 5px;\n",
       "        padding: 2px 5px;\n",
       "        display: block;\n",
       "        margin: 3px 2px;\n",
       "    \n",
       "    }\n",
       "    .spark-nlp-display-entity-type{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        color: #ffffff;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "        \n",
       "        text-transform: uppercase;\n",
       "        \n",
       "        font-weight: 500;\n",
       "\n",
       "        display: block;\n",
       "        padding: 3px 5px;\n",
       "    }\n",
       "    \n",
       "    .spark-nlp-display-entity-resolution{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        color: #ffffff;\n",
       "        font-family: 'Vistol Regular', sans-serif !important;\n",
       "        \n",
       "        text-transform: uppercase;\n",
       "        \n",
       "        font-weight: 500;\n",
       "\n",
       "        display: block;\n",
       "        padding: 3px 5px;\n",
       "    }\n",
       "    \n",
       "    .spark-nlp-display-others{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "        \n",
       "        font-weight: 400;\n",
       "    }\n",
       "\n",
       "</style>\n",
       " <span class=\"spark-nlp-display-others\" style=\"background-color: white\">Smith works as a </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #BE532BB3\"><span class=\"spark-nlp-display-entity-name\">cleaning assistant </span><span class=\"spark-nlp-display-entity-type\">Employment</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #BE532BFF\">Present </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> and does not have access to </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #8B0605B3\"><span class=\"spark-nlp-display-entity-name\">health insurance </span><span class=\"spark-nlp-display-entity-type\">Insurance_Status</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #8B0605FF\">Absent </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> or paid sick leave.<br>But she has generally housing problems. She lives in a </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #38790CB3\"><span class=\"spark-nlp-display-entity-name\">apartment </span><span class=\"spark-nlp-display-entity-type\">Housing</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #38790CFF\">Present </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> now.  She has long history of </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #0D1A8BB3\"><span class=\"spark-nlp-display-entity-name\">EtOH abuse </span><span class=\"spark-nlp-display-entity-type\">Alcohol</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #0D1A8BFF\">Past </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, beginning in her teens.<br>She is aware she needs to attend </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #6B8E9CB3\"><span class=\"spark-nlp-display-entity-name\">Rehab Programs </span><span class=\"spark-nlp-display-entity-type\">Access_To_Care</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #6B8E9CFF\">Hypothetical </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">. She had </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #7051C4B3\"><span class=\"spark-nlp-display-entity-name\">DUI </span><span class=\"spark-nlp-display-entity-type\">Legal_Issues</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #7051C4FF\">Past </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> back in April and was due to be in court this week.<br>Her partner is an </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #0D1A8BB3\"><span class=\"spark-nlp-display-entity-name\">alcoholic </span><span class=\"spark-nlp-display-entity-type\">Alcohol</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #0D1A8BFF\">Someone_Else </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> and a </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #BA0C8AB3\"><span class=\"spark-nlp-display-entity-name\">drug abuser </span><span class=\"spark-nlp-display-entity-type\">Substance_Use</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #BA0C8AFF\">Someone_Else </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> for the </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #B30851B3\"><span class=\"spark-nlp-display-entity-name\">last 5 years </span><span class=\"spark-nlp-display-entity-type\">Substance_Duration</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #B30851FF\">Someone_Else </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">.<br>She also mentioned feeling </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #67AB9EB3\"><span class=\"spark-nlp-display-entity-name\">socially isolated </span><span class=\"spark-nlp-display-entity-type\">Social_Exclusion</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #67AB9EFF\">Present </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> and lack of a </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #193366B3\"><span class=\"spark-nlp-display-entity-name\">strong support </span><span class=\"spark-nlp-display-entity-type\">Social_Support</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #193366FF\">Absent </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> system.<br></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sparknlp_display import AssertionVisualizer\n",
    "\n",
    "vis = AssertionVisualizer()\n",
    "\n",
    "vis.display(light_result[0], 'ner_chunk', 'assertion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AssertionChunkConverter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases, there may be issues while creating the chunk column by using token indices and losing some data while training and testing the assertion status model if there are issues in these token indices. So we developed a new `AssertionChunkConverter` annotator that takes **begin and end indices of the chunks** as input and creates an extended chunk column with metadata that can be used for assertion status detection model training.\n",
    "\n",
    "*NOTE*: Chunk begin and end indices in the assertion status model training dataframe can be populated using the new version of ALAB module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+----------+--------+\n",
      "|                text|target|char_begin|char_end|\n",
      "+--------------------+------+----------+--------+\n",
      "|An angiography sh...|Minnie|        57|      63|\n",
      "|After discussing ...|   PCP|        31|      34|\n",
      "+--------------------+------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark.createDataFrame([[\"An angiography showed bleeding in two vessels off of the Minnie supplying the sigmoid that were succesfully embolized.\", \"Minnie\", 57, 63],\n",
    "     [\"After discussing this with his PCP, Leon was clear that the patient had had recurrent DVTs and ultimately a PE and his PCP felt strongly that he required long-term anticoagulation \", \"PCP\", 31, 34]])\\\n",
    "     .toDF(\"text\", \"target\", \"char_begin\", \"char_end\")\n",
    "\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_assembler = nlp.DocumentAssembler() \\\n",
    "    .setInputCol(\"text\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "sentenceDetector = nlp.SentenceDetector()\\\n",
    "    .setInputCols([\"document\"])\\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "tokenizer = nlp.Tokenizer() \\\n",
    "    .setInputCols([\"sentence\"]) \\\n",
    "    .setOutputCol(\"tokens\")\n",
    "\n",
    "converter = medical.AssertionChunkConverter() \\\n",
    "    .setInputCols(\"tokens\")\\\n",
    "    .setChunkTextCol(\"target\")\\\n",
    "    .setChunkBeginCol(\"char_begin\")\\\n",
    "    .setChunkEndCol(\"char_end\")\\\n",
    "    .setOutputTokenBeginCol(\"token_begin\")\\\n",
    "    .setOutputTokenEndCol(\"token_end\")\\\n",
    "    .setOutputCol(\"chunk\")\n",
    "\n",
    "pipeline = nlp.Pipeline().setStages([document_assembler,sentenceDetector, tokenizer, converter])\n",
    "\n",
    "results = pipeline.fit(data).transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+--------+-----------+---------+--------------------------+------------------------+------+----------------------------------------------+\n",
      "|target|char_begin|char_end|token_begin|token_end|tokens[token_begin].result|tokens[token_end].result|target|chunk                                         |\n",
      "+------+----------+--------+-----------+---------+--------------------------+------------------------+------+----------------------------------------------+\n",
      "|Minnie|57        |63      |10         |10       |Minnie                    |Minnie                  |Minnie|[{chunk, 57, 62, Minnie, {sentence -> 0}, []}]|\n",
      "|PCP   |31        |34      |5          |6        |PCP                       |,                       |PCP   |[{chunk, 31, 34, PCP, {sentence -> 0}, []}]   |\n",
      "+------+----------+--------+-----------+---------+--------------------------+------------------------+------+----------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results\\\n",
    "    .selectExpr(\n",
    "        \"target\",\n",
    "        \"char_begin\",\n",
    "        \"char_end\",\n",
    "        \"token_begin\",\n",
    "        \"token_end\",\n",
    "        \"tokens[token_begin].result\",\n",
    "        \"tokens[token_end].result\",\n",
    "        \"target\",\n",
    "        \"chunk\")\\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AssertionMerger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AssertionMerger merges variety assertion columns coming from Assertion annotators such as AssertionDL and AssertionLogReg.\n",
    "AssertionMerger can filter, prioritize, and merge assertion annotations by using proper parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameters:**\n",
    "\n",
    "- `mergeOverlapping`: Whether to merge overlapping matched assertion annotations. Default: `True`\n",
    "- `applyFilterBeforeMerge`: Whether to apply filtering before merging process. If `True`, filtering will be applied before merging; if `False`, filtering will be applied after merging process. Default: `False`.\n",
    "- `blackList`: If defined, list of entities to ignore. The rest will be processed.\n",
    "- `whiteList`: If defined, list of entities to process. The rest will be ignored. Do not include IOB prefix on labels.\n",
    "- `caseSensitive`: Determines whether the definitions of the white listed and black listed entities are case sensitive. Default: `True`.\n",
    "- `assertionsConfidence`: Pairs (assertion,confidenceThreshold) to filter assertions which have confidence lower than the confidence threshold.\n",
    "- `orderingFeatures`: Specifies the ordering features to use for overlapping entities. Possible values include: 'begin', 'end', 'length', 'source', 'confidence'. Default: `['begin', 'length', 'source']`\n",
    "- `electionStrategy`: Determines the strategy for selecting annotations. Annotations can be selected either sequentially based on their order (Sequential) or using a more diverse strategy (DiverseLonger). Currently, only Sequential and DiverseLonger options are available. Default: `Sequential`.\n",
    "- `defaultConfidence` :  When the confidence value is included in the orderingFeatures and a given annotation does not have any confidence, this parameter determines the value to be used. The default value is `0`.\n",
    "- `assertionSourcePrecedence`: Specifies the assertion sources to use for prioritizing overlapping annotations when the 'source' ordering feature is utilized. This parameter contains a comma-separated list of assertion sources that drive the prioritization. Annotations will be prioritized based on the order of the given string.\n",
    "- `sortByBegin`: Whether to sort the annotations by begin at the end of the merge and filter process. Default: `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[ | ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/31 09:56:08 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK!]\n",
      "ner_jsl download started this may take some time.\n",
      "[OK!]\n",
      "assertion_jsl_augmented download started this may take some time.\n",
      "[OK!]\n",
      "ner_clinical download started this may take some time.\n",
      "ner_clinical download started this may take some time.\n",
      "Approximate size to download 13.9 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/31 09:56:16 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n",
      "24/12/31 09:56:16 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download done! Loading the resource.\n",
      "[OK!]\n",
      "assertion_dl download started this may take some time.\n",
      "assertion_dl download started this may take some time.\n",
      "Approximate size to download 1.3 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/31 09:56:19 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n",
      "24/12/31 09:56:19 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download done! Loading the resource.\n",
      "\n",
      "OK!]"
     ]
    }
   ],
   "source": [
    "document_assembler = nlp.DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "# Sentence Detector annotator, processes various sentences per line\n",
    "sentence_detector = nlp.SentenceDetector()\\\n",
    "    .setInputCols([\"document\"])\\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "# Tokenizer splits words in a relevant format for NLP\n",
    "tokenizer = nlp.Tokenizer()\\\n",
    "    .setInputCols([\"sentence\"])\\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "# Clinical word embeddings trained on PubMED dataset\n",
    "word_embeddings = nlp.WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n",
    "    .setInputCols([\"sentence\", \"token\"])\\\n",
    "    .setOutputCol(\"embeddings\")\n",
    "\n",
    "# NER model trained on i2b2 (sampled from MIMIC) dataset\n",
    "ner_jsl = medical.NerModel.pretrained(\"ner_jsl\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"ner_jsl\")\\\n",
    "    #.setIncludeAllConfidenceScores(False)\n",
    "\n",
    "ner_jsl_converter = medical.NerConverterInternal() \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"ner_jsl\"]) \\\n",
    "    .setOutputCol(\"ner_jsl_chunk\")\\\n",
    "    .setWhiteList([\"SYMPTOM\",\"VS_FINDING\",\"DISEASE_SYNDROME_DISORDER\",\"ADMISSION_DISCHARGE\",\"PROCEDURE\"])\n",
    "\n",
    "# Assertion model trained on i2b2 (sampled from MIMIC) dataset\n",
    "assertion_jsl = medical.AssertionDLModel.pretrained(\"assertion_jsl_augmented\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\", \"ner_jsl_chunk\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"assertion_jsl\")\\\n",
    "    .setEntityAssertionCaseSensitive(False)\n",
    "\n",
    "ner_clinical = medical.NerModel.pretrained(\"ner_clinical\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"ner_clinical\")\\\n",
    "    #.setIncludeAllConfidenceScores(False)\n",
    "\n",
    "ner_clinical_converter = medical.NerConverterInternal() \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"ner_clinical\"]) \\\n",
    "    .setOutputCol(\"ner_clinical_chunk\")\\\n",
    "\n",
    "# Assertion model trained on radiology dataset\n",
    "assertion_dl = medical.AssertionDLModel.pretrained(\"assertion_dl\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\", \"ner_clinical_chunk\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"assertion_dl\")\n",
    "\n",
    "from sparknlp_jsl.annotator import AssertionMerger\n",
    "assertion_merger = AssertionMerger() \\\n",
    "    .setInputCols(\"assertion_jsl\", \"assertion_dl\") \\\n",
    "    .setOutputCol(\"assertion_merger\") \\\n",
    "    .setMergeOverlapping(True) \\\n",
    "    .setSelectionStrategy(\"sequential\") \\\n",
    "    .setAssertionSourcePrecedence(\"assertion_dl, assertion_jsl\") \\\n",
    "    .setCaseSensitive(False) \\\n",
    "    .setAssertionsConfidence({\"past\": 0.70}) \\\n",
    "    .setOrderingFeatures([\"length\", \"source\", \"confidence\"]) \\\n",
    "    .setDefaultConfidence(0.50)\\\n",
    "    #.setBlackList([\"Hypothetical\"])\n",
    "\n",
    "pipeline = nlp.Pipeline(\n",
    "    stages=[\n",
    "        document_assembler,\n",
    "        sentence_detector,\n",
    "        tokenizer,\n",
    "        word_embeddings,\n",
    "        ner_jsl,\n",
    "        ner_jsl_converter,\n",
    "        assertion_jsl,\n",
    "        ner_clinical,\n",
    "        ner_clinical_converter,\n",
    "        assertion_dl,\n",
    "        assertion_merger\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.createDataFrame([\n",
    "    \"\"\"Patient had a headache for the last 2 weeks, and appears anxious when she walks fast. No alopecia noted. She denies pain. Her father is paralyzed and it is a stressor for her. She got antidepressant. We prescribed sleeping pills for her current insomnia.\"\"\"\n",
    "], StringType()).toDF(\"text\")\n",
    "\n",
    "\n",
    "data = data.coalesce(1).withColumn(\"idx\", F.monotonically_increasing_id())\n",
    "results = pipeline.fit(data).transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 33:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+-----+---+---------+---------+----------------+----------+\n",
      "|idx|ner_chunk     |begin|end|ner_label|assertion|assertion_source|confidence|\n",
      "+---+--------------+-----+---+---------+---------+----------------+----------+\n",
      "|0  |headache      |14   |21 |Symptom  |Past     |assertion_jsl   |0.9999    |\n",
      "|0  |anxious       |57   |63 |PROBLEM  |present  |assertion_dl    |0.9392    |\n",
      "|0  |alopecia      |89   |96 |PROBLEM  |absent   |assertion_dl    |0.9992    |\n",
      "|0  |pain          |116  |119|PROBLEM  |absent   |assertion_dl    |0.9884    |\n",
      "|0  |paralyzed     |136  |144|Symptom  |Family   |assertion_jsl   |0.9995    |\n",
      "|0  |stressor      |158  |165|Symptom  |Family   |assertion_jsl   |1.0       |\n",
      "|0  |antidepressant|184  |197|TREATMENT|present  |assertion_dl    |0.9628    |\n",
      "|0  |sleeping pills|214  |227|TREATMENT|present  |assertion_dl    |0.998     |\n",
      "|0  |insomnia      |245  |252|Symptom  |Past     |assertion_jsl   |0.9862    |\n",
      "+---+--------------+-----+---+---------+---------+----------------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "results.select(\"idx\",F.explode(F.arrays_zip(results.assertion_merger.metadata,\n",
    "                                            results.assertion_merger.begin,\n",
    "                                            results.assertion_merger.end,\n",
    "                                            results.assertion_merger.result)).alias(\"cols\")) \\\n",
    "        .select(\"idx\",F.expr(\"cols['0']['ner_chunk']\").alias(\"ner_chunk\"),\n",
    "                F.expr(\"cols['1']\").alias(\"begin\"),\n",
    "                F.expr(\"cols['2']\").alias(\"end\"),\n",
    "                F.expr(\"cols['0']['ner_label']\").alias(\"ner_label\"),\n",
    "                F.expr(\"cols['3']\").alias(\"assertion\"),\n",
    "                F.expr(\"cols['0']['assertion_source']\").alias(\"assertion_source\"),\n",
    "                F.expr(\"cols['0']['confidence']\").alias(\"confidence\"),\n",
    "                ).sort(\"idx\",\"begin\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JjfUo0aTKFEL"
   },
   "source": [
    "# **Train a custom Assertion Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "QPFTJxtlIKQT"
   },
   "outputs": [],
   "source": [
    "!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Healthcare/data/i2b2_assertion_sample_short.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "hRFW3nyALHx0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:35:29, INFO Error while sending or receiving.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/py4j/clientserver.py\", line 503, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "19:35:29, INFO Closing down clientserver connection\n",
      "19:35:29, INFO Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/py4j/clientserver.py\", line 503, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/py4j/clientserver.py\", line 506, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "19:35:29, INFO Closing down clientserver connection\n"
     ]
    }
   ],
   "source": [
    "assertion_df = spark.read.option(\"header\", True).option(\"inferSchema\", \"True\").csv(\"i2b2_assertion_sample_short.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TQn7bJZtL9uX",
    "outputId": "4458414c-4bbb-4965-8a19-594c1b7f2358"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------+-------------------+-------+-----+---+\n",
      "|                                             text|             target|  label|start|end|\n",
      "+-------------------------------------------------+-------------------+-------+-----+---+\n",
      "|She has no history of liver disease , hepatitis .|      liver disease| absent|    5|  6|\n",
      "|                         1. Undesired fertility .|undesired fertility|present|    1|  2|\n",
      "|                            3) STATUS POST FALL .|               fall|present|    3|  3|\n",
      "+-------------------------------------------------+-------------------+-------+-----+---+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assertion_df.show(3, truncate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B6IuDZ9Qw7Cu",
    "outputId": "09b7cdb4-3c2f-42b1-f202-7c5b46be9277"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 721\n",
      "Test Dataset Count: 170\n"
     ]
    }
   ],
   "source": [
    "(training_data, test_data) = assertion_df.randomSplit([0.8, 0.2], seed = 100)\n",
    "print(\"Training Dataset Count: \" + str(training_data.count()))\n",
    "print(\"Test Dataset Count: \" + str(test_data.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fktQ3EbBZwo-",
    "outputId": "b583259a-a44a-486d-e595-b433c61a8e07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|label  |count|\n",
      "+-------+-----+\n",
      "|present|546  |\n",
      "|absent |175  |\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data.groupBy('label').count().orderBy('count', ascending=False).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UTNhwoSDLLVG",
    "outputId": "fa0b607d-263a-4065-ba88-aed9d07d316b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[ | ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/03 19:35:32 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OK!]"
     ]
    }
   ],
   "source": [
    "document = nlp.DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "chunk = nlp.Doc2Chunk()\\\n",
    "    .setInputCols(\"document\")\\\n",
    "    .setOutputCol(\"chunk\")\\\n",
    "    .setChunkCol(\"target\")\\\n",
    "    .setStartCol(\"start\")\\\n",
    "    .setStartColByTokenIndex(True)\\\n",
    "    .setFailOnMissing(False)\\\n",
    "    .setLowerCase(True)\n",
    "\n",
    "token = nlp.Tokenizer()\\\n",
    "    .setInputCols(['document'])\\\n",
    "    .setOutputCol('token')\n",
    "\n",
    "embeddings = nlp.WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n",
    "    .setInputCols([\"document\", \"token\"])\\\n",
    "    .setOutputCol(\"embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lkp7KmK6pv0-"
   },
   "source": [
    "We will transform our test data with a pipeline consisting of same steps with the pipeline which contains AssertionDLApproach.\n",
    "By doing this, we enable that test data will have same columns with training data in AssertionDLApproach. <br/>\n",
    "The goal of this implementation is enabling the usage of `setTestDataset()` parameter in AssertionDLApproach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "-7DScL2-uIOm"
   },
   "outputs": [],
   "source": [
    "clinical_assertion_pipeline = nlp.Pipeline(\n",
    "    stages = [\n",
    "    document,\n",
    "    chunk,\n",
    "    token,\n",
    "    embeddings])\n",
    "\n",
    "assertion_test_data = clinical_assertion_pipeline.fit(test_data).transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nwuyumqGuHwY",
    "outputId": "ece31244-aec7-4970-966a-bf31c64bd079"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text',\n",
       " 'target',\n",
       " 'label',\n",
       " 'start',\n",
       " 'end',\n",
       " 'document',\n",
       " 'chunk',\n",
       " 'token',\n",
       " 'embeddings']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assertion_test_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aE-99quUsJ5V"
   },
   "source": [
    "We save the test data in parquet format to use in `AssertionDLApproach()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "A3Hx0w05uQ7E"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "assertion_test_data.write.mode(\"overwrite\").parquet('i2b2_assertion_sample_test_data.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uTishXbut1MS"
   },
   "source": [
    "## Graph setup and training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wegOakRbw9nJ"
   },
   "source": [
    "We will use TFGraphBuilder annotator which can be used to create graphs in the model training pipeline.\n",
    "\n",
    "TFGraphBuilder inspects the data and creates the proper graph if a suitable version of TensorFlow (<= 2.7 ) is available. The graph is stored in the defined folder and loaded by the approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "zl1xBA65IZ2j"
   },
   "outputs": [],
   "source": [
    "!mkdir -p training_logs\n",
    "!mkdir -p assertion_tf_graph\n",
    "\n",
    "# ready to use tf_graph\n",
    "!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Healthcare/tf_graphs/blstm_34_32_30_200_2.pb -P ./assertion_tf_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "EtR9lajQxHpc"
   },
   "outputs": [],
   "source": [
    "from sparknlp_jsl.annotator import TFGraphBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "r4nb2OmrxIsH"
   },
   "outputs": [],
   "source": [
    "graph_folder= \"./assertion_tf_graph\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "qZPZIUWYxN3r"
   },
   "outputs": [],
   "source": [
    "assertion_graph_builder = medical.TFGraphBuilder()\\\n",
    "    .setModelName(\"assertion_dl\")\\\n",
    "    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "    .setLabelColumn(\"label\")\\\n",
    "    .setGraphFolder(graph_folder)\\\n",
    "    .setGraphFile(\"assertion_graph.pb\")\\\n",
    "    .setMaxSequenceLength(250)\\\n",
    "    .setHiddenUnitsNumber(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "RNzTsoSeXezx"
   },
   "outputs": [],
   "source": [
    "# Create custom graph\n",
    "\n",
    "# from sparknlp_jsl.training import tf_graph\n",
    "# tf_graph.print_model_params(\"assertion_dl\")\n",
    "\n",
    "# feat_size = 200\n",
    "# n_classes = 6\n",
    "\n",
    "# tf_graph.build(\"assertion_dl\",\n",
    "#               build_params={\"n_classes\": n_classes},\n",
    "#               model_location= \"./tf_graphs\", \n",
    "#               model_filename=\"blstm_34_32_30_{}_{}.pb\".format(feat_size, n_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6D0Ng7nMUjJa"
   },
   "source": [
    "**Setting the Scope Window (Target Area) Dynamically in Assertion Status Detection Models**\n",
    "\n",
    "\n",
    "This parameter allows you to train the Assertion Status Models to focus on specific context windows when resolving the status of a NER chunk. The window is in format `[X,Y]` being `X` the number of tokens to consider on the left of the chunk, and `Y` the max number of tokens to consider on the right. Let’s take a look at what different windows mean:\n",
    "\n",
    "\n",
    "*   By default, the window is `[-1,-1]` which means that the Assertion Status will look at all of the tokens in the sentence/document (up to a maximum of tokens set in `setMaxSentLen()` ).\n",
    "*   `[0,0]` means “don’t pay attention to any token except the ner_chunk”, what basically is not considering any context for the Assertion resolution.\n",
    "*   `[9,15]` is what empirically seems to be the best baseline, meaning that we look up to 9 tokens on the left and 15 on the right of the ner chunk to understand the context and resolve the status.\n",
    "\n",
    "\n",
    "Check this [Scope Window Tuning Assertion Status Detection notebook](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/2.1.Scope_window_tuning_assertion_status_detection.ipynb)  that illustrates the effect of the different windows and how to properly fine-tune your AssertionDLModels to get the best of them.\n",
    "\n",
    "In our case, the best Scope Window is around [10,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "qG2o6Yq2xk4N"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIf .setTestDataset parameter is employed, raw test data cannot be fitted. .setTestDataset only works for dataframes which are correctly transformed\\nby a pipeline consisting of document, chunk, embeddings stages.\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scope_window = [10,10]\n",
    "\n",
    "assertionStatus = medical.AssertionDLApproach()\\\n",
    "    .setLabelCol(\"label\")\\\n",
    "    .setInputCols(\"document\", \"chunk\", \"embeddings\")\\\n",
    "    .setOutputCol(\"assertion\")\\\n",
    "    .setBatchSize(128)\\\n",
    "    .setDropout(0.1)\\\n",
    "    .setLearningRate(0.001)\\\n",
    "    .setEpochs(15)\\\n",
    "    .setValidationSplit(0.2)\\\n",
    "    .setStartCol(\"start\")\\\n",
    "    .setEndCol(\"end\")\\\n",
    "    .setMaxSentLen(250)\\\n",
    "    .setIncludeConfidence(True)\\\n",
    "    .setEnableOutputLogs(True)\\\n",
    "    .setOutputLogsPath('training_logs/')\\\n",
    "    .setGraphFolder(graph_folder)\\\n",
    "    .setGraphFile(f\"{graph_folder}/assertion_graph.pb\")\\\n",
    "    .setTestDataset(path=\"./i2b2_assertion_sample_test_data.parquet\")\\\n",
    "    .setScopeWindow(scope_window)\n",
    "\n",
    "'''\n",
    "If .setTestDataset parameter is employed, raw test data cannot be fitted. .setTestDataset only works for dataframes which are correctly transformed\n",
    "by a pipeline consisting of document, chunk, embeddings stages.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "97ATs6a41jdE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nassertionStatus = AssertionLogRegApproach()    .setLabelCol(\"label\")    .setInputCols(\"document\", \"chunk\", \"embeddings\")    .setOutputCol(\"assertion\")    .setMaxIter(100) # default: 26\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "assertionStatus = AssertionLogRegApproach()\\\n",
    "    .setLabelCol(\"label\")\\\n",
    "    .setInputCols(\"document\", \"chunk\", \"embeddings\")\\\n",
    "    .setOutputCol(\"assertion\")\\\n",
    "    .setMaxIter(100) # default: 26\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "EKRL7Oy4MC1C"
   },
   "outputs": [],
   "source": [
    "clinical_assertion_pipeline = nlp.Pipeline(\n",
    "    stages = [\n",
    "    document,\n",
    "    chunk,\n",
    "    token,\n",
    "    embeddings,\n",
    "    assertion_graph_builder,\n",
    "    assertionStatus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ei54XasnMU0U",
    "outputId": "72e122d5-c7f1-44e1-b58c-e92e1f8878fc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Graph Builder configuration:\n",
      "Model name: assertion_dl\n",
      "Graph folder: ./assertion_tf_graph\n",
      "Graph file name: assertion_graph.pb\n",
      "Build params: {'n_classes': 2, 'feat_size': 200, 'max_seq_len': 250, 'n_hidden': 25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:36:10, INFO Error while sending or receiving.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/py4j/clientserver.py\", line 503, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "19:36:10, INFO Closing down clientserver connection\n",
      "19:36:10, INFO Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/py4j/clientserver.py\", line 503, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/py4j/clientserver.py\", line 506, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "19:36:10, INFO Closing down clientserver connection\n",
      "19:36:17, WARNING From /home/ubuntu/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping: no known devices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:36:17, WARNING From /home/ubuntu/.local/lib/python3.8/site-packages/sparknlp_jsl/_tf_graph_builders/tf2contrib/rnn.py:229: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "19:36:17, WARNING From /home/ubuntu/.local/lib/python3.8/site-packages/tensorflow/python/ops/rnn.py:437: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "19:36:17, WARNING From /home/ubuntu/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py:762: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping: no known devices.\n",
      "assertion_dl graph exported to ./assertion_tf_graph/assertion_graph.pb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.98s\n",
      "Total validation loss: 1.0839\tAvg validation loss: 0.5420\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 112\t 31\t 1\t 0.7832168\t 0.99115044\t 0.875\n",
      "absent\t 0\t 1\t 31\t 0.0\t 0.0\t 0.0\n",
      "tp: 112 fp: 32 fn: 32 labels: 2\n",
      "Macro-average\t prec: 0.3916084, rec: 0.49557522, f1: 0.4375\n",
      "Micro-average\t prec: 0.7777778, rec: 0.7777778, f1: 0.77777773\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.88s\n",
      "Total test loss: 1.2255\tAvg test loss: 0.6127\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 116\t 53\t 1\t 0.6863905\t 0.991453\t 0.81118876\n",
      "absent\t 0\t 1\t 53\t 0.0\t 0.0\t 0.0\n",
      "tp: 116 fp: 54 fn: 54 labels: 2\n",
      "Macro-average\t prec: 0.34319526, rec: 0.4957265, f1: 0.40559438\n",
      "Micro-average\t prec: 0.68235296, rec: 0.68235296, f1: 0.68235296\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.68s\n",
      "Total validation loss: 1.0305\tAvg validation loss: 0.5153\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 113\t 31\t 0\t 0.7847222\t 1.0\t 0.8793774\n",
      "absent\t 0\t 0\t 31\t 0.0\t 0.0\t 0.0\n",
      "tp: 113 fp: 31 fn: 31 labels: 2\n",
      "Macro-average\t prec: 0.3923611, rec: 0.5, f1: 0.4396887\n",
      "Micro-average\t prec: 0.7847222, rec: 0.7847222, f1: 0.7847222\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.78s\n",
      "Total test loss: 1.2780\tAvg test loss: 0.6390\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 117\t 53\t 0\t 0.6882353\t 1.0\t 0.815331\n",
      "absent\t 0\t 0\t 53\t 0.0\t 0.0\t 0.0\n",
      "tp: 117 fp: 53 fn: 53 labels: 2\n",
      "Macro-average\t prec: 0.34411764, rec: 0.5, f1: 0.4076655\n",
      "Micro-average\t prec: 0.6882353, rec: 0.6882353, f1: 0.6882353\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.68s\n",
      "Total validation loss: 1.0069\tAvg validation loss: 0.5034\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 113\t 31\t 0\t 0.7847222\t 1.0\t 0.8793774\n",
      "absent\t 0\t 0\t 31\t 0.0\t 0.0\t 0.0\n",
      "tp: 113 fp: 31 fn: 31 labels: 2\n",
      "Macro-average\t prec: 0.3923611, rec: 0.5, f1: 0.4396887\n",
      "Micro-average\t prec: 0.7847222, rec: 0.7847222, f1: 0.7847222\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.78s\n",
      "Total test loss: 1.1826\tAvg test loss: 0.5913\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 117\t 53\t 0\t 0.6882353\t 1.0\t 0.815331\n",
      "absent\t 0\t 0\t 53\t 0.0\t 0.0\t 0.0\n",
      "tp: 117 fp: 53 fn: 53 labels: 2\n",
      "Macro-average\t prec: 0.34411764, rec: 0.5, f1: 0.4076655\n",
      "Micro-average\t prec: 0.6882353, rec: 0.6882353, f1: 0.6882353\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.68s\n",
      "Total validation loss: 0.9812\tAvg validation loss: 0.4906\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 113\t 31\t 0\t 0.7847222\t 1.0\t 0.8793774\n",
      "absent\t 0\t 0\t 31\t 0.0\t 0.0\t 0.0\n",
      "tp: 113 fp: 31 fn: 31 labels: 2\n",
      "Macro-average\t prec: 0.3923611, rec: 0.5, f1: 0.4396887\n",
      "Micro-average\t prec: 0.7847222, rec: 0.7847222, f1: 0.7847222\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.78s\n",
      "Total test loss: 1.1501\tAvg test loss: 0.5751\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 117\t 53\t 0\t 0.6882353\t 1.0\t 0.815331\n",
      "absent\t 0\t 0\t 53\t 0.0\t 0.0\t 0.0\n",
      "tp: 117 fp: 53 fn: 53 labels: 2\n",
      "Macro-average\t prec: 0.34411764, rec: 0.5, f1: 0.4076655\n",
      "Micro-average\t prec: 0.6882353, rec: 0.6882353, f1: 0.6882353\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.66s\n",
      "Total validation loss: 0.9276\tAvg validation loss: 0.4638\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 113\t 31\t 0\t 0.7847222\t 1.0\t 0.8793774\n",
      "absent\t 0\t 0\t 31\t 0.0\t 0.0\t 0.0\n",
      "tp: 113 fp: 31 fn: 31 labels: 2\n",
      "Macro-average\t prec: 0.3923611, rec: 0.5, f1: 0.4396887\n",
      "Micro-average\t prec: 0.7847222, rec: 0.7847222, f1: 0.7847222\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.78s\n",
      "Total test loss: 1.1354\tAvg test loss: 0.5677\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 117\t 53\t 0\t 0.6882353\t 1.0\t 0.815331\n",
      "absent\t 0\t 0\t 53\t 0.0\t 0.0\t 0.0\n",
      "tp: 117 fp: 53 fn: 53 labels: 2\n",
      "Macro-average\t prec: 0.34411764, rec: 0.5, f1: 0.4076655\n",
      "Micro-average\t prec: 0.6882353, rec: 0.6882353, f1: 0.6882353\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.68s\n",
      "Total validation loss: 0.8868\tAvg validation loss: 0.4434\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 113\t 31\t 0\t 0.7847222\t 1.0\t 0.8793774\n",
      "absent\t 0\t 0\t 31\t 0.0\t 0.0\t 0.0\n",
      "tp: 113 fp: 31 fn: 31 labels: 2\n",
      "Macro-average\t prec: 0.3923611, rec: 0.5, f1: 0.4396887\n",
      "Micro-average\t prec: 0.7847222, rec: 0.7847222, f1: 0.7847222\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.78s\n",
      "Total test loss: 1.0868\tAvg test loss: 0.5434\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 117\t 53\t 0\t 0.6882353\t 1.0\t 0.815331\n",
      "absent\t 0\t 0\t 53\t 0.0\t 0.0\t 0.0\n",
      "tp: 117 fp: 53 fn: 53 labels: 2\n",
      "Macro-average\t prec: 0.34411764, rec: 0.5, f1: 0.4076655\n",
      "Micro-average\t prec: 0.6882353, rec: 0.6882353, f1: 0.6882353\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.67s\n",
      "Total validation loss: 0.8463\tAvg validation loss: 0.4232\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 113\t 29\t 0\t 0.79577464\t 1.0\t 0.88627446\n",
      "absent\t 2\t 0\t 29\t 1.0\t 0.06451613\t 0.121212125\n",
      "tp: 115 fp: 29 fn: 29 labels: 2\n",
      "Macro-average\t prec: 0.89788735, rec: 0.53225803, f1: 0.6683345\n",
      "Micro-average\t prec: 0.7986111, rec: 0.7986111, f1: 0.7986111\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.76s\n",
      "Total test loss: 1.0086\tAvg test loss: 0.5043\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 117\t 49\t 0\t 0.70481926\t 1.0\t 0.8268551\n",
      "absent\t 4\t 0\t 49\t 1.0\t 0.0754717\t 0.1403509\n",
      "tp: 121 fp: 49 fn: 49 labels: 2\n",
      "Macro-average\t prec: 0.8524096, rec: 0.5377358, f1: 0.65945786\n",
      "Micro-average\t prec: 0.7117647, rec: 0.7117647, f1: 0.7117647\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.67s\n",
      "Total validation loss: 0.7875\tAvg validation loss: 0.3938\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 113\t 27\t 0\t 0.80714285\t 1.0\t 0.8932806\n",
      "absent\t 4\t 0\t 27\t 1.0\t 0.12903225\t 0.22857143\n",
      "tp: 117 fp: 27 fn: 27 labels: 2\n",
      "Macro-average\t prec: 0.9035714, rec: 0.5645161, f1: 0.6948913\n",
      "Micro-average\t prec: 0.8125, rec: 0.8125, f1: 0.8125\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.78s\n",
      "Total test loss: 0.9289\tAvg test loss: 0.4644\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 117\t 44\t 0\t 0.72670805\t 1.0\t 0.8417266\n",
      "absent\t 9\t 0\t 44\t 1.0\t 0.16981132\t 0.29032257\n",
      "tp: 126 fp: 44 fn: 44 labels: 2\n",
      "Macro-average\t prec: 0.863354, rec: 0.5849057, f1: 0.69736207\n",
      "Micro-average\t prec: 0.7411765, rec: 0.7411765, f1: 0.7411765\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.67s\n",
      "Total validation loss: 0.7285\tAvg validation loss: 0.3643\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 113\t 21\t 0\t 0.8432836\t 1.0\t 0.91497976\n",
      "absent\t 10\t 0\t 21\t 1.0\t 0.32258064\t 0.4878049\n",
      "tp: 123 fp: 21 fn: 21 labels: 2\n",
      "Macro-average\t prec: 0.9216418, rec: 0.6612903, f1: 0.77005553\n",
      "Micro-average\t prec: 0.8541667, rec: 0.8541667, f1: 0.8541667\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.78s\n",
      "Total test loss: 0.8363\tAvg test loss: 0.4182\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 117\t 29\t 0\t 0.80136985\t 1.0\t 0.8897338\n",
      "absent\t 24\t 0\t 29\t 1.0\t 0.4528302\t 0.6233766\n",
      "tp: 141 fp: 29 fn: 29 labels: 2\n",
      "Macro-average\t prec: 0.90068495, rec: 0.7264151, f1: 0.80421746\n",
      "Micro-average\t prec: 0.82941175, rec: 0.82941175, f1: 0.82941175\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.67s\n",
      "Total validation loss: 0.6810\tAvg validation loss: 0.3405\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 113\t 15\t 0\t 0.8828125\t 1.0\t 0.93775934\n",
      "absent\t 16\t 0\t 15\t 1.0\t 0.516129\t 0.68085104\n",
      "tp: 129 fp: 15 fn: 15 labels: 2\n",
      "Macro-average\t prec: 0.94140625, rec: 0.7580645, f1: 0.8398458\n",
      "Micro-average\t prec: 0.8958333, rec: 0.8958333, f1: 0.8958334\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.77s\n",
      "Total test loss: 0.7587\tAvg test loss: 0.3793\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 114\t 22\t 3\t 0.8382353\t 0.974359\t 0.9011858\n",
      "absent\t 31\t 3\t 22\t 0.9117647\t 0.5849057\t 0.7126437\n",
      "tp: 145 fp: 25 fn: 25 labels: 2\n",
      "Macro-average\t prec: 0.875, rec: 0.77963233, f1: 0.8245678\n",
      "Micro-average\t prec: 0.85294116, rec: 0.85294116, f1: 0.85294116\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.68s\n",
      "Total validation loss: 0.6678\tAvg validation loss: 0.3339\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 109\t 12\t 4\t 0.90082645\t 0.96460176\t 0.93162394\n",
      "absent\t 19\t 4\t 12\t 0.82608694\t 0.61290324\t 0.70370376\n",
      "tp: 128 fp: 16 fn: 16 labels: 2\n",
      "Macro-average\t prec: 0.8634567, rec: 0.7887525, f1: 0.8244157\n",
      "Micro-average\t prec: 0.8888889, rec: 0.8888889, f1: 0.8888889\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.79s\n",
      "Total test loss: 0.7032\tAvg test loss: 0.3516\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 114\t 20\t 3\t 0.8507463\t 0.974359\t 0.90836656\n",
      "absent\t 33\t 3\t 20\t 0.9166667\t 0.6226415\t 0.74157304\n",
      "tp: 147 fp: 23 fn: 23 labels: 2\n",
      "Macro-average\t prec: 0.88370645, rec: 0.79850024, f1: 0.8389455\n",
      "Micro-average\t prec: 0.86470586, rec: 0.86470586, f1: 0.86470586\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.67s\n",
      "Total validation loss: 0.6312\tAvg validation loss: 0.3156\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 113\t 14\t 0\t 0.8897638\t 1.0\t 0.94166666\n",
      "absent\t 17\t 0\t 14\t 1.0\t 0.5483871\t 0.7083334\n",
      "tp: 130 fp: 14 fn: 14 labels: 2\n",
      "Macro-average\t prec: 0.9448819, rec: 0.7741935, f1: 0.85106385\n",
      "Micro-average\t prec: 0.9027778, rec: 0.9027778, f1: 0.9027778\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.78s\n",
      "Total test loss: 0.7046\tAvg test loss: 0.3523\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 115\t 22\t 2\t 0.8394161\t 0.982906\t 0.9055118\n",
      "absent\t 31\t 2\t 22\t 0.93939394\t 0.5849057\t 0.7209302\n",
      "tp: 146 fp: 24 fn: 24 labels: 2\n",
      "Macro-average\t prec: 0.889405, rec: 0.78390586, f1: 0.8333296\n",
      "Micro-average\t prec: 0.85882354, rec: 0.85882354, f1: 0.85882354\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.67s\n",
      "Total validation loss: 0.6524\tAvg validation loss: 0.3262\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 105\t 10\t 8\t 0.9130435\t 0.9292035\t 0.92105263\n",
      "absent\t 21\t 8\t 10\t 0.7241379\t 0.67741936\t 0.7\n",
      "tp: 126 fp: 18 fn: 18 labels: 2\n",
      "Macro-average\t prec: 0.8185907, rec: 0.80331147, f1: 0.8108791\n",
      "Micro-average\t prec: 0.875, rec: 0.875, f1: 0.875\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.77s\n",
      "Total test loss: 0.6550\tAvg test loss: 0.3275\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 113\t 14\t 4\t 0.8897638\t 0.96581197\t 0.9262295\n",
      "absent\t 39\t 4\t 14\t 0.90697676\t 0.7358491\t 0.81250006\n",
      "tp: 152 fp: 18 fn: 18 labels: 2\n",
      "Macro-average\t prec: 0.89837027, rec: 0.85083055, f1: 0.87395436\n",
      "Micro-average\t prec: 0.89411765, rec: 0.89411765, f1: 0.89411765\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.66s\n",
      "Total validation loss: 0.5534\tAvg validation loss: 0.2767\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 111\t 13\t 2\t 0.8951613\t 0.9823009\t 0.93670887\n",
      "absent\t 18\t 2\t 13\t 0.9\t 0.58064514\t 0.7058823\n",
      "tp: 129 fp: 15 fn: 15 labels: 2\n",
      "Macro-average\t prec: 0.8975806, rec: 0.78147304, f1: 0.83551234\n",
      "Micro-average\t prec: 0.8958333, rec: 0.8958333, f1: 0.8958334\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.78s\n",
      "Total test loss: 0.7153\tAvg test loss: 0.3577\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 114\t 21\t 3\t 0.84444445\t 0.974359\t 0.9047619\n",
      "absent\t 32\t 3\t 21\t 0.9142857\t 0.6037736\t 0.72727275\n",
      "tp: 146 fp: 24 fn: 24 labels: 2\n",
      "Macro-average\t prec: 0.8793651, rec: 0.7890663, f1: 0.8317721\n",
      "Micro-average\t prec: 0.85882354, rec: 0.85882354, f1: 0.85882354\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.67s\n",
      "Total validation loss: 0.5841\tAvg validation loss: 0.2921\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 105\t 9\t 8\t 0.92105263\t 0.9292035\t 0.9251101\n",
      "absent\t 22\t 8\t 9\t 0.73333335\t 0.7096774\t 0.72131145\n",
      "tp: 127 fp: 17 fn: 17 labels: 2\n",
      "Macro-average\t prec: 0.827193, rec: 0.8194405, f1: 0.8232985\n",
      "Micro-average\t prec: 0.8819444, rec: 0.8819444, f1: 0.8819444\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.78s\n",
      "Total test loss: 0.6664\tAvg test loss: 0.3332\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 111\t 11\t 6\t 0.90983605\t 0.94871795\t 0.92887026\n",
      "absent\t 42\t 6\t 11\t 0.875\t 0.7924528\t 0.83168316\n",
      "tp: 153 fp: 17 fn: 17 labels: 2\n",
      "Macro-average\t prec: 0.892418, rec: 0.8705854, f1: 0.88136655\n",
      "Micro-average\t prec: 0.9, rec: 0.9, f1: 0.9\n",
      "CPU times: user 9.57 s, sys: 456 ms, total: 10 s\n",
      "Wall time: 1min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "assertion_model = clinical_assertion_pipeline.fit(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "30SmcTiSpnWa"
   },
   "source": [
    "## Checking the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kOiu1vuspKut",
    "outputId": "4a51d7c9-76ec-44a7-c3fc-402fc99e4d46"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AssertionDLApproach_5c39e5360ae7.log']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "log_files = os.listdir(\"./training_logs\")\n",
    "log_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CcQV0-fIrJHz",
    "outputId": "4ca50420-aad6-4459-80d7-a720d0349bec",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of the selected graph: ./assertion_tf_graph/assertion_graph.pb\n",
      "Training started, trainExamples: 721\n",
      "\n",
      "\n",
      "Epoch: 0 started, learning rate: 0.001, dataset size: 577\n",
      "Done, 4.737634573 total training loss: 3.2123528, avg training loss: 0.64247054, batches: 5\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.98s\n",
      "Total validation loss: 1.0839\tAvg validation loss: 0.5420\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 112\t 31\t 1\t 0.7832168\t 0.99115044\t 0.875\n",
      "absent\t 0\t 1\t 31\t 0.0\t 0.0\t 0.0\n",
      "tp: 112 fp: 32 fn: 32 labels: 2\n",
      "Macro-average\t prec: 0.3916084, rec: 0.49557522, f1: 0.4375\n",
      "Micro-average\t prec: 0.7777778, rec: 0.7777778, f1: 0.77777773\n",
      "\n",
      "\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.88s\n",
      "Total test loss: 1.2255\tAvg test loss: 0.6127\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 116\t 53\t 1\t 0.6863905\t 0.991453\t 0.81118876\n",
      "absent\t 0\t 1\t 53\t 0.0\t 0.0\t 0.0\n",
      "tp: 116 fp: 54 fn: 54 labels: 2\n",
      "Macro-average\t prec: 0.34319526, rec: 0.4957265, f1: 0.40559438\n",
      "Micro-average\t prec: 0.68235296, rec: 0.68235296, f1: 0.68235296\n",
      "\n",
      "\n",
      "Epoch: 1 started, learning rate: 9.5E-4, dataset size: 577\n",
      "Done, 3.339654484 total training loss: 2.8982742, avg training loss: 0.5796548, batches: 5\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.68s\n",
      "Total validation loss: 1.0305\tAvg validation loss: 0.5153\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 113\t 31\t 0\t 0.7847222\t 1.0\t 0.8793774\n",
      "absent\t 0\t 0\t 31\t 0.0\t 0.0\t 0.0\n",
      "tp: 113 fp: 31 fn: 31 labels: 2\n",
      "Macro-average\t prec: 0.3923611, rec: 0.5, f1: 0.4396887\n",
      "Micro-average\t prec: 0.7847222, rec: 0.7847222, f1: 0.7847222\n",
      "\n",
      "\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.78s\n",
      "Total test loss: 1.2780\tAvg test loss: 0.6390\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 117\t 53\t 0\t 0.6882353\t 1.0\t 0.815331\n",
      "absent\t 0\t 0\t 53\t 0.0\t 0.0\t 0.0\n",
      "tp: 117 fp: 53 fn: 53 labels: 2\n",
      "Macro-average\t prec: 0.34411764, rec: 0.5, f1: 0.4076655\n",
      "Micro-average\t prec: 0.6882353, rec: 0.6882353, f1: 0.6882353\n",
      "\n",
      "\n",
      "Epoch: 2 started, learning rate: 9.025E-4, dataset size: 577\n",
      "Done, 3.241215993 total training loss: 2.7172933, avg training loss: 0.54345864, batches: 5\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.68s\n",
      "Total validation loss: 1.0069\tAvg validation loss: 0.5034\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 113\t 31\t 0\t 0.7847222\t 1.0\t 0.8793774\n",
      "absent\t 0\t 0\t 31\t 0.0\t 0.0\t 0.0\n",
      "tp: 113 fp: 31 fn: 31 labels: 2\n",
      "Macro-average\t prec: 0.3923611, rec: 0.5, f1: 0.4396887\n",
      "Micro-average\t prec: 0.7847222, rec: 0.7847222, f1: 0.7847222\n",
      "\n",
      "\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.78s\n",
      "Total test loss: 1.1826\tAvg test loss: 0.5913\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 117\t 53\t 0\t 0.6882353\t 1.0\t 0.815331\n",
      "absent\t 0\t 0\t 53\t 0.0\t 0.0\t 0.0\n",
      "tp: 117 fp: 53 fn: 53 labels: 2\n",
      "Macro-average\t prec: 0.34411764, rec: 0.5, f1: 0.4076655\n",
      "Micro-average\t prec: 0.6882353, rec: 0.6882353, f1: 0.6882353\n",
      "\n",
      "\n",
      "Epoch: 3 started, learning rate: 8.57375E-4, dataset size: 577\n",
      "Done, 3.259647392 total training loss: 2.648775, avg training loss: 0.529755, batches: 5\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.68s\n",
      "Total validation loss: 0.9812\tAvg validation loss: 0.4906\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 113\t 31\t 0\t 0.7847222\t 1.0\t 0.8793774\n",
      "absent\t 0\t 0\t 31\t 0.0\t 0.0\t 0.0\n",
      "tp: 113 fp: 31 fn: 31 labels: 2\n",
      "Macro-average\t prec: 0.3923611, rec: 0.5, f1: 0.4396887\n",
      "Micro-average\t prec: 0.7847222, rec: 0.7847222, f1: 0.7847222\n",
      "\n",
      "\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.78s\n",
      "Total test loss: 1.1501\tAvg test loss: 0.5751\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 117\t 53\t 0\t 0.6882353\t 1.0\t 0.815331\n",
      "absent\t 0\t 0\t 53\t 0.0\t 0.0\t 0.0\n",
      "tp: 117 fp: 53 fn: 53 labels: 2\n",
      "Macro-average\t prec: 0.34411764, rec: 0.5, f1: 0.4076655\n",
      "Micro-average\t prec: 0.6882353, rec: 0.6882353, f1: 0.6882353\n",
      "\n",
      "\n",
      "Epoch: 4 started, learning rate: 8.145062E-4, dataset size: 577\n",
      "Done, 3.25829591 total training loss: 2.5988543, avg training loss: 0.51977086, batches: 5\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.66s\n",
      "Total validation loss: 0.9276\tAvg validation loss: 0.4638\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 113\t 31\t 0\t 0.7847222\t 1.0\t 0.8793774\n",
      "absent\t 0\t 0\t 31\t 0.0\t 0.0\t 0.0\n",
      "tp: 113 fp: 31 fn: 31 labels: 2\n",
      "Macro-average\t prec: 0.3923611, rec: 0.5, f1: 0.4396887\n",
      "Micro-average\t prec: 0.7847222, rec: 0.7847222, f1: 0.7847222\n",
      "\n",
      "\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.78s\n",
      "Total test loss: 1.1354\tAvg test loss: 0.5677\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 117\t 53\t 0\t 0.6882353\t 1.0\t 0.815331\n",
      "absent\t 0\t 0\t 53\t 0.0\t 0.0\t 0.0\n",
      "tp: 117 fp: 53 fn: 53 labels: 2\n",
      "Macro-average\t prec: 0.34411764, rec: 0.5, f1: 0.4076655\n",
      "Micro-average\t prec: 0.6882353, rec: 0.6882353, f1: 0.6882353\n",
      "\n",
      "\n",
      "Epoch: 5 started, learning rate: 7.7378086E-4, dataset size: 577\n",
      "Done, 3.251608317 total training loss: 2.5104785, avg training loss: 0.5020957, batches: 5\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.68s\n",
      "Total validation loss: 0.8868\tAvg validation loss: 0.4434\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 113\t 31\t 0\t 0.7847222\t 1.0\t 0.8793774\n",
      "absent\t 0\t 0\t 31\t 0.0\t 0.0\t 0.0\n",
      "tp: 113 fp: 31 fn: 31 labels: 2\n",
      "Macro-average\t prec: 0.3923611, rec: 0.5, f1: 0.4396887\n",
      "Micro-average\t prec: 0.7847222, rec: 0.7847222, f1: 0.7847222\n",
      "\n",
      "\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.78s\n",
      "Total test loss: 1.0868\tAvg test loss: 0.5434\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 117\t 53\t 0\t 0.6882353\t 1.0\t 0.815331\n",
      "absent\t 0\t 0\t 53\t 0.0\t 0.0\t 0.0\n",
      "tp: 117 fp: 53 fn: 53 labels: 2\n",
      "Macro-average\t prec: 0.34411764, rec: 0.5, f1: 0.4076655\n",
      "Micro-average\t prec: 0.6882353, rec: 0.6882353, f1: 0.6882353\n",
      "\n",
      "\n",
      "Epoch: 6 started, learning rate: 7.350918E-4, dataset size: 577\n",
      "Done, 3.282613432 total training loss: 2.410249, avg training loss: 0.4820498, batches: 5\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.67s\n",
      "Total validation loss: 0.8463\tAvg validation loss: 0.4232\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 113\t 29\t 0\t 0.79577464\t 1.0\t 0.88627446\n",
      "absent\t 2\t 0\t 29\t 1.0\t 0.06451613\t 0.121212125\n",
      "tp: 115 fp: 29 fn: 29 labels: 2\n",
      "Macro-average\t prec: 0.89788735, rec: 0.53225803, f1: 0.6683345\n",
      "Micro-average\t prec: 0.7986111, rec: 0.7986111, f1: 0.7986111\n",
      "\n",
      "\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.76s\n",
      "Total test loss: 1.0086\tAvg test loss: 0.5043\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 117\t 49\t 0\t 0.70481926\t 1.0\t 0.8268551\n",
      "absent\t 4\t 0\t 49\t 1.0\t 0.0754717\t 0.1403509\n",
      "tp: 121 fp: 49 fn: 49 labels: 2\n",
      "Macro-average\t prec: 0.8524096, rec: 0.5377358, f1: 0.65945786\n",
      "Micro-average\t prec: 0.7117647, rec: 0.7117647, f1: 0.7117647\n",
      "\n",
      "\n",
      "Epoch: 7 started, learning rate: 6.983372E-4, dataset size: 577\n",
      "Done, 3.253478967 total training loss: 2.2397738, avg training loss: 0.44795474, batches: 5\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.67s\n",
      "Total validation loss: 0.7875\tAvg validation loss: 0.3938\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 113\t 27\t 0\t 0.80714285\t 1.0\t 0.8932806\n",
      "absent\t 4\t 0\t 27\t 1.0\t 0.12903225\t 0.22857143\n",
      "tp: 117 fp: 27 fn: 27 labels: 2\n",
      "Macro-average\t prec: 0.9035714, rec: 0.5645161, f1: 0.6948913\n",
      "Micro-average\t prec: 0.8125, rec: 0.8125, f1: 0.8125\n",
      "\n",
      "\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.78s\n",
      "Total test loss: 0.9289\tAvg test loss: 0.4644\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 117\t 44\t 0\t 0.72670805\t 1.0\t 0.8417266\n",
      "absent\t 9\t 0\t 44\t 1.0\t 0.16981132\t 0.29032257\n",
      "tp: 126 fp: 44 fn: 44 labels: 2\n",
      "Macro-average\t prec: 0.863354, rec: 0.5849057, f1: 0.69736207\n",
      "Micro-average\t prec: 0.7411765, rec: 0.7411765, f1: 0.7411765\n",
      "\n",
      "\n",
      "Epoch: 8 started, learning rate: 6.6342036E-4, dataset size: 577\n",
      "Done, 3.256509821 total training loss: 2.0494676, avg training loss: 0.4098935, batches: 5\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.67s\n",
      "Total validation loss: 0.7285\tAvg validation loss: 0.3643\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 113\t 21\t 0\t 0.8432836\t 1.0\t 0.91497976\n",
      "absent\t 10\t 0\t 21\t 1.0\t 0.32258064\t 0.4878049\n",
      "tp: 123 fp: 21 fn: 21 labels: 2\n",
      "Macro-average\t prec: 0.9216418, rec: 0.6612903, f1: 0.77005553\n",
      "Micro-average\t prec: 0.8541667, rec: 0.8541667, f1: 0.8541667\n",
      "\n",
      "\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.78s\n",
      "Total test loss: 0.8363\tAvg test loss: 0.4182\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 117\t 29\t 0\t 0.80136985\t 1.0\t 0.8897338\n",
      "absent\t 24\t 0\t 29\t 1.0\t 0.4528302\t 0.6233766\n",
      "tp: 141 fp: 29 fn: 29 labels: 2\n",
      "Macro-average\t prec: 0.90068495, rec: 0.7264151, f1: 0.80421746\n",
      "Micro-average\t prec: 0.82941175, rec: 0.82941175, f1: 0.82941175\n",
      "\n",
      "\n",
      "Epoch: 9 started, learning rate: 6.302493E-4, dataset size: 577\n",
      "Done, 3.268373074 total training loss: 1.844348, avg training loss: 0.3688696, batches: 5\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.67s\n",
      "Total validation loss: 0.6810\tAvg validation loss: 0.3405\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 113\t 15\t 0\t 0.8828125\t 1.0\t 0.93775934\n",
      "absent\t 16\t 0\t 15\t 1.0\t 0.516129\t 0.68085104\n",
      "tp: 129 fp: 15 fn: 15 labels: 2\n",
      "Macro-average\t prec: 0.94140625, rec: 0.7580645, f1: 0.8398458\n",
      "Micro-average\t prec: 0.8958333, rec: 0.8958333, f1: 0.8958334\n",
      "\n",
      "\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.77s\n",
      "Total test loss: 0.7587\tAvg test loss: 0.3793\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 114\t 22\t 3\t 0.8382353\t 0.974359\t 0.9011858\n",
      "absent\t 31\t 3\t 22\t 0.9117647\t 0.5849057\t 0.7126437\n",
      "tp: 145 fp: 25 fn: 25 labels: 2\n",
      "Macro-average\t prec: 0.875, rec: 0.77963233, f1: 0.8245678\n",
      "Micro-average\t prec: 0.85294116, rec: 0.85294116, f1: 0.85294116\n",
      "\n",
      "\n",
      "Epoch: 10 started, learning rate: 5.9873686E-4, dataset size: 577\n",
      "Done, 3.216909634 total training loss: 1.7137182, avg training loss: 0.34274364, batches: 5\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.68s\n",
      "Total validation loss: 0.6678\tAvg validation loss: 0.3339\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 109\t 12\t 4\t 0.90082645\t 0.96460176\t 0.93162394\n",
      "absent\t 19\t 4\t 12\t 0.82608694\t 0.61290324\t 0.70370376\n",
      "tp: 128 fp: 16 fn: 16 labels: 2\n",
      "Macro-average\t prec: 0.8634567, rec: 0.7887525, f1: 0.8244157\n",
      "Micro-average\t prec: 0.8888889, rec: 0.8888889, f1: 0.8888889\n",
      "\n",
      "\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.79s\n",
      "Total test loss: 0.7032\tAvg test loss: 0.3516\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 114\t 20\t 3\t 0.8507463\t 0.974359\t 0.90836656\n",
      "absent\t 33\t 3\t 20\t 0.9166667\t 0.6226415\t 0.74157304\n",
      "tp: 147 fp: 23 fn: 23 labels: 2\n",
      "Macro-average\t prec: 0.88370645, rec: 0.79850024, f1: 0.8389455\n",
      "Micro-average\t prec: 0.86470586, rec: 0.86470586, f1: 0.86470586\n",
      "\n",
      "\n",
      "Epoch: 11 started, learning rate: 5.688E-4, dataset size: 577\n",
      "Done, 3.247536073 total training loss: 1.558478, avg training loss: 0.3116956, batches: 5\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.67s\n",
      "Total validation loss: 0.6312\tAvg validation loss: 0.3156\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 113\t 14\t 0\t 0.8897638\t 1.0\t 0.94166666\n",
      "absent\t 17\t 0\t 14\t 1.0\t 0.5483871\t 0.7083334\n",
      "tp: 130 fp: 14 fn: 14 labels: 2\n",
      "Macro-average\t prec: 0.9448819, rec: 0.7741935, f1: 0.85106385\n",
      "Micro-average\t prec: 0.9027778, rec: 0.9027778, f1: 0.9027778\n",
      "\n",
      "\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.78s\n",
      "Total test loss: 0.7046\tAvg test loss: 0.3523\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 115\t 22\t 2\t 0.8394161\t 0.982906\t 0.9055118\n",
      "absent\t 31\t 2\t 22\t 0.93939394\t 0.5849057\t 0.7209302\n",
      "tp: 146 fp: 24 fn: 24 labels: 2\n",
      "Macro-average\t prec: 0.889405, rec: 0.78390586, f1: 0.8333296\n",
      "Micro-average\t prec: 0.85882354, rec: 0.85882354, f1: 0.85882354\n",
      "\n",
      "\n",
      "Epoch: 12 started, learning rate: 5.4036E-4, dataset size: 577\n",
      "Done, 3.305174182 total training loss: 1.4919219, avg training loss: 0.29838437, batches: 5\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.67s\n",
      "Total validation loss: 0.6524\tAvg validation loss: 0.3262\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 105\t 10\t 8\t 0.9130435\t 0.9292035\t 0.92105263\n",
      "absent\t 21\t 8\t 10\t 0.7241379\t 0.67741936\t 0.7\n",
      "tp: 126 fp: 18 fn: 18 labels: 2\n",
      "Macro-average\t prec: 0.8185907, rec: 0.80331147, f1: 0.8108791\n",
      "Micro-average\t prec: 0.875, rec: 0.875, f1: 0.875\n",
      "\n",
      "\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.77s\n",
      "Total test loss: 0.6550\tAvg test loss: 0.3275\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 113\t 14\t 4\t 0.8897638\t 0.96581197\t 0.9262295\n",
      "absent\t 39\t 4\t 14\t 0.90697676\t 0.7358491\t 0.81250006\n",
      "tp: 152 fp: 18 fn: 18 labels: 2\n",
      "Macro-average\t prec: 0.89837027, rec: 0.85083055, f1: 0.87395436\n",
      "Micro-average\t prec: 0.89411765, rec: 0.89411765, f1: 0.89411765\n",
      "\n",
      "\n",
      "Epoch: 13 started, learning rate: 5.13342E-4, dataset size: 577\n",
      "Done, 3.234673831 total training loss: 1.3718661, avg training loss: 0.27437323, batches: 5\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.66s\n",
      "Total validation loss: 0.5534\tAvg validation loss: 0.2767\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 111\t 13\t 2\t 0.8951613\t 0.9823009\t 0.93670887\n",
      "absent\t 18\t 2\t 13\t 0.9\t 0.58064514\t 0.7058823\n",
      "tp: 129 fp: 15 fn: 15 labels: 2\n",
      "Macro-average\t prec: 0.8975806, rec: 0.78147304, f1: 0.83551234\n",
      "Micro-average\t prec: 0.8958333, rec: 0.8958333, f1: 0.8958334\n",
      "\n",
      "\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.78s\n",
      "Total test loss: 0.7153\tAvg test loss: 0.3577\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 114\t 21\t 3\t 0.84444445\t 0.974359\t 0.9047619\n",
      "absent\t 32\t 3\t 21\t 0.9142857\t 0.6037736\t 0.72727275\n",
      "tp: 146 fp: 24 fn: 24 labels: 2\n",
      "Macro-average\t prec: 0.8793651, rec: 0.7890663, f1: 0.8317721\n",
      "Micro-average\t prec: 0.85882354, rec: 0.85882354, f1: 0.85882354\n",
      "\n",
      "\n",
      "Epoch: 14 started, learning rate: 4.8767487E-4, dataset size: 577\n",
      "Done, 3.290306676 total training loss: 1.4079173, avg training loss: 0.28158346, batches: 5\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.67s\n",
      "Total validation loss: 0.5841\tAvg validation loss: 0.2921\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 105\t 9\t 8\t 0.92105263\t 0.9292035\t 0.9251101\n",
      "absent\t 22\t 8\t 9\t 0.73333335\t 0.7096774\t 0.72131145\n",
      "tp: 127 fp: 17 fn: 17 labels: 2\n",
      "Macro-average\t prec: 0.827193, rec: 0.8194405, f1: 0.8232985\n",
      "Micro-average\t prec: 0.8819444, rec: 0.8819444, f1: 0.8819444\n",
      "\n",
      "\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.78s\n",
      "Total test loss: 0.6664\tAvg test loss: 0.3332\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 111\t 11\t 6\t 0.90983605\t 0.94871795\t 0.92887026\n",
      "absent\t 42\t 6\t 11\t 0.875\t 0.7924528\t 0.83168316\n",
      "tp: 153 fp: 17 fn: 17 labels: 2\n",
      "Macro-average\t prec: 0.892418, rec: 0.8705854, f1: 0.88136655\n",
      "Micro-average\t prec: 0.9, rec: 0.9, f1: 0.9\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"./training_logs/\"+log_files[0]) as log_file:\n",
    "    print(log_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-k2WrFkRyQyP",
    "outputId": "675a5613-6291-49a9-cdfa-ef8ba5938d27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+\n",
      "|  label|   result|\n",
      "+-------+---------+\n",
      "|present|[present]|\n",
      "| absent| [absent]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "+-------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "preds = assertion_model.transform(test_data).select('label','assertion.result')\n",
    "\n",
    "preds.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "4yI73lwG2xk5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "preds_df = preds.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "yRXZFGlQ3Z2U",
    "outputId": "c7c30d32-2e4e-46db-81d0-2f4312916c9c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>present</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>absent</td>\n",
       "      <td>absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>present</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>present</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>present</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>present</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>absent</td>\n",
       "      <td>absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>absent</td>\n",
       "      <td>absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>absent</td>\n",
       "      <td>absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>present</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label   result\n",
       "0    present  present\n",
       "1     absent   absent\n",
       "2    present  present\n",
       "3    present  present\n",
       "4    present  present\n",
       "..       ...      ...\n",
       "165  present  present\n",
       "166   absent   absent\n",
       "167   absent   absent\n",
       "168   absent   absent\n",
       "169  present  present\n",
       "\n",
       "[170 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df['result'] = preds_df['result'].apply(lambda x : x[0])\n",
    "preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sYoEUlfU3cCU",
    "outputId": "5985747a-288d-485a-9f0f-aa9ebb59465c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      absent       0.95      0.70      0.80        53\n",
      "     present       0.88      0.98      0.93       117\n",
      "\n",
      "    accuracy                           0.89       170\n",
      "   macro avg       0.91      0.84      0.87       170\n",
      "weighted avg       0.90      0.89      0.89       170\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We are going to use sklearn to evalute the results on test dataset\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print (classification_report( preds_df['label'], preds_df['result']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "atNaIlnP3gKr"
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "assertion_model.stages[-1].write().overwrite().save('assertion_custom_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[ | ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/03 19:37:43 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK!]\n",
      "ner_clinical download started this may take some time.\n",
      "ner_clinical download started this may take some time.\n",
      "Approximate size to download 13.9 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/03 19:37:46 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n",
      "25/01/03 19:37:46 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download done! Loading the resource.\n",
      "\n",
      "OK!]"
     ]
    }
   ],
   "source": [
    "documentAssembler = nlp.DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "# Sentence Detector annotator, processes various sentences per line\n",
    "sentenceDetector = nlp.SentenceDetector()\\\n",
    "    .setInputCols([\"document\"])\\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "# Tokenizer splits words in a relevant format for NLP\n",
    "tokenizer = nlp.Tokenizer()\\\n",
    "    .setInputCols([\"sentence\"])\\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "# Clinical word embeddings trained on PubMED dataset\n",
    "word_embeddings = nlp.WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n",
    "    .setInputCols([\"sentence\", \"token\"])\\\n",
    "    .setOutputCol(\"embeddings\")\n",
    "\n",
    "clinical_ner = medical.NerModel.pretrained(\"ner_clinical\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"ner\")\n",
    "\n",
    "ner_converter = medical.NerConverterInternal() \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"ner\"]) \\\n",
    "    .setOutputCol(\"ner_chunk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_assertion = medical.AssertionDLModel.load(\"assertion_custom_model\") \\\n",
    "    .setInputCols([\"sentence\", \"ner_chunk\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"assertion\")\n",
    "\n",
    "nlpPipeline = nlp.Pipeline(stages=[\n",
    "    documentAssembler,\n",
    "    sentenceDetector,\n",
    "    tokenizer,\n",
    "    word_embeddings,\n",
    "    clinical_ner,\n",
    "    ner_converter,\n",
    "    clinical_assertion\n",
    "    ])\n",
    "\n",
    "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "model = nlpPipeline.fit(empty_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Patient has a headache for the last 2 weeks, needs to get a head CT, and appears anxious when she walks fast. No alopecia and pain noted'\n",
    "\n",
    "light_model = nlp.LightPipeline(model)\n",
    "\n",
    "light_result = light_model.fullAnnotate(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_tracer = PipelineTracer(model)\n",
    "\n",
    "column_maps = pipeline_tracer.createParserDictionary()\n",
    "column_maps.update({\"document_identifier\": \"custom_model\"})\n",
    "\n",
    "pipeline_parser = medical.PipelineOutputParser(column_maps)\n",
    "result = pipeline_parser.run(light_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk</th>\n",
       "      <th>begin</th>\n",
       "      <th>end</th>\n",
       "      <th>ner_label</th>\n",
       "      <th>ner_source</th>\n",
       "      <th>ner_confidence</th>\n",
       "      <th>assertion</th>\n",
       "      <th>assertion_confidence</th>\n",
       "      <th>assertion_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a headache</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>PROBLEM</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.97150004</td>\n",
       "      <td>present</td>\n",
       "      <td>0.9981</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a head CT</td>\n",
       "      <td>58</td>\n",
       "      <td>66</td>\n",
       "      <td>TEST</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.8149</td>\n",
       "      <td>present</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anxious</td>\n",
       "      <td>81</td>\n",
       "      <td>87</td>\n",
       "      <td>PROBLEM</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.9769</td>\n",
       "      <td>present</td>\n",
       "      <td>0.5982</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alopecia</td>\n",
       "      <td>113</td>\n",
       "      <td>120</td>\n",
       "      <td>PROBLEM</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>absent</td>\n",
       "      <td>0.6847</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pain</td>\n",
       "      <td>126</td>\n",
       "      <td>129</td>\n",
       "      <td>PROBLEM</td>\n",
       "      <td>ner_chunk</td>\n",
       "      <td>0.9993</td>\n",
       "      <td>absent</td>\n",
       "      <td>0.7</td>\n",
       "      <td>assertion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        chunk  begin  end ner_label ner_source ner_confidence assertion  \\\n",
       "0  a headache     12   21   PROBLEM  ner_chunk     0.97150004   present   \n",
       "1   a head CT     58   66      TEST  ner_chunk         0.8149   present   \n",
       "2     anxious     81   87   PROBLEM  ner_chunk         0.9769   present   \n",
       "3    alopecia    113  120   PROBLEM  ner_chunk         0.9994    absent   \n",
       "4        pain    126  129   PROBLEM  ner_chunk         0.9993    absent   \n",
       "\n",
       "  assertion_confidence assertion_source  \n",
       "0               0.9981        assertion  \n",
       "1               0.9928        assertion  \n",
       "2               0.5982        assertion  \n",
       "3               0.6847        assertion  \n",
       "4                  0.7        assertion  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assertions_df = pd.DataFrame(result['result'][0]['assertions'])\n",
    "entities_df = pd.DataFrame(result['result'][0]['entities'])\n",
    "\n",
    "merged_df = pd.merge(entities_df, assertions_df,  on=['chunk_id', 'chunk']).drop(columns='chunk_id')\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Informations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ExceptionHandling**\n",
    "\n",
    "A robust exception handling if the process is broken down due to corrupted inputs. If it is set as True, the annotator tries to process as usual and ff exception-causing data (e.g. corrupted record/ document) is passed to the annotator, an exception warning is emitted which has the exception message. Processing continues with the next one while the rest of the records within the same batch is parsed without interruption. This comes with a performance penalty. The default behaviour is False and will throw exception and break the process to inform users.\n",
    "\n",
    "\n",
    "*Example*:\n",
    "```python\n",
    "clinical_assertion =  medical.AssertionDLModel.pretrained(\"assertion_jsl_augmented\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\", \"ner_chunk\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"assertion\")\\\n",
    "    .setEntityAssertionCaseSensitive(False)\n",
    "    .setDoExceptionHandling(True)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "eaef4d22edbbdbc68b8d50d2a1a48c6349c8418c1052069fe906c41d47bd13e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
