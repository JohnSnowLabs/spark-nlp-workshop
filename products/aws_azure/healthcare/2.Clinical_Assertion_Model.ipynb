{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I08sFJYCxR0Z"
   },
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Niy3mZAjoayg"
   },
   "source": [
    "# Clinical Assertion Status Model \n",
    "\n",
    "\n",
    "The deep neural network architecture for assertion status detection in Spark NLP is based on a Bi-LSTM framework, and is a modified version of the architecture proposed by Federico Fancellu, Adam Lopez and Bonnie Webber ([Neural Networks For Negation Scope Detection](https://aclanthology.org/P16-1047.pdf)). Its goal is to classify the assertions made on given medical concepts as being present, absent, or possible in the patient, conditionally present in the patient under certain circumstances,\n",
    "hypothetically present in the patient at some future point, and\n",
    "mentioned in the patient report but associated with someoneelse.\n",
    "In the proposed implementation, input units depend on the\n",
    "target tokens (a named entity) and the neighboring words that\n",
    "are explicitly encoded as a sequence using word embeddings.\n",
    "Similar to paper mentioned above,  it is observed that that 95% of the scope tokens (neighboring words) fall in a window of 9 tokens to the left and 15\n",
    "to the right of the target tokens in the same dataset. Therefore, the same window size was implemented and it following parameters were used: learning\n",
    "rate 0.0012, dropout 0.05, batch size 64 and a maximum sentence length 250. The model has been implemented within\n",
    "Spark NLP as an annotator called AssertionDLModel. After\n",
    "training 20 epoch and measuring accuracy on the official test\n",
    "set, this implementation exceeds the latest state-of-the-art\n",
    "accuracy benchmarks as summarized as following table:\n",
    "\n",
    "|Assertion Label|Spark NLP|Latest Best|\n",
    "|-|-|-|\n",
    "|Absent       |0.944 |0.937|\n",
    "|Someone-else |0.904|0.869|\n",
    "|Conditional  |0.441|0.422|\n",
    "|Hypothetical |0.862|0.890|\n",
    "|Possible     |0.680|0.630|\n",
    "|Present      |0.953|0.957|\n",
    "|micro F1     |0.939|0.934|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "okhT7AcXxben"
   },
   "source": [
    "**Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‹ Loading license number 0 from /home/ubuntu/.johnsnowlabs/licenses/license_number_0_for_Spark-Healthcare_Spark-OCR.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/12 19:23:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/02/12 19:23:39 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ‘Œ Launched \u001b[92mcpu optimized\u001b[39m session with with: ðŸš€Spark-NLP==5.2.2, ðŸ’ŠSpark-Healthcare==5.2.1, ðŸ•¶Spark-OCR==5.1.2, running on âš¡ PySpark==3.4.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-63-84.ec2.internal:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>John-Snow-Labs-Spark-Session ðŸš€ with Jars for: ðŸš€Spark-NLP==5.2.2, ðŸ’ŠSpark-Healthcare==5.2.1, ðŸ•¶Spark-OCR==5.1.2, running on âš¡ PySpark==3.4.0</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fecdca9f520>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml import Pipeline,PipelineModel\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "from johnsnowlabs import nlp, medical\n",
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "spark = start_spark()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AMU4sAJQ0Rhs"
   },
   "source": [
    "# Clinical Assertion Models (with pretrained models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kql2KmQ35H7H"
   },
   "source": [
    "|    | model_name              |Predicted Entities|\n",
    "|---:|:------------------------|-|\n",
    "|  1 | [assertion_dl](https://nlp.johnsnowlabs.com/2021/01/26/assertion_dl_en.html)            |Present, Absent, Possible, conditional, hypothetical, associated_with_someone_else|\n",
    "|  2 | [assertion_dl_biobert](https://nlp.johnsnowlabs.com/2021/01/26/assertion_dl_biobert_en.html)    |Present, Absent, Possible, conditional, hypothetical, associated_with_someone_else|\n",
    "|  3 | [assertion_dl_healthcare](https://nlp.johnsnowlabs.com/2020/09/23/assertion_dl_healthcare_en.html) |Present, Absent, Possible, conditional, hypothetical, associated_with_someone_else|\n",
    "|  4 | [assertion_dl_large](https://nlp.johnsnowlabs.com/2020/05/21/assertion_dl_large_en.html)      |Present, Absent, Possible, conditional, hypothetical, associated_with_someone_else|\n",
    "|  5 | [assertion_dl_radiology](https://nlp.johnsnowlabs.com/2021/03/18/assertion_dl_radiology_en.html)   |Confirmed, Suspected, Negative|\n",
    "|  6 | [assertion_jsl](https://nlp.johnsnowlabs.com/2021/07/24/assertion_jsl_en.html)           |Present, Absent, Possible, Planned, Someoneelse, Past, Family, Hypotetical|\n",
    "|  7 | [assertion_jsl_large](https://nlp.johnsnowlabs.com/2021/07/24/assertion_jsl_large_en.html)     |present, absent, possible, planned, someoneelse, past, hypothetical|\n",
    "|  8 |  [assertion_ml](https://nlp.johnsnowlabs.com/2020/01/30/assertion_ml_en.html) |Hypothetical, Present, Absent, Possible, Conditional, Associated_with_someone_else|\n",
    "|  9 | [assertion_dl_scope_L10R10](https://nlp.johnsnowlabs.com/2022/03/17/assertion_dl_scope_L10R10_en_3_0.html)| hypothetical, associated_with_someone_else, conditional, possible, absent, present|\n",
    "| 10 | [assertion_dl_biobert_scope_L10R10](https://nlp.johnsnowlabs.com/2022/03/24/assertion_dl_biobert_scope_L10R10_en_2_4.html)| hypothetical, associated_with_someone_else, conditional, possible, absent, present|\n",
    "| 11 | [assertion_jsl_augmented](https://nlp.johnsnowlabs.com/2022/09/15/assertion_jsl_augmented_en.html)| Present, Absent, Possible, Planned, Past, Family, Hypotetical, SomeoneElse|\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "voZj8-NSbe4j"
   },
   "source": [
    "### Pretrained `assertion_jsl_augmented` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 81250,
     "status": "ok",
     "timestamp": 1662533938957,
     "user": {
      "displayName": "Merve Ertas Uslu",
      "userId": "01451729557099986551"
     },
     "user_tz": -120
    },
    "id": "DEa5SITBxmY0",
    "outputId": "27161324-cd9f-4eb7-a67a-026d9a0b97c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[ | ]embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "Download done! Loading the resource.\n",
      "[OK!]\n",
      "ner_jsl download started this may take some time.\n",
      "[ | ]ner_jsl download started this may take some time.\n",
      "Approximate size to download 14.5 MB\n",
      "Download done! Loading the resource.\n",
      "[ / ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.util.SizeEstimator$ (file:/home/ubuntu/.local/lib/python3.8/site-packages/pyspark/jars/spark-core_2.12-3.4.0.jar) to field java.lang.ref.Reference.referent\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.util.SizeEstimator$\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK!]\n",
      "assertion_jsl_augmented download started this may take some time.\n",
      "[ | ]assertion_jsl_augmented download started this may take some time.\n",
      "Approximate size to download 6.2 MB\n",
      "Download done! Loading the resource.\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "# Annotator that transforms a text column from dataframe into an Annotation ready for NLP\n",
    "\n",
    "documentAssembler = nlp.DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "# Sentence Detector annotator, processes various sentences per line\n",
    "sentenceDetector = nlp.SentenceDetector()\\\n",
    "    .setInputCols([\"document\"])\\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "# Tokenizer splits words in a relevant format for NLP\n",
    "tokenizer = nlp.Tokenizer()\\\n",
    "    .setInputCols([\"sentence\"])\\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "# Clinical word embeddings trained on PubMED dataset\n",
    "word_embeddings = nlp.WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n",
    "    .setInputCols([\"sentence\", \"token\"])\\\n",
    "    .setOutputCol(\"embeddings\")\n",
    "\n",
    "# NER model trained on i2b2 (sampled from MIMIC) dataset\n",
    "clinical_ner = medical.NerModel.pretrained(\"ner_jsl\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"ner\")\\\n",
    "    #.setIncludeAllConfidenceScores(False)\n",
    "\n",
    "ner_converter = medical.NerConverterInternal() \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"ner\"]) \\\n",
    "    .setOutputCol(\"ner_chunk\")\\\n",
    "    .setWhiteList([\"SYMPTOM\",\"VS_FINDING\",\"DISEASE_SYNDROME_DISORDER\",\"ADMISSION_DISCHARGE\",\"PROCEDURE\"])\n",
    "\n",
    "# Assertion model trained on i2b2 (sampled from MIMIC) dataset\n",
    "clinical_assertion = medical.AssertionDLModel.pretrained(\"assertion_jsl_augmented\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\", \"ner_chunk\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"assertion\")\n",
    "    \n",
    "nlpPipeline = nlp.Pipeline(stages=[\n",
    "    documentAssembler, \n",
    "    sentenceDetector,\n",
    "    tokenizer,\n",
    "    word_embeddings,\n",
    "    clinical_ner,\n",
    "    ner_converter,\n",
    "    clinical_assertion\n",
    "    ])\n",
    "\n",
    "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "model = nlpPipeline.fit(empty_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 206,
     "status": "ok",
     "timestamp": 1662533942646,
     "user": {
      "displayName": "Merve Ertas Uslu",
      "userId": "01451729557099986551"
     },
     "user_tz": -120
    },
    "id": "-Z232ubQeyTu",
    "outputId": "85c37914-4404-40bb-ef2a-56ec981fbfe2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='AssertionDLApproach_5f35da648442', name='lazyAnnotator', doc='Whether this AnnotatorModel acts as lazy in RecursivePipelines'): False,\n",
       " Param(parent='AssertionDLApproach_5f35da648442', name='label', doc='Column with one label per document'): 'label',\n",
       " Param(parent='AssertionDLApproach_5f35da648442', name='batchSize', doc='Size for each batch in the optimization process'): 64,\n",
       " Param(parent='AssertionDLApproach_5f35da648442', name='epochs', doc='Number of epochs for the optimization process'): 5,\n",
       " Param(parent='AssertionDLApproach_5f35da648442', name='learningRate', doc='Learning rate for the optimization process'): 0.0012,\n",
       " Param(parent='AssertionDLApproach_5f35da648442', name='dropout', doc='Dropout at the output of each layer'): 0.05,\n",
       " Param(parent='AssertionDLApproach_5f35da648442', name='maxSentLen', doc='Max length for an input sentence.'): 250,\n",
       " Param(parent='AssertionDLApproach_5f35da648442', name='includeConfidence', doc='whether to include confidence scores in annotation metadata'): True,\n",
       " Param(parent='AssertionDLApproach_5f35da648442', name='scopeWindow', doc='The scope window of the assertion expression'): [9,\n",
       "  15]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medical.AssertionDLApproach().extractParamMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "SMzVzklLw7B3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclinical_assertion_ml = AssertionLogRegModel.pretrained(\"assertion_ml\", \"en\", \"clinical/models\")     .setInputCols([\"sentence\", \"ner_chunk\", \"embeddings\"])     .setOutputCol(\"assertion\")\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we also have a LogReg based Assertion Model.\n",
    "'''\n",
    "clinical_assertion_ml = AssertionLogRegModel.pretrained(\"assertion_ml\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\", \"ner_chunk\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"assertion\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "executionInfo": {
     "elapsed": 1817,
     "status": "ok",
     "timestamp": 1662533950069,
     "user": {
      "displayName": "Merve Ertas Uslu",
      "userId": "01451729557099986551"
     },
     "user_tz": -120
    },
    "id": "f2RPZMmbVeN3",
    "outputId": "24e6998c-4ad0-4693-d82e-533ec28cd796"
   },
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "GENERAL: He is an elderly gentleman in no acute distress. He is sitting up in bed eating his breakfast. He is alert and oriented and answering questions appropriately.\n",
    "HEENT: Sclerae show mild arcus senilis in the right. Left is clear. Pupils are equally round and reactive to light. Extraocular movements are intact. Oropharynx is clear.\n",
    "NECK: Supple. Trachea is midline. No jugular venous pressure distention is noted. No adenopathy in the cervical, supraclavicular, or axillary areas.\n",
    "ABDOMEN: Soft and nontender. There may be some fullness in the left upper quadrant, although I do not appreciate a true spleen with inspiration.\n",
    "EXTREMITIES: There is some edema, but no cyanosis and clubbing .\n",
    "IMPRESSION: At this time is refractory anemia, which is transfusion dependent. He is on B12, iron, folic acid, and Procrit. There are no sign or symptom of blood loss and a recent esophagogastroduodenoscopy, which was negative. His creatinine was 1. \n",
    "  My impression at this time is that he probably has an underlying myelodysplastic syndrome or bone marrow failure. His creatinine on this hospitalization was up slightly to 1.6 and this may contribute to his anemia.\n",
    "  At this time, my recommendation for the patient is that he undergoes further serologic evaluation with reticulocyte count, serum protein, and electrophoresis, LDH, B12, folate, erythropoietin level, and he should undergo a bone marrow aspiration and biopsy. \n",
    "  I have discussed the procedure in detail which the patient. I have discussed the risks, benefits, and successes of that treatment and usefulness of the bone marrow and predicting his cause of refractory anemia and further therapeutic interventions, which might be beneficial to him. \n",
    "  He is willing to proceed with the studies I have described to him. We will order an ultrasound of his abdomen because of the possible fullness of the spleen, and I will probably see him in follow up after this hospitalization.\n",
    "  As always, we greatly appreciate being able to participate in the care of your patient. We appreciate the consultation of the patient. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunks</th>\n",
       "      <th>entities</th>\n",
       "      <th>assertion</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>distress</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Absent</td>\n",
       "      <td>0.9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arcus senilis</td>\n",
       "      <td>Disease_Syndrome_Disorder</td>\n",
       "      <td>Past</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jugular venous pressure distention</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adenopathy</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nontender</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fullness</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Possible</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>edema</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Present</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cyanosis</td>\n",
       "      <td>VS_Finding</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>clubbing</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>anemia</td>\n",
       "      <td>Disease_Syndrome_Disorder</td>\n",
       "      <td>Hypothetical</td>\n",
       "      <td>0.9758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>blood loss</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>esophagogastroduodenoscopy</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>Past</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>myelodysplastic syndrome</td>\n",
       "      <td>Disease_Syndrome_Disorder</td>\n",
       "      <td>Possible</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bone marrow failure</td>\n",
       "      <td>Disease_Syndrome_Disorder</td>\n",
       "      <td>Possible</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hospitalization</td>\n",
       "      <td>Admission_Discharge</td>\n",
       "      <td>Past</td>\n",
       "      <td>0.9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>anemia</td>\n",
       "      <td>Disease_Syndrome_Disorder</td>\n",
       "      <td>Hypothetical</td>\n",
       "      <td>0.9966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bone marrow aspiration</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>Family</td>\n",
       "      <td>0.9374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>biopsy</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>Family</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>anemia</td>\n",
       "      <td>Disease_Syndrome_Disorder</td>\n",
       "      <td>Hypothetical</td>\n",
       "      <td>0.9961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>fullness of the spleen</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Possible</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>hospitalization</td>\n",
       "      <td>Admission_Discharge</td>\n",
       "      <td>Planned</td>\n",
       "      <td>0.7917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                chunks                   entities  \\\n",
       "0                             distress                    Symptom   \n",
       "1                        arcus senilis  Disease_Syndrome_Disorder   \n",
       "2   jugular venous pressure distention                    Symptom   \n",
       "3                           adenopathy                    Symptom   \n",
       "4                            nontender                    Symptom   \n",
       "5                             fullness                    Symptom   \n",
       "6                                edema                    Symptom   \n",
       "7                             cyanosis                 VS_Finding   \n",
       "8                             clubbing                    Symptom   \n",
       "9                               anemia  Disease_Syndrome_Disorder   \n",
       "10                          blood loss                    Symptom   \n",
       "11          esophagogastroduodenoscopy                  Procedure   \n",
       "12            myelodysplastic syndrome  Disease_Syndrome_Disorder   \n",
       "13                 bone marrow failure  Disease_Syndrome_Disorder   \n",
       "14                     hospitalization        Admission_Discharge   \n",
       "15                              anemia  Disease_Syndrome_Disorder   \n",
       "16              bone marrow aspiration                  Procedure   \n",
       "17                              biopsy                  Procedure   \n",
       "18                              anemia  Disease_Syndrome_Disorder   \n",
       "19              fullness of the spleen                    Symptom   \n",
       "20                     hospitalization        Admission_Discharge   \n",
       "\n",
       "       assertion confidence  \n",
       "0         Absent     0.9999  \n",
       "1           Past        1.0  \n",
       "2         Absent        1.0  \n",
       "3         Absent        1.0  \n",
       "4         Absent        1.0  \n",
       "5       Possible        1.0  \n",
       "6        Present        1.0  \n",
       "7         Absent        1.0  \n",
       "8         Absent        1.0  \n",
       "9   Hypothetical     0.9758  \n",
       "10        Absent        1.0  \n",
       "11          Past        1.0  \n",
       "12      Possible        1.0  \n",
       "13      Possible        1.0  \n",
       "14          Past     0.9999  \n",
       "15  Hypothetical     0.9966  \n",
       "16        Family     0.9374  \n",
       "17        Family        1.0  \n",
       "18  Hypothetical     0.9961  \n",
       "19      Possible        1.0  \n",
       "20       Planned     0.7917  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "light_model = nlp.LightPipeline(model)\n",
    "\n",
    "light_result = light_model.fullAnnotate(text)[0]\n",
    "\n",
    "chunks=[]\n",
    "entities=[]\n",
    "status=[]\n",
    "confidence=[]\n",
    "\n",
    "for n,m in zip(light_result['ner_chunk'],light_result['assertion']):\n",
    "    \n",
    "    chunks.append(n.result)\n",
    "    entities.append(n.metadata['entity']) \n",
    "    status.append(m.result)\n",
    "    confidence.append(m.metadata['confidence'])\n",
    "        \n",
    "df = pd.DataFrame({'chunks':chunks, 'entities':entities, 'assertion':status, 'confidence':confidence})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    @import url('https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700&display=swap');\n",
       "    @import url('https://fonts.googleapis.com/css2?family=Vistol Regular:wght@300;400;500;600;700&display=swap');\n",
       "    \n",
       "    .spark-nlp-display-scroll-entities {\n",
       "        border: 1px solid #E7EDF0;\n",
       "        border-radius: 3px;\n",
       "        text-align: justify;\n",
       "        \n",
       "    }\n",
       "    .spark-nlp-display-scroll-entities span {  \n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        color: #536B76;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "    }\n",
       "    \n",
       "    .spark-nlp-display-entity-wrapper{\n",
       "    \n",
       "        display: inline-grid;\n",
       "        text-align: center;\n",
       "        border-radius: 4px;\n",
       "        margin: 0 2px 5px 2px;\n",
       "        padding: 1px\n",
       "    }\n",
       "    .spark-nlp-display-entity-name{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "        \n",
       "        background: #f1f2f3;\n",
       "        border-width: medium;\n",
       "        text-align: center;\n",
       "        \n",
       "        font-weight: 400;\n",
       "        \n",
       "        border-radius: 5px;\n",
       "        padding: 2px 5px;\n",
       "        display: block;\n",
       "        margin: 3px 2px;\n",
       "    \n",
       "    }\n",
       "    .spark-nlp-display-entity-type{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        color: #ffffff;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "        \n",
       "        text-transform: uppercase;\n",
       "        \n",
       "        font-weight: 500;\n",
       "\n",
       "        display: block;\n",
       "        padding: 3px 5px;\n",
       "    }\n",
       "    \n",
       "    .spark-nlp-display-entity-resolution{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        color: #ffffff;\n",
       "        font-family: 'Vistol Regular', sans-serif !important;\n",
       "        \n",
       "        text-transform: uppercase;\n",
       "        \n",
       "        font-weight: 500;\n",
       "\n",
       "        display: block;\n",
       "        padding: 3px 5px;\n",
       "    }\n",
       "    \n",
       "    .spark-nlp-display-others{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "        \n",
       "        font-weight: 400;\n",
       "    }\n",
       "\n",
       "</style>\n",
       " <span class=\"spark-nlp-display-others\" style=\"background-color: white\"><br>GENERAL: He is an elderly gentleman in no acute </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #496A85B3\"><span class=\"spark-nlp-display-entity-name\">distress </span><span class=\"spark-nlp-display-entity-type\">Symptom</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #496A85FF\">Absent </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">. He is sitting up in bed eating his breakfast. He is alert and oriented and answering questions appropriately.<br>HEENT: Sclerae show mild </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #6A551CB3\"><span class=\"spark-nlp-display-entity-name\">arcus senilis </span><span class=\"spark-nlp-display-entity-type\">Disease_Syndrome_Disorder</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #6A551CFF\">Past </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> in the right. Left is clear. Pupils are equally round and reactive to light. Extraocular movements are intact. Oropharynx is clear.<br>NECK: Supple. Trachea is midline. No </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #496A85B3\"><span class=\"spark-nlp-display-entity-name\">jugular venous pressure distention </span><span class=\"spark-nlp-display-entity-type\">Symptom</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #496A85FF\">Absent </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> is noted. No </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #496A85B3\"><span class=\"spark-nlp-display-entity-name\">adenopathy </span><span class=\"spark-nlp-display-entity-type\">Symptom</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #496A85FF\">Absent </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> in the cervical, supraclavicular, or axillary areas.<br>ABDOMEN: Soft and </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #496A85B3\"><span class=\"spark-nlp-display-entity-name\">nontender </span><span class=\"spark-nlp-display-entity-type\">Symptom</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #496A85FF\">Absent </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">. There may be some </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #496A85B3\"><span class=\"spark-nlp-display-entity-name\">fullness </span><span class=\"spark-nlp-display-entity-type\">Symptom</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #496A85FF\">Possible </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> in the left upper quadrant, although I do not appreciate a true spleen with inspiration.<br>EXTREMITIES: There is some </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #496A85B3\"><span class=\"spark-nlp-display-entity-name\">edema </span><span class=\"spark-nlp-display-entity-type\">Symptom</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #496A85FF\">Present </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, but no </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #B058BDB3\"><span class=\"spark-nlp-display-entity-name\">cyanosis </span><span class=\"spark-nlp-display-entity-type\">VS_Finding</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #B058BDFF\">Absent </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> and </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #496A85B3\"><span class=\"spark-nlp-display-entity-name\">clubbing </span><span class=\"spark-nlp-display-entity-type\">Symptom</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #496A85FF\">Absent </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> .<br>IMPRESSION: At this time is refractory </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #6A551CB3\"><span class=\"spark-nlp-display-entity-name\">anemia </span><span class=\"spark-nlp-display-entity-type\">Disease_Syndrome_Disorder</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #6A551CFF\">Hypothetical </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, which is transfusion dependent. He is on B12, iron, folic acid, and Procrit. There are no sign or symptom of </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #496A85B3\"><span class=\"spark-nlp-display-entity-name\">blood loss </span><span class=\"spark-nlp-display-entity-type\">Symptom</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #496A85FF\">Absent </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> and a recent </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #610058B3\"><span class=\"spark-nlp-display-entity-name\">esophagogastroduodenoscopy </span><span class=\"spark-nlp-display-entity-type\">Procedure</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #610058FF\">Past </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, which was negative. His creatinine was 1. <br>  My impression at this time is that he probably has an underlying </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #6A551CB3\"><span class=\"spark-nlp-display-entity-name\">myelodysplastic syndrome </span><span class=\"spark-nlp-display-entity-type\">Disease_Syndrome_Disorder</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #6A551CFF\">Possible </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> or </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #6A551CB3\"><span class=\"spark-nlp-display-entity-name\">bone marrow failure </span><span class=\"spark-nlp-display-entity-type\">Disease_Syndrome_Disorder</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #6A551CFF\">Possible </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">. His creatinine on this </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #153D2EB3\"><span class=\"spark-nlp-display-entity-name\">hospitalization </span><span class=\"spark-nlp-display-entity-type\">Admission_Discharge</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #153D2EFF\">Past </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> was up slightly to 1.6 and this may contribute to his </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #6A551CB3\"><span class=\"spark-nlp-display-entity-name\">anemia </span><span class=\"spark-nlp-display-entity-type\">Disease_Syndrome_Disorder</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #6A551CFF\">Hypothetical </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">.<br>  At this time, my recommendation for the patient is that he undergoes further serologic evaluation with reticulocyte count, serum protein, and electrophoresis, LDH, B12, folate, erythropoietin level, and he should undergo a </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #610058B3\"><span class=\"spark-nlp-display-entity-name\">bone marrow aspiration </span><span class=\"spark-nlp-display-entity-type\">Procedure</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #610058FF\">Family </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> and </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #610058B3\"><span class=\"spark-nlp-display-entity-name\">biopsy </span><span class=\"spark-nlp-display-entity-type\">Procedure</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #610058FF\">Family </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">. <br>  I have discussed the procedure in detail which the patient. I have discussed the risks, benefits, and successes of that treatment and usefulness of the bone marrow and predicting his cause of refractory </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #6A551CB3\"><span class=\"spark-nlp-display-entity-name\">anemia </span><span class=\"spark-nlp-display-entity-type\">Disease_Syndrome_Disorder</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #6A551CFF\">Hypothetical </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> and further therapeutic interventions, which might be beneficial to him. <br>  He is willing to proceed with the studies I have described to him. We will order an ultrasound of his abdomen because of the possible </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #496A85B3\"><span class=\"spark-nlp-display-entity-name\">fullness of the spleen </span><span class=\"spark-nlp-display-entity-type\">Symptom</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #496A85FF\">Possible </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, and I will probably see him in follow up after this </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #153D2EB3\"><span class=\"spark-nlp-display-entity-name\">hospitalization </span><span class=\"spark-nlp-display-entity-type\">Admission_Discharge</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #153D2EFF\">Planned </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">.<br>  As always, we greatly appreciate being able to participate in the care of your patient. We appreciate the consultation of the patient. <br></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "light_model = nlp.LightPipeline(model)\n",
    "\n",
    "light_result = light_model.fullAnnotate(text)[0]\n",
    "\n",
    "vis = nlp.viz.AssertionVisualizer()\n",
    "\n",
    "vis.display(light_result, 'ner_chunk', 'assertion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5991,
     "status": "ok",
     "timestamp": 1662533959181,
     "user": {
      "displayName": "Merve Ertas Uslu",
      "userId": "01451729557099986551"
     },
     "user_tz": -120
    },
    "id": "taZh-fh-vjrZ",
    "outputId": "ec413739-c445-4dbd-dc05-136a979061d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning::Spark Session already created, some configs may not take.\n",
      "Warning::Spark Session already created, some configs may not take.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/02/12 19:14:54 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['assertion', 'assertion_confidence', 'document', 'entities_ner_chunk',\n",
       "       'entities_ner_chunk_class', 'entities_ner_chunk_confidence',\n",
       "       'entities_ner_chunk_origin_chunk', 'entities_ner_chunk_origin_sentence',\n",
       "       'sentence_pragmatic', 'word_embedding_embeddings'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.nlu.to_pretty_df(model,text,output_level='chunk').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 1899,
     "status": "ok",
     "timestamp": 1662533963637,
     "user": {
      "displayName": "Merve Ertas Uslu",
      "userId": "01451729557099986551"
     },
     "user_tz": -120
    },
    "id": "0SVPER6bvkmk",
    "outputId": "c8384265-80c7-4345-ad73-7fb6aa3dc1a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning::Spark Session already created, some configs may not take.\n",
      "Warning::Spark Session already created, some configs may not take.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entities_ner_chunk</th>\n",
       "      <th>entities_ner_chunk_class</th>\n",
       "      <th>assertion</th>\n",
       "      <th>assertion_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>distress</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Absent</td>\n",
       "      <td>0.9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arcus senilis</td>\n",
       "      <td>Disease_Syndrome_Disorder</td>\n",
       "      <td>Past</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jugular venous pressure distention</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adenopathy</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nontender</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fullness</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Possible</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>edema</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Present</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cyanosis</td>\n",
       "      <td>VS_Finding</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>clubbing</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>anemia</td>\n",
       "      <td>Disease_Syndrome_Disorder</td>\n",
       "      <td>Hypothetical</td>\n",
       "      <td>0.9758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>blood loss</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>esophagogastroduodenoscopy</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>Past</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>myelodysplastic syndrome</td>\n",
       "      <td>Disease_Syndrome_Disorder</td>\n",
       "      <td>Possible</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bone marrow failure</td>\n",
       "      <td>Disease_Syndrome_Disorder</td>\n",
       "      <td>Possible</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hospitalization</td>\n",
       "      <td>Admission_Discharge</td>\n",
       "      <td>Past</td>\n",
       "      <td>0.9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>anemia</td>\n",
       "      <td>Disease_Syndrome_Disorder</td>\n",
       "      <td>Hypothetical</td>\n",
       "      <td>0.9966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bone marrow aspiration</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>Family</td>\n",
       "      <td>0.9374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>biopsy</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>Family</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>anemia</td>\n",
       "      <td>Disease_Syndrome_Disorder</td>\n",
       "      <td>Hypothetical</td>\n",
       "      <td>0.9961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>fullness of the spleen</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Possible</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>hospitalization</td>\n",
       "      <td>Admission_Discharge</td>\n",
       "      <td>Planned</td>\n",
       "      <td>0.7917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    entities_ner_chunk   entities_ner_chunk_class  \\\n",
       "0                             distress                    Symptom   \n",
       "1                        arcus senilis  Disease_Syndrome_Disorder   \n",
       "2   jugular venous pressure distention                    Symptom   \n",
       "3                           adenopathy                    Symptom   \n",
       "4                            nontender                    Symptom   \n",
       "5                             fullness                    Symptom   \n",
       "6                                edema                    Symptom   \n",
       "7                             cyanosis                 VS_Finding   \n",
       "8                             clubbing                    Symptom   \n",
       "9                               anemia  Disease_Syndrome_Disorder   \n",
       "10                          blood loss                    Symptom   \n",
       "11          esophagogastroduodenoscopy                  Procedure   \n",
       "12            myelodysplastic syndrome  Disease_Syndrome_Disorder   \n",
       "13                 bone marrow failure  Disease_Syndrome_Disorder   \n",
       "14                     hospitalization        Admission_Discharge   \n",
       "15                              anemia  Disease_Syndrome_Disorder   \n",
       "16              bone marrow aspiration                  Procedure   \n",
       "17                              biopsy                  Procedure   \n",
       "18                              anemia  Disease_Syndrome_Disorder   \n",
       "19              fullness of the spleen                    Symptom   \n",
       "20                     hospitalization        Admission_Discharge   \n",
       "\n",
       "       assertion assertion_confidence  \n",
       "0         Absent               0.9999  \n",
       "1           Past                  1.0  \n",
       "2         Absent                  1.0  \n",
       "3         Absent                  1.0  \n",
       "4         Absent                  1.0  \n",
       "5       Possible                  1.0  \n",
       "6        Present                  1.0  \n",
       "7         Absent                  1.0  \n",
       "8         Absent                  1.0  \n",
       "9   Hypothetical               0.9758  \n",
       "10        Absent                  1.0  \n",
       "11          Past                  1.0  \n",
       "12      Possible                  1.0  \n",
       "13      Possible                  1.0  \n",
       "14          Past               0.9999  \n",
       "15  Hypothetical               0.9966  \n",
       "16        Family               0.9374  \n",
       "17        Family                  1.0  \n",
       "18  Hypothetical               0.9961  \n",
       "19      Possible                  1.0  \n",
       "20       Planned               0.7917  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\n",
    "     'entities_ner_chunk',\n",
    "     'entities_ner_chunk_class', \n",
    "     'assertion',\n",
    "     'assertion_confidence']\n",
    "     \n",
    "df = nlp.nlu.to_pretty_df(model,text,output_level='chunk')[cols].reset_index(drop=True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "OP0I7ELJ0his"
   },
   "outputs": [],
   "source": [
    "# Downloading sample datasets.\n",
    "! wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Healthcare/data/mt_samples_10.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1083,
     "status": "ok",
     "timestamp": 1662533986394,
     "user": {
      "displayName": "Merve Ertas Uslu",
      "userId": "01451729557099986551"
     },
     "user_tz": -120
    },
    "id": "Z9UyX1Tx-vA0",
    "outputId": "aa341498-47d0-4503-81ca-f46dbeca231a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- index: long (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mt_samples_df = spark.createDataFrame(pd.read_csv(\"./mt_samples_10.csv\", sep=',', index_col=[\"index\"]).reset_index())\n",
    "                \n",
    "mt_samples_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tjsXUCZaNcKb",
    "outputId": "57256ad8-1f25-40b4-a31f-2ca567a83be4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|index|                text|\n",
      "+-----+--------------------+\n",
      "|    0|Sample Type / Med...|\n",
      "|    1|Sample Type / Med...|\n",
      "|    2|Sample Type / Med...|\n",
      "|    3|Sample Type / Med...|\n",
      "|    4|Sample Type / Med...|\n",
      "|    5|Sample Type / Med...|\n",
      "|    6|Sample Type / Med...|\n",
      "|    7|Sample Type / Med...|\n",
      "|    8|Sample Type / Med...|\n",
      "|    9|Sample Type / Med...|\n",
      "+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mt_samples_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.transform(mt_samples_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:15:12, INFO Error while sending or receiving.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/py4j/clientserver.py\", line 503, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "19:15:12, INFO Closing down clientserver connection\n",
      "19:15:12, INFO Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/py4j/clientserver.py\", line 503, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/py4j/clientserver.py\", line 506, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "19:15:12, INFO Closing down clientserver connection\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|index|                text|            document|            sentence|               token|          embeddings|                 ner|           ner_chunk|           assertion|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|    0|Sample Type / Med...|[{document, 0, 54...|[{document, 0, 24...|[{token, 0, 5, Sa...|[{word_embeddings...|[{named_entity, 0...|[{chunk, 68, 76, ...|[{assertion, 68, ...|\n",
      "|    1|Sample Type / Med...|[{document, 0, 32...|[{document, 0, 26...|[{token, 0, 5, Sa...|[{word_embeddings...|[{named_entity, 0...|[{chunk, 68, 92, ...|[{assertion, 68, ...|\n",
      "|    2|Sample Type / Med...|[{document, 0, 42...|[{document, 0, 14...|[{token, 0, 5, Sa...|[{word_embeddings...|[{named_entity, 0...|[{chunk, 68, 73, ...|[{assertion, 68, ...|\n",
      "|    3|Sample Type / Med...|[{document, 0, 20...|[{document, 0, 29...|[{token, 0, 5, Sa...|[{word_embeddings...|[{named_entity, 0...|                  []|                  []|\n",
      "|    4|Sample Type / Med...|[{document, 0, 34...|[{document, 0, 11...|[{token, 0, 5, Sa...|[{word_embeddings...|[{named_entity, 0...|[{chunk, 68, 82, ...|[{assertion, 68, ...|\n",
      "|    5|Sample Type / Med...|[{document, 0, 15...|[{document, 0, 28...|[{token, 0, 5, Sa...|[{word_embeddings...|[{named_entity, 0...|[{chunk, 1399, 14...|[{assertion, 1399...|\n",
      "|    6|Sample Type / Med...|[{document, 0, 25...|[{document, 0, 15...|[{token, 0, 5, Sa...|[{word_embeddings...|[{named_entity, 0...|[{chunk, 68, 73, ...|[{assertion, 68, ...|\n",
      "|    7|Sample Type / Med...|[{document, 0, 93...|[{document, 0, 19...|[{token, 0, 5, Sa...|[{word_embeddings...|[{named_entity, 0...|[{chunk, 1063, 10...|[{assertion, 1063...|\n",
      "|    8|Sample Type / Med...|[{document, 0, 20...|[{document, 0, 15...|[{token, 0, 5, Sa...|[{word_embeddings...|[{named_entity, 0...|[{chunk, 363, 372...|[{assertion, 363,...|\n",
      "|    9|Sample Type / Med...|[{document, 0, 19...|[{document, 0, 15...|[{token, 0, 5, Sa...|[{word_embeddings...|[{named_entity, 0...|[{chunk, 79, 95, ...|[{assertion, 79, ...|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8OwYh1r6WU5B",
    "outputId": "65bc3404-c845-4280-cd06-b103e2f92c53",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(result=['Sample Type / Medical Specialty:\\nHematology - Oncology\\nSample Name:\\nDischarge Summary - Mesothelioma - 1\\nDescription:\\nMesothelioma, pleural effusion, atrial fibrillation, anemia, ascites, esophageal reflux, and history of deep venous thrombosis.', '(Medical Transcription Sample Report)\\nPRINCIPAL DIAGNOSIS:\\nMesothelioma.', 'SECONDARY DIAGNOSES:\\nPleural effusion, atrial fibrillation, anemia, ascites, esophageal reflux, and history of deep venous thrombosis.', 'PROCEDURES', '1. On August 24, 2007, decortication of the lung with pleural biopsy and transpleural fluoroscopy.', '2. On August 20, 2007, thoracentesis.', '3. On August 31, 2007, Port-A-Cath placement.', 'HISTORY AND PHYSICAL:\\nThe patient is a 41-year-old Vietnamese female with a nonproductive cough that started last week.', 'She has had right-sided chest pain radiating to her back with fever starting yesterday.', 'She has a history of pericarditis and pericardectomy in May 2006 and developed cough with right-sided chest pain, and went to an urgent care center.', 'Chest x-ray revealed right-sided pleural effusion.', 'PAST MEDICAL HISTORY', '1. Pericardectomy.', '2. Pericarditis.', '2. Atrial fibrillation.', '4. RNCA with intracranial thrombolytic treatment.', '5 PTA of MCA.', '6. Mesenteric venous thrombosis.', '7. Pericardial window.', '8. Cholecystectomy.', '9. Left thoracentesis.', 'FAMILY HISTORY:\\nNo family history of coronary artery disease, CVA, diabetes, CHF or MI.', 'The patient has one family member, a sister, with history of cancer.', 'SOCIAL HISTORY:\\nShe is married.', 'Employed with the US Post Office.', 'She is a mother of three.', 'Denies tobacco, alcohol or illicit drug use.', 'MEDICATIONS', '1. Coumadin 1 mg daily.', 'Last INR was on Tuesday, August 14, 2007, and her INR was 2.3.', '2. Amiodarone 100 mg p.o. daily.', 'REVIEW OF SYSTEMS:\\nComplete review of systems negative except as in pulmonary as noted above.', 'The patient also reports occasional numbness and tingling of her left arm.', 'PHYSICAL EXAMINATION\\nVITAL SIGNS: Blood pressure 123/95, heart rate 83, respirations 20, temperature 97, and oxygen saturation 97%.', 'GENERAL: Positive nonproductive cough and pain with coughing.', 'HEENT: Pupils are equal and reactive to light and accommodation.', 'Tympanic membranes are clear.', 'NECK: Supple.', 'No lymphadenopathy.', 'No masses.', 'RESPIRATORY: Pleural friction rub is noted.', 'GI: Soft, nondistended, and nontender.', 'Positive bowel sounds.', 'No organomegaly.', 'EXTREMITIES: No edema, no clubbing, no cyanosis, no tenderness.', 'Full range of motion.', 'Normal pulses in all extremities.', 'SKIN: No breakdown or lesions.', 'No ulcers.', 'NEUROLOGIC: Grossly intact.', 'No focal deficits.', 'Awake, alert, and oriented to person, place, and time.', 'LABORATORY DATA:\\nLabs are pending.', 'HOSPITAL COURSE:\\nThe patient was admitted for a right-sided pleural effusion for thoracentesis on Monday by Dr. X. Her Coumadin was placed on hold.', 'A repeat echocardiogram was checked.', 'She was started on prophylaxis for DVT with Lovenox 40 mg subcutaneously.', 'Her history dated back to March 2005 when she first sought medical attention for evidence of pericarditis, which was treated with pericardial window in an outside hospital, at that time she was also found to have mesenteric pain and thrombosis, is now anticoagulated.', 'Her pericardial fluid was accumulated and she was seen by Dr. Y. At that time, she was recommended for pericardectomy, which was performed by Dr. Z. Review of her CT scan from March 2006 prior to her pericardectomy, already shows bilateral plural effusions.', 'The patient improved clinically after the pericardectomy with resolution of her symptoms.', 'Recently, she was readmitted to the hospital with chest pain and found to have bilateral pleural effusion, the right greater than the left.', 'CT of the chest also revealed a large mediastinal lymph node.', 'We reviewed the pathology obtained from the pericardectomy in March 2006, which was diagnostic of mesothelioma.', 'At this time, chest tube placement for drainage of the fluid occurred and thoracoscopy with fluid biopsies, which were performed, which revealed epithelioid malignant mesothelioma.', 'The patient was then stained with a PET CT, which showed extensive uptake in the chest, bilateral pleural pericardial effusions, and lymphadenopathy.', 'She also had acidic fluid, pectoral and intramammary lymph nodes and uptake in L4 with SUV of', '4. This was consistent with stage III disease.', 'Her repeat echocardiogram showed an ejection fraction of 45% to 49%.', 'She was transferred to Oncology service and started on chemotherapy on September 1, 2007 with cisplatin 75 mg/centimeter squared equaling 109 mg IV piggyback over 2 hours on September 1, 2007, Alimta 500 mg/ centimeter squared equaling 730 mg IV piggyback over 10 minutes.', 'This was all initiated after a Port-A-Cath was placed.', 'The chemotherapy was well tolerated and the patient was discharged the following day after discontinuing IV fluid and IV.', 'Her Port-A-Cath was packed with heparin according to protocol.', 'DISCHARGE MEDICATIONS:\\nZofran, Phenergan, Coumadin, and Lovenox, and Vicodin\\nDISCHARGE INSTRUCTIONS:\\nShe was instructed to followup with Dr. XYZ in the office to check her INR on Tuesday.', 'She was instructed to call if she had any other questions or concerns in the interim.', 'Keywords:\\nhematology - oncology, mesothelioma, pleural effusion, atrial fibrillation, anemia, ascites, esophageal reflux, deep venous thrombosis, port-a-cath placement, port a cath, iv piggyback, venous thrombosis, atrial, thrombosis, pericardial, lymphadenopathy, fluid, pericardectomy, chest, pleural,'])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.select('sentence.result').take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5uBnSe0--_Tn",
    "outputId": "8028bf3d-b3fa-4be1-8ea1-99230ce9b14a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+-----+---+-------------------------+-------+------------+----------+\n",
      "|chunk                    |begin|end|ner_label                |sent_id|assertion   |confidence|\n",
      "+-------------------------+-----+---+-------------------------+-------+------------+----------+\n",
      "|Discharge                |68   |76 |Admission_Discharge      |0      |Past        |0.991     |\n",
      "|pleural effusion         |132  |147|Disease_Syndrome_Disorder|0      |Present     |1.0       |\n",
      "|anemia                   |171  |176|Disease_Syndrome_Disorder|0      |Family      |1.0       |\n",
      "|ascites                  |179  |185|Disease_Syndrome_Disorder|0      |Hypothetical|0.9782    |\n",
      "|esophageal reflux        |188  |204|Disease_Syndrome_Disorder|0      |Family      |1.0       |\n",
      "|deep venous thrombosis   |222  |243|Disease_Syndrome_Disorder|0      |Family      |1.0       |\n",
      "|Pleural effusion         |340  |355|Disease_Syndrome_Disorder|2      |Present     |1.0       |\n",
      "|anemia                   |379  |384|Disease_Syndrome_Disorder|2      |Present     |1.0       |\n",
      "|ascites                  |387  |393|Disease_Syndrome_Disorder|2      |Present     |1.0       |\n",
      "|esophageal reflux        |396  |412|Disease_Syndrome_Disorder|2      |Present     |1.0       |\n",
      "|deep venous thrombosis   |430  |451|Disease_Syndrome_Disorder|2      |Past        |0.9962    |\n",
      "|decortication of the lung|488  |512|Procedure                |4      |Past        |1.0       |\n",
      "|pleural biopsy           |519  |532|Procedure                |4      |Past        |1.0       |\n",
      "|thoracentesis            |587  |599|Procedure                |5      |Past        |1.0       |\n",
      "|Port-A-Cath placement    |625  |645|Procedure                |6      |Past        |1.0       |\n",
      "|cough                    |738  |742|Symptom                  |7      |SomeoneElse |0.8521    |\n",
      "|chest pain               |792  |801|Symptom                  |8      |Past        |1.0       |\n",
      "|fever                    |830  |834|VS_Finding               |8      |Present     |0.9997    |\n",
      "|pericarditis             |877  |888|Disease_Syndrome_Disorder|9      |Present     |0.9491    |\n",
      "|pericardectomy           |894  |907|Procedure                |9      |Past        |1.0       |\n",
      "+-------------------------+-----+---+-------------------------+-------+------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "result.select(F.explode(F.arrays_zip(result.ner_chunk.result,  \n",
    "                                     result.ner_chunk.begin, \n",
    "                                     result.ner_chunk.end, \n",
    "                                     result.ner_chunk.metadata, \n",
    "                                     result.assertion.result,\n",
    "                                     result.assertion.metadata)).alias(\"cols\")) \\\n",
    "      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
    "              F.expr(\"cols['1']\").alias(\"begin\"),\n",
    "              F.expr(\"cols['2']\").alias(\"end\"),\n",
    "              F.expr(\"cols['3']['entity']\").alias(\"ner_label\"),\n",
    "              F.expr(\"cols['3']['sentence']\").alias(\"sent_id\"),\n",
    "              F.expr(\"cols['4']\").alias(\"assertion\"),\n",
    "              F.expr(\"cols['5']['confidence']\").alias(\"confidence\") ).show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dYN97Es2be4p"
   },
   "source": [
    "### Pretrained `assertion_dl_radiology` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YMl2QAeNbe4p",
    "outputId": "cdcf11f8-4561-4873-8128-63c16b4527cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence_detector_dl_healthcare download started this may take some time.\n",
      "Approximate size to download 367.3 KB\n",
      "[ | ]sentence_detector_dl_healthcare download started this may take some time.\n",
      "Approximate size to download 367.3 KB\n",
      "Download done! Loading the resource.\n",
      "[OK!]\n",
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[OK!]\n",
      "ner_radiology download started this may take some time.\n",
      "[ | ]ner_radiology download started this may take some time.\n",
      "Approximate size to download 13.9 MB\n",
      "Download done! Loading the resource.\n",
      "[OK!]\n",
      "assertion_dl_radiology download started this may take some time.\n",
      "[ | ]assertion_dl_radiology download started this may take some time.\n",
      "Approximate size to download 1.3 MB\n",
      "Download done! Loading the resource.\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "documentAssembler = nlp.DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "# Sentence Detector annotator, processes various sentences per line\n",
    "sentenceDetector = nlp.SentenceDetectorDLModel\\\n",
    "    .pretrained(\"sentence_detector_dl_healthcare\",\"en\",\"clinical/models\") \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "# Tokenizer splits words in a relevant format for NLP\n",
    "tokenizer = nlp.Tokenizer()\\\n",
    "    .setInputCols([\"sentence\"])\\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "# Clinical word embeddings trained on PubMED dataset\n",
    "word_embeddings = nlp.WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n",
    "    .setInputCols([\"sentence\", \"token\"])\\\n",
    "    .setOutputCol(\"embeddings\")\n",
    "\n",
    "# NER model for radiology\n",
    "radiology_ner = medical.NerModel.pretrained(\"ner_radiology\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"ner\")\\\n",
    "    #.setIncludeAllConfidenceScores(False)\n",
    "\n",
    "ner_converter = medical.NerConverterInternal() \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"ner\"]) \\\n",
    "    .setOutputCol(\"ner_chunk\")\\\n",
    "    .setWhiteList([\"ImagingFindings\"])\n",
    "\n",
    "# Assertion model trained on radiology dataset\n",
    "radiology_assertion = medical.AssertionDLModel.pretrained(\"assertion_dl_radiology\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\", \"ner_chunk\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"assertion\")\n",
    "\n",
    "nlpPipeline = nlp.Pipeline(stages=[\n",
    "    documentAssembler, \n",
    "    sentenceDetector,\n",
    "    tokenizer,\n",
    "    word_embeddings,\n",
    "    radiology_ner,\n",
    "    ner_converter,\n",
    "    radiology_assertion\n",
    "    ])\n",
    "\n",
    "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "radiologyAssertion_model = nlpPipeline.fit(empty_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Ehm7WwJrbe4r"
   },
   "outputs": [],
   "source": [
    "# A sample text from a radiology report\n",
    "\n",
    "text = \"\"\"No right-sided pleural effusion or pneumothorax is definitively seen and there are mildly displaced fractures of the left lateral 8th and likely 9th ribs.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "_1iCxtKjbe4s"
   },
   "outputs": [],
   "source": [
    "data = spark.createDataFrame([[text]]).toDF(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "lSpEvzDObe4s"
   },
   "outputs": [],
   "source": [
    "result = radiologyAssertion_model.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fGxRCsusbe4s",
    "outputId": "f7d576c2-24e5-4db6-9d74-1b1bb9b5f145"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 28:======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------------+-------+---------+\n",
      "|chunk              |ner_label      |sent_id|assertion|\n",
      "+-------------------+---------------+-------+---------+\n",
      "|effusion           |ImagingFindings|0      |Negative |\n",
      "|pneumothorax       |ImagingFindings|0      |Negative |\n",
      "|displaced fractures|ImagingFindings|0      |Confirmed|\n",
      "+-------------------+---------------+-------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "result.select(F.explode(F.arrays_zip(result.ner_chunk.result, \n",
    "                                     result.ner_chunk.metadata, \n",
    "                                     result.assertion.result)).alias(\"cols\")) \\\n",
    "      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
    "              F.expr(\"cols['1']['entity']\").alias(\"ner_label\"),\n",
    "              F.expr(\"cols['1']['sentence']\").alias(\"sent_id\"),\n",
    "              F.expr(\"cols['2']\").alias(\"assertion\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0vWIDpk50QfG"
   },
   "source": [
    "# **Writing a generic Assertion + NER function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ltGPQYr60F6G"
   },
   "outputs": [],
   "source": [
    "def get_base_pipeline (embeddings = 'embeddings_clinical'):\n",
    "\n",
    "    documentAssembler = nlp.DocumentAssembler()\\\n",
    "        .setInputCol(\"text\")\\\n",
    "        .setOutputCol(\"document\")\n",
    "\n",
    "  # Sentence Detector annotator, processes various sentences per line\n",
    "    sentenceDetector = nlp.SentenceDetector()\\\n",
    "        .setInputCols([\"document\"])\\\n",
    "        .setOutputCol(\"sentence\")\n",
    "\n",
    "  # Tokenizer splits words in a relevant format for NLP\n",
    "    tokenizer = nlp.Tokenizer()\\\n",
    "        .setInputCols([\"sentence\"])\\\n",
    "        .setOutputCol(\"token\")\n",
    "\n",
    "  # Clinical word embeddings trained on PubMED dataset\n",
    "    word_embeddings = nlp.WordEmbeddingsModel.pretrained(embeddings, \"en\", \"clinical/models\")\\\n",
    "        .setInputCols([\"sentence\", \"token\"])\\\n",
    "        .setOutputCol(\"embeddings\")\n",
    "\n",
    "    base_pipeline = nlp.Pipeline(stages=[\n",
    "                        documentAssembler,\n",
    "                        sentenceDetector,\n",
    "                        tokenizer,\n",
    "                        word_embeddings])\n",
    "\n",
    "    return base_pipeline\n",
    "\n",
    "\n",
    "\n",
    "def get_clinical_assertion (embeddings, spark_df, nrows = 100, ner_model_name = 'ner_clinical', assertion_model_name=\"assertion_dl\"):\n",
    "\n",
    "  # NER model trained on i2b2 (sampled from MIMIC) dataset\n",
    "    loaded_ner_model = medical.NerModel.pretrained(ner_model_name, \"en\", \"clinical/models\") \\\n",
    "        .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "        .setOutputCol(\"ner\")\n",
    "\n",
    "    ner_converter = medical.NerConverterInternal() \\\n",
    "        .setInputCols([\"sentence\", \"token\", \"ner\"]) \\\n",
    "        .setOutputCol(\"ner_chunk\")\n",
    "\n",
    "  # Assertion model trained on i2b2 (sampled from MIMIC) dataset\n",
    "  # coming from sparknlp_jsl.annotator !!\n",
    "    clinical_assertion = medical.AssertionDLModel.pretrained(assertion_model_name, \"en\", \"clinical/models\") \\\n",
    "        .setInputCols([\"sentence\", \"ner_chunk\", \"embeddings\"]) \\\n",
    "        .setOutputCol(\"assertion\")\n",
    "      \n",
    "\n",
    "    base_model = get_base_pipeline (embeddings)\n",
    "\n",
    "    nlpPipeline = nlp.Pipeline(stages=[\n",
    "        base_model,\n",
    "        loaded_ner_model,\n",
    "        ner_converter,\n",
    "        clinical_assertion])\n",
    "\n",
    "    empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "    model = nlpPipeline.fit(empty_data)\n",
    "\n",
    "    result = model.transform(spark_df.limit(nrows))\n",
    "\n",
    "    result = result.withColumn(\"id\", F.monotonically_increasing_id())\n",
    "\n",
    "    result_df = result.select(F.explode(F.arrays_zip(result.ner_chunk.result, \n",
    "                                                     result.ner_chunk.metadata, \n",
    "                                                     result.assertion.result,\n",
    "                                                     result.assertion.metadata)).alias(\"cols\")) \\\n",
    "                      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
    "                              F.expr(\"cols['1']['entity']\").alias(\"ner_label\"),\n",
    "                              F.expr(\"cols['2']\").alias(\"assertion\"),\n",
    "                              F.expr(\"cols['3']['confidence']\").alias(\"confidence\"))\\\n",
    "                      .filter(\"ner_label!='O'\")\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V81zaAe13qLU",
    "outputId": "5f22e5f9-6ad0-4274-d82c-e927d5593c0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_clinical_large download started this may take some time.\n",
      "[ | ]ner_clinical_large download started this may take some time.\n",
      "Approximate size to download 13.9 MB\n",
      "Download done! Loading the resource.\n",
      "[OK!]\n",
      "assertion_dl download started this may take some time.\n",
      "[ | ]assertion_dl download started this may take some time.\n",
      "Approximate size to download 1.3 MB\n",
      "Download done! Loading the resource.\n",
      "[OK!]\n",
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[OK!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 38:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+---------+---------+----------+\n",
      "|                       chunk|ner_label|assertion|confidence|\n",
      "+----------------------------+---------+---------+----------+\n",
      "|                Mesothelioma|  PROBLEM|  present|    0.9996|\n",
      "|                Mesothelioma|  PROBLEM|  present|    0.9996|\n",
      "|            pleural effusion|  PROBLEM|  present|    0.9998|\n",
      "|         atrial fibrillation|  PROBLEM|  present|       1.0|\n",
      "|                      anemia|  PROBLEM|  present|    0.9999|\n",
      "|                     ascites|  PROBLEM|  present|    0.9999|\n",
      "|           esophageal reflux|  PROBLEM|  present|    0.9999|\n",
      "|      deep venous thrombosis|  PROBLEM|  present|    0.8533|\n",
      "|                Mesothelioma|  PROBLEM|  present|    0.9992|\n",
      "|            Pleural effusion|  PROBLEM|  present|    0.9999|\n",
      "|         atrial fibrillation|  PROBLEM|  present|       1.0|\n",
      "|                      anemia|  PROBLEM|  present|    0.9999|\n",
      "|                     ascites|  PROBLEM|  present|    0.9998|\n",
      "|           esophageal reflux|  PROBLEM|  present|    0.9999|\n",
      "|      deep venous thrombosis|  PROBLEM|  present|    0.8612|\n",
      "|   decortication of the lung|TREATMENT|  present|       1.0|\n",
      "|              pleural biopsy|     TEST|  present|    0.9924|\n",
      "|    transpleural fluoroscopy|     TEST|  present|    0.9945|\n",
      "|               thoracentesis|TREATMENT|  present|    0.9998|\n",
      "|       Port-A-Cath placement|TREATMENT|  present|       1.0|\n",
      "|       a nonproductive cough|  PROBLEM|  present|    0.9985|\n",
      "|      right-sided chest pain|  PROBLEM|  present|    0.9998|\n",
      "|                       fever|  PROBLEM|  present|    0.9997|\n",
      "|                pericarditis|  PROBLEM|  present|    0.9998|\n",
      "|              pericardectomy|TREATMENT|  present|    0.9999|\n",
      "|                       cough|  PROBLEM|  present|    0.9999|\n",
      "|      right-sided chest pain|  PROBLEM|  present|    0.9999|\n",
      "|                 Chest x-ray|     TEST|  present|    0.9999|\n",
      "|right-sided pleural effusion|  PROBLEM|  present|    0.9999|\n",
      "|              Pericardectomy|TREATMENT|  present|    0.9985|\n",
      "+----------------------------+---------+---------+----------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "embeddings = 'embeddings_clinical'\n",
    "\n",
    "ner_model_name = 'ner_clinical_large'\n",
    "\n",
    "nrows = 100\n",
    "\n",
    "ner_df = get_clinical_assertion (embeddings, mt_samples_df, nrows, ner_model_name)\n",
    "\n",
    "ner_df.show(30,truncate=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LmLPlfCw5hh-",
    "outputId": "87c83656-5714-440f-d4ff-f73f6ed73907"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_posology download started this may take some time.\n",
      "[ | ]ner_posology download started this may take some time.\n",
      "Approximate size to download 13.8 MB\n",
      "Download done! Loading the resource.\n",
      "[OK!]\n",
      "assertion_dl download started this may take some time.\n",
      "[OK!]\n",
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[OK!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 45:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+------------+----------+\n",
      "|           chunk|ner_label|   assertion|confidence|\n",
      "+----------------+---------+------------+----------+\n",
      "|        Coumadin|     DRUG|hypothetical|    0.8709|\n",
      "|            1 mg| STRENGTH| conditional|    0.7772|\n",
      "|           daily|FREQUENCY| conditional|    0.5086|\n",
      "|      Amiodarone|     DRUG|hypothetical|    0.8589|\n",
      "|          100 mg| STRENGTH|hypothetical|    0.6143|\n",
      "|             p.o|    ROUTE|hypothetical|    0.7991|\n",
      "|           daily|FREQUENCY|     present|    0.9074|\n",
      "|        Coumadin|     DRUG|     present|    0.9999|\n",
      "|         Lovenox|     DRUG|     present|    0.9994|\n",
      "|           40 mg| STRENGTH|     present|    0.9982|\n",
      "|  subcutaneously|    ROUTE|     present|    0.9302|\n",
      "|    chemotherapy|     DRUG|     present|    0.9994|\n",
      "|       cisplatin|     DRUG|     present|    0.9995|\n",
      "|75 mg/centimeter| STRENGTH|     present|    0.9998|\n",
      "|          109 mg| STRENGTH|     present|    0.9999|\n",
      "|              IV|    ROUTE|     present|    0.9956|\n",
      "|       piggyback|     DRUG|     present|    0.9823|\n",
      "|    over 2 hours| DURATION|     present|       1.0|\n",
      "|       September|     DRUG|     present|    0.9531|\n",
      "|          Alimta|     DRUG|     present|    0.8248|\n",
      "+----------------+---------+------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "embeddings = 'embeddings_clinical'\n",
    "\n",
    "ner_model_name = 'ner_posology'\n",
    "\n",
    "nrows = 100\n",
    "\n",
    "ner_df = get_clinical_assertion (embeddings, mt_samples_df, nrows, ner_model_name)\n",
    "\n",
    "ner_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cQ9xeS3kwClE",
    "outputId": "b050b44f-fbd1-48ee-d013-b903b64d70e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_posology_greedy download started this may take some time.\n",
      "[ | ]ner_posology_greedy download started this may take some time.\n",
      "Approximate size to download 13.9 MB\n",
      "Download done! Loading the resource.\n",
      "[OK!]\n",
      "assertion_dl download started this may take some time.\n",
      "[OK!]\n",
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[OK!]\n",
      "+----------------+---------+---------+----------+\n",
      "|           chunk|ner_label|assertion|confidence|\n",
      "+----------------+---------+---------+----------+\n",
      "|capsule of Advil|     DRUG|   absent|    0.9855|\n",
      "+----------------+---------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embeddings = 'embeddings_clinical'\n",
    "\n",
    "ner_model_name = 'ner_posology_greedy'\n",
    "\n",
    "entry_data = spark.createDataFrame([[\"The patient did not take a capsule of Advil.\"]]).toDF(\"text\")\n",
    "\n",
    "ner_df = get_clinical_assertion (embeddings, entry_data, nrows, ner_model_name)\n",
    "\n",
    "ner_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "djV_FKNtYcoP",
    "outputId": "71ee07b2-e8a2-419c-fce2-8e44a01295e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_clinical download started this may take some time.\n",
      "[ | ]ner_clinical download started this may take some time.\n",
      "Approximate size to download 13.9 MB\n",
      "Download done! Loading the resource.\n",
      "[OK!]\n",
      "assertion_dl download started this may take some time.\n",
      "[OK!]\n",
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[OK!]\n",
      "+-----+---------+---------+----------+\n",
      "|chunk|ner_label|assertion|confidence|\n",
      "+-----+---------+---------+----------+\n",
      "|fever|  PROBLEM|   absent|     0.998|\n",
      "+-----+---------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embeddings = 'embeddings_clinical'\n",
    "\n",
    "ner_model_name = 'ner_clinical'\n",
    "\n",
    "entry_data = spark.createDataFrame([[\"The patient has no fever\"]]).toDF(\"text\")\n",
    "\n",
    "ner_df = get_clinical_assertion (embeddings, entry_data, nrows, ner_model_name)\n",
    "\n",
    "ner_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "sbllagh66Q8X"
   },
   "outputs": [],
   "source": [
    "def get_clinical_assertion_light (light_model, text):\n",
    "\n",
    "  light_result = light_model.fullAnnotate(text)[0]\n",
    "\n",
    "  chunks=[]\n",
    "  entities=[]\n",
    "  status=[]\n",
    "  confidence=[]\n",
    "\n",
    "  for n,m in zip(light_result['ner_chunk'],light_result['assertion']):\n",
    "      \n",
    "      chunks.append(n.result)\n",
    "      entities.append(n.metadata['entity']) \n",
    "      status.append(m.result)\n",
    "      confidence.append(m.metadata['confidence'])\n",
    "          \n",
    "  df = pd.DataFrame({'chunks':chunks, 'entities':entities, 'assertion':status,'confidence':confidence})\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "GqKH9Mw98z4x",
    "outputId": "6bcf9f5b-acf4-413b-8749-5fab02fe43b6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning::Spark Session already created, some configs may not take.\n",
      "Warning::Spark Session already created, some configs may not take.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entities_ner_chunk</th>\n",
       "      <th>entities_ner_chunk_class</th>\n",
       "      <th>assertion</th>\n",
       "      <th>assertion_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fever</td>\n",
       "      <td>VS_Finding</td>\n",
       "      <td>Present</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sore throat</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Present</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stomach pain</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pain</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Hypothetical</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>short of breath</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Present</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>climbing a flight of stairs</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Present</td>\n",
       "      <td>0.9434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alzheimer</td>\n",
       "      <td>Disease_Syndrome_Disorder</td>\n",
       "      <td>Family</td>\n",
       "      <td>0.8136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            entities_ner_chunk   entities_ner_chunk_class     assertion  \\\n",
       "0                        fever                 VS_Finding       Present   \n",
       "0                  sore throat                    Symptom       Present   \n",
       "0                 stomach pain                    Symptom        Absent   \n",
       "0                         pain                    Symptom  Hypothetical   \n",
       "0              short of breath                    Symptom       Present   \n",
       "0  climbing a flight of stairs                    Symptom       Present   \n",
       "0                    Alzheimer  Disease_Syndrome_Disorder        Family   \n",
       "\n",
       "  assertion_confidence  \n",
       "0                  1.0  \n",
       "0                  1.0  \n",
       "0                  1.0  \n",
       "0                  1.0  \n",
       "0                  1.0  \n",
       "0               0.9434  \n",
       "0               0.8136  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinical_text = \"\"\"\n",
    "Patient with severe fever and sore throat. \n",
    "He shows no stomach pain and he maintained on an epidural and PCA for pain control.\n",
    "He also became short of breath with climbing a flight of stairs.\n",
    "After CT, lung tumor located at the right lower lobe. Father with Alzheimer.\n",
    "\"\"\"\n",
    "\n",
    "light_model = nlp.LightPipeline(model)\n",
    "\n",
    "# get_clinical_assertion_light (light_model, clinical_text)\n",
    "\n",
    "cols = [\n",
    "     'entities_ner_chunk',\n",
    "     'entities_ner_chunk_class', \n",
    "     'assertion',\n",
    "     'assertion_confidence']\n",
    "     \n",
    "df = nlp.nlu.to_pretty_df(light_model,clinical_text, output_level='chunk')[cols]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity Type Constraints\r\n",
    "\r\n",
    "\r\n",
    "You can effortlessly constrain assertions based on specific entity types using a convenient dictionary format: `{\"entity\": [assertion_label1, assertion_label2, .. assertion_labelN]}`. When an entity is not found in the dictionary, no constraints are applied, ensuring flexibility in your data processing. With the `setEntityAssertionCaseSensitive` parameter, you can control the case sensitivity for both entities and assertion labels. Unleash the full potential of your NLP model with these cutting-edge additions to the AssertionDLModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_clinical_large download started this may take some time.\n",
      "[OK!]\n",
      "assertion_jsl_augmented download started this may take some time.\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "# NER model trained on i2b2 (sampled from MIMIC) dataset\n",
    "clinical_ner = medical.NerModel.pretrained(\"ner_clinical_large\",\"en\",\"clinical/models\")\\\n",
    "    .setInputCols([\"sentence\",\"token\",\"embeddings\"])\\\n",
    "    .setOutputCol(\"ner\")\n",
    "\n",
    "ner_converter = medical.NerConverterInternal()\\\n",
    "    .setInputCols([\"sentence\",\"token\",\"ner\"])\\\n",
    "    .setOutputCol(\"ner_chunk\")\n",
    "\n",
    "# Assertion model trained on i2b2 (sampled from MIMIC) dataset\n",
    "clinical_assertion = medical.AssertionDLModel.pretrained(\"assertion_jsl_augmented\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\", \"ner_chunk\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"assertion\")\\\n",
    "    .setEntityAssertionCaseSensitive(False)\\\n",
    "    .setEntityAssertion({\n",
    "        \"PROBLEM\": [\"hypothetical\", \"absent\"],\n",
    "        \"treAtment\": [\"present\"],\n",
    "        \"TEST\": [\"Possible\"],\n",
    "    })\n",
    "\n",
    "nlpPipeline = nlp.Pipeline(\n",
    "    stages=[\n",
    "        documentAssembler,\n",
    "        sentenceDetector,\n",
    "        tokenizer,\n",
    "        word_embeddings,\n",
    "        clinical_ner,\n",
    "        ner_converter,\n",
    "        clinical_assertion\n",
    "])\n",
    "\n",
    "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "model = nlpPipeline.fit(empty_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''\n",
    "A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus (T2DM), one prior episode of HTG-induced pancreatitis three years prior to presentation, and associated with an acute hepatitis, presented with a one-week history of polyuria, poor appetite, and vomiting.\n",
    "She was on metformin, glipizide, and dapagliflozin for T2DM and atorvastatin and gemfibrozil for HTG. She had been on dapagliflozin for six months at the time of presentation.\n",
    "Physical examination on presentation was significant for dry oral mucosa ; significantly , her abdominal examination was benign with no tenderness, guarding, or rigidity. Pertinent laboratory findings on admission were: serum glucose 111 mg/dl,  creatinine 0.4 mg/dL, triglycerides 508 mg/dL, total cholesterol 122 mg/dL, and venous pH 7.27.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunks</th>\n",
       "      <th>entities</th>\n",
       "      <th>assertion</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>metformin</td>\n",
       "      <td>TREATMENT</td>\n",
       "      <td>Present</td>\n",
       "      <td>0.5364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>glipizide</td>\n",
       "      <td>TREATMENT</td>\n",
       "      <td>Present</td>\n",
       "      <td>0.9993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dapagliflozin</td>\n",
       "      <td>TREATMENT</td>\n",
       "      <td>Present</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HTG</td>\n",
       "      <td>PROBLEM</td>\n",
       "      <td>Hypothetical</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Physical examination</td>\n",
       "      <td>TEST</td>\n",
       "      <td>Possible</td>\n",
       "      <td>0.943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tenderness</td>\n",
       "      <td>PROBLEM</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>guarding</td>\n",
       "      <td>PROBLEM</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rigidity</td>\n",
       "      <td>PROBLEM</td>\n",
       "      <td>Hypothetical</td>\n",
       "      <td>0.9999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 chunks   entities     assertion confidence\n",
       "0             metformin  TREATMENT       Present     0.5364\n",
       "1             glipizide  TREATMENT       Present     0.9993\n",
       "2         dapagliflozin  TREATMENT       Present        1.0\n",
       "3                   HTG    PROBLEM  Hypothetical        1.0\n",
       "4  Physical examination       TEST      Possible      0.943\n",
       "5            tenderness    PROBLEM        Absent        1.0\n",
       "6              guarding    PROBLEM        Absent        1.0\n",
       "7              rigidity    PROBLEM  Hypothetical     0.9999"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "light_model = nlp.LightPipeline(model)\n",
    "\n",
    "light_result = light_model.fullAnnotate(text)\n",
    "\n",
    "chunks=[]\n",
    "entities=[]\n",
    "status=[]\n",
    "confidence=[]\n",
    "\n",
    "for assertion_row in light_result[0][\"assertion\"]:\n",
    "  chunk_id = assertion_row.metadata[\"chunk\"]\n",
    "  for chunk_row in light_result[0][\"ner_chunk\"]:\n",
    "    if chunk_id == chunk_row.metadata[\"chunk\"]:\n",
    "        chunks.append(chunk_row.result)\n",
    "        entities.append(chunk_row.metadata['entity'])\n",
    "        status.append(assertion_row.result)\n",
    "        confidence.append(assertion_row.metadata['confidence'])\n",
    "\n",
    "df = pd.DataFrame({'chunks':chunks, 'entities':entities, 'assertion':status, 'confidence':confidence})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assertion Filterer\r\n",
    "AssertionFilterer will allow you to filter out the named entities by the list of acceptable assertion statuses by using method `setWhiteList()` or to exlude some entityes by using `.setBlackList()` method. This annotator would be quite handy if you want to set a white list / black list for the acceptable assertion statuses like present or conditional; or  put into black list if you dont want absent conditions get out of your pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[OK!]\n",
      "ner_clinical download started this may take some time.\n",
      "[OK!]\n",
      "assertion_jsl download started this may take some time.\n",
      "[ | ]assertion_jsl download started this may take some time.\n",
      "Approximate size to download 1.4 MB\n",
      "Download done! Loading the resource.\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "# Annotator that transforms a text column from dataframe into an Annotation ready for NLP\n",
    "\n",
    "documentAssembler = nlp.DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "# Sentence Detector annotator, processes various sentences per line\n",
    "sentenceDetector = nlp.SentenceDetector()\\\n",
    "    .setInputCols([\"document\"])\\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "# Tokenizer splits words in a relevant format for NLP\n",
    "tokenizer = nlp.Tokenizer()\\\n",
    "    .setInputCols([\"sentence\"])\\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "# Clinical word embeddings trained on PubMED dataset\n",
    "word_embeddings = nlp.WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n",
    "    .setInputCols([\"sentence\", \"token\"])\\\n",
    "    .setOutputCol(\"embeddings\")\n",
    "\n",
    "clinical_ner = medical.NerModel.pretrained(\"ner_clinical\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"ner\")\\\n",
    "    #.setIncludeAllConfidenceScores(False)\n",
    "\n",
    "ner_converter = medical.NerConverterInternal() \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"ner\"]) \\\n",
    "    .setOutputCol(\"ner_chunk\")\\\n",
    "    .setWhiteList([\"PROBLEM\", \"TEST\",\"TREATMENT\"])\n",
    "\n",
    "clinical_assertion = medical.AssertionDLModel.pretrained(\"assertion_jsl\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\", \"ner_chunk\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"assertion\")\n",
    "\n",
    "assertion_filterer = medical.AssertionFilterer()\\\n",
    "    .setInputCols(\"sentence\",\"ner_chunk\",\"assertion\")\\\n",
    "    .setOutputCol(\"assertion_filtered\")\\\n",
    "    .setCaseSensitive(False)\\\n",
    "    .setWhiteList([\"Present\"])\n",
    "#or .setBlackList([[\"absent\"]])\n",
    "\n",
    "nlpPipeline = nlp.Pipeline(stages=[\n",
    "      documentAssembler,\n",
    "      sentenceDetector,\n",
    "      tokenizer,\n",
    "      word_embeddings,\n",
    "      clinical_ner,\n",
    "      ner_converter,\n",
    "      clinical_assertion,\n",
    "      assertion_filterer\n",
    "    ])\n",
    "\n",
    "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "assertionFilter_model = nlpPipeline.fit(empty_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['assertion_filtered', 'document', 'ner_chunk', 'assertion', 'token', 'ner', 'embeddings', 'sentence'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Patient has a headache for the last 2 weeks, needs to get a head CT, and appears anxious when she walks fast. Alopecia noted. She denies pain.'\n",
    "\n",
    "light_model = nlp.LightPipeline(assertionFilter_model)\n",
    "light_result = light_model.annotate(text)\n",
    "\n",
    "light_result.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a headache', 'Present'),\n",
       " ('a head CT', 'Hypothetical'),\n",
       " ('anxious', 'Possible'),\n",
       " ('Alopecia', 'Present'),\n",
       " ('pain', 'Absent')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(light_result['ner_chunk'], light_result['assertion']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Present']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assertion_filterer.getWhiteList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunks</th>\n",
       "      <th>entities</th>\n",
       "      <th>assertion</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a headache</td>\n",
       "      <td>PROBLEM</td>\n",
       "      <td>Present</td>\n",
       "      <td>0.97150004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alopecia</td>\n",
       "      <td>PROBLEM</td>\n",
       "      <td>Present</td>\n",
       "      <td>0.9949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       chunks entities assertion  confidence\n",
       "0  a headache  PROBLEM   Present  0.97150004\n",
       "1    Alopecia  PROBLEM   Present      0.9949"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks=[]\n",
    "entities=[]\n",
    "status=[]\n",
    "confidence=[]\n",
    "\n",
    "light_result = light_model.fullAnnotate(text)[0]\n",
    "\n",
    "for m in light_result['assertion_filtered']:\n",
    "\n",
    "    chunks.append(m.result)\n",
    "    entities.append(m.metadata['entity'])\n",
    "    status.append(m.metadata['assertion'])\n",
    "    confidence.append(m.metadata['confidence'])\n",
    "\n",
    "df = pd.DataFrame({'chunks':chunks, 'entities':entities, 'assertion':status, 'confidence':confidence})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see, there is no \"pain\" chunk since it has \"absent\" assertion label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oncological Assertion Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oncology Assertion Models\n",
    "\n",
    "|    | model_name              |Predicted Entities|\n",
    "|---:|:------------------------|-|\n",
    "| 1 | [assertion_oncology_wip](https://nlp.johnsnowlabs.com/2022/10/11/assertion_oncology_wip_en.html) | Medical_History, Family_History, Possible, Hypothetical_Or_Absent|\n",
    "| 2 | [assertion_oncology_problem_wip](https://nlp.johnsnowlabs.com/2022/10/11/assertion_oncology_problem_wip_en.html) |Present, Possible, Hypothetical, Absent, Family|\n",
    "| 3 | [assertion_oncology_treatment_wip](https://nlp.johnsnowlabs.com/2022/10/11/assertion_oncology_treatment_binary_wip_en.html) |Present, Planned, Past, Hypothetical, Absent|\n",
    "| 3 | [assertion_oncology_treatment_wip]() |Present, Planned, Past, Hypothetical, Absent|\n",
    "| 4 | [assertion_oncology_response_to_treatment_wip](https://nlp.johnsnowlabs.com/2022/10/11/assertion_oncology_response_to_treatment_wip_en.html) |Present_Or_Past, Hypothetical_Or_Absent|\n",
    "| 5 | [assertion_oncology_test_binary_wip](https://nlp.johnsnowlabs.com/2022/10/01/assertion_oncology_test_binary_wip_en.html) |Present_Or_Past, Hypothetical_Or_Absent|\n",
    "| 6 | [assertion_oncology_smoking_status_wip](https://nlp.johnsnowlabs.com/2022/10/11/assertion_oncology_smoking_status_wip_en.html) |Absent, Past, Present|\n",
    "| 7 | [assertion_oncology_family_history_wip](https://nlp.johnsnowlabs.com/2022/10/11/assertion_oncology_family_history_wip_en.html) |Family_History, Other|\n",
    "| 8 | [assertion_oncology_demographic_binary_wip](https://nlp.johnsnowlabs.com/2022/10/11/assertion_oncology_demographic_binary_wip_en.html) |Patient, Someone_Else|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_oncology_wip download started this may take some time.\n",
      "[ | ]ner_oncology_wip download started this may take some time.\n",
      "Approximate size to download 969.3 KB\n",
      "Download done! Loading the resource.\n",
      "[OK!]\n",
      "assertion_oncology_wip download started this may take some time.\n",
      "[ | ]assertion_oncology_wip download started this may take some time.\n",
      "Approximate size to download 1.4 MB\n",
      "Download done! Loading the resource.\n",
      "[OK!]\n",
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[OK!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 74:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+--------------------+------------+----------+\n",
      "|chunk                   |ner_label           |assertion   |confidence|\n",
      "+------------------------+--------------------+------------+----------+\n",
      "|Mesothelioma            |Cancer_Dx           |Present     |0.9885    |\n",
      "|Mesothelioma            |Cancer_Dx           |Hypothetical|0.981     |\n",
      "|August 24, 2007         |Date                |Past        |0.9726    |\n",
      "|decortication           |Cancer_Surgery      |Past        |0.994     |\n",
      "|lung                    |Site_Lung           |Past        |0.9453    |\n",
      "|pleural                 |Site_Other_Body_Part|Past        |0.9624    |\n",
      "|biopsy                  |Pathology_Test      |Past        |0.9979    |\n",
      "|transpleural fluoroscopy|Imaging_Test        |Past        |0.9979    |\n",
      "|August 20, 2007         |Date                |Past        |0.956     |\n",
      "|August 31, 2007         |Date                |Past        |0.9925    |\n",
      "|41-year-old             |Gender              |Present     |0.9986    |\n",
      "|Vietnamese              |Race_Ethnicity      |Present     |0.8024    |\n",
      "|female                  |Gender              |Present     |0.9772    |\n",
      "|started last week       |Relative_Date       |Present     |0.9831    |\n",
      "|She                     |Gender              |Present     |0.9992    |\n",
      "|her                     |Gender              |Present     |0.9944    |\n",
      "|She                     |Gender              |Present     |0.9993    |\n",
      "|pericardectomy          |Cancer_Surgery      |Past        |0.997     |\n",
      "|May 2006                |Date                |Past        |0.9971    |\n",
      "|Chest x-ray             |Imaging_Test        |Past        |0.9984    |\n",
      "+------------------------+--------------------+------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "embeddings = 'embeddings_clinical'\n",
    "\n",
    "ner_model_name = 'ner_oncology_wip'\n",
    "\n",
    "assertion_model_name='assertion_oncology_wip'\n",
    "\n",
    "nrows = 100\n",
    "\n",
    "ner_df = get_clinical_assertion (embeddings, mt_samples_df, nrows, ner_model_name,assertion_model_name )\n",
    "\n",
    "ner_df.show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voice of Patient Assertion Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\r\n",
    "\r\n",
    "|    | model_name              |Predicted Entities|\r\n",
    "|---:|:------------------------|-|\r\n",
    "| 1        | [assertion_vop_clinical](https://nlp.johnsnowlabs.com/2023/08/17/assertion_vop_clinical_en.html)     | Hypothetical_Or_Absent, Present_Or_Past, SomeoneElse |\r\n",
    "| 2          | [assertion_vop_clinical_medium](https://nlp.johnsnowlabs.com/2023/08/17/assertion_vop_clinical_medium_en.html)       | Hypothetical_Or_Absent, Present_Or_Past, SomeoneElse |\r\n",
    "| 3          | [assertion_vop_clinical_large](https://nlp.johnsnowlabs.com/2023/08/17/assertion_vop_clinical_large_en.html)       | Hypothetical_Or_Absent, Present_Or_Past, SomeoneElse |\r\n",
    "|||\r\n",
    "\r\n",
    "\r\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Assertion status model](https://nlp.johnsnowlabs.com/2023/08/17/assertion_vop_clinical_en.html) used to predict if an NER chunk refers to a positive finding from the patient (Present_Or_Past), or if it refers to a family member or another person (SomeoneElse) or if it is mentioned but not as something present (Hypothetical_Or_Absent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence_detector_dl_healthcare download started this may take some time.\n",
      "Approximate size to download 367.3 KB\n",
      "[OK!]\n",
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[OK!]\n",
      "ner_vop download started this may take some time.\n",
      "[ | ]ner_vop download started this may take some time.\n",
      "Approximate size to download 3.7 MB\n",
      "Download done! Loading the resource.\n",
      "[OK!]\n",
      "assertion_vop_clinical download started this may take some time.\n",
      "[ | ]assertion_vop_clinical download started this may take some time.\n",
      "Approximate size to download 919.9 KB\n",
      "Download done! Loading the resource.\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "document_assembler = nlp.DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "sentence_detector = nlp.SentenceDetectorDLModel.pretrained(\"sentence_detector_dl_healthcare\", \"en\", \"clinical/models\")\\\n",
    "    .setInputCols([\"document\"])\\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "tokenizer = nlp.Tokenizer() \\\n",
    "    .setInputCols([\"sentence\"]) \\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "word_embeddings = nlp.WordEmbeddingsModel().pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n",
    "    .setInputCols([\"sentence\", \"token\"]) \\\n",
    "    .setOutputCol(\"embeddings\")\n",
    "\n",
    "ner = medical.NerModel.pretrained(\"ner_vop\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"ner\")\n",
    "\n",
    "ner_converter = medical.NerConverterInternal() \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"ner\"]) \\\n",
    "    .setOutputCol(\"ner_chunk\")\\\n",
    "    .setBlackList(['DATETIME',  'GENDER', 'AGE', 'SUBSTANCEQUANTITY','FORM', 'ADMISSIONDISCHARGE', 'TESTRESULT', 'TEST',\n",
    "                  'MEDICALDEVICE','CLINICALDEPT','DRUG', 'ROUTE', 'DURATION',\"DOSAGE\",'FREQUENCY', 'BODYPART',\n",
    "                   ])\n",
    "\n",
    "assertion = medical.AssertionDLModel.pretrained(\"assertion_vop_clinical\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\", \"ner_chunk\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"assertion\")\n",
    "\n",
    "pipeline = nlp.Pipeline(\n",
    "    stages=[document_assembler,\n",
    "    sentence_detector,\n",
    "    tokenizer,\n",
    "    word_embeddings,\n",
    "    ner,\n",
    "    ner_converter,\n",
    "    assertion\n",
    "])\n",
    "\n",
    "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "vop_pipeline_model = pipeline.fit(empty_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hypothetical_Or_Absent', 'Present_Or_Past', 'SomeoneElse']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assertion.getClasses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = '''Hello, I am a 20-year-old woman who was diagnosed with hyperthyroidism around a month ago. For approximately four months, I've been experiencing symptoms such as feeling light-headed, battling poor digestion, dealing with anxiety attacks, depression, a sharp pain on my left side chest, an elevated heart rate, and a significant loss of weight. Due to these conditions, I was admitted to the hospital and just got discharged recently. During my hospital stay, a number of different tests were carried out by various physicians who initially struggled to pinpoint my actual medical condition. These tests included numerous blood tests, a brain MRI, an ultrasound scan, and an endoscopy. At long last, I was examined by a homeopathic doctor who finally diagnosed me with hyperthyroidism, indicating my TSH level was at a low 0.15 while my T3 and T4 levels were normal. Additionally, I was found to be deficient in vitamins B12 and D. Hence, I've been on a regimen of vitamin D supplements once a week and a daily dose of 1000 mcg of vitamin B12. I've been undergoing homeopathic treatment for the last 40 days and underwent a second test after a month which showed my TSH level increased to 0.5. While I'm noticing a slight improvement in my feelings of weakness and depression, over the last week, I've encountered two new challenges: difficulty breathing and a dramatically increased heart rate. I'm now at a crossroads where I am unsure if I should switch to allopathic treatment or continue with homeopathy. I understand that thyroid conditions take a while to improve, but I'm wondering if both treatments would require the same duration for recovery. Several of my acquaintances have recommended transitioning to allopathy and warn against taking risks, given the potential of developing severe complications. Please forgive any errors in my English and thank you for your understanding.'''\n",
    "\n",
    "light_model = nlp.LightPipeline(vop_pipeline_model)\n",
    "\n",
    "light_result = light_model.fullAnnotate(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    @import url('https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700&display=swap');\n",
       "    @import url('https://fonts.googleapis.com/css2?family=Vistol Regular:wght@300;400;500;600;700&display=swap');\n",
       "    \n",
       "    .spark-nlp-display-scroll-entities {\n",
       "        border: 1px solid #E7EDF0;\n",
       "        border-radius: 3px;\n",
       "        text-align: justify;\n",
       "        \n",
       "    }\n",
       "    .spark-nlp-display-scroll-entities span {  \n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        color: #536B76;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "    }\n",
       "    \n",
       "    .spark-nlp-display-entity-wrapper{\n",
       "    \n",
       "        display: inline-grid;\n",
       "        text-align: center;\n",
       "        border-radius: 4px;\n",
       "        margin: 0 2px 5px 2px;\n",
       "        padding: 1px\n",
       "    }\n",
       "    .spark-nlp-display-entity-name{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "        \n",
       "        background: #f1f2f3;\n",
       "        border-width: medium;\n",
       "        text-align: center;\n",
       "        \n",
       "        font-weight: 400;\n",
       "        \n",
       "        border-radius: 5px;\n",
       "        padding: 2px 5px;\n",
       "        display: block;\n",
       "        margin: 3px 2px;\n",
       "    \n",
       "    }\n",
       "    .spark-nlp-display-entity-type{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        color: #ffffff;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "        \n",
       "        text-transform: uppercase;\n",
       "        \n",
       "        font-weight: 500;\n",
       "\n",
       "        display: block;\n",
       "        padding: 3px 5px;\n",
       "    }\n",
       "    \n",
       "    .spark-nlp-display-entity-resolution{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        color: #ffffff;\n",
       "        font-family: 'Vistol Regular', sans-serif !important;\n",
       "        \n",
       "        text-transform: uppercase;\n",
       "        \n",
       "        font-weight: 500;\n",
       "\n",
       "        display: block;\n",
       "        padding: 3px 5px;\n",
       "    }\n",
       "    \n",
       "    .spark-nlp-display-others{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "        \n",
       "        font-weight: 400;\n",
       "    }\n",
       "\n",
       "</style>\n",
       " <span class=\"spark-nlp-display-others\" style=\"background-color: white\">Hello, I am a 20-year-old woman who was diagnosed with </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #A5AD20B3\"><span class=\"spark-nlp-display-entity-name\">hyperthyroidism </span><span class=\"spark-nlp-display-entity-type\">Disease</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #A5AD20FF\">Present_Or_Past </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> around a month ago. For approximately four months, I've been experiencing symptoms such as feeling </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #445F5BB3\"><span class=\"spark-nlp-display-entity-name\">light-headed </span><span class=\"spark-nlp-display-entity-type\">Symptom</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #445F5BFF\">Present_Or_Past </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, battling poor digestion, dealing with </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #3CA356B3\"><span class=\"spark-nlp-display-entity-name\">anxiety attacks </span><span class=\"spark-nlp-display-entity-type\">PsychologicalCondition</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #3CA356FF\">Present_Or_Past </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #3CA356B3\"><span class=\"spark-nlp-display-entity-name\">depression </span><span class=\"spark-nlp-display-entity-type\">PsychologicalCondition</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #3CA356FF\">Present_Or_Past </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, a </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #8B475DB3\"><span class=\"spark-nlp-display-entity-name\">sharp </span><span class=\"spark-nlp-display-entity-type\">Modifier</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #8B475DFF\">Present_Or_Past </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #445F5BB3\"><span class=\"spark-nlp-display-entity-name\">pain </span><span class=\"spark-nlp-display-entity-type\">Symptom</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #445F5BFF\">Present_Or_Past </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> on my </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #7A889CB3\"><span class=\"spark-nlp-display-entity-name\">left side </span><span class=\"spark-nlp-display-entity-type\">Laterality</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #7A889CFF\">Present_Or_Past </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> chest, an elevated </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #B1202BB3\"><span class=\"spark-nlp-display-entity-name\">heart rate </span><span class=\"spark-nlp-display-entity-type\">VitalTest</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #B1202BFF\">Present_Or_Past </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, and a </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #8B475DB3\"><span class=\"spark-nlp-display-entity-name\">significant </span><span class=\"spark-nlp-display-entity-type\">Modifier</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #8B475DFF\">Present_Or_Past </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #445F5BB3\"><span class=\"spark-nlp-display-entity-name\">loss of weight </span><span class=\"spark-nlp-display-entity-type\">Symptom</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #445F5BFF\">Hypothetical_Or_Absent </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">. Due to these conditions, I was admitted to the hospital and just got discharged recently. During my hospital stay, a number of different tests were carried out by various </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #7F3C9AB3\"><span class=\"spark-nlp-display-entity-name\">physicians </span><span class=\"spark-nlp-display-entity-type\">Employment</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #7F3C9AFF\">SomeoneElse </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> who initially struggled to pinpoint my actual medical condition. These tests included numerous blood tests, a brain MRI, an ultrasound scan, and an </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #7A3A81B3\"><span class=\"spark-nlp-display-entity-name\">endoscopy </span><span class=\"spark-nlp-display-entity-type\">Procedure</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #7A3A81FF\">Present_Or_Past </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">. At long last, I was examined by a </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #7F3C9AB3\"><span class=\"spark-nlp-display-entity-name\">homeopathic doctor </span><span class=\"spark-nlp-display-entity-type\">Employment</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #7F3C9AFF\">SomeoneElse </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> who finally diagnosed me with </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #A5AD20B3\"><span class=\"spark-nlp-display-entity-name\">hyperthyroidism </span><span class=\"spark-nlp-display-entity-type\">Disease</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #A5AD20FF\">Present_Or_Past </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, indicating my TSH level was at a low 0.15 while my T3 and T4 levels were normal. Additionally, I was found to be </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #A5AD20B3\"><span class=\"spark-nlp-display-entity-name\">deficient </span><span class=\"spark-nlp-display-entity-type\">Disease</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #A5AD20FF\">Hypothetical_Or_Absent </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> in vitamins B12 and D. Hence, I've been on a regimen of vitamin D supplements once a week and a daily dose of 1000 mcg of vitamin B12. I've been undergoing </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #8b6673B3\"><span class=\"spark-nlp-display-entity-name\">homeopathic treatment </span><span class=\"spark-nlp-display-entity-type\">Treatment</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #8b6673FF\">Present_Or_Past </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> for the last 40 days and underwent a second test after a month which showed my TSH level increased to 0.5. While I'm noticing a slight improvement in my feelings of </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #445F5BB3\"><span class=\"spark-nlp-display-entity-name\">weakness </span><span class=\"spark-nlp-display-entity-type\">Symptom</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #445F5BFF\">Present_Or_Past </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> and </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #3CA356B3\"><span class=\"spark-nlp-display-entity-name\">depression </span><span class=\"spark-nlp-display-entity-type\">PsychologicalCondition</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #3CA356FF\">Present_Or_Past </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, over the last week, I've encountered two new challenges: </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #445F5BB3\"><span class=\"spark-nlp-display-entity-name\">difficulty breathing </span><span class=\"spark-nlp-display-entity-type\">Symptom</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #445F5BFF\">Present_Or_Past </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> and a dramatically increased </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #B1202BB3\"><span class=\"spark-nlp-display-entity-name\">heart rate </span><span class=\"spark-nlp-display-entity-type\">VitalTest</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #B1202BFF\">Present_Or_Past </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">. I'm now at a crossroads where I am unsure if I should switch to </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #8b6673B3\"><span class=\"spark-nlp-display-entity-name\">allopathic treatment </span><span class=\"spark-nlp-display-entity-type\">Treatment</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #8b6673FF\">Hypothetical_Or_Absent </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> or continue with </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #8b6673B3\"><span class=\"spark-nlp-display-entity-name\">homeopathy </span><span class=\"spark-nlp-display-entity-type\">Treatment</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #8b6673FF\">Hypothetical_Or_Absent </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">. I understand that thyroid conditions take a while to improve, but I'm wondering if both treatments would require the same duration for recovery. Several of my acquaintances have recommended transitioning to allopathy and warn against taking risks, given the potential of developing severe complications. Please forgive any errors in my English and thank you for your understanding.</span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vis = nlp.viz.AssertionVisualizer()\n",
    "\n",
    "vis.display(light_result[0], 'ner_chunk', 'assertion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social Determinant of Health Assertion Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\r\n",
    "\r\n",
    "|    | model_name              |Predicted Entities|\r\n",
    "|---------------|----------------------|---|\r\n",
    "| 1        | [assertion_sdoh_wip](https://nlp.johnsnowlabs.com/2023/08/13/assertion_sdoh_wip_en.html)     | `Present`, `Absent`, `Someone_Else`, `Past`, `Hypothetical`, `Possible` |\r\n",
    "\r\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence_detector_dl download started this may take some time.\n",
      "Approximate size to download 354.6 KB\n",
      "[ | ]sentence_detector_dl download started this may take some time.\n",
      "Approximate size to download 354.6 KB\n",
      "Download done! Loading the resource.\n",
      "[OK!]\n",
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[OK!]\n",
      "ner_sdoh download started this may take some time.\n",
      "[ | ]ner_sdoh download started this may take some time.\n",
      "Approximate size to download 2.8 MB\n",
      "Download done! Loading the resource.\n",
      "[OK!]\n",
      "assertion_sdoh_wip download started this may take some time.\n",
      "[ | ]assertion_sdoh_wip download started this may take some time.\n",
      "Approximate size to download 10.3 MB\n",
      "Download done! Loading the resource.\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "document_assembler = nlp.DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "sentence_detector = nlp.SentenceDetectorDLModel.pretrained(\"sentence_detector_dl\", \"en\")\\\n",
    "    .setInputCols([\"document\"])\\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "tokenizer = nlp.Tokenizer()\\\n",
    "    .setInputCols([\"sentence\"])\\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "clinical_embeddings = nlp.WordEmbeddingsModel.pretrained('embeddings_clinical', \"en\", \"clinical/models\")\\\n",
    "    .setInputCols([\"sentence\", \"token\"])\\\n",
    "    .setOutputCol(\"embeddings\")\n",
    "\n",
    "ner_model = medical.NerModel.pretrained(\"ner_sdoh\", \"en\", \"clinical/models\")\\\n",
    "    .setInputCols([\"sentence\", \"token\",\"embeddings\"])\\\n",
    "    .setOutputCol(\"ner\")\n",
    "\n",
    "ner_converter = medical.NerConverterInternal()\\\n",
    "    .setInputCols(['sentence', 'token', 'ner'])\\\n",
    "    .setOutputCol('ner_chunk')\\\n",
    "    .setBlackList(['Age','Gender','Language','Healthcare_Institution'])   # I dont need these assertion of entities\n",
    "\n",
    "assertion = medical.AssertionDLModel.pretrained(\"assertion_sdoh_wip\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\", \"ner_chunk\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"assertion\")\n",
    "\n",
    "pipeline = nlp.Pipeline(\n",
    "    stages=[\n",
    "        document_assembler,\n",
    "        sentence_detector,\n",
    "        tokenizer,\n",
    "        clinical_embeddings,\n",
    "        ner_model,\n",
    "        ner_converter,\n",
    "        assertion\n",
    "])\n",
    "\n",
    "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "sdoh_pipeline_model = pipeline.fit(empty_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Absent', 'Present', 'Someone_Else', 'Past', 'Hypothetical', 'Possible']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assertion.getClasses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text= [\n",
    "\"\"\"Smith works as a cleaning assistant and does not have access to health insurance or paid sick leave.\n",
    "But she has generally housing problems. She lives in a apartment now.  She has long history of EtOH abuse, beginning in her teens.\n",
    "She is aware she needs to attend Rehab Programs. She had DUI back in April and was due to be in court this week.\n",
    "Her partner is an alcoholic and a drug abuser for the last 5 years.\n",
    "She also mentioned feeling socially isolated and lack of a strong support system \"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "light_model = nlp.LightPipeline(sdoh_pipeline_model)\n",
    "\n",
    "light_result = light_model.fullAnnotate(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunks</th>\n",
       "      <th>entities</th>\n",
       "      <th>assertion</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cleaning assistant</td>\n",
       "      <td>Employment</td>\n",
       "      <td>Present</td>\n",
       "      <td>0.7926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>health insurance</td>\n",
       "      <td>Insurance_Status</td>\n",
       "      <td>Absent</td>\n",
       "      <td>0.5072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apartment</td>\n",
       "      <td>Housing</td>\n",
       "      <td>Present</td>\n",
       "      <td>0.9956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EtOH abuse</td>\n",
       "      <td>Alcohol</td>\n",
       "      <td>Past</td>\n",
       "      <td>0.6054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rehab Programs</td>\n",
       "      <td>Access_To_Care</td>\n",
       "      <td>Hypothetical</td>\n",
       "      <td>0.5861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DUI</td>\n",
       "      <td>Legal_Issues</td>\n",
       "      <td>Past</td>\n",
       "      <td>0.5037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>alcoholic</td>\n",
       "      <td>Alcohol</td>\n",
       "      <td>Someone_Else</td>\n",
       "      <td>0.9868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>drug abuser</td>\n",
       "      <td>Substance_Use</td>\n",
       "      <td>Someone_Else</td>\n",
       "      <td>0.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>last 5 years</td>\n",
       "      <td>Substance_Duration</td>\n",
       "      <td>Someone_Else</td>\n",
       "      <td>0.9951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>socially isolated</td>\n",
       "      <td>Social_Exclusion</td>\n",
       "      <td>Present</td>\n",
       "      <td>0.9699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>strong support</td>\n",
       "      <td>Social_Support</td>\n",
       "      <td>Absent</td>\n",
       "      <td>0.9873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                chunks            entities     assertion confidence\n",
       "0   cleaning assistant          Employment       Present     0.7926\n",
       "1     health insurance    Insurance_Status        Absent     0.5072\n",
       "2            apartment             Housing       Present     0.9956\n",
       "3           EtOH abuse             Alcohol          Past     0.6054\n",
       "4       Rehab Programs      Access_To_Care  Hypothetical     0.5861\n",
       "5                  DUI        Legal_Issues          Past     0.5037\n",
       "6            alcoholic             Alcohol  Someone_Else     0.9868\n",
       "7          drug abuser       Substance_Use  Someone_Else     0.9996\n",
       "8         last 5 years  Substance_Duration  Someone_Else     0.9951\n",
       "9    socially isolated    Social_Exclusion       Present     0.9699\n",
       "10      strong support      Social_Support        Absent     0.9873"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks=[]\n",
    "entities=[]\n",
    "status=[]\n",
    "confidence=[]\n",
    "\n",
    "for assertion_row in light_result[0][\"assertion\"]:\n",
    "  chunk_id = assertion_row.metadata[\"chunk\"]\n",
    "  for chunk_row in light_result[0][\"ner_chunk\"]:\n",
    "    if chunk_id == chunk_row.metadata[\"chunk\"]:\n",
    "        chunks.append(chunk_row.result)\n",
    "        entities.append(chunk_row.metadata['entity'])\n",
    "        status.append(assertion_row.result)\n",
    "        confidence.append(assertion_row.metadata['confidence'])\n",
    "\n",
    "df = pd.DataFrame({'chunks':chunks, 'entities':entities, 'assertion':status, 'confidence':confidence})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    @import url('https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700&display=swap');\n",
       "    @import url('https://fonts.googleapis.com/css2?family=Vistol Regular:wght@300;400;500;600;700&display=swap');\n",
       "    \n",
       "    .spark-nlp-display-scroll-entities {\n",
       "        border: 1px solid #E7EDF0;\n",
       "        border-radius: 3px;\n",
       "        text-align: justify;\n",
       "        \n",
       "    }\n",
       "    .spark-nlp-display-scroll-entities span {  \n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        color: #536B76;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "    }\n",
       "    \n",
       "    .spark-nlp-display-entity-wrapper{\n",
       "    \n",
       "        display: inline-grid;\n",
       "        text-align: center;\n",
       "        border-radius: 4px;\n",
       "        margin: 0 2px 5px 2px;\n",
       "        padding: 1px\n",
       "    }\n",
       "    .spark-nlp-display-entity-name{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "        \n",
       "        background: #f1f2f3;\n",
       "        border-width: medium;\n",
       "        text-align: center;\n",
       "        \n",
       "        font-weight: 400;\n",
       "        \n",
       "        border-radius: 5px;\n",
       "        padding: 2px 5px;\n",
       "        display: block;\n",
       "        margin: 3px 2px;\n",
       "    \n",
       "    }\n",
       "    .spark-nlp-display-entity-type{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        color: #ffffff;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "        \n",
       "        text-transform: uppercase;\n",
       "        \n",
       "        font-weight: 500;\n",
       "\n",
       "        display: block;\n",
       "        padding: 3px 5px;\n",
       "    }\n",
       "    \n",
       "    .spark-nlp-display-entity-resolution{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        color: #ffffff;\n",
       "        font-family: 'Vistol Regular', sans-serif !important;\n",
       "        \n",
       "        text-transform: uppercase;\n",
       "        \n",
       "        font-weight: 500;\n",
       "\n",
       "        display: block;\n",
       "        padding: 3px 5px;\n",
       "    }\n",
       "    \n",
       "    .spark-nlp-display-others{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "        \n",
       "        font-weight: 400;\n",
       "    }\n",
       "\n",
       "</style>\n",
       " <span class=\"spark-nlp-display-others\" style=\"background-color: white\">Smith works as a </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #C33DBEB3\"><span class=\"spark-nlp-display-entity-name\">cleaning assistant </span><span class=\"spark-nlp-display-entity-type\">Employment</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #C33DBEFF\">Present </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> and does not have access to </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #1E38C6B3\"><span class=\"spark-nlp-display-entity-name\">health insurance </span><span class=\"spark-nlp-display-entity-type\">Insurance_Status</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #1E38C6FF\">Absent </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> or paid sick leave.<br>But she has generally housing problems. She lives in a </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #707D0CB3\"><span class=\"spark-nlp-display-entity-name\">apartment </span><span class=\"spark-nlp-display-entity-type\">Housing</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #707D0CFF\">Present </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> now.  She has long history of </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #A05144B3\"><span class=\"spark-nlp-display-entity-name\">EtOH abuse </span><span class=\"spark-nlp-display-entity-type\">Alcohol</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #A05144FF\">Past </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, beginning in her teens.<br>She is aware she needs to attend </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #A95471B3\"><span class=\"spark-nlp-display-entity-name\">Rehab Programs </span><span class=\"spark-nlp-display-entity-type\">Access_To_Care</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #A95471FF\">Hypothetical </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">. She had </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #0601C7B3\"><span class=\"spark-nlp-display-entity-name\">DUI </span><span class=\"spark-nlp-display-entity-type\">Legal_Issues</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #0601C7FF\">Past </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> back in April and was due to be in court this week.<br>Her partner is an </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #A05144B3\"><span class=\"spark-nlp-display-entity-name\">alcoholic </span><span class=\"spark-nlp-display-entity-type\">Alcohol</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #A05144FF\">Someone_Else </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> and a </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #65481AB3\"><span class=\"spark-nlp-display-entity-name\">drug abuser </span><span class=\"spark-nlp-display-entity-type\">Substance_Use</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #65481AFF\">Someone_Else </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> for the </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #9D4A72B3\"><span class=\"spark-nlp-display-entity-name\">last 5 years </span><span class=\"spark-nlp-display-entity-type\">Substance_Duration</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #9D4A72FF\">Someone_Else </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">.<br>She also mentioned feeling </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #9C0480B3\"><span class=\"spark-nlp-display-entity-name\">socially isolated </span><span class=\"spark-nlp-display-entity-type\">Social_Exclusion</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #9C0480FF\">Present </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> and lack of a </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #B9B624B3\"><span class=\"spark-nlp-display-entity-name\">strong support </span><span class=\"spark-nlp-display-entity-type\">Social_Support</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #B9B624FF\">Absent </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> system </span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sparknlp_display import AssertionVisualizer\n",
    "\n",
    "vis = AssertionVisualizer()\n",
    "\n",
    "vis.display(light_result[0], 'ner_chunk', 'assertion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AssertionChunkConverter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases, there may be issues while creating the chunk column by using token indices and losing some data while training and testing the assertion status model if there are issues in these token indices. So we developed a new `AssertionChunkConverter` annotator that takes **begin and end indices of the chunks** as input and creates an extended chunk column with metadata that can be used for assertion status detection model training.\n",
    "\n",
    "*NOTE*: Chunk begin and end indices in the assertion status model training dataframe can be populated using the new version of ALAB module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+----------+--------+\n",
      "|                text|target|char_begin|char_end|\n",
      "+--------------------+------+----------+--------+\n",
      "|An angiography sh...|Minnie|        57|      63|\n",
      "|After discussing ...|   PCP|        31|      34|\n",
      "+--------------------+------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark.createDataFrame([[\"An angiography showed bleeding in two vessels off of the Minnie supplying the sigmoid that were succesfully embolized.\", \"Minnie\", 57, 63],\n",
    "     [\"After discussing this with his PCP, Leon was clear that the patient had had recurrent DVTs and ultimately a PE and his PCP felt strongly that he required long-term anticoagulation \", \"PCP\", 31, 34]])\\\n",
    "     .toDF(\"text\", \"target\", \"char_begin\", \"char_end\")\n",
    "\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_assembler = nlp.DocumentAssembler() \\\n",
    "    .setInputCol(\"text\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "sentenceDetector = nlp.SentenceDetector()\\\n",
    "    .setInputCols([\"document\"])\\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "tokenizer = nlp.Tokenizer() \\\n",
    "    .setInputCols([\"sentence\"]) \\\n",
    "    .setOutputCol(\"tokens\")\n",
    "\n",
    "converter = medical.AssertionChunkConverter() \\\n",
    "    .setInputCols(\"tokens\")\\\n",
    "    .setChunkTextCol(\"target\")\\\n",
    "    .setChunkBeginCol(\"char_begin\")\\\n",
    "    .setChunkEndCol(\"char_end\")\\\n",
    "    .setOutputTokenBeginCol(\"token_begin\")\\\n",
    "    .setOutputTokenEndCol(\"token_end\")\\\n",
    "    .setOutputCol(\"chunk\")\n",
    "\n",
    "pipeline = nlp.Pipeline().setStages([document_assembler,sentenceDetector, tokenizer, converter])\n",
    "\n",
    "results = pipeline.fit(data).transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+--------+-----------+---------+--------------------------+------------------------+------+----------------------------------------------+\n",
      "|target|char_begin|char_end|token_begin|token_end|tokens[token_begin].result|tokens[token_end].result|target|chunk                                         |\n",
      "+------+----------+--------+-----------+---------+--------------------------+------------------------+------+----------------------------------------------+\n",
      "|Minnie|57        |63      |10         |10       |Minnie                    |Minnie                  |Minnie|[{chunk, 57, 62, Minnie, {sentence -> 0}, []}]|\n",
      "|PCP   |31        |34      |5          |5        |PCP                       |PCP                     |PCP   |[{chunk, 31, 33, PCP, {sentence -> 0}, []}]   |\n",
      "+------+----------+--------+-----------+---------+--------------------------+------------------------+------+----------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results\\\n",
    "    .selectExpr(\n",
    "        \"target\",\n",
    "        \"char_begin\",\n",
    "        \"char_end\",\n",
    "        \"token_begin\",\n",
    "        \"token_end\",\n",
    "        \"tokens[token_begin].result\",\n",
    "        \"tokens[token_end].result\",\n",
    "        \"target\",\n",
    "        \"chunk\")\\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JjfUo0aTKFEL"
   },
   "source": [
    "# **Train a custom Assertion Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "QPFTJxtlIKQT"
   },
   "outputs": [],
   "source": [
    "!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Healthcare/data/i2b2_assertion_sample_short.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "hRFW3nyALHx0"
   },
   "outputs": [],
   "source": [
    "assertion_df = spark.read.option(\"header\", True).option(\"inferSchema\", \"True\").csv(\"i2b2_assertion_sample_short.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TQn7bJZtL9uX",
    "outputId": "4458414c-4bbb-4965-8a19-594c1b7f2358"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------+-------------------+-------+-----+---+\n",
      "|                                             text|             target|  label|start|end|\n",
      "+-------------------------------------------------+-------------------+-------+-----+---+\n",
      "|She has no history of liver disease , hepatitis .|      liver disease| absent|    5|  6|\n",
      "|                         1. Undesired fertility .|undesired fertility|present|    1|  2|\n",
      "|                            3) STATUS POST FALL .|               fall|present|    3|  3|\n",
      "+-------------------------------------------------+-------------------+-------+-----+---+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assertion_df.show(3, truncate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B6IuDZ9Qw7Cu",
    "outputId": "09b7cdb4-3c2f-42b1-f202-7c5b46be9277"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:17:29, INFO Error while sending or receiving.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/py4j/clientserver.py\", line 503, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "19:17:29, INFO Closing down clientserver connection\n",
      "19:17:29, INFO Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/py4j/clientserver.py\", line 503, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/py4j/clientserver.py\", line 506, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "19:17:29, INFO Closing down clientserver connection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 721\n",
      "Test Dataset Count: 170\n"
     ]
    }
   ],
   "source": [
    "(training_data, test_data) = assertion_df.randomSplit([0.8, 0.2], seed = 100)\n",
    "print(\"Training Dataset Count: \" + str(training_data.count()))\n",
    "print(\"Test Dataset Count: \" + str(test_data.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fktQ3EbBZwo-",
    "outputId": "b583259a-a44a-486d-e595-b433c61a8e07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|label  |count|\n",
      "+-------+-----+\n",
      "|present|546  |\n",
      "|absent |175  |\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data.groupBy('label').count().orderBy('count', ascending=False).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UTNhwoSDLLVG",
    "outputId": "fa0b607d-263a-4065-ba88-aed9d07d316b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "document = nlp.DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "chunk = nlp.Doc2Chunk()\\\n",
    "    .setInputCols(\"document\")\\\n",
    "    .setOutputCol(\"chunk\")\\\n",
    "    .setChunkCol(\"target\")\\\n",
    "    .setStartCol(\"start\")\\\n",
    "    .setStartColByTokenIndex(True)\\\n",
    "    .setFailOnMissing(False)\\\n",
    "    .setLowerCase(True)\n",
    "\n",
    "token = nlp.Tokenizer()\\\n",
    "    .setInputCols(['document'])\\\n",
    "    .setOutputCol('token')\n",
    "\n",
    "embeddings = nlp.WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n",
    "    .setInputCols([\"document\", \"token\"])\\\n",
    "    .setOutputCol(\"embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lkp7KmK6pv0-"
   },
   "source": [
    "We will transform our test data with a pipeline consisting of same steps with the pipeline which contains AssertionDLApproach.\n",
    "By doing this, we enable that test data will have same columns with training data in AssertionDLApproach. <br/>\n",
    "The goal of this implementation is enabling the usage of `setTestDataset()` parameter in AssertionDLApproach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "-7DScL2-uIOm"
   },
   "outputs": [],
   "source": [
    "clinical_assertion_pipeline = nlp.Pipeline(\n",
    "    stages = [\n",
    "    document,\n",
    "    chunk,\n",
    "    token,\n",
    "    embeddings])\n",
    "\n",
    "assertion_test_data = clinical_assertion_pipeline.fit(test_data).transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nwuyumqGuHwY",
    "outputId": "ece31244-aec7-4970-966a-bf31c64bd079"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text',\n",
       " 'target',\n",
       " 'label',\n",
       " 'start',\n",
       " 'end',\n",
       " 'document',\n",
       " 'chunk',\n",
       " 'token',\n",
       " 'embeddings']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assertion_test_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aE-99quUsJ5V"
   },
   "source": [
    "We save the test data in parquet format to use in `AssertionDLApproach()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "A3Hx0w05uQ7E"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "assertion_test_data.write.mode(\"overwrite\").parquet('i2b2_assertion_sample_test_data.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uTishXbut1MS"
   },
   "source": [
    "## Graph setup and training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wegOakRbw9nJ"
   },
   "source": [
    "We will use TFGraphBuilder annotator which can be used to create graphs in the model training pipeline.\n",
    "\n",
    "TFGraphBuilder inspects the data and creates the proper graph if a suitable version of TensorFlow (<= 2.7 ) is available. The graph is stored in the defined folder and loaded by the approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "zl1xBA65IZ2j"
   },
   "outputs": [],
   "source": [
    "!mkdir -p training_logs\n",
    "!mkdir -p assertion_tf_graph\n",
    "\n",
    "# ready to use tf_graph\n",
    "!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Healthcare/tf_graphs/blstm_34_32_30_200_2.pb -P ./assertion_tf_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "EtR9lajQxHpc"
   },
   "outputs": [],
   "source": [
    "from sparknlp_jsl.annotator import TFGraphBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "r4nb2OmrxIsH"
   },
   "outputs": [],
   "source": [
    "graph_folder= \"./assertion_tf_graph\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "qZPZIUWYxN3r"
   },
   "outputs": [],
   "source": [
    "assertion_graph_builder = medical.TFGraphBuilder()\\\n",
    "    .setModelName(\"assertion_dl\")\\\n",
    "    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "    .setLabelColumn(\"label\")\\\n",
    "    .setGraphFolder(graph_folder)\\\n",
    "    .setGraphFile(\"assertion_graph.pb\")\\\n",
    "    .setMaxSequenceLength(250)\\\n",
    "    .setHiddenUnitsNumber(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "RNzTsoSeXezx"
   },
   "outputs": [],
   "source": [
    "# Create custom graph\n",
    "\n",
    "# from sparknlp_jsl.training import tf_graph\n",
    "# tf_graph.print_model_params(\"assertion_dl\")\n",
    "\n",
    "# feat_size = 200\n",
    "# n_classes = 6\n",
    "\n",
    "# tf_graph.build(\"assertion_dl\",\n",
    "#               build_params={\"n_classes\": n_classes},\n",
    "#               model_location= \"./tf_graphs\", \n",
    "#               model_filename=\"blstm_34_32_30_{}_{}.pb\".format(feat_size, n_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6D0Ng7nMUjJa"
   },
   "source": [
    "**Setting the Scope Window (Target Area) Dynamically in Assertion Status Detection Models**\n",
    "\n",
    "\n",
    "This parameter allows you to train the Assertion Status Models to focus on specific context windows when resolving the status of a NER chunk. The window is in format `[X,Y]` being `X` the number of tokens to consider on the left of the chunk, and `Y` the max number of tokens to consider on the right. Letâ€™s take a look at what different windows mean:\n",
    "\n",
    "\n",
    "*   By default, the window is `[-1,-1]` which means that the Assertion Status will look at all of the tokens in the sentence/document (up to a maximum of tokens set in `setMaxSentLen()` ).\n",
    "*   `[0,0]` means â€œdonâ€™t pay attention to any token except the ner_chunkâ€, what basically is not considering any context for the Assertion resolution.\n",
    "*   `[9,15]` is what empirically seems to be the best baseline, meaning that we look up to 9 tokens on the left and 15 on the right of the ner chunk to understand the context and resolve the status.\n",
    "\n",
    "\n",
    "Check this [Scope Window Tuning Assertion Status Detection notebook](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/2.1.Scope_window_tuning_assertion_status_detection.ipynb)  that illustrates the effect of the different windows and how to properly fine-tune your AssertionDLModels to get the best of them.\n",
    "\n",
    "In our case, the best Scope Window is around [10,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "qG2o6Yq2xk4N"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIf .setTestDataset parameter is employed, raw test data cannot be fitted. .setTestDataset only works for dataframes which are correctly transformed\\nby a pipeline consisting of document, chunk, embeddings stages.\\n'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scope_window = [10,10]\n",
    "\n",
    "assertionStatus = medical.AssertionDLApproach()\\\n",
    "    .setLabelCol(\"label\")\\\n",
    "    .setInputCols(\"document\", \"chunk\", \"embeddings\")\\\n",
    "    .setOutputCol(\"assertion\")\\\n",
    "    .setBatchSize(128)\\\n",
    "    .setDropout(0.1)\\\n",
    "    .setLearningRate(0.001)\\\n",
    "    .setEpochs(15)\\\n",
    "    .setValidationSplit(0.2)\\\n",
    "    .setStartCol(\"start\")\\\n",
    "    .setEndCol(\"end\")\\\n",
    "    .setMaxSentLen(250)\\\n",
    "    .setIncludeConfidence(True)\\\n",
    "    .setEnableOutputLogs(True)\\\n",
    "    .setOutputLogsPath('training_logs/')\\\n",
    "    .setGraphFolder(graph_folder)\\\n",
    "    .setGraphFile(f\"{graph_folder}/assertion_graph.pb\")\\\n",
    "    .setTestDataset(path=\"./i2b2_assertion_sample_test_data.parquet\")\\\n",
    "    .setScopeWindow(scope_window)\n",
    "\n",
    "'''\n",
    "If .setTestDataset parameter is employed, raw test data cannot be fitted. .setTestDataset only works for dataframes which are correctly transformed\n",
    "by a pipeline consisting of document, chunk, embeddings stages.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "97ATs6a41jdE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nassertionStatus = AssertionLogRegApproach()    .setLabelCol(\"label\")    .setInputCols(\"document\", \"chunk\", \"embeddings\")    .setOutputCol(\"assertion\")    .setMaxIter(100) # default: 26\\n'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "assertionStatus = AssertionLogRegApproach()\\\n",
    "    .setLabelCol(\"label\")\\\n",
    "    .setInputCols(\"document\", \"chunk\", \"embeddings\")\\\n",
    "    .setOutputCol(\"assertion\")\\\n",
    "    .setMaxIter(100) # default: 26\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "EKRL7Oy4MC1C"
   },
   "outputs": [],
   "source": [
    "clinical_assertion_pipeline = nlp.Pipeline(\n",
    "    stages = [\n",
    "    document,\n",
    "    chunk,\n",
    "    token,\n",
    "    embeddings,\n",
    "    assertion_graph_builder,\n",
    "    assertionStatus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ei54XasnMU0U",
    "outputId": "72e122d5-c7f1-44e1-b58c-e92e1f8878fc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Graph Builder configuration:\n",
      "Model name: assertion_dl\n",
      "Graph folder: ./assertion_tf_graph\n",
      "Graph file name: assertion_graph.pb\n",
      "Build params: {'n_classes': 2, 'feat_size': 200, 'max_seq_len': 250, 'n_hidden': 25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:18:05, INFO Error while sending or receiving.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/py4j/clientserver.py\", line 503, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "19:18:05, INFO Closing down clientserver connection\n",
      "19:18:05, INFO Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/py4j/clientserver.py\", line 503, in send_command\n",
      "    self.socket.sendall(command.encode(\"utf-8\"))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/py4j/clientserver.py\", line 506, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending\n",
      "19:18:05, INFO Closing down clientserver connection\n",
      "19:18:08, WARNING From /home/ubuntu/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping: no known devices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:18:08, WARNING From /home/ubuntu/.local/lib/python3.8/site-packages/sparknlp_jsl/_tf_graph_builders/tf2contrib/rnn.py:229: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "19:18:08, WARNING From /home/ubuntu/.local/lib/python3.8/site-packages/tensorflow/python/ops/rnn.py:437: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "19:18:08, WARNING From /home/ubuntu/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py:762: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping: no known devices.\n",
      "assertion_dl graph exported to ./assertion_tf_graph/assertion_graph.pb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.83s\n",
      "Total validation loss: 0.9217\tAvg validation loss: 0.4608\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 116\t 28\t 0\t 0.8055556\t 1.0\t 0.8923077\n",
      "absent\t 0\t 0\t 28\t 0.0\t 0.0\t 0.0\n",
      "tp: 116 fp: 28 fn: 28 labels: 2\n",
      "Macro-average\t prec: 0.4027778, rec: 0.5, f1: 0.44615385\n",
      "Micro-average\t prec: 0.8055556, rec: 0.8055556, f1: 0.80555564\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.61s\n",
      "Total test loss: 1.2239\tAvg test loss: 0.6119\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 117\t 53\t 0\t 0.6882353\t 1.0\t 0.815331\n",
      "absent\t 0\t 0\t 53\t 0.0\t 0.0\t 0.0\n",
      "tp: 117 fp: 53 fn: 53 labels: 2\n",
      "Macro-average\t prec: 0.34411764, rec: 0.5, f1: 0.4076655\n",
      "Micro-average\t prec: 0.6882353, rec: 0.6882353, f1: 0.6882353\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.54s\n",
      "Total validation loss: 0.8705\tAvg validation loss: 0.4352\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 116\t 28\t 0\t 0.8055556\t 1.0\t 0.8923077\n",
      "absent\t 0\t 0\t 28\t 0.0\t 0.0\t 0.0\n",
      "tp: 116 fp: 28 fn: 28 labels: 2\n",
      "Macro-average\t prec: 0.4027778, rec: 0.5, f1: 0.44615385\n",
      "Micro-average\t prec: 0.8055556, rec: 0.8055556, f1: 0.80555564\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.61s\n",
      "Total test loss: 1.1969\tAvg test loss: 0.5985\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 117\t 53\t 0\t 0.6882353\t 1.0\t 0.815331\n",
      "absent\t 0\t 0\t 53\t 0.0\t 0.0\t 0.0\n",
      "tp: 117 fp: 53 fn: 53 labels: 2\n",
      "Macro-average\t prec: 0.34411764, rec: 0.5, f1: 0.4076655\n",
      "Micro-average\t prec: 0.6882353, rec: 0.6882353, f1: 0.6882353\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.53s\n",
      "Total validation loss: 0.8443\tAvg validation loss: 0.4221\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 116\t 28\t 0\t 0.8055556\t 1.0\t 0.8923077\n",
      "absent\t 0\t 0\t 28\t 0.0\t 0.0\t 0.0\n",
      "tp: 116 fp: 28 fn: 28 labels: 2\n",
      "Macro-average\t prec: 0.4027778, rec: 0.5, f1: 0.44615385\n",
      "Micro-average\t prec: 0.8055556, rec: 0.8055556, f1: 0.80555564\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.60s\n",
      "Total test loss: 1.1270\tAvg test loss: 0.5635\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 117\t 53\t 0\t 0.6882353\t 1.0\t 0.815331\n",
      "absent\t 0\t 0\t 53\t 0.0\t 0.0\t 0.0\n",
      "tp: 117 fp: 53 fn: 53 labels: 2\n",
      "Macro-average\t prec: 0.34411764, rec: 0.5, f1: 0.4076655\n",
      "Micro-average\t prec: 0.6882353, rec: 0.6882353, f1: 0.6882353\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.52s\n",
      "Total validation loss: 0.8032\tAvg validation loss: 0.4016\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 116\t 26\t 0\t 0.8169014\t 1.0\t 0.89922476\n",
      "absent\t 2\t 0\t 26\t 1.0\t 0.071428575\t 0.13333334\n",
      "tp: 118 fp: 26 fn: 26 labels: 2\n",
      "Macro-average\t prec: 0.9084507, rec: 0.53571427, f1: 0.6739812\n",
      "Micro-average\t prec: 0.8194444, rec: 0.8194444, f1: 0.8194445\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.59s\n",
      "Total test loss: 1.0405\tAvg test loss: 0.5202\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 117\t 47\t 0\t 0.7134146\t 1.0\t 0.8327402\n",
      "absent\t 6\t 0\t 47\t 1.0\t 0.11320755\t 0.20338982\n",
      "tp: 123 fp: 47 fn: 47 labels: 2\n",
      "Macro-average\t prec: 0.85670733, rec: 0.5566038, f1: 0.6747934\n",
      "Micro-average\t prec: 0.7235294, rec: 0.7235294, f1: 0.7235294\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.52s\n",
      "Total validation loss: 0.7384\tAvg validation loss: 0.3692\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 115\t 22\t 1\t 0.8394161\t 0.9913793\t 0.9090909\n",
      "absent\t 6\t 1\t 22\t 0.85714287\t 0.21428572\t 0.34285715\n",
      "tp: 121 fp: 23 fn: 23 labels: 2\n",
      "Macro-average\t prec: 0.8482795, rec: 0.6028325, f1: 0.704798\n",
      "Micro-average\t prec: 0.8402778, rec: 0.8402778, f1: 0.8402778\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.60s\n",
      "Total test loss: 0.9418\tAvg test loss: 0.4709\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 117\t 39\t 0\t 0.75\t 1.0\t 0.85714287\n",
      "absent\t 14\t 0\t 39\t 1.0\t 0.26415095\t 0.41791046\n",
      "tp: 131 fp: 39 fn: 39 labels: 2\n",
      "Macro-average\t prec: 0.875, rec: 0.6320755, f1: 0.7339593\n",
      "Micro-average\t prec: 0.7705882, rec: 0.7705882, f1: 0.7705882\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.52s\n",
      "Total validation loss: 0.6841\tAvg validation loss: 0.3420\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 113\t 15\t 3\t 0.8828125\t 0.9741379\t 0.9262295\n",
      "absent\t 13\t 3\t 15\t 0.8125\t 0.4642857\t 0.59090906\n",
      "tp: 126 fp: 18 fn: 18 labels: 2\n",
      "Macro-average\t prec: 0.84765625, rec: 0.7192118, f1: 0.77816945\n",
      "Micro-average\t prec: 0.875, rec: 0.875, f1: 0.875\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.59s\n",
      "Total test loss: 0.8154\tAvg test loss: 0.4077\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 115\t 28\t 2\t 0.8041958\t 0.982906\t 0.8846154\n",
      "absent\t 25\t 2\t 28\t 0.9259259\t 0.4716981\t 0.625\n",
      "tp: 140 fp: 30 fn: 30 labels: 2\n",
      "Macro-average\t prec: 0.86506087, rec: 0.7273021, f1: 0.79022264\n",
      "Micro-average\t prec: 0.8235294, rec: 0.8235294, f1: 0.8235294\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.51s\n",
      "Total validation loss: 0.6397\tAvg validation loss: 0.3199\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 111\t 11\t 5\t 0.90983605\t 0.95689654\t 0.9327731\n",
      "absent\t 17\t 5\t 11\t 0.77272725\t 0.60714287\t 0.68\n",
      "tp: 128 fp: 16 fn: 16 labels: 2\n",
      "Macro-average\t prec: 0.84128165, rec: 0.78201973, f1: 0.8105689\n",
      "Micro-average\t prec: 0.8888889, rec: 0.8888889, f1: 0.8888889\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.59s\n",
      "Total test loss: 0.6995\tAvg test loss: 0.3498\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 110\t 22\t 7\t 0.8333333\t 0.94017094\t 0.88353413\n",
      "absent\t 31\t 7\t 22\t 0.81578946\t 0.5849057\t 0.6813187\n",
      "tp: 141 fp: 29 fn: 29 labels: 2\n",
      "Macro-average\t prec: 0.82456136, rec: 0.7625383, f1: 0.7923379\n",
      "Micro-average\t prec: 0.82941175, rec: 0.82941175, f1: 0.82941175\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.52s\n",
      "Total validation loss: 0.5931\tAvg validation loss: 0.2966\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 114\t 14\t 2\t 0.890625\t 0.98275864\t 0.93442625\n",
      "absent\t 14\t 2\t 14\t 0.875\t 0.5\t 0.6363636\n",
      "tp: 128 fp: 16 fn: 16 labels: 2\n",
      "Macro-average\t prec: 0.8828125, rec: 0.7413793, f1: 0.805938\n",
      "Micro-average\t prec: 0.8888889, rec: 0.8888889, f1: 0.8888889\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.59s\n",
      "Total test loss: 0.6656\tAvg test loss: 0.3328\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 115\t 28\t 2\t 0.8041958\t 0.982906\t 0.8846154\n",
      "absent\t 25\t 2\t 28\t 0.9259259\t 0.4716981\t 0.625\n",
      "tp: 140 fp: 30 fn: 30 labels: 2\n",
      "Macro-average\t prec: 0.86506087, rec: 0.7273021, f1: 0.79022264\n",
      "Micro-average\t prec: 0.8235294, rec: 0.8235294, f1: 0.8235294\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.52s\n",
      "Total validation loss: 0.5944\tAvg validation loss: 0.2972\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 106\t 9\t 10\t 0.9217391\t 0.9137931\t 0.9177489\n",
      "absent\t 19\t 10\t 9\t 0.6551724\t 0.6785714\t 0.6666667\n",
      "tp: 125 fp: 19 fn: 19 labels: 2\n",
      "Macro-average\t prec: 0.7884557, rec: 0.7961823, f1: 0.7923001\n",
      "Micro-average\t prec: 0.8680556, rec: 0.8680556, f1: 0.8680556\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.59s\n",
      "Total test loss: 0.5849\tAvg test loss: 0.2924\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 108\t 14\t 9\t 0.8852459\t 0.9230769\t 0.9037656\n",
      "absent\t 39\t 9\t 14\t 0.8125\t 0.7358491\t 0.77227724\n",
      "tp: 147 fp: 23 fn: 23 labels: 2\n",
      "Macro-average\t prec: 0.84887296, rec: 0.829463, f1: 0.8390558\n",
      "Micro-average\t prec: 0.86470586, rec: 0.86470586, f1: 0.86470586\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.53s\n",
      "Total validation loss: 0.5453\tAvg validation loss: 0.2727\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 114\t 13\t 2\t 0.8976378\t 0.98275864\t 0.9382716\n",
      "absent\t 15\t 2\t 13\t 0.88235295\t 0.53571427\t 0.6666666\n",
      "tp: 129 fp: 15 fn: 15 labels: 2\n",
      "Macro-average\t prec: 0.88999534, rec: 0.75923645, f1: 0.81943226\n",
      "Micro-average\t prec: 0.8958333, rec: 0.8958333, f1: 0.8958334\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.60s\n",
      "Total test loss: 0.5971\tAvg test loss: 0.2986\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 116\t 24\t 1\t 0.82857144\t 0.991453\t 0.9027237\n",
      "absent\t 29\t 1\t 24\t 0.96666664\t 0.5471698\t 0.6987952\n",
      "tp: 145 fp: 25 fn: 25 labels: 2\n",
      "Macro-average\t prec: 0.897619, rec: 0.7693114, f1: 0.8285271\n",
      "Micro-average\t prec: 0.85294116, rec: 0.85294116, f1: 0.85294116\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.51s\n",
      "Total validation loss: 0.5550\tAvg validation loss: 0.2775\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 108\t 9\t 8\t 0.9230769\t 0.9310345\t 0.92703867\n",
      "absent\t 19\t 8\t 9\t 0.7037037\t 0.6785714\t 0.690909\n",
      "tp: 127 fp: 17 fn: 17 labels: 2\n",
      "Macro-average\t prec: 0.8133903, rec: 0.80480295, f1: 0.80907387\n",
      "Micro-average\t prec: 0.8819444, rec: 0.8819444, f1: 0.8819444\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.58s\n",
      "Total test loss: 0.5462\tAvg test loss: 0.2731\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 108\t 15\t 9\t 0.8780488\t 0.9230769\t 0.9\n",
      "absent\t 38\t 9\t 15\t 0.80851066\t 0.7169811\t 0.76000005\n",
      "tp: 146 fp: 24 fn: 24 labels: 2\n",
      "Macro-average\t prec: 0.8432797, rec: 0.820029, f1: 0.8314918\n",
      "Micro-average\t prec: 0.85882354, rec: 0.85882354, f1: 0.85882354\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.51s\n",
      "Total validation loss: 0.4964\tAvg validation loss: 0.2482\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 112\t 10\t 4\t 0.91803277\t 0.9655172\t 0.9411765\n",
      "absent\t 18\t 4\t 10\t 0.8181818\t 0.64285713\t 0.72\n",
      "tp: 130 fp: 14 fn: 14 labels: 2\n",
      "Macro-average\t prec: 0.8681073, rec: 0.8041872, f1: 0.83492565\n",
      "Micro-average\t prec: 0.9027778, rec: 0.9027778, f1: 0.9027778\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.59s\n",
      "Total test loss: 0.5194\tAvg test loss: 0.2597\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 115\t 17\t 2\t 0.8712121\t 0.982906\t 0.9236948\n",
      "absent\t 36\t 2\t 17\t 0.94736844\t 0.6792453\t 0.7912088\n",
      "tp: 151 fp: 19 fn: 19 labels: 2\n",
      "Macro-average\t prec: 0.9092903, rec: 0.83107567, f1: 0.8684255\n",
      "Micro-average\t prec: 0.8882353, rec: 0.8882353, f1: 0.8882353\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.54s\n",
      "Total validation loss: 0.5145\tAvg validation loss: 0.2573\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 114\t 11\t 2\t 0.912\t 0.98275864\t 0.9460581\n",
      "absent\t 17\t 2\t 11\t 0.8947368\t 0.60714287\t 0.7234043\n",
      "tp: 131 fp: 13 fn: 13 labels: 2\n",
      "Macro-average\t prec: 0.9033684, rec: 0.7949507, f1: 0.84569895\n",
      "Micro-average\t prec: 0.9097222, rec: 0.9097222, f1: 0.9097222\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.60s\n",
      "Total test loss: 0.5657\tAvg test loss: 0.2829\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 116\t 21\t 1\t 0.84671533\t 0.991453\t 0.9133858\n",
      "absent\t 32\t 1\t 21\t 0.969697\t 0.6037736\t 0.7441861\n",
      "tp: 148 fp: 22 fn: 22 labels: 2\n",
      "Macro-average\t prec: 0.90820616, rec: 0.79761326, f1: 0.84932476\n",
      "Micro-average\t prec: 0.87058824, rec: 0.87058824, f1: 0.87058824\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.51s\n",
      "Total validation loss: 0.5385\tAvg validation loss: 0.2693\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 110\t 8\t 6\t 0.9322034\t 0.94827586\t 0.94017094\n",
      "absent\t 20\t 6\t 8\t 0.7692308\t 0.71428573\t 0.7407408\n",
      "tp: 130 fp: 14 fn: 14 labels: 2\n",
      "Macro-average\t prec: 0.85071707, rec: 0.8312808, f1: 0.84088665\n",
      "Micro-average\t prec: 0.9027778, rec: 0.9027778, f1: 0.9027778\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.59s\n",
      "Total test loss: 0.5251\tAvg test loss: 0.2626\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 106\t 13\t 11\t 0.8907563\t 0.9059829\t 0.8983051\n",
      "absent\t 40\t 11\t 13\t 0.78431374\t 0.754717\t 0.7692308\n",
      "tp: 146 fp: 24 fn: 24 labels: 2\n",
      "Macro-average\t prec: 0.837535, rec: 0.8303499, f1: 0.833927\n",
      "Micro-average\t prec: 0.85882354, rec: 0.85882354, f1: 0.85882354\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.51s\n",
      "Total validation loss: 0.4902\tAvg validation loss: 0.2451\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 111\t 10\t 5\t 0.91735536\t 0.95689654\t 0.93670887\n",
      "absent\t 18\t 5\t 10\t 0.7826087\t 0.64285713\t 0.7058824\n",
      "tp: 129 fp: 15 fn: 15 labels: 2\n",
      "Macro-average\t prec: 0.849982, rec: 0.7998768, f1: 0.8241686\n",
      "Micro-average\t prec: 0.8958333, rec: 0.8958333, f1: 0.8958334\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.60s\n",
      "Total test loss: 0.5043\tAvg test loss: 0.2521\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 116\t 16\t 1\t 0.8787879\t 0.991453\t 0.9317269\n",
      "absent\t 37\t 1\t 16\t 0.9736842\t 0.6981132\t 0.8131868\n",
      "tp: 153 fp: 17 fn: 17 labels: 2\n",
      "Macro-average\t prec: 0.92623603, rec: 0.84478307, f1: 0.8836364\n",
      "Micro-average\t prec: 0.9, rec: 0.9, f1: 0.9\n",
      "CPU times: user 9.16 s, sys: 486 ms, total: 9.64 s\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "assertion_model = clinical_assertion_pipeline.fit(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "30SmcTiSpnWa"
   },
   "source": [
    "## Checking the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kOiu1vuspKut",
    "outputId": "4a51d7c9-76ec-44a7-c3fc-402fc99e4d46"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AssertionDLApproach_f452107e592d.log',\n",
       " 'AssertionDLApproach_dfa2143baaf8.log']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "log_files = os.listdir(\"./training_logs\")\n",
    "log_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CcQV0-fIrJHz",
    "outputId": "4ca50420-aad6-4459-80d7-a720d0349bec",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of the selected graph: ./assertion_tf_graph/assertion_graph.pb\n",
      "Training started, trainExamples: 721\n",
      "\n",
      "\n",
      "Epoch: 0 started, learning rate: 0.001, dataset size: 577\n",
      "Done, 3.909256108 total training loss: 2.8042927, avg training loss: 0.56085855, batches: 5\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.83s\n",
      "Total validation loss: 0.9217\tAvg validation loss: 0.4608\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 116\t 28\t 0\t 0.8055556\t 1.0\t 0.8923077\n",
      "absent\t 0\t 0\t 28\t 0.0\t 0.0\t 0.0\n",
      "tp: 116 fp: 28 fn: 28 labels: 2\n",
      "Macro-average\t prec: 0.4027778, rec: 0.5, f1: 0.44615385\n",
      "Micro-average\t prec: 0.8055556, rec: 0.8055556, f1: 0.80555564\n",
      "\n",
      "\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.61s\n",
      "Total test loss: 1.2239\tAvg test loss: 0.6119\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 117\t 53\t 0\t 0.6882353\t 1.0\t 0.815331\n",
      "absent\t 0\t 0\t 53\t 0.0\t 0.0\t 0.0\n",
      "tp: 117 fp: 53 fn: 53 labels: 2\n",
      "Macro-average\t prec: 0.34411764, rec: 0.5, f1: 0.4076655\n",
      "Micro-average\t prec: 0.6882353, rec: 0.6882353, f1: 0.6882353\n",
      "\n",
      "\n",
      "Epoch: 1 started, learning rate: 9.5E-4, dataset size: 577\n",
      "Done, 2.75927445 total training loss: 2.7187839, avg training loss: 0.5437568, batches: 5\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.54s\n",
      "Total validation loss: 0.8705\tAvg validation loss: 0.4352\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 116\t 28\t 0\t 0.8055556\t 1.0\t 0.8923077\n",
      "absent\t 0\t 0\t 28\t 0.0\t 0.0\t 0.0\n",
      "tp: 116 fp: 28 fn: 28 labels: 2\n",
      "Macro-average\t prec: 0.4027778, rec: 0.5, f1: 0.44615385\n",
      "Micro-average\t prec: 0.8055556, rec: 0.8055556, f1: 0.80555564\n",
      "\n",
      "\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.61s\n",
      "Total test loss: 1.1969\tAvg test loss: 0.5985\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 117\t 53\t 0\t 0.6882353\t 1.0\t 0.815331\n",
      "absent\t 0\t 0\t 53\t 0.0\t 0.0\t 0.0\n",
      "tp: 117 fp: 53 fn: 53 labels: 2\n",
      "Macro-average\t prec: 0.34411764, rec: 0.5, f1: 0.4076655\n",
      "Micro-average\t prec: 0.6882353, rec: 0.6882353, f1: 0.6882353\n",
      "\n",
      "\n",
      "Epoch: 2 started, learning rate: 9.025E-4, dataset size: 577\n",
      "Done, 2.761598508 total training loss: 2.6137254, avg training loss: 0.5227451, batches: 5\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.53s\n",
      "Total validation loss: 0.8443\tAvg validation loss: 0.4221\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 116\t 28\t 0\t 0.8055556\t 1.0\t 0.8923077\n",
      "absent\t 0\t 0\t 28\t 0.0\t 0.0\t 0.0\n",
      "tp: 116 fp: 28 fn: 28 labels: 2\n",
      "Macro-average\t prec: 0.4027778, rec: 0.5, f1: 0.44615385\n",
      "Micro-average\t prec: 0.8055556, rec: 0.8055556, f1: 0.80555564\n",
      "\n",
      "\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.60s\n",
      "Total test loss: 1.1270\tAvg test loss: 0.5635\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 117\t 53\t 0\t 0.6882353\t 1.0\t 0.815331\n",
      "absent\t 0\t 0\t 53\t 0.0\t 0.0\t 0.0\n",
      "tp: 117 fp: 53 fn: 53 labels: 2\n",
      "Macro-average\t prec: 0.34411764, rec: 0.5, f1: 0.4076655\n",
      "Micro-average\t prec: 0.6882353, rec: 0.6882353, f1: 0.6882353\n",
      "\n",
      "\n",
      "Epoch: 3 started, learning rate: 8.57375E-4, dataset size: 577\n",
      "Done, 2.685597071 total training loss: 2.4472969, avg training loss: 0.48945937, batches: 5\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.52s\n",
      "Total validation loss: 0.8032\tAvg validation loss: 0.4016\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 116\t 26\t 0\t 0.8169014\t 1.0\t 0.89922476\n",
      "absent\t 2\t 0\t 26\t 1.0\t 0.071428575\t 0.13333334\n",
      "tp: 118 fp: 26 fn: 26 labels: 2\n",
      "Macro-average\t prec: 0.9084507, rec: 0.53571427, f1: 0.6739812\n",
      "Micro-average\t prec: 0.8194444, rec: 0.8194444, f1: 0.8194445\n",
      "\n",
      "\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.59s\n",
      "Total test loss: 1.0405\tAvg test loss: 0.5202\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 117\t 47\t 0\t 0.7134146\t 1.0\t 0.8327402\n",
      "absent\t 6\t 0\t 47\t 1.0\t 0.11320755\t 0.20338982\n",
      "tp: 123 fp: 47 fn: 47 labels: 2\n",
      "Macro-average\t prec: 0.85670733, rec: 0.5566038, f1: 0.6747934\n",
      "Micro-average\t prec: 0.7235294, rec: 0.7235294, f1: 0.7235294\n",
      "\n",
      "\n",
      "Epoch: 4 started, learning rate: 8.145062E-4, dataset size: 577\n",
      "Done, 2.704177881 total training loss: 2.2614367, avg training loss: 0.45228735, batches: 5\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.52s\n",
      "Total validation loss: 0.7384\tAvg validation loss: 0.3692\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 115\t 22\t 1\t 0.8394161\t 0.9913793\t 0.9090909\n",
      "absent\t 6\t 1\t 22\t 0.85714287\t 0.21428572\t 0.34285715\n",
      "tp: 121 fp: 23 fn: 23 labels: 2\n",
      "Macro-average\t prec: 0.8482795, rec: 0.6028325, f1: 0.704798\n",
      "Micro-average\t prec: 0.8402778, rec: 0.8402778, f1: 0.8402778\n",
      "\n",
      "\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.60s\n",
      "Total test loss: 0.9418\tAvg test loss: 0.4709\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 117\t 39\t 0\t 0.75\t 1.0\t 0.85714287\n",
      "absent\t 14\t 0\t 39\t 1.0\t 0.26415095\t 0.41791046\n",
      "tp: 131 fp: 39 fn: 39 labels: 2\n",
      "Macro-average\t prec: 0.875, rec: 0.6320755, f1: 0.7339593\n",
      "Micro-average\t prec: 0.7705882, rec: 0.7705882, f1: 0.7705882\n",
      "\n",
      "\n",
      "Epoch: 5 started, learning rate: 7.7378086E-4, dataset size: 577\n",
      "Done, 2.765654885 total training loss: 2.1217086, avg training loss: 0.42434174, batches: 5\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.52s\n",
      "Total validation loss: 0.6841\tAvg validation loss: 0.3420\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 113\t 15\t 3\t 0.8828125\t 0.9741379\t 0.9262295\n",
      "absent\t 13\t 3\t 15\t 0.8125\t 0.4642857\t 0.59090906\n",
      "tp: 126 fp: 18 fn: 18 labels: 2\n",
      "Macro-average\t prec: 0.84765625, rec: 0.7192118, f1: 0.77816945\n",
      "Micro-average\t prec: 0.875, rec: 0.875, f1: 0.875\n",
      "\n",
      "\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.59s\n",
      "Total test loss: 0.8154\tAvg test loss: 0.4077\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 115\t 28\t 2\t 0.8041958\t 0.982906\t 0.8846154\n",
      "absent\t 25\t 2\t 28\t 0.9259259\t 0.4716981\t 0.625\n",
      "tp: 140 fp: 30 fn: 30 labels: 2\n",
      "Macro-average\t prec: 0.86506087, rec: 0.7273021, f1: 0.79022264\n",
      "Micro-average\t prec: 0.8235294, rec: 0.8235294, f1: 0.8235294\n",
      "\n",
      "\n",
      "Epoch: 6 started, learning rate: 7.350918E-4, dataset size: 577\n",
      "Done, 2.762225796 total training loss: 1.9511225, avg training loss: 0.39022452, batches: 5\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.51s\n",
      "Total validation loss: 0.6397\tAvg validation loss: 0.3199\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 111\t 11\t 5\t 0.90983605\t 0.95689654\t 0.9327731\n",
      "absent\t 17\t 5\t 11\t 0.77272725\t 0.60714287\t 0.68\n",
      "tp: 128 fp: 16 fn: 16 labels: 2\n",
      "Macro-average\t prec: 0.84128165, rec: 0.78201973, f1: 0.8105689\n",
      "Micro-average\t prec: 0.8888889, rec: 0.8888889, f1: 0.8888889\n",
      "\n",
      "\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.59s\n",
      "Total test loss: 0.6995\tAvg test loss: 0.3498\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 110\t 22\t 7\t 0.8333333\t 0.94017094\t 0.88353413\n",
      "absent\t 31\t 7\t 22\t 0.81578946\t 0.5849057\t 0.6813187\n",
      "tp: 141 fp: 29 fn: 29 labels: 2\n",
      "Macro-average\t prec: 0.82456136, rec: 0.7625383, f1: 0.7923379\n",
      "Micro-average\t prec: 0.82941175, rec: 0.82941175, f1: 0.82941175\n",
      "\n",
      "\n",
      "Epoch: 7 started, learning rate: 6.983372E-4, dataset size: 577\n",
      "Done, 2.712616376 total training loss: 1.7134274, avg training loss: 0.3426855, batches: 5\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.52s\n",
      "Total validation loss: 0.5931\tAvg validation loss: 0.2966\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 114\t 14\t 2\t 0.890625\t 0.98275864\t 0.93442625\n",
      "absent\t 14\t 2\t 14\t 0.875\t 0.5\t 0.6363636\n",
      "tp: 128 fp: 16 fn: 16 labels: 2\n",
      "Macro-average\t prec: 0.8828125, rec: 0.7413793, f1: 0.805938\n",
      "Micro-average\t prec: 0.8888889, rec: 0.8888889, f1: 0.8888889\n",
      "\n",
      "\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.59s\n",
      "Total test loss: 0.6656\tAvg test loss: 0.3328\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 115\t 28\t 2\t 0.8041958\t 0.982906\t 0.8846154\n",
      "absent\t 25\t 2\t 28\t 0.9259259\t 0.4716981\t 0.625\n",
      "tp: 140 fp: 30 fn: 30 labels: 2\n",
      "Macro-average\t prec: 0.86506087, rec: 0.7273021, f1: 0.79022264\n",
      "Micro-average\t prec: 0.8235294, rec: 0.8235294, f1: 0.8235294\n",
      "\n",
      "\n",
      "Epoch: 8 started, learning rate: 6.6342036E-4, dataset size: 577\n",
      "Done, 2.719090181 total training loss: 1.6095885, avg training loss: 0.3219177, batches: 5\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.52s\n",
      "Total validation loss: 0.5944\tAvg validation loss: 0.2972\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 106\t 9\t 10\t 0.9217391\t 0.9137931\t 0.9177489\n",
      "absent\t 19\t 10\t 9\t 0.6551724\t 0.6785714\t 0.6666667\n",
      "tp: 125 fp: 19 fn: 19 labels: 2\n",
      "Macro-average\t prec: 0.7884557, rec: 0.7961823, f1: 0.7923001\n",
      "Micro-average\t prec: 0.8680556, rec: 0.8680556, f1: 0.8680556\n",
      "\n",
      "\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.59s\n",
      "Total test loss: 0.5849\tAvg test loss: 0.2924\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 108\t 14\t 9\t 0.8852459\t 0.9230769\t 0.9037656\n",
      "absent\t 39\t 9\t 14\t 0.8125\t 0.7358491\t 0.77227724\n",
      "tp: 147 fp: 23 fn: 23 labels: 2\n",
      "Macro-average\t prec: 0.84887296, rec: 0.829463, f1: 0.8390558\n",
      "Micro-average\t prec: 0.86470586, rec: 0.86470586, f1: 0.86470586\n",
      "\n",
      "\n",
      "Epoch: 9 started, learning rate: 6.302493E-4, dataset size: 577\n",
      "Done, 2.742437782 total training loss: 1.5244641, avg training loss: 0.30489284, batches: 5\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.53s\n",
      "Total validation loss: 0.5453\tAvg validation loss: 0.2727\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 114\t 13\t 2\t 0.8976378\t 0.98275864\t 0.9382716\n",
      "absent\t 15\t 2\t 13\t 0.88235295\t 0.53571427\t 0.6666666\n",
      "tp: 129 fp: 15 fn: 15 labels: 2\n",
      "Macro-average\t prec: 0.88999534, rec: 0.75923645, f1: 0.81943226\n",
      "Micro-average\t prec: 0.8958333, rec: 0.8958333, f1: 0.8958334\n",
      "\n",
      "\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.60s\n",
      "Total test loss: 0.5971\tAvg test loss: 0.2986\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 116\t 24\t 1\t 0.82857144\t 0.991453\t 0.9027237\n",
      "absent\t 29\t 1\t 24\t 0.96666664\t 0.5471698\t 0.6987952\n",
      "tp: 145 fp: 25 fn: 25 labels: 2\n",
      "Macro-average\t prec: 0.897619, rec: 0.7693114, f1: 0.8285271\n",
      "Micro-average\t prec: 0.85294116, rec: 0.85294116, f1: 0.85294116\n",
      "\n",
      "\n",
      "Epoch: 10 started, learning rate: 5.9873686E-4, dataset size: 577\n",
      "Done, 2.734959831 total training loss: 1.5360202, avg training loss: 0.30720404, batches: 5\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.51s\n",
      "Total validation loss: 0.5550\tAvg validation loss: 0.2775\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 108\t 9\t 8\t 0.9230769\t 0.9310345\t 0.92703867\n",
      "absent\t 19\t 8\t 9\t 0.7037037\t 0.6785714\t 0.690909\n",
      "tp: 127 fp: 17 fn: 17 labels: 2\n",
      "Macro-average\t prec: 0.8133903, rec: 0.80480295, f1: 0.80907387\n",
      "Micro-average\t prec: 0.8819444, rec: 0.8819444, f1: 0.8819444\n",
      "\n",
      "\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.58s\n",
      "Total test loss: 0.5462\tAvg test loss: 0.2731\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 108\t 15\t 9\t 0.8780488\t 0.9230769\t 0.9\n",
      "absent\t 38\t 9\t 15\t 0.80851066\t 0.7169811\t 0.76000005\n",
      "tp: 146 fp: 24 fn: 24 labels: 2\n",
      "Macro-average\t prec: 0.8432797, rec: 0.820029, f1: 0.8314918\n",
      "Micro-average\t prec: 0.85882354, rec: 0.85882354, f1: 0.85882354\n",
      "\n",
      "\n",
      "Epoch: 11 started, learning rate: 5.688E-4, dataset size: 577\n",
      "Done, 2.769083698 total training loss: 1.5663543, avg training loss: 0.31327087, batches: 5\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.51s\n",
      "Total validation loss: 0.4964\tAvg validation loss: 0.2482\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 112\t 10\t 4\t 0.91803277\t 0.9655172\t 0.9411765\n",
      "absent\t 18\t 4\t 10\t 0.8181818\t 0.64285713\t 0.72\n",
      "tp: 130 fp: 14 fn: 14 labels: 2\n",
      "Macro-average\t prec: 0.8681073, rec: 0.8041872, f1: 0.83492565\n",
      "Micro-average\t prec: 0.9027778, rec: 0.9027778, f1: 0.9027778\n",
      "\n",
      "\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.59s\n",
      "Total test loss: 0.5194\tAvg test loss: 0.2597\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 115\t 17\t 2\t 0.8712121\t 0.982906\t 0.9236948\n",
      "absent\t 36\t 2\t 17\t 0.94736844\t 0.6792453\t 0.7912088\n",
      "tp: 151 fp: 19 fn: 19 labels: 2\n",
      "Macro-average\t prec: 0.9092903, rec: 0.83107567, f1: 0.8684255\n",
      "Micro-average\t prec: 0.8882353, rec: 0.8882353, f1: 0.8882353\n",
      "\n",
      "\n",
      "Epoch: 12 started, learning rate: 5.4036E-4, dataset size: 577\n",
      "Done, 2.730129449 total training loss: 1.4808924, avg training loss: 0.2961785, batches: 5\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.54s\n",
      "Total validation loss: 0.5145\tAvg validation loss: 0.2573\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 114\t 11\t 2\t 0.912\t 0.98275864\t 0.9460581\n",
      "absent\t 17\t 2\t 11\t 0.8947368\t 0.60714287\t 0.7234043\n",
      "tp: 131 fp: 13 fn: 13 labels: 2\n",
      "Macro-average\t prec: 0.9033684, rec: 0.7949507, f1: 0.84569895\n",
      "Micro-average\t prec: 0.9097222, rec: 0.9097222, f1: 0.9097222\n",
      "\n",
      "\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.60s\n",
      "Total test loss: 0.5657\tAvg test loss: 0.2829\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 116\t 21\t 1\t 0.84671533\t 0.991453\t 0.9133858\n",
      "absent\t 32\t 1\t 21\t 0.969697\t 0.6037736\t 0.7441861\n",
      "tp: 148 fp: 22 fn: 22 labels: 2\n",
      "Macro-average\t prec: 0.90820616, rec: 0.79761326, f1: 0.84932476\n",
      "Micro-average\t prec: 0.87058824, rec: 0.87058824, f1: 0.87058824\n",
      "\n",
      "\n",
      "Epoch: 13 started, learning rate: 5.13342E-4, dataset size: 577\n",
      "Done, 2.797825917 total training loss: 1.2489679, avg training loss: 0.24979357, batches: 5\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.51s\n",
      "Total validation loss: 0.5385\tAvg validation loss: 0.2693\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 110\t 8\t 6\t 0.9322034\t 0.94827586\t 0.94017094\n",
      "absent\t 20\t 6\t 8\t 0.7692308\t 0.71428573\t 0.7407408\n",
      "tp: 130 fp: 14 fn: 14 labels: 2\n",
      "Macro-average\t prec: 0.85071707, rec: 0.8312808, f1: 0.84088665\n",
      "Micro-average\t prec: 0.9027778, rec: 0.9027778, f1: 0.9027778\n",
      "\n",
      "\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.59s\n",
      "Total test loss: 0.5251\tAvg test loss: 0.2626\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 106\t 13\t 11\t 0.8907563\t 0.9059829\t 0.8983051\n",
      "absent\t 40\t 11\t 13\t 0.78431374\t 0.754717\t 0.7692308\n",
      "tp: 146 fp: 24 fn: 24 labels: 2\n",
      "Macro-average\t prec: 0.837535, rec: 0.8303499, f1: 0.833927\n",
      "Micro-average\t prec: 0.85882354, rec: 0.85882354, f1: 0.85882354\n",
      "\n",
      "\n",
      "Epoch: 14 started, learning rate: 4.8767487E-4, dataset size: 577\n",
      "Done, 2.749479035 total training loss: 1.333621, avg training loss: 0.2667242, batches: 5\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.51s\n",
      "Total validation loss: 0.4902\tAvg validation loss: 0.2451\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 111\t 10\t 5\t 0.91735536\t 0.95689654\t 0.93670887\n",
      "absent\t 18\t 5\t 10\t 0.7826087\t 0.64285713\t 0.7058824\n",
      "tp: 129 fp: 15 fn: 15 labels: 2\n",
      "Macro-average\t prec: 0.849982, rec: 0.7998768, f1: 0.8241686\n",
      "Micro-average\t prec: 0.8958333, rec: 0.8958333, f1: 0.8958334\n",
      "\n",
      "\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.60s\n",
      "Total test loss: 0.5043\tAvg test loss: 0.2521\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 116\t 16\t 1\t 0.8787879\t 0.991453\t 0.9317269\n",
      "absent\t 37\t 1\t 16\t 0.9736842\t 0.6981132\t 0.8131868\n",
      "tp: 153 fp: 17 fn: 17 labels: 2\n",
      "Macro-average\t prec: 0.92623603, rec: 0.84478307, f1: 0.8836364\n",
      "Micro-average\t prec: 0.9, rec: 0.9, f1: 0.9\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"./training_logs/\"+log_files[0]) as log_file:\n",
    "    print(log_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-k2WrFkRyQyP",
    "outputId": "675a5613-6291-49a9-cdfa-ef8ba5938d27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+\n",
      "|  label|   result|\n",
      "+-------+---------+\n",
      "|present|[present]|\n",
      "| absent|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "+-------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "preds = assertion_model.transform(test_data).select('label','assertion.result')\n",
    "\n",
    "preds.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "4yI73lwG2xk5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "preds_df = preds.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "yRXZFGlQ3Z2U",
    "outputId": "c7c30d32-2e4e-46db-81d0-2f4312916c9c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>present</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>absent</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>present</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>present</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>present</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>present</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>absent</td>\n",
       "      <td>absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>absent</td>\n",
       "      <td>absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>absent</td>\n",
       "      <td>absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>present</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label   result\n",
       "0    present  present\n",
       "1     absent  present\n",
       "2    present  present\n",
       "3    present  present\n",
       "4    present  present\n",
       "..       ...      ...\n",
       "165  present  present\n",
       "166   absent   absent\n",
       "167   absent   absent\n",
       "168   absent   absent\n",
       "169  present  present\n",
       "\n",
       "[170 rows x 2 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df['result'] = preds_df['result'].apply(lambda x : x[0])\n",
    "preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sYoEUlfU3cCU",
    "outputId": "5985747a-288d-485a-9f0f-aa9ebb59465c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      absent       0.95      0.70      0.80        53\n",
      "     present       0.88      0.98      0.93       117\n",
      "\n",
      "    accuracy                           0.89       170\n",
      "   macro avg       0.91      0.84      0.87       170\n",
      "weighted avg       0.90      0.89      0.89       170\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We are going to use sklearn to evalute the results on test dataset\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print (classification_report( preds_df['label'], preds_df['result']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "atNaIlnP3gKr"
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "assertion_model.stages[-1].write().overwrite().save('assertion_custom_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[OK!]\n",
      "ner_clinical download started this may take some time.\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "documentAssembler = nlp.DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "# Sentence Detector annotator, processes various sentences per line\n",
    "sentenceDetector = nlp.SentenceDetector()\\\n",
    "    .setInputCols([\"document\"])\\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "# Tokenizer splits words in a relevant format for NLP\n",
    "tokenizer = nlp.Tokenizer()\\\n",
    "    .setInputCols([\"sentence\"])\\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "# Clinical word embeddings trained on PubMED dataset\n",
    "word_embeddings = nlp.WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n",
    "    .setInputCols([\"sentence\", \"token\"])\\\n",
    "    .setOutputCol(\"embeddings\")\n",
    "\n",
    "clinical_ner = medical.NerModel.pretrained(\"ner_clinical\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"ner\")\n",
    "\n",
    "ner_converter = medical.NerConverterInternal() \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"ner\"]) \\\n",
    "    .setOutputCol(\"ner_chunk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_assertion = medical.AssertionDLModel.load(\"assertion_custom_model\") \\\n",
    "    .setInputCols([\"sentence\", \"ner_chunk\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"assertion\")\n",
    "\n",
    "nlpPipeline = nlp.Pipeline(stages=[\n",
    "    documentAssembler,\n",
    "    sentenceDetector,\n",
    "    tokenizer,\n",
    "    word_embeddings,\n",
    "    clinical_ner,\n",
    "    ner_converter,\n",
    "    clinical_assertion\n",
    "    ])\n",
    "\n",
    "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "model = nlpPipeline.fit(empty_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient has a headache for the last 2 weeks, needs to get a head CT, and appears anxious when she walks fast. No alopecia noted. She denies pain\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunks</th>\n",
       "      <th>entities</th>\n",
       "      <th>assertion</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a headache</td>\n",
       "      <td>PROBLEM</td>\n",
       "      <td>present</td>\n",
       "      <td>0.9765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a head CT</td>\n",
       "      <td>TEST</td>\n",
       "      <td>present</td>\n",
       "      <td>0.9928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anxious</td>\n",
       "      <td>PROBLEM</td>\n",
       "      <td>present</td>\n",
       "      <td>0.9113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alopecia</td>\n",
       "      <td>PROBLEM</td>\n",
       "      <td>absent</td>\n",
       "      <td>0.6672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pain</td>\n",
       "      <td>PROBLEM</td>\n",
       "      <td>present</td>\n",
       "      <td>0.6478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       chunks entities assertion confidence\n",
       "0  a headache  PROBLEM   present     0.9765\n",
       "1   a head CT     TEST   present     0.9928\n",
       "2     anxious  PROBLEM   present     0.9113\n",
       "3    alopecia  PROBLEM    absent     0.6672\n",
       "4        pain  PROBLEM   present     0.6478"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Patient has a headache for the last 2 weeks, needs to get a head CT, and appears anxious when she walks fast. No alopecia noted. She denies pain'\n",
    "\n",
    "light_model = nlp.LightPipeline(model)\n",
    "\n",
    "light_result = light_model.fullAnnotate(text)[0]\n",
    "\n",
    "print(text)\n",
    "\n",
    "chunks=[]\n",
    "entities=[]\n",
    "status=[]\n",
    "confidence=[]\n",
    "\n",
    "for n,m in zip(light_result['ner_chunk'],light_result['assertion']):\n",
    "\n",
    "    chunks.append(n.result)\n",
    "    entities.append(n.metadata['entity'])\n",
    "    status.append(m.result)\n",
    "    confidence.append(m.metadata['confidence'])\n",
    "\n",
    "df = pd.DataFrame({'chunks':chunks, 'entities':entities, 'assertion':status, 'confidence':confidence})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "eaef4d22edbbdbc68b8d50d2a1a48c6349c8418c1052069fe906c41d47bd13e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
