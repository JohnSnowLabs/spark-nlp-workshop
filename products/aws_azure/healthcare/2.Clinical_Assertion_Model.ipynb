{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I08sFJYCxR0Z"
   },
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Niy3mZAjoayg"
   },
   "source": [
    "# Clinical Assertion Status Model \n",
    "\n",
    "\n",
    "The deep neural network architecture for assertion status detection in Spark NLP is based on a Bi-LSTM framework, and is a modified version of the architecture proposed by Federico Fancellu, Adam Lopez and Bonnie Webber ([Neural Networks For Negation Scope Detection](https://aclanthology.org/P16-1047.pdf)). Its goal is to classify the assertions made on given medical concepts as being present, absent, or possible in the patient, conditionally present in the patient under certain circumstances,\n",
    "hypothetically present in the patient at some future point, and\n",
    "mentioned in the patient report but associated with someoneelse.\n",
    "In the proposed implementation, input units depend on the\n",
    "target tokens (a named entity) and the neighboring words that\n",
    "are explicitly encoded as a sequence using word embeddings.\n",
    "Similar to paper mentioned above,  it is observed that that 95% of the scope tokens (neighboring words) fall in a window of 9 tokens to the left and 15\n",
    "to the right of the target tokens in the same dataset. Therefore, the same window size was implemented and it following parameters were used: learning\n",
    "rate 0.0012, dropout 0.05, batch size 64 and a maximum sentence length 250. The model has been implemented within\n",
    "Spark NLP as an annotator called AssertionDLModel. After\n",
    "training 20 epoch and measuring accuracy on the official test\n",
    "set, this implementation exceeds the latest state-of-the-art\n",
    "accuracy benchmarks as summarized as following table:\n",
    "\n",
    "|Assertion Label|Spark NLP|Latest Best|\n",
    "|-|-|-|\n",
    "|Absent       |0.944 |0.937|\n",
    "|Someone-else |0.904|0.869|\n",
    "|Conditional  |0.441|0.422|\n",
    "|Hypothetical |0.862|0.890|\n",
    "|Possible     |0.680|0.630|\n",
    "|Present      |0.953|0.957|\n",
    "|micro F1     |0.939|0.934|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "okhT7AcXxben"
   },
   "source": [
    "**Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 Loading license number 0 from /home/ubuntu/.johnsnowlabs/licenses/license_number_0_for_.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/ubuntu/.jup_env/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "23/01/06 14:04:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/01/06 14:04:54 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👌 Launched \u001b[92mcpu optimized\u001b[39m session with with: 🚀Spark-NLP==4.2.4, 💊Spark-Healthcare==4.2.4, running on ⚡ PySpark==3.1.2\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml import Pipeline,PipelineModel\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "from johnsnowlabs import nlp, medical\n",
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "spark = start_spark()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AMU4sAJQ0Rhs"
   },
   "source": [
    "# Clinical Assertion Models (with pretrained models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kql2KmQ35H7H"
   },
   "source": [
    "|    | model_name              |Predicted Entities|\n",
    "|---:|:------------------------|-|\n",
    "|  1 | [assertion_dl](https://nlp.johnsnowlabs.com/2021/01/26/assertion_dl_en.html)            |Present, Absent, Possible, conditional, hypothetical, associated_with_someone_else|\n",
    "|  2 | [assertion_dl_biobert](https://nlp.johnsnowlabs.com/2021/01/26/assertion_dl_biobert_en.html)    |Present, Absent, Possible, conditional, hypothetical, associated_with_someone_else|\n",
    "|  3 | [assertion_dl_healthcare](https://nlp.johnsnowlabs.com/2020/09/23/assertion_dl_healthcare_en.html) |Present, Absent, Possible, conditional, hypothetical, associated_with_someone_else|\n",
    "|  4 | [assertion_dl_large](https://nlp.johnsnowlabs.com/2020/05/21/assertion_dl_large_en.html)      |Present, Absent, Possible, conditional, hypothetical, associated_with_someone_else|\n",
    "|  5 | [assertion_dl_radiology](https://nlp.johnsnowlabs.com/2021/03/18/assertion_dl_radiology_en.html)   |Confirmed, Suspected, Negative|\n",
    "|  6 | [assertion_jsl](https://nlp.johnsnowlabs.com/2021/07/24/assertion_jsl_en.html)           |Present, Absent, Possible, Planned, Someoneelse, Past, Family, Hypotetical|\n",
    "|  7 | [assertion_jsl_large](https://nlp.johnsnowlabs.com/2021/07/24/assertion_jsl_large_en.html)     |present, absent, possible, planned, someoneelse, past, hypothetical|\n",
    "|  8 |  [assertion_ml](https://nlp.johnsnowlabs.com/2020/01/30/assertion_ml_en.html) |Hypothetical, Present, Absent, Possible, Conditional, Associated_with_someone_else|\n",
    "|  9 | [assertion_dl_scope_L10R10](https://nlp.johnsnowlabs.com/2022/03/17/assertion_dl_scope_L10R10_en_3_0.html)| hypothetical, associated_with_someone_else, conditional, possible, absent, present|\n",
    "| 10 | [assertion_dl_biobert_scope_L10R10](https://nlp.johnsnowlabs.com/2022/03/24/assertion_dl_biobert_scope_L10R10_en_2_4.html)| hypothetical, associated_with_someone_else, conditional, possible, absent, present|\n",
    "| 11 | [assertion_jsl_augmented](https://nlp.johnsnowlabs.com/2022/09/15/assertion_jsl_augmented_en.html)| Present, Absent, Possible, Planned, Past, Family, Hypotetical, SomeoneElse|\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Oncology Assertion Models\n",
    "|    | model_name              |Predicted Entities|\n",
    "|---:|:------------------------|-|\n",
    "| 1 | **assertion_oncology_wip** | Medical_History, Family_History, Possible, Hypothetical_Or_Absent|\n",
    "| 2 | **assertion_oncology_problem_wip** |Present, Possible, Hypothetical, Absent, Family|\n",
    "| 3 | **assertion_oncology_treatment_wip** |Present, Planned, Past, Hypothetical, Absent|\n",
    "| 4 | **assertion_oncology_response_to_treatment_wip** |Present_Or_Past, Hypothetical_Or_Absent|\n",
    "| 5 | **assertion_oncology_test_binary_wip** |Present_Or_Past, Hypothetical_Or_Absent|\n",
    "| 6 | **assertion_oncology_smoking_status_wip** |Absent, Past, Present|\n",
    "| 7 | **assertion_oncology_family_history_wip** |Family_History, Other|\n",
    "| 8 | **assertion_oncology_demographic_binary_wip** |Patient, Someone_Else|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "voZj8-NSbe4j"
   },
   "source": [
    "### Pretrained `assertion_jsl_augmented` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 81250,
     "status": "ok",
     "timestamp": 1662533938957,
     "user": {
      "displayName": "Merve Ertas Uslu",
      "userId": "01451729557099986551"
     },
     "user_tz": -120
    },
    "id": "DEa5SITBxmY0",
    "outputId": "27161324-cd9f-4eb7-a67a-026d9a0b97c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[ | ]embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "Download done! Loading the resource.\n",
      "[OK!]\n",
      "ner_jsl download started this may take some time.\n",
      "[ | ]ner_jsl download started this may take some time.\n",
      "Approximate size to download 14.5 MB\n",
      "Download done! Loading the resource.\n",
      "[OK!]\n",
      "assertion_jsl_augmented download started this may take some time.\n",
      "[ | ]assertion_jsl_augmented download started this may take some time.\n",
      "Approximate size to download 6.2 MB\n",
      "Download done! Loading the resource.\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "# Annotator that transforms a text column from dataframe into an Annotation ready for NLP\n",
    "\n",
    "documentAssembler = nlp.DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "# Sentence Detector annotator, processes various sentences per line\n",
    "sentenceDetector = nlp.SentenceDetector()\\\n",
    "    .setInputCols([\"document\"])\\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "# Tokenizer splits words in a relevant format for NLP\n",
    "tokenizer = nlp.Tokenizer()\\\n",
    "    .setInputCols([\"sentence\"])\\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "# Clinical word embeddings trained on PubMED dataset\n",
    "word_embeddings = nlp.WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n",
    "    .setInputCols([\"sentence\", \"token\"])\\\n",
    "    .setOutputCol(\"embeddings\")\n",
    "\n",
    "# NER model trained on i2b2 (sampled from MIMIC) dataset\n",
    "clinical_ner = medical.NerModel.pretrained(\"ner_jsl\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"ner\")\\\n",
    "    #.setIncludeAllConfidenceScores(False)\n",
    "\n",
    "ner_converter = medical.NerConverterInternal() \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"ner\"]) \\\n",
    "    .setOutputCol(\"ner_chunk\")\\\n",
    "    .setWhiteList([\"SYMPTOM\",\"VS_FINDING\",\"DISEASE_SYNDROME_DISORDER\",\"ADMISSION_DISCHARGE\",\"PROCEDURE\"])\n",
    "\n",
    "# Assertion model trained on i2b2 (sampled from MIMIC) dataset\n",
    "clinical_assertion = medical.AssertionDLModel.pretrained(\"assertion_jsl_augmented\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\", \"ner_chunk\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"assertion\")\n",
    "    \n",
    "nlpPipeline = nlp.Pipeline(stages=[\n",
    "    documentAssembler, \n",
    "    sentenceDetector,\n",
    "    tokenizer,\n",
    "    word_embeddings,\n",
    "    clinical_ner,\n",
    "    ner_converter,\n",
    "    clinical_assertion\n",
    "    ])\n",
    "\n",
    "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "model = nlpPipeline.fit(empty_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 206,
     "status": "ok",
     "timestamp": 1662533942646,
     "user": {
      "displayName": "Merve Ertas Uslu",
      "userId": "01451729557099986551"
     },
     "user_tz": -120
    },
    "id": "-Z232ubQeyTu",
    "outputId": "85c37914-4404-40bb-ef2a-56ec981fbfe2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='AssertionDLApproach_b7f93b0aefdc', name='lazyAnnotator', doc='Whether this AnnotatorModel acts as lazy in RecursivePipelines'): False,\n",
       " Param(parent='AssertionDLApproach_b7f93b0aefdc', name='label', doc='Column with one label per document'): 'label',\n",
       " Param(parent='AssertionDLApproach_b7f93b0aefdc', name='batchSize', doc='Size for each batch in the optimization process'): 64,\n",
       " Param(parent='AssertionDLApproach_b7f93b0aefdc', name='epochs', doc='Number of epochs for the optimization process'): 5,\n",
       " Param(parent='AssertionDLApproach_b7f93b0aefdc', name='learningRate', doc='Learning rate for the optimization process'): 0.0012,\n",
       " Param(parent='AssertionDLApproach_b7f93b0aefdc', name='dropout', doc='Dropout at the output of each layer'): 0.05,\n",
       " Param(parent='AssertionDLApproach_b7f93b0aefdc', name='maxSentLen', doc='Max length for an input sentence.'): 250,\n",
       " Param(parent='AssertionDLApproach_b7f93b0aefdc', name='includeConfidence', doc='whether to include confidence scores in annotation metadata'): True,\n",
       " Param(parent='AssertionDLApproach_b7f93b0aefdc', name='scopeWindow', doc='The scope window of the assertion expression'): [-1,\n",
       "  -1]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medical.AssertionDLApproach().extractParamMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "SMzVzklLw7B3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclinical_assertion_ml = AssertionLogRegModel.pretrained(\"assertion_ml\", \"en\", \"clinical/models\")     .setInputCols([\"sentence\", \"ner_chunk\", \"embeddings\"])     .setOutputCol(\"assertion\")\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we also have a LogReg based Assertion Model.\n",
    "'''\n",
    "clinical_assertion_ml = AssertionLogRegModel.pretrained(\"assertion_ml\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\", \"ner_chunk\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"assertion\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "executionInfo": {
     "elapsed": 1817,
     "status": "ok",
     "timestamp": 1662533950069,
     "user": {
      "displayName": "Merve Ertas Uslu",
      "userId": "01451729557099986551"
     },
     "user_tz": -120
    },
    "id": "f2RPZMmbVeN3",
    "outputId": "24e6998c-4ad0-4693-d82e-533ec28cd796"
   },
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "GENERAL: He is an elderly gentleman in no acute distress. He is sitting up in bed eating his breakfast. He is alert and oriented and answering questions appropriately.\n",
    "HEENT: Sclerae show mild arcus senilis in the right. Left is clear. Pupils are equally round and reactive to light. Extraocular movements are intact. Oropharynx is clear.\n",
    "NECK: Supple. Trachea is midline. No jugular venous pressure distention is noted. No adenopathy in the cervical, supraclavicular, or axillary areas.\n",
    "ABDOMEN: Soft and nontender. There may be some fullness in the left upper quadrant, although I do not appreciate a true spleen with inspiration.\n",
    "EXTREMITIES: There is some edema, but no cyanosis and clubbing .\n",
    "IMPRESSION: At this time is refractory anemia, which is transfusion dependent. He is on B12, iron, folic acid, and Procrit. There are no sign or symptom of blood loss and a recent esophagogastroduodenoscopy, which was negative. His creatinine was 1. \n",
    "  My impression at this time is that he probably has an underlying myelodysplastic syndrome or bone marrow failure. His creatinine on this hospitalization was up slightly to 1.6 and this may contribute to his anemia.\n",
    "  At this time, my recommendation for the patient is that he undergoes further serologic evaluation with reticulocyte count, serum protein, and electrophoresis, LDH, B12, folate, erythropoietin level, and he should undergo a bone marrow aspiration and biopsy. \n",
    "  I have discussed the procedure in detail which the patient. I have discussed the risks, benefits, and successes of that treatment and usefulness of the bone marrow and predicting his cause of refractory anemia and further therapeutic interventions, which might be beneficial to him. \n",
    "  He is willing to proceed with the studies I have described to him. We will order an ultrasound of his abdomen because of the possible fullness of the spleen, and I will probably see him in follow up after this hospitalization.\n",
    "  As always, we greatly appreciate being able to participate in the care of your patient. We appreciate the consultation of the patient. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunks</th>\n",
       "      <th>entities</th>\n",
       "      <th>assertion</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>distress</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arcus senilis</td>\n",
       "      <td>Disease_Syndrome_Disorder</td>\n",
       "      <td>Past</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jugular venous pressure distention</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adenopathy</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nontender</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fullness</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Possible</td>\n",
       "      <td>0.9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>edema</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Present</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cyanosis</td>\n",
       "      <td>VS_Finding</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>clubbing</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>anemia</td>\n",
       "      <td>Disease_Syndrome_Disorder</td>\n",
       "      <td>Hypothetical</td>\n",
       "      <td>0.9758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>blood loss</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>esophagogastroduodenoscopy</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>myelodysplastic syndrome</td>\n",
       "      <td>Disease_Syndrome_Disorder</td>\n",
       "      <td>Possible</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bone marrow failure</td>\n",
       "      <td>Disease_Syndrome_Disorder</td>\n",
       "      <td>Possible</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hospitalization</td>\n",
       "      <td>Admission_Discharge</td>\n",
       "      <td>Past</td>\n",
       "      <td>0.9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>anemia</td>\n",
       "      <td>Disease_Syndrome_Disorder</td>\n",
       "      <td>Present</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bone marrow aspiration</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>Planned</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>biopsy</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>Planned</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>anemia</td>\n",
       "      <td>Disease_Syndrome_Disorder</td>\n",
       "      <td>Hypothetical</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>fullness of the spleen</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Possible</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>hospitalization</td>\n",
       "      <td>Admission_Discharge</td>\n",
       "      <td>Planned</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                chunks                   entities  \\\n",
       "0                             distress                    Symptom   \n",
       "1                        arcus senilis  Disease_Syndrome_Disorder   \n",
       "2   jugular venous pressure distention                    Symptom   \n",
       "3                           adenopathy                    Symptom   \n",
       "4                            nontender                    Symptom   \n",
       "5                             fullness                    Symptom   \n",
       "6                                edema                    Symptom   \n",
       "7                             cyanosis                 VS_Finding   \n",
       "8                             clubbing                    Symptom   \n",
       "9                               anemia  Disease_Syndrome_Disorder   \n",
       "10                          blood loss                    Symptom   \n",
       "11          esophagogastroduodenoscopy                  Procedure   \n",
       "12            myelodysplastic syndrome  Disease_Syndrome_Disorder   \n",
       "13                 bone marrow failure  Disease_Syndrome_Disorder   \n",
       "14                     hospitalization        Admission_Discharge   \n",
       "15                              anemia  Disease_Syndrome_Disorder   \n",
       "16              bone marrow aspiration                  Procedure   \n",
       "17                              biopsy                  Procedure   \n",
       "18                              anemia  Disease_Syndrome_Disorder   \n",
       "19              fullness of the spleen                    Symptom   \n",
       "20                     hospitalization        Admission_Discharge   \n",
       "\n",
       "       assertion confidence  \n",
       "0         Absent        1.0  \n",
       "1           Past        1.0  \n",
       "2         Absent        1.0  \n",
       "3         Absent        1.0  \n",
       "4         Absent        1.0  \n",
       "5       Possible     0.9999  \n",
       "6        Present        1.0  \n",
       "7         Absent        1.0  \n",
       "8         Absent        1.0  \n",
       "9   Hypothetical     0.9758  \n",
       "10        Absent        1.0  \n",
       "11        Absent        1.0  \n",
       "12      Possible        1.0  \n",
       "13      Possible        1.0  \n",
       "14          Past     0.9999  \n",
       "15       Present        1.0  \n",
       "16       Planned        1.0  \n",
       "17       Planned        1.0  \n",
       "18  Hypothetical      0.999  \n",
       "19      Possible        1.0  \n",
       "20       Planned        1.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "light_model = nlp.LightPipeline(model)\n",
    "\n",
    "light_result = light_model.fullAnnotate(text)[0]\n",
    "\n",
    "chunks=[]\n",
    "entities=[]\n",
    "status=[]\n",
    "confidence=[]\n",
    "\n",
    "for n,m in zip(light_result['ner_chunk'],light_result['assertion']):\n",
    "    \n",
    "    chunks.append(n.result)\n",
    "    entities.append(n.metadata['entity']) \n",
    "    status.append(m.result)\n",
    "    confidence.append(m.metadata['confidence'])\n",
    "        \n",
    "df = pd.DataFrame({'chunks':chunks, 'entities':entities, 'assertion':status, 'confidence':confidence})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    @import url('https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700&display=swap');\n",
       "    @import url('https://fonts.googleapis.com/css2?family=Vistol Regular:wght@300;400;500;600;700&display=swap');\n",
       "    \n",
       "    .spark-nlp-display-scroll-entities {\n",
       "        border: 1px solid #E7EDF0;\n",
       "        border-radius: 3px;\n",
       "        text-align: justify;\n",
       "        \n",
       "    }\n",
       "    .spark-nlp-display-scroll-entities span {  \n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        color: #536B76;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "    }\n",
       "    \n",
       "    .spark-nlp-display-entity-wrapper{\n",
       "    \n",
       "        display: inline-grid;\n",
       "        text-align: center;\n",
       "        border-radius: 4px;\n",
       "        margin: 0 2px 5px 2px;\n",
       "        padding: 1px\n",
       "    }\n",
       "    .spark-nlp-display-entity-name{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "        \n",
       "        background: #f1f2f3;\n",
       "        border-width: medium;\n",
       "        text-align: center;\n",
       "        \n",
       "        font-weight: 400;\n",
       "        \n",
       "        border-radius: 5px;\n",
       "        padding: 2px 5px;\n",
       "        display: block;\n",
       "        margin: 3px 2px;\n",
       "    \n",
       "    }\n",
       "    .spark-nlp-display-entity-type{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        color: #ffffff;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "        \n",
       "        text-transform: uppercase;\n",
       "        \n",
       "        font-weight: 500;\n",
       "\n",
       "        display: block;\n",
       "        padding: 3px 5px;\n",
       "    }\n",
       "    \n",
       "    .spark-nlp-display-entity-resolution{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        color: #ffffff;\n",
       "        font-family: 'Vistol Regular', sans-serif !important;\n",
       "        \n",
       "        text-transform: uppercase;\n",
       "        \n",
       "        font-weight: 500;\n",
       "\n",
       "        display: block;\n",
       "        padding: 3px 5px;\n",
       "    }\n",
       "    \n",
       "    .spark-nlp-display-others{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "        \n",
       "        font-weight: 400;\n",
       "    }\n",
       "\n",
       "</style>\n",
       " <span class=\"spark-nlp-display-others\" style=\"background-color: white\"><br>GENERAL: He is an elderly gentleman in no acute </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #030583B3\"><span class=\"spark-nlp-display-entity-name\">distress </span><span class=\"spark-nlp-display-entity-type\">Symptom</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #030583FF\">Absent </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">. He is sitting up in bed eating his breakfast. He is alert and oriented and answering questions appropriately.<br>HEENT: Sclerae show mild </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #A49D3EB3\"><span class=\"spark-nlp-display-entity-name\">arcus senilis </span><span class=\"spark-nlp-display-entity-type\">Disease_Syndrome_Disorder</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #A49D3EFF\">Past </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> in the right. Left is clear. Pupils are equally round and reactive to light. Extraocular movements are intact. Oropharynx is clear.<br>NECK: Supple. Trachea is midline. No </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #030583B3\"><span class=\"spark-nlp-display-entity-name\">jugular venous pressure distention </span><span class=\"spark-nlp-display-entity-type\">Symptom</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #030583FF\">Absent </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> is noted. No </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #030583B3\"><span class=\"spark-nlp-display-entity-name\">adenopathy </span><span class=\"spark-nlp-display-entity-type\">Symptom</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #030583FF\">Absent </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> in the cervical, supraclavicular, or axillary areas.<br>ABDOMEN: Soft and </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #030583B3\"><span class=\"spark-nlp-display-entity-name\">nontender </span><span class=\"spark-nlp-display-entity-type\">Symptom</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #030583FF\">Absent </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">. There may be some </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #030583B3\"><span class=\"spark-nlp-display-entity-name\">fullness </span><span class=\"spark-nlp-display-entity-type\">Symptom</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #030583FF\">Possible </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> in the left upper quadrant, although I do not appreciate a true spleen with inspiration.<br>EXTREMITIES: There is some </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #030583B3\"><span class=\"spark-nlp-display-entity-name\">edema </span><span class=\"spark-nlp-display-entity-type\">Symptom</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #030583FF\">Present </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, but no </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #6B84A4B3\"><span class=\"spark-nlp-display-entity-name\">cyanosis </span><span class=\"spark-nlp-display-entity-type\">VS_Finding</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #6B84A4FF\">Absent </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> and </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #030583B3\"><span class=\"spark-nlp-display-entity-name\">clubbing </span><span class=\"spark-nlp-display-entity-type\">Symptom</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #030583FF\">Absent </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> .<br>IMPRESSION: At this time is refractory </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #A49D3EB3\"><span class=\"spark-nlp-display-entity-name\">anemia </span><span class=\"spark-nlp-display-entity-type\">Disease_Syndrome_Disorder</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #A49D3EFF\">Hypothetical </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, which is transfusion dependent. He is on B12, iron, folic acid, and Procrit. There are no sign or symptom of </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #030583B3\"><span class=\"spark-nlp-display-entity-name\">blood loss </span><span class=\"spark-nlp-display-entity-type\">Symptom</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #030583FF\">Absent </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> and a recent </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #92C672B3\"><span class=\"spark-nlp-display-entity-name\">esophagogastroduodenoscopy </span><span class=\"spark-nlp-display-entity-type\">Procedure</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #92C672FF\">Absent </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, which was negative. His creatinine was 1. <br>  My impression at this time is that he probably has an underlying </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #A49D3EB3\"><span class=\"spark-nlp-display-entity-name\">myelodysplastic syndrome </span><span class=\"spark-nlp-display-entity-type\">Disease_Syndrome_Disorder</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #A49D3EFF\">Possible </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> or </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #A49D3EB3\"><span class=\"spark-nlp-display-entity-name\">bone marrow failure </span><span class=\"spark-nlp-display-entity-type\">Disease_Syndrome_Disorder</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #A49D3EFF\">Possible </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">. His creatinine on this </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #370F76B3\"><span class=\"spark-nlp-display-entity-name\">hospitalization </span><span class=\"spark-nlp-display-entity-type\">Admission_Discharge</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #370F76FF\">Past </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> was up slightly to 1.6 and this may contribute to his </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #A49D3EB3\"><span class=\"spark-nlp-display-entity-name\">anemia </span><span class=\"spark-nlp-display-entity-type\">Disease_Syndrome_Disorder</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #A49D3EFF\">Present </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">.<br>  At this time, my recommendation for the patient is that he undergoes further serologic evaluation with reticulocyte count, serum protein, and electrophoresis, LDH, B12, folate, erythropoietin level, and he should undergo a </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #92C672B3\"><span class=\"spark-nlp-display-entity-name\">bone marrow aspiration </span><span class=\"spark-nlp-display-entity-type\">Procedure</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #92C672FF\">Planned </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> and </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #92C672B3\"><span class=\"spark-nlp-display-entity-name\">biopsy </span><span class=\"spark-nlp-display-entity-type\">Procedure</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #92C672FF\">Planned </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">. <br>  I have discussed the procedure in detail which the patient. I have discussed the risks, benefits, and successes of that treatment and usefulness of the bone marrow and predicting his cause of refractory </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #A49D3EB3\"><span class=\"spark-nlp-display-entity-name\">anemia </span><span class=\"spark-nlp-display-entity-type\">Disease_Syndrome_Disorder</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #A49D3EFF\">Hypothetical </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> and further therapeutic interventions, which might be beneficial to him. <br>  He is willing to proceed with the studies I have described to him. We will order an ultrasound of his abdomen because of the possible </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #030583B3\"><span class=\"spark-nlp-display-entity-name\">fullness of the spleen </span><span class=\"spark-nlp-display-entity-type\">Symptom</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #030583FF\">Possible </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, and I will probably see him in follow up after this </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #370F76B3\"><span class=\"spark-nlp-display-entity-name\">hospitalization </span><span class=\"spark-nlp-display-entity-type\">Admission_Discharge</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #370F76FF\">Planned </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">.<br>  As always, we greatly appreciate being able to participate in the care of your patient. We appreciate the consultation of the patient. <br></span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "light_model = nlp.LightPipeline(model)\n",
    "\n",
    "light_result = light_model.fullAnnotate(text)[0]\n",
    "\n",
    "vis = nlp.viz.AssertionVisualizer()\n",
    "\n",
    "vis.display(light_result, 'ner_chunk', 'assertion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5991,
     "status": "ok",
     "timestamp": 1662533959181,
     "user": {
      "displayName": "Merve Ertas Uslu",
      "userId": "01451729557099986551"
     },
     "user_tz": -120
    },
    "id": "taZh-fh-vjrZ",
    "outputId": "ec413739-c445-4dbd-dc05-136a979061d7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['assertion', 'assertion_confidence', 'document', 'entities_ner_chunk',\n",
       "       'entities_ner_chunk_class', 'entities_ner_chunk_confidence',\n",
       "       'entities_ner_chunk_origin_chunk', 'entities_ner_chunk_origin_sentence',\n",
       "       'sentence_pragmatic', 'word_embedding_embeddings'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.nlu.to_pretty_df(model,text,output_level='chunk').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 1899,
     "status": "ok",
     "timestamp": 1662533963637,
     "user": {
      "displayName": "Merve Ertas Uslu",
      "userId": "01451729557099986551"
     },
     "user_tz": -120
    },
    "id": "0SVPER6bvkmk",
    "outputId": "c8384265-80c7-4345-ad73-7fb6aa3dc1a6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entities_ner_chunk</th>\n",
       "      <th>entities_ner_chunk_class</th>\n",
       "      <th>assertion</th>\n",
       "      <th>assertion_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>distress</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arcus senilis</td>\n",
       "      <td>Disease_Syndrome_Disorder</td>\n",
       "      <td>Past</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jugular venous pressure distention</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adenopathy</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nontender</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fullness</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Possible</td>\n",
       "      <td>0.9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>edema</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Present</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cyanosis</td>\n",
       "      <td>VS_Finding</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>clubbing</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>anemia</td>\n",
       "      <td>Disease_Syndrome_Disorder</td>\n",
       "      <td>Hypothetical</td>\n",
       "      <td>0.9758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>blood loss</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>esophagogastroduodenoscopy</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>myelodysplastic syndrome</td>\n",
       "      <td>Disease_Syndrome_Disorder</td>\n",
       "      <td>Possible</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bone marrow failure</td>\n",
       "      <td>Disease_Syndrome_Disorder</td>\n",
       "      <td>Possible</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hospitalization</td>\n",
       "      <td>Admission_Discharge</td>\n",
       "      <td>Past</td>\n",
       "      <td>0.9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>anemia</td>\n",
       "      <td>Disease_Syndrome_Disorder</td>\n",
       "      <td>Present</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bone marrow aspiration</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>Planned</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>biopsy</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>Planned</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>anemia</td>\n",
       "      <td>Disease_Syndrome_Disorder</td>\n",
       "      <td>Hypothetical</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>fullness of the spleen</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Possible</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>hospitalization</td>\n",
       "      <td>Admission_Discharge</td>\n",
       "      <td>Planned</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    entities_ner_chunk   entities_ner_chunk_class  \\\n",
       "0                             distress                    Symptom   \n",
       "1                        arcus senilis  Disease_Syndrome_Disorder   \n",
       "2   jugular venous pressure distention                    Symptom   \n",
       "3                           adenopathy                    Symptom   \n",
       "4                            nontender                    Symptom   \n",
       "5                             fullness                    Symptom   \n",
       "6                                edema                    Symptom   \n",
       "7                             cyanosis                 VS_Finding   \n",
       "8                             clubbing                    Symptom   \n",
       "9                               anemia  Disease_Syndrome_Disorder   \n",
       "10                          blood loss                    Symptom   \n",
       "11          esophagogastroduodenoscopy                  Procedure   \n",
       "12            myelodysplastic syndrome  Disease_Syndrome_Disorder   \n",
       "13                 bone marrow failure  Disease_Syndrome_Disorder   \n",
       "14                     hospitalization        Admission_Discharge   \n",
       "15                              anemia  Disease_Syndrome_Disorder   \n",
       "16              bone marrow aspiration                  Procedure   \n",
       "17                              biopsy                  Procedure   \n",
       "18                              anemia  Disease_Syndrome_Disorder   \n",
       "19              fullness of the spleen                    Symptom   \n",
       "20                     hospitalization        Admission_Discharge   \n",
       "\n",
       "       assertion assertion_confidence  \n",
       "0         Absent                  1.0  \n",
       "1           Past                  1.0  \n",
       "2         Absent                  1.0  \n",
       "3         Absent                  1.0  \n",
       "4         Absent                  1.0  \n",
       "5       Possible               0.9999  \n",
       "6        Present                  1.0  \n",
       "7         Absent                  1.0  \n",
       "8         Absent                  1.0  \n",
       "9   Hypothetical               0.9758  \n",
       "10        Absent                  1.0  \n",
       "11        Absent                  1.0  \n",
       "12      Possible                  1.0  \n",
       "13      Possible                  1.0  \n",
       "14          Past               0.9999  \n",
       "15       Present                  1.0  \n",
       "16       Planned                  1.0  \n",
       "17       Planned                  1.0  \n",
       "18  Hypothetical                0.999  \n",
       "19      Possible                  1.0  \n",
       "20       Planned                  1.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\n",
    "     'entities_ner_chunk',\n",
    "     'entities_ner_chunk_class', \n",
    "     'assertion',\n",
    "     'assertion_confidence']\n",
    "     \n",
    "df = nlp.nlu.to_pretty_df(model,text,output_level='chunk')[cols].reset_index(drop=True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "OP0I7ELJ0his"
   },
   "outputs": [],
   "source": [
    "# Downloading sample datasets.\n",
    "! wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Healthcare/data/mt_samples_10.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1083,
     "status": "ok",
     "timestamp": 1662533986394,
     "user": {
      "displayName": "Merve Ertas Uslu",
      "userId": "01451729557099986551"
     },
     "user_tz": -120
    },
    "id": "Z9UyX1Tx-vA0",
    "outputId": "aa341498-47d0-4503-81ca-f46dbeca231a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- index: long (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mt_samples_df = spark.createDataFrame(pd.read_csv(\"./mt_samples_10.csv\", sep=',', index_col=[\"index\"]).reset_index())\n",
    "                \n",
    "mt_samples_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tjsXUCZaNcKb",
    "outputId": "57256ad8-1f25-40b4-a31f-2ca567a83be4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|index|                text|\n",
      "+-----+--------------------+\n",
      "|    0|Sample Type / Med...|\n",
      "|    1|Sample Type / Med...|\n",
      "|    2|Sample Type / Med...|\n",
      "|    3|Sample Type / Med...|\n",
      "|    4|Sample Type / Med...|\n",
      "|    5|Sample Type / Med...|\n",
      "|    6|Sample Type / Med...|\n",
      "|    7|Sample Type / Med...|\n",
      "|    8|Sample Type / Med...|\n",
      "|    9|Sample Type / Med...|\n",
      "+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mt_samples_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.transform(mt_samples_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|index|                text|            document|            sentence|               token|          embeddings|                 ner|           ner_chunk|           assertion|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|    0|Sample Type / Med...|[{document, 0, 54...|[{document, 0, 24...|[{token, 0, 5, Sa...|[{word_embeddings...|[{named_entity, 0...|[{chunk, 68, 76, ...|[{assertion, 68, ...|\n",
      "|    1|Sample Type / Med...|[{document, 0, 32...|[{document, 0, 26...|[{token, 0, 5, Sa...|[{word_embeddings...|[{named_entity, 0...|[{chunk, 68, 92, ...|[{assertion, 68, ...|\n",
      "|    2|Sample Type / Med...|[{document, 0, 42...|[{document, 0, 14...|[{token, 0, 5, Sa...|[{word_embeddings...|[{named_entity, 0...|[{chunk, 68, 73, ...|[{assertion, 68, ...|\n",
      "|    3|Sample Type / Med...|[{document, 0, 20...|[{document, 0, 29...|[{token, 0, 5, Sa...|[{word_embeddings...|[{named_entity, 0...|                  []|                  []|\n",
      "|    4|Sample Type / Med...|[{document, 0, 34...|[{document, 0, 11...|[{token, 0, 5, Sa...|[{word_embeddings...|[{named_entity, 0...|[{chunk, 68, 82, ...|[{assertion, 68, ...|\n",
      "|    5|Sample Type / Med...|[{document, 0, 15...|[{document, 0, 28...|[{token, 0, 5, Sa...|[{word_embeddings...|[{named_entity, 0...|[{chunk, 1399, 14...|[{assertion, 1399...|\n",
      "|    6|Sample Type / Med...|[{document, 0, 25...|[{document, 0, 15...|[{token, 0, 5, Sa...|[{word_embeddings...|[{named_entity, 0...|[{chunk, 68, 73, ...|[{assertion, 68, ...|\n",
      "|    7|Sample Type / Med...|[{document, 0, 93...|[{document, 0, 19...|[{token, 0, 5, Sa...|[{word_embeddings...|[{named_entity, 0...|[{chunk, 1063, 10...|[{assertion, 1063...|\n",
      "|    8|Sample Type / Med...|[{document, 0, 20...|[{document, 0, 15...|[{token, 0, 5, Sa...|[{word_embeddings...|[{named_entity, 0...|[{chunk, 363, 372...|[{assertion, 363,...|\n",
      "|    9|Sample Type / Med...|[{document, 0, 19...|[{document, 0, 15...|[{token, 0, 5, Sa...|[{word_embeddings...|[{named_entity, 0...|[{chunk, 79, 95, ...|[{assertion, 79, ...|\n",
      "+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8OwYh1r6WU5B",
    "outputId": "65bc3404-c845-4280-cd06-b103e2f92c53"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(result=['Sample Type / Medical Specialty:\\nHematology - Oncology\\nSample Name:\\nDischarge Summary - Mesothelioma - 1\\nDescription:\\nMesothelioma, pleural effusion, atrial fibrillation, anemia, ascites, esophageal reflux, and history of deep venous thrombosis.', '(Medical Transcription Sample Report)\\nPRINCIPAL DIAGNOSIS:\\nMesothelioma.', 'SECONDARY DIAGNOSES:\\nPleural effusion, atrial fibrillation, anemia, ascites, esophageal reflux, and history of deep venous thrombosis.', 'PROCEDURES', '1. On August 24, 2007, decortication of the lung with pleural biopsy and transpleural fluoroscopy.', '2. On August 20, 2007, thoracentesis.', '3. On August 31, 2007, Port-A-Cath placement.', 'HISTORY AND PHYSICAL:\\nThe patient is a 41-year-old Vietnamese female with a nonproductive cough that started last week.', 'She has had right-sided chest pain radiating to her back with fever starting yesterday.', 'She has a history of pericarditis and pericardectomy in May 2006 and developed cough with right-sided chest pain, and went to an urgent care center.', 'Chest x-ray revealed right-sided pleural effusion.', 'PAST MEDICAL HISTORY', '1. Pericardectomy.', '2. Pericarditis.', '2. Atrial fibrillation.', '4. RNCA with intracranial thrombolytic treatment.', '5 PTA of MCA.', '6. Mesenteric venous thrombosis.', '7. Pericardial window.', '8. Cholecystectomy.', '9. Left thoracentesis.', 'FAMILY HISTORY:\\nNo family history of coronary artery disease, CVA, diabetes, CHF or MI.', 'The patient has one family member, a sister, with history of cancer.', 'SOCIAL HISTORY:\\nShe is married.', 'Employed with the US Post Office.', 'She is a mother of three.', 'Denies tobacco, alcohol or illicit drug use.', 'MEDICATIONS', '1. Coumadin 1 mg daily.', 'Last INR was on Tuesday, August 14, 2007, and her INR was 2.3.', '2. Amiodarone 100 mg p.o. daily.', 'REVIEW OF SYSTEMS:\\nComplete review of systems negative except as in pulmonary as noted above.', 'The patient also reports occasional numbness and tingling of her left arm.', 'PHYSICAL EXAMINATION\\nVITAL SIGNS: Blood pressure 123/95, heart rate 83, respirations 20, temperature 97, and oxygen saturation 97%.', 'GENERAL: Positive nonproductive cough and pain with coughing.', 'HEENT: Pupils are equal and reactive to light and accommodation.', 'Tympanic membranes are clear.', 'NECK: Supple.', 'No lymphadenopathy.', 'No masses.', 'RESPIRATORY: Pleural friction rub is noted.', 'GI: Soft, nondistended, and nontender.', 'Positive bowel sounds.', 'No organomegaly.', 'EXTREMITIES: No edema, no clubbing, no cyanosis, no tenderness.', 'Full range of motion.', 'Normal pulses in all extremities.', 'SKIN: No breakdown or lesions.', 'No ulcers.', 'NEUROLOGIC: Grossly intact.', 'No focal deficits.', 'Awake, alert, and oriented to person, place, and time.', 'LABORATORY DATA:\\nLabs are pending.', 'HOSPITAL COURSE:\\nThe patient was admitted for a right-sided pleural effusion for thoracentesis on Monday by Dr. X. Her Coumadin was placed on hold.', 'A repeat echocardiogram was checked.', 'She was started on prophylaxis for DVT with Lovenox 40 mg subcutaneously.', 'Her history dated back to March 2005 when she first sought medical attention for evidence of pericarditis, which was treated with pericardial window in an outside hospital, at that time she was also found to have mesenteric pain and thrombosis, is now anticoagulated.', 'Her pericardial fluid was accumulated and she was seen by Dr. Y. At that time, she was recommended for pericardectomy, which was performed by Dr. Z. Review of her CT scan from March 2006 prior to her pericardectomy, already shows bilateral plural effusions.', 'The patient improved clinically after the pericardectomy with resolution of her symptoms.', 'Recently, she was readmitted to the hospital with chest pain and found to have bilateral pleural effusion, the right greater than the left.', 'CT of the chest also revealed a large mediastinal lymph node.', 'We reviewed the pathology obtained from the pericardectomy in March 2006, which was diagnostic of mesothelioma.', 'At this time, chest tube placement for drainage of the fluid occurred and thoracoscopy with fluid biopsies, which were performed, which revealed epithelioid malignant mesothelioma.', 'The patient was then stained with a PET CT, which showed extensive uptake in the chest, bilateral pleural pericardial effusions, and lymphadenopathy.', 'She also had acidic fluid, pectoral and intramammary lymph nodes and uptake in L4 with SUV of', '4. This was consistent with stage III disease.', 'Her repeat echocardiogram showed an ejection fraction of 45% to 49%.', 'She was transferred to Oncology service and started on chemotherapy on September 1, 2007 with cisplatin 75 mg/centimeter squared equaling 109 mg IV piggyback over 2 hours on September 1, 2007, Alimta 500 mg/ centimeter squared equaling 730 mg IV piggyback over 10 minutes.', 'This was all initiated after a Port-A-Cath was placed.', 'The chemotherapy was well tolerated and the patient was discharged the following day after discontinuing IV fluid and IV.', 'Her Port-A-Cath was packed with heparin according to protocol.', 'DISCHARGE MEDICATIONS:\\nZofran, Phenergan, Coumadin, and Lovenox, and Vicodin\\nDISCHARGE INSTRUCTIONS:\\nShe was instructed to followup with Dr. XYZ in the office to check her INR on Tuesday.', 'She was instructed to call if she had any other questions or concerns in the interim.', 'Keywords:\\nhematology - oncology, mesothelioma, pleural effusion, atrial fibrillation, anemia, ascites, esophageal reflux, deep venous thrombosis, port-a-cath placement, port a cath, iv piggyback, venous thrombosis, atrial, thrombosis, pericardial, lymphadenopathy, fluid, pericardectomy, chest, pleural,'])]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.select('sentence.result').take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5uBnSe0--_Tn",
    "outputId": "8028bf3d-b3fa-4be1-8ea1-99230ce9b14a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+-----+---+-------------------------+-------+---------+----------+\n",
      "|chunk                    |begin|end|ner_label                |sent_id|assertion|confidence|\n",
      "+-------------------------+-----+---+-------------------------+-------+---------+----------+\n",
      "|Discharge                |68   |76 |Admission_Discharge      |0      |Past     |1.0       |\n",
      "|pleural effusion         |132  |147|Disease_Syndrome_Disorder|0      |Present  |0.9904    |\n",
      "|anemia                   |171  |176|Disease_Syndrome_Disorder|0      |Present  |0.8993    |\n",
      "|ascites                  |179  |185|Disease_Syndrome_Disorder|0      |Present  |0.9992    |\n",
      "|esophageal reflux        |188  |204|Disease_Syndrome_Disorder|0      |Present  |1.0       |\n",
      "|deep venous thrombosis   |222  |243|Disease_Syndrome_Disorder|0      |Past     |1.0       |\n",
      "|Pleural effusion         |340  |355|Disease_Syndrome_Disorder|2      |Present  |1.0       |\n",
      "|anemia                   |379  |384|Disease_Syndrome_Disorder|2      |Present  |1.0       |\n",
      "|ascites                  |387  |393|Disease_Syndrome_Disorder|2      |Present  |1.0       |\n",
      "|esophageal reflux        |396  |412|Disease_Syndrome_Disorder|2      |Present  |1.0       |\n",
      "|deep venous thrombosis   |430  |451|Disease_Syndrome_Disorder|2      |Past     |1.0       |\n",
      "|decortication of the lung|488  |512|Procedure                |4      |Past     |1.0       |\n",
      "|pleural biopsy           |519  |532|Procedure                |4      |Past     |1.0       |\n",
      "|thoracentesis            |587  |599|Procedure                |5      |Past     |1.0       |\n",
      "|Port-A-Cath placement    |625  |645|Procedure                |6      |Past     |1.0       |\n",
      "|cough                    |738  |742|Symptom                  |7      |Past     |1.0       |\n",
      "|chest pain               |792  |801|Symptom                  |8      |Past     |1.0       |\n",
      "|fever                    |830  |834|VS_Finding               |8      |Present  |1.0       |\n",
      "|pericarditis             |877  |888|Disease_Syndrome_Disorder|9      |Present  |0.9999    |\n",
      "|pericardectomy           |894  |907|Procedure                |9      |Past     |1.0       |\n",
      "+-------------------------+-----+---+-------------------------+-------+---------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "result.select(F.explode(F.arrays_zip(result.ner_chunk.result,  \n",
    "                                     result.ner_chunk.begin, \n",
    "                                     result.ner_chunk.end, \n",
    "                                     result.ner_chunk.metadata, \n",
    "                                     result.assertion.result,\n",
    "                                     result.assertion.metadata)).alias(\"cols\")) \\\n",
    "      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
    "              F.expr(\"cols['1']\").alias(\"begin\"),\n",
    "              F.expr(\"cols['2']\").alias(\"end\"),\n",
    "              F.expr(\"cols['3']['entity']\").alias(\"ner_label\"),\n",
    "              F.expr(\"cols['3']['sentence']\").alias(\"sent_id\"),\n",
    "              F.expr(\"cols['4']\").alias(\"assertion\"),\n",
    "              F.expr(\"cols['5']['confidence']\").alias(\"confidence\") ).show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dYN97Es2be4p"
   },
   "source": [
    "### Pretrained `assertion_dl_radiology` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YMl2QAeNbe4p",
    "outputId": "cdcf11f8-4561-4873-8128-63c16b4527cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence_detector_dl_healthcare download started this may take some time.\n",
      "Approximate size to download 367.3 KB\n",
      "[ | ]sentence_detector_dl_healthcare download started this may take some time.\n",
      "Approximate size to download 367.3 KB\n",
      "Download done! Loading the resource.\n",
      "[OK!]\n",
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[OK!]\n",
      "ner_radiology download started this may take some time.\n",
      "[ | ]ner_radiology download started this may take some time.\n",
      "Approximate size to download 13.9 MB\n",
      "Download done! Loading the resource.\n",
      "[OK!]\n",
      "assertion_dl_radiology download started this may take some time.\n",
      "[ | ]assertion_dl_radiology download started this may take some time.\n",
      "Approximate size to download 1.3 MB\n",
      "Download done! Loading the resource.\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "documentAssembler = nlp.DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "# Sentence Detector annotator, processes various sentences per line\n",
    "sentenceDetector = nlp.SentenceDetectorDLModel\\\n",
    "    .pretrained(\"sentence_detector_dl_healthcare\",\"en\",\"clinical/models\") \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "# Tokenizer splits words in a relevant format for NLP\n",
    "tokenizer = nlp.Tokenizer()\\\n",
    "    .setInputCols([\"sentence\"])\\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "# Clinical word embeddings trained on PubMED dataset\n",
    "word_embeddings = nlp.WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n",
    "    .setInputCols([\"sentence\", \"token\"])\\\n",
    "    .setOutputCol(\"embeddings\")\n",
    "\n",
    "# NER model for radiology\n",
    "radiology_ner = medical.NerModel.pretrained(\"ner_radiology\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"ner\")\\\n",
    "    #.setIncludeAllConfidenceScores(False)\n",
    "\n",
    "ner_converter = medical.NerConverterInternal() \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"ner\"]) \\\n",
    "    .setOutputCol(\"ner_chunk\")\\\n",
    "    .setWhiteList([\"ImagingFindings\"])\n",
    "\n",
    "# Assertion model trained on radiology dataset\n",
    "radiology_assertion = medical.AssertionDLModel.pretrained(\"assertion_dl_radiology\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\", \"ner_chunk\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"assertion\")\n",
    "\n",
    "nlpPipeline = nlp.Pipeline(stages=[\n",
    "    documentAssembler, \n",
    "    sentenceDetector,\n",
    "    tokenizer,\n",
    "    word_embeddings,\n",
    "    radiology_ner,\n",
    "    ner_converter,\n",
    "    radiology_assertion\n",
    "    ])\n",
    "\n",
    "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "radiologyAssertion_model = nlpPipeline.fit(empty_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Ehm7WwJrbe4r"
   },
   "outputs": [],
   "source": [
    "# A sample text from a radiology report\n",
    "\n",
    "text = \"\"\"No right-sided pleural effusion or pneumothorax is definitively seen and there are mildly displaced fractures of the left lateral 8th and likely 9th ribs.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "_1iCxtKjbe4s"
   },
   "outputs": [],
   "source": [
    "data = spark.createDataFrame([[text]]).toDF(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "lSpEvzDObe4s"
   },
   "outputs": [],
   "source": [
    "result = radiologyAssertion_model.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fGxRCsusbe4s",
    "outputId": "f7d576c2-24e5-4db6-9d74-1b1bb9b5f145"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 30:======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------------+-------+---------+\n",
      "|chunk              |ner_label      |sent_id|assertion|\n",
      "+-------------------+---------------+-------+---------+\n",
      "|effusion           |ImagingFindings|0      |Negative |\n",
      "|pneumothorax       |ImagingFindings|0      |Negative |\n",
      "|displaced fractures|ImagingFindings|0      |Confirmed|\n",
      "+-------------------+---------------+-------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "result.select(F.explode(F.arrays_zip(result.ner_chunk.result, \n",
    "                                     result.ner_chunk.metadata, \n",
    "                                     result.assertion.result)).alias(\"cols\")) \\\n",
    "      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
    "              F.expr(\"cols['1']['entity']\").alias(\"ner_label\"),\n",
    "              F.expr(\"cols['1']['sentence']\").alias(\"sent_id\"),\n",
    "              F.expr(\"cols['2']\").alias(\"assertion\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0vWIDpk50QfG"
   },
   "source": [
    "# **Writing a generic Assertion + NER function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "ltGPQYr60F6G"
   },
   "outputs": [],
   "source": [
    "def get_base_pipeline (embeddings = 'embeddings_clinical'):\n",
    "\n",
    "    documentAssembler = nlp.DocumentAssembler()\\\n",
    "        .setInputCol(\"text\")\\\n",
    "        .setOutputCol(\"document\")\n",
    "\n",
    "  # Sentence Detector annotator, processes various sentences per line\n",
    "    sentenceDetector = nlp.SentenceDetector()\\\n",
    "        .setInputCols([\"document\"])\\\n",
    "        .setOutputCol(\"sentence\")\n",
    "\n",
    "  # Tokenizer splits words in a relevant format for NLP\n",
    "    tokenizer = nlp.Tokenizer()\\\n",
    "        .setInputCols([\"sentence\"])\\\n",
    "        .setOutputCol(\"token\")\n",
    "\n",
    "  # Clinical word embeddings trained on PubMED dataset\n",
    "    word_embeddings = nlp.WordEmbeddingsModel.pretrained(embeddings, \"en\", \"clinical/models\")\\\n",
    "        .setInputCols([\"sentence\", \"token\"])\\\n",
    "        .setOutputCol(\"embeddings\")\n",
    "\n",
    "    base_pipeline = nlp.Pipeline(stages=[\n",
    "                        documentAssembler,\n",
    "                        sentenceDetector,\n",
    "                        tokenizer,\n",
    "                        word_embeddings])\n",
    "\n",
    "    return base_pipeline\n",
    "\n",
    "\n",
    "\n",
    "def get_clinical_assertion (embeddings, spark_df, nrows = 100, ner_model_name = 'ner_clinical', assertion_model_name=\"assertion_dl\"):\n",
    "\n",
    "  # NER model trained on i2b2 (sampled from MIMIC) dataset\n",
    "    loaded_ner_model = medical.NerModel.pretrained(ner_model_name, \"en\", \"clinical/models\") \\\n",
    "        .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "        .setOutputCol(\"ner\")\n",
    "\n",
    "    ner_converter = medical.NerConverterInternal() \\\n",
    "        .setInputCols([\"sentence\", \"token\", \"ner\"]) \\\n",
    "        .setOutputCol(\"ner_chunk\")\n",
    "\n",
    "  # Assertion model trained on i2b2 (sampled from MIMIC) dataset\n",
    "  # coming from sparknlp_jsl.annotator !!\n",
    "    clinical_assertion = medical.AssertionDLModel.pretrained(assertion_model_name, \"en\", \"clinical/models\") \\\n",
    "        .setInputCols([\"sentence\", \"ner_chunk\", \"embeddings\"]) \\\n",
    "        .setOutputCol(\"assertion\")\n",
    "      \n",
    "\n",
    "    base_model = get_base_pipeline (embeddings)\n",
    "\n",
    "    nlpPipeline = nlp.Pipeline(stages=[\n",
    "        base_model,\n",
    "        loaded_ner_model,\n",
    "        ner_converter,\n",
    "        clinical_assertion])\n",
    "\n",
    "    empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "    model = nlpPipeline.fit(empty_data)\n",
    "\n",
    "    result = model.transform(spark_df.limit(nrows))\n",
    "\n",
    "    result = result.withColumn(\"id\", F.monotonically_increasing_id())\n",
    "\n",
    "    result_df = result.select(F.explode(F.arrays_zip(result.ner_chunk.result, \n",
    "                                                     result.ner_chunk.metadata, \n",
    "                                                     result.assertion.result,\n",
    "                                                     result.assertion.metadata)).alias(\"cols\")) \\\n",
    "                      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
    "                              F.expr(\"cols['1']['entity']\").alias(\"ner_label\"),\n",
    "                              F.expr(\"cols['2']\").alias(\"assertion\"),\n",
    "                              F.expr(\"cols['3']['confidence']\").alias(\"confidence\"))\\\n",
    "                      .filter(\"ner_label!='O'\")\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V81zaAe13qLU",
    "outputId": "5f22e5f9-6ad0-4274-d82c-e927d5593c0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_clinical_large download started this may take some time.\n",
      "[ | ]ner_clinical_large download started this may take some time.\n",
      "Approximate size to download 13.9 MB\n",
      "Download done! Loading the resource.\n",
      "[OK!]\n",
      "assertion_dl download started this may take some time.\n",
      "[ | ]assertion_dl download started this may take some time.\n",
      "Approximate size to download 1.3 MB\n",
      "Download done! Loading the resource.\n",
      "[OK!]\n",
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[OK!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 40:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+---------+---------+----------+\n",
      "|                       chunk|ner_label|assertion|confidence|\n",
      "+----------------------------+---------+---------+----------+\n",
      "|                Mesothelioma|  PROBLEM|  present|    0.9996|\n",
      "|                Mesothelioma|  PROBLEM|  present|    0.9996|\n",
      "|            pleural effusion|  PROBLEM|  present|    0.9997|\n",
      "|         atrial fibrillation|  PROBLEM|  present|    0.9998|\n",
      "|                      anemia|  PROBLEM|  present|    0.9997|\n",
      "|                     ascites|  PROBLEM|  present|    0.9997|\n",
      "|           esophageal reflux|  PROBLEM|  present|    0.9998|\n",
      "|      deep venous thrombosis|  PROBLEM|  present|    0.9998|\n",
      "|                Mesothelioma|  PROBLEM|  present|    0.9992|\n",
      "|            Pleural effusion|  PROBLEM|  present|    0.9999|\n",
      "|         atrial fibrillation|  PROBLEM|  present|       1.0|\n",
      "|                      anemia|  PROBLEM|  present|    0.9999|\n",
      "|                     ascites|  PROBLEM|  present|    0.9999|\n",
      "|           esophageal reflux|  PROBLEM|  present|    0.9999|\n",
      "|      deep venous thrombosis|  PROBLEM|  present|    0.9993|\n",
      "|   decortication of the lung|TREATMENT|  present|       1.0|\n",
      "|              pleural biopsy|     TEST|  present|    0.9999|\n",
      "|    transpleural fluoroscopy|     TEST|  present|    0.9997|\n",
      "|               thoracentesis|TREATMENT|  present|    0.9998|\n",
      "|       Port-A-Cath placement|TREATMENT|  present|       1.0|\n",
      "|       a nonproductive cough|  PROBLEM|  present|    0.9972|\n",
      "|      right-sided chest pain|  PROBLEM|  present|    0.9998|\n",
      "|                       fever|  PROBLEM|  present|    0.9998|\n",
      "|                pericarditis|  PROBLEM|  present|    0.9998|\n",
      "|              pericardectomy|TREATMENT|  present|    0.9999|\n",
      "|                       cough|  PROBLEM|  present|    0.9996|\n",
      "|      right-sided chest pain|  PROBLEM|  present|    0.9998|\n",
      "|                 Chest x-ray|     TEST|  present|    0.9999|\n",
      "|right-sided pleural effusion|  PROBLEM|  present|    0.9999|\n",
      "|              Pericardectomy|TREATMENT|  present|    0.9985|\n",
      "+----------------------------+---------+---------+----------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "embeddings = 'embeddings_clinical'\n",
    "\n",
    "ner_model_name = 'ner_clinical_large'\n",
    "\n",
    "nrows = 100\n",
    "\n",
    "ner_df = get_clinical_assertion (embeddings, mt_samples_df, nrows, ner_model_name)\n",
    "\n",
    "ner_df.show(30,truncate=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LmLPlfCw5hh-",
    "outputId": "87c83656-5714-440f-d4ff-f73f6ed73907"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_posology download started this may take some time.\n",
      "[ | ]ner_posology download started this may take some time.\n",
      "Approximate size to download 13.8 MB\n",
      "Download done! Loading the resource.\n",
      "[OK!]\n",
      "assertion_dl download started this may take some time.\n",
      "[OK!]\n",
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[OK!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 46:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+------------+----------+\n",
      "|           chunk|ner_label|   assertion|confidence|\n",
      "+----------------+---------+------------+----------+\n",
      "|        Coumadin|     DRUG|hypothetical|    0.8709|\n",
      "|            1 mg| STRENGTH| conditional|    0.7772|\n",
      "|           daily|FREQUENCY| conditional|    0.5086|\n",
      "|      Amiodarone|     DRUG|hypothetical|    0.8589|\n",
      "|          100 mg| STRENGTH|hypothetical|    0.6143|\n",
      "|             p.o|    ROUTE|hypothetical|    0.7991|\n",
      "|           daily|FREQUENCY|     present|    0.9074|\n",
      "|        Coumadin|     DRUG|     present|    0.9997|\n",
      "|         Lovenox|     DRUG|     present|    0.9994|\n",
      "|           40 mg| STRENGTH|     present|    0.9982|\n",
      "|  subcutaneously|    ROUTE|     present|    0.9871|\n",
      "|    chemotherapy|     DRUG|     present|    0.9999|\n",
      "|       cisplatin|     DRUG|     present|    0.9999|\n",
      "|75 mg/centimeter| STRENGTH|     present|    0.9998|\n",
      "|          109 mg| STRENGTH|     present|    0.9999|\n",
      "|              IV|    ROUTE|     present|    0.9999|\n",
      "|       piggyback|     DRUG|     present|    0.9999|\n",
      "|    over 2 hours| DURATION|     present|    0.9999|\n",
      "|       September|     DRUG|     present|       1.0|\n",
      "|          Alimta|     DRUG|     present|       1.0|\n",
      "+----------------+---------+------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "embeddings = 'embeddings_clinical'\n",
    "\n",
    "ner_model_name = 'ner_posology'\n",
    "\n",
    "nrows = 100\n",
    "\n",
    "ner_df = get_clinical_assertion (embeddings, mt_samples_df, nrows, ner_model_name)\n",
    "\n",
    "ner_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cQ9xeS3kwClE",
    "outputId": "b050b44f-fbd1-48ee-d013-b903b64d70e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_posology_greedy download started this may take some time.\n",
      "[ | ]ner_posology_greedy download started this may take some time.\n",
      "Approximate size to download 13.9 MB\n",
      "Download done! Loading the resource.\n",
      "[OK!]\n",
      "assertion_dl download started this may take some time.\n",
      "[OK!]\n",
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[OK!]\n",
      "+----------------+---------+---------+----------+\n",
      "|           chunk|ner_label|assertion|confidence|\n",
      "+----------------+---------+---------+----------+\n",
      "|capsule of Advil|     DRUG|   absent|    0.9855|\n",
      "+----------------+---------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embeddings = 'embeddings_clinical'\n",
    "\n",
    "ner_model_name = 'ner_posology_greedy'\n",
    "\n",
    "entry_data = spark.createDataFrame([[\"The patient did not take a capsule of Advil.\"]]).toDF(\"text\")\n",
    "\n",
    "ner_df = get_clinical_assertion (embeddings, entry_data, nrows, ner_model_name)\n",
    "\n",
    "ner_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "djV_FKNtYcoP",
    "outputId": "71ee07b2-e8a2-419c-fce2-8e44a01295e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_clinical download started this may take some time.\n",
      "[ | ]ner_clinical download started this may take some time.\n",
      "Approximate size to download 13.9 MB\n",
      "[ / ]Download done! Loading the resource.\n",
      "[OK!]\n",
      "assertion_dl download started this may take some time.\n",
      "[OK!]\n",
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[OK!]\n",
      "+-----+---------+---------+----------+\n",
      "|chunk|ner_label|assertion|confidence|\n",
      "+-----+---------+---------+----------+\n",
      "|fever|  PROBLEM|   absent|     0.998|\n",
      "+-----+---------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embeddings = 'embeddings_clinical'\n",
    "\n",
    "ner_model_name = 'ner_clinical'\n",
    "\n",
    "entry_data = spark.createDataFrame([[\"The patient has no fever\"]]).toDF(\"text\")\n",
    "\n",
    "ner_df = get_clinical_assertion (embeddings, entry_data, nrows, ner_model_name)\n",
    "\n",
    "ner_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "sbllagh66Q8X"
   },
   "outputs": [],
   "source": [
    "def get_clinical_assertion_light (light_model, text):\n",
    "\n",
    "  light_result = light_model.fullAnnotate(text)[0]\n",
    "\n",
    "  chunks=[]\n",
    "  entities=[]\n",
    "  status=[]\n",
    "  confidence=[]\n",
    "\n",
    "  for n,m in zip(light_result['ner_chunk'],light_result['assertion']):\n",
    "      \n",
    "      chunks.append(n.result)\n",
    "      entities.append(n.metadata['entity']) \n",
    "      status.append(m.result)\n",
    "      confidence.append(m.metadata['confidence'])\n",
    "          \n",
    "  df = pd.DataFrame({'chunks':chunks, 'entities':entities, 'assertion':status,'confidence':confidence})\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "GqKH9Mw98z4x",
    "outputId": "6bcf9f5b-acf4-413b-8749-5fab02fe43b6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entities_ner_chunk</th>\n",
       "      <th>entities_ner_chunk_class</th>\n",
       "      <th>assertion</th>\n",
       "      <th>assertion_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fever</td>\n",
       "      <td>VS_Finding</td>\n",
       "      <td>Present</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sore throat</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Present</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stomach pain</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pain</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Hypothetical</td>\n",
       "      <td>0.9973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>short of breath</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Present</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>climbing a flight of stairs</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Present</td>\n",
       "      <td>0.9434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alzheimer</td>\n",
       "      <td>Disease_Syndrome_Disorder</td>\n",
       "      <td>Family</td>\n",
       "      <td>0.8136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            entities_ner_chunk   entities_ner_chunk_class     assertion  \\\n",
       "0                        fever                 VS_Finding       Present   \n",
       "0                  sore throat                    Symptom       Present   \n",
       "0                 stomach pain                    Symptom        Absent   \n",
       "0                         pain                    Symptom  Hypothetical   \n",
       "0              short of breath                    Symptom       Present   \n",
       "0  climbing a flight of stairs                    Symptom       Present   \n",
       "0                    Alzheimer  Disease_Syndrome_Disorder        Family   \n",
       "\n",
       "  assertion_confidence  \n",
       "0                  1.0  \n",
       "0                  1.0  \n",
       "0                  1.0  \n",
       "0               0.9973  \n",
       "0                  1.0  \n",
       "0               0.9434  \n",
       "0               0.8136  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinical_text = \"\"\"\n",
    "Patient with severe fever and sore throat. \n",
    "He shows no stomach pain and he maintained on an epidural and PCA for pain control.\n",
    "He also became short of breath with climbing a flight of stairs.\n",
    "After CT, lung tumor located at the right lower lobe. Father with Alzheimer.\n",
    "\"\"\"\n",
    "\n",
    "light_model = nlp.LightPipeline(model)\n",
    "\n",
    "# get_clinical_assertion_light (light_model, clinical_text)\n",
    "\n",
    "cols = [\n",
    "     'entities_ner_chunk',\n",
    "     'entities_ner_chunk_class', \n",
    "     'assertion',\n",
    "     'assertion_confidence']\n",
    "     \n",
    "df = nlp.nlu.to_pretty_df(light_model,clinical_text, output_level='chunk')[cols]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oncological Assertion Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oncology Assertion Models\n",
    "\n",
    "|    | model_name              |Predicted Entities|\n",
    "|---:|:------------------------|-|\n",
    "| 1 | [assertion_oncology_wip](https://nlp.johnsnowlabs.com/2022/10/11/assertion_oncology_wip_en.html) | Medical_History, Family_History, Possible, Hypothetical_Or_Absent|\n",
    "| 2 | [assertion_oncology_problem_wip](https://nlp.johnsnowlabs.com/2022/10/11/assertion_oncology_problem_wip_en.html) |Present, Possible, Hypothetical, Absent, Family|\n",
    "| 3 | [assertion_oncology_treatment_wip](https://nlp.johnsnowlabs.com/2022/10/11/assertion_oncology_treatment_binary_wip_en.html) |Present, Planned, Past, Hypothetical, Absent|\n",
    "| 3 | [assertion_oncology_treatment_wip]() |Present, Planned, Past, Hypothetical, Absent|\n",
    "| 4 | [assertion_oncology_response_to_treatment_wip](https://nlp.johnsnowlabs.com/2022/10/11/assertion_oncology_response_to_treatment_wip_en.html) |Present_Or_Past, Hypothetical_Or_Absent|\n",
    "| 5 | [assertion_oncology_test_binary_wip](https://nlp.johnsnowlabs.com/2022/10/01/assertion_oncology_test_binary_wip_en.html) |Present_Or_Past, Hypothetical_Or_Absent|\n",
    "| 6 | [assertion_oncology_smoking_status_wip](https://nlp.johnsnowlabs.com/2022/10/11/assertion_oncology_smoking_status_wip_en.html) |Absent, Past, Present|\n",
    "| 7 | [assertion_oncology_family_history_wip](https://nlp.johnsnowlabs.com/2022/10/11/assertion_oncology_family_history_wip_en.html) |Family_History, Other|\n",
    "| 8 | [assertion_oncology_demographic_binary_wip](https://nlp.johnsnowlabs.com/2022/10/11/assertion_oncology_demographic_binary_wip_en.html) |Patient, Someone_Else|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_oncology_wip download started this may take some time.\n",
      "[ | ]ner_oncology_wip download started this may take some time.\n",
      "Approximate size to download 969.3 KB\n",
      "Download done! Loading the resource.\n",
      "[OK!]\n",
      "assertion_oncology_wip download started this may take some time.\n",
      "[ | ]assertion_oncology_wip download started this may take some time.\n",
      "Approximate size to download 1.4 MB\n",
      "Download done! Loading the resource.\n",
      "[OK!]\n",
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[OK!]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 70:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+--------------------+------------+----------+\n",
      "|chunk                   |ner_label           |assertion   |confidence|\n",
      "+------------------------+--------------------+------------+----------+\n",
      "|Mesothelioma            |Cancer_Dx           |Present     |0.9885    |\n",
      "|Mesothelioma            |Cancer_Dx           |Hypothetical|0.981     |\n",
      "|August 24, 2007         |Date                |Past        |0.9726    |\n",
      "|decortication           |Cancer_Surgery      |Past        |0.994     |\n",
      "|lung                    |Site_Lung           |Past        |0.9453    |\n",
      "|pleural                 |Site_Other_Body_Part|Past        |0.9624    |\n",
      "|biopsy                  |Pathology_Test      |Past        |0.9979    |\n",
      "|transpleural fluoroscopy|Imaging_Test        |Past        |0.9979    |\n",
      "|August 20, 2007         |Date                |Past        |0.956     |\n",
      "|August 31, 2007         |Date                |Past        |0.9925    |\n",
      "|41-year-old             |Gender              |Present     |0.9986    |\n",
      "|Vietnamese              |Race_Ethnicity      |Present     |0.8024    |\n",
      "|female                  |Gender              |Present     |0.9772    |\n",
      "|started last week       |Relative_Date       |Present     |0.9831    |\n",
      "|She                     |Gender              |Present     |0.9992    |\n",
      "|her                     |Gender              |Present     |0.9944    |\n",
      "|She                     |Gender              |Present     |0.9993    |\n",
      "|pericardectomy          |Cancer_Surgery      |Past        |0.997     |\n",
      "|May 2006                |Date                |Past        |0.9971    |\n",
      "|Chest x-ray             |Imaging_Test        |Past        |0.9984    |\n",
      "+------------------------+--------------------+------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "embeddings = 'embeddings_clinical'\n",
    "\n",
    "ner_model_name = 'ner_oncology_wip'\n",
    "\n",
    "assertion_model_name='assertion_oncology_wip'\n",
    "\n",
    "nrows = 100\n",
    "\n",
    "ner_df = get_clinical_assertion (embeddings, mt_samples_df, nrows, ner_model_name,assertion_model_name )\n",
    "\n",
    "ner_df.show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jECAdcYGcJJT"
   },
   "source": [
    "# **Assertion Filterer**\n",
    "AssertionFilterer will allow you to filter out the named entities by the list of acceptable assertion statuses. This annotator would be quite handy if you want to set a white list for the acceptable assertion statuses like present or conditional; and do not want absent conditions get out of your pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c8xRF4yScwP3",
    "outputId": "1c315e15-a09f-493e-f276-869ceb91ad1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[OK!]\n",
      "ner_clinical download started this may take some time.\n",
      "[OK!]\n",
      "assertion_jsl_augmented download started this may take some time.\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "# Annotator that transforms a text column from dataframe into an Annotation ready for NLP\n",
    "\n",
    "documentAssembler = nlp.DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "# Sentence Detector annotator, processes various sentences per line\n",
    "sentenceDetector = nlp.SentenceDetector()\\\n",
    "    .setInputCols([\"document\"])\\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "# Tokenizer splits words in a relevant format for NLP\n",
    "tokenizer = nlp.Tokenizer()\\\n",
    "    .setInputCols([\"sentence\"])\\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "# Clinical word embeddings trained on PubMED dataset\n",
    "word_embeddings = nlp.WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n",
    "    .setInputCols([\"sentence\", \"token\"])\\\n",
    "    .setOutputCol(\"embeddings\")\n",
    "\n",
    "clinical_ner = medical.NerModel.pretrained(\"ner_clinical\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"ner\")\\\n",
    "    #.setIncludeAllConfidenceScores(False)\n",
    "\n",
    "ner_converter = medical.NerConverterInternal() \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"ner\"]) \\\n",
    "    .setOutputCol(\"ner_chunk\")\n",
    "\n",
    "clinical_assertion = medical.AssertionDLModel.pretrained(\"assertion_jsl_augmented\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\", \"ner_chunk\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"assertion\")\n",
    "\n",
    "assertion_filterer = medical.AssertionFilterer()\\\n",
    "    .setInputCols(\"sentence\",\"ner_chunk\",\"assertion\")\\\n",
    "    .setOutputCol(\"assertion_filtered\")\\\n",
    "    .setCaseSensitive(False)\\\n",
    "    .setWhiteList([\"PREsent\"])\n",
    "\n",
    "nlpPipeline = nlp.Pipeline(stages=[\n",
    "      documentAssembler, \n",
    "      sentenceDetector,\n",
    "      tokenizer,\n",
    "      word_embeddings,\n",
    "      clinical_ner,\n",
    "      ner_converter,\n",
    "      clinical_assertion,\n",
    "      assertion_filterer\n",
    "    ])\n",
    "\n",
    "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "assertionFilter_model = nlpPipeline.fit(empty_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KE6Qt20Sfqc-",
    "outputId": "285eef8a-f8ea-4061-80fd-ec6782068a1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['assertion_filtered', 'document', 'ner_chunk', 'assertion', 'token', 'ner', 'embeddings', 'sentence'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Patient has a headache for the last 2 weeks, needs to get a head CT, and appears anxious when she walks fast. Alopecia noted. She denies pain.'\n",
    "\n",
    "light_model = nlp.LightPipeline(assertionFilter_model)\n",
    "light_result = light_model.annotate(text)\n",
    "\n",
    "light_result.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3gJfCLMHk0MV",
    "outputId": "a177afed-b272-474e-bacb-34f5da00d311"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a headache', 'Present'),\n",
       " ('a head CT', 'Planned'),\n",
       " ('anxious', 'Possible'),\n",
       " ('Alopecia', 'Present'),\n",
       " ('pain', 'Absent')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(light_result['ner_chunk'], light_result['assertion']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XjuVg_4N15y2",
    "outputId": "4db6a3d6-4d46-4438-e749-61fb7b31522b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PREsent']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assertion_filterer.getWhiteList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunks</th>\n",
       "      <th>entities</th>\n",
       "      <th>assertion</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a headache</td>\n",
       "      <td>PROBLEM</td>\n",
       "      <td>Present</td>\n",
       "      <td>0.97150004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alopecia</td>\n",
       "      <td>PROBLEM</td>\n",
       "      <td>Present</td>\n",
       "      <td>0.9949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       chunks entities assertion  confidence\n",
       "0  a headache  PROBLEM   Present  0.97150004\n",
       "1    Alopecia  PROBLEM   Present      0.9949"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks=[]\n",
    "entities=[]\n",
    "status=[]\n",
    "confidence=[]\n",
    "\n",
    "light_result = light_model.fullAnnotate(text)[0]\n",
    "\n",
    "for m in light_result['assertion_filtered']:\n",
    "    \n",
    "    chunks.append(m.result)\n",
    "    entities.append(m.metadata['entity']) \n",
    "    status.append(m.metadata['assertion'])\n",
    "    confidence.append(m.metadata['confidence'])\n",
    "        \n",
    "df = pd.DataFrame({'chunks':chunks, 'entities':entities, 'assertion':status, 'confidence':confidence})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rpWfTJbsk7tp",
    "outputId": "d43b5263-bc83-48c4-b80f-0a58da4b9f14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Annotation(chunk, 12, 21, a headache, {'chunk': '0', 'confidence': '0.97150004', 'ner_source': 'ner_chunk', 'assertion': 'Present', 'entity': 'PROBLEM', 'sentence': '0'}),\n",
       " Annotation(chunk, 110, 117, Alopecia, {'chunk': '3', 'confidence': '0.9949', 'ner_source': 'ner_chunk', 'assertion': 'Present', 'entity': 'PROBLEM', 'sentence': '1'})]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "light_result['assertion_filtered']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see, there is no \"pain\" chunk since it has \"absent\" assertion label. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AssertionChunkConverter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases, there may be issues while creating the chunk column by using token indices and losing some data while training and testing the assertion status model if there are issues in these token indices. So we developed a new `AssertionChunkConverter` annotator that takes **begin and end indices of the chunks** as input and creates an extended chunk column with metadata that can be used for assertion status detection model training.\n",
    "\n",
    "*NOTE*: Chunk begin and end indices in the assertion status model training dataframe can be populated using the new version of ALAB module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+----------+--------+\n",
      "|                text|target|char_begin|char_end|\n",
      "+--------------------+------+----------+--------+\n",
      "|An angiography sh...|Minnie|        57|      63|\n",
      "|After discussing ...|   PCP|        31|      34|\n",
      "+--------------------+------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark.createDataFrame([[\"An angiography showed bleeding in two vessels off of the Minnie supplying the sigmoid that were succesfully embolized.\", \"Minnie\", 57, 63],\n",
    "     [\"After discussing this with his PCP, Leon was clear that the patient had had recurrent DVTs and ultimately a PE and his PCP felt strongly that he required long-term anticoagulation \", \"PCP\", 31, 34]])\\\n",
    "     .toDF(\"text\", \"target\", \"char_begin\", \"char_end\")\n",
    "\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_assembler = nlp.DocumentAssembler() \\\n",
    "    .setInputCol(\"text\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "sentenceDetector = nlp.SentenceDetector()\\\n",
    "    .setInputCols([\"document\"])\\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "tokenizer = nlp.Tokenizer() \\\n",
    "    .setInputCols([\"sentence\"]) \\\n",
    "    .setOutputCol(\"tokens\")\n",
    "\n",
    "converter = medical.AssertionChunkConverter() \\\n",
    "    .setInputCols(\"tokens\")\\\n",
    "    .setChunkTextCol(\"target\")\\\n",
    "    .setChunkBeginCol(\"char_begin\")\\\n",
    "    .setChunkEndCol(\"char_end\")\\\n",
    "    .setOutputTokenBeginCol(\"token_begin\")\\\n",
    "    .setOutputTokenEndCol(\"token_end\")\\\n",
    "    .setOutputCol(\"chunk\")\n",
    "\n",
    "pipeline = nlp.Pipeline().setStages([document_assembler,sentenceDetector, tokenizer, converter])\n",
    "\n",
    "results = pipeline.fit(data).transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JjfUo0aTKFEL"
   },
   "source": [
    "# **Train a custom Assertion Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "QPFTJxtlIKQT"
   },
   "outputs": [],
   "source": [
    "!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Healthcare/data/i2b2_assertion_sample_short.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "hRFW3nyALHx0"
   },
   "outputs": [],
   "source": [
    "assertion_df = spark.read.option(\"header\", True).option(\"inferSchema\", \"True\").csv(\"i2b2_assertion_sample_short.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TQn7bJZtL9uX",
    "outputId": "4458414c-4bbb-4965-8a19-594c1b7f2358"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------+-------------------+-------+-----+---+\n",
      "|                                             text|             target|  label|start|end|\n",
      "+-------------------------------------------------+-------------------+-------+-----+---+\n",
      "|She has no history of liver disease , hepatitis .|      liver disease| absent|    5|  6|\n",
      "|                         1. Undesired fertility .|undesired fertility|present|    1|  2|\n",
      "|                            3) STATUS POST FALL .|               fall|present|    3|  3|\n",
      "+-------------------------------------------------+-------------------+-------+-----+---+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assertion_df.show(3, truncate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B6IuDZ9Qw7Cu",
    "outputId": "09b7cdb4-3c2f-42b1-f202-7c5b46be9277"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 721\n",
      "Test Dataset Count: 170\n"
     ]
    }
   ],
   "source": [
    "(training_data, test_data) = assertion_df.randomSplit([0.8, 0.2], seed = 100)\n",
    "print(\"Training Dataset Count: \" + str(training_data.count()))\n",
    "print(\"Test Dataset Count: \" + str(test_data.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fktQ3EbBZwo-",
    "outputId": "b583259a-a44a-486d-e595-b433c61a8e07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|label  |count|\n",
      "+-------+-----+\n",
      "|present|546  |\n",
      "|absent |175  |\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data.groupBy('label').count().orderBy('count', ascending=False).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UTNhwoSDLLVG",
    "outputId": "fa0b607d-263a-4065-ba88-aed9d07d316b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "document = nlp.DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "chunk = nlp.Doc2Chunk()\\\n",
    "    .setInputCols(\"document\")\\\n",
    "    .setOutputCol(\"chunk\")\\\n",
    "    .setChunkCol(\"target\")\\\n",
    "    .setStartCol(\"start\")\\\n",
    "    .setStartColByTokenIndex(True)\\\n",
    "    .setFailOnMissing(False)\\\n",
    "    .setLowerCase(True)\n",
    "\n",
    "token = nlp.Tokenizer()\\\n",
    "    .setInputCols(['document'])\\\n",
    "    .setOutputCol('token')\n",
    "\n",
    "embeddings = nlp.WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n",
    "    .setInputCols([\"document\", \"token\"])\\\n",
    "    .setOutputCol(\"embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lkp7KmK6pv0-"
   },
   "source": [
    "We will transform our test data with a pipeline consisting of same steps with the pipeline which contains AssertionDLApproach.\n",
    "By doing this, we enable that test data will have same columns with training data in AssertionDLApproach. <br/>\n",
    "The goal of this implementation is enabling the usage of `setTestDataset()` parameter in AssertionDLApproach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "-7DScL2-uIOm"
   },
   "outputs": [],
   "source": [
    "clinical_assertion_pipeline = nlp.Pipeline(\n",
    "    stages = [\n",
    "    document,\n",
    "    chunk,\n",
    "    token,\n",
    "    embeddings])\n",
    "\n",
    "assertion_test_data = clinical_assertion_pipeline.fit(test_data).transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nwuyumqGuHwY",
    "outputId": "ece31244-aec7-4970-966a-bf31c64bd079"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text',\n",
       " 'target',\n",
       " 'label',\n",
       " 'start',\n",
       " 'end',\n",
       " 'document',\n",
       " 'chunk',\n",
       " 'token',\n",
       " 'embeddings']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assertion_test_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aE-99quUsJ5V"
   },
   "source": [
    "We save the test data in parquet format to use in `AssertionDLApproach()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "A3Hx0w05uQ7E"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "assertion_test_data.write.parquet('i2b2_assertion_sample_test_data.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uTishXbut1MS"
   },
   "source": [
    "# **Graph setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "zl1xBA65IZ2j"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘training_logs’: File exists\n",
      "mkdir: cannot create directory ‘assertion_tf_graph’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir training_logs\n",
    "!mkdir assertion_tf_graph\n",
    "\n",
    "# ready to use tf_graph\n",
    "!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Healthcare/tf_graphs/blstm_34_32_30_200_2.pb -P ./assertion_tf_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wegOakRbw9nJ"
   },
   "source": [
    "We will use TFGraphBuilder annotator which can be used to create graphs in the model training pipeline.\n",
    "\n",
    "TFGraphBuilder inspects the data and creates the proper graph if a suitable version of TensorFlow (<= 2.7 ) is available. The graph is stored in the defined folder and loaded by the approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "EtR9lajQxHpc"
   },
   "outputs": [],
   "source": [
    "from sparknlp_jsl.annotator import TFGraphBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "r4nb2OmrxIsH"
   },
   "outputs": [],
   "source": [
    "graph_folder= \"./tf_graphs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "qZPZIUWYxN3r"
   },
   "outputs": [],
   "source": [
    "assertion_graph_builder = medical.TFGraphBuilder()\\\n",
    "    .setModelName(\"assertion_dl\")\\\n",
    "    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "    .setLabelColumn(\"label\")\\\n",
    "    .setGraphFolder(graph_folder)\\\n",
    "    .setGraphFile(\"assertion_graph.pb\")\\\n",
    "    .setMaxSequenceLength(250)\\\n",
    "    .setHiddenUnitsNumber(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "RNzTsoSeXezx"
   },
   "outputs": [],
   "source": [
    "# Create custom graph\n",
    "\n",
    "# from sparknlp_jsl.training import tf_graph\n",
    "# tf_graph.print_model_params(\"assertion_dl\")\n",
    "\n",
    "# feat_size = 200\n",
    "# n_classes = 6\n",
    "\n",
    "# tf_graph.build(\"assertion_dl\",\n",
    "#               build_params={\"n_classes\": n_classes},\n",
    "#               model_location= \"./tf_graphs\", \n",
    "#               model_filename=\"blstm_34_32_30_{}_{}.pb\".format(feat_size, n_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6D0Ng7nMUjJa"
   },
   "source": [
    "**Setting the Scope Window (Target Area) Dynamically in Assertion Status Detection Models**\n",
    "\n",
    "\n",
    "This parameter allows you to train the Assertion Status Models to focus on specific context windows when resolving the status of a NER chunk. The window is in format `[X,Y]` being `X` the number of tokens to consider on the left of the chunk, and `Y` the max number of tokens to consider on the right. Let’s take a look at what different windows mean:\n",
    "\n",
    "\n",
    "*   By default, the window is `[-1,-1]` which means that the Assertion Status will look at all of the tokens in the sentence/document (up to a maximum of tokens set in `setMaxSentLen()` ).\n",
    "*   `[0,0]` means “don’t pay attention to any token except the ner_chunk”, what basically is not considering any context for the Assertion resolution.\n",
    "*   `[9,15]` is what empirically seems to be the best baseline, meaning that we look up to 9 tokens on the left and 15 on the right of the ner chunk to understand the context and resolve the status.\n",
    "\n",
    "\n",
    "Check this [Scope Window Tuning Assertion Status Detection notebook](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/2.1.Scope_window_tuning_assertion_status_detection.ipynb)  that illustrates the effect of the different windows and how to properly fine-tune your AssertionDLModels to get the best of them.\n",
    "\n",
    "In our case, the best Scope Window is around [10,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "qG2o6Yq2xk4N"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIf .setTestDataset parameter is employed, raw test data cannot be fitted. .setTestDataset only works for dataframes which are correctly transformed\\nby a pipeline consisting of document, chunk, embeddings stages.\\n'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scope_window = [10,10]\n",
    "\n",
    "assertionStatus = medical.AssertionDLApproach()\\\n",
    "    .setLabelCol(\"label\")\\\n",
    "    .setInputCols(\"document\", \"chunk\", \"embeddings\")\\\n",
    "    .setOutputCol(\"assertion\")\\\n",
    "    .setBatchSize(128)\\\n",
    "    .setDropout(0.1)\\\n",
    "    .setLearningRate(0.001)\\\n",
    "    .setEpochs(15)\\\n",
    "    .setValidationSplit(0.2)\\\n",
    "    .setStartCol(\"start\")\\\n",
    "    .setEndCol(\"end\")\\\n",
    "    .setMaxSentLen(250)\\\n",
    "    .setIncludeConfidence(True)\\\n",
    "    .setEnableOutputLogs(True)\\\n",
    "    .setOutputLogsPath('training_logs/')\\\n",
    "    .setGraphFolder(graph_folder)\\\n",
    "    .setGraphFile(f\"{graph_folder}/assertion_graph.pb\")\\\n",
    "    .setTestDataset(path=\"./i2b2_assertion_sample_test_data.parquet\")\\\n",
    "    .setScopeWindow(scope_window)\n",
    "\n",
    "'''\n",
    "If .setTestDataset parameter is employed, raw test data cannot be fitted. .setTestDataset only works for dataframes which are correctly transformed\n",
    "by a pipeline consisting of document, chunk, embeddings stages.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "97ATs6a41jdE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nassertionStatus = AssertionLogRegApproach()    .setLabelCol(\"label\")    .setInputCols(\"document\", \"chunk\", \"embeddings\")    .setOutputCol(\"assertion\")    .setMaxIter(100) # default: 26\\n'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "assertionStatus = AssertionLogRegApproach()\\\n",
    "    .setLabelCol(\"label\")\\\n",
    "    .setInputCols(\"document\", \"chunk\", \"embeddings\")\\\n",
    "    .setOutputCol(\"assertion\")\\\n",
    "    .setMaxIter(100) # default: 26\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "EKRL7Oy4MC1C"
   },
   "outputs": [],
   "source": [
    "clinical_assertion_pipeline = nlp.Pipeline(\n",
    "    stages = [\n",
    "    document,\n",
    "    chunk,\n",
    "    token,\n",
    "    embeddings,\n",
    "    assertion_graph_builder,\n",
    "    assertionStatus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ei54XasnMU0U",
    "outputId": "72e122d5-c7f1-44e1-b58c-e92e1f8878fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Graph Builder configuration:\n",
      "Model name: assertion_dl\n",
      "Graph folder: ./tf_graphs\n",
      "Graph file name: assertion_graph.pb\n",
      "Build params: {'n_classes': 2, 'feat_size': 200, 'max_seq_len': 250, 'n_hidden': 25}\n",
      "Device mapping: no known devices.\n",
      "Device mapping: no known devices.\n",
      "assertion_dl graph exported to ./tf_graphs/assertion_graph.pb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.78s\n",
      "Total validation loss: 0.8720\tAvg validation loss: 0.4360\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 116\t 28\t 0\t 0.8055556\t 1.0\t 0.8923077\n",
      "absent\t 0\t 0\t 28\t 0.0\t 0.0\t 0.0\n",
      "tp: 116 fp: 28 fn: 28 labels: 2\n",
      "Macro-average\t prec: 0.4027778, rec: 0.5, f1: 0.44615385\n",
      "Micro-average\t prec: 0.8055556, rec: 0.8055556, f1: 0.80555564\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.57s\n",
      "Total test loss: 1.2309\tAvg test loss: 0.6155\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 117\t 53\t 0\t 0.6882353\t 1.0\t 0.815331\n",
      "absent\t 0\t 0\t 53\t 0.0\t 0.0\t 0.0\n",
      "tp: 117 fp: 53 fn: 53 labels: 2\n",
      "Macro-average\t prec: 0.34411764, rec: 0.5, f1: 0.4076655\n",
      "Micro-average\t prec: 0.6882353, rec: 0.6882353, f1: 0.6882353\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.54s\n",
      "Total validation loss: 0.8139\tAvg validation loss: 0.4070\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 116\t 28\t 0\t 0.8055556\t 1.0\t 0.8923077\n",
      "absent\t 0\t 0\t 28\t 0.0\t 0.0\t 0.0\n",
      "tp: 116 fp: 28 fn: 28 labels: 2\n",
      "Macro-average\t prec: 0.4027778, rec: 0.5, f1: 0.44615385\n",
      "Micro-average\t prec: 0.8055556, rec: 0.8055556, f1: 0.80555564\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.59s\n",
      "Total test loss: 1.1847\tAvg test loss: 0.5923\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 117\t 53\t 0\t 0.6882353\t 1.0\t 0.815331\n",
      "absent\t 0\t 0\t 53\t 0.0\t 0.0\t 0.0\n",
      "tp: 117 fp: 53 fn: 53 labels: 2\n",
      "Macro-average\t prec: 0.34411764, rec: 0.5, f1: 0.4076655\n",
      "Micro-average\t prec: 0.6882353, rec: 0.6882353, f1: 0.6882353\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.55s\n",
      "Total validation loss: 0.7987\tAvg validation loss: 0.3993\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 116\t 28\t 0\t 0.8055556\t 1.0\t 0.8923077\n",
      "absent\t 0\t 0\t 28\t 0.0\t 0.0\t 0.0\n",
      "tp: 116 fp: 28 fn: 28 labels: 2\n",
      "Macro-average\t prec: 0.4027778, rec: 0.5, f1: 0.44615385\n",
      "Micro-average\t prec: 0.8055556, rec: 0.8055556, f1: 0.80555564\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.57s\n",
      "Total test loss: 1.1003\tAvg test loss: 0.5501\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 117\t 53\t 0\t 0.6882353\t 1.0\t 0.815331\n",
      "absent\t 0\t 0\t 53\t 0.0\t 0.0\t 0.0\n",
      "tp: 117 fp: 53 fn: 53 labels: 2\n",
      "Macro-average\t prec: 0.34411764, rec: 0.5, f1: 0.4076655\n",
      "Micro-average\t prec: 0.6882353, rec: 0.6882353, f1: 0.6882353\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.55s\n",
      "Total validation loss: 0.7910\tAvg validation loss: 0.3955\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 116\t 24\t 0\t 0.82857144\t 1.0\t 0.90625\n",
      "absent\t 4\t 0\t 24\t 1.0\t 0.14285715\t 0.25\n",
      "tp: 120 fp: 24 fn: 24 labels: 2\n",
      "Macro-average\t prec: 0.9142857, rec: 0.5714286, f1: 0.7032967\n",
      "Micro-average\t prec: 0.8333333, rec: 0.8333333, f1: 0.8333333\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.59s\n",
      "Total test loss: 0.9818\tAvg test loss: 0.4909\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 117\t 44\t 0\t 0.72670805\t 1.0\t 0.8417266\n",
      "absent\t 9\t 0\t 44\t 1.0\t 0.16981132\t 0.29032257\n",
      "tp: 126 fp: 44 fn: 44 labels: 2\n",
      "Macro-average\t prec: 0.863354, rec: 0.5849057, f1: 0.69736207\n",
      "Micro-average\t prec: 0.7411765, rec: 0.7411765, f1: 0.7411765\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.55s\n",
      "Total validation loss: 0.7266\tAvg validation loss: 0.3633\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 115\t 23\t 1\t 0.8333333\t 0.9913793\t 0.9055118\n",
      "absent\t 5\t 1\t 23\t 0.8333333\t 0.17857143\t 0.29411766\n",
      "tp: 120 fp: 24 fn: 24 labels: 2\n",
      "Macro-average\t prec: 0.8333333, rec: 0.58497536, f1: 0.6874095\n",
      "Micro-average\t prec: 0.8333333, rec: 0.8333333, f1: 0.8333333\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.57s\n",
      "Total test loss: 0.8697\tAvg test loss: 0.4348\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 117\t 39\t 0\t 0.75\t 1.0\t 0.85714287\n",
      "absent\t 14\t 0\t 39\t 1.0\t 0.26415095\t 0.41791046\n",
      "tp: 131 fp: 39 fn: 39 labels: 2\n",
      "Macro-average\t prec: 0.875, rec: 0.6320755, f1: 0.7339593\n",
      "Micro-average\t prec: 0.7705882, rec: 0.7705882, f1: 0.7705882\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.55s\n",
      "Total validation loss: 0.7194\tAvg validation loss: 0.3597\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 115\t 20\t 1\t 0.8518519\t 0.9913793\t 0.9163347\n",
      "absent\t 8\t 1\t 20\t 0.8888889\t 0.2857143\t 0.43243244\n",
      "tp: 123 fp: 21 fn: 21 labels: 2\n",
      "Macro-average\t prec: 0.8703704, rec: 0.6385468, f1: 0.7366504\n",
      "Micro-average\t prec: 0.8541667, rec: 0.8541667, f1: 0.8541667\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.58s\n",
      "Total test loss: 0.7551\tAvg test loss: 0.3776\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 116\t 28\t 1\t 0.8055556\t 0.991453\t 0.8888889\n",
      "absent\t 25\t 1\t 28\t 0.96153843\t 0.4716981\t 0.6329113\n",
      "tp: 141 fp: 29 fn: 29 labels: 2\n",
      "Macro-average\t prec: 0.883547, rec: 0.73157555, f1: 0.8004116\n",
      "Micro-average\t prec: 0.82941175, rec: 0.82941175, f1: 0.82941175\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.54s\n",
      "Total validation loss: 0.7152\tAvg validation loss: 0.3576\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 114\t 16\t 2\t 0.8769231\t 0.98275864\t 0.9268293\n",
      "absent\t 12\t 2\t 16\t 0.85714287\t 0.42857143\t 0.5714286\n",
      "tp: 126 fp: 18 fn: 18 labels: 2\n",
      "Macro-average\t prec: 0.867033, rec: 0.70566505, f1: 0.77807033\n",
      "Micro-average\t prec: 0.875, rec: 0.875, f1: 0.875\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.57s\n",
      "Total test loss: 0.6664\tAvg test loss: 0.3332\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 114\t 23\t 3\t 0.8321168\t 0.974359\t 0.8976378\n",
      "absent\t 30\t 3\t 23\t 0.90909094\t 0.5660377\t 0.69767445\n",
      "tp: 144 fp: 26 fn: 26 labels: 2\n",
      "Macro-average\t prec: 0.87060386, rec: 0.77019835, f1: 0.81732905\n",
      "Micro-average\t prec: 0.84705883, rec: 0.84705883, f1: 0.84705883\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.54s\n",
      "Total validation loss: 0.7103\tAvg validation loss: 0.3552\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 115\t 15\t 1\t 0.88461536\t 0.9913793\t 0.93495935\n",
      "absent\t 13\t 1\t 15\t 0.9285714\t 0.4642857\t 0.6190476\n",
      "tp: 128 fp: 16 fn: 16 labels: 2\n",
      "Macro-average\t prec: 0.9065934, rec: 0.7278325, f1: 0.80743724\n",
      "Micro-average\t prec: 0.8888889, rec: 0.8888889, f1: 0.8888889\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.59s\n",
      "Total test loss: 0.6091\tAvg test loss: 0.3046\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 113\t 21\t 4\t 0.8432836\t 0.96581197\t 0.9003984\n",
      "absent\t 32\t 4\t 21\t 0.8888889\t 0.6037736\t 0.7191012\n",
      "tp: 145 fp: 25 fn: 25 labels: 2\n",
      "Macro-average\t prec: 0.86608624, rec: 0.7847928, f1: 0.823438\n",
      "Micro-average\t prec: 0.85294116, rec: 0.85294116, f1: 0.85294116\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.53s\n",
      "Total validation loss: 0.7211\tAvg validation loss: 0.3606\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 113\t 14\t 3\t 0.8897638\t 0.9741379\t 0.9300412\n",
      "absent\t 14\t 3\t 14\t 0.8235294\t 0.5\t 0.6222222\n",
      "tp: 127 fp: 17 fn: 17 labels: 2\n",
      "Macro-average\t prec: 0.8566466, rec: 0.73706895, f1: 0.7923718\n",
      "Micro-average\t prec: 0.8819444, rec: 0.8819444, f1: 0.8819444\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.58s\n",
      "Total test loss: 0.5812\tAvg test loss: 0.2906\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 112\t 21\t 5\t 0.84210527\t 0.95726496\t 0.896\n",
      "absent\t 32\t 5\t 21\t 0.8648649\t 0.6037736\t 0.7111111\n",
      "tp: 144 fp: 26 fn: 26 labels: 2\n",
      "Macro-average\t prec: 0.8534851, rec: 0.78051925, f1: 0.815373\n",
      "Micro-average\t prec: 0.84705883, rec: 0.84705883, f1: 0.84705883\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.53s\n",
      "Total validation loss: 0.7032\tAvg validation loss: 0.3516\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 114\t 18\t 2\t 0.8636364\t 0.98275864\t 0.91935486\n",
      "absent\t 10\t 2\t 18\t 0.8333333\t 0.35714287\t 0.5\n",
      "tp: 124 fp: 20 fn: 20 labels: 2\n",
      "Macro-average\t prec: 0.8484849, rec: 0.6699507, f1: 0.748722\n",
      "Micro-average\t prec: 0.8611111, rec: 0.8611111, f1: 0.8611111\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.58s\n",
      "Total test loss: 0.5699\tAvg test loss: 0.2849\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 114\t 24\t 3\t 0.82608694\t 0.974359\t 0.89411765\n",
      "absent\t 29\t 3\t 24\t 0.90625\t 0.5471698\t 0.68235296\n",
      "tp: 143 fp: 27 fn: 27 labels: 2\n",
      "Macro-average\t prec: 0.8661685, rec: 0.76076436, f1: 0.81005204\n",
      "Micro-average\t prec: 0.84117645, rec: 0.84117645, f1: 0.84117645\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.54s\n",
      "Total validation loss: 0.7220\tAvg validation loss: 0.3610\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 114\t 15\t 2\t 0.88372093\t 0.98275864\t 0.9306122\n",
      "absent\t 13\t 2\t 15\t 0.8666667\t 0.4642857\t 0.60465115\n",
      "tp: 127 fp: 17 fn: 17 labels: 2\n",
      "Macro-average\t prec: 0.87519383, rec: 0.7235222, f1: 0.79216343\n",
      "Micro-average\t prec: 0.8819444, rec: 0.8819444, f1: 0.8819444\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.58s\n",
      "Total test loss: 0.5507\tAvg test loss: 0.2753\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 113\t 22\t 4\t 0.837037\t 0.96581197\t 0.8968253\n",
      "absent\t 31\t 4\t 22\t 0.8857143\t 0.5849057\t 0.7045455\n",
      "tp: 144 fp: 26 fn: 26 labels: 2\n",
      "Macro-average\t prec: 0.8613757, rec: 0.7753588, f1: 0.816107\n",
      "Micro-average\t prec: 0.84705883, rec: 0.84705883, f1: 0.84705883\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.54s\n",
      "Total validation loss: 0.7179\tAvg validation loss: 0.3590\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 114\t 16\t 2\t 0.8769231\t 0.98275864\t 0.9268293\n",
      "absent\t 12\t 2\t 16\t 0.85714287\t 0.42857143\t 0.5714286\n",
      "tp: 126 fp: 18 fn: 18 labels: 2\n",
      "Macro-average\t prec: 0.867033, rec: 0.70566505, f1: 0.77807033\n",
      "Micro-average\t prec: 0.875, rec: 0.875, f1: 0.875\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.59s\n",
      "Total test loss: 0.5440\tAvg test loss: 0.2720\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 114\t 21\t 3\t 0.84444445\t 0.974359\t 0.9047619\n",
      "absent\t 32\t 3\t 21\t 0.9142857\t 0.6037736\t 0.72727275\n",
      "tp: 146 fp: 24 fn: 24 labels: 2\n",
      "Macro-average\t prec: 0.8793651, rec: 0.7890663, f1: 0.8317721\n",
      "Micro-average\t prec: 0.85882354, rec: 0.85882354, f1: 0.85882354\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.54s\n",
      "Total validation loss: 0.7305\tAvg validation loss: 0.3653\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 112\t 13\t 4\t 0.896\t 0.9655172\t 0.92946064\n",
      "absent\t 15\t 4\t 13\t 0.7894737\t 0.53571427\t 0.6382979\n",
      "tp: 127 fp: 17 fn: 17 labels: 2\n",
      "Macro-average\t prec: 0.84273684, rec: 0.7506157, f1: 0.79401326\n",
      "Micro-average\t prec: 0.8819444, rec: 0.8819444, f1: 0.8819444\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.58s\n",
      "Total test loss: 0.5306\tAvg test loss: 0.2653\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 114\t 20\t 3\t 0.8507463\t 0.974359\t 0.90836656\n",
      "absent\t 33\t 3\t 20\t 0.9166667\t 0.6226415\t 0.74157304\n",
      "tp: 147 fp: 23 fn: 23 labels: 2\n",
      "Macro-average\t prec: 0.88370645, rec: 0.79850024, f1: 0.8389455\n",
      "Micro-average\t prec: 0.86470586, rec: 0.86470586, f1: 0.86470586\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.53s\n",
      "Total validation loss: 0.7446\tAvg validation loss: 0.3723\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 112\t 12\t 4\t 0.9032258\t 0.9655172\t 0.93333334\n",
      "absent\t 16\t 4\t 12\t 0.8\t 0.5714286\t 0.6666667\n",
      "tp: 128 fp: 16 fn: 16 labels: 2\n",
      "Macro-average\t prec: 0.8516129, rec: 0.7684729, f1: 0.8079096\n",
      "Micro-average\t prec: 0.8888889, rec: 0.8888889, f1: 0.8888889\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.57s\n",
      "Total test loss: 0.5251\tAvg test loss: 0.2626\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 114\t 18\t 3\t 0.8636364\t 0.974359\t 0.9156627\n",
      "absent\t 35\t 3\t 18\t 0.92105263\t 0.6603774\t 0.76923084\n",
      "tp: 149 fp: 21 fn: 21 labels: 2\n",
      "Macro-average\t prec: 0.8923445, rec: 0.81736815, f1: 0.8532123\n",
      "Micro-average\t prec: 0.87647057, rec: 0.87647057, f1: 0.87647057\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.54s\n",
      "Total validation loss: 0.7040\tAvg validation loss: 0.3520\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 113\t 15\t 3\t 0.8828125\t 0.9741379\t 0.9262295\n",
      "absent\t 13\t 3\t 15\t 0.8125\t 0.4642857\t 0.59090906\n",
      "tp: 126 fp: 18 fn: 18 labels: 2\n",
      "Macro-average\t prec: 0.84765625, rec: 0.7192118, f1: 0.77816945\n",
      "Micro-average\t prec: 0.875, rec: 0.875, f1: 0.875\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.58s\n",
      "Total test loss: 0.5321\tAvg test loss: 0.2660\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 114\t 20\t 3\t 0.8507463\t 0.974359\t 0.90836656\n",
      "absent\t 33\t 3\t 20\t 0.9166667\t 0.6226415\t 0.74157304\n",
      "tp: 147 fp: 23 fn: 23 labels: 2\n",
      "Macro-average\t prec: 0.88370645, rec: 0.79850024, f1: 0.8389455\n",
      "Micro-average\t prec: 0.86470586, rec: 0.86470586, f1: 0.86470586\n",
      "CPU times: user 4.16 s, sys: 74 ms, total: 4.24 s\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "assertion_model = clinical_assertion_pipeline.fit(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "30SmcTiSpnWa"
   },
   "source": [
    "Checking the results saved in the log file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kOiu1vuspKut",
    "outputId": "4a51d7c9-76ec-44a7-c3fc-402fc99e4d46"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AssertionDLApproach_2915a6614175.log',\n",
       " 'AssertionDLApproach_db1aee033c36.log',\n",
       " 'AssertionDLApproach_81309dd0f404.log']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "log_files = os.listdir(\"./training_logs\")\n",
    "log_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CcQV0-fIrJHz",
    "outputId": "4ca50420-aad6-4459-80d7-a720d0349bec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of the selected graph: ./tf_graphs/assertion_graph.pb\n",
      "Training started, trainExamples: 721\n",
      "\n",
      "\n",
      "Epoch: 0 started, learning rate: 0.001, dataset size: 577\n",
      "Done, 3.544471085 total training loss: 2.8244052, avg training loss: 0.564881, batches: 5\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.78s\n",
      "Total validation loss: 0.8720\tAvg validation loss: 0.4360\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 116\t 28\t 0\t 0.8055556\t 1.0\t 0.8923077\n",
      "absent\t 0\t 0\t 28\t 0.0\t 0.0\t 0.0\n",
      "tp: 116 fp: 28 fn: 28 labels: 2\n",
      "Macro-average\t prec: 0.4027778, rec: 0.5, f1: 0.44615385\n",
      "Micro-average\t prec: 0.8055556, rec: 0.8055556, f1: 0.80555564\n",
      "\n",
      "\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.57s\n",
      "Total test loss: 1.2309\tAvg test loss: 0.6155\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 117\t 53\t 0\t 0.6882353\t 1.0\t 0.815331\n",
      "absent\t 0\t 0\t 53\t 0.0\t 0.0\t 0.0\n",
      "tp: 117 fp: 53 fn: 53 labels: 2\n",
      "Macro-average\t prec: 0.34411764, rec: 0.5, f1: 0.4076655\n",
      "Micro-average\t prec: 0.6882353, rec: 0.6882353, f1: 0.6882353\n",
      "\n",
      "\n",
      "Epoch: 1 started, learning rate: 9.5E-4, dataset size: 577\n",
      "Done, 2.486416008 total training loss: 2.7408278, avg training loss: 0.54816556, batches: 5\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.54s\n",
      "Total validation loss: 0.8139\tAvg validation loss: 0.4070\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 116\t 28\t 0\t 0.8055556\t 1.0\t 0.8923077\n",
      "absent\t 0\t 0\t 28\t 0.0\t 0.0\t 0.0\n",
      "tp: 116 fp: 28 fn: 28 labels: 2\n",
      "Macro-average\t prec: 0.4027778, rec: 0.5, f1: 0.44615385\n",
      "Micro-average\t prec: 0.8055556, rec: 0.8055556, f1: 0.80555564\n",
      "\n",
      "\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.59s\n",
      "Total test loss: 1.1847\tAvg test loss: 0.5923\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 117\t 53\t 0\t 0.6882353\t 1.0\t 0.815331\n",
      "absent\t 0\t 0\t 53\t 0.0\t 0.0\t 0.0\n",
      "tp: 117 fp: 53 fn: 53 labels: 2\n",
      "Macro-average\t prec: 0.34411764, rec: 0.5, f1: 0.4076655\n",
      "Micro-average\t prec: 0.6882353, rec: 0.6882353, f1: 0.6882353\n",
      "\n",
      "\n",
      "Epoch: 2 started, learning rate: 9.025E-4, dataset size: 577\n",
      "Done, 2.48447761 total training loss: 2.6142895, avg training loss: 0.5228579, batches: 5\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.55s\n",
      "Total validation loss: 0.7987\tAvg validation loss: 0.3993\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 116\t 28\t 0\t 0.8055556\t 1.0\t 0.8923077\n",
      "absent\t 0\t 0\t 28\t 0.0\t 0.0\t 0.0\n",
      "tp: 116 fp: 28 fn: 28 labels: 2\n",
      "Macro-average\t prec: 0.4027778, rec: 0.5, f1: 0.44615385\n",
      "Micro-average\t prec: 0.8055556, rec: 0.8055556, f1: 0.80555564\n",
      "\n",
      "\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.57s\n",
      "Total test loss: 1.1003\tAvg test loss: 0.5501\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 117\t 53\t 0\t 0.6882353\t 1.0\t 0.815331\n",
      "absent\t 0\t 0\t 53\t 0.0\t 0.0\t 0.0\n",
      "tp: 117 fp: 53 fn: 53 labels: 2\n",
      "Macro-average\t prec: 0.34411764, rec: 0.5, f1: 0.4076655\n",
      "Micro-average\t prec: 0.6882353, rec: 0.6882353, f1: 0.6882353\n",
      "\n",
      "\n",
      "Epoch: 3 started, learning rate: 8.57375E-4, dataset size: 577\n",
      "Done, 2.532037999 total training loss: 2.4062681, avg training loss: 0.48125362, batches: 5\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.55s\n",
      "Total validation loss: 0.7910\tAvg validation loss: 0.3955\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 116\t 24\t 0\t 0.82857144\t 1.0\t 0.90625\n",
      "absent\t 4\t 0\t 24\t 1.0\t 0.14285715\t 0.25\n",
      "tp: 120 fp: 24 fn: 24 labels: 2\n",
      "Macro-average\t prec: 0.9142857, rec: 0.5714286, f1: 0.7032967\n",
      "Micro-average\t prec: 0.8333333, rec: 0.8333333, f1: 0.8333333\n",
      "\n",
      "\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.59s\n",
      "Total test loss: 0.9818\tAvg test loss: 0.4909\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 117\t 44\t 0\t 0.72670805\t 1.0\t 0.8417266\n",
      "absent\t 9\t 0\t 44\t 1.0\t 0.16981132\t 0.29032257\n",
      "tp: 126 fp: 44 fn: 44 labels: 2\n",
      "Macro-average\t prec: 0.863354, rec: 0.5849057, f1: 0.69736207\n",
      "Micro-average\t prec: 0.7411765, rec: 0.7411765, f1: 0.7411765\n",
      "\n",
      "\n",
      "Epoch: 4 started, learning rate: 8.145062E-4, dataset size: 577\n",
      "Done, 2.461891142 total training loss: 2.2613578, avg training loss: 0.45227155, batches: 5\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.55s\n",
      "Total validation loss: 0.7266\tAvg validation loss: 0.3633\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 115\t 23\t 1\t 0.8333333\t 0.9913793\t 0.9055118\n",
      "absent\t 5\t 1\t 23\t 0.8333333\t 0.17857143\t 0.29411766\n",
      "tp: 120 fp: 24 fn: 24 labels: 2\n",
      "Macro-average\t prec: 0.8333333, rec: 0.58497536, f1: 0.6874095\n",
      "Micro-average\t prec: 0.8333333, rec: 0.8333333, f1: 0.8333333\n",
      "\n",
      "\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.57s\n",
      "Total test loss: 0.8697\tAvg test loss: 0.4348\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 117\t 39\t 0\t 0.75\t 1.0\t 0.85714287\n",
      "absent\t 14\t 0\t 39\t 1.0\t 0.26415095\t 0.41791046\n",
      "tp: 131 fp: 39 fn: 39 labels: 2\n",
      "Macro-average\t prec: 0.875, rec: 0.6320755, f1: 0.7339593\n",
      "Micro-average\t prec: 0.7705882, rec: 0.7705882, f1: 0.7705882\n",
      "\n",
      "\n",
      "Epoch: 5 started, learning rate: 7.7378086E-4, dataset size: 577\n",
      "Done, 2.449308023 total training loss: 2.0225847, avg training loss: 0.40451694, batches: 5\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.55s\n",
      "Total validation loss: 0.7194\tAvg validation loss: 0.3597\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 115\t 20\t 1\t 0.8518519\t 0.9913793\t 0.9163347\n",
      "absent\t 8\t 1\t 20\t 0.8888889\t 0.2857143\t 0.43243244\n",
      "tp: 123 fp: 21 fn: 21 labels: 2\n",
      "Macro-average\t prec: 0.8703704, rec: 0.6385468, f1: 0.7366504\n",
      "Micro-average\t prec: 0.8541667, rec: 0.8541667, f1: 0.8541667\n",
      "\n",
      "\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.58s\n",
      "Total test loss: 0.7551\tAvg test loss: 0.3776\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 116\t 28\t 1\t 0.8055556\t 0.991453\t 0.8888889\n",
      "absent\t 25\t 1\t 28\t 0.96153843\t 0.4716981\t 0.6329113\n",
      "tp: 141 fp: 29 fn: 29 labels: 2\n",
      "Macro-average\t prec: 0.883547, rec: 0.73157555, f1: 0.8004116\n",
      "Micro-average\t prec: 0.82941175, rec: 0.82941175, f1: 0.82941175\n",
      "\n",
      "\n",
      "Epoch: 6 started, learning rate: 7.350918E-4, dataset size: 577\n",
      "Done, 2.524158129 total training loss: 1.7781672, avg training loss: 0.35563344, batches: 5\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.54s\n",
      "Total validation loss: 0.7152\tAvg validation loss: 0.3576\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 114\t 16\t 2\t 0.8769231\t 0.98275864\t 0.9268293\n",
      "absent\t 12\t 2\t 16\t 0.85714287\t 0.42857143\t 0.5714286\n",
      "tp: 126 fp: 18 fn: 18 labels: 2\n",
      "Macro-average\t prec: 0.867033, rec: 0.70566505, f1: 0.77807033\n",
      "Micro-average\t prec: 0.875, rec: 0.875, f1: 0.875\n",
      "\n",
      "\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.57s\n",
      "Total test loss: 0.6664\tAvg test loss: 0.3332\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 114\t 23\t 3\t 0.8321168\t 0.974359\t 0.8976378\n",
      "absent\t 30\t 3\t 23\t 0.90909094\t 0.5660377\t 0.69767445\n",
      "tp: 144 fp: 26 fn: 26 labels: 2\n",
      "Macro-average\t prec: 0.87060386, rec: 0.77019835, f1: 0.81732905\n",
      "Micro-average\t prec: 0.84705883, rec: 0.84705883, f1: 0.84705883\n",
      "\n",
      "\n",
      "Epoch: 7 started, learning rate: 6.983372E-4, dataset size: 577\n",
      "Done, 2.501738796 total training loss: 1.7076668, avg training loss: 0.34153336, batches: 5\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.54s\n",
      "Total validation loss: 0.7103\tAvg validation loss: 0.3552\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 115\t 15\t 1\t 0.88461536\t 0.9913793\t 0.93495935\n",
      "absent\t 13\t 1\t 15\t 0.9285714\t 0.4642857\t 0.6190476\n",
      "tp: 128 fp: 16 fn: 16 labels: 2\n",
      "Macro-average\t prec: 0.9065934, rec: 0.7278325, f1: 0.80743724\n",
      "Micro-average\t prec: 0.8888889, rec: 0.8888889, f1: 0.8888889\n",
      "\n",
      "\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.59s\n",
      "Total test loss: 0.6091\tAvg test loss: 0.3046\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 113\t 21\t 4\t 0.8432836\t 0.96581197\t 0.9003984\n",
      "absent\t 32\t 4\t 21\t 0.8888889\t 0.6037736\t 0.7191012\n",
      "tp: 145 fp: 25 fn: 25 labels: 2\n",
      "Macro-average\t prec: 0.86608624, rec: 0.7847928, f1: 0.823438\n",
      "Micro-average\t prec: 0.85294116, rec: 0.85294116, f1: 0.85294116\n",
      "\n",
      "\n",
      "Epoch: 8 started, learning rate: 6.6342036E-4, dataset size: 577\n",
      "Done, 2.466461124 total training loss: 1.4865835, avg training loss: 0.2973167, batches: 5\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.53s\n",
      "Total validation loss: 0.7211\tAvg validation loss: 0.3606\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 113\t 14\t 3\t 0.8897638\t 0.9741379\t 0.9300412\n",
      "absent\t 14\t 3\t 14\t 0.8235294\t 0.5\t 0.6222222\n",
      "tp: 127 fp: 17 fn: 17 labels: 2\n",
      "Macro-average\t prec: 0.8566466, rec: 0.73706895, f1: 0.7923718\n",
      "Micro-average\t prec: 0.8819444, rec: 0.8819444, f1: 0.8819444\n",
      "\n",
      "\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.58s\n",
      "Total test loss: 0.5812\tAvg test loss: 0.2906\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 112\t 21\t 5\t 0.84210527\t 0.95726496\t 0.896\n",
      "absent\t 32\t 5\t 21\t 0.8648649\t 0.6037736\t 0.7111111\n",
      "tp: 144 fp: 26 fn: 26 labels: 2\n",
      "Macro-average\t prec: 0.8534851, rec: 0.78051925, f1: 0.815373\n",
      "Micro-average\t prec: 0.84705883, rec: 0.84705883, f1: 0.84705883\n",
      "\n",
      "\n",
      "Epoch: 9 started, learning rate: 6.302493E-4, dataset size: 577\n",
      "Done, 2.505138004 total training loss: 1.4473907, avg training loss: 0.28947812, batches: 5\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.53s\n",
      "Total validation loss: 0.7032\tAvg validation loss: 0.3516\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 114\t 18\t 2\t 0.8636364\t 0.98275864\t 0.91935486\n",
      "absent\t 10\t 2\t 18\t 0.8333333\t 0.35714287\t 0.5\n",
      "tp: 124 fp: 20 fn: 20 labels: 2\n",
      "Macro-average\t prec: 0.8484849, rec: 0.6699507, f1: 0.748722\n",
      "Micro-average\t prec: 0.8611111, rec: 0.8611111, f1: 0.8611111\n",
      "\n",
      "\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.58s\n",
      "Total test loss: 0.5699\tAvg test loss: 0.2849\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 114\t 24\t 3\t 0.82608694\t 0.974359\t 0.89411765\n",
      "absent\t 29\t 3\t 24\t 0.90625\t 0.5471698\t 0.68235296\n",
      "tp: 143 fp: 27 fn: 27 labels: 2\n",
      "Macro-average\t prec: 0.8661685, rec: 0.76076436, f1: 0.81005204\n",
      "Micro-average\t prec: 0.84117645, rec: 0.84117645, f1: 0.84117645\n",
      "\n",
      "\n",
      "Epoch: 10 started, learning rate: 5.9873686E-4, dataset size: 577\n",
      "Done, 2.430912369 total training loss: 1.3481052, avg training loss: 0.26962104, batches: 5\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.54s\n",
      "Total validation loss: 0.7220\tAvg validation loss: 0.3610\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 114\t 15\t 2\t 0.88372093\t 0.98275864\t 0.9306122\n",
      "absent\t 13\t 2\t 15\t 0.8666667\t 0.4642857\t 0.60465115\n",
      "tp: 127 fp: 17 fn: 17 labels: 2\n",
      "Macro-average\t prec: 0.87519383, rec: 0.7235222, f1: 0.79216343\n",
      "Micro-average\t prec: 0.8819444, rec: 0.8819444, f1: 0.8819444\n",
      "\n",
      "\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.58s\n",
      "Total test loss: 0.5507\tAvg test loss: 0.2753\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 113\t 22\t 4\t 0.837037\t 0.96581197\t 0.8968253\n",
      "absent\t 31\t 4\t 22\t 0.8857143\t 0.5849057\t 0.7045455\n",
      "tp: 144 fp: 26 fn: 26 labels: 2\n",
      "Macro-average\t prec: 0.8613757, rec: 0.7753588, f1: 0.816107\n",
      "Micro-average\t prec: 0.84705883, rec: 0.84705883, f1: 0.84705883\n",
      "\n",
      "\n",
      "Epoch: 11 started, learning rate: 5.688E-4, dataset size: 577\n",
      "Done, 2.480224686 total training loss: 1.3088491, avg training loss: 0.26176983, batches: 5\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.54s\n",
      "Total validation loss: 0.7179\tAvg validation loss: 0.3590\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 114\t 16\t 2\t 0.8769231\t 0.98275864\t 0.9268293\n",
      "absent\t 12\t 2\t 16\t 0.85714287\t 0.42857143\t 0.5714286\n",
      "tp: 126 fp: 18 fn: 18 labels: 2\n",
      "Macro-average\t prec: 0.867033, rec: 0.70566505, f1: 0.77807033\n",
      "Micro-average\t prec: 0.875, rec: 0.875, f1: 0.875\n",
      "\n",
      "\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.59s\n",
      "Total test loss: 0.5440\tAvg test loss: 0.2720\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 114\t 21\t 3\t 0.84444445\t 0.974359\t 0.9047619\n",
      "absent\t 32\t 3\t 21\t 0.9142857\t 0.6037736\t 0.72727275\n",
      "tp: 146 fp: 24 fn: 24 labels: 2\n",
      "Macro-average\t prec: 0.8793651, rec: 0.7890663, f1: 0.8317721\n",
      "Micro-average\t prec: 0.85882354, rec: 0.85882354, f1: 0.85882354\n",
      "\n",
      "\n",
      "Epoch: 12 started, learning rate: 5.4036E-4, dataset size: 577\n",
      "Done, 2.463728681 total training loss: 1.2654985, avg training loss: 0.2530997, batches: 5\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.54s\n",
      "Total validation loss: 0.7305\tAvg validation loss: 0.3653\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 112\t 13\t 4\t 0.896\t 0.9655172\t 0.92946064\n",
      "absent\t 15\t 4\t 13\t 0.7894737\t 0.53571427\t 0.6382979\n",
      "tp: 127 fp: 17 fn: 17 labels: 2\n",
      "Macro-average\t prec: 0.84273684, rec: 0.7506157, f1: 0.79401326\n",
      "Micro-average\t prec: 0.8819444, rec: 0.8819444, f1: 0.8819444\n",
      "\n",
      "\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.58s\n",
      "Total test loss: 0.5306\tAvg test loss: 0.2653\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 114\t 20\t 3\t 0.8507463\t 0.974359\t 0.90836656\n",
      "absent\t 33\t 3\t 20\t 0.9166667\t 0.6226415\t 0.74157304\n",
      "tp: 147 fp: 23 fn: 23 labels: 2\n",
      "Macro-average\t prec: 0.88370645, rec: 0.79850024, f1: 0.8389455\n",
      "Micro-average\t prec: 0.86470586, rec: 0.86470586, f1: 0.86470586\n",
      "\n",
      "\n",
      "Epoch: 13 started, learning rate: 5.13342E-4, dataset size: 577\n",
      "Done, 2.45669043 total training loss: 1.2578954, avg training loss: 0.25157908, batches: 5\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.53s\n",
      "Total validation loss: 0.7446\tAvg validation loss: 0.3723\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 112\t 12\t 4\t 0.9032258\t 0.9655172\t 0.93333334\n",
      "absent\t 16\t 4\t 12\t 0.8\t 0.5714286\t 0.6666667\n",
      "tp: 128 fp: 16 fn: 16 labels: 2\n",
      "Macro-average\t prec: 0.8516129, rec: 0.7684729, f1: 0.8079096\n",
      "Micro-average\t prec: 0.8888889, rec: 0.8888889, f1: 0.8888889\n",
      "\n",
      "\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.57s\n",
      "Total test loss: 0.5251\tAvg test loss: 0.2626\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 114\t 18\t 3\t 0.8636364\t 0.974359\t 0.9156627\n",
      "absent\t 35\t 3\t 18\t 0.92105263\t 0.6603774\t 0.76923084\n",
      "tp: 149 fp: 21 fn: 21 labels: 2\n",
      "Macro-average\t prec: 0.8923445, rec: 0.81736815, f1: 0.8532123\n",
      "Micro-average\t prec: 0.87647057, rec: 0.87647057, f1: 0.87647057\n",
      "\n",
      "\n",
      "Epoch: 14 started, learning rate: 4.8767487E-4, dataset size: 577\n",
      "Done, 2.557565333 total training loss: 1.1833298, avg training loss: 0.23666596, batches: 5\n",
      "Quality on validation dataset (20.0%), validation examples = 144\n",
      "time to finish evaluation: 0.54s\n",
      "Total validation loss: 0.7040\tAvg validation loss: 0.3520\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 113\t 15\t 3\t 0.8828125\t 0.9741379\t 0.9262295\n",
      "absent\t 13\t 3\t 15\t 0.8125\t 0.4642857\t 0.59090906\n",
      "tp: 126 fp: 18 fn: 18 labels: 2\n",
      "Macro-average\t prec: 0.84765625, rec: 0.7192118, f1: 0.77816945\n",
      "Micro-average\t prec: 0.875, rec: 0.875, f1: 0.875\n",
      "\n",
      "\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 0.58s\n",
      "Total test loss: 0.5321\tAvg test loss: 0.2660\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "present\t 114\t 20\t 3\t 0.8507463\t 0.974359\t 0.90836656\n",
      "absent\t 33\t 3\t 20\t 0.9166667\t 0.6226415\t 0.74157304\n",
      "tp: 147 fp: 23 fn: 23 labels: 2\n",
      "Macro-average\t prec: 0.88370645, rec: 0.79850024, f1: 0.8389455\n",
      "Micro-average\t prec: 0.86470586, rec: 0.86470586, f1: 0.86470586\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"./training_logs/\"+log_files[0]) as log_file:\n",
    "    print(log_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-k2WrFkRyQyP",
    "outputId": "675a5613-6291-49a9-cdfa-ef8ba5938d27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+\n",
      "|  label|   result|\n",
      "+-------+---------+\n",
      "|present|[present]|\n",
      "| absent|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "|present|[present]|\n",
      "+-------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = assertion_model.transform(test_data).select('label','assertion.result')\n",
    "\n",
    "preds.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "4yI73lwG2xk5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "preds_df = preds.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "yRXZFGlQ3Z2U",
    "outputId": "c7c30d32-2e4e-46db-81d0-2f4312916c9c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>present</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>absent</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>present</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>present</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>present</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>present</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>absent</td>\n",
       "      <td>absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>absent</td>\n",
       "      <td>absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>absent</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>present</td>\n",
       "      <td>present</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label   result\n",
       "0    present  present\n",
       "1     absent  present\n",
       "2    present  present\n",
       "3    present  present\n",
       "4    present  present\n",
       "..       ...      ...\n",
       "165  present  present\n",
       "166   absent   absent\n",
       "167   absent   absent\n",
       "168   absent  present\n",
       "169  present  present\n",
       "\n",
       "[170 rows x 2 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df['result'] = preds_df['result'].apply(lambda x : x[0])\n",
    "preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sYoEUlfU3cCU",
    "outputId": "5985747a-288d-485a-9f0f-aa9ebb59465c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      absent       0.92      0.62      0.74        53\n",
      "     present       0.85      0.97      0.91       117\n",
      "\n",
      "    accuracy                           0.86       170\n",
      "   macro avg       0.88      0.80      0.82       170\n",
      "weighted avg       0.87      0.86      0.86       170\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We are going to use sklearn to evalute the results on test dataset\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print (classification_report( preds_df['label'], preds_df['result']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "atNaIlnP3gKr"
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "assertion_model.stages[-1].write().overwrite().save('assertion_custom_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "documentAssembler = nlp.DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "# Sentence Detector annotator, processes various sentences per line\n",
    "sentenceDetector = nlp.SentenceDetector()\\\n",
    "    .setInputCols([\"document\"])\\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "# Tokenizer splits words in a relevant format for NLP\n",
    "tokenizer = nlp.Tokenizer()\\\n",
    "    .setInputCols([\"sentence\"])\\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "# Clinical word embeddings trained on PubMED dataset\n",
    "word_embeddings = nlp.WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n",
    "    .setInputCols([\"sentence\", \"token\"])\\\n",
    "    .setOutputCol(\"embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "documentAssembler = nlp.DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "# Sentence Detector annotator, processes various sentences per line\n",
    "sentenceDetector = nlp.SentenceDetector()\\\n",
    "    .setInputCols([\"document\"])\\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "# Tokenizer splits words in a relevant format for NLP\n",
    "tokenizer = nlp.Tokenizer()\\\n",
    "    .setInputCols([\"sentence\"])\\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "# Clinical word embeddings trained on PubMED dataset\n",
    "word_embeddings = nlp.WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n",
    "    .setInputCols([\"sentence\", \"token\"])\\\n",
    "    .setOutputCol(\"embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient has a headache for the last 2 weeks, needs to get a head CT, and appears anxious when she walks fast. No alopecia noted. She denies pain\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunks</th>\n",
       "      <th>entities</th>\n",
       "      <th>assertion</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>headache</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>SomeoneElse</td>\n",
       "      <td>0.8405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anxious</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Possible</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alopecia</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Absent</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pain</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>Absent</td>\n",
       "      <td>0.9999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     chunks entities    assertion confidence\n",
       "0  headache  Symptom  SomeoneElse     0.8405\n",
       "1   anxious  Symptom     Possible        1.0\n",
       "2  alopecia  Symptom       Absent        1.0\n",
       "3      pain  Symptom       Absent     0.9999"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Patient has a headache for the last 2 weeks, needs to get a head CT, and appears anxious when she walks fast. No alopecia noted. She denies pain'\n",
    "\n",
    "light_model = nlp.LightPipeline(model)\n",
    "\n",
    "light_result = light_model.fullAnnotate(text)[0]\n",
    "\n",
    "print(text)\n",
    "\n",
    "chunks=[]\n",
    "entities=[]\n",
    "status=[]\n",
    "confidence=[]\n",
    "\n",
    "for n,m in zip(light_result['ner_chunk'],light_result['assertion']):\n",
    "    \n",
    "    chunks.append(n.result)\n",
    "    entities.append(n.metadata['entity']) \n",
    "    status.append(m.result)\n",
    "    confidence.append(m.metadata['confidence'])\n",
    "        \n",
    "df = pd.DataFrame({'chunks':chunks, 'entities':entities, 'assertion':status, 'confidence':confidence})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "eaef4d22edbbdbc68b8d50d2a1a48c6349c8418c1052069fe906c41d47bd13e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
