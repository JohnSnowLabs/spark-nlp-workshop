{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "EwFzpuFhVnFR",
                "pycharm": {
                    "name": "#%% md\n"
                }
            },
            "source": [
                "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "HxStFMMVVnFU",
                "pycharm": {
                    "name": "#%% md\n"
                }
            },
            "source": [
                "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-ocr-workshop/blob/master/tutorials/Certification_Trainings/6.1.SparkOcrStreamingPDF.ipynb)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "2vh3AEyqVnFU",
                "pycharm": {
                    "name": "#%% md\n"
                }
            },
            "source": [
                "## Spark OCR Streaming"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "mCQ2Pl-UVnFU",
                "pycharm": {
                    "name": "#%% md\n"
                }
            },
            "source": [
                "## Blogposts and videos\n",
                "\n",
                "- [Text Detection in Spark OCR](https://medium.com/spark-nlp/text-detection-in-spark-ocr-dcd8002bdc97)\n",
                "\n",
                "- [Table Detection & Extraction in Spark OCR](https://medium.com/spark-nlp/table-detection-extraction-in-spark-ocr-50765c6cedc9)\n",
                "\n",
                "- [Extract Tabular Data from PDF in Spark OCR](https://medium.com/spark-nlp/extract-tabular-data-from-pdf-in-spark-ocr-b02136bc0fcb)\n",
                "\n",
                "- [Signature Detection in Spark OCR](https://medium.com/spark-nlp/signature-detection-in-spark-ocr-32f9e6f91e3c)\n",
                "\n",
                "- [GPU image pre-processing in Spark OCR](https://medium.com/spark-nlp/gpu-image-pre-processing-in-spark-ocr-3-1-0-6fc27560a9bb)\n",
                "\n",
                "- [How to Setup Spark OCR on UBUNTU - Video](https://www.youtube.com/watch?v=cmt4WIcL0nI)\n",
                "\n",
                "\n",
                "**More examples here**\n",
                "\n",
                "https://github.com/JohnSnowLabs/spark-ocr-workshop"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": false,
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": [
                "## Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {
                "id": "M-ftVAZdVnFV",
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": [
                "import os\n",
                "from pyspark.ml import PipelineModel\n",
                "import sparkocr\n",
                "from pyspark.sql.functions import *\n",
                "from sparkocr.transformers import *\n",
                "\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
                "\n",
                "spark = start_spark()\n",
                "print(\"Spark OCR Version :\", sparkocr.version())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": false,
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": [
                "!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-ocr-workshop/master/jupyter/data/pdfs/noised.pdf"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {
                "id": "4VmVAhtZVnFa",
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": [
                "# fill path to folder with PDF's here\n",
                "dataset_path = \"*.pdf\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {
                "id": "fFp-fzw6VnFa",
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": [
                "# read one file for infer schema\n",
                "pdfs_df = spark.read.format(\"binaryFile\").load(dataset_path).limit(1)\n",
                "pdfs_df.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "BHHhEzKKVnFb",
                "pycharm": {
                    "name": "#%% md\n"
                }
            },
            "source": [
                "## Define OCR pipeline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {
                "id": "lpUD5kghVnFb",
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": [
                "# Transform binary to image\n",
                "pdf_to_image = PdfToImage()\n",
                "pdf_to_image.setOutputCol(\"image\")\n",
                "\n",
                "# Run OCR for each region\n",
                "ocr = ImageToText()\n",
                "ocr.setInputCol(\"image\")\n",
                "ocr.setOutputCol(\"text\")\n",
                "ocr.setConfidenceThreshold(60)\n",
                "\n",
                "# OCR pipeline\n",
                "pipeline = PipelineModel(stages=[\n",
                "    pdf_to_image,\n",
                "    ocr\n",
                "])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "poeHsXI3VnFb",
                "pycharm": {
                    "name": "#%% md\n"
                }
            },
            "source": [
                "## Define streaming pipeline and start it\n",
                "Note: each start erase previous results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {
                "id": "jMohfzzXVnFb",
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": [
                "# count of files in one microbatch\n",
                "maxFilesPerTrigger = 4 \n",
                "\n",
                "# read files as stream\n",
                "pdf_stream_df = spark.readStream \\\n",
                ".format(\"binaryFile\") \\\n",
                ".schema(pdfs_df.schema) \\\n",
                ".option(\"maxFilesPerTrigger\", maxFilesPerTrigger) \\\n",
                ".load(dataset_path)\n",
                "\n",
                "# process files using OCR pipeline\n",
                "result = pipeline.transform(pdf_stream_df).withColumn(\"timestamp\", current_timestamp())\n",
                "\n",
                "# store results to memory table\n",
                "query = result.writeStream \\\n",
                " .format('memory') \\\n",
                " .queryName('result') \\\n",
                " .start()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {
                "id": "eUaWbXgNVnFc",
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": [
                "# get progress of streamig job\n",
                "query.lastProgress"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "Ls3CjwnCVnFc",
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": [
                "# need to run for stop steraming job\n",
                "query.stop()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "hqH2GjqOVnFc",
                "pycharm": {
                    "name": "#%% md\n"
                }
            },
            "source": [
                "## Show results from 'result' table"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "8Nlsn48tVnFc",
                "outputId": "78ad67e3-106c-4a6a-99aa-efd2f280ed9a",
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "3"
                        ]
                    },
                    "execution_count": 27,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# count of processed records (number of processed pages in results)\n",
                "spark.table(\"result\").count() "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "q04UZA8kVnFd",
                "outputId": "1feb4855-cef4-4139-86ed-09db5230f91c",
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "+--------------------+-------+--------------------+--------------------+\n",
                        "|           timestamp|pagenum|                path|                text|\n",
                        "+--------------------+-------+--------------------+--------------------+\n",
                        "|2022-07-20 21:45:...|      0|file:/content/dat...|FOREWORD\\n\\nElect...|\n",
                        "|2022-07-20 21:45:...|      0|file:/content/dat...|C nca Document fo...|\n",
                        "|2022-07-20 21:56:...|      0|file:/content/dat...|6/13/22, 11:47 AM...|\n",
                        "+--------------------+-------+--------------------+--------------------+\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "# show results\n",
                "spark.table(\"result\").select(\"timestamp\",\"pagenum\", \"path\", \"text\").show(10)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "oyPk7dD3VnFd",
                "pycharm": {
                    "name": "#%% md\n"
                }
            },
            "source": [
                "## Run streaming job for storing results to disk"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {
                "id": "z36PWzv-VnFd",
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": [
                "query = result.select(\"text\").writeStream \\\n",
                " .format('text') \\\n",
                " .option(\"path\", \"results/\") \\\n",
                " .option(\"checkpointLocation\", \"checkpointDir\") \\\n",
                " .start()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {
                "id": "6IxwNFfHVnFd",
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": [
                "# get progress of streamig job\n",
                "query.lastProgress"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "eWQ6rveKVnFe",
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": [
                "# need to run for stop steraming job\n",
                "query.stop()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "NGJa_r51VnFe",
                "pycharm": {
                    "name": "#%% md\n"
                }
            },
            "source": [
                "## Read results from disk"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "IUzerwK9VnFe",
                "outputId": "0723673e-3f41-490c-e5f1-24bdf3b0c20b",
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "+---------------------------------------------------------------------------------------------+\n",
                        "|value                                                                                        |\n",
                        "+---------------------------------------------------------------------------------------------+\n",
                        "|                                                                                             |\n",
                        "|                                                                                             |\n",
                        "|                                                                                             |\n",
                        "|                                                                                             |\n",
                        "|                                                                                             |\n",
                        "|                                                                                             |\n",
                        "|                                                                                             |\n",
                        "|                                                                                             |\n",
                        "|                                                                                             |\n",
                        "|He does report to me that he just had a recent evaluation by Dr, nd he has had allergy       |\n",
                        "|fluticasone. He ordered Prilosec. There is one medication that he is not taking because he is|\n",
                        "|worked as a school administrator. 3) Married and no children. 4) Li elong nonsmoker,         |\n",
                        "|                                                                                             |\n",
                        "|                                                                                             |\n",
                        "|                                                                                             |\n",
                        "|industries. They create ideas and use them in their designs, they stimu-                     |\n",
                        "|To encourage this exchange of ideas, ELECTRONIC DESIGN                                       |\n",
                        "|                                                                                             |\n",
                        "|New York EDWARD E. GRAZDA                                                                    |\n",
                        "|Payment Date Tuesday, June 14, 2022                                                          |\n",
                        "+---------------------------------------------------------------------------------------------+\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "results = spark.read.format(\"text\").load(\"results/*.txt\")\n",
                "results.sample(.1).show(truncate=False)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "3BEWgzNPVnFe",
                "pycharm": {
                    "name": "#%% md\n"
                }
            },
            "source": [
                "## Clean results and checkpoint folders"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "-a5ZHZLcVnFe",
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": [
                "%%bash\n",
                "rm -r -f results\n",
                "rm -r -f checkpointDir"
            ]
        }
    ],
    "metadata": {
        "colab": {
            "collapsed_sections": [],
            "name": "6.1.SparkOcrStreamingPDF.ipynb",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.7.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
