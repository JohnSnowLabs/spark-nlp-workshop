{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwFzpuFhVnFR",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HxStFMMVVnFU",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-ocr-workshop/blob/master/tutorials/Certification_Trainings/6.1.SparkOcrStreamingPDF.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2vh3AEyqVnFU",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Spark OCR Streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mCQ2Pl-UVnFU",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Blogposts and videos\n",
    "\n",
    "- [Text Detection in Spark OCR](https://medium.com/spark-nlp/text-detection-in-spark-ocr-dcd8002bdc97)\n",
    "\n",
    "- [Table Detection & Extraction in Spark OCR](https://medium.com/spark-nlp/table-detection-extraction-in-spark-ocr-50765c6cedc9)\n",
    "\n",
    "- [Extract Tabular Data from PDF in Spark OCR](https://medium.com/spark-nlp/extract-tabular-data-from-pdf-in-spark-ocr-b02136bc0fcb)\n",
    "\n",
    "- [Signature Detection in Spark OCR](https://medium.com/spark-nlp/signature-detection-in-spark-ocr-32f9e6f91e3c)\n",
    "\n",
    "- [GPU image pre-processing in Spark OCR](https://medium.com/spark-nlp/gpu-image-pre-processing-in-spark-ocr-3-1-0-6fc27560a9bb)\n",
    "\n",
    "- [How to Setup Spark OCR on UBUNTU - Video](https://www.youtube.com/watch?v=cmt4WIcL0nI)\n",
    "\n",
    "\n",
    "**More examples here**\n",
    "\n",
    "https://github.com/JohnSnowLabs/spark-ocr-workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oZidgaH6gWX5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M-ftVAZdVnFV",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.ml import PipelineModel\n",
    "import sparkocr\n",
    "from pyspark.sql.functions import *\n",
    "from sparkocr.transformers import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "spark = start_spark()\n",
    "print(\"Spark OCR Version :\", sparkocr.version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "56cp6hDLgWX6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-ocr-workshop/master/jupyter/data/pdfs/noised.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4VmVAhtZVnFa",
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fill path to folder with PDF's here\n",
    "dataset_path = \"*.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fFp-fzw6VnFa",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# read one file for infer schema\n",
    "pdfs_df = spark.read.format(\"binaryFile\").load(dataset_path).limit(1)\n",
    "pdfs_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BHHhEzKKVnFb",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Define OCR pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lpUD5kghVnFb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Transform binary to image\n",
    "pdf_to_image = PdfToImage()\n",
    "pdf_to_image.setOutputCol(\"image\")\n",
    "\n",
    "# Run OCR for each region\n",
    "ocr = ImageToText()\n",
    "ocr.setInputCol(\"image\")\n",
    "ocr.setOutputCol(\"text\")\n",
    "ocr.setConfidenceThreshold(60)\n",
    "\n",
    "# OCR pipeline\n",
    "pipeline = PipelineModel(stages=[\n",
    "    pdf_to_image,\n",
    "    ocr\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "poeHsXI3VnFb",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Define streaming pipeline and start it\n",
    "Note: each start erase previous results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jMohfzzXVnFb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# count of files in one microbatch\n",
    "maxFilesPerTrigger = 4\n",
    "\n",
    "# read files as stream\n",
    "pdf_stream_df = spark.readStream \\\n",
    ".format(\"binaryFile\") \\\n",
    ".schema(pdfs_df.schema) \\\n",
    ".option(\"maxFilesPerTrigger\", maxFilesPerTrigger) \\\n",
    ".load(dataset_path)\n",
    "\n",
    "# process files using OCR pipeline\n",
    "result = pipeline.transform(pdf_stream_df).withColumn(\"timestamp\", current_timestamp())\n",
    "\n",
    "# store results to memory table\n",
    "query = result.writeStream \\\n",
    " .format('memory') \\\n",
    " .queryName('result') \\\n",
    " .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eUaWbXgNVnFc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get progress of streamig job\n",
    "query.lastProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ls3CjwnCVnFc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# need to run for stop steraming job\n",
    "query.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hqH2GjqOVnFc",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Show results from 'result' table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Nlsn48tVnFc",
    "outputId": "78ad67e3-106c-4a6a-99aa-efd2f280ed9a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count of processed records (number of processed pages in results)\n",
    "spark.table(\"result\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q04UZA8kVnFd",
    "outputId": "1feb4855-cef4-4139-86ed-09db5230f91c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+--------------------+--------------------+\n",
      "|           timestamp|pagenum|                path|                text|\n",
      "+--------------------+-------+--------------------+--------------------+\n",
      "|2022-07-20 21:45:...|      0|file:/content/dat...|FOREWORD\\n\\nElect...|\n",
      "|2022-07-20 21:45:...|      0|file:/content/dat...|C nca Document fo...|\n",
      "|2022-07-20 21:56:...|      0|file:/content/dat...|6/13/22, 11:47 AM...|\n",
      "+--------------------+-------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show results\n",
    "spark.table(\"result\").select(\"timestamp\",\"pagenum\", \"path\", \"text\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oyPk7dD3VnFd",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Run streaming job for storing results to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z36PWzv-VnFd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "query = result.select(\"text\").writeStream \\\n",
    " .format('text') \\\n",
    " .option(\"path\", \"results/\") \\\n",
    " .option(\"checkpointLocation\", \"checkpointDir\") \\\n",
    " .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6IxwNFfHVnFd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get progress of streamig job\n",
    "query.lastProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eWQ6rveKVnFe",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# need to run for stop steraming job\n",
    "query.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NGJa_r51VnFe",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Read results from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IUzerwK9VnFe",
    "outputId": "0723673e-3f41-490c-e5f1-24bdf3b0c20b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------+\n",
      "|value                                                                                        |\n",
      "+---------------------------------------------------------------------------------------------+\n",
      "|                                                                                             |\n",
      "|                                                                                             |\n",
      "|                                                                                             |\n",
      "|                                                                                             |\n",
      "|                                                                                             |\n",
      "|                                                                                             |\n",
      "|                                                                                             |\n",
      "|                                                                                             |\n",
      "|                                                                                             |\n",
      "|He does report to me that he just had a recent evaluation by Dr, nd he has had allergy       |\n",
      "|fluticasone. He ordered Prilosec. There is one medication that he is not taking because he is|\n",
      "|worked as a school administrator. 3) Married and no children. 4) Li elong nonsmoker,         |\n",
      "|                                                                                             |\n",
      "|                                                                                             |\n",
      "|                                                                                             |\n",
      "|industries. They create ideas and use them in their designs, they stimu-                     |\n",
      "|To encourage this exchange of ideas, ELECTRONIC DESIGN                                       |\n",
      "|                                                                                             |\n",
      "|New York EDWARD E. GRAZDA                                                                    |\n",
      "|Payment Date Tuesday, June 14, 2022                                                          |\n",
      "+---------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = spark.read.format(\"text\").load(\"results/*.txt\")\n",
    "results.sample(.1).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3BEWgzNPVnFe",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Clean results and checkpoint folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-a5ZHZLcVnFe",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -r -f results\n",
    "rm -r -f checkpointDir"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "6.1.SparkOcrStreamingPDF.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
