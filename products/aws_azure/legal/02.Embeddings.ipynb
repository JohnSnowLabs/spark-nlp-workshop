{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "KyBA2DOGetGo",
   "metadata": {
    "id": "KyBA2DOGetGo"
   },
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e18220",
   "metadata": {
    "id": "18e18220"
   },
   "source": [
    "# Legal Word and Sentence Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a14890-bc41-4765-9557-89a969c04d8f",
   "metadata": {
    "id": "69a14890-bc41-4765-9557-89a969c04d8f"
   },
   "source": [
    "# Legal Word and Sentence Embeddings visualization using PCA (Principal Component Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f982ae9-0570-4f90-bd30-c9d55d219e5b",
   "metadata": {
    "id": "5f982ae9-0570-4f90-bd30-c9d55d219e5b"
   },
   "source": [
    "Modern NLP models work with a numerical representation of texts and their menaning. For token classification problems (inferring a class for a token, for example Name Entity Recognition) Word Embeddings are required. For sentences, paragraph, document classification - we use Sentence Embeddings.\n",
    "\n",
    "In this notebook, we use Spark NLP Legal Word (**roberta_embeddings_legal_roberta_base**) and Sentence (**sent_bert_base_uncased_legal**) Embeddings to get those numerical representations of the semantics of the texts. The result is a 768 embeddings matrix, impossible to process by the human eye.\n",
    "\n",
    "There are many techniques we can use to visualize those embeddings. We are using one of them - Principal Component Analysis, a dimensionality reduction process, carried out by Spark MLLib. Both embeddings have 768 dimensions, so we will reduced this dimensions from **768** to **3** (X, Y, Z) and will use a color for the word / sentence legend."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f475cb0-c6e7-45a7-8305-7739eb4bd539",
   "metadata": {
    "id": "okhT7AcXxben"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147eb4db-b38d-4bfa-b3d6-ee9898627db1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 115199,
     "status": "ok",
     "timestamp": 1664816113389,
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     },
     "user_tz": -120
    },
    "id": "dmcB5zVBHZO8",
    "outputId": "cd366e47-7f4d-457a-dfe5-3ed5174d4a0c"
   },
   "outputs": [],
   "source": [
    "from johnsnowlabs import *\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "spark = start_spark()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7c011d-eac8-4eda-b272-027bab6a8895",
   "metadata": {
    "id": "4b7c011d-eac8-4eda-b272-027bab6a8895"
   },
   "source": [
    "# Get sample text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_flo8uccfKfh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3390,
     "status": "ok",
     "timestamp": 1664822300095,
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     },
     "user_tz": -120
    },
    "id": "_flo8uccfKfh",
    "outputId": "1f8636e9-82ba-4182-b2cd-de6bb3ceddca"
   },
   "outputs": [],
   "source": [
    "# Downloading sample datasets.\n",
    "\n",
    "! wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/legal-nlp/data/legal_pca_samples.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b29ed0e-a708-441f-91b4-ab2905304581",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 201
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1664822300095,
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     },
     "user_tz": -120
    },
    "id": "1b29ed0e-a708-441f-91b4-ab2905304581",
    "outputId": "ba747463-8c77-43f4-da2d-b980278203da",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('legal_pca_samples.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3977898f-24e8-43d6-a338-80f3bf8ad2a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5187,
     "status": "ok",
     "timestamp": 1664822305276,
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     },
     "user_tz": -120
    },
    "id": "3977898f-24e8-43d6-a338-80f3bf8ad2a1",
    "outputId": "69bd870d-54c4-4f73-afca-55855e955bc7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create spark dataframe\n",
    "sdf = spark.createDataFrame(df)\n",
    "sdf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d751fd45-9810-4b43-b893-0d373e8d4870",
   "metadata": {
    "id": "d751fd45-9810-4b43-b893-0d373e8d4870"
   },
   "source": [
    "# Sentence Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b990cfd8-576f-4057-a548-0434d39897bd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41980,
     "status": "ok",
     "timestamp": 1664822347251,
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     },
     "user_tz": -120
    },
    "id": "b990cfd8-576f-4057-a548-0434d39897bd",
    "outputId": "a0df1c9a-f151-49bb-a3dc-377566d15705",
    "tags": []
   },
   "outputs": [],
   "source": [
    "document_assembler = nlp.DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "embeddings = nlp.BertSentenceEmbeddings.pretrained(\"sent_bert_base_uncased_legal\", \"en\") \\\n",
    "    .setInputCols(\"document\") \\\n",
    "    .setOutputCol(\"document_embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde3b08f-6187-43fd-8d7b-3fe6da054c18",
   "metadata": {
    "id": "fde3b08f-6187-43fd-8d7b-3fe6da054c18"
   },
   "source": [
    "# Custom transform to retrieve the numerical embeddings from Spark NLP and pass it to Spark MLLib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bd3f4b-2eeb-416c-b34d-fba81d073de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "import pyspark.sql as SQL\n",
    "from pyspark import keyword_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cfff3f-487b-4808-8b32-f54fc443777b",
   "metadata": {
    "id": "30cfff3f-487b-4808-8b32-f54fc443777b"
   },
   "outputs": [],
   "source": [
    "# This class extracts the embeddings from the Spark NLP Annotation object\n",
    "# from pyspark import ml as ML\n",
    "\n",
    "class EmbeddingsUDF(\n",
    "    nlp.Transformer, nlp.ML.param.shared.HasInputCol,  nlp.ML.param.shared.HasOutputCol,\n",
    "    nlp.ML.util.DefaultParamsReadable, nlp.ML.util.DefaultParamsWritable\n",
    "):\n",
    "    @keyword_only\n",
    "    def __init__(self):\n",
    "        super(EmbeddingsUDF, self).__init__()\n",
    "\n",
    "        def _sum(r):\n",
    "            result = 0.0\n",
    "            for e in r:\n",
    "                result += e\n",
    "            return result\n",
    "\n",
    "        self.udfs = {\n",
    "            'convertToVectorUDF': F.udf(lambda vs: nlp.ML.linalg.Vectors.dense(vs), nlp.ML.linalg.VectorUDT()),\n",
    "            'sumUDF': F.udf(lambda r: _sum(r), T.FloatType())\n",
    "        }\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "\n",
    "        results = dataset.select(\n",
    "            \"*\", F.explode(\"document_embeddings.embeddings\").alias(\"embeddings\")\n",
    "        )\n",
    "        results = results.withColumn(\n",
    "            \"features\",\n",
    "            self.udfs['convertToVectorUDF'](F.col(\"embeddings\"))\n",
    "        )\n",
    "        results = results.withColumn(\n",
    "            \"emb_sum\",\n",
    "            self.udfs['sumUDF'](F.col(\"embeddings\"))\n",
    "        )\n",
    "        # Remove those with embeddings all zeroes (so we can calculate cosine distance)\n",
    "        results = results.where(F.col(\"emb_sum\")!=0.0)\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f82e139-1cc3-423d-9d53-c0ccfec835c2",
   "metadata": {
    "id": "5f82e139-1cc3-423d-9d53-c0ccfec835c2"
   },
   "outputs": [],
   "source": [
    "embeddings_for_pca = EmbeddingsUDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5213dfcf-61bc-4db2-a8c7-797a318a13f4",
   "metadata": {
    "id": "5213dfcf-61bc-4db2-a8c7-797a318a13f4"
   },
   "outputs": [],
   "source": [
    "DIMENSIONS  = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285ba04a-dbe2-4f53-9aa0-fc66ba783e14",
   "metadata": {
    "id": "285ba04a-dbe2-4f53-9aa0-fc66ba783e14"
   },
   "outputs": [],
   "source": [
    "pca = nlp.ML.feature.PCA(k=DIMENSIONS, inputCol=\"features\", outputCol=\"pca_features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f95669-0f8e-491b-b6d8-33f590aa06cf",
   "metadata": {
    "id": "82f95669-0f8e-491b-b6d8-33f590aa06cf"
   },
   "source": [
    "### Full Spark NLP + Spark MLLib pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c279de78-563f-474c-8d3e-3c72243bb04b",
   "metadata": {
    "id": "c279de78-563f-474c-8d3e-3c72243bb04b"
   },
   "outputs": [],
   "source": [
    "# We did all process in one pipeline\n",
    "\n",
    "pipeline = nlp.Pipeline().setStages([document_assembler, embeddings, embeddings_for_pca, pca])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c3691b-ba62-446c-ac2d-7f7e869781ef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1664822347253,
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     },
     "user_tz": -120
    },
    "id": "13c3691b-ba62-446c-ac2d-7f7e869781ef",
    "outputId": "baeaeb6d-d20d-48f9-c0db-d41fd9de1ee3"
   },
   "outputs": [],
   "source": [
    "pipeline.getStages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d46c615-d2b6-408a-99c3-bac0f824dcf4",
   "metadata": {
    "id": "0d46c615-d2b6-408a-99c3-bac0f824dcf4"
   },
   "outputs": [],
   "source": [
    "model = pipeline.fit(sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d52ebe0-4257-4354-817f-5b8f2a363b8e",
   "metadata": {
    "id": "4d52ebe0-4257-4354-817f-5b8f2a363b8e"
   },
   "outputs": [],
   "source": [
    "result = model.transform(sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b852cad-e1e7-48bc-94b0-9da7188a9727",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3462,
     "status": "ok",
     "timestamp": 1664822368654,
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     },
     "user_tz": -120
    },
    "id": "7b852cad-e1e7-48bc-94b0-9da7188a9727",
    "outputId": "ec110894-886d-460c-c78b-86a591b453e3"
   },
   "outputs": [],
   "source": [
    "result.select('pca_features', 'label').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbf7811-b04c-4f63-88e4-10e51341ce0f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 352
    },
    "executionInfo": {
     "elapsed": 2392,
     "status": "ok",
     "timestamp": 1664822371038,
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     },
     "user_tz": -120
    },
    "id": "adbf7811-b04c-4f63-88e4-10e51341ce0f",
    "outputId": "1eb51133-bf64-4048-b190-587883a62f34"
   },
   "outputs": [],
   "source": [
    "df = result.select('pca_features', 'label').toPandas()\n",
    "\n",
    "df\n",
    "# As you see, dimension values are inside a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3707de-8ff4-49b7-89c2-85e9616bc337",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 352
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1664822371039,
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     },
     "user_tz": -120
    },
    "id": "5c3707de-8ff4-49b7-89c2-85e9616bc337",
    "outputId": "f33f9dff-c510-4e2d-a1a6-96dcc5b522e5"
   },
   "outputs": [],
   "source": [
    "# We extract the dimension values out off the list\n",
    "\n",
    "df[\"x\"] = df[\"pca_features\"].apply(lambda x: x[0])\n",
    "\n",
    "df[\"y\"] = df[\"pca_features\"].apply(lambda x: x[1])\n",
    "\n",
    "df[\"z\"] = df[\"pca_features\"].apply(lambda x: x[2])\n",
    "\n",
    "df = df[[\"x\", \"y\", \"z\", \"label\"]]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7281d091-9356-41a7-83e7-6b5ee541a09c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 616
    },
    "executionInfo": {
     "elapsed": 2200,
     "status": "ok",
     "timestamp": 1664822373231,
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     },
     "user_tz": -120
    },
    "id": "7281d091-9356-41a7-83e7-6b5ee541a09c",
    "outputId": "f39bb5e0-4e05-4037-fcc6-960fabe7fab4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(df, x='x', y='y', z='z', color='label', width=800, height=600)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602bc911-284b-4e0e-8882-99ac444fbb51",
   "metadata": {
    "id": "602bc911-284b-4e0e-8882-99ac444fbb51"
   },
   "source": [
    "# Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bfbc63-cb97-4189-8d6c-6629bbc898e8",
   "metadata": {
    "id": "11bfbc63-cb97-4189-8d6c-6629bbc898e8"
   },
   "source": [
    "We can also visualize the semantics of words, instead of full texts, by using Word Embeddings. We will add a Tokenizer and a WordEmbeddings model to get those embeddings, and them apply PCA as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cebc272-4b73-4a66-89ed-64278a46bab8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31114,
     "status": "ok",
     "timestamp": 1664822404340,
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     },
     "user_tz": -120
    },
    "id": "0cebc272-4b73-4a66-89ed-64278a46bab8",
    "outputId": "64f42504-0483-4271-823b-2189eff7ea7f"
   },
   "outputs": [],
   "source": [
    "document_assembler = nlp.DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "tokenizer = nlp.Tokenizer() \\\n",
    "    .setInputCols(\"document\")\\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "embeddings = nlp.RoBertaEmbeddings.pretrained(\"roberta_embeddings_legal_roberta_base\",\"en\") \\\n",
    "    .setInputCols([\"document\", \"token\"])\\\n",
    "    .setOutputCol(\"document_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2a3d86-cac7-40b7-a769-69d3b0a1dea1",
   "metadata": {
    "id": "5b2a3d86-cac7-40b7-a769-69d3b0a1dea1"
   },
   "outputs": [],
   "source": [
    "# Firstly we splitted the pipeline in two to get all token embeddings\n",
    "\n",
    "pipeline = nlp.Pipeline().setStages([document_assembler, tokenizer, embeddings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f0cced-e804-4415-aa57-6ae05587adf2",
   "metadata": {
    "id": "28f0cced-e804-4415-aa57-6ae05587adf2"
   },
   "outputs": [],
   "source": [
    "model = pipeline.fit(sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31090faa-0bbe-4e94-8384-e38a338e1989",
   "metadata": {
    "id": "31090faa-0bbe-4e94-8384-e38a338e1989"
   },
   "outputs": [],
   "source": [
    "result = model.transform(sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1815b79d-81c5-45ec-ac80-418e31f9df8e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4632,
     "status": "ok",
     "timestamp": 1664822409425,
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     },
     "user_tz": -120
    },
    "id": "1815b79d-81c5-45ec-ac80-418e31f9df8e",
    "outputId": "d480cc43-97ff-42c4-bd30-402e35e2cb3a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_df = result.select(\"label\", F.explode(F.arrays_zip(\"token.result\", \"document_embeddings.embeddings\")).alias(\"cols\"))\\\n",
    "                   .select(F.expr(\"cols['0']\").alias(\"token\"),\n",
    "                           F.expr(\"cols['1']\").alias(\"embeddings\"),\n",
    "                           \"label\")\n",
    "\n",
    "result_df.show(truncate = 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6186b5d6-fa75-42db-b5f6-febbe0f6c957",
   "metadata": {
    "id": "6186b5d6-fa75-42db-b5f6-febbe0f6c957"
   },
   "outputs": [],
   "source": [
    "# Here we defined inheritance class from that defined previously EmbeddingsUDF class\n",
    "class WordEmbeddingsUDF(EmbeddingsUDF):    \n",
    "    def _transform(self, dataset):\n",
    "        \n",
    "        results = dataset.select('token', 'label', 'embeddings') # We changed this line because our embedding cloumn is already exploded\n",
    "\n",
    "        results = results.withColumn(\n",
    "            \"features\",\n",
    "            self.udfs['convertToVectorUDF'](F.col(\"embeddings\"))\n",
    "        )\n",
    "        results = results.withColumn(\n",
    "            \"emb_sum\",\n",
    "            self.udfs['sumUDF'](F.col(\"embeddings\"))\n",
    "        )\n",
    "        # Remove those with embeddings all zeroes (so we can calculate cosine distance)\n",
    "        results = results.where(F.col(\"emb_sum\")!=0.0)\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e416012e-ba80-4ca8-98de-aa675660ecb1",
   "metadata": {
    "id": "e416012e-ba80-4ca8-98de-aa675660ecb1"
   },
   "outputs": [],
   "source": [
    "embeddings_for_pca = WordEmbeddingsUDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cca3d1f-0261-42de-96f8-f68f7fe6210a",
   "metadata": {
    "id": "0cca3d1f-0261-42de-96f8-f68f7fe6210a"
   },
   "outputs": [],
   "source": [
    "DIMENSIONS  = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9e30a2-cc23-463f-87d1-4846c7a321e7",
   "metadata": {
    "id": "2f9e30a2-cc23-463f-87d1-4846c7a321e7"
   },
   "outputs": [],
   "source": [
    "pca = nlp.ML.feature.PCA(k=DIMENSIONS, inputCol=\"features\", outputCol=\"pca_features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec00af2-8e16-4473-8b43-4f7cff630a3d",
   "metadata": {
    "id": "4ec00af2-8e16-4473-8b43-4f7cff630a3d"
   },
   "source": [
    "## Full Spark NLP + Spark MLLib pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b8590b-2bf4-45b9-924d-d7438b87f08a",
   "metadata": {
    "id": "69b8590b-2bf4-45b9-924d-d7438b87f08a"
   },
   "outputs": [],
   "source": [
    "# We run the second part of the pipeline\n",
    "\n",
    "pipeline = nlp.Pipeline().setStages([embeddings_for_pca, pca])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8207c543-9fb0-4187-a359-61abad891934",
   "metadata": {
    "id": "8207c543-9fb0-4187-a359-61abad891934",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = pipeline.fit(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf674445-20d2-4ee9-8409-6a3782794aae",
   "metadata": {
    "id": "cf674445-20d2-4ee9-8409-6a3782794aae"
   },
   "outputs": [],
   "source": [
    "result = model.transform(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9093ca0e-e46e-40e8-8958-c47702fc4a43",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1665,
     "status": "ok",
     "timestamp": 1664822424121,
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     },
     "user_tz": -120
    },
    "id": "9093ca0e-e46e-40e8-8958-c47702fc4a43",
    "outputId": "bed73fad-ef28-4ebe-f984-78271abcb4f4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "result.select(\"token\", \"embeddings\", \"pca_features\", \"label\").show(truncate = 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2299c9bc-8e8e-4c49-ad29-133df31da543",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "executionInfo": {
     "elapsed": 3651,
     "status": "ok",
     "timestamp": 1664822427770,
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     },
     "user_tz": -120
    },
    "id": "2299c9bc-8e8e-4c49-ad29-133df31da543",
    "outputId": "7d261405-b536-41e9-9df3-55ffe9560ebe"
   },
   "outputs": [],
   "source": [
    "df = result.select('token', 'pca_features',  'label').toPandas()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20443a2f-9e6e-4cd2-885e-b42720bcb840",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1664822427771,
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     },
     "user_tz": -120
    },
    "id": "20443a2f-9e6e-4cd2-885e-b42720bcb840",
    "outputId": "82731ad4-cb84-46a5-a245-c6a0b48b97fa"
   },
   "outputs": [],
   "source": [
    "df[\"x\"] = df[\"pca_features\"].apply(lambda x: x[0])\n",
    "\n",
    "df[\"y\"] = df[\"pca_features\"].apply(lambda x: x[1])\n",
    "\n",
    "df[\"z\"] = df[\"pca_features\"].apply(lambda x: x[2])\n",
    "\n",
    "df = df[[\"token\", \"x\", \"y\", \"z\", \"label\"]]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96d9799-e838-4cdc-903e-dbd5cdc37aa9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1664822427771,
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     },
     "user_tz": -120
    },
    "id": "e96d9799-e838-4cdc-903e-dbd5cdc37aa9",
    "outputId": "924ce9a6-da3c-4217-9efd-0a4742b53a95",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter_3d(df, x = 'x', y = 'y', z = 'z', color = \"label\", width=1000, height = 800, hover_data = [\"token\", \"label\"])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i8Vd4v12AYZs",
   "metadata": {
    "id": "i8Vd4v12AYZs"
   },
   "source": [
    "That chart is super cool because you can see how the same token gets different embeddings depending on the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853e94b4-a0ca-4369-8670-16e3cc94f23f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "eaef4d22edbbdbc68b8d50d2a1a48c6349c8418c1052069fe906c41d47bd13e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}