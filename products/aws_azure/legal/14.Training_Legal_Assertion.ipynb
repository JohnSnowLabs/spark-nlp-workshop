{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "wxZDXLDCXkk_",
   "metadata": {
    "id": "wxZDXLDCXkk_"
   },
   "source": [
    "\n",
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KLqW6FOnEvov",
   "metadata": {
    "id": "KLqW6FOnEvov"
   },
   "source": [
    "# Training Legal Assertion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11e1a1b-fa10-422b-baeb-31698cd3ee52",
   "metadata": {
    "id": "okhT7AcXxben"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d6fedd2-8462-4d08-b3f8-f85092ffef6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q tensorflow==2.7.0\n",
    "%pip install -q tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4baa3e8-80c1-4639-9abc-f598a760e198",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 115199,
     "status": "ok",
     "timestamp": 1664816113389,
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     },
     "user_tz": -120
    },
    "id": "dmcB5zVBHZO8",
    "outputId": "cd366e47-7f4d-457a-dfe5-3ed5174d4a0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP Version : 4.2.1\n",
      "ðŸ“‹ Loading license number 0 from /home/ubuntu/.johnsnowlabs/licenses/license_number_0_for_.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/10/20 18:32:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/10/20 18:32:27 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/10/20 18:32:27 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ‘Œ Launched \u001b[92mcpu-Optimized JVM\u001b[39m SparkSession with Jars for: ðŸš€Spark-NLP==4.2.1, ðŸ’ŠSpark-Healthcare==4.2.0, ðŸ•¶Spark-OCR==4.1.0, running on âš¡ PySpark==3.1.2\n"
     ]
    }
   ],
   "source": [
    "from johnsnowlabs import *\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "print(\"Spark NLP Version :\", sparknlp.version())\n",
    "\n",
    "spark = start_spark()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2e8327-8e17-4726-9010-b187335909f0",
   "metadata": {
    "id": "JYBQyxEd0uR0"
   },
   "source": [
    "# CoNLL Data Prep "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JYBQyxEd0uR0",
   "metadata": {
    "id": "JYBQyxEd0uR0"
   },
   "source": [
    "# Data Prep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "AVBmGFcQ03La",
   "metadata": {
    "id": "AVBmGFcQ03La"
   },
   "outputs": [],
   "source": [
    "! wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings_JSL/Legal/data/assertion_fin.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8iJF_HCw1Lgh",
   "metadata": {
    "id": "8iJF_HCw1Lgh"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "training_df = pd.read_csv('./assertion_fin.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "JREBeTzb8ov-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JREBeTzb8ov-",
    "outputId": "4714acfc-92dd-45fb-df1f-455c1171aeff"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+---------+-------+--------------------+------+---------------+\n",
      "|task_id|            sentence|tkn_start|tkn_end|               chunk|entity|assertion_label|\n",
      "+-------+--------------------+---------+-------+--------------------+------+---------------+\n",
      "|      1|The Swedish East ...|        1|      4|Swedish East Indi...|   ORG|           PAST|\n",
      "|      1|The Swedish East ...|        6|      8|Svenska Ostindisk...| ALIAS|           PAST|\n",
      "|      1|The Swedish East ...|       10|     10|                SOIC| ALIAS|           PAST|\n",
      "|      1|The Swedish East ...|       14|     14|          Gothenburg|   LOC|           PAST|\n",
      "|      1|The Swedish East ...|       15|     15|              Sweden|   LOC|           PAST|\n",
      "|      1|The Swedish East ...|       17|     17|                1731|  DATE|           PAST|\n",
      "|      1|The Swedish East ...|       25|     25|               China|   LOC|           PAST|\n",
      "|      1|The Swedish East ...|       28|     29|            Far East|   LOC|           PAST|\n",
      "|      1|The venture was i...|        9|     12|Dutch East India ...|   ORG|           PAST|\n",
      "|      1|The venture was i...|       15|     18|British East Indi...|   ORG|           PAST|\n",
      "|      1|This made Gothenb...|        2|      2|          Gothenburg|   LOC|           PAST|\n",
      "|      1|Trade with China ...|        2|      2|               China|   LOC|           PAST|\n",
      "|      1|Trade with China ...|       11|     11|              Sweden|   LOC|           PAST|\n",
      "|      1|The Chinese cultu...|       34|     34|              Sweden|   LOC|           PAST|\n",
      "|      1|The company folde...|        4|      4|                1813|  DATE|           PAST|\n",
      "|      1|nevertheless, it ...|       11|     11|          Gothenburg|   LOC|           PAST|\n",
      "|      1|Background Sweden...|       16|     17|          East India|   LOC|           PAST|\n",
      "|      1|The royal privile...|        5|      8|Swedish East Indi...|   ORG|           PAST|\n",
      "|      1|The royal privile...|        9|      9|                SOIC| ALIAS|           PAST|\n",
      "|      1|The royal privile...|       27|     28|          East India|   LOC|           PAST|\n",
      "+-------+--------------------+---------+-------+--------------------+------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "training_data = spark.createDataFrame(training_df)\n",
    "training_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ET8GD3y3-17e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ET8GD3y3-17e",
    "outputId": "5e478418-b365-4168-8de9-aab1a885d189"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- task_id: long (nullable = true)\n",
      " |-- sentence: string (nullable = true)\n",
      " |-- tkn_start: long (nullable = true)\n",
      " |-- tkn_end: long (nullable = true)\n",
      " |-- chunk: string (nullable = true)\n",
      " |-- entity: string (nullable = true)\n",
      " |-- assertion_label: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "R6xa4jp8Szs0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R6xa4jp8Szs0",
    "outputId": "6e8e951c-f1c7-445d-af8c-f6e76182174f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.87 ms, sys: 680 Âµs, total: 2.55 ms\n",
      "Wall time: 489 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8050"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time training_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fxcHD_Q_-_lD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fxcHD_Q_-_lD",
    "outputId": "1a114990-64d0-43c1-8522-ef4a9b2145fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 8050\n",
      "Test Dataset Count: 797\n"
     ]
    }
   ],
   "source": [
    "(train_data, test_data) = training_data.randomSplit([0.9, 0.1], seed = 100)\n",
    "print(\"Training Dataset Count: \" + str(training_data.count()))\n",
    "print(\"Test Dataset Count: \" + str(test_data.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "DFN_BuHU84HF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DFN_BuHU84HF",
    "outputId": "ea931a9b-a829-4fcc-90fd-19d7aedf982d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+---------+-------+--------------------+------+---------------+\n",
      "|task_id|            sentence|tkn_start|tkn_end|               chunk|entity|assertion_label|\n",
      "+-------+--------------------+---------+-------+--------------------+------+---------------+\n",
      "|      1|\"Stockholms-varve...|        6|      6|           Stockholm|   LOC|           PAST|\n",
      "|      1|\"The funny busine...|        5|      8|Swedish East Indi...|   ORG|           PAST|\n",
      "|      1|             (1998).|        0|      0|                1998|  DATE|           PAST|\n",
      "|      1|2.5 tonnes) and t...|       34|     34|              Sweden|   LOC|           PAST|\n",
      "|      1|37. Gothenburg: R...|        2|      7|Royal Society of ...|   ORG|           PAST|\n",
      "|      1|= Decline and fal...|       11|     11|                1806|  DATE|           PAST|\n",
      "|      1|= Early attempts ...|        9|     11|  Swedish East India|   ORG|           PAST|\n",
      "|      1|= Early attempts ...|       19|     19|            merchant|  ROLE|           PAST|\n",
      "|      1|= Early attempts ...|       20|     21|    Willem Usselincx|   PER|           PAST|\n",
      "|      1|= Sweden after th...|        1|      1|              Sweden|   LOC|           PAST|\n",
      "|      1|= The Royal chart...|        9|     12|Henrik KÃ¶nig & Co...|   ORG|           PAST|\n",
      "|      1|= The Royal chart...|       39|     42|   Cape of Good Hope|   LOC|           PAST|\n",
      "|      1|= The Royal chart...|       46|     46|               Japan|   LOC|           PAST|\n",
      "|      1|= The Royal chart...|       79|     79|          Gothenburg|   LOC|           PAST|\n",
      "|      1|= The first octro...|        8|      8|           directors|  ROLE|           PAST|\n",
      "|      1|= The first octro...|       11|     11|                SOIC|   ORG|           PAST|\n",
      "|      1|= The first octro...|       13|     14|        Henrik KÃ¶nig|   PER|           PAST|\n",
      "|      1|= The first octro...|       15|     16|      Colin Campbell|   PER|           PAST|\n",
      "|      1|= The first octro...|       23|     23|           Stockholm|   LOC|           PAST|\n",
      "|      1|= The fourth octr...|        6|      6|                SOIC|   ORG|           PAST|\n",
      "+-------+--------------------+---------+-------+--------------------+------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2WZDqlZA_kmb",
   "metadata": {
    "id": "2WZDqlZA_kmb"
   },
   "source": [
    "# Using RoBerta Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7qfJh8ap_nI2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7qfJh8ap_nI2",
    "outputId": "9bd7bd23-7a37-4961-bb94-8374b0abf7d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta_embeddings_legal_roberta_base download started this may take some time.\n",
      "Approximate size to download 447.2 MB\n",
      "[ | ]roberta_embeddings_legal_roberta_base download started this may take some time.\n",
      "Approximate size to download 447.2 MB\n",
      "Download done! Loading the resource.\n",
      "[ â€” ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-20 18:33:34.892472: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "roberta_embeddings = nlp.RoBertaEmbeddings.pretrained(\"roberta_embeddings_legal_roberta_base\",\"en\") \\\n",
    "    .setInputCols([\"document\", \"token\"]) \\\n",
    "    .setOutputCol(\"embeddings\") \\\n",
    "    .setMaxSentenceLength(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "Fe0957BT_rcy",
   "metadata": {
    "id": "Fe0957BT_rcy"
   },
   "outputs": [],
   "source": [
    "document = nlp.DocumentAssembler()\\\n",
    "    .setInputCol(\"sentence\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "chunk = nlp.Doc2Chunk()\\\n",
    "    .setInputCols(\"document\")\\\n",
    "    .setOutputCol(\"doc_chunk\")\\\n",
    "    .setChunkCol(\"chunk\")\\\n",
    "    .setStartCol(\"tkn_start\")\\\n",
    "    .setStartColByTokenIndex(True)\\\n",
    "    .setFailOnMissing(False)\\\n",
    "    .setLowerCase(False)\n",
    "\n",
    "token = nlp.Tokenizer()\\\n",
    "    .setInputCols(['document'])\\\n",
    "    .setOutputCol('token')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LFTO0PlI9-3e",
   "metadata": {
    "id": "LFTO0PlI9-3e"
   },
   "source": [
    "We save the test data in parquet format to use in `AssertionDLApproach()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "M9u4c65G9VaC",
   "metadata": {
    "id": "M9u4c65G9VaC"
   },
   "outputs": [],
   "source": [
    "assertion_pipeline = Pipeline(\n",
    "    stages = [\n",
    "    document,\n",
    "    chunk,\n",
    "    token,\n",
    "    roberta_embeddings])\n",
    "\n",
    "assertion_test_data = assertion_pipeline.fit(test_data).transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "r-UREmtI9Vd3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r-UREmtI9Vd3",
    "outputId": "31cd6903-4929-491c-83a7-09c5ef42d9dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['task_id',\n",
       " 'sentence',\n",
       " 'tkn_start',\n",
       " 'tkn_end',\n",
       " 'chunk',\n",
       " 'entity',\n",
       " 'assertion_label',\n",
       " 'document',\n",
       " 'doc_chunk',\n",
       " 'token',\n",
       " 'embeddings']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assertion_test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "kBaiXx78BTLT",
   "metadata": {
    "id": "kBaiXx78BTLT"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "assertion_test_data.write.mode('overwrite').parquet('test_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "tFhN6evk9ViI",
   "metadata": {
    "id": "tFhN6evk9ViI"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "assertion_train_data = assertion_pipeline.fit(training_data).transform(training_data)\n",
    "assertion_train_data.write.mode('overwrite').parquet('train_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "BtxnrvcA9VlN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BtxnrvcA9VlN",
    "outputId": "dd24e11a-9ad8-470b-9610-3d9eb1dfaac5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['task_id',\n",
       " 'sentence',\n",
       " 'tkn_start',\n",
       " 'tkn_end',\n",
       " 'chunk',\n",
       " 'entity',\n",
       " 'assertion_label',\n",
       " 'document',\n",
       " 'doc_chunk',\n",
       " 'token',\n",
       " 'embeddings']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assertion_train_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uTishXbut1MS",
   "metadata": {
    "id": "uTishXbut1MS"
   },
   "source": [
    "## Graph setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1hTawAHemzGn",
   "metadata": {
    "id": "1hTawAHemzGn"
   },
   "outputs": [],
   "source": [
    "!pip install -q tensorflow==2.7.0\n",
    "!pip install -q tensorflow-addons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ShZT8BBo4FY",
   "metadata": {
    "id": "0ShZT8BBo4FY"
   },
   "source": [
    "We will use TFGraphBuilder annotator which can be used to create graphs in the model training pipeline. \n",
    "\n",
    "TFGraphBuilder inspects the data and creates the proper graph if a suitable version of TensorFlow (<= 2.7 ) is available. The graph is stored in the defined folder and loaded by the approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "XhU0L1OXdaLN",
   "metadata": {
    "id": "XhU0L1OXdaLN"
   },
   "outputs": [],
   "source": [
    "graph_folder= \"./tf_graphs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "miNgoTjio0mL",
   "metadata": {
    "id": "miNgoTjio0mL"
   },
   "outputs": [],
   "source": [
    "assertion_graph_builder =  legal.TFGraphBuilder()\\\n",
    "    .setModelName(\"assertion_dl\")\\\n",
    "    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "    .setLabelColumn(\"assertion_label\")\\\n",
    "    .setGraphFolder(graph_folder)\\\n",
    "    .setGraphFile(\"assertion_graph.pb\")\\\n",
    "    .setMaxSequenceLength(1200)\\\n",
    "    .setHiddenUnitsNumber(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6D0Ng7nMUjJa",
   "metadata": {
    "id": "6D0Ng7nMUjJa"
   },
   "source": [
    "**Setting the Scope Window (Target Area) Dynamically in Assertion Status Detection Models**\n",
    "\n",
    "\n",
    "This parameter allows you to train the Assertion Status Models to focus on specific context windows when resolving the status of a NER chunk. The window is in format `[X,Y]` being `X` the number of tokens to consider on the left of the chunk, and `Y` the max number of tokens to consider on the right. Letâ€™s take a look at what different windows mean:\n",
    "\n",
    "\n",
    "*   By default, the window is `[-1,-1]` which means that the Assertion Status will look at all of the tokens in the sentence/document (up to a maximum of tokens set in `setMaxSentLen()` ).\n",
    "*   `[0,0]` means â€œdonâ€™t pay attention to any token except the ner_chunkâ€, what basically is not considering any context for the Assertion resolution.\n",
    "*   `[9,15]` is what empirically seems to be the best baseline, meaning that we look up to 9 tokens on the left and 15 on the right of the ner chunk to understand the context and resolve the status.\n",
    "\n",
    "\n",
    "Check this [Scope Window Tuning Assertion Status Detection notebook](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/2.1.Scope_window_tuning_assertion_status_detection.ipynb)  that illustrates the effect of the different windows and how to properly fine-tune your AssertionDLModels to get the best of them.\n",
    "\n",
    "In our case, the best Scope Window is around [10,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "BQxGbYks91go",
   "metadata": {
    "id": "BQxGbYks91go"
   },
   "outputs": [],
   "source": [
    "scope_window = [50, 50]\n",
    "\n",
    "assertionStatus = legal.AssertionDLApproach()\\\n",
    "    .setLabelCol(\"assertion_label\")\\\n",
    "    .setInputCols(\"document\", \"doc_chunk\", \"embeddings\")\\\n",
    "    .setOutputCol(\"assertion\")\\\n",
    "    .setBatchSize(128)\\\n",
    "    .setLearningRate(0.001)\\\n",
    "    .setEpochs(2)\\\n",
    "    .setStartCol(\"tkn_start\")\\\n",
    "    .setEndCol(\"tkn_end\")\\\n",
    "    .setMaxSentLen(1200)\\\n",
    "    .setEnableOutputLogs(True)\\\n",
    "    .setOutputLogsPath('training_logs/')\\\n",
    "    .setGraphFolder(graph_folder)\\\n",
    "    .setGraphFile(f\"{graph_folder}/assertion_graph.pb\")\\\n",
    "    .setTestDataset(path=\"test_data.parquet\", read_as='SPARK', options={'format': 'parquet'})\\\n",
    "    .setScopeWindow(scope_window)\n",
    "    #.setValidationSplit(0.2)\\    \n",
    "    #.setDropout(0.1)\\    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "T2MZLeCYATrS",
   "metadata": {
    "id": "T2MZLeCYATrS"
   },
   "outputs": [],
   "source": [
    "clinical_assertion_pipeline = Pipeline(\n",
    "    stages = [\n",
    "    #document,\n",
    "    #chunk,\n",
    "    #token,\n",
    "    #embeddings,\n",
    "    assertion_graph_builder,\n",
    "    assertionStatus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "yIvnuaQP91j8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yIvnuaQP91j8",
    "outputId": "54d68047-97f2-4cc0-d8ee-b7b57948145b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- task_id: long (nullable = true)\n",
      " |-- sentence: string (nullable = true)\n",
      " |-- tkn_start: long (nullable = true)\n",
      " |-- tkn_end: long (nullable = true)\n",
      " |-- chunk: string (nullable = true)\n",
      " |-- entity: string (nullable = true)\n",
      " |-- assertion_label: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ueJz0aiJ_7l4",
   "metadata": {
    "id": "ueJz0aiJ_7l4"
   },
   "outputs": [],
   "source": [
    "assertion_train_data = spark.read.parquet('train_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "j1NCZ89T_7ol",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j1NCZ89T_7ol",
    "outputId": "5a2a676d-0b61-4c59-c7db-6f2bc475c334"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Graph Builder configuration:\n",
      "Model name: assertion_dl\n",
      "Graph folder: ./tf_graphs\n",
      "Graph file name: assertion_graph.pb\n",
      "Build params: {'n_classes': 4, 'feat_size': 768, 'max_seq_len': 1200, 'n_hidden': 25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-20 18:38:08.146421: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ubuntu/.jupyter_env/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-10-20 18:38:08.146463: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "18:38:10, WARNING From /home/ubuntu/.jupyter_env/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping: no known devices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-20 18:38:10.880722: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-20 18:38:10.890931: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-10-20 18:38:10.890976: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (jsl-test): /proc/driver/nvidia/version does not exist\n",
      "18:38:10, WARNING From /home/ubuntu/.jupyter_env/lib/python3.8/site-packages/sparknlp_jsl/_tf_graph_builders/tf2contrib/rnn.py:229: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "18:38:10, WARNING From /home/ubuntu/.jupyter_env/lib/python3.8/site-packages/tensorflow/python/ops/rnn.py:441: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "18:38:10, WARNING From /home/ubuntu/.jupyter_env/lib/python3.8/site-packages/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py:766: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping: no known devices.\n",
      "assertion_dl graph exported to ./tf_graphs/assertion_graph.pb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality on test dataset: \n",
      "time to finish evaluation: 39.63s\n",
      "Total test loss: 2.2837\tAvg test loss: 0.3262\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "PRESENT\t 184\t 32\t 33\t 0.8518519\t 0.84792626\t 0.84988457\n",
      "POSSIBLE\t 161\t 30\t 16\t 0.8429319\t 0.90960455\t 0.875\n",
      "FUTURE\t 88\t 6\t 35\t 0.9361702\t 0.7154471\t 0.81105995\n",
      "PAST\t 256\t 40\t 24\t 0.8648649\t 0.9142857\t 0.88888896\n",
      "tp: 689 fp: 108 fn: 108 labels: 4\n",
      "Macro-average\t prec: 0.8739547, rec: 0.8468159, f1: 0.8601713\n",
      "Micro-average\t prec: 0.8644918, rec: 0.8644918, f1: 0.8644918\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 41.15s\n",
      "Total test loss: 1.2913\tAvg test loss: 0.1845\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "PRESENT\t 199\t 18\t 18\t 0.9170507\t 0.9170507\t 0.9170507\n",
      "POSSIBLE\t 165\t 4\t 12\t 0.97633135\t 0.9322034\t 0.9537573\n",
      "FUTURE\t 120\t 16\t 3\t 0.88235295\t 0.9756098\t 0.9266409\n",
      "PAST\t 259\t 16\t 21\t 0.9418182\t 0.925\t 0.93333334\n",
      "tp: 743 fp: 54 fn: 54 labels: 4\n",
      "Macro-average\t prec: 0.9293883, rec: 0.93746597, f1: 0.9334097\n",
      "Micro-average\t prec: 0.9322459, rec: 0.9322459, f1: 0.9322459\n",
      "CPU times: user 6 s, sys: 493 ms, total: 6.49 s\n",
      "Wall time: 16min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "assertion_model = clinical_assertion_pipeline.fit(assertion_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30SmcTiSpnWa",
   "metadata": {
    "id": "30SmcTiSpnWa"
   },
   "source": [
    "Checking the results saved in the log file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "kOiu1vuspKut",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kOiu1vuspKut",
    "outputId": "f62ec0f2-c361-4ecb-e094-bf659e956e17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AssertionDLApproach_047b549cd16e.log']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_files = os.listdir(\"./training_logs\")\n",
    "log_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "CcQV0-fIrJHz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CcQV0-fIrJHz",
    "outputId": "4239e398-1b0e-405a-cdd3-a608ea7687ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of the selected graph: ./tf_graphs/assertion_graph.pb\n",
      "Training started, trainExamples: 8050\n",
      "\n",
      "\n",
      "Epoch: 0 started, learning rate: 0.001, dataset size: 8050\n",
      "Done, 439.796040062 total training loss: 54.84761, avg training loss: 0.870597, batches: 63\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 39.63s\n",
      "Total test loss: 2.2837\tAvg test loss: 0.3262\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "PRESENT\t 184\t 32\t 33\t 0.8518519\t 0.84792626\t 0.84988457\n",
      "POSSIBLE\t 161\t 30\t 16\t 0.8429319\t 0.90960455\t 0.875\n",
      "FUTURE\t 88\t 6\t 35\t 0.9361702\t 0.7154471\t 0.81105995\n",
      "PAST\t 256\t 40\t 24\t 0.8648649\t 0.9142857\t 0.88888896\n",
      "tp: 689 fp: 108 fn: 108 labels: 4\n",
      "Macro-average\t prec: 0.8739547, rec: 0.8468159, f1: 0.8601713\n",
      "Micro-average\t prec: 0.8644918, rec: 0.8644918, f1: 0.8644918\n",
      "\n",
      "\n",
      "Epoch: 1 started, learning rate: 9.5E-4, dataset size: 8050\n",
      "Done, 432.156751051 total training loss: 17.7556, avg training loss: 0.28183493, batches: 63\n",
      "Quality on test dataset: \n",
      "time to finish evaluation: 41.15s\n",
      "Total test loss: 1.2913\tAvg test loss: 0.1845\n",
      "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
      "PRESENT\t 199\t 18\t 18\t 0.9170507\t 0.9170507\t 0.9170507\n",
      "POSSIBLE\t 165\t 4\t 12\t 0.97633135\t 0.9322034\t 0.9537573\n",
      "FUTURE\t 120\t 16\t 3\t 0.88235295\t 0.9756098\t 0.9266409\n",
      "PAST\t 259\t 16\t 21\t 0.9418182\t 0.925\t 0.93333334\n",
      "tp: 743 fp: 54 fn: 54 labels: 4\n",
      "Macro-average\t prec: 0.9293883, rec: 0.93746597, f1: 0.9334097\n",
      "Micro-average\t prec: 0.9322459, rec: 0.9322459, f1: 0.9322459\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"./training_logs/\"+log_files[0]) as log_file:\n",
    "    print(log_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bgcG00nT91nn",
   "metadata": {
    "id": "bgcG00nT91nn"
   },
   "outputs": [],
   "source": [
    "assertion_test_data = spark.read.parquet('test_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "-k2WrFkRyQyP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-k2WrFkRyQyP",
    "outputId": "de6214ba-b53d-4eb5-a3da-53410f470169"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 21:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------+\n",
      "|assertion_label|   result|\n",
      "+---------------+---------+\n",
      "|           PAST|[PRESENT]|\n",
      "|           PAST|   [PAST]|\n",
      "|           PAST|   [PAST]|\n",
      "|           PAST|   [PAST]|\n",
      "|           PAST|   [PAST]|\n",
      "|        PRESENT|[PRESENT]|\n",
      "|        PRESENT|[PRESENT]|\n",
      "|           PAST|   [PAST]|\n",
      "|        PRESENT|   [PAST]|\n",
      "|        PRESENT|[PRESENT]|\n",
      "|        PRESENT|[PRESENT]|\n",
      "|           PAST|   [PAST]|\n",
      "|           PAST|   [PAST]|\n",
      "|        PRESENT|[PRESENT]|\n",
      "|           PAST|   [PAST]|\n",
      "|           PAST|   [PAST]|\n",
      "|           PAST|   [PAST]|\n",
      "|        PRESENT|[PRESENT]|\n",
      "|        PRESENT|[PRESENT]|\n",
      "|        PRESENT|[PRESENT]|\n",
      "+---------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "preds = assertion_model.transform(assertion_test_data).select('assertion_label','assertion.result')\n",
    "\n",
    "preds.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4yI73lwG2xk5",
   "metadata": {
    "id": "4yI73lwG2xk5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "preds_df = preds.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "yRXZFGlQ3Z2U",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "yRXZFGlQ3Z2U",
    "outputId": "103b1d38-b06e-4282-b878-5d1d64127b91"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assertion_label</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PAST</td>\n",
       "      <td>PRESENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PAST</td>\n",
       "      <td>PAST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PAST</td>\n",
       "      <td>PAST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PAST</td>\n",
       "      <td>PAST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PAST</td>\n",
       "      <td>PAST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>POSSIBLE</td>\n",
       "      <td>POSSIBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>POSSIBLE</td>\n",
       "      <td>FUTURE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>POSSIBLE</td>\n",
       "      <td>POSSIBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>POSSIBLE</td>\n",
       "      <td>POSSIBLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>POSSIBLE</td>\n",
       "      <td>POSSIBLE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>795 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    assertion_label    result\n",
       "0              PAST   PRESENT\n",
       "1              PAST      PAST\n",
       "2              PAST      PAST\n",
       "3              PAST      PAST\n",
       "4              PAST      PAST\n",
       "..              ...       ...\n",
       "792        POSSIBLE  POSSIBLE\n",
       "793        POSSIBLE    FUTURE\n",
       "794        POSSIBLE  POSSIBLE\n",
       "795        POSSIBLE  POSSIBLE\n",
       "796        POSSIBLE  POSSIBLE\n",
       "\n",
       "[795 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df[\"result\"] = preds_df[\"result\"].apply(lambda x: x[0] if len(x) else pd.NA)\n",
    "preds_df.dropna(inplace=True)\n",
    "\n",
    "preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1hb1kyGAE0Gn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1hb1kyGAE0Gn",
    "outputId": "468f0f48-2a58-494e-c827-8df5bb141c7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      FUTURE       0.88      0.98      0.93       123\n",
      "        PAST       0.94      0.92      0.93       278\n",
      "    POSSIBLE       0.98      0.93      0.95       177\n",
      "     PRESENT       0.91      0.92      0.91       217\n",
      "\n",
      "    accuracy                           0.93       795\n",
      "   macro avg       0.93      0.94      0.93       795\n",
      "weighted avg       0.93      0.93      0.93       795\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We are going to use sklearn to evalute the results on test dataset\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print (classification_report( preds_df['assertion_label'], preds_df['result']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WuJ5YZ9sXU13",
   "metadata": {
    "id": "WuJ5YZ9sXU13"
   },
   "source": [
    "### Saving the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "KBcoOwvwXV8p",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KBcoOwvwXV8p",
    "outputId": "85a27749-4cdc-498b-ffa1-02aa99a47912"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TFGraphBuilderModel_4906f0357f51, FINANCE-ASSERTION_DL_b54d1344dc62]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assertion_model.stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ioMW1jSrA-wg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ioMW1jSrA-wg",
    "outputId": "329f2545-0041-494f-8719-c641cb5b4c5e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/notebooks/examples/legal/Assertion.zip'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save a Spark NLP model\n",
    "assertion_model.stages[-1].write().overwrite().save('Assertion')\n",
    "\n",
    "import shutil\n",
    "shutil.make_archive('Assertion', 'zip', 'Assertion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec63a751-f945-4038-b9c8-275062f8e1e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
