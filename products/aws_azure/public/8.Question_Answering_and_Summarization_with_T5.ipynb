{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sXatvRX899i0"
   },
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kl6fW8Fkf3vN"
   },
   "source": [
    "# Question Answering and Summarization with [T5](https://arxiv.org/pdf/1910.10683.pdf)\n",
    "\n",
    "\n",
    "Google's T5 is a Sequence to Sequence model that was trained on over 15 different NLP datasets with various problem types, raning from Text Summarization, Question Answering, Translation to various semantical deduction tasks, which enriches T5's ability to map token sequences to semantic vectors which contain more meaning, which T5 leverages to generalize across various tasks and even to never before trained tasks.\n",
    "\n",
    "On top of this, T5 is trained on the standard Word prediction task, which most transformer based models like BERT, GPT, ELMO have been trained on. This gives T5 general knowledge of real world concepts to additionally enhance its understanding.\n",
    "\n",
    "With T5 you can answer **general knowledge based questions given no context** and in addition answer **questions on text databases**.      \n",
    "These questions can be asked in natural human.\n",
    "\n",
    "\n",
    "## What is a `open book question`? \n",
    "You can imagine an `open book` question similar to an examen where you are allowed to bring in text documents or cheat sheets that help you answer questions in an examen. Kinda like bringing a history book to an history examen. \n",
    "\n",
    "In `T5's` terms, this means the model is given a `question` and an **additional piece of textual information** or so called `context`.\n",
    "\n",
    "This enables the `T5` model to answer questions on textual datasets like `medical records`,`newsarticles` , `wiki-databases` , `stories` and `movie scripts` , `product descriptions`, 'legal documents' and many more.\n",
    "\n",
    "\n",
    "\n",
    "## What is a `closed book question`? \n",
    "A `closed book question` is the exact opposite of a `open book question`. In an examen scenario, you are only allowed to use what you have memorized in your brain and nothing else.      \n",
    "In `T5's` terms this means that T5 can only use it's stored weights to answer a `question` and is given **no aditional context**.        \n",
    "`T5` was pre-trained on the [C4 dataset](https://commoncrawl.org/) which contains **petabytes  of web crawling data**  collected over the last 8 years, including Wikipedia in every language.\n",
    "\n",
    "\n",
    "This gives `T5` the broad knowledge of the internet stored in it's weights to answer various `closed book questions` \n",
    "\n",
    "\n",
    "\n",
    "<!-- [T5]() -->\n",
    "![T5 GIF](https://1.bp.blogspot.com/-o4oiOExxq1s/Xk26XPC3haI/AAAAAAAAFU8/NBlvOWB84L0PTYy9TzZBaLf6fwPGJTR0QCLcBGAsYHQ/s1600/image3.gif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06DMedvcgjKa"
   },
   "source": [
    "## Start Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "KjcBNzFVgoky"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP Version : 4.2.4\n",
      "Spark Session already created, some configs may not take.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-15-180.ec2.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>John-Snow-Labs-Spark-Session ðŸš€ with Jars for: ðŸš€Spark-NLP==4.2.4, ðŸ’ŠSpark-Healthcare==4.2.4, ðŸ•¶Spark-OCR==4.2.4, running on âš¡ PySpark==3.1.2</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f675a9e6880>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import sparknlp\n",
    "from sparknlp.base import *\n",
    "from sparknlp.common import *\n",
    "from sparknlp.annotator import *\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml import Pipeline,PipelineModel\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "print(\"Spark NLP Version :\", sparknlp.version())\n",
    "\n",
    "spark = sparknlp.start()\n",
    "# params =>> gpu=False\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZyycKyzQcwQ"
   },
   "source": [
    "# Download T5 Model and Create Spark NLP Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 89926,
     "status": "ok",
     "timestamp": 1656885191581,
     "user": {
      "displayName": "Monster C",
      "userId": "08787989274818793476"
     },
     "user_tz": -180
    },
    "id": "gXdynTiFHKLK",
    "outputId": "beba0add-8a11-472c-f31d-722eb76db560"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t5_base download started this may take some time.\n",
      "Approximate size to download 451.8 MB\n",
      "[ | ]t5_base download started this may take some time.\n",
      "Approximate size to download 451.8 MB\n",
      "[ | ]Download done! Loading the resource.\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "documentAssembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\") \\\n",
    "    .setOutputCol(\"document\") \n",
    "\n",
    "# Can take in document or sentence columns\n",
    "t5 = T5Transformer.pretrained(name='t5_base',lang='en')\\\n",
    "    .setInputCols('document')\\\n",
    "    .setOutputCol(\"T5\")\\\n",
    "    .setMaxOutputLength(400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FzSthAbHS72B"
   },
   "source": [
    "# Answering Questions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aem2oG-iQhAA"
   },
   "source": [
    "## Set the Task to `question`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1656885191582,
     "user": {
      "displayName": "Monster C",
      "userId": "08787989274818793476"
     },
     "user_tz": -180
    },
    "id": "XAmbHcTjM6BP",
    "outputId": "3f83a6f2-513d-4c90-f912-6ead4fa38310"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5TRANSFORMER_8078c2d39352"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the task for questions on T5. Depending to what this is currently set, we get different behaivour\n",
    "t5.setTask('question')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "airN5MRMQq7h"
   },
   "source": [
    "## Answer **Closed Book Questions**  \n",
    "Closed book means that no additional context is given and the model must answer the question with the knowledge stored in it's weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12164,
     "status": "ok",
     "timestamp": 1656885203740,
     "user": {
      "displayName": "Monster C",
      "userId": "08787989274818793476"
     },
     "user_tz": -180
    },
    "id": "vFVGcgXrHSfZ",
    "outputId": "c242d423-a31d-4569-f779-98ba42dc57c1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------+------------------+\n",
      "|text                                       |result            |\n",
      "+-------------------------------------------+------------------+\n",
      "|Who is president of Nigeria?               |[Muhammadu Buhari]|\n",
      "|What is the most common language in India? |[Hindi]           |\n",
      "|What is the capital of Germany?            |[Berlin]          |\n",
      "+-------------------------------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build pipeline with T5\n",
    "pipe_components = [documentAssembler,t5]\n",
    "pipeline = Pipeline().setStages( pipe_components)\n",
    "\n",
    "# define Data\n",
    "data = [[\"Who is president of Nigeria? \"],\n",
    "        [\"What is the most common language in India? \"],\n",
    "        [\"What is the capital of Germany? \"]]\n",
    "df=spark.createDataFrame(data).toDF('text')\n",
    "\n",
    "#Predict on text data with T5\n",
    "model = pipeline.fit(df)\n",
    "annotated_df = model.transform(df)\n",
    "annotated_df.select(['text','t5.result']).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f86fFTXMQvPt"
   },
   "source": [
    "## Answer **Open Book Questions** \n",
    "These are questions where we give the model some additional context, that is used to answer the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5745,
     "status": "ok",
     "timestamp": 1656885213704,
     "user": {
      "displayName": "Monster C",
      "userId": "08787989274818793476"
     },
     "user_tz": -180
    },
    "id": "9isRW-2lFsfl",
    "outputId": "434e5db7-644d-48b0-a669-23ce6d167fec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------+\n",
      "|text                                                                                                                             |result                                             |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------+\n",
      "|question: Why was peters week so bad? context: Peters last week was terrible! He had an accident and broke his leg while skiing! |[He had an accident and broke his leg while skiing]|\n",
      "|question: How did peter broke his leg? context: Peters last week was terrible! He had an accident and broke his leg while skiing!|[skiing]                                           |\n",
      "|question: How did peter broke his leg? context: Peters last week was terrible! He had an accident and broke his leg while skiing!|[skiing]                                           |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "context    = 'context: Peters last week was terrible! He had an accident and broke his leg while skiing!'\n",
    "question1  = 'question: Why was peters week so bad? ' #\n",
    "question2  = 'question: How did peter broke his leg? ' \n",
    "question3  = 'question: How did peter broke his leg? '\n",
    " \n",
    "data = [[question1+context],[question2+context],[question3+context],]\n",
    "df=spark.createDataFrame(data).toDF('text')\n",
    "\n",
    "#Predict on text data with T5\n",
    "model = pipeline.fit(df)\n",
    "annotated_df = model.transform(df)\n",
    "annotated_df.select(['text','t5.result']).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9712,
     "status": "ok",
     "timestamp": 1656885228206,
     "user": {
      "displayName": "Monster C",
      "userId": "08787989274818793476"
     },
     "user_tz": -180
    },
    "id": "yWpiawiA5GwS",
    "outputId": "8d74e4fe-9d5a-4353-f0ef-24323a81cff8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:>                                                         (0 + 3) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+\n",
      "|result                 |\n",
      "+-----------------------+\n",
      "|[Alibaba Group founder]|\n",
      "|[Jack Ma]              |\n",
      "|[Wednesday]            |\n",
      "|[surged 5%]            |\n",
      "|[100 rural teachers]   |\n",
      "|[Chinese regulators]   |\n",
      "+-----------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Ask T5 questions in the context of a News Article\n",
    "question1 = 'question: Who is Jack ma? '\n",
    "question2 = 'question: Who is founder of Alibaba Group? '\n",
    "question3 = 'question: When did Jack Ma re-appear? '\n",
    "question4 = 'question: How did Alibaba stocks react? '\n",
    "question5 = 'question: Whom did Jack Ma meet? '\n",
    "question6 = 'question: Who did Jack Ma hide from? '\n",
    "\n",
    "\n",
    "# from https://www.bbc.com/news/business-55728338 \n",
    "news_article_context = \"\"\" context:\n",
    "Alibaba Group founder Jack Ma has made his first appearance since Chinese regulators cracked down on his business empire.\n",
    "His absence had fuelled speculation over his whereabouts amid increasing official scrutiny of his businesses.\n",
    "The billionaire met 100 rural teachers in China via a video meeting on Wednesday, according to local government media.\n",
    "Alibaba shares surged 5% on Hong Kong's stock exchange on the news.\n",
    "\"\"\"\n",
    "\n",
    "data = [\n",
    "             [question1+ news_article_context],\n",
    "             [question2+ news_article_context],\n",
    "             [question3+ news_article_context],\n",
    "             [question4+ news_article_context],\n",
    "             [question5+ news_article_context],\n",
    "             [question6+ news_article_context]]\n",
    "\n",
    "\n",
    "df=spark.createDataFrame(data).toDF('text')\n",
    "\n",
    "#Predict on text data with T5\n",
    "model = pipeline.fit(df)\n",
    "annotated_df = model.transform(df)\n",
    "annotated_df.select(['t5.result']).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tUfqQBdtNTS6"
   },
   "source": [
    "# Summarize documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 403,
     "status": "ok",
     "timestamp": 1656885253213,
     "user": {
      "displayName": "Monster C",
      "userId": "08787989274818793476"
     },
     "user_tz": -180
    },
    "id": "X1-x-TLL5iJK",
    "outputId": "f784a4d3-7835-416c-f8bc-dcdb22e33ce0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5TRANSFORMER_8078c2d39352"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the task for questions on T5\n",
    "t5.setTask('summarize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47276,
     "status": "ok",
     "timestamp": 1656885303079,
     "user": {
      "displayName": "Monster C",
      "userId": "08787989274818793476"
     },
     "user_tz": -180
    },
    "id": "fzKvMHteNUTB",
    "outputId": "cd2cf3cf-ae9b-4a48-de7a-10fed14bc52a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|result                                                                                                                                                                                                                                                                                                                                                            |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[mastercard said on Wednesday it was planning to offer support for some cryptocurrencies on its network this year . the credit-card giantâ€™s announcement comes days after Elon Muskâ€™s Tesla Inc revealed it had purchased $1.5 billion of bitcoin . asset manager blackrock and payments companies Square and PayPal have also recently backed cryptocurrencies .]|\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# https://www.reuters.com/article/instant-article/idCAKBN2AA2WF\n",
    "text = \"\"\"(Reuters) - Mastercard Inc said on Wednesday it was planning to offer support for some cryptocurrencies on its network this year, joining a string of big-ticket firms that have pledged similar support.\n",
    "\n",
    "The credit-card giantâ€™s announcement comes days after Elon Muskâ€™s Tesla Inc revealed it had purchased $1.5 billion of bitcoin and would soon accept it as a form of payment.\n",
    "\n",
    "Asset manager BlackRock Inc and payments companies Square and PayPal have also recently backed cryptocurrencies.\n",
    "\n",
    "Mastercard already offers customers cards that allow people to transact using their cryptocurrencies, although without going through its network.\n",
    "\n",
    "\"Doing this work will create a lot more possibilities for shoppers and merchants, allowing them to transact in an entirely new form of payment. This change may open merchants up to new customers who are already flocking to digital assets,\" Mastercard said. (mstr.cd/3tLaPZM)\n",
    "\n",
    "Mastercard specified that not all cryptocurrencies will be supported on its network, adding that many of the hundreds of digital assets in circulation still need to tighten their compliance measures.\n",
    "\n",
    "Many cryptocurrencies have struggled to win the trust of mainstream investors and the general public due to their speculative nature and potential for money laundering.\n",
    "\"\"\"\n",
    "data = [[text]]\n",
    "df=spark.createDataFrame(data).toDF('text')\n",
    "#Predict on text data with T5\n",
    "model = pipeline.fit(df)\n",
    "annotated_df = model.transform(df)\n",
    "annotated_df.select(['t5.result']).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48051,
     "status": "ok",
     "timestamp": 1656885384561,
     "user": {
      "displayName": "Monster C",
      "userId": "08787989274818793476"
     },
     "user_tz": -180
    },
    "id": "cdII1LrdNq3p",
    "outputId": "be7a7a02-bc14-4a95-ef93-646ca8b3b8e7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Length 1284   Summarized Length : 352 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "v = annotated_df.take(1)\n",
    "print(f\"Original Length {len(v[0].text)}   Summarized Length : {len(v[0].T5[0].result)} \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1656885384562,
     "user": {
      "displayName": "Monster C",
      "userId": "08787989274818793476"
     },
     "user_tz": -180
    },
    "id": "do_7s8baOCej",
    "outputId": "c3f6bec1-1600-4b1d-e793-645c4b7fd543"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mastercard said on Wednesday it was planning to offer support for some cryptocurrencies on its network this year . the credit-card giantâ€™s announcement comes days after Elon Muskâ€™s Tesla Inc revealed it had purchased $1.5 billion of bitcoin . asset manager blackrock and payments companies Square and PayPal have also recently backed cryptocurrencies .'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Full summarized text\n",
    "v[0].T5[0].result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lUu1b5j7PXHL"
   },
   "source": [
    "# Multi Problem T5 model for Summarization and more\n",
    "The main T5 model was trained for over 20 tasks from the SQUAD/GLUE/SUPERGLUE datasets. See [this notebook](https://github.com/JohnSnowLabs/nlu/blob/master/examples/webinars_conferences_etc/multi_lingual_webinar/7_T5_SQUAD_GLUE_SUPER_GLUE_TASKS.ipynb) for a demo of all tasks \n",
    "\n",
    "\n",
    "# Overview of every task available with T5\n",
    "[The T5 model](https://arxiv.org/pdf/1910.10683.pdf) is trained on various datasets for 17 different tasks which fall into 8 categories.\n",
    "\n",
    "\n",
    "\n",
    "1. Text summarization\n",
    "2. Question answering\n",
    "3. Translation\n",
    "4. Sentiment analysis\n",
    "5. Natural Language inference\n",
    "6. Coreference resolution\n",
    "7. Sentence Completion\n",
    "8. Word sense disambiguation\n",
    "\n",
    "### Every T5 Task with explanation:\n",
    "|Task Name | Explanation | \n",
    "|----------|--------------|\n",
    "|[1.CoLA](https://nyu-mll.github.io/CoLA/)                   | Classify if a sentence is gramaticaly correct|\n",
    "|[2.RTE](https://dl.acm.org/doi/10.1007/11736790_9)                    | Classify whether if a statement can be deducted from a sentence|\n",
    "|[3.MNLI](https://arxiv.org/abs/1704.05426)                   | Classify for a hypothesis and premise whether they contradict or contradict each other or neither of both (3 class).|\n",
    "|[4.MRPC](https://www.aclweb.org/anthology/I05-5002.pdf)                   | Classify whether a pair of sentences is a re-phrasing of each other (semantically equivalent)|\n",
    "|[5.QNLI](https://arxiv.org/pdf/1804.07461.pdf)                   | Classify whether the answer to a question can be deducted from an answer candidate.|\n",
    "|[6.QQP](https://www.quora.com/q/quoradata/First-Quora-Dataset-Release-Question-Pairs)                    | Classify whether a pair of questions is a re-phrasing of each other (semantically equivalent)|\n",
    "|[7.SST2](https://www.aclweb.org/anthology/D13-1170.pdf)                   | Classify the sentiment of a sentence as positive or negative|\n",
    "|[8.STSB](https://www.aclweb.org/anthology/S17-2001/)                   | Classify the sentiment of a sentence on a scale from 1 to 5 (21 Sentiment classes)|\n",
    "|[9.CB](https://ojs.ub.uni-konstanz.de/sub/index.php/sub/article/view/601)                     | Classify for a premise and a hypothesis whether they contradict each other or not (binary).|\n",
    "|[10.COPA](https://www.aaai.org/ocs/index.php/SSS/SSS11/paper/view/2418/0)                   | Classify for a question, premise, and 2 choices which choice the correct choice is (binary).|\n",
    "|[11.MultiRc](https://www.aclweb.org/anthology/N18-1023.pdf)                | Classify for a question, a paragraph of text, and an answer candidate, if the answer is correct (binary),|\n",
    "|[12.WiC](https://arxiv.org/abs/1808.09121)                    | Classify for a pair of sentences and a disambigous word if the word has the same meaning in both sentences.|\n",
    "|[13.WSC/DPR](https://www.aaai.org/ocs/index.php/KR/KR12/paper/view/4492/0)       | Predict for an ambiguous pronoun in a sentence what it is referring to.  |\n",
    "|[14.Summarization](https://arxiv.org/abs/1506.03340)          | Summarize text into a shorter representation.|\n",
    "|[15.SQuAD](https://arxiv.org/abs/1606.05250)                  | Answer a question for a given context.|\n",
    "|[16.WMT1.](https://arxiv.org/abs/1706.03762)                  | Translate English to German|\n",
    "|[17.WMT2.](https://arxiv.org/abs/1706.03762)                   | Translate English to French|\n",
    "|[18.WMT3.](https://arxiv.org/abs/1706.03762)                   | Translate English to Romanian|\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "jsl4.2.3",
   "language": "python",
   "name": "jsl4.2.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
