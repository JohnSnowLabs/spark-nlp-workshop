{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db5f4f9a-7776-42b3-8758-85624d4c15ea",
   "metadata": {
    "id": "db5f4f9a-7776-42b3-8758-85624d4c15ea"
   },
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbbcfc0-e0b7-4c25-8bd7-c64d90f836d1",
   "metadata": {
    "id": "cfbbcfc0-e0b7-4c25-8bd7-c64d90f836d1"
   },
   "source": [
    "# Financial Data Augmentation with Chunk Mappers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281f50e2-a3bb-4ce6-a244-deb48dc956f3",
   "metadata": {
    "id": "okhT7AcXxben"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b50a075-9221-4132-b0cc-00d896c80a0d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 115199,
     "status": "ok",
     "timestamp": 1664816113389,
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     },
     "user_tz": -120
    },
    "id": "dmcB5zVBHZO8",
    "outputId": "cd366e47-7f4d-457a-dfe5-3ed5174d4a0c"
   },
   "outputs": [],
   "source": [
    "from johnsnowlabs import *\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "spark = start_spark()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cd4221-fbca-4ca1-86a9-65e6264c4ad1",
   "metadata": {
    "id": "d2cd4221-fbca-4ca1-86a9-65e6264c4ad1"
   },
   "source": [
    "# About Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9835fd-9def-44e4-b022-e8db0f045fec",
   "metadata": {
    "id": "bf9835fd-9def-44e4-b022-e8db0f045fec"
   },
   "source": [
    "__Data Augmentation__ is the process of increase an extracted datapoint with external sources. \n",
    "\n",
    "For example, let's suppose I work with a document which mentions the company _Amazon_. We could be talking about stock prices, or some legal litigations, or just a commercial agreement with a provider, among others.\n",
    "\n",
    "In the document, we can extract `Amazon` using NER as an Organization, but that's all the information available about `Amazon` in that document.\n",
    "\n",
    "Well, with __Data Augmentation__, we can use external sources, as _SEC Edgar, Crunchbase, Nasdaq_ or even _Wikipedia_, to enrich `Amazon` with much more information, allowing us to take better decisions.\n",
    "\n",
    "Let's see how to do it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef8c0e5-6793-4db5-ab39-f6381c9e500d",
   "metadata": {
    "id": "eef8c0e5-6793-4db5-ab39-f6381c9e500d"
   },
   "source": [
    "# Step 1: Name Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612f9fe0-4d7c-4d6e-afc1-47a59b99f529",
   "metadata": {
    "id": "612f9fe0-4d7c-4d6e-afc1-47a59b99f529"
   },
   "source": [
    "Let's suppose we get this news from scrapping the Internet, or from Twitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27f44267-72be-45de-afaa-a2c911195d89",
   "metadata": {
    "id": "27f44267-72be-45de-afaa-a2c911195d89"
   },
   "outputs": [],
   "source": [
    "text = \"Amazon announces new service to help solve supply chain challenges for sellers\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a5e806-9659-4b41-8ab6-38f81b26797f",
   "metadata": {
    "id": "71a5e806-9659-4b41-8ab6-38f81b26797f"
   },
   "source": [
    "We use NER to extract the companies name, in this case, Amazon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb765952-24c2-48b6-8d86-5413b13bd9fa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45399,
     "status": "ok",
     "timestamp": 1664820419875,
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     },
     "user_tz": -120
    },
    "id": "cb765952-24c2-48b6-8d86-5413b13bd9fa",
    "outputId": "995f4eca-f767-4261-a7f1-efff726c9270",
    "tags": []
   },
   "outputs": [],
   "source": [
    "documentAssembler = nlp.DocumentAssembler()\\\n",
    "        .setInputCol(\"text\")\\\n",
    "        .setOutputCol(\"document\")\n",
    "        \n",
    "sentenceDetector = nlp.SentenceDetectorDLModel.pretrained(\"sentence_detector_dl\",\"xx\")\\\n",
    "        .setInputCols([\"document\"])\\\n",
    "        .setOutputCol(\"sentence\")\n",
    "\n",
    "tokenizer = nlp.Tokenizer()\\\n",
    "        .setInputCols([\"sentence\"])\\\n",
    "        .setOutputCol(\"token\")\n",
    "\n",
    "embeddings = nlp.BertEmbeddings.pretrained(\"bert_embeddings_sec_bert_base\",\"en\") \\\n",
    "    .setInputCols([\"sentence\", \"token\"]) \\\n",
    "    .setOutputCol(\"embeddings\")\n",
    "\n",
    "ner_model = finance.NerModel.pretrained(\"finner_orgs_prods_alias\", \"en\", \"finance/models\")\\\n",
    "        .setInputCols([\"sentence\", \"token\", \"embeddings\"])\\\n",
    "        .setOutputCol(\"ner\")\n",
    "        \n",
    "ner_converter = nlp.NerConverter()\\\n",
    "        .setInputCols([\"sentence\",\"token\",\"ner\"])\\\n",
    "        .setOutputCol(\"ner_chunk\")\n",
    "\n",
    "nlp_pipeline = nlp.Pipeline(stages=[\n",
    "        documentAssembler,\n",
    "        sentenceDetector,\n",
    "        tokenizer,\n",
    "        embeddings,\n",
    "        ner_model,\n",
    "        ner_converter,\n",
    "])\n",
    "\n",
    "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "model = nlp_pipeline.fit(empty_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37eae9a4-52e1-400e-a1dd-effc6ed1da35",
   "metadata": {
    "id": "37eae9a4-52e1-400e-a1dd-effc6ed1da35"
   },
   "source": [
    "## We use LightPipelines to get the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a05a20-b9b1-4868-a198-0e950c05a786",
   "metadata": {
    "id": "76a05a20-b9b1-4868-a198-0e950c05a786"
   },
   "outputs": [],
   "source": [
    "lp_ner = nlp.LightPipeline(model)\n",
    "ner_result = lp_ner.annotate(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19545c7d-1738-47be-afdd-5f44236a4a2a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1993,
     "status": "ok",
     "timestamp": 1664820421864,
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     },
     "user_tz": -120
    },
    "id": "19545c7d-1738-47be-afdd-5f44236a4a2a",
    "outputId": "1aaa4316-72f4-4fbd-a155-ab5d7f5fa4e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'document': ['Amazon announces new service to help solve supply chain challenges for sellers'],\n",
       " 'ner_chunk': ['Amazon'],\n",
       " 'token': ['Amazon',\n",
       "  'announces',\n",
       "  'new',\n",
       "  'service',\n",
       "  'to',\n",
       "  'help',\n",
       "  'solve',\n",
       "  'supply',\n",
       "  'chain',\n",
       "  'challenges',\n",
       "  'for',\n",
       "  'sellers'],\n",
       " 'ner': ['B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
       " 'embeddings': ['Amazon',\n",
       "  'announces',\n",
       "  'new',\n",
       "  'service',\n",
       "  'to',\n",
       "  'help',\n",
       "  'solve',\n",
       "  'supply',\n",
       "  'chain',\n",
       "  'challenges',\n",
       "  'for',\n",
       "  'sellers'],\n",
       " 'sentence': ['Amazon announces new service to help solve supply chain challenges for sellers']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe41161-c8fd-467e-9fff-5d4fe1cb5160",
   "metadata": {
    "id": "9fe41161-c8fd-467e-9fff-5d4fe1cb5160"
   },
   "source": [
    "Alright! Amazon has been detected as an organization. \n",
    "\n",
    "Now, let's augment `Amazon` with more information about the company, given that there are no more details in the tweet I can use.\n",
    "\n",
    "But before __augmenting__, there is a very important step we need to carry out: `Company Name Normalization`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3e2808-3550-46d9-835b-f747cac4123c",
   "metadata": {
    "id": "eb3e2808-3550-46d9-835b-f747cac4123c"
   },
   "source": [
    "# Step 2: Company Names Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e55a84c-2806-4a0e-b30f-90a43dc497ca",
   "metadata": {
    "id": "4e55a84c-2806-4a0e-b30f-90a43dc497ca"
   },
   "source": [
    "Let's suppose we want to manually get information about Amazon.\n",
    "\n",
    "Since it's a public US company, we can go to [SEC Edgar's database](https://www.sec.gov/edgar/searchedgar/companysearch) and look for it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f414e7-d727-4b8a-ba8a-8b0c644bb7da",
   "metadata": {
    "id": "13f414e7-d727-4b8a-ba8a-8b0c644bb7da"
   },
   "source": [
    "Unfortunately, `Amazon` is not the official name of the company, which means no entry for `Amazon` is available. That's were __Company Names Normalization__ comes in handy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb8eb7f-1bda-454c-8318-bb4df34f0b6a",
   "metadata": {
    "id": "6eb8eb7f-1bda-454c-8318-bb4df34f0b6a"
   },
   "source": [
    "`Company Name Normalization` is the process of obtaining the name of the company used by data providers, usually the \"official\" name of the company.\n",
    "\n",
    "Sometimes, some data providers may have different versions of the name with different punctuation. For example, for Meta:\n",
    "- Meta Platforms, Inc.\n",
    "- Meta Platforms Inc.\n",
    "- Meta Platforms, Inc\n",
    "- etc\n",
    "\n",
    "So, it's mandatory we do `Company Normalization` taking into account the database / datasource provider we want to extract data from. The data providers we have are:\n",
    "- SEC Edgar\n",
    "- Crunchbase until 2015\n",
    "- Wikidata (in progress)\n",
    "\n",
    "Let's normalize `Amazon` to the official name in _SEC Edgar_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2564fd32-99ec-451c-ae34-2792cf3036ef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 85937,
     "status": "ok",
     "timestamp": 1664820507793,
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     },
     "user_tz": -120
    },
    "id": "2564fd32-99ec-451c-ae34-2792cf3036ef",
    "outputId": "3f54702f-29cf-4474-d958-749e69bad78b"
   },
   "outputs": [],
   "source": [
    "embeddings = nlp.UniversalSentenceEncoder.pretrained(\"tfhub_use\", \"en\") \\\n",
    "      .setInputCols(\"document\") \\\n",
    "      .setOutputCol(\"sentence_embeddings\")\n",
    "    \n",
    "resolver = finance.SentenceEntityResolverModel.pretrained(\"finel_edgar_company_name\", \"en\", \"finance/models\")\\\n",
    "      .setInputCols([\"sentence_embeddings\"]) \\\n",
    "      .setOutputCol(\"resolution\")\\\n",
    "      .setDistanceFunction(\"EUCLIDEAN\")\n",
    "\n",
    "pipelineModel = nlp.PipelineModel(stages = [\n",
    "          documentAssembler,\n",
    "          embeddings,\n",
    "          resolver])\n",
    "\n",
    "lp_res = nlp.LightPipeline(pipelineModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36a6d5f7-6477-4219-acf7-53a95d1ebea3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1664820507794,
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     },
     "user_tz": -120
    },
    "id": "36a6d5f7-6477-4219-acf7-53a95d1ebea3",
    "outputId": "5dc87903-1fa4-43d2-82f4-02c85abe28eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Amazon']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_result['ner_chunk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c319f7b8-fe7e-4408-9960-15e7675a36c1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 991,
     "status": "ok",
     "timestamp": 1664820508777,
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     },
     "user_tz": -120
    },
    "id": "c319f7b8-fe7e-4408-9960-15e7675a36c1",
    "outputId": "99580f72-95b1-47c2-b63e-adf972cd9e8b"
   },
   "outputs": [],
   "source": [
    "el_res = lp_res.annotate(ner_result['ner_chunk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4057823-a4a1-4e24-90cf-dd9b75d5cc3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'document': ['Amazon'],\n",
       "  'sentence_embeddings': ['Amazon'],\n",
       "  'resolution': ['AMAZON COM INC']}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "el_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109efb72-bfae-413b-b1cb-ef1c57b9b66d",
   "metadata": {
    "id": "109efb72-bfae-413b-b1cb-ef1c57b9b66d"
   },
   "source": [
    "Here is our normalized name for Amazon: `AMAZON COM INC`.\n",
    "\n",
    "Now, let's see which information is available in Edgar database for `AMAZON COM INC`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520b8b1d-2754-4338-acc4-d74aeab8a673",
   "metadata": {
    "id": "520b8b1d-2754-4338-acc4-d74aeab8a673"
   },
   "source": [
    "# Steps 1 and 2 in the same pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ed95a6-aa6e-47b5-897e-6430249f9532",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14131,
     "status": "ok",
     "timestamp": 1664820522905,
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     },
     "user_tz": -120
    },
    "id": "46ed95a6-aa6e-47b5-897e-6430249f9532",
    "outputId": "f9671ce2-a459-45f1-942f-72697a9a81fd"
   },
   "outputs": [],
   "source": [
    "documentAssembler = nlp.DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "sentenceDetector = nlp.SentenceDetectorDLModel.pretrained(\"sentence_detector_dl\",\"xx\")\\\n",
    "    .setInputCols([\"document\"])\\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "tokenizer = nlp.Tokenizer()\\\n",
    "    .setInputCols([\"sentence\"])\\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "embeddings = nlp.BertEmbeddings.pretrained(\"bert_embeddings_sec_bert_base\",\"en\") \\\n",
    "    .setInputCols([\"sentence\", \"token\"]) \\\n",
    "    .setOutputCol(\"embeddings\")\n",
    "\n",
    "ner_model = finance.NerModel.pretrained(\"finner_orgs_prods_alias\", \"en\", \"finance/models\")\\\n",
    "    .setInputCols([\"sentence\", \"token\", \"embeddings\"])\\\n",
    "    .setOutputCol(\"ner\")\n",
    "\n",
    "ner_converter = nlp.NerConverter()\\\n",
    "    .setInputCols([\"sentence\",\"token\",\"ner\"])\\\n",
    "    .setOutputCol(\"ner_chunk\")\n",
    "\n",
    "chunk2doc = nlp.Chunk2Doc()\\\n",
    "    .setInputCols(\"ner_chunk\")\\\n",
    "    .setOutputCol(\"ner_chunk_doc\")\n",
    "\n",
    "sentence_embeddings = nlp.UniversalSentenceEncoder.pretrained(\"tfhub_use\", \"en\") \\\n",
    "    .setInputCols(\"ner_chunk_doc\") \\\n",
    "    .setOutputCol(\"sentence_embeddings\")\n",
    "\n",
    "resolver = finance.SentenceEntityResolverModel.pretrained(\"finel_edgar_company_name\", \"en\", \"finance/models\")\\\n",
    "    .setInputCols([\"sentence_embeddings\"]) \\\n",
    "    .setOutputCol(\"resolution\")\\\n",
    "    .setDistanceFunction(\"EUCLIDEAN\")\n",
    "\n",
    "nlp_pipeline = nlp.Pipeline(stages=[\n",
    "    documentAssembler,\n",
    "    sentenceDetector,\n",
    "    tokenizer,\n",
    "    embeddings,\n",
    "    ner_model,\n",
    "    ner_converter,\n",
    "    chunk2doc,\n",
    "    sentence_embeddings,\n",
    "    resolver\n",
    "    ])\n",
    "\n",
    "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "model = nlp_pipeline.fit(empty_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9647e98c-6a53-4892-93ec-c1187110b024",
   "metadata": {
    "id": "9647e98c-6a53-4892-93ec-c1187110b024"
   },
   "outputs": [],
   "source": [
    "lp_model = nlp.LightPipeline(model)\n",
    "el_res = lp_model.annotate(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b29c1146-c38c-4def-8c38-30f494461d3b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1096,
     "status": "ok",
     "timestamp": 1664820523995,
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     },
     "user_tz": -120
    },
    "id": "b29c1146-c38c-4def-8c38-30f494461d3b",
    "outputId": "f252404c-8527-4c57-c5d5-f83828ed41f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'document': ['Amazon announces new service to help solve supply chain challenges for sellers'],\n",
       " 'ner_chunk': ['Amazon'],\n",
       " 'sentence_embeddings': ['Amazon'],\n",
       " 'resolution': ['AMAZON COM INC'],\n",
       " 'token': ['Amazon',\n",
       "  'announces',\n",
       "  'new',\n",
       "  'service',\n",
       "  'to',\n",
       "  'help',\n",
       "  'solve',\n",
       "  'supply',\n",
       "  'chain',\n",
       "  'challenges',\n",
       "  'for',\n",
       "  'sellers'],\n",
       " 'ner': ['B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'],\n",
       " 'embeddings': ['Amazon',\n",
       "  'announces',\n",
       "  'new',\n",
       "  'service',\n",
       "  'to',\n",
       "  'help',\n",
       "  'solve',\n",
       "  'supply',\n",
       "  'chain',\n",
       "  'challenges',\n",
       "  'for',\n",
       "  'sellers'],\n",
       " 'ner_chunk_doc': ['Amazon'],\n",
       " 'sentence': ['Amazon announces new service to help solve supply chain challenges for sellers']}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "el_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e51e16-56a2-4dad-a27c-1047a36ecea3",
   "metadata": {
    "id": "85e51e16-56a2-4dad-a27c-1047a36ecea3"
   },
   "source": [
    "# Step 3: Data Augmentation with Chunk Mappers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dff3ed-08f0-4961-ba54-bbffb2606a81",
   "metadata": {
    "id": "39dff3ed-08f0-4961-ba54-bbffb2606a81"
   },
   "source": [
    "The component which carries out __Data Augmentation__ is called `ChunkMapper`.\n",
    "\n",
    "It's name comes from the way it works: it uses a _Ner Chunk_ to map it to an external data source.\n",
    "\n",
    "As a result, you will get a JSON with a dictionary of additional fields and their values. \n",
    "\n",
    "Let's take a look at how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b246357e-0ab7-489b-9dc0-6d74d3eb97ef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35321,
     "status": "ok",
     "timestamp": 1664820559312,
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     },
     "user_tz": -120
    },
    "id": "b246357e-0ab7-489b-9dc0-6d74d3eb97ef",
    "outputId": "bd2292f7-e675-4a30-e51f-e893a604d4ad"
   },
   "outputs": [],
   "source": [
    "chunkAssembler = nlp.Doc2Chunk() \\\n",
    "    .setInputCols(\"document\") \\\n",
    "    .setOutputCol(\"chunk\") \\\n",
    "    .setIsArray(False)\n",
    "\n",
    "CM = finance.ChunkMapperModel().pretrained(\"finmapper_edgar_companyname\", \"en\", \"finance/models\")\\\n",
    "    .setInputCols([\"chunk\"])\\\n",
    "    .setOutputCol(\"mappings\")\n",
    "\n",
    "cm_pipeline = nlp.Pipeline(stages=[\n",
    "    documentAssembler, \n",
    "    chunkAssembler, \n",
    "    CM])\n",
    "fit_cm_pipeline = cm_pipeline.fit(empty_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "340f193f-dabd-4e41-96e0-0afe0a22ed8b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1232,
     "status": "ok",
     "timestamp": 1664820560539,
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     },
     "user_tz": -120
    },
    "id": "340f193f-dabd-4e41-96e0-0afe0a22ed8b",
    "outputId": "ca55d63a-f111-4f91-fe6b-1fbaf1990171"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|          text|\n",
      "+--------------+\n",
      "|AMAZON COM INC|\n",
      "+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# LightPipelines don't support Doc2Chunk, so we will use here usual transform\n",
    "\n",
    "df = spark.createDataFrame([el_res['resolution']]).toDF(\"text\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b6729d6-32a9-4cea-b88f-0b6b7bf04d83",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 973,
     "status": "ok",
     "timestamp": 1664820561507,
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     },
     "user_tz": -120
    },
    "id": "1b6729d6-32a9-4cea-b88f-0b6b7bf04d83",
    "outputId": "809c62a0-ef11-488c-c1e1-e547ec439f8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+--------------------+--------------------+\n",
      "|          text|            document|               chunk|            mappings|\n",
      "+--------------+--------------------+--------------------+--------------------+\n",
      "|AMAZON COM INC|[{document, 0, 13...|[{chunk, 0, 13, A...|[{labeled_depende...|\n",
      "+--------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = fit_cm_pipeline.transform(df)\n",
    "res.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c2d4a37d-b0a1-413a-9e36-5489396a042d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1664820561508,
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     },
     "user_tz": -120
    },
    "id": "c2d4a37d-b0a1-413a-9e36-5489396a042d",
    "outputId": "e641d657-797e-402a-b930-3326cad5fdab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(text='AMAZON COM INC', document=[Row(annotatorType='document', begin=0, end=13, result='AMAZON COM INC', metadata={'sentence': '0'}, embeddings=[])], chunk=[Row(annotatorType='chunk', begin=0, end=13, result='AMAZON COM INC', metadata={'sentence': '0', 'chunk': '0'}, embeddings=[])], mappings=[Row(annotatorType='labeled_dependency', begin=0, end=13, result='AMAZON COM INC', metadata={'sentence': '0', 'chunk': '0', 'entity': 'AMAZON COM INC', 'relation': 'name', 'all_relations': ''}, embeddings=[]), Row(annotatorType='labeled_dependency', begin=0, end=13, result='RETAIL-CATALOG & MAIL-ORDER HOUSES [5961]', metadata={'sentence': '0', 'chunk': '0', 'entity': 'AMAZON COM INC', 'relation': 'sic', 'all_relations': '[5961'}, embeddings=[]), Row(annotatorType='labeled_dependency', begin=0, end=13, result='5961', metadata={'sentence': '0', 'chunk': '0', 'entity': 'AMAZON COM INC', 'relation': 'sic_code', 'all_relations': '0'}, embeddings=[]), Row(annotatorType='labeled_dependency', begin=0, end=13, result='911646860', metadata={'sentence': '0', 'chunk': '0', 'entity': 'AMAZON COM INC', 'relation': 'irs_number', 'all_relations': '0:::261631624'}, embeddings=[]), Row(annotatorType='labeled_dependency', begin=0, end=13, result='1231', metadata={'sentence': '0', 'chunk': '0', 'entity': 'AMAZON COM INC', 'relation': 'fiscal_year_end', 'all_relations': '0'}, embeddings=[]), Row(annotatorType='labeled_dependency', begin=0, end=13, result='WA', metadata={'sentence': '0', 'chunk': '0', 'entity': 'AMAZON COM INC', 'relation': 'state_location', 'all_relations': ''}, embeddings=[]), Row(annotatorType='labeled_dependency', begin=0, end=13, result='DE', metadata={'sentence': '0', 'chunk': '0', 'entity': 'AMAZON COM INC', 'relation': 'state_incorporation', 'all_relations': ''}, embeddings=[]), Row(annotatorType='labeled_dependency', begin=0, end=13, result='410 TERRY AVENUE NORTH', metadata={'sentence': '0', 'chunk': '0', 'entity': 'AMAZON COM INC', 'relation': 'business_street', 'all_relations': '1200 12TH AVENUE S SUITE 1200'}, embeddings=[]), Row(annotatorType='labeled_dependency', begin=0, end=13, result='SEATTLE', metadata={'sentence': '0', 'chunk': '0', 'entity': 'AMAZON COM INC', 'relation': 'business_city', 'all_relations': ''}, embeddings=[]), Row(annotatorType='labeled_dependency', begin=0, end=13, result='WA', metadata={'sentence': '0', 'chunk': '0', 'entity': 'AMAZON COM INC', 'relation': 'business_state', 'all_relations': ''}, embeddings=[]), Row(annotatorType='labeled_dependency', begin=0, end=13, result='98109', metadata={'sentence': '0', 'chunk': '0', 'entity': 'AMAZON COM INC', 'relation': 'business_zip', 'all_relations': '98144'}, embeddings=[]), Row(annotatorType='labeled_dependency', begin=0, end=13, result='2062661000', metadata={'sentence': '0', 'chunk': '0', 'entity': 'AMAZON COM INC', 'relation': 'business_phone', 'all_relations': ''}, embeddings=[]), Row(annotatorType='labeled_dependency', begin=0, end=13, result='ABX Holdings, Inc.', metadata={'sentence': '0', 'chunk': '0', 'entity': 'AMAZON COM INC', 'relation': 'former_name', 'all_relations': 'ABX AIR INC'}, embeddings=[]), Row(annotatorType='labeled_dependency', begin=0, end=13, result='20080102', metadata={'sentence': '0', 'chunk': '0', 'entity': 'AMAZON COM INC', 'relation': 'former_name_date', 'all_relations': '19950728'}, embeddings=[]), Row(annotatorType='labeled_dependency', begin=0, end=13, result='2017-02-10', metadata={'sentence': '0', 'chunk': '0', 'entity': 'AMAZON COM INC', 'relation': 'date', 'all_relations': '2016-01-29:::2016-02-10:::2016-09-08:::2016-10-28:::2019-02-01:::2019-10-25:::2018-02-02:::2018-07-27:::2015-01-30:::2015-07-24:::2015-10-23:::2015-12-04:::2014-01-31:::2014-01-30:::2014-02-11:::2014-02-18:::2014-02-19:::2014-02-13:::2014-02-20:::2014-03-06:::2014-04-09:::2014-04-04:::2013-01-30:::2012-02-01:::2011-01-28:::2011-07-27:::2011-10-26:::2022-02-04:::2022-07-29:::2021-02-03:::2021-04-08:::2020-01-31:::2020-05-01:::2020-10-30:::2010-01-29:::2010-07-23:::2010-10-22:::2009-01-30:::2009-07-24:::2009-10-23:::2008-02-11:::2008-07-25:::2007-02-16:::2007-04-26:::2007-07-26:::2007-10-25:::2006-02-17:::2006-07-27:::2006-10-26:::2005-03-11:::2005-07-28:::2004-02-25:::2004-04-23:::2003-02-19:::2003-07-24:::2003-09-24:::2002-01-24:::2003-10-24:::2002-07-26:::2002-10-25:::2000-08-02:::2000-10-30'}, embeddings=[]), Row(annotatorType='labeled_dependency', begin=0, end=13, result='1018724', metadata={'sentence': '0', 'chunk': '0', 'entity': 'AMAZON COM INC', 'relation': 'company_id', 'all_relations': ''}, embeddings=[])])]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = res.collect()\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd37fe7a-6823-4ab3-a41e-e1e711fdbbb8",
   "metadata": {
    "id": "bd37fe7a-6823-4ab3-a41e-e1e711fdbbb8"
   },
   "outputs": [],
   "source": [
    "json_dict = dict()\n",
    "for n in r[0]['mappings']:\n",
    "    json_dict[n.metadata['relation']] = str(n.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35e22829-8c0d-4853-a896-cc9502a567b1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1664820561508,
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     },
     "user_tz": -120
    },
    "id": "35e22829-8c0d-4853-a896-cc9502a567b1",
    "outputId": "0a22ebaa-dab7-4583-c697-d7c8d2c848b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"business_city\": \"SEATTLE\",\n",
      "    \"business_phone\": \"2062661000\",\n",
      "    \"business_state\": \"WA\",\n",
      "    \"business_street\": \"410 TERRY AVENUE NORTH\",\n",
      "    \"business_zip\": \"98109\",\n",
      "    \"company_id\": \"1018724\",\n",
      "    \"date\": \"2017-02-10\",\n",
      "    \"fiscal_year_end\": \"1231\",\n",
      "    \"former_name\": \"ABX Holdings, Inc.\",\n",
      "    \"former_name_date\": \"20080102\",\n",
      "    \"irs_number\": \"911646860\",\n",
      "    \"name\": \"AMAZON COM INC\",\n",
      "    \"sic\": \"RETAIL-CATALOG & MAIL-ORDER HOUSES [5961]\",\n",
      "    \"sic_code\": \"5961\",\n",
      "    \"state_incorporation\": \"DE\",\n",
      "    \"state_location\": \"WA\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(json_dict, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5c162c-e2d2-40f2-8fc3-44a97c899a79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "jsl4.2.3",
   "language": "python",
   "name": "jsl4.2.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "ca1c4b8877e01dec1d65bc94ac0771fb7b4e7d433b24c0ced0afdc05f796f65d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
