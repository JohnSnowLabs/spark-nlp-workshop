{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db5f4f9a-7776-42b3-8758-85624d4c15ea",
   "metadata": {
    "id": "db5f4f9a-7776-42b3-8758-85624d4c15ea"
   },
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212325cc-182f-4565-abed-9b46864d6d69",
   "metadata": {
    "id": "212325cc-182f-4565-abed-9b46864d6d69"
   },
   "source": [
    "# Financial Named Entity Recognition (NER) and Zero-shot NER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b67567-4afc-4188-a087-34aa0f646c65",
   "metadata": {
    "id": "okhT7AcXxben"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3bfe78-679b-4c40-a243-fe0070b720db",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 115199,
     "status": "ok",
     "timestamp": 1664816113389,
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     },
     "user_tz": -120
    },
    "id": "dmcB5zVBHZO8",
    "outputId": "cd366e47-7f4d-457a-dfe5-3ed5174d4a0c"
   },
   "outputs": [],
   "source": [
    "from johnsnowlabs import *\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "spark = start_spark()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766fe57a-fcd5-4072-99d0-7626c7888493",
   "metadata": {
    "id": "766fe57a-fcd5-4072-99d0-7626c7888493"
   },
   "source": [
    "## NER Model Implementation in Spark NLP\n",
    "\n",
    "  The deep neural network architecture for NER model in Spark NLP is BiLSTM-CNN-Char framework. a slightly modified version of the architecture proposed by Jason PC Chiu and Eric Nichols ([Named Entity Recognition with Bidirectional LSTM-CNNs](https://arxiv.org/abs/1511.08308)). It is a neural network architecture that automatically detects word and character-level features using a hybrid bidirectional LSTM and CNN architecture, eliminating the need for most feature engineering steps.\n",
    "  \n",
    "  In the original framework, the CNN extracts a fixed length feature vector from character-level features. For each word, these vectors are concatenated and fed to the BLSTM network and then to the output layers. They employed a stacked bi-directional recurrent neural network with long short-term memory units to transform word features into named entity tag scores. The extracted features of each word are fed into a forward LSTM network and a backward LSTM network. The output of each network at each time step is decoded by a linear layer and a log-softmax layer into log-probabilities for each tag category. These two vectors are then simply added together to produce the final output. In the architecture of the proposed framework in the original paper, 50-dimensional pretrained word embeddings is used for word features, 25-dimension character embeddings is used for char features, and capitalization features (allCaps, upperInitial, lowercase, mixedCaps, noinfo) are used for case features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee4b28c-dda1-4708-9240-edb6fe105013",
   "metadata": {
    "id": "bee4b28c-dda1-4708-9240-edb6fe105013"
   },
   "source": [
    "### Finance SEC NER Model\n",
    "\n",
    "This model detects Organizations (ORG), People (PER) and Locations (LOC) in financial texts. It was trained using manual annotations, conll2003 and financial documents obtained from U.S. Security and Exchange Commission (SEC) filings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889067cf-a64c-4f3a-b27a-51fdca438599",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 90653,
     "status": "ok",
     "timestamp": 1664819852014,
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     },
     "user_tz": -120
    },
    "id": "889067cf-a64c-4f3a-b27a-51fdca438599",
    "outputId": "fdf85ca0-f99b-47ff-bc26-8ddb816fc064",
    "tags": []
   },
   "outputs": [],
   "source": [
    "documentAssembler = nlp.DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "# Consider using SentenceDetector with rules/patterns to get smaller chunks from long sentences\n",
    "sentence_detector = nlp.SentenceDetectorDLModel.pretrained(\"sentence_detector_dl\", \"xx\")\\\n",
    "    .setInputCols([\"document\"])\\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "tokenizer = nlp.Tokenizer()\\\n",
    "    .setInputCols([\"sentence\"])\\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "embeddings = nlp.BertEmbeddings.pretrained(\"bert_embeddings_legal_bert_base_uncased\",\"en\")\\\n",
    "    .setInputCols([\"sentence\", \"token\"])\\\n",
    "    .setOutputCol(\"embeddings\")\n",
    "\n",
    "ner_model = finance.NerModel.pretrained(\"finner_sec_conll\", \"en\", \"finance/models\") \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"embeddings\"])\\\n",
    "    .setOutputCol(\"ner\")\n",
    "\n",
    "ner_converter = nlp.NerConverter()\\\n",
    "    .setInputCols([\"sentence\",\"token\",\"ner\"])\\\n",
    "    .setOutputCol(\"ner_chunk\")\n",
    "\n",
    "pipeline = nlp.Pipeline(stages=[\n",
    "    documentAssembler,\n",
    "    sentence_detector,\n",
    "    tokenizer,\n",
    "    embeddings,\n",
    "    ner_model,\n",
    "    ner_converter])\n",
    "\n",
    "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "model = pipeline.fit(empty_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46fa5d8a-a5f0-4173-a21e-1df147d1b2e8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1664819852014,
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     },
     "user_tz": -120
    },
    "id": "46fa5d8a-a5f0-4173-a21e-1df147d1b2e8",
    "outputId": "c4da9bf2-46d3-48d5-be60-74e518717363"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DocumentAssembler_f06d8eaf5696,\n",
       " SentenceDetectorDLModel_8aaebf7e098e,\n",
       " REGEX_TOKENIZER_4d596af282cf,\n",
       " BERT_EMBEDDINGS_ed0baec430e2,\n",
       " MedicalNerModel_5a7a3c15ca97,\n",
       " NerConverter_dd4450035bbd]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## you can see pipeline stages with this code\n",
    "\n",
    "model.stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af5baafe-793a-4022-ac3c-95c5345ef606",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1664819852015,
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     },
     "user_tz": -120
    },
    "id": "af5baafe-793a-4022-ac3c-95c5345ef606",
    "outputId": "969a9b88-1fc3-4a0f-9d67-726e43811b09"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-ORG', 'I-ORG', 'B-PER', 'I-PER', 'B-LOC', 'I-LOC']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## With this code, you can see which labels your NER model has.\n",
    "\n",
    "ner_model.getClasses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5954047c-ec79-47ec-98fa-44c74b492140",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1664819852015,
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     },
     "user_tz": -120
    },
    "id": "5954047c-ec79-47ec-98fa-44c74b492140",
    "outputId": "8a1c2431-ed8a-40fa-c637-2a826b4d77a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='MedicalNerModel_5a7a3c15ca97', name='inferenceBatchSize', doc='number of sentences to process in a single batch during inference'): 1,\n",
       " Param(parent='MedicalNerModel_5a7a3c15ca97', name='labelCasing', doc='Setting all labels of the NER models upper/lower case. values upper|lower'): '',\n",
       " Param(parent='MedicalNerModel_5a7a3c15ca97', name='lazyAnnotator', doc='Whether this AnnotatorModel acts as lazy in RecursivePipelines'): False,\n",
       " Param(parent='MedicalNerModel_5a7a3c15ca97', name='includeConfidence', doc='whether to include confidence scores in annotation metadata'): True,\n",
       " Param(parent='MedicalNerModel_5a7a3c15ca97', name='includeAllConfidenceScores', doc='whether to include all confidence scores in annotation metadata or just the score of the predicted tag'): False,\n",
       " Param(parent='MedicalNerModel_5a7a3c15ca97', name='batchSize', doc='Size of every batch'): 128,\n",
       " Param(parent='MedicalNerModel_5a7a3c15ca97', name='classes', doc='get the tags used to trained this MedicalNerModel'): ['O',\n",
       "  'B-ORG',\n",
       "  'I-ORG',\n",
       "  'B-PER',\n",
       "  'I-PER',\n",
       "  'B-LOC',\n",
       "  'I-LOC'],\n",
       " Param(parent='MedicalNerModel_5a7a3c15ca97', name='inputCols', doc='previous annotations columns, if renamed'): ['sentence',\n",
       "  'token',\n",
       "  'embeddings'],\n",
       " Param(parent='MedicalNerModel_5a7a3c15ca97', name='outputCol', doc='output annotation column. can be left default.'): 'ner',\n",
       " Param(parent='MedicalNerModel_5a7a3c15ca97', name='storageRef', doc='unique reference name for identification'): 'bert_embeddings_legal_bert_base_uncased_en'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_model.extractParamMap()\n",
    "\n",
    "# With extractParamMap() function, you can see the parameters of any annotators you are using."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7d801c-fcc0-458c-9835-b6cbb0149f38",
   "metadata": {
    "id": "9e7d801c-fcc0-458c-9835-b6cbb0149f38"
   },
   "source": [
    "#### Sample Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d74636-3490-4a24-9dc2-4f3f023c8909",
   "metadata": {
    "id": "00d74636-3490-4a24-9dc2-4f3f023c8909"
   },
   "outputs": [],
   "source": [
    "text = '''December 2007 SUBORDINATED LOAN AGREEMENT. THIS LOAN AGREEMENT is made on 7th December, 2007 BETWEEN: (1) SILICIUM DE PROVENCE S.A.S., a private company with limited liability, incorporated under the laws of France, whose registered office is situated at Usine de Saint Auban, France, represented by Mr.Frank Wouters, hereinafter referred to as the \"Borrower\", and ( 2 ) EVERGREEN SOLAR INC., a company incorporated in Delaware, U.S.A., with registered number 2426798, whose registered office is situated at Bartlett Street, Marlboro, Massachusetts, U.S.A. represented by Richard Chleboski, hereinafter referred to as \"Lender\" '''\n",
    "\n",
    "df = spark.createDataFrame([[text]]).toDF(\"text\")\n",
    "\n",
    "result = model.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7c211c-448e-494f-9f83-3274b9ca0aba",
   "metadata": {
    "id": "4c7c211c-448e-494f-9f83-3274b9ca0aba"
   },
   "source": [
    "#### Getting Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec9a99c6-4d22-4837-aed9-425b8f9efed6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12518,
     "status": "ok",
     "timestamp": 1664819866119,
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     },
     "user_tz": -120
    },
    "id": "ec9a99c6-4d22-4837-aed9-425b8f9efed6",
    "outputId": "744ae435-fdbd-4d47-95fb-4cce739e39da",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+----------+\n",
      "|        token|ner_label|confidence|\n",
      "+-------------+---------+----------+\n",
      "|     December|        O|       1.0|\n",
      "|         2007|        O|       1.0|\n",
      "| SUBORDINATED|        O|    0.9933|\n",
      "|         LOAN|        O|    0.8545|\n",
      "|    AGREEMENT|        O|    0.9997|\n",
      "|            .|        O|    0.9999|\n",
      "|         THIS|        O|       1.0|\n",
      "|         LOAN|        O|       1.0|\n",
      "|    AGREEMENT|        O|       1.0|\n",
      "|           is|        O|       1.0|\n",
      "|         made|        O|       1.0|\n",
      "|           on|        O|       1.0|\n",
      "|          7th|        O|       1.0|\n",
      "|     December|        O|       1.0|\n",
      "|            ,|        O|       1.0|\n",
      "|         2007|        O|       1.0|\n",
      "|      BETWEEN|        O|       1.0|\n",
      "|            :|        O|       1.0|\n",
      "|            (|        O|       1.0|\n",
      "|            1|        O|       1.0|\n",
      "|            )|        O|       1.0|\n",
      "|     SILICIUM|    B-ORG|    0.9569|\n",
      "|           DE|    I-ORG|    0.8519|\n",
      "|     PROVENCE|    I-ORG|    0.9618|\n",
      "|        S.A.S|    I-ORG|    0.9977|\n",
      "|           .,|        O|    0.9998|\n",
      "|            a|        O|       1.0|\n",
      "|      private|        O|       1.0|\n",
      "|      company|        O|       1.0|\n",
      "|         with|        O|       1.0|\n",
      "|      limited|        O|       1.0|\n",
      "|    liability|        O|       1.0|\n",
      "|            ,|        O|       1.0|\n",
      "| incorporated|        O|       1.0|\n",
      "|        under|        O|       1.0|\n",
      "|          the|        O|       1.0|\n",
      "|         laws|        O|       1.0|\n",
      "|           of|        O|       1.0|\n",
      "|       France|    B-LOC|    0.9921|\n",
      "|            ,|        O|       1.0|\n",
      "|        whose|        O|       1.0|\n",
      "|   registered|        O|       1.0|\n",
      "|       office|        O|       1.0|\n",
      "|           is|        O|       1.0|\n",
      "|     situated|        O|       1.0|\n",
      "|           at|        O|       1.0|\n",
      "|        Usine|    B-LOC|    0.9698|\n",
      "|           de|    I-LOC|    0.9942|\n",
      "|        Saint|    I-LOC|    0.9949|\n",
      "|        Auban|    I-LOC|    0.9983|\n",
      "|            ,|        O|     0.999|\n",
      "|       France|    B-LOC|    0.9928|\n",
      "|            ,|        O|    0.9999|\n",
      "|  represented|        O|       1.0|\n",
      "|           by|        O|       1.0|\n",
      "|     Mr.Frank|    B-PER|    0.9707|\n",
      "|      Wouters|    I-PER|    0.9992|\n",
      "|            ,|        O|       1.0|\n",
      "|  hereinafter|        O|       1.0|\n",
      "|     referred|        O|       1.0|\n",
      "|           to|        O|    0.9999|\n",
      "|           as|        O|       1.0|\n",
      "|          the|        O|       1.0|\n",
      "|            \"|        O|       1.0|\n",
      "|     Borrower|    B-PER|    0.9982|\n",
      "|           \",|        O|       1.0|\n",
      "|          and|        O|       1.0|\n",
      "|            (|        O|       1.0|\n",
      "|            2|        O|       1.0|\n",
      "|            )|        O|       1.0|\n",
      "|    EVERGREEN|    B-ORG|    0.9991|\n",
      "|        SOLAR|    I-ORG|    0.9996|\n",
      "|          INC|    I-ORG|    0.9999|\n",
      "|            .|        O|    0.9995|\n",
      "|            ,|        O|       1.0|\n",
      "|            a|        O|       1.0|\n",
      "|      company|        O|       1.0|\n",
      "| incorporated|        O|       1.0|\n",
      "|           in|        O|       1.0|\n",
      "|     Delaware|    B-LOC|    0.9976|\n",
      "|            ,|        O|       1.0|\n",
      "|        U.S.A|    B-LOC|    0.9998|\n",
      "|           .,|        O|    0.9999|\n",
      "|         with|        O|       1.0|\n",
      "|   registered|        O|       1.0|\n",
      "|       number|        O|       1.0|\n",
      "|      2426798|        O|       1.0|\n",
      "|            ,|        O|       1.0|\n",
      "|        whose|        O|       1.0|\n",
      "|   registered|        O|       1.0|\n",
      "|       office|        O|       1.0|\n",
      "|           is|        O|       1.0|\n",
      "|     situated|        O|    0.9998|\n",
      "|           at|        O|    0.9993|\n",
      "|     Bartlett|    B-LOC|    0.9982|\n",
      "|       Street|    I-LOC|       1.0|\n",
      "|            ,|        O|    0.9903|\n",
      "|     Marlboro|    B-LOC|    0.9923|\n",
      "|            ,|        O|    0.9987|\n",
      "|Massachusetts|    B-LOC|    0.6154|\n",
      "|            ,|        O|    0.9992|\n",
      "|        U.S.A|    B-LOC|    0.9995|\n",
      "|            .|        O|    0.9978|\n",
      "|  represented|        O|       1.0|\n",
      "|           by|        O|       1.0|\n",
      "|      Richard|    B-PER|       1.0|\n",
      "|    Chleboski|    I-PER|    0.9994|\n",
      "|            ,|        O|       1.0|\n",
      "|  hereinafter|        O|       1.0|\n",
      "|     referred|        O|       1.0|\n",
      "|           to|        O|     0.999|\n",
      "|           as|        O|    0.9999|\n",
      "|            \"|        O|       1.0|\n",
      "|       Lender|    B-PER|    0.9998|\n",
      "|            \"|        O|    0.9997|\n",
      "+-------------+---------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "result.select(F.explode(F.arrays_zip(result.token.result, result.ner.result, result.ner.metadata)).alias(\"cols\"))\\\n",
    "                  .select(F.expr(\"cols['0']\").alias(\"token\"),\n",
    "                          F.expr(\"cols['1']\").alias(\"ner_label\"),\n",
    "                          F.expr(\"cols['2']['confidence']\").alias(\"confidence\")).show(200, truncate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "865dce29-ece0-45f6-8f5b-9028292523f0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3910,
     "status": "ok",
     "timestamp": 1664819870025,
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     },
     "user_tz": -120
    },
    "id": "865dce29-ece0-45f6-8f5b-9028292523f0",
    "outputId": "b65aa790-53ad-492b-a874-f4c11e30a8b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+---------+----------+\n",
      "|chunk                     |ner_label|confidence|\n",
      "+--------------------------+---------+----------+\n",
      "|SILICIUM DE PROVENCE S.A.S|ORG      |0.94207495|\n",
      "|France                    |LOC      |0.9921    |\n",
      "|Usine de Saint Auban      |LOC      |0.9893    |\n",
      "|France                    |LOC      |0.9928    |\n",
      "|Mr.Frank Wouters          |PER      |0.98495   |\n",
      "|Borrower                  |PER      |0.9982    |\n",
      "|EVERGREEN SOLAR INC       |ORG      |0.99953336|\n",
      "|Delaware                  |LOC      |0.9976    |\n",
      "|U.S.A                     |LOC      |0.9998    |\n",
      "|Bartlett Street           |LOC      |0.99909997|\n",
      "|Marlboro                  |LOC      |0.9923    |\n",
      "|Massachusetts             |LOC      |0.6154    |\n",
      "|U.S.A                     |LOC      |0.9995    |\n",
      "|Richard Chleboski         |PER      |0.9997    |\n",
      "|Lender                    |PER      |0.9998    |\n",
      "+--------------------------+---------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result.select(F.explode(F.arrays_zip(result.ner_chunk.result, result.ner_chunk.metadata)).alias(\"cols\"))\\\n",
    "      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
    "              F.expr(\"cols['1']['entity']\").alias(\"ner_label\"),\n",
    "              F.expr(\"cols['1']['confidence']\").alias(\"confidence\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47e34e0-3633-4202-afdf-63a0f2475520",
   "metadata": {
    "id": "b47e34e0-3633-4202-afdf-63a0f2475520"
   },
   "source": [
    "#### Getting Result with LightPipeline\n",
    "\n",
    "LightPipelines are Spark NLP specific Pipelines, equivalent to Spark ML Pipeline, but meant to deal with smaller amounts of data. They’re useful working with small datasets, debugging results, or when running either training or prediction from an API that serves one-off requests.\n",
    "\n",
    "Spark NLP LightPipelines are Spark ML pipelines converted into a single machine but the multi-threaded task, becoming more than 10x times faster for smaller amounts of data (small is relative, but 50k sentences are roughly a good maximum). To use them, we simply plug in a trained (fitted) pipeline and then annotate a plain text. We don't even need to convert the input text to DataFrame in order to feed it into a pipeline that's accepting DataFrame as an input in the first place. This feature would be quite useful when it comes to getting a prediction for a few lines of text from a trained ML model.\n",
    "\n",
    " **It is nearly 10x faster than using Spark ML Pipeline**\n",
    "\n",
    "For more details:\n",
    "[https://medium.com/spark-nlp/spark-nlp-101-lightpipeline-a544e93f20f1](https://medium.com/spark-nlp/spark-nlp-101-lightpipeline-a544e93f20f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22dd0c2-c63d-43c8-bc96-2f7cead3553b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 504
    },
    "executionInfo": {
     "elapsed": 4622,
     "status": "ok",
     "timestamp": 1664819874643,
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     },
     "user_tz": -120
    },
    "id": "f22dd0c2-c63d-43c8-bc96-2f7cead3553b",
    "outputId": "1dc35522-c620-4052-fbab-8364c52fe16f"
   },
   "outputs": [],
   "source": [
    "light_model = nlp.LightPipeline(model)\n",
    "\n",
    "light_result = light_model.fullAnnotate(text)\n",
    "\n",
    "chunks = []\n",
    "entities = []\n",
    "sentence= []\n",
    "begin = []\n",
    "end = []\n",
    "\n",
    "for n in light_result[0]['ner_chunk']:\n",
    "        \n",
    "    begin.append(n.begin)\n",
    "    end.append(n.end)\n",
    "    chunks.append(n.result)\n",
    "    entities.append(n.metadata['entity']) \n",
    "    sentence.append(n.metadata['sentence'])\n",
    "    \n",
    "    \n",
    "\n",
    "df = pd.DataFrame({'chunks':chunks, 'begin': begin, 'end':end, \n",
    "                   'sentence_id':sentence, 'entities':entities})\n",
    "\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e91726a-2fd2-4432-a3ff-fe5238b00e9d",
   "metadata": {
    "id": "0e91726a-2fd2-4432-a3ff-fe5238b00e9d"
   },
   "source": [
    "#### NER Visualizer\n",
    "\n",
    "For saving the visualization result as html, provide `save_path` parameter in the display function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f9e05ec-1724-4d53-b4e2-68e454c4e3bb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1664819874644,
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     },
     "user_tz": -120
    },
    "id": "1f9e05ec-1724-4d53-b4e2-68e454c4e3bb",
    "outputId": "c1ff868b-f852-4992-bb6b-3d4b9c0ba58d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    @import url('https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700&display=swap');\n",
       "    @import url('https://fonts.googleapis.com/css2?family=Vistol Regular:wght@300;400;500;600;700&display=swap');\n",
       "    \n",
       "    .spark-nlp-display-scroll-entities {\n",
       "        border: 1px solid #E7EDF0;\n",
       "        border-radius: 3px;\n",
       "        text-align: justify;\n",
       "        \n",
       "    }\n",
       "    .spark-nlp-display-scroll-entities span {  \n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        color: #536B76;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "    }\n",
       "    \n",
       "    .spark-nlp-display-entity-wrapper{\n",
       "    \n",
       "        display: inline-grid;\n",
       "        text-align: center;\n",
       "        border-radius: 4px;\n",
       "        margin: 0 2px 5px 2px;\n",
       "        padding: 1px\n",
       "    }\n",
       "    .spark-nlp-display-entity-name{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "        \n",
       "        background: #f1f2f3;\n",
       "        border-width: medium;\n",
       "        text-align: center;\n",
       "        \n",
       "        font-weight: 400;\n",
       "        \n",
       "        border-radius: 5px;\n",
       "        padding: 2px 5px;\n",
       "        display: block;\n",
       "        margin: 3px 2px;\n",
       "    \n",
       "    }\n",
       "    .spark-nlp-display-entity-type{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        color: #ffffff;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "        \n",
       "        text-transform: uppercase;\n",
       "        \n",
       "        font-weight: 500;\n",
       "\n",
       "        display: block;\n",
       "        padding: 3px 5px;\n",
       "    }\n",
       "    \n",
       "    .spark-nlp-display-entity-resolution{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        color: #ffffff;\n",
       "        font-family: 'Vistol Regular', sans-serif !important;\n",
       "        \n",
       "        text-transform: uppercase;\n",
       "        \n",
       "        font-weight: 500;\n",
       "\n",
       "        display: block;\n",
       "        padding: 3px 5px;\n",
       "    }\n",
       "    \n",
       "    .spark-nlp-display-others{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "        \n",
       "        font-weight: 400;\n",
       "    }\n",
       "\n",
       "</style>\n",
       " <span class=\"spark-nlp-display-others\" style=\"background-color: white\">December 2007 SUBORDINATED LOAN AGREEMENT. THIS LOAN AGREEMENT is made on 7th December, 2007 BETWEEN: (1) </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #980917\"><span class=\"spark-nlp-display-entity-name\">SILICIUM DE PROVENCE S.A.S </span><span class=\"spark-nlp-display-entity-type\">ORG</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">., a private company with limited liability, incorporated under the laws of </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #508762\"><span class=\"spark-nlp-display-entity-name\">France </span><span class=\"spark-nlp-display-entity-type\">LOC</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, whose registered office is situated at </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #508762\"><span class=\"spark-nlp-display-entity-name\">Usine de Saint Auban </span><span class=\"spark-nlp-display-entity-type\">LOC</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #508762\"><span class=\"spark-nlp-display-entity-name\">France </span><span class=\"spark-nlp-display-entity-type\">LOC</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, represented by </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #62672D\"><span class=\"spark-nlp-display-entity-name\">Mr.Frank Wouters </span><span class=\"spark-nlp-display-entity-type\">PER</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, hereinafter referred to as the \"</span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #62672D\"><span class=\"spark-nlp-display-entity-name\">Borrower </span><span class=\"spark-nlp-display-entity-type\">PER</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">\", and ( 2 ) </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #980917\"><span class=\"spark-nlp-display-entity-name\">EVERGREEN SOLAR INC </span><span class=\"spark-nlp-display-entity-type\">ORG</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">., a company incorporated in </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #508762\"><span class=\"spark-nlp-display-entity-name\">Delaware </span><span class=\"spark-nlp-display-entity-type\">LOC</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #508762\"><span class=\"spark-nlp-display-entity-name\">U.S.A </span><span class=\"spark-nlp-display-entity-type\">LOC</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">., with registered number 2426798, whose registered office is situated at </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #508762\"><span class=\"spark-nlp-display-entity-name\">Bartlett Street </span><span class=\"spark-nlp-display-entity-type\">LOC</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #508762\"><span class=\"spark-nlp-display-entity-name\">Marlboro </span><span class=\"spark-nlp-display-entity-type\">LOC</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #508762\"><span class=\"spark-nlp-display-entity-name\">Massachusetts </span><span class=\"spark-nlp-display-entity-type\">LOC</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #508762\"><span class=\"spark-nlp-display-entity-name\">U.S.A </span><span class=\"spark-nlp-display-entity-type\">LOC</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">. represented by </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #62672D\"><span class=\"spark-nlp-display-entity-name\">Richard Chleboski </span><span class=\"spark-nlp-display-entity-type\">PER</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, hereinafter referred to as \"</span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #62672D\"><span class=\"spark-nlp-display-entity-name\">Lender </span><span class=\"spark-nlp-display-entity-type\">PER</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">\" </span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from sparknlp_display import NerVisualizer\n",
    "\n",
    "visualiser = viz.NerVisualizer()\n",
    "\n",
    "visualiser.display(light_result[0], label_col='ner_chunk', document_col='document')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95645147-7f43-4fc1-b668-3bb2317bb74f",
   "metadata": {
    "id": "95645147-7f43-4fc1-b668-3bb2317bb74f"
   },
   "source": [
    "## Create Generic Pipeline for NerDL Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da501a7a-aabd-477d-b19b-1e18b4ee7042",
   "metadata": {
    "id": "da501a7a-aabd-477d-b19b-1e18b4ee7042"
   },
   "outputs": [],
   "source": [
    "def base_pipeline():\n",
    "    \n",
    "    document_assembler = nlp.DocumentAssembler()\\\n",
    "        .setInputCol(\"text\")\\\n",
    "        .setOutputCol(\"document\")\n",
    "\n",
    "    # Consider using SentenceDetector with rules/patterns to get smaller chunks from long sentences\n",
    "    sentence_detector = nlp.SentenceDetector() \\\n",
    "        .setInputCols([\"document\"]) \\\n",
    "        .setOutputCol(\"sentence\") \\\n",
    "        .setCustomBounds([\"\\n\\n\"])\n",
    "\n",
    "    tokenizer = nlp.Tokenizer()\\\n",
    "        .setInputCols([\"sentence\"])\\\n",
    "        .setOutputCol(\"token\")\n",
    "    \n",
    "    pipeline = nlp.Pipeline(stages=[\n",
    "            documentAssembler,\n",
    "            sentence_detector,\n",
    "            tokenizer])\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b050243-1a9d-4b9e-a7a8-3fc084e69d08",
   "metadata": {
    "id": "6b050243-1a9d-4b9e-a7a8-3fc084e69d08"
   },
   "outputs": [],
   "source": [
    "def generic_ner_pipeline(model_name, embeddings):\n",
    "    \n",
    "    word_embeddings = nlp.BertEmbeddings.pretrained(embeddings, \"en\")\\\n",
    "            .setInputCols(\"sentence\", \"token\") \\\n",
    "            .setOutputCol(\"embeddings\")\\\n",
    "\n",
    "    ner_model = finance.NerModel.pretrained(model_name, \"en\", \"finance/models\")\\\n",
    "            .setInputCols([\"sentence\", \"token\", \"embeddings\"])\\\n",
    "            .setOutputCol(\"ner\")\n",
    "\n",
    "    ner_converter = nlp.NerConverter()\\\n",
    "            .setInputCols([\"sentence\",\"token\",\"ner\"])\\\n",
    "            .setOutputCol(\"ner_chunk\")\n",
    "\n",
    "    nlp_pipeline = nlp.Pipeline(stages=[\n",
    "            base_pipeline(),\n",
    "            word_embeddings,\n",
    "            ner_model,\n",
    "            ner_converter])\n",
    "\n",
    "    empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "    model = nlp_pipeline.fit(empty_data)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479103f2-1256-4b78-971a-55d81140d030",
   "metadata": {
    "id": "479103f2-1256-4b78-971a-55d81140d030"
   },
   "source": [
    "## Create Generic Result Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19fac60f-f99a-4bf6-8668-0d40aa50a24d",
   "metadata": {
    "id": "19fac60f-f99a-4bf6-8668-0d40aa50a24d"
   },
   "outputs": [],
   "source": [
    "def get_result(result):\n",
    "    result.select(F.explode(F.arrays_zip(result.ner_chunk.result, result.ner_chunk.metadata)).alias(\"cols\")) \\\n",
    "          .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
    "                  F.expr(\"cols['1']['entity']\").alias(\"ner_label\")).show(50, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817a44c1-52a3-40b3-9bd2-bc7b67c4c7fe",
   "metadata": {
    "id": "817a44c1-52a3-40b3-9bd2-bc7b67c4c7fe"
   },
   "source": [
    "### Finance SEC10K Forms NER Model\n",
    "\n",
    "This model uses Name Entity Recognition to extract information like **Company Name**, **Trading symbols**, **Stock markets**, **Addresses**, **Phones**, **Stock types* and values, **IRS**, **CFN**, etc. from the first page of 10-K filings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa0104c-bdb7-4e4a-b3bb-f7e21f912964",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 65327,
     "status": "ok",
     "timestamp": 1664819939959,
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     },
     "user_tz": -120
    },
    "id": "3fa0104c-bdb7-4e4a-b3bb-f7e21f912964",
    "outputId": "a445dd6f-8ff5-4eee-f53a-345d0cf331ca",
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"\"\"ANNUAL REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES AND EXCHANGE ACT OF 1934\n",
    "For the annual period ended January 31, 2021\n",
    "or\n",
    "TRANSITION REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\n",
    "For the transition period from________to_______\n",
    "Commission File Number: 001-38856\n",
    "PAGERDUTY, INC.\n",
    "(Exact name of registrant as specified in its charter)\n",
    "Delaware\n",
    "27-2793871\n",
    "(State or other jurisdiction of\n",
    "incorporation or organization)\n",
    "(I.R.S. Employer\n",
    "Identification Number)\n",
    "600 Townsend St., Suite 200, San Francisco, CA 94103\n",
    "(844) 800-3889\n",
    "(Address, including zip code, and telephone number, including area code, of registrant’s principal executive offices)\n",
    "Securities registered pursuant to Section 12(b) of the Act:\n",
    "Title of each class\n",
    "Trading symbol(s)\n",
    "Name of each exchange on which registered\n",
    "Common Stock, $0.000005 par value,\n",
    "PD\n",
    "New York Stock Exchange\"\"\"\n",
    "\n",
    "model_name = \"finner_10k_summary\"\n",
    "\n",
    "embeddings = \"bert_embeddings_finbert_pretrain_yiyanghkust\"\n",
    "\n",
    "df = spark.createDataFrame([[text]]).toDF(\"text\")\n",
    "\n",
    "result = generic_ner_pipeline(model_name, embeddings).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c143057-ddfc-4823-947f-9e51506e50ce",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7908,
     "status": "ok",
     "timestamp": 1664819947863,
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     },
     "user_tz": -120
    },
    "id": "0c143057-ddfc-4823-947f-9e51506e50ce",
    "outputId": "2f072e25-ff16-4905-8ed6-8df4d77b629e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------+-----------------+\n",
      "|chunk                                         |ner_label        |\n",
      "+----------------------------------------------+-----------------+\n",
      "|January 31, 2021                              |FISCAL_YEAR      |\n",
      "|001-38856                                     |CFN              |\n",
      "|PAGERDUTY, INC                                |ORG              |\n",
      "|Delaware                                      |STATE            |\n",
      "|27-2793871                                    |IRS              |\n",
      "|600 Townsend St., Suite 200, San Francisco, CA|ADDRESS          |\n",
      "|(844) 800-3889                                |PHONE            |\n",
      "|Common Stock                                  |TITLE_CLASS      |\n",
      "|$0.000005                                     |TITLE_CLASS_VALUE|\n",
      "|PD                                            |TICKER           |\n",
      "|New York Stock Exchange                       |STOCK_EXCHANGE   |\n",
      "+----------------------------------------------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "get_result(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab56faa-0646-4c84-ac4e-e9710c0ba891",
   "metadata": {
    "id": "aab56faa-0646-4c84-ac4e-e9710c0ba891"
   },
   "source": [
    "### Finance Cuad_NER_Org_Products Model\n",
    "\n",
    "This model uses Name Entity Recognition to extract ORG (Organization names), PRODUCT (Product names) and ALIAS.\n",
    "\n",
    "Entities:\n",
    " - ORG (Organization names)\n",
    " - PRODUCT (Product names)\n",
    " - ALIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e48a792-b252-42bd-8d0f-0e543240b289",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 67096,
     "status": "ok",
     "timestamp": 1664820014955,
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     },
     "user_tz": -120
    },
    "id": "6e48a792-b252-42bd-8d0f-0e543240b289",
    "outputId": "0106c78f-cc97-424f-bd73-c2c06a832cea",
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"\"\"This INTELLECTUAL PROPERTY AGREEMENT (this \"Agreement\"), dated as of December 31, 2018 (the \"Effective Date\") is entered into by and between Armstrong Flooring, Inc., a Delaware corporation (\"Seller\") and AFI Licensing LLC, a Delaware limited liability company (\"Licensing\" and together with Seller, \"Arizona\") and AHF Holding, Inc. (formerly known as Tarzan HoldCo, Inc.), a Delaware corporation (\"Buyer\") and Armstrong Hardwood Flooring Company, a Tennessee corporation (the \"Company\" and together with Buyer the \"Buyer Entities\") (each of Arizona on the one hand and the Buyer Entities on the other hand, a \"Party\" and collectively, the \"Parties\").\"\"\"\n",
    "\n",
    "model_name = \"finner_orgs_prods_alias\"\n",
    "\n",
    "embeddings = \"bert_embeddings_sec_bert_base\"\n",
    "\n",
    "df = spark.createDataFrame([[text]]).toDF(\"text\")\n",
    "\n",
    "result = generic_ner_pipeline(model_name, embeddings).transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56f94eaf-e394-4052-b33b-518ae5876ca1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6982,
     "status": "ok",
     "timestamp": 1664820021927,
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     },
     "user_tz": -120
    },
    "id": "56f94eaf-e394-4052-b33b-518ae5876ca1",
    "outputId": "fdbeb59d-a566-404f-e804-e8fbc06cbc5f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 36:======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+---------+\n",
      "|chunk                              |ner_label|\n",
      "+-----------------------------------+---------+\n",
      "|Armstrong Flooring, Inc            |ORG      |\n",
      "|Seller                             |ALIAS    |\n",
      "|AFI Licensing LLC                  |ORG      |\n",
      "|Licensing                          |ALIAS    |\n",
      "|Seller                             |ALIAS    |\n",
      "|Arizona                            |ALIAS    |\n",
      "|AHF Holding, Inc                   |ORG      |\n",
      "|Tarzan HoldCo, Inc                 |ORG      |\n",
      "|Buyer                              |ALIAS    |\n",
      "|Armstrong Hardwood Flooring Company|ORG      |\n",
      "|Company                            |ALIAS    |\n",
      "|Buyer                              |ALIAS    |\n",
      "|Buyer Entities                     |ALIAS    |\n",
      "|Arizona                            |ALIAS    |\n",
      "|Buyer Entities                     |ALIAS    |\n",
      "|Party                              |ALIAS    |\n",
      "|Parties                            |ALIAS    |\n",
      "+-----------------------------------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "get_result(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3aab70-a7e4-477c-9415-9ed845afb9c1",
   "metadata": {
    "id": "bd3aab70-a7e4-477c-9415-9ed845afb9c1"
   },
   "source": [
    "### Finance NER_Ticker Model with RoBertaForTokenClassification\n",
    "\n",
    "This model aims to detect Trading Symbols / Tickers in texts.\n",
    "\n",
    "Enities\n",
    " - TICKER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e350660c-4e30-42d9-8086-7f835036fa19",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 56201,
     "status": "ok",
     "timestamp": 1664820078122,
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     },
     "user_tz": -120
    },
    "id": "e350660c-4e30-42d9-8086-7f835036fa19",
    "outputId": "49408b16-5ca0-4ee9-94b5-3cac5ab15d85"
   },
   "outputs": [],
   "source": [
    "tokenClassifier = nlp.RoBertaForTokenClassification.pretrained(\"finner_roberta_ticker\", \"en\", \"finance/models\")\\\n",
    "    .setInputCols([\"sentence\", \"token\"])\\\n",
    "    .setOutputCol(\"ner\")\n",
    "\n",
    "ner_converter = nlp.NerConverter()\\\n",
    "    .setInputCols([\"sentence\",\"token\",\"ner\"])\\\n",
    "    .setOutputCol(\"ner_chunk\")\n",
    "\n",
    "pipeline = nlp.Pipeline(stages=[\n",
    "    base_pipeline(), \n",
    "    tokenClassifier,\n",
    "    ner_converter\n",
    "])\n",
    "\n",
    "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "model = pipeline.fit(empty_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad62ed1d-7972-45dc-adf0-46318bfcdc4f",
   "metadata": {
    "id": "ad62ed1d-7972-45dc-adf0-46318bfcdc4f"
   },
   "outputs": [],
   "source": [
    "text = \"\"\"There are some serious purchases and sales of AMZN, NFLX and GPRO stock today.\"\"\"\n",
    "\n",
    "df = spark.createDataFrame([[text]]).toDF(\"text\")\n",
    "\n",
    "result = model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0cd698ee-0302-427b-bdf8-a43d878468cc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3589,
     "status": "ok",
     "timestamp": 1664820083027,
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     },
     "user_tz": -120
    },
    "id": "0cd698ee-0302-427b-bdf8-a43d878468cc",
    "outputId": "505307be-1dd3-4b63-d4c6-6ed07d98aa38"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 44:======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+\n",
      "|chunk|ner_label|\n",
      "+-----+---------+\n",
      "|AMZN |TICKER   |\n",
      "|NFLX |TICKER   |\n",
      "|GPRO |TICKER   |\n",
      "+-----+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "get_result(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a32aee6",
   "metadata": {
    "id": "5a32aee6"
   },
   "source": [
    "# Zero-shot Named Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43420eee-1c29-4148-b1c8-fa7884eff9b3",
   "metadata": {
    "id": "43420eee-1c29-4148-b1c8-fa7884eff9b3"
   },
   "source": [
    "`Zero-shot` is a new inference paradigm which allows us to use a model for prediction without any previous training step.\n",
    "\n",
    "For doing that, several examples (_hypotheses_) are provided and sent to the Language model, which will use `NLI (Natural Language Inference)` to check if the any information found in the text matches the examples (confirm the hypotheses).\n",
    "\n",
    "NLI usually works by trying to _confirm or reject an hypotheses_. The _hypotheses_ are the `prompts` or examples we are going to provide. If any piece of information confirm the constructed hypotheses (answer the examples we are given), then the hypotheses is confirmed and the Zero-shot is triggered.\n",
    "\n",
    "Let's see it  in action.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2948d346-d522-43b9-9cd7-99430882621f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 57951,
     "status": "ok",
     "timestamp": 1664820140973,
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     },
     "user_tz": -120
    },
    "id": "2948d346-d522-43b9-9cd7-99430882621f",
    "outputId": "dc5b44d5-e64f-41de-9844-5d98eebc0da8"
   },
   "outputs": [],
   "source": [
    "document_assembler = nlp.DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "sentence_detector = nlp.SentenceDetector()\\\n",
    "    .setInputCols([\"document\"])\\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "tokenizer = nlp.Tokenizer()\\\n",
    "    .setInputCols(\"sentence\")\\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "zero_shot_ner = finance.ZeroShotNerModel.pretrained(\"finner_roberta_zeroshot\", \"en\", \"finance/models\")\\\n",
    "    .setInputCols([\"sentence\", \"token\"])\\\n",
    "    .setOutputCol(\"zero_shot_ner\")\\\n",
    "    .setEntityDefinitions(\n",
    "        {\n",
    "            \"DATE\": ['When was the company acquisition?', 'When was the company purchase agreement?'],\n",
    "            \"ORG\": [\"Which company was acquired?\"],\n",
    "            \"PRODUCT\": [\"Which product?\"],\n",
    "            \"PROFIT_INCREASE\": [\"How much has the gross profit increased?\"],\n",
    "            \"REVENUES_DECLINED\": [\"How much has the revenues declined?\"],\n",
    "            \"OPERATING_LOSS_2020\": [\"Which was the operating loss in 2020\"],\n",
    "            \"OPERATING_LOSS_2019\": [\"Which was the operating loss in 2019\"]\n",
    "        })\n",
    "\n",
    "ner_converter = nlp.NerConverter()\\\n",
    "    .setInputCols([\"sentence\", \"token\", \"zero_shot_ner\"])\\\n",
    "    .setOutputCol(\"ner_chunk\")\n",
    "\n",
    "pipeline =  nlp.Pipeline(stages=[\n",
    "      document_assembler,\n",
    "      sentence_detector,\n",
    "      tokenizer,\n",
    "      zero_shot_ner,\n",
    "      ner_converter,\n",
    "      ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b005b29f-f0c0-44dd-baac-590166d6bf8c",
   "metadata": {
    "id": "b005b29f-f0c0-44dd-baac-590166d6bf8c"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "\n",
    "sample_text = [\"In March 2012, as part of a longer-term strategy, the Company acquired Vertro, Inc., which owned and operated the ALOT product portfolio.\",\n",
    "               \"In February 2017, the Company entered into an asset purchase agreement with NetSeer, Inc.\",\n",
    "               \"While our gross profit margin increased to 81.4% in 2020 from 63.1% in 2019, our revenues declined approximately 27% in 2020 as compared to 2019.\",\n",
    "               \"We reported an operating loss of approximately $8,048,581 million in 2020 as compared to an operating loss of $7,738,193 in 2019.\"]\n",
    "\n",
    "p_model = pipeline.fit(spark.createDataFrame([[\"\"]]).toDF(\"text\"))\n",
    "\n",
    "res = p_model.transform(spark.createDataFrame(sample_text, StringType()).toDF(\"text\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "183fb2db-1cee-4f78-a486-dd6c9f6abd57",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20293,
     "status": "ok",
     "timestamp": 1664820161978,
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     },
     "user_tz": -120
    },
    "id": "183fb2db-1cee-4f78-a486-dd6c9f6abd57",
    "outputId": "fb92d018-4b7d-41ff-9547-da791128d036"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 51:===================>                                      (1 + 2) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------------+\n",
      "|chunk             |ner_label          |\n",
      "+------------------+-------------------+\n",
      "|March 2012        |DATE               |\n",
      "|Vertro            |ORG                |\n",
      "|ALOT              |PRODUCT            |\n",
      "|February 2017     |DATE               |\n",
      "|NetSeer           |ORG                |\n",
      "|81.4%             |PROFIT_INCREASE    |\n",
      "|27%               |REVENUES_DECLINED  |\n",
      "|$8,048,581 million|OPERATING_LOSS_2020|\n",
      "|$7,738,193        |OPERATING_LOSS_2019|\n",
      "|2019              |DATE               |\n",
      "+------------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "res.select(F.explode(F.arrays_zip(res.ner_chunk.result, res.ner_chunk.begin, res.ner_chunk.end, res.ner_chunk.metadata)).alias(\"cols\")) \\\n",
    "   .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
    "           F.expr(\"cols['3']['entity']\").alias(\"ner_label\"))\\\n",
    "   .filter(\"ner_label!='O'\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef9d8b5-420a-4001-b604-c7086d100be2",
   "metadata": {
    "id": "1ef9d8b5-420a-4001-b604-c7086d100be2"
   },
   "outputs": [],
   "source": [
    "lp = nlp.LightPipeline(p_model)\n",
    "\n",
    "lp_res_1 = lp.fullAnnotate(sample_text[2])\n",
    "\n",
    "lp_res_2 = lp.fullAnnotate(sample_text[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76965465-7b3e-4ed5-a2a8-9e522807bc20",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1664820170886,
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     },
     "user_tz": -120
    },
    "id": "76965465-7b3e-4ed5-a2a8-9e522807bc20",
    "outputId": "6d886922-e3c2-453c-db96-0e63f05340d5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    @import url('https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700&display=swap');\n",
       "    @import url('https://fonts.googleapis.com/css2?family=Vistol Regular:wght@300;400;500;600;700&display=swap');\n",
       "    \n",
       "    .spark-nlp-display-scroll-entities {\n",
       "        border: 1px solid #E7EDF0;\n",
       "        border-radius: 3px;\n",
       "        text-align: justify;\n",
       "        \n",
       "    }\n",
       "    .spark-nlp-display-scroll-entities span {  \n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        color: #536B76;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "    }\n",
       "    \n",
       "    .spark-nlp-display-entity-wrapper{\n",
       "    \n",
       "        display: inline-grid;\n",
       "        text-align: center;\n",
       "        border-radius: 4px;\n",
       "        margin: 0 2px 5px 2px;\n",
       "        padding: 1px\n",
       "    }\n",
       "    .spark-nlp-display-entity-name{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "        \n",
       "        background: #f1f2f3;\n",
       "        border-width: medium;\n",
       "        text-align: center;\n",
       "        \n",
       "        font-weight: 400;\n",
       "        \n",
       "        border-radius: 5px;\n",
       "        padding: 2px 5px;\n",
       "        display: block;\n",
       "        margin: 3px 2px;\n",
       "    \n",
       "    }\n",
       "    .spark-nlp-display-entity-type{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        color: #ffffff;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "        \n",
       "        text-transform: uppercase;\n",
       "        \n",
       "        font-weight: 500;\n",
       "\n",
       "        display: block;\n",
       "        padding: 3px 5px;\n",
       "    }\n",
       "    \n",
       "    .spark-nlp-display-entity-resolution{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        color: #ffffff;\n",
       "        font-family: 'Vistol Regular', sans-serif !important;\n",
       "        \n",
       "        text-transform: uppercase;\n",
       "        \n",
       "        font-weight: 500;\n",
       "\n",
       "        display: block;\n",
       "        padding: 3px 5px;\n",
       "    }\n",
       "    \n",
       "    .spark-nlp-display-others{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "        \n",
       "        font-weight: 400;\n",
       "    }\n",
       "\n",
       "</style>\n",
       " <span class=\"spark-nlp-display-others\" style=\"background-color: white\">While our gross profit margin increased to </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #94A72D\"><span class=\"spark-nlp-display-entity-name\">81.4% </span><span class=\"spark-nlp-display-entity-type\">PROFIT_INCREASE</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> in 2020 from 63.1% in 2019, our revenues declined approximately </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #22916B\"><span class=\"spark-nlp-display-entity-name\">27% </span><span class=\"spark-nlp-display-entity-type\">REVENUES_DECLINED</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> in 2020 as compared to 2019.</span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from sparknlp_display import NerVisualizer\n",
    "\n",
    "visualiser = viz.NerVisualizer()\n",
    "\n",
    "visualiser.display(lp_res_1[0], label_col='ner_chunk', document_col='document')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e60d6c8a-f65b-4218-8605-6bcef98f1204",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1664820170886,
     "user": {
      "displayName": "Damla",
      "userId": "03285166568766987047"
     },
     "user_tz": -120
    },
    "id": "e60d6c8a-f65b-4218-8605-6bcef98f1204",
    "outputId": "9cdd896e-6e23-4576-9731-1aa3c95a81e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    @import url('https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700&display=swap');\n",
       "    @import url('https://fonts.googleapis.com/css2?family=Vistol Regular:wght@300;400;500;600;700&display=swap');\n",
       "    \n",
       "    .spark-nlp-display-scroll-entities {\n",
       "        border: 1px solid #E7EDF0;\n",
       "        border-radius: 3px;\n",
       "        text-align: justify;\n",
       "        \n",
       "    }\n",
       "    .spark-nlp-display-scroll-entities span {  \n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        color: #536B76;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "    }\n",
       "    \n",
       "    .spark-nlp-display-entity-wrapper{\n",
       "    \n",
       "        display: inline-grid;\n",
       "        text-align: center;\n",
       "        border-radius: 4px;\n",
       "        margin: 0 2px 5px 2px;\n",
       "        padding: 1px\n",
       "    }\n",
       "    .spark-nlp-display-entity-name{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "        \n",
       "        background: #f1f2f3;\n",
       "        border-width: medium;\n",
       "        text-align: center;\n",
       "        \n",
       "        font-weight: 400;\n",
       "        \n",
       "        border-radius: 5px;\n",
       "        padding: 2px 5px;\n",
       "        display: block;\n",
       "        margin: 3px 2px;\n",
       "    \n",
       "    }\n",
       "    .spark-nlp-display-entity-type{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        color: #ffffff;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "        \n",
       "        text-transform: uppercase;\n",
       "        \n",
       "        font-weight: 500;\n",
       "\n",
       "        display: block;\n",
       "        padding: 3px 5px;\n",
       "    }\n",
       "    \n",
       "    .spark-nlp-display-entity-resolution{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        color: #ffffff;\n",
       "        font-family: 'Vistol Regular', sans-serif !important;\n",
       "        \n",
       "        text-transform: uppercase;\n",
       "        \n",
       "        font-weight: 500;\n",
       "\n",
       "        display: block;\n",
       "        padding: 3px 5px;\n",
       "    }\n",
       "    \n",
       "    .spark-nlp-display-others{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "        \n",
       "        font-weight: 400;\n",
       "    }\n",
       "\n",
       "</style>\n",
       " <span class=\"spark-nlp-display-others\" style=\"background-color: white\">We reported an operating loss of approximately </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #65866B\"><span class=\"spark-nlp-display-entity-name\">$8,048,581 million </span><span class=\"spark-nlp-display-entity-type\">OPERATING_LOSS_2020</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> in 2020 as compared to an operating loss of </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #6A6033\"><span class=\"spark-nlp-display-entity-name\">$7,738,193 </span><span class=\"spark-nlp-display-entity-type\">OPERATING_LOSS_2019</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> in </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #a6b1e1\"><span class=\"spark-nlp-display-entity-name\">2019 </span><span class=\"spark-nlp-display-entity-type\">DATE</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">.</span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualiser.display(lp_res_2[0], label_col='ner_chunk', document_col='document')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa24194b-37cc-4e82-8aa1-f013e7529ae3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "eaef4d22edbbdbc68b8d50d2a1a48c6349c8418c1052069fe906c41d47bd13e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
