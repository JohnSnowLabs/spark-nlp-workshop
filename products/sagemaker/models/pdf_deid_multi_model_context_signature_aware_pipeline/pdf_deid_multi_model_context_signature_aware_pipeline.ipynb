{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Subscribe to the model package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To subscribe to the model package:\n",
    "1. Open the model package listing page [Clinical De-identification for PDF (Signature aware)](https://aws.amazon.com/marketplace/pp/prodview-jmtngbxhcmmfk)\n",
    "1. On the AWS Marketplace listing, click on the **Continue to subscribe** button.\n",
    "1. On the **Subscribe to this software** page, review and click on **\"Accept Offer\"** if you and your organization agrees with EULA, pricing, and support terms. \n",
    "1. Once you click on **Continue to configuration button** and then choose a **region**, you will see a **Product Arn** displayed. This is the model package ARN that you need to specify while creating a deployable model using Boto3. Copy the ARN corresponding to your region and specify the same in the following cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEID Multi Model\n",
    "\n",
    "\n",
    "- **Model**: `pdf_deid_multi_model_context_signature_aware_pipeline`\n",
    "- **Model Description**:  This pipeline is designed to deidentify all printed text from (Multiple and Single) page PDF.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_package_arn = 'customer to specify model package arn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import shutil\n",
    "\n",
    "from sagemaker import ModelPackage\n",
    "import sagemaker as sage\n",
    "from sagemaker import get_execution_role\n",
    "import boto3\n",
    "from IPython.display import Image, display, IFrame\n",
    "from PIL import Image as ImageEdit\n",
    "from urllib.parse import urlparse\n",
    "import numpy as np\n",
    "from IPython.display import display, IFrame, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sagemaker_session = sage.Session()\n",
    "s3_bucket = sagemaker_session.default_bucket()\n",
    "region = sagemaker_session.boto_region_name\n",
    "account_id = boto3.client(\"sts\").get_caller_identity().get(\"Account\")\n",
    "role = get_execution_role()\n",
    "\n",
    "sagemaker = boto3.client(\"sagemaker\")\n",
    "s3_client = sagemaker_session.boto_session.client(\"s3\")\n",
    "ecr = boto3.client(\"ecr\")\n",
    "sm_runtime = boto3.client(\"sagemaker-runtime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create an endpoint and perform real-time inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to understand how real-time inference with Amazon SageMaker works, see [Documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-hosting.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"pdf_deid_multi_model_context_signature_aware_pipeline\"\n",
    "\n",
    "real_time_inference_instance_type = \"ml.c5.9xlarge\"\n",
    "batch_transform_inference_instance_type = \"ml.c5.9xlarge\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Create an endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!"
     ]
    }
   ],
   "source": [
    "# create a deployable model from the model package.\n",
    "model = ModelPackage(\n",
    "    role=role, model_package_arn=model_package_arn, sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "# Deploy the model\n",
    "predictor = model.deploy(1, real_time_inference_instance_type, endpoint_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once endpoint has been created, you would be able to perform real-time inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import io\n",
    "\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "def process_data_and_invoke_realtime_endpoint(pdf_file,content_type):\n",
    "    with open(pdf_file, \"rb\") as file:\n",
    "        pdf_data = file.read()\n",
    "\n",
    "    i = 1\n",
    "    input_extension = os.path.splitext(pdf_file)[-1]\n",
    "    input_file_name = f'inputs/real-time/input{i}{input_extension}'\n",
    "\n",
    "    while os.path.exists(input_file_name):\n",
    "        i += 1\n",
    "        input_file_name = f'inputs/real-time/input{i}{input_extension}'\n",
    "\n",
    "    output_file_name = f'outputs/real-time/{os.path.basename(input_file_name)}.out'\n",
    "\n",
    "    os.makedirs(os.path.dirname(input_file_name), exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(output_file_name), exist_ok=True)\n",
    "\n",
    "    shutil.copy2(pdf_file, input_file_name)\n",
    "\n",
    "    # Assuming s3_client is defined and used correctly\n",
    "    validation_input_file_path = f\"{model_name}/validation-input/real-time/{os.path.basename(input_file_name)}\"\n",
    "    s3_client.upload_file(pdf_file, s3_bucket, validation_input_file_path)\n",
    "\n",
    "    # Assuming sm_runtime is defined and used correctly\n",
    "    response = sm_runtime.invoke_endpoint(\n",
    "        EndpointName=model_name,\n",
    "        ContentType=content_type,\n",
    "        Accept=\"application/json\",\n",
    "        Body=pdf_data,\n",
    "    )\n",
    "\n",
    "    # Process response\n",
    "    with io.FileIO(output_file_name, 'w') as file:\n",
    "        for b in response['Body']._raw_stream:\n",
    "            file.write(b)\n",
    "\n",
    "    return output_file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1 - Multiple Page PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget --no-check-certificate https://raw.githubusercontent.com/JohnSnowLabs/pdf-deid-dataset/cc91a94e7fb044591d987b7650807731b73980fb/PDF_Original/Medium/PDF_Deid_Deidentification_Medium_7.pdf -O example_input_1.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#IFrame(\"./example_input_1.pdf\", width=1000, height=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data =  process_data_and_invoke_realtime_endpoint(pdf_file='./example_input_1.pdf', content_type='application/octet-stream')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#IFrame(data, width=1000, height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget --no-check-certificate https://raw.githubusercontent.com/JohnSnowLabs/pdf-deid-dataset/cc91a94e7fb044591d987b7650807731b73980fb/PDF_Original/Easy/PDF_Deid_Deidentification_0.pdf -O input_printed_1.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#IFrame(\"./example_input_2.pdf\", width=1000, height=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data =  process_data_and_invoke_realtime_endpoint(pdf_file='./example_input_2.pdf', content_type='application/octet-stream')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#IFrame(data, width=1000, height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Delete the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have successfully performed a real-time inference, you do not need the endpoint any more. You can terminate the endpoint to avoid being charged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.sagemaker_session.delete_endpoint(model_name)\n",
    "model.sagemaker_session.delete_endpoint_config(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Batch inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_file_name1 = \"example_input_1.pdf\"\n",
    "validation_file_name2 = \"example_input_2.pdf\"\n",
    "\n",
    "validation_input_path = f\"s3://{s3_bucket}/{model_name}/validation-input/batch\"\n",
    "validation_output_path = f\"s3://{s3_bucket}/{model_name}/validation-output/batch\"\n",
    "\n",
    "input_dir = 'inputs/batch'\n",
    "output_dir = 'outputs/batch'\n",
    "\n",
    "os.makedirs(input_dir, exist_ok=True)\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def upload_pdf_to_s3(local_file_path):\n",
    "    shutil.copy2(local_file_path, input_dir)\n",
    "    base_file_name = os.path.basename(local_file_path)\n",
    "    validation_input_file_path = f\"{model_name}/validation-input/batch/{base_file_name}\"\n",
    "    s3_client.upload_file(local_file_path, s3_bucket, validation_input_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "upload_pdf_to_s3(validation_file_name1)\n",
    "upload_pdf_to_s3(validation_file_name2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize a SageMaker Transformer object for making predictions\n",
    "transformer = model.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type=batch_transform_inference_instance_type,\n",
    "    accept=\"application/json\",\n",
    "    output_path=validation_output_path\n",
    ")\n",
    "\n",
    "transformer.transform(validation_input_path, content_type='application/octet-stream')\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parsed_url = urlparse(transformer.output_path)\n",
    "file_key = f\"{parsed_url.path[1:]}/input_printed.pdf.out\"\n",
    "response = s3_client.get_object(Bucket=s3_bucket, Key=file_key)\n",
    "with io.FileIO(f\"{output_dir}/example_out_1.pdf\", 'w') as file:\n",
    "    for b in response['Body']._raw_stream:\n",
    "        file.write(b)\n",
    "\n",
    "IFrame(f\"{output_dir}/example_out_1.pdf\", width=600, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parsed_url = urlparse(transformer.output_path)\n",
    "file_key = f\"{parsed_url.path[1:]}/input_printed_1.pdf.out\"\n",
    "response = s3_client.get_object(Bucket=s3_bucket, Key=file_key)\n",
    "with io.FileIO(f\"{output_dir}/example_out_2.pdf\", 'w') as file:\n",
    "    for b in response['Body']._raw_stream:\n",
    "        file.write(b)\n",
    "\n",
    "IFrame(f\"{output_dir}/example_out_2.pdf\", width=600, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting model with name: en-printed-transformer-extraction-pipel-2024-07-24-11-48-08-864\n"
     ]
    }
   ],
   "source": [
    "model.delete_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsubscribe to the listing (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "If you would like to unsubscribe to the model package, follow these steps. Before you cancel the subscription, ensure that you do not have any [deployable model](https://console.aws.amazon.com/sagemaker/home#/models) created from the model package or using the algorithm. Note - You can find this information by looking at the container name associated with the model. \n",
    "\n",
    "**Steps to unsubscribe to product from AWS Marketplace**:\n",
    "1. Navigate to __Machine Learning__ tab on [__Your Software subscriptions page__](https://aws.amazon.com/marketplace/ai/library?productType=ml&ref_=mlmp_gitdemo_indust)\n",
    "2. Locate the listing that you want to cancel the subscription for, and then choose __Cancel Subscription__  to cancel the subscription.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
