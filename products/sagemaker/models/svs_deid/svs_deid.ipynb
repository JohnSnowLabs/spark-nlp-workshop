{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6878f251",
   "metadata": {},
   "source": [
    "## Subscribe to the model package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1020a1",
   "metadata": {},
   "source": [
    "To subscribe to the model package:\n",
    "1. Open the model package listing page [SVS Images De-identification](https://aws.amazon.com/marketplace/pp/prodview-kh7vsfj4pwxry)\n",
    "1. On the AWS Marketplace listing, click on the **Continue to subscribe** button.\n",
    "1. On the **Subscribe to this software** page, review and click on **\"Accept Offer\"** if you and your organization agrees with EULA, pricing, and support terms. \n",
    "1. Once you click on **Continue to configuration button** and then choose a **region**, you will see a **Product Arn** displayed. This is the model package ARN that you need to specify while creating a deployable model using Boto3. Copy the ARN corresponding to your region and specify the same in the following cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b277045d4a412b",
   "metadata": {},
   "source": [
    " ## Initialize Your Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from urllib.parse import urlparse\n",
    "import re\n",
    "import boto3\n",
    "import sagemaker as sage\n",
    "from sagemaker import get_execution_role, ModelPackage\n",
    "from sagemaker.async_inference import AsyncInferenceConfig\n",
    "import requests\n",
    "\n",
    "session = sage.Session()\n",
    "s3_bucket = session.default_bucket()\n",
    "region = session.boto_region_name\n",
    "account_id = boto3.client(\"sts\").get_caller_identity().get(\"Account\")\n",
    "role = get_execution_role()\n",
    "\n",
    "sagemaker = boto3.client(\"sagemaker\")\n",
    "s3_client = session.boto_session.client(\"s3\")\n",
    "ecr = boto3.client(\"ecr\")\n",
    "sm_runtime = boto3.client(\"sagemaker-runtime\")\n",
    "boto_session = boto3.Session()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591c10ec3ef355b0",
   "metadata": {},
   "source": [
    " # Deploy the model as endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f629ab14-7d1e-442c-b913-c925ab8af3e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_package_arn = 'arn:aws:sagemaker:YOUR ARN'\n",
    "model_package_name = \"svs-deid-pipeline\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "454d9f4585243f99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'svs-deid-pipeline'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ModelPackage(\n",
    "    role=role,\n",
    "    model_package_arn=model_package_arn,\n",
    "    sagemaker_session=session,\n",
    ")\n",
    "model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m5.2xlarge',\n",
    "    endpoint_name=model_package_name,\n",
    "    async_inference_config=AsyncInferenceConfig(\n",
    "        output_path=f\"s3://{s3_bucket}/{model_package_name}/output/\"\n",
    "    )\n",
    ")\n",
    "model.endpoint_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206c44cbba3b9887",
   "metadata": {},
   "source": [
    "# List Endpoints and status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "902fda9076ddc5fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EndpointName                                                 | Status\n",
      "--------------------------------------------------------------------------------\n",
      "svs-deid-pipeline                                            | InService\n"
     ]
    }
   ],
   "source": [
    "sagemaker = boto_session.client(\"sagemaker\")\n",
    "paginator = sagemaker.get_paginator(\"list_endpoints\")\n",
    "\n",
    "endpoints_found = False\n",
    "\n",
    "for page in paginator.paginate():\n",
    "    if page[\"Endpoints\"]:\n",
    "        if not endpoints_found:\n",
    "            print(f\"{'EndpointName':<60} | {'Status'}\")\n",
    "            print(\"-\" * 80)\n",
    "            endpoints_found = True\n",
    "        for ep in page[\"Endpoints\"]:\n",
    "            name = ep[\"EndpointName\"]\n",
    "            status = ep[\"EndpointStatus\"]\n",
    "            print(f\"{name:<60} | {status}\")\n",
    "\n",
    "if not endpoints_found:\n",
    "    print(\"No endpoints found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db52453a855182a5",
   "metadata": {},
   "source": [
    "# 1. Upload a SVS file to S3 if not already done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50dc916547c1004",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 1: Download the SVS file from GitHub\n",
    "svs_url = \"https://github.com/JohnSnowLabs/visual-nlp-workshop/raw/refs/heads/master/jupyter/data/svs/62893.svs\"\n",
    "local_path = \"input.svs\"\n",
    "response = requests.get(svs_url)\n",
    "with open(local_path, \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "print(f\"Downloaded to {local_path}\")\n",
    "\n",
    "# Step 2: Upload to S3\n",
    "s3_key = f\"{model_package_name}/input/input.svs\"\n",
    "\n",
    "s3_client.upload_file(local_path, s3_bucket, s3_key)\n",
    "print(f\"Uploaded {local_path} to s3://{s3_bucket}/{s3_key}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51115e5aecd8247",
   "metadata": {},
   "source": [
    "## 2. Test Deployed Endpoint\n",
    "Do **not use** `sm_runtime.invoke_endpoint()`, it is not supported.        \n",
    "You must use `sm_runtime.invoke_endpoint_async()` for async inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403587092d1044e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ASYNC\n",
    "sm_runtime = boto_session.client(\"sagemaker-runtime\", region_name='us-east-1')\n",
    "\n",
    "response = sm_runtime.invoke_endpoint_async(\n",
    "    EndpointName=model_package_name,\n",
    "    ContentType='application/octet-stream',\n",
    "    InputLocation=f's3://{s3_bucket}/{s3_key}',\n",
    "    Accept='application/octet-stream',\n",
    ")\n",
    "# Using `invoke_endpoint_async` returns a response with an `InferenceId` and `OutputLocation` where the results will be stored.\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262c5658c850d727",
   "metadata": {},
   "source": [
    "Lets check s3 until the output file is ready and download it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f306b8436105fbce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get output S3 location\n",
    "s3 = boto_session.client('s3')\n",
    "output_s3_url = response['OutputLocation']\n",
    "parsed_url = urlparse(output_s3_url)\n",
    "bucket = parsed_url.netloc\n",
    "key = parsed_url.path.lstrip('/')\n",
    "\n",
    "print(f\"Waiting for output file to be ready at: {output_s3_url}\")\n",
    "\n",
    "# Wait until file exists in S3\n",
    "while True:\n",
    "    try:\n",
    "        s3.head_object(Bucket=bucket, Key=key)\n",
    "        print(\"Output file is ready!\")\n",
    "        break\n",
    "    except s3.exceptions.ClientError as e:\n",
    "        if e.response['Error']['Code'] == '404':\n",
    "            print(\"Still processing... checking again in 10 seconds.\")\n",
    "            time.sleep(20)\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "# Download the file\n",
    "output_path = 'input.svs.out'\n",
    "s3.download_file(bucket, key, output_path)\n",
    "print(f\"Downloaded output to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea78f469b9ed8ad",
   "metadata": {},
   "source": [
    "## Put everything in re-usable functions\n",
    "These helper functions defined below will \n",
    "1. Upload local file to S3 \n",
    "2. Submit an async inference job to the SageMaker endpoint\n",
    "3. Poll sagemaker endpoint logs until inference ID is completed, then download file  `wait_until_file_available_and_download()`\n",
    "4. Download the output file from S3 to a local path \n",
    "\n",
    "Feel free to adjust it to your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3204d60c68379c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def wait_until_file_available_and_download(s3_client, logs_client, s3_url, inference_id, log_group, download_path,\n",
    "                                           poll_interval=20, timeout=1000):\n",
    "    parsed_url = urlparse(s3_url)\n",
    "    bucket = parsed_url.netloc\n",
    "    key = parsed_url.path.lstrip('/')\n",
    "\n",
    "    print(f\"Waiting for output file at: {s3_url}\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    found_log = False\n",
    "    latency_pattern = re.compile(\n",
    "        r\"ModelLatency: (\\d+) us, \"\n",
    "        r\"RequestDownloadLatency: (\\d+) us, \"\n",
    "        r\"ResponseUploadLatency: (\\d+) us, \"\n",
    "        r\"TimeInBacklog: (\\d+) ms, \"\n",
    "        r\"TotalProcessingTime: (\\d+) ms\"\n",
    "    )\n",
    "\n",
    "    while True:\n",
    "        now = int(time.time() * 1000)\n",
    "        one_hour_ago = now - 60 * 60 * 1000\n",
    "\n",
    "        response = logs_client.filter_log_events(\n",
    "            logGroupName=log_group,\n",
    "            filterPattern=f'\"Inference request succeeded\" \"{inference_id}\"',\n",
    "            startTime=one_hour_ago,\n",
    "            endTime=now,\n",
    "            limit=10\n",
    "        )\n",
    "\n",
    "        for event in response.get(\"events\", []):\n",
    "            message = event[\"message\"]\n",
    "            match = latency_pattern.search(message)\n",
    "            if match:\n",
    "                model_latency_us = int(match.group(1))\n",
    "                request_download_latency_us = int(match.group(2))\n",
    "                response_upload_latency_us = int(match.group(3))\n",
    "                time_in_backlog_ms = int(match.group(4))\n",
    "                total_processing_ms = int(match.group(5))\n",
    "\n",
    "                print(\"📦 Inference Latency Breakdown (in seconds):\")\n",
    "                print(f\"🧠 ModelLatency:           {model_latency_us / 1e6:.3f} s\")\n",
    "                print(f\"⬇️ RequestDownloadLatency: {request_download_latency_us / 1e6:.3f} s\")\n",
    "                print(f\"⬆️ ResponseUploadLatency:  {response_upload_latency_us / 1e6:.3f} s\")\n",
    "                print(f\"⏳ TimeInBacklog:          {time_in_backlog_ms / 1e3:.3f} s\")\n",
    "                print(f\"📈 TotalProcessingTime:    {total_processing_ms / 1e3:.3f} s\")\n",
    "                found_log = True\n",
    "                break\n",
    "\n",
    "        if found_log:\n",
    "            break\n",
    "\n",
    "        if time.time() - start_time > timeout:\n",
    "            raise TimeoutError(\"Timeout waiting for inference logs.\")\n",
    "\n",
    "        print(\"Still processing... checking logs again shortly.\")\n",
    "        time.sleep(poll_interval)\n",
    "\n",
    "    # Now poll S3 for result\n",
    "    while True:\n",
    "        try:\n",
    "            s3_client.head_object(Bucket=bucket, Key=key)\n",
    "            print(\"Output file is ready!\")\n",
    "            break\n",
    "        except s3_client.exceptions.ClientError as e:\n",
    "            if e.response['Error']['Code'] == '404':\n",
    "                if time.time() - start_time > timeout:\n",
    "                    raise TimeoutError(\"Timeout waiting for output file.\")\n",
    "                print(\"Still processing... checking S3 again shortly.\")\n",
    "                time.sleep(poll_interval)\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "    s3_client.download_file(bucket, key, download_path)\n",
    "    print(f\"Downloaded output to {download_path}\")\n",
    "    return download_path\n",
    "\n",
    "\n",
    "def upload_file_to_s3(s3_client, local_path, s3_path):\n",
    "    parsed = urlparse(s3_path)\n",
    "    bucket = parsed.netloc\n",
    "    key = parsed.path.lstrip('/')\n",
    "\n",
    "    print(f\"Uploading {local_path} to {s3_path}...\")\n",
    "    s3_client.upload_file(local_path, bucket, key)\n",
    "    print(\"Upload complete.\")\n",
    "\n",
    "\n",
    "def process_and_download(\n",
    "        input_s3_path,\n",
    "        endpoint_name,\n",
    "        download_path,\n",
    "        region='us-east-1',\n",
    "        poll_interval=10,\n",
    "        timeout=600,\n",
    "        local_svs_to_upload=None,\n",
    "        deid_tags=None\n",
    "):\n",
    "    s3 = boto_session.client(\"s3\", region_name=region)\n",
    "    sm_runtime = boto_session.client(\"sagemaker-runtime\", region_name=region)\n",
    "    logs = boto_session.client(\"logs\", region_name=region)\n",
    "\n",
    "    if local_svs_to_upload:\n",
    "        upload_file_to_s3(s3, local_svs_to_upload, input_s3_path)\n",
    "\n",
    "    custom_attributes = None\n",
    "    if deid_tags:\n",
    "        custom_attributes = f\"svs_tags={','.join(deid_tags)}\"\n",
    "        print(f\"Sending custom attributes: {custom_attributes}\")\n",
    "\n",
    "    response = sm_runtime.invoke_endpoint_async(\n",
    "        EndpointName=endpoint_name,\n",
    "        ContentType='application/octet-stream',\n",
    "        InputLocation=input_s3_path,\n",
    "        Accept='application/octet-stream',\n",
    "        CustomAttributes=custom_attributes\n",
    "    )\n",
    "\n",
    "    print(f'Got response: {response}')\n",
    "\n",
    "    inference_id = response['InferenceId']\n",
    "    output_s3_url = response['OutputLocation']\n",
    "    log_group = f\"/aws/sagemaker/Endpoints/{endpoint_name}\"\n",
    "\n",
    "    return wait_until_file_available_and_download(\n",
    "        s3_client=s3,\n",
    "        logs_client=logs,\n",
    "        s3_url=output_s3_url,\n",
    "        inference_id=inference_id,\n",
    "        log_group=log_group,\n",
    "        download_path=download_path,\n",
    "        poll_interval=poll_interval,\n",
    "        timeout=timeout\n",
    "    )\n",
    "\n",
    "\n",
    "# Example usage\n",
    "\n",
    "process_and_download(\n",
    "    # Specify the Sagemaker endpoint name\n",
    "    endpoint_name=model_package_name,\n",
    "\n",
    "    # Specify the S3 path where the input SVS file is located or will be uploaded\n",
    "    input_s3_path=f's3://{s3_bucket}/{s3_key}',\n",
    "\n",
    "    # Specify the local SVS file to upload, if needed\n",
    "    local_svs_to_upload=None,\n",
    "\n",
    "    # Specify the local path where you want to download the output\n",
    "    download_path='output.svs',\n",
    "\n",
    "    # Specify the tags you want to de-identify from SVS metadata\n",
    "    deid_tags=[\n",
    "        'ImageDescription.ScanScope ID',\n",
    "        'ImageDescription.Time Zone',\n",
    "        'ImageDescription.ScannerType',\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db35f528",
   "metadata": {},
   "source": [
    "Now that you have successfully performed a real-time inference, you do not need the endpoint any more. You can terminate the endpoint to avoid being charged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "26e4f30e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.sagemaker_session.delete_endpoint(model.endpoint_name)\n",
    "model.sagemaker_session.delete_endpoint_config(model.endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ee269c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.delete_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
