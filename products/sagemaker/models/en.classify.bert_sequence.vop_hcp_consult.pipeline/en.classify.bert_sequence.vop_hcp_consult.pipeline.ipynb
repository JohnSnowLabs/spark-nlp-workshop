{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Subscribe to the model package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To subscribe to the model package:\n",
    "1. Open the model package listing page <font color='red'> For Seller to update:[Title_of_your_product](Provide link to your marketplace listing of your product).</font>\n",
    "1. On the AWS Marketplace listing, click on the **Continue to subscribe** button.\n",
    "1. On the **Subscribe to this software** page, review and click on **\"Accept Offer\"** if you and your organization agrees with EULA, pricing, and support terms. \n",
    "1. Once you click on **Continue to configuration button** and then choose a **region**, you will see a **Product Arn** displayed. This is the model package ARN that you need to specify while creating a deployable model using Boto3. Copy the ARN corresponding to your region and specify the same in the following cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text classification\n",
    "\n",
    "Text classification is a common task in natural language processing (NLP) where text is categorized into different labels or classes.\n",
    "\n",
    "\n",
    "- **Model**: `en.classify.bert_sequence.vop_hcp_consult.pipeline`\n",
    "- **Model Description**: This pretrained pipeline is built on top of the `bert_sequence_classifier_vop_hcp_consult` model, which includes the Medical Bert for Sequence Classification model to identify texts that mention a HCP consult.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_package_arn = \"<Customer to specify Model package ARN corresponding to their AWS region>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import json\n",
    "import uuid\n",
    "from sagemaker import ModelPackage\n",
    "import sagemaker as sage\n",
    "from sagemaker import get_execution_role\n",
    "import boto3\n",
    "from IPython.display import Image, display\n",
    "from PIL import Image as ImageEdit\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sagemaker_session = sage.Session()\n",
    "s3_bucket = sagemaker_session.default_bucket()\n",
    "region = sagemaker_session.boto_region_name\n",
    "account_id = boto3.client(\"sts\").get_caller_identity().get(\"Account\")\n",
    "role = get_execution_role()\n",
    "\n",
    "sagemaker = boto3.client(\"sagemaker\")\n",
    "s3_client = sagemaker_session.boto_session.client(\"s3\")\n",
    "ecr = boto3.client(\"ecr\")\n",
    "sm_runtime = boto3.client(\"sagemaker-runtime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create an endpoint and perform real-time inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to understand how real-time inference with Amazon SageMaker works, see [Documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-hosting.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"en-classify-bert-sequence-vop-hcp-consult-pipeline\"\n",
    "\n",
    "content_type = \"application/json\"\n",
    "\n",
    "real_time_inference_instance_type = \"ml.m4.xlarge\"\n",
    "batch_transform_inference_instance_type = \"ml.m4.xlarge\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Create an endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "# create a deployable model from the model package.\n",
    "model = ModelPackage(\n",
    "    role=role, model_package_arn=model_package_arn, sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "# Deploy the model\n",
    "predictor = model.deploy(1, real_time_inference_instance_type, endpoint_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once endpoint has been created, you would be able to perform real-time inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Perform real-time inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import boto3\n",
    "\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "\n",
    "def process_data_and_invoke_realtime_endpoint(data_dicts):\n",
    "    for data_dict in data_dicts:\n",
    "        json_input_data = json.dumps(data_dict)    \n",
    "        i = 1\n",
    "        input_file_name = f'inputs/real-time/input{i}.json'\n",
    "        output_file_name = f'outputs/real-time/out{i}.out'\n",
    "\n",
    "        while os.path.exists(input_file_name) or os.path.exists(output_file_name):\n",
    "            i += 1\n",
    "            input_file_name = f'inputs/real-time/input{i}.json'\n",
    "            output_file_name = f'outputs/real-time/out{i}.out'\n",
    "\n",
    "        os.makedirs(os.path.dirname(input_file_name), exist_ok=True)\n",
    "        os.makedirs(os.path.dirname(output_file_name), exist_ok=True)\n",
    "\n",
    "        with open(input_file_name, 'w') as f:\n",
    "            f.write(json_input_data)\n",
    "\n",
    "        s3_client.put_object(Bucket=s3_bucket, Key=f\"{model_name}/validation-input-json/real-time/{os.path.basename(input_file_name)}\", Body=bytes(json_input_data.encode('UTF-8')))\n",
    "\n",
    "        response = sm_runtime.invoke_endpoint(\n",
    "            EndpointName=model_name,\n",
    "            ContentType=content_type,\n",
    "            Accept=\"application/json\",\n",
    "            Body=json_input_data,\n",
    "        )\n",
    "\n",
    "        # Process response\n",
    "        response_data = json.loads(response[\"Body\"].read().decode(\"utf-8\"))\n",
    "\n",
    "        df = pd.DataFrame(response_data[\"predictions\"])\n",
    "\n",
    "        display(df)\n",
    "\n",
    "        # Save response data to file\n",
    "        with open(output_file_name, 'w') as f_out:\n",
    "            json.dump(response_data, f_out, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs = [\n",
    "    \"hi does anybody have feet aches with anxiety, i do suffer from anxiety but never had anything wrong with my feet before\",\n",
    "    \"My son has been to two doctors who gave him antibiotic drops but they also say the problem might related to allergies.\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "sample_text = \"My daughter has been to two physicians who prescribed antibiotic drops but they also suspect the issue might be related to allergies.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "  **Input format**:\n",
    "  \n",
    "  \n",
    "```json\n",
    "{\n",
    "    \"text\": \"Single text document\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Other</td>\n",
       "      <td>0.955436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  prediction  confidence\n",
       "0      Other    0.955436"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_dicts = [\n",
    "    {\n",
    "        \"text\": sample_text\n",
    "    }\n",
    "]\n",
    "\n",
    "process_data_and_invoke_realtime_endpoint(data_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  **Input format**:\n",
    "  \n",
    "  \n",
    "```json\n",
    "{\n",
    "    \"text\": [\n",
    "        \"Text document 1\",\n",
    "        \"Text document 2\",\n",
    "        ...\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Other</td>\n",
       "      <td>0.997565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Consulted_By_HCP</td>\n",
       "      <td>0.930115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         prediction  confidence\n",
       "0             Other    0.997565\n",
       "1  Consulted_By_HCP    0.930115"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_dicts = [\n",
    "    {\n",
    "        \"text\": docs\n",
    "    }\n",
    "]\n",
    "\n",
    "process_data_and_invoke_realtime_endpoint(data_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Delete the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have successfully performed a real-time inference, you do not need the endpoint any more. You can terminate the endpoint to avoid being charged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.sagemaker_session.delete_endpoint(model_name)\n",
    "model.sagemaker_session.delete_endpoint_config(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Batch inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "validation_file_name = \"input.json\"\n",
    "\n",
    "validation_input_path = f\"s3://{s3_bucket}/{model_name}/validation-input-json/batch\"\n",
    "validation_output_path = f\"s3://{s3_bucket}/{model_name}/validation-output-json/batch\"\n",
    "\n",
    "input_dir = 'inputs/batch'\n",
    "output_dir = 'outputs/batch'\n",
    "\n",
    "os.makedirs(input_dir, exist_ok=True)\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def write_and_upload_to_s3(json_input_data, file_name):\n",
    "\n",
    "    json_data = json.dumps(json_input_data)\n",
    "\n",
    "    with open(file_name, \"w\") as f:\n",
    "        f.write(json_data)\n",
    "\n",
    "    s3_client.put_object(\n",
    "        Bucket=s3_bucket,\n",
    "        Key=f\"{model_name}/validation-input-json/batch/{os.path.basename(file_name)}\",\n",
    "        Body=(bytes(json_data.encode(\"UTF-8\"))),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define input JSON data for each validation file\n",
    "input_json_data = {\"text\": docs}\n",
    "\n",
    "write_and_upload_to_s3(input_json_data, f\"{input_dir}/{validation_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize a SageMaker Transformer object for making predictions\n",
    "transformer = model.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type=batch_transform_inference_instance_type,\n",
    "    accept=\"application/json\",\n",
    ")\n",
    "transformer.transform(validation_input_path, content_type=content_type)\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "def process_s3_output_and_save(validation_file_name, output_file_name):\n",
    "\n",
    "    output_file_path = f\"{output_dir}/{output_file_name}\"\n",
    "    parsed_url = urlparse(transformer.output_path)\n",
    "    file_key = f\"{parsed_url.path[1:]}/{validation_file_name}.out\"\n",
    "    response = s3_client.get_object(Bucket=s3_bucket, Key=file_key)\n",
    "\n",
    "    data = json.loads(response[\"Body\"].read().decode(\"utf-8\"))\n",
    "    df = pd.DataFrame(data[\"predictions\"])\n",
    "    display(df)\n",
    "\n",
    "    # Save the data to the output file\n",
    "    with open(output_file_path, 'w') as f_out:\n",
    "        json.dump(data, f_out, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Other</td>\n",
       "      <td>0.997565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Consulted_By_HCP</td>\n",
       "      <td>0.930115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         prediction  confidence\n",
       "0             Other    0.997565\n",
       "1  Consulted_By_HCP    0.930115"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "process_s3_output_and_save(validation_file_name, \"out.out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting model with name: en-classify-bert-sequence-vop-hcp-consu-2024-03-19-08-12-59-369\n"
     ]
    }
   ],
   "source": [
    "model.delete_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsubscribe to the listing (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to unsubscribe to the model package, follow these steps. Before you cancel the subscription, ensure that you do not have any [deployable model](https://console.aws.amazon.com/sagemaker/home#/models) created from the model package or using the algorithm. Note - You can find this information by looking at the container name associated with the model. \n",
    "\n",
    "**Steps to unsubscribe to product from AWS Marketplace**:\n",
    "1. Navigate to __Machine Learning__ tab on [__Your Software subscriptions page__](https://aws.amazon.com/marketplace/ai/library?productType=ml&ref_=mlmp_gitdemo_indust)\n",
    "2. Locate the listing that you want to cancel the subscription for, and then choose __Cancel Subscription__  to cancel the subscription.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
