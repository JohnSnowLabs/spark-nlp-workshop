{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Train a Spark NLP Model.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/models_hub/Train_a_Spark_NLP_Model.ipynb)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WZEkgBuabyGF"
   },
   "source": [
    "%%capture\n",
    " \n",
    "# Setup Spark NLP on Colab\n",
    "!wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/colab_setup.sh -O - | bash"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7i4Z9OrgcE4b",
    "outputId": "579e109c-2eb9-4a6c-aadb-8ad4c14b76c1"
   },
   "source": [
    "import sparknlp\n",
    " \n",
    "spark = sparknlp.start() # for GPU training >> sparknlp.start(gpu = True) # for Spark 2.3 =>> sparknlp.start(spark23 = True)\n",
    "import pyspark.sql.functions as F\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import *\n",
    "import sparknlp\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    " \n",
    "print(\"Spark NLP version\", sparknlp.version())\n",
    " \n",
    "print(\"Apache Spark version:\", spark.version)"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Spark NLP version 3.1.0\n",
      "Apache Spark version: 3.0.2\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ooWKiaQEcUPB"
   },
   "source": [
    "#download training data\n",
    "!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/src/test/resources/conll2003/eng.train\n",
    "!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/src/test/resources/conll2003/eng.testa"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jn72rDuTcW_l"
   },
   "source": [
    "from sparknlp.training import CoNLL\n",
    "\n",
    "training_data = CoNLL().readDataset(spark, './eng.train')\n",
    "testing_data= CoNLL().readDataset(spark, './eng.testa')"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1RW2pBP_cdgP",
    "outputId": "a70f0a9d-b7b8-4d4c-8bf9-98dd85e06917"
   },
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "training_data.select(F.explode(F.arrays_zip('token.result', 'pos.result',  'label.result')).alias(\"cols\")) \\\n",
    ".select(F.expr(\"cols['0']\").alias(\"token\"),\n",
    "        F.expr(\"cols['1']\").alias(\"pos\"),\n",
    "        F.expr(\"cols['2']\").alias(\"ner_label\")).show(truncate=50)"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+---+---------+\n",
      "|     token|pos|ner_label|\n",
      "+----------+---+---------+\n",
      "|        EU|NNP|    B-ORG|\n",
      "|   rejects|VBZ|        O|\n",
      "|    German| JJ|   B-MISC|\n",
      "|      call| NN|        O|\n",
      "|        to| TO|        O|\n",
      "|   boycott| VB|        O|\n",
      "|   British| JJ|   B-MISC|\n",
      "|      lamb| NN|        O|\n",
      "|         .|  .|        O|\n",
      "|     Peter|NNP|    B-PER|\n",
      "| Blackburn|NNP|    I-PER|\n",
      "|  BRUSSELS|NNP|    B-LOC|\n",
      "|1996-08-22| CD|        O|\n",
      "|       The| DT|        O|\n",
      "|  European|NNP|    B-ORG|\n",
      "|Commission|NNP|    I-ORG|\n",
      "|      said|VBD|        O|\n",
      "|        on| IN|        O|\n",
      "|  Thursday|NNP|        O|\n",
      "|        it|PRP|        O|\n",
      "+----------+---+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cLule_H4rDmv"
   },
   "source": [
    "## 1. Create Spark NLP train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Z6mvq8Avcjyx",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "3b029733-eaf7-4eb4-d1ad-2b1dd3c2761a"
   },
   "source": [
    "!mkdir ner_logs"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mkdir: cannot create directory ‘ner_logs’: File exists\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zijeZRPrcmE4",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4bf81eeb-db55-4229-d792-08a93b81fc6a"
   },
   "source": [
    "# You can use any word embeddings you want (Glove, Elmo, Bert, custom etc.)\n",
    "\n",
    "embeddings = WordEmbeddingsModel.pretrained('glove_100d')\\\n",
    "          .setInputCols([\"document\", \"token\"])\\\n",
    "          .setOutputCol(\"embeddings\")\n",
    "\n",
    "nerTagger = NerDLApproach()\\\n",
    "      .setInputCols([\"sentence\", \"token\", \"embeddings\"])\\\n",
    "      .setLabelColumn(\"label\")\\\n",
    "      .setOutputCol(\"ner\")\\\n",
    "      .setMaxEpochs(1)\\\n",
    "      .setLr(0.003)\\\n",
    "      .setBatchSize(32)\\\n",
    "      .setRandomSeed(0)\\\n",
    "      .setVerbose(1)\\\n",
    "      .setValidationSplit(0.2)\\\n",
    "      .setEvaluationLogExtended(True) \\\n",
    "      .setEnableOutputLogs(True)\\\n",
    "      .setIncludeConfidence(True)\\\n",
    "      .setOutputLogsPath('ner_logs') # if not set, logs will be written to ~/annotator_logs\n",
    " #    .setGraphFolder('graphs') >> put your graph file (pb) under this folder if you are using a custom graph generated thru 4.1 NerDL-Graph.ipynb notebook\n",
    " #    .setEnableMemoryOptimizer() >> if you have a limited memory and a large conll file, you can set this True to train batch by batch \n",
    "    \n",
    "ner_converter = NerConverter() \\\n",
    "    .setInputCols(['document', 'token', 'ner']) \\\n",
    "    .setOutputCol('ner_chunk')\n",
    "\n",
    "ner_pipeline = Pipeline(stages=[\n",
    "      embeddings,\n",
    "      nerTagger,\n",
    "      ner_converter\n",
    " ])"
   ],
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "glove_100d download started this may take some time.\n",
      "Approximate size to download 145.3 MB\n",
      "[OK!]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6lJ8fCjmrLtw"
   },
   "source": [
    "## 2. Train model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rsJO74W-czVS",
    "outputId": "74055cac-d50c-470b-e420-4178278e873d"
   },
   "source": [
    "%%time\n",
    "ner_model = ner_pipeline.fit(training_data)\n",
    "ner_model.stages[-1].write().overwrite().save('outputs/ner_wiki_glove100d_en')"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 1.01 s, sys: 131 ms, total: 1.14 s\n",
      "Wall time: 3min 8s\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3TIDdUYHdG7y",
    "outputId": "7eb373a6-f632-4e28-a31d-e069926b5fdf"
   },
   "source": [
    "import pyspark.sql.functions as F\n",
    "predictions = ner_model.transform(testing_data) \n",
    "predictions.select(F.explode(F.arrays_zip('token.result','label.result','ner.result')).alias(\"cols\")) \\\n",
    "           .select(F.expr(\"cols['0']\").alias(\"token\"),\n",
    "                   F.expr(\"cols['1']\").alias(\"ground_truth\"),\n",
    "                   F.expr(\"cols['2']\").alias(\"prediction\")).show(truncate=False)"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------+------------+----------+\n",
      "|token         |ground_truth|prediction|\n",
      "+--------------+------------+----------+\n",
      "|CRICKET       |O           |O         |\n",
      "|-             |O           |O         |\n",
      "|LEICESTERSHIRE|B-ORG       |B-ORG     |\n",
      "|TAKE          |O           |O         |\n",
      "|OVER          |O           |O         |\n",
      "|AT            |O           |O         |\n",
      "|TOP           |O           |O         |\n",
      "|AFTER         |O           |O         |\n",
      "|INNINGS       |O           |O         |\n",
      "|VICTORY       |O           |O         |\n",
      "|.             |O           |O         |\n",
      "|LONDON        |B-LOC       |B-LOC     |\n",
      "|1996-08-30    |O           |O         |\n",
      "|West          |B-MISC      |B-MISC    |\n",
      "|Indian        |I-MISC      |B-MISC    |\n",
      "|all-rounder   |O           |O         |\n",
      "|Phil          |B-PER       |B-PER     |\n",
      "|Simmons       |I-PER       |I-PER     |\n",
      "|took          |O           |O         |\n",
      "|four          |O           |O         |\n",
      "+--------------+------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M7gTMzBXSJY1"
   },
   "source": [
    "## 3. Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hV8fcONKdMgF",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "07be85e0-501f-447f-cdb9-38dca72d7fd3"
   },
   "source": [
    "from sklearn.metrics import classification_report\n",
    " \n",
    "preds_df = predictions.select(F.explode(F.arrays_zip('token.result','label.result','ner.result')).alias(\"cols\")) \\\n",
    "                      .select(F.expr(\"cols['0']\").alias(\"token\"),\n",
    "                              F.expr(\"cols['1']\").alias(\"ground_truth\"),\n",
    "                              F.expr(\"cols['2']\").alias(\"prediction\")).toPandas()\n",
    " \n",
    "print(classification_report(preds_df['ground_truth'], preds_df['prediction']))"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.93      0.91      0.92      1837\n",
      "      B-MISC       0.79      0.87      0.83       922\n",
      "       B-ORG       0.88      0.81      0.84      1341\n",
      "       B-PER       0.93      0.96      0.95      1842\n",
      "       I-LOC       0.93      0.68      0.78       257\n",
      "      I-MISC       0.78      0.61      0.68       346\n",
      "       I-ORG       0.86      0.70      0.77       751\n",
      "       I-PER       0.96      0.97      0.96      1307\n",
      "           O       0.99      1.00      0.99     42759\n",
      "\n",
      "    accuracy                           0.98     51362\n",
      "   macro avg       0.89      0.83      0.86     51362\n",
      "weighted avg       0.98      0.98      0.98     51362\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "562zPiw4SlRg"
   },
   "source": [
    "## 4. Saving model and Zipping it"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cwIo061j8KPm",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "outputId": "e5ae8d70-69f5-4ab3-cf93-9280aadfdc1d"
   },
   "source": [
    "import shutil\n",
    "\n",
    "shutil.make_archive(\"/content/outputs/ner_wiki_glove100d_en\", 'zip', \"/content/outputs/ner_wiki_glove100d_en\")"
   ],
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/outputs/ner_wiki_glove100d_en.zip'"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ]
  }
 ]
}