{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "c168511e-1278-4fe1-9e10-f55f7cb69213"
        },
        "id": "qZyBOOIzgMFf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Serving Spark NLP with API: Synapse ML"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "64263998-73cc-4de7-914b-63f09d5f6ce2"
        },
        "id": "P41lOks_gMFj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SynapseML"
      ],
      "metadata": {
        "id": "fhoeHWW1lcHN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation"
      ],
      "metadata": {
        "tags": [],
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "6a45dc2c-211e-46c7-8e7d-88aeddf1e6e5"
        },
        "id": "XWoKybSqgMFk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import json\n",
        "import os\n",
        "with open('spark_nlp_for_healthcare-3.4.0.json') as f:\n",
        "    license_keys = json.load(f)\n",
        "    \n",
        "locals().update(license_keys)\n",
        "os.environ.update(license_keys)"
      ],
      "metadata": {
        "id": "knjt2yEliM8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark==3.2.0 spark-nlp==$PUBLIC_VERSION"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "eb9af348-1a22-4db6-97be-48d9aca0906c"
        },
        "id": "RGgp_LnugMFk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spark-nlp-jsl==$JSL_VERSION --extra-index-url https://pypi.johnsnowlabs.com/$SECRET"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "59fa8b64-322a-4bb2-94ea-4a5432c0f6bc"
        },
        "id": "LV80dAx3gMFm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "fab81cae-cd66-4b52-8cf3-6cf2f8862357"
        },
        "id": "70Lz2EAugMFm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "sparknlpjsl_jar = \"./spark-nlp-jsl.jar\" # Download the FAT jar to include it in the SparkSession. This is reuquired by SynapseML"
      ],
      "metadata": {
        "id": "d3zcmK-8imAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Imports and Spark Session"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "e46207ef-867c-48ec-9f1c-219a8e5ff750"
        },
        "id": "AFde6nnSgMFm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pyspark\n",
        "import sparknlp\n",
        "import sparknlp_jsl\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml import Pipeline, PipelineModel\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.types import *\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp_jsl.annotator import *\n",
        "from sparknlp.training import *\n",
        "from sparknlp.training import CoNLL\n",
        "import time\n",
        "import requests\n",
        "import uuid\n",
        "import json\n",
        "import requests\n",
        "from concurrent.futures import ThreadPoolExecutor\n"
      ],
      "metadata": {
        "scrolled": true,
        "tags": [],
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "71837fea-adb4-4e5f-90d7-0eb474d5067d"
        },
        "id": "HoDZoYJxgMFn",
        "outputId": "c9f0e123-8beb-410d-fbbb-2176ca88ac88"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\"></div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "metadata": {},
              "type": "html",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"
            ]
          },
          "transient": null
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Spark\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .config(\"spark.driver.memory\", \"16G\") \\\n",
        "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
        "    .config(\"spark.kryoserializer.buffer.max\", \"2000M\") \\\n",
        "    .config(\"spark.jars.packages\", \"com.microsoft.azure:synapseml_2.12:0.9.5,com.johnsnowlabs.nlp:spark-nlp-spark32_2.12:3.4.0\")\\\n",
        "    .config(\"spark.jars\", sparknlpjsl_jar)\\\n",
        "    .config(\"spark.jars.repositories\", \"https://mmlspark.azureedge.net/maven\")\\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "b0LKm7ruip_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sparknlp.version())\n",
        "print(sparknlp_jsl.version())"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "0060d257-0ca2-4e43-a641-675db36ba689"
        },
        "id": "7HZXmvaHgMFo",
        "outputId": "614bbae7-ff5c-46b6-c540-060e8281ead0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\">3.4.0\n3.4.0\n</div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "metadata": {},
              "type": "html",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">3.4.0\n3.4.0\n</div>"
            ]
          },
          "transient": null
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "aff6c8fc-92cc-4166-ae9b-050574fa51a0"
        },
        "id": "gns8bOFJgMFp",
        "outputId": "9f65dc73-20a4-4b21-f5cd-9acb0f00a6ee"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\">Out[8]: </div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "metadata": {},
              "type": "html",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[8]: </div>"
            ]
          },
          "transient": null
        },
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=7956323724731612#setting/sparkui/0127-082007-5g2tpazx/driver-1729089974107808210\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.2.0</code></dd>\n              <dt>Master</dt>\n                <dd><code>spark://10.139.64.12:7077</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ",
              "textData": null,
              "removedWidgets": [],
              "addedWidgets": {},
              "metadata": {},
              "type": "htmlSandbox",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=7956323724731612#setting/sparkui/0127-082007-5g2tpazx/driver-1729089974107808210\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.2.0</code></dd>\n              <dt>Master</dt>\n                <dd><code>spark://10.139.64.12:7077</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "
            ]
          },
          "transient": null
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import synapse.ml\n",
        "from synapse.ml.io import *"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "7dc0cb8e-01d1-4dae-a266-d2bda3292185"
        },
        "id": "8_f_PasWgMFp",
        "outputId": "7ad6e2a5-309a-473d-94c7-79df761df3aa"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\"></div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "metadata": {},
              "type": "html",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"
            ]
          },
          "transient": null
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing a pipeline with Entity Resolution"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "af6149fb-1df7-476d-b74b-0256789151b0"
        },
        "id": "jzvMA3IJgMFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Annotator that transforms a text column from dataframe into an Annotation ready for NLP\n",
        "document_assembler = DocumentAssembler()\\\n",
        "      .setInputCol(\"text\")\\\n",
        "      .setOutputCol(\"document\")\n",
        "\n",
        "# Sentence Detector DL annotator, processes various sentences per line\n",
        "sentenceDetectorDL = SentenceDetectorDLModel.pretrained(\"sentence_detector_dl_healthcare\", \"en\", 'clinical/models') \\\n",
        "      .setInputCols([\"document\"]) \\\n",
        "      .setOutputCol(\"sentence\")\n",
        "\n",
        "# Tokenizer splits words in a relevant format for NLP\n",
        "tokenizer = Tokenizer()\\\n",
        "      .setInputCols([\"sentence\"])\\\n",
        "      .setOutputCol(\"token\")\n",
        "\n",
        "# WordEmbeddingsModel pretrained \"embeddings_clinical\" includes a model of 1.7Gb that needs to be downloaded\n",
        "word_embeddings = WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n",
        "  .setInputCols([\"sentence\", \"token\"])\\\n",
        "  .setOutputCol(\"word_embeddings\")\n",
        "\n",
        "# Named Entity Recognition for clinical concepts.\n",
        "clinical_ner = MedicalNerModel.pretrained(\"ner_clinical\", \"en\", \"clinical/models\") \\\n",
        "      .setInputCols([\"sentence\", \"token\", \"word_embeddings\"]) \\\n",
        "      .setOutputCol(\"ner\")\n",
        "\n",
        "ner_converter_icd = NerConverterInternal() \\\n",
        "      .setInputCols([\"sentence\", \"token\", \"ner\"]) \\\n",
        "      .setOutputCol(\"ner_chunk\")\\\n",
        "      .setWhiteList(['PROBLEM'])\\\n",
        "      .setPreservePosition(False)\n",
        "\n",
        "c2doc = Chunk2Doc()\\\n",
        "      .setInputCols(\"ner_chunk\")\\\n",
        "      .setOutputCol(\"ner_chunk_doc\") \n",
        "\n",
        "sbert_embedder = BertSentenceEmbeddings.pretrained('sbiobert_base_cased_mli', 'en','clinical/models')\\\n",
        "      .setInputCols([\"ner_chunk_doc\"])\\\n",
        "      .setOutputCol(\"sentence_embeddings\")\\\n",
        "      .setCaseSensitive(False)\n",
        "    \n",
        "icd_resolver = SentenceEntityResolverModel.pretrained(\"sbiobertresolve_icd10cm_augmented_billable_hcc\",\"en\", \"clinical/models\") \\\n",
        "     .setInputCols([\"ner_chunk\", \"sentence_embeddings\"]) \\\n",
        "     .setOutputCol(\"icd10cm_code\")\\\n",
        "     .setDistanceFunction(\"EUCLIDEAN\")\n",
        "    \n",
        "\n",
        "# Build up the pipeline\n",
        "resolver_pipeline = Pipeline(\n",
        "    stages = [\n",
        "        document_assembler,\n",
        "        sentenceDetectorDL,\n",
        "        tokenizer,\n",
        "        word_embeddings,\n",
        "        clinical_ner,\n",
        "        ner_converter_icd,\n",
        "        c2doc,\n",
        "        sbert_embedder,\n",
        "        icd_resolver\n",
        "  ])\n",
        "\n",
        "\n",
        "empty_data = spark.createDataFrame([['']]).toDF(\"text\")\n",
        "\n",
        "resolver_p_model = resolver_pipeline.fit(empty_data)"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "68f6b971-2097-46f7-a8e3-331c6373b91d"
        },
        "id": "dFxLKwBGgMFq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding a clinical note as a text example"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "c642dcd8-8dd1-45e9-9468-fd8a1e524ba0"
        },
        "id": "D7EocdfogMFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clinical_note = \"\"\"A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years \n",
        "    prior to presentation and subsequent type two diabetes mellitus (T2DM), one prior \n",
        "    episode of HTG-induced pancreatitis three years prior to presentation, associated \n",
        "    with an acute hepatitis, and obesity with a body mass index (BMI) of 33.5 kg/m2, \n",
        "    presented with a one-week history of polyuria, polydipsia, poor appetite, and vomiting. \n",
        "    Two weeks prior to presentation, she was treated with a five-day course of amoxicillin \n",
        "    for a respiratory tract infection. She was on metformin, glipizide, and dapagliflozin \n",
        "    for T2DM and atorvastatin and gemfibrozil for HTG. She had been on dapagliflozin for six months \n",
        "    at the time of presentation. Physical examination on presentation was significant for dry oral mucosa; \n",
        "    significantly, her abdominal examination was benign with no tenderness, guarding, or rigidity. Pertinent \n",
        "    laboratory findings on admission were: serum glucose 111 mg/dl, bicarbonate 18 mmol/l, anion gap 20, \n",
        "    creatinine 0.4 mg/dL, triglycerides 508 mg/dL, total cholesterol 122 mg/dL, glycated hemoglobin (HbA1c) \n",
        "    10%, and venous pH 7.27. Serum lipase was normal at 43 U/L. Serum acetone levels could not be assessed \n",
        "    as blood samples kept hemolyzing due to significant lipemia. The patient was initially admitted for \n",
        "    starvation ketosis, as she reported poor oral intake for three days prior to admission. However, \n",
        "    serum chemistry obtained six hours after presentation revealed her glucose was 186 mg/dL, the anion gap \n",
        "    was still elevated at 21, serum bicarbonate was 16 mmol/L, triglyceride level peaked at 2050 mg/dL, and \n",
        "    lipase was 52 U/L. The Î²-hydroxybutyrate level was obtained and found to be elevated at 5.29 mmol/L - \n",
        "    the original sample was centrifuged and the chylomicron layer removed prior to analysis due to \n",
        "    interference from turbidity caused by lipemia again. The patient was treated with an insulin drip \n",
        "    for euDKA and HTG with a reduction in the anion gap to 13 and triglycerides to 1400 mg/dL, within \n",
        "    24 hours. Her euDKA was thought to be precipitated by her respiratory tract infection in the setting \n",
        "    of SGLT2 inhibitor use. The patient was seen by the endocrinology service and she was discharged on \n",
        "    40 units of insulin glargine at night, 12 units of insulin lispro with meals, and metformin 1000 mg \n",
        "    two times a day. It was determined that all SGLT2 inhibitors should be discontinued indefinitely. She \n",
        "    had close follow-up with endocrinology post discharge.\"\"\"\n",
        "\n",
        "\n",
        "data = spark.createDataFrame([[clinical_note]]).toDF(\"text\")"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "d06acccf-1773-4d4c-b02c-3aa7045c0548"
        },
        "id": "7mOcVmZ6gMFr",
        "outputId": "1827385a-f98c-4557-9675-f9127ccf97b2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\"></div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "metadata": {},
              "type": "html",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"
            ]
          },
          "transient": null
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a JSON file with the clinical note\n",
        "Since SynapseML runs a webservice that accepts HTTP calls with json format"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "82044e07-6c3b-497c-a65a-bbf8d5ba2a12"
        },
        "id": "CXO1JX2jgMFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_json = {\"text\": clinical_note }"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "e0e402f4-859d-481e-8cc3-9f5b366bcf73"
        },
        "id": "yac_FVrpgMFs",
        "outputId": "463a65c5-c6c0-4dfd-f636-2dfdb891563d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\"></div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "metadata": {},
              "type": "html",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"
            ]
          },
          "transient": null
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running a Synapse server"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "214d7d56-45af-4669-af9c-c1c0a08fd651"
        },
        "id": "0gjx1_1qgMFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "serving_input = spark.readStream.server() \\\n",
        "    .address(\"localhost\", 9999, \"benchmark_api\") \\\n",
        "    .option(\"name\", \"benchmark_api\") \\\n",
        "    .load() \\\n",
        "    .parseRequest(\"benchmark_api\", data.schema)\n",
        "\n",
        "serving_output = resolver_p_model.transform(serving_input) \\\n",
        "    .makeReply(\"icd10cm_code\")\n",
        "\n",
        "server = serving_output.writeStream \\\n",
        "      .server() \\\n",
        "      .replyTo(\"benchmark_api\") \\\n",
        "      .queryName(\"benchmark_query\") \\\n",
        "      .option(\"checkpointLocation\", \"file:///tmp/checkpoints-{}\".format(uuid.uuid1())) \\\n",
        "      .start()"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "87715459-0d21-4bfd-a85a-d9fc3e33d5d8"
        },
        "id": "tWZzC9AzgMFt",
        "outputId": "39a4788a-0af3-4212-a54d-43975c836b34"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\">/databricks/spark/python/pyspark/sql/context.py:134: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n  warnings.warn(\n</div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "metadata": {},
              "type": "html",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/spark/python/pyspark/sql/context.py:134: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n  warnings.warn(\n</div>"
            ]
          },
          "transient": null
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def post_url(args):\n",
        "    print(f\"- Request {str(args[2])} launched!\")\n",
        "    res = requests.post(args[0], data=args[1])    \n",
        "    print(f\"**Response {str(args[2])} received**\")\n",
        "    return res\n",
        "\n",
        "# If you want to send parallel calls, just add more tuples to list_of_urls array\n",
        "# tuple: (URL from above, json, number_of_call)\n",
        "list_of_urls = [(\"http://localhost:9999/benchmark_api\",json.dumps(data_json), 0)]\n",
        "\n",
        "with ThreadPoolExecutor() as pool:\n",
        "    response_list = list(pool.map(post_url,list_of_urls))"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "92daabe4-d70e-433b-8e89-e4b4b4b9c4d8"
        },
        "id": "sGuWqekLgMFt"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking Results"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "98482a54-b02a-451a-9d52-fdaa440efdce"
        },
        "id": "x4dXBTVzgMFu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range (0, len(response_list.json())):\n",
        "  print(response_list.json()[i]['result'])"
      ],
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "title": "",
          "showTitle": false,
          "inputWidgets": {},
          "nuid": "5d7091ed-3e4e-43dd-8729-d7775d3645bd"
        },
        "id": "Y0iHycFZgMFu",
        "outputId": "f527a956-45a0-4f1d-e1d6-1d73c7c27f98"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {
            "application/vnd.databricks.v1+output": {
              "datasetInfos": [],
              "data": "<div class=\"ansiout\">O2441\nO2411\nP702\nK8520\nB159\nE669\nZ6841\nR35\nR631\nR630\nR111\nJ988\nP702\nG600\nK130\nR529\nM6283\nR4689\nO046\nE785\nE872\nE639\nH5330\nR799\nR829\nE785\nA832\nG600\nJ988\nO2441\nO2411\nP702\nK8520\nB159\nE669\nZ6841\nR35\nR631\nR630\nR111\nJ988\nP702\nG600\nK130\nR529\nM6283\nR4689\nO046\nE785\nE872\nE639\nH5330\nR799\nR829\nE785\nA832\nG600\nJ988\nO2441\nO2411\nP702\nK8520\nB159\nE669\nZ6841\nR35\nR631\nR630\nR111\nJ988\nP702\nG600\nK130\nR529\nM6283\nR4689\nO046\nE785\nE872\nE639\nH5330\nR799\nR829\nE785\nA832\nG600\nJ988\n</div>",
              "removedWidgets": [],
              "addedWidgets": {},
              "metadata": {},
              "type": "html",
              "arguments": {}
            }
          },
          "data": {
            "text/html": [
              "<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">O2441\nO2411\nP702\nK8520\nB159\nE669\nZ6841\nR35\nR631\nR630\nR111\nJ988\nP702\nG600\nK130\nR529\nM6283\nR4689\nO046\nE785\nE872\nE639\nH5330\nR799\nR829\nE785\nA832\nG600\nJ988\nO2441\nO2411\nP702\nK8520\nB159\nE669\nZ6841\nR35\nR631\nR630\nR111\nJ988\nP702\nG600\nK130\nR529\nM6283\nR4689\nO046\nE785\nE872\nE639\nH5330\nR799\nR829\nE785\nA832\nG600\nJ988\nO2441\nO2411\nP702\nK8520\nB159\nE669\nZ6841\nR35\nR631\nR630\nR111\nJ988\nP702\nG600\nK130\nR529\nM6283\nR4689\nO046\nE785\nE872\nE639\nH5330\nR799\nR829\nE785\nA832\nG600\nJ988\n</div>"
            ]
          },
          "transient": null
        }
      ],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "synapse2",
      "language": "python",
      "name": "synapse2"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "version": "3.8.12",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "application/vnd.databricks.v1+notebook": {
      "notebookName": "Synapse example",
      "dashboards": [],
      "notebookMetadata": {
        "pythonIndentUnit": 2
      },
      "language": "python",
      "widgets": {},
      "notebookOrigID": 4082361247410207
    },
    "colab": {
      "name": "Serving SparkNLP with Synapse.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}