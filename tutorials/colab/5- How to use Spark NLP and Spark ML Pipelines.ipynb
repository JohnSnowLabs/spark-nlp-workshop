{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BxzW_3bimNjP"
   },
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "epkk3MUMmNjR"
   },
   "source": [
    "# Spark NLP and Spark ML Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 48646,
     "status": "ok",
     "timestamp": 1568998549917,
     "user": {
      "displayName": "Alexander Thomas",
      "photoUrl": "",
      "userId": "11939695612384769217"
     },
     "user_tz": 420
    },
    "id": "LwLEsf3LmPx5",
    "outputId": "05b19a65-3196-4189-eea7-000cbbc6abe1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openjdk version \"1.8.0_222\"\n",
      "OpenJDK Runtime Environment (build 1.8.0_222-8u222-b10-1ubuntu1~18.04.1-b10)\n",
      "OpenJDK 64-Bit Server VM (build 25.222-b10, mixed mode)\n",
      "Collecting pyspark==2.4.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/98/244399c0daa7894cdf387e7007d5e8b3710a79b67f3fd991c0b0b644822d/pyspark-2.4.3.tar.gz (215.6MB)\n",
      "\u001b[K     |████████████████████████████████| 215.6MB 125kB/s \n",
      "\u001b[?25hCollecting py4j==0.10.7 (from pyspark==2.4.3)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
      "\u001b[K     |████████████████████████████████| 204kB 39.6MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyspark: filename=pyspark-2.4.3-py2.py3-none-any.whl size=215964963 sha256=bd5c6069dd9ab3f9cffc13cd7533b8a44ed40fe831e8042417c2b8327c7f714d\n",
      "  Stored in directory: /root/.cache/pip/wheels/8d/20/f0/b30e2024226dc112e256930dd2cd4f06d00ab053c86278dcf3\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.7 pyspark-2.4.3\n",
      "Collecting spark-nlp==2.2.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/83/89/16492f3c61c6cfc9b41344de7c1c875f171c33cba1b8b9546dd0c4d77ff6/spark_nlp-2.2.1-py2.py3-none-any.whl (64kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 4.7MB/s \n",
      "\u001b[?25hInstalling collected packages: spark-nlp\n",
      "Successfully installed spark-nlp-2.2.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Install java\n",
    "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
    "! java -version\n",
    "\n",
    "# Install pyspark\n",
    "! pip install --ignore-installed pyspark==2.4.3\n",
    "\n",
    "# Install Spark NLP\n",
    "! pip install --ignore-installed spark-nlp==2.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ouQjb9kWmNjS"
   },
   "source": [
    "## Simple Topic Modeling\n",
    "\n",
    "`Spark-NLP`\n",
    "* DocumentAssembler\n",
    "* SentenceDetector\n",
    "* Tokenizer\n",
    "* Normalizer\n",
    "* POS tagger\n",
    "* Chunker\n",
    "* Finisher\n",
    "\n",
    "`Spark ML`\n",
    "* Hashing\n",
    "* TF-IDF\n",
    "* LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8aKWnMGkmNjU"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import CountVectorizer, HashingTF, IDF, Tokenizer\n",
    "from pyspark.ml.clustering import LDA, LDAModel\n",
    "\n",
    "#Spark NLP\n",
    "import sparknlp\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.common import RegexRule\n",
    "from sparknlp.base import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q3wJ02KWmNjY"
   },
   "source": [
    "### Let's create a Spark Session for our app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 65883,
     "status": "ok",
     "timestamp": 1568998567318,
     "user": {
      "displayName": "Alexander Thomas",
      "photoUrl": "",
      "userId": "11939695612384769217"
     },
     "user_tz": 420
    },
    "id": "irMmrC0JmNjZ",
    "outputId": "91f47e10-c0ea-4006-b927-b7777b9435c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version\n",
      "2.2.1\n",
      "Apache Spark version\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.4.3'"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = sparknlp.start()\n",
    "\n",
    "print(\"Spark NLP version\")\n",
    "sparknlp.version()\n",
    "print(\"Apache Spark version\")\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s8DvVMvnmNjd"
   },
   "source": [
    "Let's download some scientific sample from PubMed dataset:\n",
    "```\n",
    "wget -N \thttps://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/pubmed/pubmed-sample.csv -P /tmp\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 63633,
     "status": "ok",
     "timestamp": 1568998569059,
     "user": {
      "displayName": "Alexander Thomas",
      "photoUrl": "",
      "userId": "11939695612384769217"
     },
     "user_tz": 420
    },
    "id": "ndXJqm2LmNje",
    "outputId": "44e8c0e3-bc69-409f-d67e-5275d6139f25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-09-20 16:56:07--  https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/pubmed/pubmed-sample.csv\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.139.157\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.139.157|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10484510 (10.0M) [text/csv]\n",
      "Saving to: ‘/tmp/pubmed-sample.csv’\n",
      "\n",
      "pubmed-sample.csv   100%[===================>]  10.00M  17.3MB/s    in 0.6s    \n",
      "\n",
      "2019-09-20 16:56:08 (17.3 MB/s) - ‘/tmp/pubmed-sample.csv’ saved [10484510/10484510]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget -N \thttps://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/pubmed/pubmed-sample.csv -P /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bUeGQLVGmNjh"
   },
   "outputs": [],
   "source": [
    "pubMedDF = spark.read\\\n",
    "                .option(\"header\", \"true\")\\\n",
    "                .csv(\"/tmp/pubmed-sample.csv\")\\\n",
    "                .filter(\"AB IS NOT null\")\\\n",
    "                .withColumn(\"text\", col(\"AB\"))\\\n",
    "                .drop(\"TI\", \"AB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 635,
     "status": "ok",
     "timestamp": 1568998597748,
     "user": {
      "displayName": "Alexander Thomas",
      "photoUrl": "",
      "userId": "11939695612384769217"
     },
     "user_tz": 420
    },
    "id": "n9rmOCPrmNjk",
    "outputId": "6078c6b8-c472-4822-92d5-b50c7f4b9a0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      "\n",
      "+--------------------+\n",
      "|                text|\n",
      "+--------------------+\n",
      "|The human KCNJ9 (...|\n",
      "|BACKGROUND: At pr...|\n",
      "|OBJECTIVE: To inv...|\n",
      "|Combined EEG/fMRI...|\n",
      "|Kohlschutter synd...|\n",
      "|Statistical analy...|\n",
      "|The synthetic DOX...|\n",
      "|Our objective was...|\n",
      "|We conducted a ph...|\n",
      "|\"Monomeric sarcos...|\n",
      "|We presented the ...|\n",
      "|The literature de...|\n",
      "|A novel approach ...|\n",
      "|An HPLC-ESI-MS-MS...|\n",
      "|The localizing an...|\n",
      "|OBJECTIVE: To eva...|\n",
      "|For the construct...|\n",
      "|We report the res...|\n",
      "|Intraparenchymal ...|\n",
      "|It is known that ...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pubMedDF.printSchema()\n",
    "pubMedDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1341,
     "status": "ok",
     "timestamp": 1568998599815,
     "user": {
      "displayName": "Alexander Thomas",
      "photoUrl": "",
      "userId": "11939695612384769217"
     },
     "user_tz": 420
    },
    "id": "1P7fpHe0mNjm",
    "outputId": "0a616d29-2305-433b-c41a-6d0f64e71b8c",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7537"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pubMedDF.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8jGB30xSmNjp"
   },
   "source": [
    "### Let's create Spark-NLP Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12495,
     "status": "ok",
     "timestamp": 1568998613783,
     "user": {
      "displayName": "Alexander Thomas",
      "photoUrl": "",
      "userId": "11939695612384769217"
     },
     "user_tz": 420
    },
    "id": "GcltBIMymNjq",
    "outputId": "70585882-0d9a-472c-9255-5469717467ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_anc download started this may take some time.\n",
      "Approximate size to download 4.3 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "# Spark NLP Pipeline\n",
    "\n",
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\")\n",
    "\n",
    "sentence_detector = SentenceDetector() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols([\"sentence\"]) \\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "posTagger = PerceptronModel.pretrained() \\\n",
    "  .setInputCols([\"sentence\", \"token\"])\n",
    "\n",
    "chunker = Chunker() \\\n",
    "    .setInputCols([\"sentence\", \"pos\"]) \\\n",
    "    .setOutputCol(\"chunk\") \\\n",
    "    .setRegexParsers([\"<NNP>+\", \"<DT>?<JJ>*<NN>\"])\n",
    "\n",
    "finisher = Finisher() \\\n",
    "  .setInputCols([\"chunk\"]) \\\n",
    "  .setIncludeMetadata(False)\n",
    "\n",
    "nlpPipeline = Pipeline(stages=[\n",
    "    document_assembler, \n",
    "    sentence_detector, \n",
    "    tokenizer,\n",
    "    posTagger,\n",
    "    chunker,\n",
    "    finisher\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UPPJ0m3hmNjt"
   },
   "outputs": [],
   "source": [
    "nlpPipelineDF = nlpPipeline.fit(pubMedDF).transform(pubMedDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LgDdXnn2mNjv"
   },
   "source": [
    "### Let's create Spark ML Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5BDQ5C6hmNjw"
   },
   "outputs": [],
   "source": [
    "# SPark ML Pipeline\n",
    "\n",
    "cv = CountVectorizer(inputCol=\"finished_chunk\", outputCol=\"features\", vocabSize=1000, minDF=10.0, minTF=10.0)\n",
    "idf = IDF(inputCol=\"features\", outputCol=\"idf\")\n",
    "lda = LDA(k=10, maxIter=5)\n",
    "### Let's create Spark-NLP Pipeline\n",
    "mlPipeline = Pipeline(stages=[\n",
    "    cv,\n",
    "    idf,\n",
    "    lda\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lM6qSQKHmNjy"
   },
   "source": [
    "### We are going to train Spark ML Pipeline by using Spark-NLP Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EXinh1fEmNjz"
   },
   "outputs": [],
   "source": [
    "# Let's create Spark-NLP Pipeline\n",
    "mlModel = mlPipeline.fit(nlpPipelineDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i34QTAtdmNj2"
   },
   "outputs": [],
   "source": [
    "mlPipelineDF = mlModel.transform(nlpPipelineDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2101644,
     "status": "ok",
     "timestamp": 1569000748500,
     "user": {
      "displayName": "Alexander Thomas",
      "photoUrl": "",
      "userId": "11939695612384769217"
     },
     "user_tz": 420
    },
    "id": "aTbgegKhmNj4",
    "outputId": "e4b913b4-af10-4b04-8a8e-a3cc26f619c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+------------+--------------------+\n",
      "|                text|      finished_chunk|    features|         idf|   topicDistribution|\n",
      "+--------------------+--------------------+------------+------------+--------------------+\n",
      "|The human KCNJ9 (...|[KCNJ9, Kir, GIRK...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|BACKGROUND: At pr...|[BACKGROUND, the ...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|OBJECTIVE: To inv...|[OBJECTIVE, =9796...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|Combined EEG/fMRI...|[Combined EEG/fMR...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|Kohlschutter synd...|[Kohlschutter, sy...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|Statistical analy...|[Statistical, ana...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|The synthetic DOX...|[DOX-LNA, conjuga...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|Our objective was...|[objective, blood...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|We conducted a ph...|[II, a phase, stu...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|\"Monomeric sarcos...|[Monomeric, MSOX,...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|We presented the ...|[Exorista, Mythim...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|The literature de...|[The literature, ...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|A novel approach ...|[A novel, approac...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|An HPLC-ESI-MS-MS...|[HPLC-ESI-MS-MS, ...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|The localizing an...|[The localizing, ...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|OBJECTIVE: To eva...|[OBJECTIVE, June,...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|For the construct...|[the construction...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|We report the res...|[PNP, GSTO, Yaqui...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|Intraparenchymal ...|[Intraparenchymal...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|It is known that ...|[Klinefelter's, s...|(1000,[],[])|(1000,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "+--------------------+--------------------+------------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlPipelineDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vf4y90rGmNj7"
   },
   "outputs": [],
   "source": [
    "ldaModel = mlModel.stages[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 775379,
     "status": "ok",
     "timestamp": 1569001585847,
     "user": {
      "displayName": "Alexander Thomas",
      "photoUrl": "",
      "userId": "11939695612384769217"
     },
     "user_tz": 420
    },
    "id": "F5oFHh8qmNj9",
    "outputId": "bfe40b9c-04fd-43e1-abea-dc6b30887b59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lower bound on the log likelihood of the entire corpus: -19726.433220525225\n",
      "The upper bound on perplexity: 12.884672253772191\n"
     ]
    }
   ],
   "source": [
    "ll = ldaModel.logLikelihood(mlPipelineDF)\n",
    "lp = ldaModel.logPerplexity(mlPipelineDF)\n",
    "print(\"The lower bound on the log likelihood of the entire corpus: \" + str(ll))\n",
    "print(\"The upper bound on perplexity: \" + str(lp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 774949,
     "status": "ok",
     "timestamp": 1569001585980,
     "user": {
      "displayName": "Alexander Thomas",
      "photoUrl": "",
      "userId": "11939695612384769217"
     },
     "user_tz": 420
    },
    "id": "lfYw9B1amNj_",
    "outputId": "0c303140-3653-428e-e01d-bbf5f6c98788"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The topics described by their top-weighted terms:\n",
      "+-----+---------------+--------------------------------------------------------------------+\n",
      "|topic|termIndices    |termWeights                                                         |\n",
      "+-----+---------------+--------------------------------------------------------------------+\n",
      "|0    |[336, 332, 532]|[0.009033212891258758, 0.007667261000964144, 0.0013511317082461137] |\n",
      "|1    |[58, 19, 12]   |[0.007537349858706455, 0.007315605370934027, 0.007296100365897374]  |\n",
      "|2    |[6, 734, 782]  |[0.013425615684859974, 0.0013520736783566656, 0.001277673905437223] |\n",
      "|3    |[667, 8, 740]  |[0.010233026009741185, 0.008338828924965243, 0.0012886921893720548] |\n",
      "|4    |[44, 1, 56]    |[0.012990841987488821, 0.00875576662804429, 0.0013456833031477216]  |\n",
      "|5    |[6, 2, 3]      |[0.029841550767097064, 0.01355462742744253, 0.008304519935501157]   |\n",
      "|6    |[71, 555, 72]  |[0.008022563719229428, 0.007869305917223087, 0.007324476544108817]  |\n",
      "|7    |[297, 619, 541]|[0.008112312632943113, 0.007866389770194382, 0.004009821680160631]  |\n",
      "|8    |[133, 625, 615]|[0.007813065473463738, 0.0013529043585145137, 0.001304822448630996] |\n",
      "|9    |[469, 512, 30] |[0.008395661885712814, 0.0013666454999008402, 0.0013182480654961002]|\n",
      "+-----+---------------+--------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Describe topics.\n",
    "print(\"The topics described by their top-weighted terms:\")\n",
    "ldaModel.describeTopics(3).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X6w3HawgmNkC"
   },
   "source": [
    "### Let's look at out topics\n",
    "NOTE: More cleaning, filtering, playing around with `CountVectorizer`, and more iterations in `LDA` will result in better Topic Modelling results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 552,
     "status": "ok",
     "timestamp": 1569001818933,
     "user": {
      "displayName": "Alexander Thomas",
      "photoUrl": "",
      "userId": "11939695612384769217"
     },
     "user_tz": 420
    },
    "id": "5PRurlj8mNkD",
    "outputId": "1ee4735d-2539-4201-8255-dca117c1bbf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned topics (as distributions over vocab of 1000 words):\n",
      "topic:  0\n",
      "----------\n",
      "PD\n",
      "history\n",
      "extent\n",
      "education\n",
      "this review\n",
      "reconstruction\n",
      "the blood\n",
      "signal\n",
      "RT-PCR\n",
      "the response\n",
      "cleavage\n",
      "healthcare\n",
      "antigen\n",
      "UV\n",
      "intensity\n",
      "protocol\n",
      "cannot\n",
      "Cu\n",
      "HIV\n",
      "salt\n",
      "host\n",
      "week\n",
      "the left\n",
      "efficiency\n",
      "%\n",
      "quality\n",
      "migration\n",
      "LDL\n",
      "initiation\n",
      "access\n",
      "AIM\n",
      "synthase\n",
      "the lack\n",
      "the diagnosis\n",
      "the possibility\n",
      "series\n",
      "group\n",
      "theory\n",
      "MAP\n",
      "the occurrence\n",
      "serum\n",
      "the maximum\n",
      "MS\n",
      "INTRODUCTION\n",
      "December\n",
      "The expression\n",
      "plasma\n",
      "mutant\n",
      "PA\n",
      "system\n",
      "----------\n",
      "topic:  1\n",
      "----------\n",
      "mice\n",
      "p\n",
      "<\n",
      "search\n",
      "the risk\n",
      "the other hand\n",
      "component\n",
      "MS\n",
      "Blood\n",
      "accumulation\n",
      "impairment\n",
      "radiation\n",
      "F\n",
      "Escherichia\n",
      "inflammation\n",
      "preparation\n",
      "novel\n",
      "LPS\n",
      "wall\n",
      "assay\n",
      "the presence\n",
      "CO(2\n",
      "analysis\n",
      "the detection\n",
      "observation\n",
      "))\n",
      "agent\n",
      "S\n",
      "pretreatment\n",
      "point\n",
      "limit\n",
      "a total\n",
      "HCV\n",
      "the efficacy\n",
      "mg\n",
      "sensitivity\n",
      "case\n",
      "temperature\n",
      "Further\n",
      "restriction\n",
      "sex\n",
      "coli\n",
      "understanding\n",
      "height\n",
      "mellitus\n",
      "Hz\n",
      "a range\n",
      "pressure\n",
      "class\n",
      "diagnosis\n",
      "----------\n",
      "topic:  2\n",
      "----------\n",
      "+/\n",
      "December\n",
      "albumin\n",
      "maintenance\n",
      "SC\n",
      "component\n",
      "HR\n",
      "energy\n",
      "the nucleus\n",
      "the treatment\n",
      "the relationship\n",
      "ml\n",
      "glucose\n",
      "GnRH\n",
      "the other hand\n",
      "amount\n",
      "the onset\n",
      "COPD\n",
      "assessment\n",
      "transplantation\n",
      "association\n",
      "DCs\n",
      "sodium\n",
      "use\n",
      "None\n",
      "T-cell\n",
      "toxin\n",
      "mouse\n",
      "stroke\n",
      "examination\n",
      "resistance\n",
      "hypertension\n",
      "OBJECTIVE\n",
      "the disease\n",
      "absence\n",
      "efficacy\n",
      "CNS\n",
      "hypoxia\n",
      "healthcare\n",
      "membrane\n",
      "electron\n",
      "Human\n",
      "food\n",
      "attention\n",
      "necrosis\n",
      "susceptibility\n",
      "microm\n",
      "phosphate\n",
      "community\n",
      "knowledge\n",
      "----------\n",
      "topic:  3\n",
      "----------\n",
      "max\n",
      "expression\n",
      "bladder\n",
      "anxiety\n",
      "contact\n",
      "marrow\n",
      "Group\n",
      "IL-2\n",
      "curve\n",
      "patientswith\n",
      "HCV\n",
      "LPS\n",
      "DCs\n",
      "isolation\n",
      "perfusion\n",
      "epithelium\n",
      "sample\n",
      "host\n",
      "staff\n",
      "vaccination\n",
      "behavior\n",
      "J\n",
      "cent\n",
      "rate\n",
      "contrast\n",
      "virus\n",
      "the number\n",
      "length\n",
      "drug\n",
      "repair\n",
      "period\n",
      "profile\n",
      "disease\n",
      "The mean\n",
      "selection\n",
      "search\n",
      "METHOD\n",
      "assay\n",
      "transport\n",
      "aim\n",
      "DESIGN\n",
      "generation\n",
      "CT\n",
      "interest\n",
      "mass\n",
      "the outcome\n",
      "the detection\n",
      "the role\n",
      "phosphate\n",
      "metabolism\n",
      "----------\n",
      "topic:  4\n",
      "----------\n",
      "type\n",
      "),\n",
      "B\n",
      "weight\n",
      "mellitus\n",
      "AIM\n",
      "tube\n",
      "transition\n",
      "the liver\n",
      "health\n",
      "e.g\n",
      "position\n",
      ").\n",
      "toxin\n",
      "account\n",
      "neural\n",
      "effect\n",
      "distance\n",
      "brain\n",
      "SETTING\n",
      "chromatography\n",
      "exposure\n",
      "vector\n",
      "the need\n",
      "novel\n",
      "sample\n",
      "January\n",
      "ethanol\n",
      "shock\n",
      "adsorption\n",
      "ELISA\n",
      "J\n",
      "antigen\n",
      "the case\n",
      "sera\n",
      "wall\n",
      "glutathione\n",
      "METHOD\n",
      "AA\n",
      "network\n",
      "the rat\n",
      "DC\n",
      "Blood\n",
      "this method\n",
      "duration\n",
      "system\n",
      ")),\n",
      "The aim\n",
      "life\n",
      "onset\n",
      "----------\n",
      "topic:  5\n",
      "----------\n",
      "+/\n",
      "P\n",
      "group\n",
      ").\n",
      "brain\n",
      "impairment\n",
      "the other hand\n",
      "amino acid\n",
      "the relationship\n",
      "the presence\n",
      "and/or\n",
      "placement\n",
      "the context\n",
      "schizophrenia\n",
      "COPD\n",
      "base\n",
      "production\n",
      "IFN-gamma\n",
      "tumor\n",
      "morbidity\n",
      "the rat\n",
      "core\n",
      "the efficacy\n",
      "This study\n",
      "CD\n",
      "the occurrence\n",
      "order\n",
      "the surface\n",
      "administration\n",
      "amount\n",
      "invasion\n",
      "activity\n",
      "family\n",
      "processing\n",
      "size\n",
      "This review\n",
      "a wide range\n",
      "SETTING\n",
      "OBJECTIVES\n",
      "albumin\n",
      "reconstruction\n",
      "radiotherapy\n",
      "loci\n",
      "transition\n",
      "the field\n",
      "metastasis\n",
      "transplant\n",
      "measurement\n",
      "regard\n",
      "animal\n",
      "----------\n",
      "topic:  6\n",
      "----------\n",
      "mRNA\n",
      "TB\n",
      "care\n",
      "ER\n",
      "PURPOSE\n",
      "VEGF\n",
      "environment\n",
      "reliability\n",
      "CT\n",
      "temperature\n",
      "adherence\n",
      "MRI\n",
      "a significant increase\n",
      "replication\n",
      "the concentration\n",
      "gel\n",
      "the brain\n",
      "beta\n",
      "plasma\n",
      "adsorption\n",
      "the rat\n",
      "T-cell\n",
      "LPS\n",
      "the time\n",
      "healthcare\n",
      "HR\n",
      "benefit\n",
      "SC\n",
      "AR\n",
      "yeast\n",
      "correlation\n",
      "ion\n",
      "home\n",
      "organ\n",
      "SP\n",
      "lead\n",
      "carbon\n",
      "J\n",
      "HPLC\n",
      "conclusion\n",
      "growth\n",
      "GSH\n",
      "spectrometry\n",
      "structure\n",
      "transplant\n",
      "al\n",
      "implantation\n",
      "PET\n",
      "inhibit\n",
      "position\n",
      "----------\n",
      "topic:  7\n",
      "----------\n",
      "cm\n",
      "IgE\n",
      "ER\n",
      "activity\n",
      "questionnaire\n",
      "space\n",
      "recovery\n",
      "IL-2\n",
      "dialysis\n",
      "sulfate\n",
      "RA\n",
      "component\n",
      "stroke\n",
      "regulation\n",
      "root\n",
      "ligand\n",
      "place\n",
      "mortality\n",
      "the case\n",
      "length\n",
      "saline\n",
      "area\n",
      "IL-6\n",
      "the need\n",
      "platelet\n",
      "a role\n",
      "extract\n",
      "the degree\n",
      "the development\n",
      "kinase\n",
      "vivo\n",
      "beta\n",
      "V\n",
      "temperature\n",
      "a history\n",
      "volume\n",
      "P\n",
      "bone\n",
      "HIV-1\n",
      "sex\n",
      "AML\n",
      "the type\n",
      "time\n",
      "contrast\n",
      "Mean\n",
      "the range\n",
      "material\n",
      "dementia\n",
      "culture\n",
      "release\n",
      "----------\n",
      "topic:  8\n",
      "----------\n",
      "life\n",
      "agreement\n",
      "emission\n",
      "source\n",
      "vivo\n",
      "family\n",
      "cluster\n",
      "action\n",
      "maintenance\n",
      "unit\n",
      "air\n",
      "satisfaction\n",
      "gas\n",
      "injury\n",
      "this method\n",
      "regression\n",
      "work\n",
      "bone\n",
      "microm\n",
      "extracellular\n",
      "Ca2+\n",
      "effectiveness\n",
      "pain\n",
      "N-terminal\n",
      "thickness\n",
      "depression\n",
      "program\n",
      "T-cell\n",
      "hybridization\n",
      "PA\n",
      "the mechanism\n",
      "milk\n",
      "sample\n",
      "delivery\n",
      "muscle\n",
      "utilization\n",
      "diameter\n",
      "hypertension\n",
      "brain\n",
      "week\n",
      "interval\n",
      "GH\n",
      "reliability\n",
      "HCV\n",
      "proximal\n",
      "function\n",
      "acid\n",
      "adsorption\n",
      "US\n",
      "the basis\n",
      "----------\n",
      "topic:  9\n",
      "----------\n",
      "iron\n",
      "infarction\n",
      "blood\n",
      "compliance\n",
      "spectra\n",
      "prevention\n",
      "polymerase\n",
      "water\n",
      "nucleus\n",
      "acid\n",
      "enzyme\n",
      "the need\n",
      "fraction\n",
      "the plasma\n",
      "tube\n",
      "prevalence\n",
      "PCR\n",
      "the amount\n",
      "CONCLUSION\n",
      "the effect\n",
      "the occurrence\n",
      "the production\n",
      "specificity\n",
      "the protein\n",
      "the result\n",
      "assay\n",
      "sperm\n",
      "the process\n",
      "image\n",
      "muscle\n",
      "maximal\n",
      "optimal\n",
      "chain\n",
      "the basis\n",
      "the nature\n",
      "TNF-alpha\n",
      "transfer\n",
      "lesion\n",
      ">\n",
      "location\n",
      "ligand\n",
      "layer\n",
      "recognition\n",
      "BMI\n",
      "time\n",
      "microscopy\n",
      "T-cell\n",
      "tissue\n",
      "rat\n",
      "substrate\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# Output topics. Each is a distribution over words (matching word count vectors)\n",
    "print(\"Learned topics (as distributions over vocab of \" + str(ldaModel.vocabSize())\n",
    "      + \" words):\")\n",
    "\n",
    "topics = ldaModel.describeTopics(50)\n",
    "topics_rdd = topics.rdd\n",
    "\n",
    "vocab = mlModel.stages[0].vocabulary\n",
    "\n",
    "topics_words = topics_rdd\\\n",
    "       .map(lambda row: row['termIndices'])\\\n",
    "       .map(lambda idx_list: [vocab[idx] for idx in idx_list])\\\n",
    "       .collect()\n",
    "\n",
    "for idx, topic in enumerate(topics_words):\n",
    "    print(\"topic: \", idx)\n",
    "    print(\"----------\")\n",
    "    for word in topic:\n",
    "       print(word)\n",
    "    print(\"----------\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "5- How to use Spark NLP and Spark ML Pipelines.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
