{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Td8ivUBhi607"
   },
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4CAKXMChi609"
   },
   "source": [
    "# Train POS Tagger in French by Spark NLP\n",
    "### Based on Universal Dependency `UD_French-GSD`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 52207,
     "status": "ok",
     "timestamp": 1568997703663,
     "user": {
      "displayName": "Alexander Thomas",
      "photoUrl": "",
      "userId": "11939695612384769217"
     },
     "user_tz": 420
    },
    "id": "FCFaM2z2jBKI",
    "outputId": "43627dcb-bf7e-41c8-e1e3-c9f6b49aa6ce"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Install java\n",
    "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
    "! java -version\n",
    "\n",
    "# Install pyspark\n",
    "! pip install --ignore-installed pyspark==2.4.4\n",
    "\n",
    "# Install Spark NLP\n",
    "! pip install --ignore-installed spark-nlp==2.3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ght3dzL1i60-"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "#Spark ML and SQL\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.sql.functions import array_contains\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "#Spark NLP\n",
    "import sparknlp\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.common import RegexRule\n",
    "from sparknlp.base import DocumentAssembler, Finisher\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xbuc8JGii61C"
   },
   "source": [
    "### Let's create a Spark Session for our app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 71515,
     "status": "ok",
     "timestamp": 1568997725123,
     "user": {
      "displayName": "Alexander Thomas",
      "photoUrl": "",
      "userId": "11939695612384769217"
     },
     "user_tz": 420
    },
    "id": "lvWCetHOi61E",
    "outputId": "7784ffc9-b82e-4456-872e-b89a465dae90"
   },
   "outputs": [],
   "source": [
    "spark = sparknlp.start()\n",
    "\n",
    "print(\"Spark NLP version: \", sparknlp.version())\n",
    "print(\"Apache Spark version: \", spark.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G8gbf20gi61I"
   },
   "source": [
    "Let's prepare our training datasets containing `token_posTag` like `de_DET`. You can download this data set from Amazon S3:\n",
    "\n",
    "```\n",
    "wget -N https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/fr/pos/UD_French/UD_French-GSD_2.3.txt -P /tmp\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2792,
     "status": "ok",
     "timestamp": 1568998107174,
     "user": {
      "displayName": "Alexander Thomas",
      "photoUrl": "",
      "userId": "11939695612384769217"
     },
     "user_tz": 420
    },
    "id": "ziEpVDqRi61J",
    "outputId": "9da241e8-26da-4418-d3b0-9ccbe5fe6a59"
   },
   "outputs": [],
   "source": [
    "! wget -N https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/fr/pos/UD_French/UD_French-GSD_2.3.txt -P /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LJYEcPpii61L"
   },
   "outputs": [],
   "source": [
    "from sparknlp.training import POS\n",
    "training_data = POS().readDataset(spark, '/tmp/UD_French-GSD_2.3.txt', '_', 'tags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10375,
     "status": "ok",
     "timestamp": 1568998125347,
     "user": {
      "displayName": "Alexander Thomas",
      "photoUrl": "",
      "userId": "11939695612384769217"
     },
     "user_tz": 420
    },
    "id": "G_2KFczOi61O",
    "outputId": "df959636-ee85-437e-aca3-26598f403731"
   },
   "outputs": [],
   "source": [
    "training_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HXiPEJ4yi61R"
   },
   "outputs": [],
   "source": [
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\")\n",
    "\n",
    "sentence_detector = SentenceDetector() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols([\"sentence\"]) \\\n",
    "    .setOutputCol(\"token\")\\\n",
    "    .setExceptions([\"jusqu'\", \"aujourd'hui\", \"États-Unis\", \"lui-même\", \"celui-ci\", \"c'est-à-dire\", \"celle-ci\", \"au-dessus\", \"etc.\", \"sud-est\", \"Royaume-Uni\", \"ceux-ci\", \"au-delà\", \"elle-même\", \"peut-être\", \"sud-ouest\", \"nord-ouest\", \"nord-est\", \"Etats-Unis\", \"Grande-Bretagne\", \"Pays-Bas\", \"eux-mêmes\", \"porte-parole\", \"Notre-Dame\", \"puisqu'\", \"week-end\", \"quelqu'un\", \"celles-ci\", \"chef-lieu\"])\\\n",
    "    .setPrefixPattern(\"\\\\A([^\\\\s\\\\p{L}\\\\d\\\\$\\\\.#]*)\")\\\n",
    "    .setSuffixPattern(\"([^\\\\s\\\\p{L}\\\\d]?)([^\\\\s\\\\p{L}\\\\d]*)\\\\z\")\\\n",
    "    .setInfixPatterns([\n",
    "      \"([\\\\p{L}\\\\w]+'{1})\",\n",
    "      \"([\\\\$#]?\\\\d+(?:[^\\\\s\\\\d]{1}\\\\d+)*)\",\n",
    "      \"((?:\\\\p{L}\\\\.)+)\",\n",
    "      \"((?:\\\\p{L}+[^\\\\s\\\\p{L}]{1})+\\\\p{L}+)\",\n",
    "      \"([\\\\p{L}\\\\w]+)\"\n",
    "    ])\n",
    "\n",
    "posTagger = PerceptronApproach() \\\n",
    "    .setNIterations(1) \\\n",
    "    .setInputCols([\"sentence\", \"token\"]) \\\n",
    "    .setOutputCol(\"pos\") \\\n",
    "    .setPosCol(\"tags\")\n",
    "    \n",
    "pipeline = Pipeline(stages=[\n",
    "    document_assembler, \n",
    "    sentence_detector, \n",
    "    tokenizer,\n",
    "    posTagger\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hu9YoE8Fi61T"
   },
   "outputs": [],
   "source": [
    "# Let's train our Pipeline by using our training dataset\n",
    "model = pipeline.fit(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S6lE7os-i61W"
   },
   "source": [
    "This is our testing DataFrame where we get some sentences in French. We are going to use our trained Pipeline to transform these sentence and predict each token's `Part Of Speech`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xEPzcy-Qi61X"
   },
   "outputs": [],
   "source": [
    "dfTest = spark.createDataFrame([\n",
    "    \"Je sens qu'entre ça et les films de médecins et scientifiques fous que nous avons déjà vus, nous pourrions emprunter un autre chemin pour l'origine.\",\n",
    "    \"On pourra toujours parler à propos d'Averroès de décentrement du Sujet.\"\n",
    "], StringType()).toDF(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kr8nIWebi61Z"
   },
   "outputs": [],
   "source": [
    "predict = model.transform(dfTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1891,
     "status": "ok",
     "timestamp": 1568998184744,
     "user": {
      "displayName": "Alexander Thomas",
      "photoUrl": "",
      "userId": "11939695612384769217"
     },
     "user_tz": 420
    },
    "id": "YQ40EvlPi61c",
    "outputId": "a9dd10e4-e960-4dfa-a28b-9b967393536a"
   },
   "outputs": [],
   "source": [
    "predict.select(\"token.result\", \"pos.result\").show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "3- Build your own French POS tagger.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
