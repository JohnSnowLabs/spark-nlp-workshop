{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7p69LnaldJa_"
   },
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "83aGge0ndJbB"
   },
   "source": [
    "# Use pretrained `explain_document` Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 49109,
     "status": "ok",
     "timestamp": 1568996489923,
     "user": {
      "displayName": "Alexander Thomas",
      "photoUrl": "",
      "userId": "11939695612384769217"
     },
     "user_tz": 420
    },
    "id": "pVycMjc1dLIe",
    "outputId": "119d0133-503b-43af-a4c2-0fa4da502264"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openjdk version \"1.8.0_222\"\n",
      "OpenJDK Runtime Environment (build 1.8.0_222-8u222-b10-1ubuntu1~18.04.1-b10)\n",
      "OpenJDK 64-Bit Server VM (build 25.222-b10, mixed mode)\n",
      "Collecting pyspark==2.4.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/98/244399c0daa7894cdf387e7007d5e8b3710a79b67f3fd991c0b0b644822d/pyspark-2.4.3.tar.gz (215.6MB)\n",
      "\u001b[K     |████████████████████████████████| 215.6MB 117kB/s \n",
      "\u001b[?25hCollecting py4j==0.10.7 (from pyspark==2.4.3)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
      "\u001b[K     |████████████████████████████████| 204kB 42.2MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyspark: filename=pyspark-2.4.3-py2.py3-none-any.whl size=215964963 sha256=663275ebafc590b978b1dcd1216cbf91cd9352ed9f67024746167f29f011dc47\n",
      "  Stored in directory: /root/.cache/pip/wheels/8d/20/f0/b30e2024226dc112e256930dd2cd4f06d00ab053c86278dcf3\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.7 pyspark-2.4.3\n",
      "Collecting spark-nlp==2.2.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/83/89/16492f3c61c6cfc9b41344de7c1c875f171c33cba1b8b9546dd0c4d77ff6/spark_nlp-2.2.1-py2.py3-none-any.whl (64kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 2.8MB/s \n",
      "\u001b[?25hInstalling collected packages: spark-nlp\n",
      "Successfully installed spark-nlp-2.2.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Install java\n",
    "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
    "! java -version\n",
    "\n",
    "# Install pyspark\n",
    "! pip install --ignore-installed pyspark==2.4.3\n",
    "\n",
    "# Install Spark NLP\n",
    "! pip install --ignore-installed spark-nlp==2.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mOeiIKN1dJbC"
   },
   "source": [
    "### Stages\n",
    "\n",
    " * DocumentAssembler\n",
    " * SentenceDetector\n",
    " * Tokenizer\n",
    " * Lemmatizer\n",
    " * Stemmer\n",
    " * Part of Speech\n",
    " * SpellChecker (Norvig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JwzCcMrkdJbE"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "#Spark ML and SQL\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.sql.functions import array_contains\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "#Spark NLP\n",
    "import sparknlp\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.common import RegexRule\n",
    "from sparknlp.base import DocumentAssembler, Finisher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cV-HCwyqdJbI"
   },
   "source": [
    "### Let's create a Spark Session for our app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 72214,
     "status": "ok",
     "timestamp": 1568996513047,
     "user": {
      "displayName": "Alexander Thomas",
      "photoUrl": "",
      "userId": "11939695612384769217"
     },
     "user_tz": 420
    },
    "id": "GxPGe1DEdJbK",
    "outputId": "64e807df-416c-408e-d21e-f907ccfebac1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version\n",
      "2.2.1\n",
      "Apache Spark version\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.4.3'"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = sparknlp.start()\n",
    "\n",
    "print(\"Spark NLP version\")\n",
    "sparknlp.version()\n",
    "print(\"Apache Spark version\")\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J3zO5qw3dJbO"
   },
   "source": [
    "#### This is our testing document, we'll use it to exemplify all different pipeline stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V6VlR5wWdJbP"
   },
   "outputs": [],
   "source": [
    "testDoc = [\n",
    "\"French author who helped pioner the science-fiction genre. \\\n",
    "Verne wrate about space, air, and underwater travel before \\\n",
    "navigable aircrast and practical submarines were invented, \\\n",
    "and before any means of space travel had been devised. \"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 104704,
     "status": "ok",
     "timestamp": 1568996545547,
     "user": {
      "displayName": "Alexander Thomas",
      "photoUrl": "",
      "userId": "11939695612384769217"
     },
     "user_tz": 420
    },
    "id": "bMWRxstQdJbR",
    "outputId": "924b895d-553f-49fa-dc8c-a63a7160fe01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explain_document_ml download started this may take some time.\n",
      "Approx size to download 9.4 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "pipeline = PretrainedPipeline('explain_document_ml', lang='en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OUE9Pnw_dJbU"
   },
   "source": [
    "#### We are not interested in handling big datasets, let's switch to LightPipelines for speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6atL1g_UdJbV"
   },
   "outputs": [],
   "source": [
    "result = pipeline.annotate(testDoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3WLmPeANdJbX"
   },
   "source": [
    "#### Let's analyze these results - first let's see what sentences we detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 105667,
     "status": "ok",
     "timestamp": 1568996546519,
     "user": {
      "displayName": "Alexander Thomas",
      "photoUrl": "",
      "userId": "11939695612384769217"
     },
     "user_tz": 420
    },
    "id": "GBQLpz4EdJbY",
    "outputId": "b0ba2294-b65d-4aa4-c1d0-c3c3a51e89b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['French author who helped pioner the science-fiction genre.',\n",
       "  'Verne wrate about space, air, and underwater travel before navigable aircrast and practical submarines were invented, and before any means of space travel had been devised.']]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[content['sentence'] for content in result]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "89vjlh-CdJbb"
   },
   "source": [
    "#### Now let's see how those sentences were tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 105663,
     "status": "ok",
     "timestamp": 1568996546521,
     "user": {
      "displayName": "Alexander Thomas",
      "photoUrl": "",
      "userId": "11939695612384769217"
     },
     "user_tz": 420
    },
    "id": "G1PAPYxidJbb",
    "outputId": "c5e74e3f-0307-49b7-f074-2aefbae11c82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['French',\n",
       "  'author',\n",
       "  'who',\n",
       "  'helped',\n",
       "  'pioner',\n",
       "  'the',\n",
       "  'science-fiction',\n",
       "  'genre',\n",
       "  '.',\n",
       "  'Verne',\n",
       "  'wrate',\n",
       "  'about',\n",
       "  'space',\n",
       "  ',',\n",
       "  'air',\n",
       "  ',',\n",
       "  'and',\n",
       "  'underwater',\n",
       "  'travel',\n",
       "  'before',\n",
       "  'navigable',\n",
       "  'aircrast',\n",
       "  'and',\n",
       "  'practical',\n",
       "  'submarines',\n",
       "  'were',\n",
       "  'invented',\n",
       "  ',',\n",
       "  'and',\n",
       "  'before',\n",
       "  'any',\n",
       "  'means',\n",
       "  'of',\n",
       "  'space',\n",
       "  'travel',\n",
       "  'had',\n",
       "  'been',\n",
       "  'devised',\n",
       "  '.']]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[content['token'] for content in result]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Etpy_GS6dJbe"
   },
   "source": [
    "#### Notice some spelling errors? the pipeline takes care of that as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 105657,
     "status": "ok",
     "timestamp": 1568996546521,
     "user": {
      "displayName": "Alexander Thomas",
      "photoUrl": "",
      "userId": "11939695612384769217"
     },
     "user_tz": 420
    },
    "id": "hh9aebz8dJbf",
    "outputId": "f7c5850f-04c8-4beb-94df-d25c684fdd01"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['French',\n",
       "  'author',\n",
       "  'who',\n",
       "  'helped',\n",
       "  'pioneer',\n",
       "  'the',\n",
       "  'sciencefiction',\n",
       "  'genre',\n",
       "  '.',\n",
       "  'Verne',\n",
       "  'wrote',\n",
       "  'about',\n",
       "  'space',\n",
       "  ',',\n",
       "  'air',\n",
       "  ',',\n",
       "  'and',\n",
       "  'underwater',\n",
       "  'travel',\n",
       "  'before',\n",
       "  'navigable',\n",
       "  'aircraft',\n",
       "  'and',\n",
       "  'practical',\n",
       "  'submarines',\n",
       "  'were',\n",
       "  'invented',\n",
       "  ',',\n",
       "  'and',\n",
       "  'before',\n",
       "  'any',\n",
       "  'means',\n",
       "  'of',\n",
       "  'space',\n",
       "  'travel',\n",
       "  'had',\n",
       "  'been',\n",
       "  'devised',\n",
       "  '.']]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[content['checked'] for content in result]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GU-UNS8AdJbh"
   },
   "source": [
    "#### Now let's see the lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 105651,
     "status": "ok",
     "timestamp": 1568996546522,
     "user": {
      "displayName": "Alexander Thomas",
      "photoUrl": "",
      "userId": "11939695612384769217"
     },
     "user_tz": 420
    },
    "id": "fHgN1eOkdJbi",
    "outputId": "9f4c6513-abc8-4ea7-a1a1-3521b9f68081"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['French',\n",
       "  'author',\n",
       "  'who',\n",
       "  'help',\n",
       "  'pioneer',\n",
       "  'the',\n",
       "  'sciencefiction',\n",
       "  'genre',\n",
       "  '.',\n",
       "  'Verne',\n",
       "  'write',\n",
       "  'about',\n",
       "  'space',\n",
       "  ',',\n",
       "  'air',\n",
       "  ',',\n",
       "  'and',\n",
       "  'underwater',\n",
       "  'travel',\n",
       "  'before',\n",
       "  'navigable',\n",
       "  'aircraft',\n",
       "  'and',\n",
       "  'practical',\n",
       "  'submarine',\n",
       "  'be',\n",
       "  'invent',\n",
       "  ',',\n",
       "  'and',\n",
       "  'before',\n",
       "  'any',\n",
       "  'mean',\n",
       "  'of',\n",
       "  'space',\n",
       "  'travel',\n",
       "  'have',\n",
       "  'be',\n",
       "  'devise',\n",
       "  '.']]"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[content['lemma'] for content in result]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5eCXgmSYdJbk"
   },
   "source": [
    "#### Let's check the stems, any difference with the lemmas shown bebore?\n",
    "\n",
    "[content['lemmas'] for content in result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 105644,
     "status": "ok",
     "timestamp": 1568996546522,
     "user": {
      "displayName": "Alexander Thomas",
      "photoUrl": "",
      "userId": "11939695612384769217"
     },
     "user_tz": 420
    },
    "id": "B-rn3_sodJbl",
    "outputId": "1409efb5-5bba-447a-97e9-700b61895ea0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['french',\n",
       "  'author',\n",
       "  'who',\n",
       "  'help',\n",
       "  'pioneer',\n",
       "  'the',\n",
       "  'sciencefict',\n",
       "  'genr',\n",
       "  '.',\n",
       "  'vern',\n",
       "  'wrote',\n",
       "  'about',\n",
       "  'space',\n",
       "  ',',\n",
       "  'air',\n",
       "  ',',\n",
       "  'and',\n",
       "  'underwat',\n",
       "  'travel',\n",
       "  'befor',\n",
       "  'navig',\n",
       "  'aircraft',\n",
       "  'and',\n",
       "  'practic',\n",
       "  'submarin',\n",
       "  'were',\n",
       "  'invent',\n",
       "  ',',\n",
       "  'and',\n",
       "  'befor',\n",
       "  'ani',\n",
       "  'mean',\n",
       "  'of',\n",
       "  'space',\n",
       "  'travel',\n",
       "  'had',\n",
       "  'been',\n",
       "  'devis',\n",
       "  '.']]"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[content['stem'] for content in result]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "818sKySUdJbo"
   },
   "source": [
    "#### Now it's the turn on Part Of Speech(POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 105638,
     "status": "ok",
     "timestamp": 1568996546523,
     "user": {
      "displayName": "Alexander Thomas",
      "photoUrl": "",
      "userId": "11939695612384769217"
     },
     "user_tz": 420
    },
    "id": "Hnd1vUzodJbo",
    "outputId": "96cc186a-8e5c-4451-dcc2-58bc55c0b107",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('French', 'JJ'),\n",
       " ('author', 'NN'),\n",
       " ('who', 'WP'),\n",
       " ('helped', 'VBD'),\n",
       " ('pioner', 'NN'),\n",
       " ('the', 'DT'),\n",
       " ('science-fiction', 'NN'),\n",
       " ('genre', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Verne', 'NNP'),\n",
       " ('wrate', 'VBD'),\n",
       " ('about', 'IN'),\n",
       " ('space', 'NN'),\n",
       " (',', ','),\n",
       " ('air', 'NN'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('underwater', 'JJ'),\n",
       " ('travel', 'NN'),\n",
       " ('before', 'IN'),\n",
       " ('navigable', 'JJ'),\n",
       " ('aircrast', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('practical', 'JJ'),\n",
       " ('submarines', 'NNS'),\n",
       " ('were', 'VBD'),\n",
       " ('invented', 'VBN'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('before', 'IN'),\n",
       " ('any', 'DT'),\n",
       " ('means', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('space', 'NN'),\n",
       " ('travel', 'NN'),\n",
       " ('had', 'VBD'),\n",
       " ('been', 'VBN'),\n",
       " ('devised', 'VBN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = [content['pos'] for content in result]\n",
    "token = [content['token'] for content in result]\n",
    "# let's put token and tag together\n",
    "list(zip(token[0], pos[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bbJZWBVadJbr"
   },
   "source": [
    "# Use pretrained `match_chunk` Pipeline for Individual Noun Phrase "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mCYGDKLCdJbs"
   },
   "source": [
    "* DocumentAssembler\n",
    "* SentenceDetector\n",
    "* Tokenizer\n",
    "* Part of speech\n",
    "* chunker\n",
    "\n",
    "Pipeline:\n",
    "* The pipeline uses regex `<DT>?<JJ>*<NN>+`\n",
    "* which states that whenever the chunk finds an optional determiner \n",
    "* (DT) followed by any number of adjectives (JJ) and then a noun (NN) then the Noun Phrase(NP) chunk should be formed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 116016,
     "status": "ok",
     "timestamp": 1568996556907,
     "user": {
      "displayName": "Alexander Thomas",
      "photoUrl": "",
      "userId": "11939695612384769217"
     },
     "user_tz": 420
    },
    "id": "g0bA6ADsdJbt",
    "outputId": "b356fe38-946c-4657-96ac-83b8b780010d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match_chunks download started this may take some time.\n",
      "Approx size to download 4.3 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "pipeline = PretrainedPipeline('match_chunks', lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nnW9ditjdJbv"
   },
   "outputs": [],
   "source": [
    "result = pipeline.annotate(\"The book has many chapters\") # single noun phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 116016,
     "status": "ok",
     "timestamp": 1568996556912,
     "user": {
      "displayName": "Alexander Thomas",
      "photoUrl": "",
      "userId": "11939695612384769217"
     },
     "user_tz": 420
    },
    "id": "8RAa24DXdJbx",
    "outputId": "be95765b-9dce-4eb7-9a78-f0d34474b0b3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The book']"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['chunk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9zPjsztSdJb0"
   },
   "outputs": [],
   "source": [
    "result = pipeline.annotate(\"the little yellow dog barked at the cat\") #multiple noune phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 116142,
     "status": "ok",
     "timestamp": 1568996557047,
     "user": {
      "displayName": "Alexander Thomas",
      "photoUrl": "",
      "userId": "11939695612384769217"
     },
     "user_tz": 420
    },
    "id": "9VkV1fwZdJb2",
    "outputId": "b83e101d-a235-4eb4-8d11-dd8e9ec0125a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the little yellow dog', 'the cat']"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['chunk']"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "1- How to use Light Pipelines.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
