{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c66a353-6202-4e7f-92be-0efe5aed2b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spark-nlp==4.1.0 pyspark==3.3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b52ff5f-1bbd-47ce-af82-aa8581bc1e93",
   "metadata": {},
   "source": [
    "# Spark NLP Image Classification\n",
    "## Vision Transformer (ViT) models\n",
    "\n",
    "### Benchmarking image classification in Spark NLP on CPU, CPU with one DNN enabled, and GPU\n",
    "\n",
    "**Disclaimer**: This notebook is for the benchmarking purposes. In order to use ViT image classification in Spark NLP you can just simply follow this code:\n",
    "\n",
    "```python\n",
    "imageAssembler = ImageAssembler() \\\n",
    "    .setInputCol(\"image\") \\\n",
    "    .setOutputCol(\"image_assembler\")\n",
    "\n",
    "imageClassifier = ViTForImageClassification \\\n",
    "    .pretrained(\"image_classifier_vit_base_patch16_224\") \\\n",
    "    .setInputCols(\"image_assembler\") \\\n",
    "    .setOutputCol(\"class\")\n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "    imageAssembler,\n",
    "    imageClassifier\n",
    "])\n",
    "\n",
    "\n",
    "pipelineModel = pipeline.fit(testDataset)\n",
    "pipelineDF = pipelineModel.transform(testDataset)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd75cc4-62c8-4e19-8c35-375dd2b256c2",
   "metadata": {},
   "source": [
    "If you need to download the datasets (sample/full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53e9489e-8c05-47ea-b484-49ee179dbced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget -q https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/images/imagenet-mini-sample.zip && unzip ./imagenet-mini-sample.zip >/dev/null 2>&1\n",
    "# !wget -q https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/images/imagenet-mini.zip && unzip ./imagenet-mini.zip >/dev/null 2>&1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a16ec9-c09b-4b42-b056-f9d828ba95ce",
   "metadata": {},
   "source": [
    "- let's select the device we want to benchmark\n",
    ">keeping in mind in a normal Spark NLP application `spark = sparknlp.start()` is all you need - for GPU you do `spark = sparknlp.start(gpu=True)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30148bc3-e5bb-434b-a837-a187c04b1aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_device = \"4.1.0-cpu\"\n",
    "# lib_device = \"4.1.0-cpu-opt\"\n",
    "# lib_device = \"4.1.0-gpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cbd19e-ae0d-498c-ab0b-9f428cb5df69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparknlp.annotator import *\n",
    "from sparknlp.common import *\n",
    "from sparknlp.base import *\n",
    "import sparknlp\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "\n",
    "spark = SparkSession\n",
    "\n",
    "if(lib_device == \"4.1.0-cpu\"):\n",
    "    os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"\n",
    "    !export TF_ENABLE_ONEDNN_OPTS=0\n",
    "    \n",
    "\n",
    "    spark = sparknlp.start(memory=\"128g\")\n",
    "\n",
    "elif(lib_device == \"4.1.0-cpu-opt\"):\n",
    "    os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"1\"\n",
    "    !export TF_ENABLE_ONEDNN_OPTS=1\n",
    "    \n",
    "    spark = sparknlp.start(memory=\"128g\")\n",
    "\n",
    "elif(lib_device == \"4.1.0-gpu\"):\n",
    "    os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"\n",
    "    !export TF_ENABLE_ONEDNN_OPTS=0\n",
    "    \n",
    "    spark = sparknlp.start(gpu=True, memory=\"128g\")\n",
    "    \n",
    "    \n",
    "print(\"Spark NLP: \", sparknlp.version())\n",
    "print(\"Apache Spark: \", spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83da9eeb-83bd-41ca-abc9-27cfadf559a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               image|\n",
      "+--------------------+\n",
      "|{file:///home/maz...|\n",
      "|{file:///home/maz...|\n",
      "|{file:///home/maz...|\n",
      "+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DATASET_SIZE = \"sample\"\n",
    "# DATASET_SIZE = \"full\"\n",
    "DATASET_PATH = \"\"\n",
    "\n",
    "if(DATASET_SIZE == \"sample\"):\n",
    "    DATASET_PATH = \"./imagenet-mini-sample\"\n",
    "else:    \n",
    "    DATASET_PATH = \"./imagenet-mini\"\n",
    "\n",
    "testDataset = spark.read\\\n",
    "  .format(\"image\")\\\n",
    "  .option(\"dropInvalid\", value = True)\\\n",
    "  .load(DATASET_PATH)\n",
    "\n",
    "#  for sample dataset (3k)\n",
    "#  .load(\"./imagenet-mini-sample\")\n",
    "#  for full dataset (34k)\n",
    "#  .load(\"./imagenet-mini\")\n",
    "\n",
    "print(testDataset.count())\n",
    "testDataset.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df1b4b8e-a264-4b19-849d-ba07bab075ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "imageAssembler = ImageAssembler() \\\n",
    "    .setInputCol(\"image\") \\\n",
    "    .setOutputCol(\"image_assembler\")\n",
    "\n",
    "def RunBenchPipeline(annot, model, batch_size=8):\n",
    "        print(\"-\" * 30)\n",
    "        if annot == \"ViTForImageClassification\":\n",
    "            imageClassifier = ViTForImageClassification \\\n",
    "                .pretrained(\"image_classifier_vit_base_patch16_224\") \\\n",
    "                .setInputCols(\"image_assembler\") \\\n",
    "                .setOutputCol(\"class\") \\\n",
    "                .setBatchSize(batch_size)\n",
    "\n",
    "            pipeline = Pipeline(stages=[\n",
    "                imageAssembler,\n",
    "                imageClassifier\n",
    "            ])\n",
    "\n",
    "            pipelineModel = pipeline.fit(testDataset)\n",
    "            pipelineDF = pipelineModel.transform(testDataset)\n",
    "            \n",
    "            with open('./{}_{}_{}.txt'.format(lib_device, annot, model), 'a') as f:\n",
    "                print(\"-\" * 30, file=f)\n",
    "                start = timer()\n",
    "                total_count = pipelineDF.select(\"class.result\").count()\n",
    "                end = timer() - start\n",
    "                print(f'{lib_device}: took {end:.2f} seconds to finish computing {total_count} images with batch size {imageClassifier.getBatchSize()}')\n",
    "                print(f'{lib_device}: took {end:.2f} seconds to finish computing {total_count} images with batch size {imageClassifier.getBatchSize()}', file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fb0c50-109f-46c7-942b-4104e3f9ba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a nice way to call the pipeline for benchmarks\n",
    "# Set different batch sizes, choose different annotators, and specific models for them\n",
    "# It's more flexible than a simple for loops to set different batch sizes\n",
    "\n",
    "benchmarks = {\n",
    "    'image_classifier_vit_base_patch16_224': 'ViTForImageClassification'\n",
    "}\n",
    "\n",
    "for model, annot in benchmarks.items():\n",
    "    RunBenchPipeline(annot, model, 2)\n",
    "    RunBenchPipeline(annot, model, 8)\n",
    "    RunBenchPipeline(annot, model, 16)\n",
    "    RunBenchPipeline(annot, model, 32)\n",
    "    RunBenchPipeline(annot, model, 64)\n",
    "    RunBenchPipeline(annot, model, 128)\n",
    "    RunBenchPipeline(annot, model, 256)\n",
    "    RunBenchPipeline(annot, model, 512)\n",
    "    RunBenchPipeline(annot, model, 1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8fadb0-bb71-407a-b1c5-e957f8539b2f",
   "metadata": {},
   "source": [
    "## imagenet-mini-sample\n",
    "\n",
    "### CPU\n",
    "```\n",
    "                                                                                \n",
    "4.1.0-cpu: took 161.02 seconds to finish computing 3544 images with batch size 2\n",
    "------------------------------\n",
    "4.1.0-cpu: took 144.00 seconds to finish computing 3544 images with batch size 8\n",
    "------------------------------\n",
    "4.1.0-cpu: took 129.40 seconds to finish computing 3544 images with batch size 16\n",
    "------------------------------\n",
    "4.1.0-cpu: took 138.17 seconds to finish computing 3544 images with batch size 32\n",
    "------------------------------\n",
    "4.1.0-cpu: took 138.52 seconds to finish computing 3544 images with batch size 64\n",
    "------------------------------\n",
    "4.1.0-cpu: took 136.54 seconds to finish computing 3544 images with batch size 128\n",
    "```\n",
    "\n",
    "### CPU with oneDNN\n",
    "```\n",
    "------------------------------\n",
    "4.1.0-cpu-opt: took 113.67 seconds to finish computing 3544 images with batch size 2\n",
    "------------------------------\n",
    "4.1.0-cpu-opt: took 116.34 seconds to finish computing 3544 images with batch size 8\n",
    "------------------------------\n",
    "4.1.0-cpu-opt: took 131.04 seconds to finish computing 3544 images with batch size 16\n",
    "------------------------------\n",
    "4.1.0-cpu-opt: took 144.99 seconds to finish computing 3544 images with batch size 32\n",
    "------------------------------\n",
    "4.1.0-cpu-opt: took 157.73 seconds to finish computing 3544 images with batch size 64\n",
    "------------------------------\n",
    "4.1.0-cpu-opt: took 152.32 seconds to finish computing 3544 images with batch size 128\n",
    "\n",
    "```\n",
    "\n",
    "### GPU\n",
    "```\n",
    "------------------------------\n",
    "4.1.0-gpu: took 48.91 seconds to finish computing 3544 images with batch size 2\n",
    "------------------------------\n",
    "4.1.0-gpu: took 41.15 seconds to finish computing 3544 images with batch size 8\n",
    "------------------------------\n",
    "4.1.0-gpu: took 38.80 seconds to finish computing 3544 images with batch size 16\n",
    "------------------------------\n",
    "4.1.0-gpu: took 36.55 seconds to finish computing 3544 images with batch size 32\n",
    "------------------------------\n",
    "4.1.0-gpu: took 42.44 seconds to finish computing 3544 images with batch size 64\n",
    "------------------------------\n",
    "4.1.0-gpu: took 44.06 seconds to finish computing 3544 images with batch size 128\n",
    "------------------------------\n",
    "4.1.0-gpu: took 41.46 seconds to finish computing 3544 images with batch size 256\n",
    "------------------------------\n",
    "4.1.0-gpu: took 51.32 seconds to finish computing 3544 images with batch size 512\n",
    "------------------------------\n",
    "4.1.0-gpu: took 41.76 seconds to finish computing 3544 images with batch size 1024\n",
    "```\n",
    "\n",
    "\n",
    "## imagenet-mini\n",
    "\n",
    "### CPU\n",
    "```\n",
    "4.1.0-cpu: took 1423.02 seconds to finish computing 34742 images with batch size 16\n",
    "```\n",
    "\n",
    "### CPU with oneDNN\n",
    "```\n",
    "4.1.0-cpu-opt: took 1277.69 seconds to finish computing 34742 images with batch size 2\n",
    "```\n",
    "\n",
    "### GPU\n",
    "```\n",
    "------------------------------\n",
    "4.1.0-gpu: took 408.46 seconds to finish computing 34742 images with batch size 2\n",
    "------------------------------\n",
    "4.1.0-gpu: took 337.21 seconds to finish computing 34742 images with batch size 8\n",
    "------------------------------\n",
    "4.1.0-gpu: took 306.45 seconds to finish computing 34742 images with batch size 16\n",
    "------------------------------\n",
    "4.1.0-gpu: took 277.35 seconds to finish computing 34742 images with batch size 32\n",
    "------------------------------\n",
    "4.1.0-gpu: took 280.50 seconds to finish computing 34742 images with batch size 64\n",
    "------------------------------\n",
    "4.1.0-gpu: took 297.29 seconds to finish computing 34742 images with batch size 128\n",
    "------------------------------\n",
    "4.1.0-gpu: took 283.23 seconds to finish computing 34742 images with batch size 256\n",
    "------------------------------\n",
    "4.1.0-gpu: took 289.30 seconds to finish computing 34742 images with batch size 512\n",
    "------------------------------\n",
    "4.1.0-gpu: took 285.95 seconds to finish computing 34742 images with batch size 1024\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb137e5-01bb-4739-a8e6-44a3ce694661",
   "metadata": {},
   "source": [
    "### Hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77ab6f96-5624-4a8b-8a09-eb9bf2086c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture:          x86_64\n",
      "CPU op-mode(s):        32-bit, 64-bit\n",
      "Byte Order:            Little Endian\n",
      "CPU(s):                80\n",
      "On-line CPU(s) list:   0-79\n",
      "Thread(s) per core:    2\n",
      "Core(s) per socket:    20\n",
      "Socket(s):             2\n",
      "NUMA node(s):          2\n",
      "Vendor ID:             GenuineIntel\n",
      "CPU family:            6\n",
      "Model:                 79\n",
      "Model name:            Intel(R) Xeon(R) CPU E5-2698 v4 @ 2.20GHz\n",
      "Stepping:              1\n",
      "CPU MHz:               1200.718\n",
      "CPU max MHz:           3600.0000\n",
      "CPU min MHz:           1200.0000\n",
      "BogoMIPS:              4401.48\n",
      "Virtualization:        VT-x\n",
      "L1d cache:             32K\n",
      "L1i cache:             32K\n",
      "L2 cache:              256K\n",
      "L3 cache:              51200K\n",
      "NUMA node0 CPU(s):     0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48,50,52,54,56,58,60,62,64,66,68,70,72,74,76,78\n",
      "NUMA node1 CPU(s):     1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79\n",
      "Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt ssbd ibrs ibpb stibp kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdseed adx smap xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts md_clear flush_l1d\n",
      "              total        used        free      shared  buff/cache   available\n",
      "Mem:           251G         94G        124G        3.1G         33G        153G\n",
      "Swap:           46G         23M         46G\n",
      "Fri Aug 12 17:41:14 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA Tesla P1...  Off  | 00000000:04:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    30W / 250W |  11895MiB / 12198MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA Tesla P1...  Off  | 00000000:05:00.0 Off |                    0 |\n",
      "| N/A   33C    P0    31W / 250W |    383MiB / 12198MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA Tesla P1...  Off  | 00000000:06:00.0 Off |                    0 |\n",
      "| N/A   35C    P0    31W / 250W |    383MiB / 12198MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA Tesla P1...  Off  | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   28C    P0    30W / 250W |    383MiB / 12198MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A    111098      C   ....0-openjdk-amd64/bin/java    11893MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!lscpu\n",
    "\n",
    "!free -h\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa2d10b-c7fd-44d7-8fbc-90bc9061a80f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
