{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4z7qzgHN57Da"
   },
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2IAGcd8757D3"
   },
   "source": [
    "# Spark NLP and Spark ML Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0EPeAfbf57EN"
   },
   "source": [
    "## Simple Topic Modeling\n",
    "\n",
    "`Spark-NLP`\n",
    "* DocumentAssembler\n",
    "* SentenceDetector\n",
    "* Tokenizer\n",
    "* Normalizer\n",
    "* POS tagger\n",
    "* Chunker\n",
    "* Finisher\n",
    "\n",
    "`Spark ML`\n",
    "* Hashing\n",
    "* TF-IDF\n",
    "* LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KEuzEtYE57Eg"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import CountVectorizer, HashingTF, IDF, Tokenizer\n",
    "from pyspark.ml.clustering import LDA, LDAModel\n",
    "\n",
    "#Spark NLP\n",
    "import sparknlp\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.common import RegexRule\n",
    "from sparknlp.base import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wVWI81h257FH"
   },
   "source": [
    "### Let's create a Spark Session for our app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "-aMxhxT057FM",
    "outputId": "e08fd8a1-24c9-4de3-d9d1-eed3080e5cdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version:  2.6.0\n",
      "Apache Spark version:  2.4.4\n"
     ]
    }
   ],
   "source": [
    "spark = sparknlp.start()\n",
    "\n",
    "print(\"Spark NLP version: \", sparknlp.version())\n",
    "print(\"Apache Spark version: \", spark.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ljYdLGFg57Fn"
   },
   "source": [
    "Let's download some scientific sample from PubMed dataset:\n",
    "```\n",
    "wget -N \thttps://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/pubmed/pubmed-sample.csv -P /tmp\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "colab_type": "code",
    "id": "THoie2TP57Fq",
    "outputId": "73cd41ae-823f-4fc3-d53d-d919786a61c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-09-13 17:31:17--  https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/pubmed/pubmed-sample.csv\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.184.157\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.184.157|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10484510 (10.0M) [text/csv]\n",
      "Saving to: ‘/tmp/pubmed-sample.csv’\n",
      "\n",
      "pubmed-sample.csv   100%[===================>]  10.00M  4.26MB/s    in 2.3s    \n",
      "\n",
      "2020-09-13 17:31:20 (4.26 MB/s) - ‘/tmp/pubmed-sample.csv’ saved [10484510/10484510]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget -N \thttps://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/pubmed/pubmed-sample.csv -P /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "emTfVUoT57F1"
   },
   "outputs": [],
   "source": [
    "pubMedDF = spark.read\\\n",
    "                .option(\"header\", \"true\")\\\n",
    "                .csv(\"/tmp/pubmed-sample.csv\")\\\n",
    "                .filter(\"AB IS NOT null\")\\\n",
    "                .withColumn(\"text\", col(\"AB\"))\\\n",
    "                .drop(\"TI\", \"AB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 505
    },
    "colab_type": "code",
    "id": "BJLM8EJg57F-",
    "outputId": "2259b358-109a-4d0d-d5b9-b83e25ca89af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      "\n",
      "+--------------------+\n",
      "|                text|\n",
      "+--------------------+\n",
      "|The human KCNJ9 (...|\n",
      "|BACKGROUND: At pr...|\n",
      "|OBJECTIVE: To inv...|\n",
      "|Combined EEG/fMRI...|\n",
      "|Kohlschutter synd...|\n",
      "|Statistical analy...|\n",
      "|The synthetic DOX...|\n",
      "|Our objective was...|\n",
      "|We conducted a ph...|\n",
      "|\"Monomeric sarcos...|\n",
      "|We presented the ...|\n",
      "|The literature de...|\n",
      "|A novel approach ...|\n",
      "|An HPLC-ESI-MS-MS...|\n",
      "|The localizing an...|\n",
      "|OBJECTIVE: To eva...|\n",
      "|For the construct...|\n",
      "|We report the res...|\n",
      "|Intraparenchymal ...|\n",
      "|It is known that ...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "rows 7537\n"
     ]
    }
   ],
   "source": [
    "pubMedDF.printSchema()\n",
    "pubMedDF.show()\n",
    "print('rows', pubMedDF.count())\n",
    "pubMedDF = pubMedDF.limit(200) #minimize dataset if you are not running on a cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vqdu2hFt57GL"
   },
   "source": [
    "### Let's create Spark-NLP Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66
    },
    "colab_type": "code",
    "id": "KF4bSQGg57GN",
    "outputId": "12e95e44-f7f1-438f-c82c-15d1fd8e75ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_anc download started this may take some time.\n",
      "Approximate size to download 4.3 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "# Spark NLP Pipeline\n",
    "\n",
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\")\n",
    "\n",
    "sentence_detector = SentenceDetector() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols([\"sentence\"]) \\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "posTagger = PerceptronModel.pretrained() \\\n",
    "  .setInputCols([\"sentence\", \"token\"])\n",
    "\n",
    "chunker = Chunker() \\\n",
    "    .setInputCols([\"sentence\", \"pos\"]) \\\n",
    "    .setOutputCol(\"chunk\") \\\n",
    "    .setRegexParsers([\"<NNP>+\", \"<DT>?<JJ>*<NN>\"])\n",
    "\n",
    "finisher = Finisher() \\\n",
    "  .setInputCols([\"chunk\"]) \\\n",
    "  .setIncludeMetadata(False)\n",
    "\n",
    "nlpPipeline = Pipeline(stages=[\n",
    "    document_assembler, \n",
    "    sentence_detector, \n",
    "    tokenizer,\n",
    "    posTagger,\n",
    "    chunker,\n",
    "    finisher\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wQpoBmBQ57GZ"
   },
   "outputs": [],
   "source": [
    "nlpPipelineDF = nlpPipeline.fit(pubMedDF).transform(pubMedDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v3cTHcvM57Gh"
   },
   "source": [
    "### Let's create Spark ML Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J86d68dw57Gi"
   },
   "outputs": [],
   "source": [
    "# SPark ML Pipeline\n",
    "\n",
    "cv = CountVectorizer(inputCol=\"finished_chunk\", outputCol=\"features\", vocabSize=1000, minDF=10.0, minTF=10.0)\n",
    "idf = IDF(inputCol=\"features\", outputCol=\"idf\")\n",
    "lda = LDA(k=10, maxIter=5)\n",
    "### Let's create Spark-NLP Pipeline\n",
    "mlPipeline = Pipeline(stages=[\n",
    "    cv,\n",
    "    idf,\n",
    "    lda\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3gsgIMYb57Gp"
   },
   "source": [
    "### We are going to train Spark ML Pipeline by using Spark-NLP Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "02kj9BFc57Gr"
   },
   "outputs": [],
   "source": [
    "# Let's create Spark-NLP Pipeline\n",
    "mlModel = mlPipeline.fit(nlpPipelineDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uePteSjt57Gw"
   },
   "outputs": [],
   "source": [
    "mlPipelineDF = mlModel.transform(nlpPipelineDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 440
    },
    "colab_type": "code",
    "id": "h1aJa9wq57G5",
    "outputId": "9353f6f5-75cd-4497-d4f3-a347ca7da40a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------+----------+--------------------+\n",
      "|                text|      finished_chunk|  features|       idf|   topicDistribution|\n",
      "+--------------------+--------------------+----------+----------+--------------------+\n",
      "|The human KCNJ9 (...|[KCNJ9, Kir, GIRK...|(39,[],[])|(39,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|BACKGROUND: At pr...|[BACKGROUND, the ...|(39,[],[])|(39,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|OBJECTIVE: To inv...|[OBJECTIVE, =9796...|(39,[],[])|(39,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|Combined EEG/fMRI...|[Combined EEG/fMR...|(39,[],[])|(39,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|Kohlschutter synd...|[Kohlschutter, sy...|(39,[],[])|(39,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|Statistical analy...|[Statistical, ana...|(39,[],[])|(39,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|The synthetic DOX...|[DOX-LNA, conjuga...|(39,[],[])|(39,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|Our objective was...|[objective, blood...|(39,[],[])|(39,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|We conducted a ph...|[II, a phase, stu...|(39,[],[])|(39,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|\"Monomeric sarcos...|[Monomeric, MSOX,...|(39,[],[])|(39,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|We presented the ...|[Exorista, Mythim...|(39,[],[])|(39,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|The literature de...|[The literature, ...|(39,[],[])|(39,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|A novel approach ...|[A novel, approac...|(39,[],[])|(39,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|An HPLC-ESI-MS-MS...|[HPLC-ESI-MS-MS, ...|(39,[],[])|(39,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|The localizing an...|[The localizing, ...|(39,[],[])|(39,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|OBJECTIVE: To eva...|[OBJECTIVE, June,...|(39,[],[])|(39,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|For the construct...|[the construction...|(39,[],[])|(39,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|We report the res...|[PNP, GSTO, Yaqui...|(39,[],[])|(39,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|Intraparenchymal ...|[Intraparenchymal...|(39,[],[])|(39,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "|It is known that ...|[Klinefelter's, s...|(39,[],[])|(39,[],[])|[0.0,0.0,0.0,0.0,...|\n",
      "+--------------------+--------------------+----------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlPipelineDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "suE9r6hs57HB"
   },
   "outputs": [],
   "source": [
    "ldaModel = mlModel.stages[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "tCXM4vDp57HH",
    "outputId": "543801e3-25f1-4a43-9488-82d6e76e5e6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lower bound on the log likelihood of the entire corpus: -473.13472468195687\n",
      "The upper bound on perplexity: 20.57107498617204\n"
     ]
    }
   ],
   "source": [
    "ll = ldaModel.logLikelihood(mlPipelineDF)\n",
    "lp = ldaModel.logPerplexity(mlPipelineDF)\n",
    "print(\"The lower bound on the log likelihood of the entire corpus: \" + str(ll))\n",
    "print(\"The upper bound on perplexity: \" + str(lp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277
    },
    "colab_type": "code",
    "id": "RxnifLA257HO",
    "outputId": "a2423f29-cc71-4030-8887-c8c5e96670ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The topics described by their top-weighted terms:\n",
      "+-----+------------+-----------------------------------------------------------------+\n",
      "|topic|termIndices |termWeights                                                      |\n",
      "+-----+------------+-----------------------------------------------------------------+\n",
      "|0    |[31, 27, 9] |[0.03257476024357697, 0.030675255742522122, 0.03046738952388627] |\n",
      "|1    |[5, 35, 8]  |[0.030694164334629563, 0.029606943258556426, 0.02874382837700391]|\n",
      "|2    |[9, 17, 1]  |[0.030174246224099154, 0.03008463621531343, 0.029110783343217993]|\n",
      "|3    |[16, 21, 17]|[0.030326862202922272, 0.03006946863540257, 0.028664585585146864]|\n",
      "|4    |[11, 34, 17]|[0.0327023724028336, 0.032491287107370766, 0.029777996132834567] |\n",
      "|5    |[1, 4, 10]  |[0.19069340337059643, 0.027078607193686037, 0.02691452950534889] |\n",
      "|6    |[20, 29, 32]|[0.03305884263172731, 0.03217891937972598, 0.030787830019083622] |\n",
      "|7    |[27, 20, 7] |[0.033333923807145116, 0.029616433465517945, 0.02935799300889215]|\n",
      "|8    |[24, 21, 3] |[0.03312480702370545, 0.030568576982645604, 0.03033976117133302] |\n",
      "|9    |[7, 31, 2]  |[0.03129689527508416, 0.030329533304573983, 0.029998939553729464]|\n",
      "+-----+------------+-----------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Describe topics.\n",
    "print(\"The topics described by their top-weighted terms:\")\n",
    "ldaModel.describeTopics(3).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "63TxUsJw57HS"
   },
   "source": [
    "### Let's look at out topics\n",
    "NOTE: More cleaning, filtering, playing around with `CountVectorizer`, and more iterations in `LDA` will result in better Topic Modelling results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "wVzJ8Vcv57HU",
    "outputId": "1427a7e1-cc6e-4fcf-c7d0-634894d2723e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned topics (as distributions over vocab of 39 words):\n",
      "topic:  0\n",
      "----------\n",
      "therapy\n",
      "OBJECTIVE\n",
      "treatment\n",
      "addition\n",
      "function\n",
      "age\n",
      "group\n",
      "<\n",
      "this study\n",
      "CONCLUSION\n",
      "protein\n",
      "factor\n",
      "DNA\n",
      "METHODS\n",
      "time\n",
      "expression\n",
      "gene\n",
      "risk\n",
      "response\n",
      ").\n",
      "----------\n",
      "topic:  1\n",
      "----------\n",
      "protein\n",
      "family\n",
      "analysis\n",
      "),\n",
      "CONCLUSIONS\n",
      "group\n",
      "rate\n",
      "treatment\n",
      "response\n",
      "vitro\n",
      "function\n",
      "cell\n",
      "activity\n",
      "<\n",
      "addition\n",
      "cancer\n",
      "PURPOSE\n",
      "factor\n",
      "CONCLUSION\n",
      "disease\n",
      "----------\n",
      "topic:  2\n",
      "----------\n",
      "treatment\n",
      "function\n",
      "),\n",
      "PURPOSE\n",
      "vivo\n",
      "vitro\n",
      "serum\n",
      "cell\n",
      "method\n",
      "CONCLUSIONS\n",
      "P\n",
      "time\n",
      "group\n",
      "BACKGROUND\n",
      "disease\n",
      "CONCLUSION\n",
      "response\n",
      "DNA\n",
      "OBJECTIVE\n",
      "analysis\n",
      "----------\n",
      "topic:  3\n",
      "----------\n",
      "activity\n",
      "serum\n",
      "function\n",
      "therapy\n",
      "vivo\n",
      "cell\n",
      "response\n",
      "vitro\n",
      "factor\n",
      "METHODS\n",
      "OBJECTIVE\n",
      "),\n",
      "addition\n",
      "family\n",
      "CONCLUSIONS\n",
      "PURPOSE\n",
      "treatment\n",
      "age\n",
      "P\n",
      "study\n",
      "----------\n",
      "topic:  4\n",
      "----------\n",
      "<\n",
      "contrast\n",
      "function\n",
      "this study\n",
      "analysis\n",
      "vivo\n",
      "CONCLUSION\n",
      "cell\n",
      "),\n",
      "family\n",
      "rate\n",
      "time\n",
      "therapy\n",
      "OBJECTIVE\n",
      "response\n",
      "protein\n",
      "CONCLUSIONS\n",
      "risk\n",
      "activity\n",
      "METHODS\n",
      "----------\n",
      "topic:  5\n",
      "----------\n",
      "),\n",
      "cancer\n",
      "CONCLUSIONS\n",
      "therapy\n",
      "level\n",
      "<\n",
      "BACKGROUND\n",
      "activity\n",
      "OBJECTIVE\n",
      "CONCLUSION\n",
      "vivo\n",
      "METHODS\n",
      "P\n",
      "contrast\n",
      "PURPOSE\n",
      "study\n",
      "this study\n",
      "family\n",
      "method\n",
      "rate\n",
      "----------\n",
      "topic:  6\n",
      "----------\n",
      "expression\n",
      "addition\n",
      "risk\n",
      "group\n",
      "treatment\n",
      "function\n",
      "activity\n",
      "BACKGROUND\n",
      "disease\n",
      "this study\n",
      "contrast\n",
      "analysis\n",
      "study\n",
      "serum\n",
      "time\n",
      "method\n",
      "P\n",
      "OBJECTIVE\n",
      ").\n",
      "cancer\n",
      "----------\n",
      "topic:  7\n",
      "----------\n",
      "OBJECTIVE\n",
      "expression\n",
      "cell\n",
      "analysis\n",
      "serum\n",
      "factor\n",
      "protein\n",
      "DNA\n",
      "treatment\n",
      "<\n",
      "contrast\n",
      "group\n",
      "level\n",
      "METHODS\n",
      "this study\n",
      "activity\n",
      "function\n",
      "gene\n",
      "PURPOSE\n",
      "rate\n",
      "----------\n",
      "topic:  8\n",
      "----------\n",
      "time\n",
      "serum\n",
      "METHODS\n",
      "this study\n",
      "family\n",
      "rate\n",
      "level\n",
      "group\n",
      "gene\n",
      "activity\n",
      "therapy\n",
      "cell\n",
      "age\n",
      "P\n",
      ").\n",
      "),\n",
      "PURPOSE\n",
      "response\n",
      "CONCLUSIONS\n",
      "risk\n",
      "----------\n",
      "topic:  9\n",
      "----------\n",
      "cell\n",
      "therapy\n",
      "P\n",
      "PURPOSE\n",
      "DNA\n",
      "METHODS\n",
      "rate\n",
      "vivo\n",
      "contrast\n",
      "function\n",
      ").\n",
      "protein\n",
      "group\n",
      "),\n",
      "analysis\n",
      "method\n",
      "<\n",
      "time\n",
      "vitro\n",
      "disease\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# Output topics. Each is a distribution over words (matching word count vectors)\n",
    "print(\"Learned topics (as distributions over vocab of \" + str(ldaModel.vocabSize())\n",
    "      + \" words):\")\n",
    "\n",
    "topics = ldaModel.describeTopics(20)\n",
    "topics_rdd = topics.rdd\n",
    "\n",
    "vocab = mlModel.stages[0].vocabulary\n",
    "\n",
    "topics_words = topics_rdd\\\n",
    "       .map(lambda row: row['termIndices'])\\\n",
    "       .map(lambda idx_list: [vocab[idx] for idx in idx_list])\\\n",
    "       .collect()\n",
    "\n",
    "for idx, topic in enumerate(topics_words):\n",
    "    print(\"topic: \", idx)\n",
    "    print(\"----------\")\n",
    "    for word in topic:\n",
    "        print(word)\n",
    "    print(\"----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "5- How to use Spark NLP and Spark ML Pipelines.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
