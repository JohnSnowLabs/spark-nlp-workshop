{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Raw Data (with Sentences and Ground Truths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data path: ../data/deid/100_rows_with_gt_jsl.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>ground_truth_list</th>\n",
       "      <th>jsl_prediction_list</th>\n",
       "      <th>prediction_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>929334185</td>\n",
       "      <td>\\n929334185\\nFIH\\n8151167\\n53653/y9m1\\n539442\\...</td>\n",
       "      <td>[{'entity_type': 'ID', 'chunk': '929334185', '...</td>\n",
       "      <td>[{'entity_type': 'ID', 'chunk': '929334185', '...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               text  \\\n",
       "0  929334185  \\n929334185\\nFIH\\n8151167\\n53653/y9m1\\n539442\\...   \n",
       "\n",
       "                                   ground_truth_list  \\\n",
       "0  [{'entity_type': 'ID', 'chunk': '929334185', '...   \n",
       "\n",
       "                                 jsl_prediction_list prediction_list  \n",
       "0  [{'entity_type': 'ID', 'chunk': '929334185', '...              []  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "file_name= '100_rows_with_gt_jsl.pkl'\n",
    "data_path = os.path.join('..', 'data/deid/', file_name )\n",
    "print(\"Raw data path:\", data_path)\n",
    "\n",
    "data_df = pd.read_pickle(data_path)\n",
    "data_df.head(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Task Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# read tasks from file\n",
    "with open(\"./sources/tasks_list.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# extract problem_entity_list and task_list\n",
    "task_list = data[\"task_list\"]\n",
    "eval_options_dict = data[\"eval_options_dict\"]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Select Task to Get Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions will be generated for the entities: Deid\n"
     ]
    }
   ],
   "source": [
    "# select entity for evaluation\n",
    "entity_under_test = \"Deid\"\n",
    "# continue with evaluation using selected entity_under_test\n",
    "print(\"Predictions will be generated for the entities:\", entity_under_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Prepare Data for Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter gt data for prediction based on selected entity under test and entity counts\n",
    "covered_gt_label_list = task_list[entity_under_test]['covered_gt_label_list']\n",
    "\n",
    "prediction_source = \"ChatGPT\"\n",
    "\n",
    "processed_gt_df = data_df.copy()\n",
    "processed_gt_df.loc[:, 'prediction_list'] = [[] for _ in range(len(processed_gt_df))]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. GPT Predictions "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Load Prompt and Initiate Entity Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt for [Deid] extraction task: (./prompts/13_01_DEID.txt)\n",
      "PROMPT:\n",
      "\n",
      "Please extract the following entities from the provided medical record text, specifically hospital discharge notes and/or discharge summaries:\n",
      "\n",
      "ID, DATE, AGE, PHONE, PERSON, ORGANIZATION, LOCATION.\n",
      "\n",
      "IMPOTANT!!! Do not return any other entities except these ones.\n",
      "\n",
      "\n",
      "\n",
      "I have provided sample sentences for each entity type below:\n",
      "\n",
      "\n",
      "\n",
      "ID:\n",
      "\n",
      "\"Mr. Smith's patient ID is 123456789 and he has been visiting our clinic since 2020.\"\n",
      "\n",
      "Example:\n",
      "\n",
      "[{'entity_type': 'ID', 'chunk': '123456789'}]\n",
      "\n",
      "\n",
      "\n",
      "DATE:\n",
      "\n",
      "\"Mrs. Johnson had her last appointment on March 21, 2023, and her next appointment is scheduled for April 18, 2023.\"\n",
      "\n",
      "Example:\n",
      "\n",
      "[{'entity_type': 'DATE', 'chunk': 'March 21, 2023'},\n",
      "\n",
      "{'entity_type': 'DATE', 'chunk': 'April 18, 2023'}]\n",
      "\n",
      "\n",
      "\n",
      "AGE:\n",
      "\n",
      "\"Mr. Anderson is a 45-year-old patient with a history of hypertension.\"\n",
      "\n",
      "Example:\n",
      "\n",
      "[{'entity_type': 'AGE', 'chunk': '45'}]\n",
      "\n",
      "\n",
      "\n",
      "PHONE:\n",
      "\n",
      "\"You can reach Dr. Adams at 555-123-4567 for any questions regarding your treatment plan.\"\n",
      "\n",
      "Example:\n",
      "\n",
      "[{'entity_type': 'PHONE', 'chunk': '555-123-4567'}]\n",
      "\n",
      "\n",
      "\n",
      "PERSON:\n",
      "\n",
      "\"Jane Doe has been suffering from migraines for the past five years.\"\n",
      "\n",
      "Example:\n",
      "\n",
      "[{'entity_type': 'PATIENT', 'chunk': 'Jane Doe'}]\n",
      "\n",
      "\n",
      "\n",
      "ORGANIZATION:\n",
      "\n",
      "\"Mr. Johnson had his surgery at Memorial Hospital, and his recovery was smooth.\"\n",
      "\n",
      "Example:\n",
      "\n",
      "[{'entity_type': 'ORGANIZATION', 'chunk': 'Memorial Hospital'}]\n",
      "\n",
      "\n",
      "\n",
      "LOCATION:\n",
      "\n",
      "\"The patient resides in Los Angeles, California, and visits our local clinic for routine check-ups.\"\n",
      "\n",
      "Example:\n",
      "\n",
      "[{'entity_type': 'LOCATION', 'chunk': 'Los Angeles, California'}]\n",
      "\n",
      "\n",
      "\n",
      "Desired format for extracted entities:\n",
      "\n",
      "{\"list_of_entities\":\n",
      "\n",
      "[\n",
      "\n",
      "{\"entity_type\": \"ID\", \"chunk\": \"929334185\"},\n",
      "\n",
      "{\"entity_type\": \"LOCATION\", \"chunk\": \"Los Angeles\"},\n",
      "\n",
      "...\n",
      "\n",
      "]\n",
      "\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "If an entity is missing or not available in the text, do not include it in the list of entities.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from modules import NerExtraction\n",
    "prompt_file_path = os.path.join('.', 'prompts', task_list[entity_under_test]['prompt_file'] )\n",
    "print(f\"Prompt for [{entity_under_test}] extraction task: ({prompt_file_path})\")\n",
    "\n",
    "with open(prompt_file_path, 'r') as file:\n",
    "    print(\"PROMPT:\\n\")\n",
    "    for line in file:\n",
    "        print(line)\n",
    "    \n",
    "ner_extraction = NerExtraction.ChatGPTNER(prompt_file_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single GPT Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n356529973\\nFIH\\n2102647\\n73383/3545\\n791416\\n1/19/1993 12:00:00 AM\\nPERSISTENT PRIMARY HYPERPARATHYROIDISM .\\nUnsigned\\nDIS\\nReport Status :\\nUnsigned\\nADMISSION DATE :\\n1-19-93\\nDISCHARGE DATE :\\n1-25-93\\nPRINCIPAL DIAGNOSIS :\\npersistent primary hyperparathyroidism .\\nASSOCIATED DIAGNOSIS :\\n1. hypercalcemia ,\\n2. status post previous parathyroidectomy ,\\n3. history of depression ,\\n4. hypertension ,\\n5. cholelithiasis ,\\n6. thyroid papillary carcinoma ,\\n7. status post total thyroidectomy ,\\n8. status post radio-iodine therapy ,\\n9. history of pancreatitis ,\\n10. status post tube thoracostomy for empyema ,\\n11. history of cigarette smoking ,\\n12. history of lymphosarcoma , treated with radiation therapy ,\\n13. abnormal Papanicolaou smear ,\\n14. status post colonic polypectomy ,\\n15. nephrolithiasis ,\\n16. status post extracorporeal shockwave lithotripsy ,\\n17. history of urinary tract infections , recurrent ,\\n18. status post appendectomy ,\\n19. hiatus hernia ,\\n20. migraine headaches ,\\n21. right ovarian enlargement .\\nSPECIAL PROCEDURES AND OPERATIONS :\\n1-19-93 bilateral neck re-exploration with right parathyroidectomy and right modified radical neck dissection .\\nHISTORY OF PRESENT ILLNESS :\\nThe patient is a 52 year old married female with nephrolithiasis , history of depression , bone pain , anorexia , insomnia , headache , nausea , fatigue , malaise , hypercalcemia , elevated PTH and history of pancreatitis .\\nRecent biochemical investigation revealed calcium of 10.4 , phosphorus of 2.6 and elevated PTH of 84 ( normal less than 60 ) .\\nAn ultrasound examination of the neck was unrewarding .\\nPrevious computerized tomography scan , magnetic resonance imaging study and Thallium scan showed a right paratracheal mass , consistent with persistent parathyroid tumor .\\nShe has undergone previous parathyroidectomy and thyroidectomy for papillary carcinoma .\\nThe patient is admitted at this time for further treatment of persistent primary hyperparathyroidism .\\nPHYSICAL EXAMINATION :\\nOn physical examination , the patient is an anxious , middle aged female with a normal voice .\\nHer vital signs included a temperature of 96.9 , blood pressure 150/90 , respirations of 18 and heart rate 92 .\\nNeck examination reveals a thyroidectomy scar with no palpable thyroid bed masses or lymphadenopathy .\\nHer lungs were clear to auscultation and percussion .\\nShe has a right lower neck surgical clip visible on chest X-ray but nothing palpable in this region .\\nBreast examination reveals no lumps , skin changes or axillary lymphadenopathy .\\nCardiovascular exam :\\nregular rate and rhythm , with a grade II / VI systolic ejection murmur at the left sternal border .\\nThe abdomen was soft , nontender , nondistended , well healed incisions but no hepatosplenomegaly or masses .\\nLABORATORY DATA :\\nsignificant for a calcium of 10.4 , phosphorus 2.9 , alkaline phosphatase 76 , magnesium 1.7 , BUN and creatinine 10 and 0.7 , CA-125 11.1 ( normal less than 35 ) , sodium 143 , potassium 3.8 and chloride 107 , bicarbonate 25.3 , glucose 99 , direct bilirubin 0.1 , total bilirubin 0.5 , SGOT 15 , prothrombin time 9.8/10.0 , partial thromboplastin time 29.2 , platelet count 216,000 , white blood count 18.4 , hematocrit 41.1 , hemoglobin 14.2 , platelet count already mentioned .\\nThe urinalysis , chest X-ray and electrocardiogram were within normal limits .\\nHOSPITAL COURSE :\\nThe patient was admitted and on 1-19-93 , she underwent bilateral neck exploration with excision of a right paratracheal parathyroid adenoma , measuring 23 x 13 x 9 millimeters in size .\\nA limited right neck dissection was performed , removing multiple small cervical lymph nodes .\\nThe left thyroid bed was examined , but no residual thyroid was identified .\\nA normal appearing left upper parathyroid gland was seen and preserved .\\nAbout 75 mg of the right sided parathyroid adenoma was cryopreserved should transplantation be necessary .\\nShe underwent dilation and curettage under the same anesthesia .\\nHer calcium fell postoperatively , to 6.8 mg % and she developed paresthesias , requiring intravenous calcium .\\nSubsequently , the calcium stabilized with oral medication , 2 grams a day .\\nThe calcium was fluctuating between 8.3 and 8.7 at the time of discharge .\\nDuring her hospitalization , she underwent gynecologic and neurological evaluation .\\nShe appears to have a right sided ovarian enlargement with previous abnormal Papanicolaou smear requiring further investigation .\\nAn ultrasound disclosed enlargement of the right ovary .\\nPapanicolaou smear previously documented psammoma body .\\nRepeat Papanicolaou smear studies are pending at the time of this dictation .\\nThe curettage of the endometrium was nondiagnostic .\\nA computerized tomography scan and neurologic evaluation was consistent with migraine headaches and no other focal problems .\\nThe patient had no hoarseness or airway problems .\\nHer sutures were removed on the third postoperative day .\\nThe patient was discharged home in stable condition .\\nDOCTORS DISCHARGE ORDERS :\\nSynthroid 0.125 mg PO q.day , Os-Cal 500 mg PO q.i.d.\\nShe will remove the neck suture line steri-strips in one week and will follow up with Dr. Bone in his office in two weeks .\\nERTCA D. BONE , M.D.\\nTR :\\niz / bmot\\nDD :\\n1-25-93\\nTD :\\n01/26/93\\nCC :\\n3 copies to Dr. Bone Dr. Drabelk Kote at Box Memorial Hospital Nursing Home Dr. Naabel Scgach Dr. Bone\\n[ report_end ]\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = processed_gt_df.iloc[3,1]\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ner_extraction.do_query(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-75HMmjHYjvwDevQPJYV3NRYe3RZOz at 0x7f9fa46f5220> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"content\": \"{\\\"list_of_entities\\\":\\n[\\n{\\\"entity_type\\\": \\\"ID\\\", \\\"chunk\\\": \\\"2102647\\\"},\\n{\\\"entity_type\\\": \\\"AGE\\\", \\\"chunk\\\": \\\"52\\\"},\\n{\\\"entity_type\\\": \\\"PHONE\\\", \\\"chunk\\\": null},\\n{\\\"entity_type\\\": \\\"PATIENT\\\", \\\"chunk\\\": null},\\n{\\\"entity_type\\\": \\\"ORGANIZATION\\\", \\\"chunk\\\": \\\"Memorial Hospital\\\"},\\n{\\\"entity_type\\\": \\\"LOCATION\\\", \\\"chunk\\\": null},\\n{\\\"entity_type\\\": \\\"DATE\\\", \\\"chunk\\\": \\\"1-19-93\\\"},\\n{\\\"entity_type\\\": \\\"DATE\\\", \\\"chunk\\\": \\\"1-25-93\\\"}\\n]\\n}\",\n",
       "        \"role\": \"assistant\"\n",
       "      }\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1681492752,\n",
       "  \"id\": \"chatcmpl-75HMmjHYjvwDevQPJYV3NRYe3RZOz\",\n",
       "  \"model\": \"gpt-3.5-turbo-0301\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 124,\n",
       "    \"prompt_tokens\": 1814,\n",
       "    \"total_tokens\": 1938\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"list_of_entities\":\\n[\\n{\"entity_type\": \"ID\", \"chunk\": \"2102647\"},\\n{\"entity_type\": \"AGE\", \"chunk\": \"52\"},\\n{\"entity_type\": \"PHONE\", \"chunk\": null},\\n{\"entity_type\": \"PATIENT\", \"chunk\": null},\\n{\"entity_type\": \"ORGANIZATION\", \"chunk\": \"Memorial Hospital\"},\\n{\"entity_type\": \"LOCATION\", \"chunk\": null},\\n{\"entity_type\": \"DATE\", \"chunk\": \"1-19-93\"},\\n{\"entity_type\": \"DATE\", \"chunk\": \"1-25-93\"}\\n]\\n}'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"choices\"][0][\"message\"]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'list_of_entities': [{'entity_type': 'ID', 'chunk': '2102647'},\n",
       "  {'entity_type': 'AGE', 'chunk': '52'},\n",
       "  {'entity_type': 'PHONE', 'chunk': None},\n",
       "  {'entity_type': 'PATIENT', 'chunk': None},\n",
       "  {'entity_type': 'ORGANIZATION', 'chunk': 'Memorial Hospital'},\n",
       "  {'entity_type': 'LOCATION', 'chunk': None},\n",
       "  {'entity_type': 'DATE', 'chunk': '1-19-93'},\n",
       "  {'entity_type': 'DATE', 'chunk': '1-25-93'}]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPT3.5\n",
    "from modules.ProcessPredData import corrected_json, get_list_of_entities\n",
    "\n",
    "json_result = corrected_json(result)\n",
    "json_result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Get Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./processed_data/Deid_preds_0414_1712\n",
      "Given dataframe shape (5, 5)\n",
      "Getting predictions from API started...\n",
      "Query: 1 | index: 0 | status: SUCCESS\n",
      "Query: 2 | index: 1 | status: SUCCESS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-14 17:12:49,248 - ProcessPredData - ERROR - generate_start_end_index function error decoding to str: need a bytes-like object, NoneType found\n",
      "2023-04-14 17:12:49,251 - ProcessPredData - ERROR - generate_start_end_index function error decoding to str: need a bytes-like object, NoneType found\n",
      "2023-04-14 17:12:49,253 - ProcessPredData - ERROR - generate_start_end_index function error decoding to str: need a bytes-like object, NoneType found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 3 | index: 2 | status: SUCCESS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-14 17:12:55,477 - ProcessPredData - ERROR - generate_start_end_index function error decoding to str: need a bytes-like object, NoneType found\n",
      "2023-04-14 17:12:55,479 - ProcessPredData - ERROR - generate_start_end_index function error decoding to str: need a bytes-like object, NoneType found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 4 | index: 3 | status: SUCCESS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-14 17:13:13,779 - ProcessPredData - ERROR - corrected_json function error :malformed or empty prediction from gpt api... skipping this sentence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting predictions from API finished.\n",
      "final df shape: (4, 5)\n",
      "file saved as ./processed_data/Deid_preds_0414_1712.csv \n"
     ]
    }
   ],
   "source": [
    "# !!! Run without any changes\n",
    "\n",
    "from modules import BatchProcessing\n",
    "from modules.ProcessPredData import corrected_json, get_list_of_entities\n",
    "import datetime\n",
    "\n",
    "# Assing auto name to save prediction data as csv and excel\n",
    "now = datetime.datetime.now()\n",
    "file_name = f\"{entity_under_test}_preds_{now.strftime('%m%d_%H%M')}\"\n",
    "if not os.path.exists('processed_data'):\n",
    "    os.makedirs('processed_data')\n",
    "processed_data_path = os.path.join('.', 'processed_data', file_name)\n",
    "\n",
    "# number of sentences to process\n",
    "i = 5\n",
    "\n",
    "print(processed_data_path)\n",
    "batch_processor = BatchProcessing.ProcessBatch(\n",
    "    processed_gt_df.head(i),\n",
    "    ner_extraction,\n",
    "    corrected_json,\n",
    "    get_list_of_entities,\n",
    "    processed_data_path\n",
    ")\n",
    "\n",
    "results_df = batch_processor.do_processing()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Selection of entity for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "###!!! USER INPUT MIGHT BE NECESSARY if there are multiple entites for evaluation under given task\n",
    "entity_for_benchmark = \"Deid\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Run Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results saved as ./eval_results/Deid_ChatGPT_eval_0414_1713.xlsx\n",
      "Results appended to file: eval_results/eval_result.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'version': 'Deid_ChatGPT_eval_0414_1713',\n",
       " 'selected_entity_prediction': ['ID',\n",
       "  'DATE',\n",
       "  'AGE',\n",
       "  'PHONE',\n",
       "  'PERSON',\n",
       "  'LOCATION',\n",
       "  'ORGANIZATION'],\n",
       " 'selected_entity_gt': ['ID',\n",
       "  'DATE',\n",
       "  'AGE',\n",
       "  'PHONE',\n",
       "  'DOCTOR',\n",
       "  'PATIENT',\n",
       "  'NAME',\n",
       "  'HOSPITAL',\n",
       "  'LOCATION',\n",
       "  'ORGANIZATION'],\n",
       " 'full_match': 21,\n",
       " 'accuracy_full_match': 0.09,\n",
       " 'partial_match': 11,\n",
       " 'accuracy_partial_match': 0.13,\n",
       " 'no_match': 207,\n",
       " 'gt_count': 239,\n",
       " 'fp_count': 5}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No user interaction needed, just run the cell\n",
    "from modules import Evaluation\n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "eval_file_to_save = entity_for_benchmark + \"_\" + prediction_source + f\"_eval_{now.strftime('%m%d_%H%M')}\"\n",
    "\n",
    "selected_entity_prediction = eval_options_dict[entity_for_benchmark][\"selected_entity_prediction\"]\n",
    "selected_entity_gt = eval_options_dict[entity_for_benchmark][\"selected_entity_gt\"]\n",
    "gt_type_dict = eval_options_dict[entity_for_benchmark][\"gt_type_dict\"]\n",
    "\n",
    "file_path__to_read_prediction = f\"{processed_data_path}.csv\"\n",
    "# alternative to reading prediction results from file \n",
    "# dataframe = results_df !!! make >> file_path__to_read_prediction = None \n",
    "\n",
    "evaluator = Evaluation.Evaluate(\n",
    "    file_path=file_path__to_read_prediction, \n",
    "    dataframe=None, \n",
    "    prediction_source=prediction_source\n",
    ")\n",
    "\n",
    "eval_results = evaluator.get_match_counts(\n",
    "    selected_entity_prediction, \n",
    "    selected_entity_gt, \n",
    "    eval_file_to_save,\n",
    "    gt_type_dict\n",
    ")\n",
    "\n",
    "# create folder if it doesn't exist\n",
    "if not os.path.exists('eval_results'):\n",
    "    os.makedirs('eval_results')\n",
    "    \n",
    "# write result to JSON file\n",
    "with open('eval_results/eval_result.json', 'a') as f:\n",
    "    json.dump(eval_results, f)\n",
    "    print(\"Results appended to file: eval_results/eval_result.json\")\n",
    "    \n",
    "eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
