{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLqW6FOnEvov"
      },
      "source": [
        "# Train Legal Assertion\n"
      ],
      "id": "KLqW6FOnEvov"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxZDXLDCXkk_"
      },
      "source": [
        "\n",
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "wxZDXLDCXkk_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZ6sKi8ZX1z4"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Legal/16.Training_Legal_Assertion.ipynb)"
      ],
      "id": "pZ6sKi8ZX1z4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcsTZJmZu7CQ"
      },
      "source": [
        "# Colab Setup"
      ],
      "id": "PcsTZJmZu7CQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELqzaf32MT6E"
      },
      "outputs": [],
      "source": [
        "# Install the johnsnowlabs library to access Spark-OCR and Spark-NLP for Healthcare, Finance, and Legal.\n",
        "! pip install johnsnowlabs "
      ],
      "id": "ELqzaf32MT6E"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fe96e8d6-c2a3-4464-b78e-90e83f743823"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "print('Please upload your John Snow Labs License using the button below')\n",
        "license_keys = files.upload()"
      ],
      "id": "fe96e8d6-c2a3-4464-b78e-90e83f743823"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOzbTlCRNvVd",
        "outputId": "aa4536cc-fd00-446b-91d1-2615a159b722"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üëå Detected license file /content/4.2.0.spark_nlp_for_healthcare.json\n",
            "üö® Outdated Medical Secrets in license file. Version=4.2.0 but should be Version=0.1.14\n",
            "üìã Stored John Snow Labs License in /root/.johnsnowlabs/licenses/license_number_0_for_Spark-Healthcare_Spark-OCR.json\n",
            "üë∑ Setting up if John Snow Labs home exists in /root/.johnsnowlabs this might take a few minutes.\n",
            "Downloading üêç+üöÄ Python Library spark_nlp-4.2.0-py2.py3-none-any.whl\n",
            "Downloading üêç+üíä Python Library internal_with_finleg-4.0.0rc1-py3-none-any.whl\n",
            "Downloading üêç+üï∂ Python Library spark_ocr-4.1.0-py3-none-any.whl\n",
            "Downloading ü´ò+üöÄ Java Library spark-nlp-assembly-4.2.0.jar\n",
            "Downloading ü´ò+üíä Java Library spark-nlp-jsl-assembly-4.2.0fl1.jar\n",
            "Downloading ü´ò+üï∂ Java Library spark-ocr-assembly-4.1.0.jar\n",
            "üôÜ JSL Home setup in /root/.johnsnowlabs\n",
            "üëå Detected license file /content/4.2.0.spark_nlp_for_healthcare.json\n",
            "Installing /root/.johnsnowlabs/py_installs/internal_with_finleg-4.0.0rc1-py3-none-any.whl to /usr/bin/python3\n",
            "Running: /usr/bin/python3 -m pip install /root/.johnsnowlabs/py_installs/internal_with_finleg-4.0.0rc1-py3-none-any.whl\n",
            "üëå Detected license file /content/4.2.0.spark_nlp_for_healthcare.json\n",
            "Installing /root/.johnsnowlabs/py_installs/spark_ocr-4.1.0-py3-none-any.whl to /usr/bin/python3\n",
            "Running: /usr/bin/python3 -m pip install /root/.johnsnowlabs/py_installs/spark_ocr-4.1.0-py3-none-any.whl\n",
            "üëå Detected license file /content/4.2.0.spark_nlp_for_healthcare.json\n",
            "Installing /root/.johnsnowlabs/py_installs/spark_nlp-4.2.0-py2.py3-none-any.whl to /usr/bin/python3\n",
            "Running: /usr/bin/python3 -m pip install /root/.johnsnowlabs/py_installs/spark_nlp-4.2.0-py2.py3-none-any.whl\n",
            "Installing pyspark to /usr/bin/python3\n",
            "Running: /usr/bin/python3 -m pip install pyspark\n",
            "Installed 3 products:\n",
            "üíä Spark-Healthcare==False installed! ‚úÖ Heal the planet with NLP! \n",
            "üï∂ Spark-OCR==4.1.0 installed! ‚úÖ Empower your NLP with a set of eyes \n",
            "üöÄ Spark-NLP==4.2.0 installed! ‚úÖ State of the art NLP at scale \n",
            "üîÅ\u001b[91m If you are on Google Colab, please restart your Notebook for changes to take effect \u001b[39müîÅ\n"
          ]
        }
      ],
      "source": [
        "from johnsnowlabs import * \n",
        "# After uploading your license run this to install all licensed Python Wheels and pre-download Jars the Spark Session JVM\n",
        "# Make sure to restart your notebook afterwards for changes to take effect\n",
        "jsl.install()"
      ],
      "id": "JOzbTlCRNvVd"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZIjuI3zN1Oi",
        "outputId": "4571e6e6-2983-4637-b18d-535162453fbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[91müö® Your Spark-OCR is outdated, installed==4.0.0rc1 but latest version==4.1.0\n",
            "You can run \u001b[92m jsl.install() \u001b[39mto update Spark-OCR\n",
            "DEBUG START!\n",
            "üëå Detected license file /content/4.2.0.spark_nlp_for_healthcare.json\n",
            "üö® Outdated Medical Secrets in license file. Version=4.2.0 but should be Version=0.1.14\n",
            "üëå Launched \u001b[92mcpu-Optimized JVM\u001b[39m SparkSession with Jars for: üöÄSpark-NLP==4.2.0, üíäSpark-Healthcare==4.0.0rc1, üï∂Spark-OCR==4.1.0, running on ‚ö° PySpark==3.1.2\n"
          ]
        }
      ],
      "source": [
        "# Automatically load license data and start a session with all jars user has access to\n",
        "from johnsnowlabs import * \n",
        "spark = jsl.start()"
      ],
      "id": "TZIjuI3zN1Oi"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GlmdmVsK0npI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "a4119408-fca9-4dae-9ca5-fb8f32d87735"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f9dfc3560d0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://baf374c9ecf3:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>John-Snow-Labs-Spark-Session üöÄ with Jars for: üöÄSpark-NLP==4.2.0, üíäSpark-Healthcare==4.0.0rc1, üï∂Spark-OCR==4.1.0, running on ‚ö° PySpark==3.1.2</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "spark"
      ],
      "id": "GlmdmVsK0npI"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYBQyxEd0uR0"
      },
      "source": [
        "# Data Prep "
      ],
      "id": "JYBQyxEd0uR0"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "AVBmGFcQ03La"
      },
      "outputs": [],
      "source": [
        "! wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Legal/data/assertion_fin.csv"
      ],
      "id": "AVBmGFcQ03La"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8iJF_HCw1Lgh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "training_df = pd.read_csv('./assertion_fin.csv')"
      ],
      "id": "8iJF_HCw1Lgh"
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = spark.createDataFrame(training_df)\n",
        "training_data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JREBeTzb8ov-",
        "outputId": "4714acfc-92dd-45fb-df1f-455c1171aeff"
      },
      "id": "JREBeTzb8ov-",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+---------+-------+--------------------+------+---------------+\n",
            "|task_id|            sentence|tkn_start|tkn_end|               chunk|entity|assertion_label|\n",
            "+-------+--------------------+---------+-------+--------------------+------+---------------+\n",
            "|      1|The Swedish East ...|        1|      4|Swedish East Indi...|   ORG|           PAST|\n",
            "|      1|The Swedish East ...|        6|      8|Svenska Ostindisk...| ALIAS|           PAST|\n",
            "|      1|The Swedish East ...|       10|     10|                SOIC| ALIAS|           PAST|\n",
            "|      1|The Swedish East ...|       14|     14|          Gothenburg|   LOC|           PAST|\n",
            "|      1|The Swedish East ...|       15|     15|              Sweden|   LOC|           PAST|\n",
            "|      1|The Swedish East ...|       17|     17|                1731|  DATE|           PAST|\n",
            "|      1|The Swedish East ...|       25|     25|               China|   LOC|           PAST|\n",
            "|      1|The Swedish East ...|       28|     29|            Far East|   LOC|           PAST|\n",
            "|      1|The venture was i...|        9|     12|Dutch East India ...|   ORG|           PAST|\n",
            "|      1|The venture was i...|       15|     18|British East Indi...|   ORG|           PAST|\n",
            "|      1|This made Gothenb...|        2|      2|          Gothenburg|   LOC|           PAST|\n",
            "|      1|Trade with China ...|        2|      2|               China|   LOC|           PAST|\n",
            "|      1|Trade with China ...|       11|     11|              Sweden|   LOC|           PAST|\n",
            "|      1|The Chinese cultu...|       34|     34|              Sweden|   LOC|           PAST|\n",
            "|      1|The company folde...|        4|      4|                1813|  DATE|           PAST|\n",
            "|      1|nevertheless, it ...|       11|     11|          Gothenburg|   LOC|           PAST|\n",
            "|      1|Background Sweden...|       16|     17|          East India|   LOC|           PAST|\n",
            "|      1|The royal privile...|        5|      8|Swedish East Indi...|   ORG|           PAST|\n",
            "|      1|The royal privile...|        9|      9|                SOIC| ALIAS|           PAST|\n",
            "|      1|The royal privile...|       27|     28|          East India|   LOC|           PAST|\n",
            "+-------+--------------------+---------+-------+--------------------+------+---------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ET8GD3y3-17e",
        "outputId": "5e478418-b365-4168-8de9-aab1a885d189"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- task_id: long (nullable = true)\n",
            " |-- sentence: string (nullable = true)\n",
            " |-- tkn_start: long (nullable = true)\n",
            " |-- tkn_end: long (nullable = true)\n",
            " |-- chunk: string (nullable = true)\n",
            " |-- entity: string (nullable = true)\n",
            " |-- assertion_label: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "training_data.printSchema()"
      ],
      "id": "ET8GD3y3-17e"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6xa4jp8Szs0",
        "outputId": "6e8e951c-f1c7-445d-af8c-f6e76182174f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 9.97 ms, sys: 1.23 ms, total: 11.2 ms\n",
            "Wall time: 854 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8050"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "%time training_data.count()"
      ],
      "id": "R6xa4jp8Szs0"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxcHD_Q_-_lD",
        "outputId": "1a114990-64d0-43c1-8522-ef4a9b2145fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Dataset Count: 8050\n",
            "Test Dataset Count: 802\n"
          ]
        }
      ],
      "source": [
        "(train_data, test_data) = training_data.randomSplit([0.9, 0.1], seed = 100)\n",
        "print(\"Training Dataset Count: \" + str(training_data.count()))\n",
        "print(\"Test Dataset Count: \" + str(test_data.count()))"
      ],
      "id": "fxcHD_Q_-_lD"
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFN_BuHU84HF",
        "outputId": "ea931a9b-a829-4fcc-90fd-19d7aedf982d"
      },
      "id": "DFN_BuHU84HF",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+---------+-------+--------------------+------+---------------+\n",
            "|task_id|            sentence|tkn_start|tkn_end|               chunk|entity|assertion_label|\n",
            "+-------+--------------------+---------+-------+--------------------+------+---------------+\n",
            "|      1|\"Stockholms-varve...|        6|      6|           Stockholm|   LOC|           PAST|\n",
            "|      1|\"The funny busine...|        5|      8|Swedish East Indi...|   ORG|           PAST|\n",
            "|      1|             (1998).|        0|      0|                1998|  DATE|           PAST|\n",
            "|      1|2.5 tonnes) and t...|       34|     34|              Sweden|   LOC|           PAST|\n",
            "|      1|37. Gothenburg: R...|        2|      7|Royal Society of ...|   ORG|           PAST|\n",
            "|      1|= Decline and fal...|       11|     11|                1806|  DATE|           PAST|\n",
            "|      1|= Early attempts ...|        9|     11|  Swedish East India|   ORG|           PAST|\n",
            "|      1|= Early attempts ...|       19|     19|            merchant|  ROLE|           PAST|\n",
            "|      1|= Early attempts ...|       20|     21|    Willem Usselincx|   PER|           PAST|\n",
            "|      1|= Sweden after th...|        1|      1|              Sweden|   LOC|           PAST|\n",
            "|      1|= The Royal chart...|        9|     12|Henrik K√∂nig & Co...|   ORG|           PAST|\n",
            "|      1|= The Royal chart...|       39|     42|   Cape of Good Hope|   LOC|           PAST|\n",
            "|      1|= The Royal chart...|       46|     46|               Japan|   LOC|           PAST|\n",
            "|      1|= The Royal chart...|       79|     79|          Gothenburg|   LOC|           PAST|\n",
            "|      1|= The first octro...|        8|      8|           directors|  ROLE|           PAST|\n",
            "|      1|= The first octro...|       11|     11|                SOIC|   ORG|           PAST|\n",
            "|      1|= The first octro...|       13|     14|        Henrik K√∂nig|   PER|           PAST|\n",
            "|      1|= The first octro...|       15|     16|      Colin Campbell|   PER|           PAST|\n",
            "|      1|= The first octro...|       23|     23|           Stockholm|   LOC|           PAST|\n",
            "|      1|= The fourth octr...|        6|      6|                SOIC|   ORG|           PAST|\n",
            "+-------+--------------------+---------+-------+--------------------+------+---------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WZDqlZA_kmb"
      },
      "source": [
        "# Using RoBerta Embeddings"
      ],
      "id": "2WZDqlZA_kmb"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qfJh8ap_nI2",
        "outputId": "9bd7bd23-7a37-4961-bb94-8374b0abf7d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "roberta_embeddings_legal_roberta_base download started this may take some time.\n",
            "Approximate size to download 447.2 MB\n",
            "[OK!]\n"
          ]
        }
      ],
      "source": [
        "roberta_embeddings = nlp.RoBertaEmbeddings.pretrained(\"roberta_embeddings_legal_roberta_base\",\"en\") \\\n",
        "    .setInputCols([\"document\", \"token\"]) \\\n",
        "    .setOutputCol(\"embeddings\") \\\n",
        "    .setMaxSentenceLength(512)"
      ],
      "id": "7qfJh8ap_nI2"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Fe0957BT_rcy"
      },
      "outputs": [],
      "source": [
        "document = nlp.DocumentAssembler()\\\n",
        "    .setInputCol(\"sentence\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "chunk = nlp.Doc2Chunk()\\\n",
        "    .setInputCols(\"document\")\\\n",
        "    .setOutputCol(\"doc_chunk\")\\\n",
        "    .setChunkCol(\"chunk\")\\\n",
        "    .setStartCol(\"tkn_start\")\\\n",
        "    .setStartColByTokenIndex(True)\\\n",
        "    .setFailOnMissing(False)\\\n",
        "    .setLowerCase(False)\n",
        "\n",
        "token = nlp.Tokenizer()\\\n",
        "    .setInputCols(['document'])\\\n",
        "    .setOutputCol('token')\n"
      ],
      "id": "Fe0957BT_rcy"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We save the test data in parquet format to use in `AssertionDLApproach()`. "
      ],
      "metadata": {
        "id": "LFTO0PlI9-3e"
      },
      "id": "LFTO0PlI9-3e"
    },
    {
      "cell_type": "code",
      "source": [
        "assertion_pipeline = Pipeline(\n",
        "    stages = [\n",
        "    document,\n",
        "    chunk,\n",
        "    token,\n",
        "    roberta_embeddings])\n",
        "\n",
        "assertion_test_data = assertion_pipeline.fit(test_data).transform(test_data)"
      ],
      "metadata": {
        "id": "M9u4c65G9VaC"
      },
      "id": "M9u4c65G9VaC",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assertion_test_data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-UREmtI9Vd3",
        "outputId": "31cd6903-4929-491c-83a7-09c5ef42d9dd"
      },
      "id": "r-UREmtI9Vd3",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['task_id',\n",
              " 'sentence',\n",
              " 'tkn_start',\n",
              " 'tkn_end',\n",
              " 'chunk',\n",
              " 'entity',\n",
              " 'assertion_label',\n",
              " 'document',\n",
              " 'doc_chunk',\n",
              " 'token',\n",
              " 'embeddings']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assertion_test_data.write.mode('overwrite').parquet('test_data.parquet')"
      ],
      "metadata": {
        "id": "kBaiXx78BTLT"
      },
      "id": "kBaiXx78BTLT",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assertion_train_data = assertion_pipeline.fit(training_data).transform(training_data)\n",
        "assertion_train_data.write.mode('overwrite').parquet('train_data.parquet')"
      ],
      "metadata": {
        "id": "tFhN6evk9ViI"
      },
      "id": "tFhN6evk9ViI",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assertion_train_data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtxnrvcA9VlN",
        "outputId": "dd24e11a-9ad8-470b-9610-3d9eb1dfaac5"
      },
      "id": "BtxnrvcA9VlN",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['task_id',\n",
              " 'sentence',\n",
              " 'tkn_start',\n",
              " 'tkn_end',\n",
              " 'chunk',\n",
              " 'entity',\n",
              " 'assertion_label',\n",
              " 'document',\n",
              " 'doc_chunk',\n",
              " 'token',\n",
              " 'embeddings']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTishXbut1MS"
      },
      "source": [
        "## Graph setup"
      ],
      "id": "uTishXbut1MS"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "1hTawAHemzGn"
      },
      "outputs": [],
      "source": [
        "!pip install -q tensorflow==2.7.0\n",
        "!pip install -q tensorflow-addons"
      ],
      "id": "1hTawAHemzGn"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ShZT8BBo4FY"
      },
      "source": [
        "We will use TFGraphBuilder annotator which can be used to create graphs in the model training pipeline. \n",
        "\n",
        "TFGraphBuilder inspects the data and creates the proper graph if a suitable version of TensorFlow (<= 2.7 ) is available. The graph is stored in the defined folder and loaded by the approach."
      ],
      "id": "0ShZT8BBo4FY"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "XhU0L1OXdaLN"
      },
      "outputs": [],
      "source": [
        "graph_folder= \"./tf_graphs\""
      ],
      "id": "XhU0L1OXdaLN"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "miNgoTjio0mL"
      },
      "outputs": [],
      "source": [
        "assertion_graph_builder =  legal.TFGraphBuilder()\\\n",
        "    .setModelName(\"assertion_dl\")\\\n",
        "    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
        "    .setLabelColumn(\"assertion_label\")\\\n",
        "    .setGraphFolder(graph_folder)\\\n",
        "    .setGraphFile(\"assertion_graph.pb\")\\\n",
        "    .setMaxSequenceLength(1200)\\\n",
        "    .setHiddenUnitsNumber(25)"
      ],
      "id": "miNgoTjio0mL"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6D0Ng7nMUjJa"
      },
      "source": [
        "**Setting the Scope Window (Target Area) Dynamically in Assertion Status Detection Models**\n",
        "\n",
        "\n",
        "This parameter allows you to train the Assertion Status Models to focus on specific context windows when resolving the status of a NER chunk. The window is in format `[X,Y]` being `X` the number of tokens to consider on the left of the chunk, and `Y` the max number of tokens to consider on the right. Let‚Äôs take a look at what different windows mean:\n",
        "\n",
        "\n",
        "*   By default, the window is `[-1,-1]` which means that the Assertion Status will look at all of the tokens in the sentence/document (up to a maximum of tokens set in `setMaxSentLen()` ).\n",
        "*   `[0,0]` means ‚Äúdon‚Äôt pay attention to any token except the ner_chunk‚Äù, what basically is not considering any context for the Assertion resolution.\n",
        "*   `[9,15]` is what empirically seems to be the best baseline, meaning that we look up to 9 tokens on the left and 15 on the right of the ner chunk to understand the context and resolve the status.\n",
        "\n",
        "\n",
        "Check this [Scope Window Tuning Assertion Status Detection notebook](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/2.1.Scope_window_tuning_assertion_status_detection.ipynb)  that illustrates the effect of the different windows and how to properly fine-tune your AssertionDLModels to get the best of them.\n",
        "\n",
        "In our case, the best Scope Window is around [10,10]"
      ],
      "id": "6D0Ng7nMUjJa"
    },
    {
      "cell_type": "code",
      "source": [
        "scope_window = [50, 50]\n",
        "\n",
        "assertionStatus = legal.AssertionDLApproach()\\\n",
        "    .setLabelCol(\"assertion_label\")\\\n",
        "    .setInputCols(\"document\", \"doc_chunk\", \"embeddings\")\\\n",
        "    .setOutputCol(\"assertion\")\\\n",
        "    .setBatchSize(128)\\\n",
        "    .setLearningRate(0.001)\\\n",
        "    .setEpochs(2)\\\n",
        "    .setStartCol(\"tkn_start\")\\\n",
        "    .setEndCol(\"tkn_end\")\\\n",
        "    .setMaxSentLen(1200)\\\n",
        "    .setEnableOutputLogs(True)\\\n",
        "    .setOutputLogsPath('training_logs/')\\\n",
        "    .setGraphFolder(graph_folder)\\\n",
        "    .setGraphFile(f\"{graph_folder}/assertion_graph.pb\")\\\n",
        "    .setTestDataset(path=\"test_data.parquet\", read_as='SPARK', options={'format': 'parquet'})\\\n",
        "    .setScopeWindow(scope_window)\n",
        "    #.setValidationSplit(0.2)\\    \n",
        "    #.setDropout(0.1)\\    "
      ],
      "metadata": {
        "id": "BQxGbYks91go"
      },
      "id": "BQxGbYks91go",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clinical_assertion_pipeline = Pipeline(\n",
        "    stages = [\n",
        "    #document,\n",
        "    #chunk,\n",
        "    #token,\n",
        "    #embeddings,\n",
        "    assertion_graph_builder,\n",
        "    assertionStatus])"
      ],
      "metadata": {
        "id": "T2MZLeCYATrS"
      },
      "id": "T2MZLeCYATrS",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIvnuaQP91j8",
        "outputId": "54d68047-97f2-4cc0-d8ee-b7b57948145b"
      },
      "id": "yIvnuaQP91j8",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- task_id: long (nullable = true)\n",
            " |-- sentence: string (nullable = true)\n",
            " |-- tkn_start: long (nullable = true)\n",
            " |-- tkn_end: long (nullable = true)\n",
            " |-- chunk: string (nullable = true)\n",
            " |-- entity: string (nullable = true)\n",
            " |-- assertion_label: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assertion_train_data = spark.read.parquet('train_data.parquet')"
      ],
      "metadata": {
        "id": "ueJz0aiJ_7l4"
      },
      "id": "ueJz0aiJ_7l4",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "assertion_model = clinical_assertion_pipeline.fit(assertion_train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1NCZ89T_7ol",
        "outputId": "5a2a676d-0b61-4c59-c7db-6f2bc475c334"
      },
      "id": "j1NCZ89T_7ol",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF Graph Builder configuration:\n",
            "Model name: assertion_dl\n",
            "Graph folder: ./tf_graphs\n",
            "Graph file name: assertion_graph.pb\n",
            "Build params: {'n_classes': 4, 'feat_size': 768, 'max_seq_len': 1200, 'n_hidden': 25}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/sparknlp_jsl/_tf_graph_builders/tf2contrib/rnn.py:239: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/rnn.py:450: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py:766: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "\n",
            "assertion_dl graph exported to ./tf_graphs/assertion_graph.pb\n",
            "CPU times: user 13.8 s, sys: 2.32 s, total: 16.1 s\n",
            "Wall time: 17min 58s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30SmcTiSpnWa"
      },
      "source": [
        "Checking the results saved in the log file"
      ],
      "id": "30SmcTiSpnWa"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOiu1vuspKut",
        "outputId": "f62ec0f2-c361-4ecb-e094-bf659e956e17"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AssertionDLApproach_6026f20884ae.log']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "log_files = os.listdir(\"./training_logs\")\n",
        "log_files"
      ],
      "id": "kOiu1vuspKut"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcQV0-fIrJHz",
        "outputId": "4239e398-1b0e-405a-cdd3-a608ea7687ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name of the selected graph: ./tf_graphs/assertion_graph.pb\n",
            "Training started, trainExamples: 8050\n",
            "\n",
            "\n",
            "Epoch: 0 started, learning rate: 0.001, dataset size: 8050\n",
            "Done, 479.809131515 total training loss: 62.679592, avg training loss: 0.9949142, batches: 63\n",
            "Quality on test dataset: \n",
            "time to finish evaluation: 41.41s\n",
            "Total test loss: 2.4015\tAvg test loss: 0.3431\n",
            "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
            "PRESENT\t 216\t 26\t 25\t 0.892562\t 0.89626557\t 0.8944099\n",
            "POSSIBLE\t 158\t 6\t 30\t 0.9634146\t 0.84042555\t 0.89772725\n",
            "FUTURE\t 95\t 12\t 25\t 0.88785046\t 0.7916667\t 0.8370044\n",
            "PAST\t 240\t 49\t 13\t 0.8304498\t 0.9486166\t 0.88560885\n",
            "tp: 709 fp: 93 fn: 93 labels: 4\n",
            "Macro-average\t prec: 0.89356923, rec: 0.8692436, f1: 0.8812386\n",
            "Micro-average\t prec: 0.8840399, rec: 0.8840399, f1: 0.8840399\n",
            "\n",
            "\n",
            "Epoch: 1 started, learning rate: 9.5E-4, dataset size: 8050\n",
            "Done, 475.062305214 total training loss: 18.358475, avg training loss: 0.29140437, batches: 63\n",
            "Quality on test dataset: \n",
            "time to finish evaluation: 41.80s\n",
            "Total test loss: 1.3833\tAvg test loss: 0.1976\n",
            "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
            "PRESENT\t 207\t 6\t 34\t 0.97183096\t 0.8589212\t 0.9118943\n",
            "POSSIBLE\t 170\t 2\t 18\t 0.9883721\t 0.90425533\t 0.9444444\n",
            "FUTURE\t 117\t 13\t 3\t 0.9\t 0.975\t 0.936\n",
            "PAST\t 249\t 38\t 4\t 0.8675958\t 0.98418975\t 0.9222222\n",
            "tp: 743 fp: 59 fn: 59 labels: 4\n",
            "Macro-average\t prec: 0.93194973, rec: 0.9305915, f1: 0.9312701\n",
            "Micro-average\t prec: 0.9264339, rec: 0.9264339, f1: 0.9264339\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "with open(\"./training_logs/\"+log_files[0]) as log_file:\n",
        "    print(log_file.read())"
      ],
      "id": "CcQV0-fIrJHz"
    },
    {
      "cell_type": "code",
      "source": [
        "assertion_test_data = spark.read.parquet('test_data.parquet')"
      ],
      "metadata": {
        "id": "bgcG00nT91nn"
      },
      "id": "bgcG00nT91nn",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-k2WrFkRyQyP",
        "outputId": "de6214ba-b53d-4eb5-a3da-53410f470169"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+---------+\n",
            "|assertion_label|   result|\n",
            "+---------------+---------+\n",
            "|           PAST|   [PAST]|\n",
            "|           PAST|   [PAST]|\n",
            "|           PAST|   [PAST]|\n",
            "|        PRESENT|[PRESENT]|\n",
            "|           PAST|   [PAST]|\n",
            "|        PRESENT|[PRESENT]|\n",
            "|           PAST|   [PAST]|\n",
            "|           PAST|   [PAST]|\n",
            "|           PAST|   [PAST]|\n",
            "|           PAST|   [PAST]|\n",
            "|           PAST|   [PAST]|\n",
            "|           PAST|   [PAST]|\n",
            "|           PAST|   [PAST]|\n",
            "|           PAST|   [PAST]|\n",
            "|           PAST| [FUTURE]|\n",
            "|        PRESENT|   [PAST]|\n",
            "|        PRESENT|   [PAST]|\n",
            "|        PRESENT|[PRESENT]|\n",
            "|           PAST|   [PAST]|\n",
            "|           PAST|   [PAST]|\n",
            "+---------------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "preds = assertion_model.transform(assertion_test_data).select('assertion_label','assertion.result')\n",
        "\n",
        "preds.show()"
      ],
      "id": "-k2WrFkRyQyP"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "4yI73lwG2xk5"
      },
      "outputs": [],
      "source": [
        "preds_df = preds.toPandas()"
      ],
      "id": "4yI73lwG2xk5"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "yRXZFGlQ3Z2U",
        "outputId": "103b1d38-b06e-4282-b878-5d1d64127b91"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    assertion_label   result\n",
              "0              PAST     PAST\n",
              "1              PAST     PAST\n",
              "2              PAST     PAST\n",
              "3           PRESENT  PRESENT\n",
              "4              PAST     PAST\n",
              "..              ...      ...\n",
              "797         PRESENT  PRESENT\n",
              "798         PRESENT  PRESENT\n",
              "799         PRESENT  PRESENT\n",
              "800         PRESENT  PRESENT\n",
              "801         PRESENT  PRESENT\n",
              "\n",
              "[799 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-69118cbd-dd5a-4aea-af1b-0b2219ede756\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>assertion_label</th>\n",
              "      <th>result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PAST</td>\n",
              "      <td>PAST</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PAST</td>\n",
              "      <td>PAST</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PAST</td>\n",
              "      <td>PAST</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PRESENT</td>\n",
              "      <td>PRESENT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PAST</td>\n",
              "      <td>PAST</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>797</th>\n",
              "      <td>PRESENT</td>\n",
              "      <td>PRESENT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>798</th>\n",
              "      <td>PRESENT</td>\n",
              "      <td>PRESENT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799</th>\n",
              "      <td>PRESENT</td>\n",
              "      <td>PRESENT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>800</th>\n",
              "      <td>PRESENT</td>\n",
              "      <td>PRESENT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>801</th>\n",
              "      <td>PRESENT</td>\n",
              "      <td>PRESENT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>799 rows √ó 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-69118cbd-dd5a-4aea-af1b-0b2219ede756')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-69118cbd-dd5a-4aea-af1b-0b2219ede756 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-69118cbd-dd5a-4aea-af1b-0b2219ede756');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "preds_df[\"result\"] = preds_df[\"result\"].apply(lambda x: x[0] if len(x) else pd.NA)\n",
        "preds_df.dropna(inplace=True)\n",
        "\n",
        "preds_df"
      ],
      "id": "yRXZFGlQ3Z2U"
    },
    {
      "cell_type": "code",
      "source": [
        "# We are going to use sklearn to evalute the results on test dataset\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print (classification_report( preds_df['assertion_label'], preds_df['result']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hb1kyGAE0Gn",
        "outputId": "468f0f48-2a58-494e-c827-8df5bb141c7a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      FUTURE       0.90      0.97      0.94       120\n",
            "        PAST       0.87      0.98      0.92       250\n",
            "    POSSIBLE       0.99      0.90      0.94       188\n",
            "     PRESENT       0.97      0.86      0.91       241\n",
            "\n",
            "    accuracy                           0.93       799\n",
            "   macro avg       0.93      0.93      0.93       799\n",
            "weighted avg       0.93      0.93      0.93       799\n",
            "\n"
          ]
        }
      ],
      "id": "1hb1kyGAE0Gn"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuJ5YZ9sXU13"
      },
      "source": [
        "### Saving the trained model"
      ],
      "id": "WuJ5YZ9sXU13"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "KBcoOwvwXV8p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85a27749-4cdc-498b-ffa1-02aa99a47912"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[TFGraphBuilderModel_bf68c0049344, FINANCE-ASSERTION_DL_70bbc388fb95]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "assertion_model.stages"
      ],
      "id": "KBcoOwvwXV8p"
    },
    {
      "cell_type": "code",
      "source": [
        "# Save a Spark NLP model\n",
        "assertion_model.stages[-1].write().overwrite().save('Assertion')\n",
        "\n",
        "# cd into saved dir and zip\n",
        "! cd /content/Assertion ; zip -r /content/Assertion.zip *"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioMW1jSrA-wg",
        "outputId": "329f2545-0041-494f-8719-c641cb5b4c5e"
      },
      "id": "ioMW1jSrA-wg",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: fields/ (stored 0%)\n",
            "  adding: fields/datasetParams/ (stored 0%)\n",
            "  adding: fields/datasetParams/.part-00003.crc (deflated 45%)\n",
            "  adding: fields/datasetParams/.part-00002.crc (stored 0%)\n",
            "  adding: fields/datasetParams/part-00000 (deflated 26%)\n",
            "  adding: fields/datasetParams/.part-00000.crc (stored 0%)\n",
            "  adding: fields/datasetParams/part-00002 (deflated 26%)\n",
            "  adding: fields/datasetParams/._SUCCESS.crc (stored 0%)\n",
            "  adding: fields/datasetParams/part-00003 (deflated 95%)\n",
            "  adding: fields/datasetParams/part-00001 (deflated 27%)\n",
            "  adding: fields/datasetParams/.part-00001.crc (stored 0%)\n",
            "  adding: fields/datasetParams/_SUCCESS (stored 0%)\n",
            "  adding: metadata/ (stored 0%)\n",
            "  adding: metadata/part-00000 (deflated 38%)\n",
            "  adding: metadata/.part-00000.crc (stored 0%)\n",
            "  adding: metadata/._SUCCESS.crc (stored 0%)\n",
            "  adding: metadata/_SUCCESS (stored 0%)\n",
            "  adding: tensorflow (deflated 40%)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "finleg_jar",
      "language": "python",
      "name": "finleg_jar"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}