{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
      ],
      "metadata": {
        "id": "S6jlakvDCElY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUdOMUOQYJNe"
      },
      "source": [
        "# Classify Financial Texts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "focTiQUhYJNg"
      },
      "source": [
        "In this notebook, you will learn how to use Spark NLP and Finance NLP to perform text classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNS9C_-2YJNi"
      },
      "source": [
        "## Environment Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3dj43KRYJNi"
      },
      "source": [
        "First, you need to setup the environment to be able to use the licensed package. If you are not running in Google Colab, please check the documentation [here](https://nlp.johnsnowlabs.com/docs/en/licensed_install)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IsqHKhxrYJNj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3924732-6fdb-4fca-a8e3-bddfde1f99ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/74.2 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m74.2/74.2 KB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m570.6/570.6 KB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m95.4/95.4 KB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m212.4/212.4 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m448.4/448.4 KB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m198.6/198.6 KB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m66.9/66.9 KB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m82.3/82.3 KB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Install the johnsnowlabs library to access Spark-OCR and Spark-NLP for Healthcare, Finance, and Legal.\n",
        "! pip install -qU johnsnowlabs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "a41DyL61YJNk",
        "outputId": "72741449-6d62-4193-b4a7-609c69154fa4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        var a = document.createElement(\"a\");\n",
              "        a.id=\"auth-btn\"\n",
              "        a.setAttribute(\"target\", \"_blank\");\n",
              "        a.href=\"https://my.johnsnowlabs.com/oauth/authorize/?client_id=sI4MKSmLHOX2Pg7XhM3McJS2oyKG5PHcp0BlANEW&response_type=code&code_challenge_method=S256&code_challenge=epj3N66y99BqAimWmfJ64mD5XU8T2Jh80PeTqL7INpk&redirect_uri=https%3A%2F%2F5x4hk2sh4gv-496ff2e9c6d22116-8000-colab.googleusercontent.com%2Flogin\";\n",
              "        a.style=\"padding:15px 20px;background-color:#0298d9;border-radius:7px;color:white;text-decoration:none;\"\n",
              "        a.innerText=\"Click here to Authorize on My.Johnsnowlabs.com\"\n",
              "        document.body.appendChild(a);\n",
              "        document.body.style = \"text-align:center;padding-top:15px;\"\n",
              "        a.click()\n",
              "      "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127.0.0.1 - - [08/Jan/2023 05:03:19] \"GET /login?code=eusKtNI7QgPqwXL0YNLZ2RX1Tbp6y4 HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "document.body.removeChild(a);"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading license...\n",
            "Licenses extracted successfully\n",
            "üìã Stored John Snow Labs License in /root/.johnsnowlabs/licenses/license_number_0_for_Spark-Healthcare_Spark-OCR.json\n",
            "üë∑ Setting up  John Snow Labs home in /root/.johnsnowlabs, this might take a few minutes.\n",
            "Downloading üêç+üöÄ Python Library spark_nlp-4.2.4-py2.py3-none-any.whl\n",
            "Downloading üêç+üíä Python Library spark_nlp_jsl-4.2.4-py3-none-any.whl\n",
            "Downloading ü´ò+üöÄ Java Library spark-nlp-assembly-4.2.4.jar\n",
            "Downloading ü´ò+üíä Java Library spark-nlp-jsl-4.2.4.jar\n",
            "üôÜ JSL Home setup in /root/.johnsnowlabs\n",
            "Installing /root/.johnsnowlabs/py_installs/spark_nlp_jsl-4.2.4-py3-none-any.whl to /usr/bin/python3\n",
            "Running: /usr/bin/python3 -m pip install /root/.johnsnowlabs/py_installs/spark_nlp_jsl-4.2.4-py3-none-any.whl\n",
            "Installed 1 products:\n",
            "üíä Spark-Healthcare==4.2.4 installed! ‚úÖ Heal the planet with NLP! \n"
          ]
        }
      ],
      "source": [
        "from johnsnowlabs import nlp\n",
        "# Log in to your John Snow Labs account to login and get your license keys\n",
        "nlp.install(force_browser=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also, let's install some tools to display PDF files that will be used on examples."
      ],
      "metadata": {
        "id": "pTWVIzg61ycN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lS6Z-_E1YJNk"
      },
      "source": [
        "> Please restart the runtime and follow to the next cells"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fxm3OQn9YJNh"
      },
      "source": [
        "## Pretrained models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzDnEztPYJNh"
      },
      "source": [
        "For the text classification tasks, we will use two annotators:\n",
        "\n",
        "- `ClassifierDL`: uses the state-of-the-art Universal Sentence Encoder as an input for text classifications. Then, a deep learning model (DNNs) built with TensorFlow that supports `Binary Classification` and `Multiclass Classification` (up to 100 classes).\n",
        "- `MultiClassifierDL`: `Multilabel Classification` (can predict more than one class for each text) using a Bidirectional GRU with Convolution architecture built with TensorFlow that supports up to 100 classes. The inputs are Sentence Embeddings such as state-of-the-art UniversalSentenceEncoder, BertSentenceEmbeddings or SentenceEmbeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example Classification models:\n",
        "\n",
        "| title                                                    | language   | predicted_entities                                                                                                      | compatible_editions                |\n",
        "|:---------------------------------------------------------|:-----------|:------------------------------------------------------------------------------------------------------------------------|:-----------------------------------|\n",
        "| Bank Complaints Classification                           | en         | ['Accounts', 'Credit Cards', 'Credit Reporting', 'Debt Collection', 'Loans', 'Money Transfer and Currency', 'Mortgage'] | ['Finance NLP 1.0', 'Finance NLP'] |\n",
        "| Financial Finbert Sentiment Analysis (DistilRoBerta)     | en         | ['positive', 'negative', 'neutral']                                                                                     | ['Finance NLP 1.0', 'Finance NLP'] |\n",
        "| Financial Business Item Binary Classifier                | en         | ['other', 'business']                                                                                                   | ['Finance NLP 1.0', 'Finance NLP'] |\n",
        "| Financial Controls procedures Item Binary Classifier     | en         | ['other', 'controls_procedures']                                                                                        | ['Finance NLP 1.0', 'Finance NLP'] |\n",
        "| Financial Equity Item Binary Classifier                  | en         | ['other', 'equity']                                                                                                     | ['Finance NLP 1.0', 'Finance NLP'] |\n",
        "| Financial Executives compensation Item Binary Classifier | en         | ['other', 'executives_compensation']                                                                                    | ['Finance NLP 1.0', 'Finance NLP'] |\n",
        "| Financial Executives Item Binary Classifier              | en         | ['other', 'executives']                                                                                                 | ['Finance NLP 1.0', 'Finance NLP'] |\n",
        "| Financial Exhibits Item Binary Classifier                | en         | ['other', 'exhibits']                                                                                                   | ['Finance NLP 1.0', 'Finance NLP'] |\n",
        "| Financial Financial conditions Item Binary Classifier    | en         | ['other', 'financial_conditions']                                                                                       | ['Finance NLP 1.0', 'Finance NLP'] |\n",
        "| Financial Financial statements Item Binary Classifier    | en         | ['other', 'financial_statements']                                                                                       | ['Finance NLP 1.0', 'Finance NLP'] |"
      ],
      "metadata": {
        "id": "t6gvJ4RU5hw0"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvvv93e2YJNl"
      },
      "source": [
        "## Multiclass Classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multiclass classifiers predicts one class out of a predefined set of possible classes. \n",
        "\n",
        "Before using the model, let's first start the Spark Session, which can be done using our library: "
      ],
      "metadata": {
        "id": "rt-7A1iPj2XS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "id": "2Gt-mN6WYJNm",
        "outputId": "43a122cf-a9c3-481e-a150-05e5c92fd7dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üëå Launched \u001b[92mcpu optimized\u001b[39m session with with: üöÄSpark-NLP==4.2.4, üíäSpark-Healthcare==4.2.4, running on ‚ö° PySpark==3.1.2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f8ef4475be0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://fd5ad33e3e7f:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>John-Snow-Labs-Spark-Session üöÄ with Jars for: üöÄSpark-NLP==4.2.4, üíäSpark-Healthcare==4.2.4, running on ‚ö° PySpark==3.1.2</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import pyspark.sql.functions as F\n",
        "from johnsnowlabs import nlp, finance, viz\n",
        "# Automatically load license data and start a session with all jars user has access to\n",
        "spark = nlp.start()\n",
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Environmental, Social and Governance (ESG)"
      ],
      "metadata": {
        "id": "kBsPTv_6OQdN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use two classifiers, one with 26 classes:\n",
        "\n",
        "`Business_Ethics`, `Data_Security`, `Access_And_Affordability`, `Business_Model_Resilience`, `Competitive_Behavior`, `Critical_Incident_Risk_Management`, `Customer_Welfare`, `Director_Removal`, `Employee_Engagement_Inclusion_And_Diversity`, `Employee_Health_And_Safety`, `Human_Rights_And_Community_Relations`, `Labor_Practices`, `Management_Of_Legal_And_Regulatory_Framework`, `Physical_Impacts_Of_Climate_Change`, `Product_Quality_And_Safety`, `Product_Design_And_Lifecycle_Management`, `Selling_Practices_And_Product_Labeling`, `Supply_Chain_Management`, `Systemic_Risk_Management`, `Waste_And_Hazardous_Materials_Management`, `Water_And_Wastewater_Management`, `Air_Quality`, `Customer_Privacy`, `Ecological_Impacts`, `Energy_Management`, `GHG_Emissions`\n",
        "\n",
        "\n",
        "and one with only three: `Social`, `Governance`, `Environmental` (or `None`)"
      ],
      "metadata": {
        "id": "hOZ-CVOLYgm4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VCZa88JZYJNm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98bfeb52-6fdc-46dc-f0c6-f64d73599e11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finclf_augmented_esg download started this may take some time.\n",
            "[OK!]\n",
            "finclf_esg download started this may take some time.\n",
            "[OK!]\n",
            "+--------------------------------------------------------------------------------+------------------------------------------+---------------+\n",
            "|                                                                            text|                                      many|            esg|\n",
            "+--------------------------------------------------------------------------------+------------------------------------------+---------------+\n",
            "|The Canadian Environmental Assessment Agency (CEAA) concluded that in June 20...|[Waste_And_Hazardous_Materials_Management]|[Environmental]|\n",
            "+--------------------------------------------------------------------------------+------------------------------------------+---------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "document_assembler = (\n",
        "    nlp.DocumentAssembler().setInputCol(\"text\").setOutputCol(\"document\")\n",
        ")\n",
        "\n",
        "tokenizer = nlp.Tokenizer().setInputCols([\"document\"]).setOutputCol(\"token\")\n",
        "\n",
        "many_classes = (\n",
        "    finance.BertForSequenceClassification.pretrained(\n",
        "        \"finclf_augmented_esg\", \"en\", \"finance/models\"\n",
        "    )\n",
        "    .setInputCols([\"document\", \"token\"])\n",
        "    .setOutputCol(\"esg_many\")\n",
        ")\n",
        "\n",
        "three_classes = (\n",
        "    finance.BertForSequenceClassification.pretrained(\n",
        "        \"finclf_esg\", \"en\", \"finance/models\"\n",
        "    )\n",
        "    .setInputCols([\"document\", \"token\"])\n",
        "    .setOutputCol(\"esg\")\n",
        ")\n",
        "\n",
        "pipeline = nlp.Pipeline(\n",
        "    stages=[document_assembler, tokenizer, many_classes, three_classes]\n",
        ")\n",
        "\n",
        "# couple of simple examples\n",
        "example = spark.createDataFrame(\n",
        "    [\n",
        "        [\n",
        "            \"\"\"The Canadian Environmental Assessment Agency (CEAA) concluded that in June 2016 the company had not made an effort\n",
        " to protect public drinking water and was ignoring concerns raised by its own scientists about the potential levels of pollutants in the local water supply.\n",
        "  At the time, there were concerns that the company was not fully testing onsite wells for contaminants and did not use the proper methods for testing because \n",
        "  of its test kits now manufactured in China.A preliminary report by the company in June 2016 was commissioned by the Alberta government to provide recommendations \n",
        "  to Alberta Environment officials\"\"\"\n",
        "        ]\n",
        "    ]\n",
        ").toDF(\"text\")\n",
        "\n",
        "result = pipeline.fit(example).transform(example)\n",
        "\n",
        "# result is a DataFrame\n",
        "result.select(\n",
        "    \"text\", F.expr(\"esg_many.result as many\"), F.expr(\"esg.result as esg\")\n",
        ").show(truncate=80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-u4sgWg-YJNn"
      },
      "source": [
        "### Financial News Multilabel Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model can identify different topics contained in financial news (trained on news scrapped from the Internet and manual in-house annotations). The available topics are:\n",
        "\n",
        "- `acq`: Acquisition / Purchase operations\n",
        "- `finance`: Generic financial news\n",
        "- `fuel`: News about fuel and energy sources\n",
        "- `jobs`: News about jobs, employment rates, etc.\n",
        "- `livestock`: News about animales and livestock\n",
        "- `mineral`: News about mineral as copper, gold, silver, coal, etc.\n",
        "- `plant`: News about greens, plants, cereals, etc\n",
        "- `trade`: Trading news"
      ],
      "metadata": {
        "id": "UUl0CVse3Tba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documentAssembler = (\n",
        "    nlp.DocumentAssembler()\n",
        "    .setInputCol(\"text\")\n",
        "    .setOutputCol(\"document\")\n",
        "    .setCleanupMode(\"shrink\")\n",
        ")\n",
        "\n",
        "embeddings = (\n",
        "    nlp.UniversalSentenceEncoder.pretrained()\n",
        "    .setInputCols(\"document\")\n",
        "    .setOutputCol(\"embeddings\")\n",
        ")\n",
        "\n",
        "docClassifier = (\n",
        "    nlp.MultiClassifierDLModel.pretrained(\"finmulticlf_news\", \"en\", \"finance/models\")\n",
        "    .setInputCols(\"embeddings\")\n",
        "    .setOutputCol(\"topics\")\n",
        ")\n",
        "\n",
        "pipeline = nlp.Pipeline().setStages([documentAssembler, embeddings, docClassifier])\n",
        "\n",
        "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
        "pipelineModel = pipeline.fit(empty_data)"
      ],
      "metadata": {
        "id": "6J4r4WRCau5s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48d90dd7-b579-44b8-f7ee-0ddd4d7564bc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tfhub_use download started this may take some time.\n",
            "Approximate size to download 923.7 MB\n",
            "[OK!]\n",
            "finmulticlf_news download started this may take some time.\n",
            "Approximate size to download 12.3 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = [\"\"\"\n",
        "ECUADOR HAS TRADE SURPLUS IN FIRST FOUR MONTHS Ecuador posted a trade surplus of 10.6 mln dlrs in the first four months of 1987 compared with a surplus of 271.7 mln in the same period in 1986, the central bank of Ecuador said in its latest monthly report. Ecuador suspended sales of crude oil, its principal export product, in March after an earthquake destroyed part of its oil-producing infrastructure. Exports in the first four months of 1987 were around 639 mln dlrs and imports 628.3 mln, compared with 771 mln and 500 mln respectively in the same period last year. Exports of crude and products in the first four months were around 256.1 mln dlrs, compared with 403.3 mln in the same period in 1986. The central bank said that between January and May Ecuador sold 16.1 mln barrels of crude and 2.3 mln barrels of products, compared with 32 mln and 2.7 mln respectively in the same period last year. Ecuador's international reserves at the end of May were around 120.9 mln dlrs, compared with 118.6 mln at the end of April and 141.3 mln at the end of May 1986, the central bank said. gold reserves were 165.7 mln dlrs at the end of May compared with 124.3 mln at the end of April.\n",
        "\"\"\"]\n",
        "\n",
        "df = spark.createDataFrame([text]).toDF(\"text\")\n",
        "\n",
        "result = pipelineModel.transform(df)\n",
        "result.select(\"text\", \"topics.result\").show(truncate=60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOa6ba8yN8je",
        "outputId": "f918b8f9-e060-4301-964d-cd9201c0e12d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------------------------------+----------------+\n",
            "|                                                        text|          result|\n",
            "+------------------------------------------------------------+----------------+\n",
            "|\n",
            "ECUADOR HAS TRADE SURPLUS IN FIRST FOUR MONTHS Ecuador p...|[finance, trade]|\n",
            "+------------------------------------------------------------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finding relevant sections of 10-K fillings  "
      ],
      "metadata": {
        "id": "wznFFR8CSLB5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use a publicly available information about Cadence in SEC's Edgar database [here](https://www.sec.gov/Archives/edgar/data/813672/000081367222000012/cdns-20220101.htm) and [Wikipedia](https://en.wikipedia.org/wiki/Cadence_Design_Systems) for to illustrate some of our binary classifiers."
      ],
      "metadata": {
        "id": "xo9iT-7LVKDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings_JSL/Finance/data/cdns-20220101.html.txt -O sample10k.txt"
      ],
      "metadata": {
        "id": "tlEkssWFTTPK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = open(\"sample10k.txt\", \"r\").read()\n",
        "print(text[:200])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QaaANmETZ2Z",
        "outputId": "151843e2-1cc2-4ec5-e543-3a71b37d6c92"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Table of Contents\n",
            "UNITED STATES SECURITIES AND EXCHANGE COMMISSION\n",
            "Washington, D.C. 20549\n",
            "_____________________________________ \n",
            "FORM 10-K \n",
            "_____________________________________  \n",
            "(Mark One)\n",
            "‚òí\n",
            "ANNUAL \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, lets split this big text into pages (we identified that every page starts with the string \"Table of Contents\" and use that to split)."
      ],
      "metadata": {
        "id": "EuJBm8zYVe0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document_assembler = (\n",
        "    nlp.DocumentAssembler().setInputCol(\"text\").setOutputCol(\"document\")\n",
        ")\n",
        "\n",
        "sentence_detector = (\n",
        "    nlp.SentenceDetector()\n",
        "    .setInputCols([\"document\"])\n",
        "    .setOutputCol(\"pages\")\n",
        "    .setCustomBounds([\"Table of Contents\"])\n",
        "    .setUseCustomBoundsOnly(True)\n",
        ")\n",
        "\n",
        "nlp_pipeline = nlp.Pipeline(stages=[document_assembler, sentence_detector])\n",
        "\n",
        "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
        "sentence_splitting_pipe = nlp_pipeline.fit(empty_data)\n",
        "sentence_splitting_lightpipe = nlp.LightPipeline(sentence_splitting_pipe)"
      ],
      "metadata": {
        "id": "wQQCVhaqVpRL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = sentence_splitting_lightpipe.annotate(text)\n",
        "pages = res['pages']\n",
        "pages = [p for p in pages if p.strip() != ''] # We remove empty pages\n",
        "len(pages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYEwIsqKVzG1",
        "outputId": "63a36b7e-eb44-473e-d9b7-6a2618da4889"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "90"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pages[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVjLwikeV60w",
        "outputId": "d5326ac3-15b9-4cff-e8f0-d3419f1903d5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UNITED STATES SECURITIES AND EXCHANGE COMMISSION\n",
            "Washington, D.C. 20549\n",
            "_____________________________________ \n",
            "FORM 10-K \n",
            "_____________________________________  \n",
            "(Mark One)\n",
            "‚òí\n",
            "ANNUAL REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\n",
            "For the fiscal year ended January 1, 2022 \n",
            "OR\n",
            "‚òê\n",
            "TRANSITION REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\n",
            "For the transition period from _________ to_________.\n",
            "\n",
            "Commission file number 000-15867 \n",
            "_____________________________________\n",
            " \n",
            "CADENCE DESIGN SYSTEMS, INC. \n",
            "(Exact name of registrant as specified in its charter)\n",
            "____________________________________ \n",
            "Delaware\n",
            " \n",
            "00-0000000\n",
            "(State or Other Jurisdiction ofIncorporation or Organization)\n",
            " \n",
            "(I.R.S. EmployerIdentification No.)\n",
            "2655 Seely Avenue, Building 5,\n",
            "San Jose,\n",
            "California\n",
            " \n",
            "95134\n",
            "(Address of Principal Executive Offices)\n",
            " \n",
            "(Zip Code)\n",
            "(408)\n",
            "-943-1234 \n",
            "(Registrant‚Äôs Telephone Number, including Area Code) \n",
            "Securities registered pursuant to Section 12(b) of the Act:\n",
            "Title of Each Class\n",
            "Trading Symbol(s)\n",
            "Names of Each Exchange on which Registered\n",
            "Common Stock, $0.01 par value per share\n",
            "CDNS\n",
            "Nasdaq Global Select Market\n",
            "Securities registered pursuant to Section 12(g) of the Act:\n",
            "None\n",
            "Indicate by check mark if the registrant is a well-known seasoned issuer, as defined in Rule 405 of the Securities Act.  \n",
            " Yes  \n",
            "‚òí\n",
            "    No  \n",
            "‚òê\n",
            "Indicate by check mark if the registrant is not required to file reports pursuant to Section 13 or Section 15(d) of the Act.  \n",
            " Yes \n",
            "‚òê    \n",
            "No  \n",
            "‚òí\n",
            "Indicate by check mark whether the registrant (1) has filed all reports required to be filed by Section 13 or 15(d) of the Securities Exchange Act of 1934 during the preceding 12 months (or for such shorter period that the registrant was required to file such reports), and (2) has been subject to such filing requirements for the past 90 days.  \n",
            " Yes  \n",
            "‚òí\n",
            "    No  \n",
            "‚òê\n",
            "Indicate by check mark whether the registrant has submitted electronically every Interactive Data File required to be submitted pursuant to Rule 405 of Regulation S-T (¬ß 232.405 of this chapter) during the preceding 12 months (or for such shorter period that the registrant was required to submit such files). \n",
            " Yes  \n",
            "‚òí\n",
            "    No  \n",
            "‚òê\n",
            "Indicate by check mark whether the registrant is a large accelerated filer, an accelerated filer, a non-accelerated filer, a smaller reporting company, or an emerging growth company. See the definitions of ‚Äúlarge accelerated filer,‚Äù ‚Äúaccelerated filer,‚Äù ‚Äúsmaller reporting company,‚Äù and ‚Äúemerging growth company‚Äù in Rule 12b-2 of the Exchange Act.\n",
            "Large Accelerated Filer\n",
            "‚òí\n",
            "Accelerated Filer\n",
            "‚òê\n",
            "Non-accelerated Filer\n",
            "‚òê\n",
            "Smaller Reporting Company\n",
            "‚òê\n",
            "Emerging Growth Company\n",
            "‚òê\n",
            "If an emerging growth company, indicate by check mark if the registrant has elected not to use the extended transition period for complying with any new or revised financial accounting standards provided pursuant to Section 13(a) of the Exchange Act.  \n",
            "‚òê\n",
            "Indicate by check mark whether the registrant has filed a report on and attestation to its management‚Äôs assessment of the effectiveness of its internal control over financial reporting under Section 404(b) of the Sarbanes-Oxley Act (15 U.S.C. 7262(b)) by the registered public accounting firm that prepared or issued its audit report. \n",
            "‚òí\n",
            "Indicate by check mark whether the registrant is a shell company (as defined in Rule 12b-2 of the Act). \n",
            " Yes \n",
            "‚òê \n",
            "No  \n",
            "‚òí\n",
            "The aggregate market value of the voting and non-voting common equity held by non-affiliates computed by reference to the price at which the common equity was last sold as of the last business day of the registrant‚Äôs most recently completed second fiscal quarter ended July 3, 2021 was approximately $38,179,000,000.\n",
            "On February 5, 2022, approximately 277,336,000 shares of the Registrant‚Äôs Common Stock, $0.01 par value, were outstanding.\n",
            "DOCUMENTS INCORPORATED BY REFERENCE\n",
            "Portions of the definitive proxy statement for Cadence Design Systems, Inc.‚Äôs 2022 Annual Meeting of Stockholders are incorporated by reference into Part III hereof.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings_JSL/Finance/data/10k_image.png?raw=true\"/>"
      ],
      "metadata": {
        "id": "dtm5aLGgWDHF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a funtion that generates pipelines with the desird model, so we can use different binary classifiers with ease."
      ],
      "metadata": {
        "id": "XnLUIiIyWoc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_binary_pipeline(model_name):\n",
        "    documentAssembler = (\n",
        "        nlp.DocumentAssembler().setInputCol(\"text\").setOutputCol(\"document\")\n",
        "    )\n",
        "\n",
        "    useEmbeddings = (\n",
        "        nlp.UniversalSentenceEncoder.pretrained()\n",
        "        .setInputCols(\"document\")\n",
        "        .setOutputCol(\"sentence_embeddings\")\n",
        "    )\n",
        "\n",
        "    docClassifier = (\n",
        "        nlp.ClassifierDLModel.pretrained(model_name, \"en\", \"finance/models\")\n",
        "        .setInputCols([\"sentence_embeddings\"])\n",
        "        .setOutputCol(\"category\")\n",
        "    )\n",
        "\n",
        "    nlpPipeline = nlp.Pipeline(stages=[documentAssembler, useEmbeddings, docClassifier])\n",
        "\n",
        "    return nlpPipeline"
      ],
      "metadata": {
        "id": "nD0szSjlWuj9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finding Summary part"
      ],
      "metadata": {
        "id": "xm8TJ9wKWH4D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary page is usually the first page of the report, but let's suppose we don't know that. This binary classifier will predict `summary` if the page is the summary page or `other` otherwise."
      ],
      "metadata": {
        "id": "xk_qXoRbWKpp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cls_pipeline = get_binary_pipeline(\"finclf_form_10k_summary_item\")\n",
        "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
        "\n",
        "cls_model = cls_pipeline.fit(empty_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNeWAcsFWCnH",
        "outputId": "d1cde201-74b8-4493-dc0c-8dfc4427b2ae"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tfhub_use download started this may take some time.\n",
            "Approximate size to download 923.7 MB\n",
            "[OK!]\n",
            "finclf_form_10k_summary_item download started this may take some time.\n",
            "Approximate size to download 21.2 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.createDataFrame([[pages[0]]]).toDF(\"text\")\n",
        "result = cls_model.transform(df)\n",
        "result.select('category.result').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZ25QzEFXPJV",
        "outputId": "6d4bbcff-314c-4deb-d462-443e6077aca1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+\n",
            "|            result|\n",
            "+------------------+\n",
            "|[form_10k_summary]|\n",
            "+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finding Acquisitions and Subsidiaries part"
      ],
      "metadata": {
        "id": "EoQe_gZom2k8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's send some pages and check which one(s) contain that information. In a real case, you could send all the pages to the model, but here for time saving purposes, we will show just a subset."
      ],
      "metadata": {
        "id": "3GwLJlYZm-Gp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "candidates = [[pages[0]], [pages[1]], [pages[35]], [pages[50]], [pages[67]]] # Some examples\n",
        "df = spark.createDataFrame(candidates).toDF(\"text\")"
      ],
      "metadata": {
        "id": "eKKfzE7qm-xy"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classification_pipeline = get_binary_pipeline('finclf_acquisitions_item')\n",
        "\n",
        "model = classification_pipeline.fit(df)\n",
        "result = model.transform(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZJMZJ1VnEX2",
        "outputId": "79c00d8d-2fe4-4731-9350-2bfb889051f9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tfhub_use download started this may take some time.\n",
            "Approximate size to download 923.7 MB\n",
            "[OK!]\n",
            "finclf_acquisitions_item download started this may take some time.\n",
            "Approximate size to download 21.3 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.select('category.result').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEAus5MXnLdO",
        "outputId": "ae9cb7bc-fce9-46f1-8c8c-4206a0ef0e66"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+\n",
            "|        result|\n",
            "+--------------+\n",
            "|       [other]|\n",
            "|       [other]|\n",
            "|       [other]|\n",
            "|       [other]|\n",
            "|[acquisitions]|\n",
            "+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "### Finding About Management and their work experience part\n"
      ],
      "metadata": {
        "id": "g9REr6uYnRu8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's send some pages and check which one(s) contain that information. In a real case, you could send all the pages to the model, but here for time saving purposes, we will show just a subset."
      ],
      "metadata": {
        "id": "o_r7htornbWy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "candidates = [[pages[4]], [pages[84]], [pages[85]], [pages[86]], [pages[87]]]\n",
        "df = spark.createDataFrame(candidates).toDF(\"text\")\n",
        "\n",
        "\n",
        "classification_pipeline = get_binary_pipeline('finclf_work_experience_item')\n",
        "model = classification_pipeline.fit(df)\n",
        "result = model.transform(df)\n",
        "result.select('category.result').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16FptfBXnboU",
        "outputId": "1145e793-eee8-4497-d958-ba25a41c92ce"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tfhub_use download started this may take some time.\n",
            "Approximate size to download 923.7 MB\n",
            "[OK!]\n",
            "finclf_work_experience_item download started this may take some time.\n",
            "Approximate size to download 21.2 MB\n",
            "[OK!]\n",
            "+-----------------+\n",
            "|           result|\n",
            "+-----------------+\n",
            "|          [other]|\n",
            "|          [other]|\n",
            "|          [other]|\n",
            "|[work_experience]|\n",
            "|          [other]|\n",
            "+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using LightPipeline"
      ],
      "metadata": {
        "id": "CPSxpGYCj8cF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[LightPipelines](https://nlp.johnsnowlabs.com/docs/en/concepts#using-spark-nlps-lightpipeline) are Spark NLP specific Pipelines, equivalent to Spark ML Pipeline, but meant to deal with smaller amounts of data. They‚Äôre useful working with small datasets, debugging results, or when running either training or prediction from an API that serves one-off requests.\n",
        "\n",
        "Spark NLP LightPipelines are Spark ML pipelines converted into a single machine but the multi-threaded task, **becoming more than 10x times faster** for smaller amounts of data (small is relative, but 50k sentences are roughly a good maximum). To use them, we simply plug in a trained (fitted) pipeline and then annotate a plain text. We don't even need to convert the input text to DataFrame in order to feed it into a pipeline that's accepting DataFrame as an input in the first place. This feature would be quite useful when it comes to getting a prediction for a few lines of text from a trained ML model.\n",
        "\n",
        "For more details:\n",
        "[https://medium.com/spark-nlp/spark-nlp-101-lightpipeline-a544e93f20f1](https://medium.com/spark-nlp/spark-nlp-101-lightpipeline-a544e93f20f1)"
      ],
      "metadata": {
        "id": "2v2CYCq6j-i0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "light_model = nlp.LightPipeline(cls_model)"
      ],
      "metadata": {
        "id": "juiznw0cdgOb"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can use strings or list of strings with the method [.annotate()](https://nlp.johnsnowlabs.com/api/python/reference/autosummary/sparknlp/base/light_pipeline/index.html#sparknlp.base.light_pipeline.LightPipeline.annotate) to get the results. To get more metadata in the result, use the method [.fullAnnotate()](https://nlp.johnsnowlabs.com/api/python/reference/autosummary/sparknlp/base/light_pipeline/index.html#sparknlp.base.light_pipeline.LightPipeline.fullAnnotate) instead. The result is a `list` if a `list` is given, or a `dict` if a string was given.\n",
        "\n",
        "To extract the results from the object, you just need to parse the dictionary."
      ],
      "metadata": {
        "id": "kltKN3XEpOHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lp_results = light_model.annotate(pages[0])\n",
        "lp_results.keys()"
      ],
      "metadata": {
        "id": "a9zQvgZftS18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7aa0000-cebc-496b-c4bd-96d1dfdb5431"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['document', 'sentence_embeddings', 'category'])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List with all the chunks\n",
        "lp_results[\"category\"]"
      ],
      "metadata": {
        "id": "CCCX2g_ctS0D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5b654ce-b6f3-4b89-a04e-cdd75b5e8d2e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['form_10k_summary']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the `.annotate()` did't return metadata in the `category` item. How can we obtain them? Using the `.fullAnnotate()` instead. This method always returns a list."
      ],
      "metadata": {
        "id": "geH7M8XkrBnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lp_results_full = light_model.fullAnnotate(pages[0])\n",
        "lp_results_full[0].keys()"
      ],
      "metadata": {
        "id": "PLIGPnJntSx8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c41c3165-fb80-4663-92ff-4f86353e92fe"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['document', 'sentence_embeddings', 'category'])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lp_results_full[0][\"category\"]"
      ],
      "metadata": {
        "id": "HDBT6Cb-tSvu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0125dbaa-835e-46f9-9b9d-2e7421974217"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Annotation(category, 0, 4047, form_10k_summary, {'sentence': '0', 'form_10k_summary': '0.99994636', 'other': '5.3589152E-5'})]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can see all the metadata in the annotation objects. Let's get the results in a tabular form."
      ],
      "metadata": {
        "id": "lROIxxO_r0zR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_tabular = []\n",
        "for res in lp_results_full[0][\"category\"]:\n",
        "    results_tabular.append(\n",
        "        (\n",
        "            res.begin,\n",
        "            res.end,\n",
        "            res.result,\n",
        "            res.metadata[\"form_10k_summary\"],\n",
        "        )\n",
        "    )\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "pd.DataFrame(results_tabular, columns=[\"begin\", \"end\", \"category\", \"confidence\"])\n"
      ],
      "metadata": {
        "id": "Q0l4JNsPtStH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "92b2e359-369f-48fd-fd24-6414a8371751"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   begin   end          category  confidence\n",
              "0      0  4047  form_10k_summary  0.99994636"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bfafed3a-b1e0-40fe-90dd-b10935b9527c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>begin</th>\n",
              "      <th>end</th>\n",
              "      <th>category</th>\n",
              "      <th>confidence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>4047</td>\n",
              "      <td>form_10k_summary</td>\n",
              "      <td>0.99994636</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bfafed3a-b1e0-40fe-90dd-b10935b9527c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bfafed3a-b1e0-40fe-90dd-b10935b9527c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bfafed3a-b1e0-40fe-90dd-b10935b9527c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training a custom Classification model"
      ],
      "metadata": {
        "id": "TyHZxXE91GXD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Please restart the runtime (if in Colab) to free memory required for training**"
      ],
      "metadata": {
        "id": "KjVZ_2i5xpVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from johnsnowlabs import nlp, finance\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import pyspark.sql.functions as F\n"
      ],
      "metadata": {
        "id": "Q0fgjxOLxrGB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = nlp.start()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWrobAwAyQnp",
        "outputId": "9852f4bc-d43d-4774-f8ab-8311aa89dbae"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìã Loading license number 0 from /root/.johnsnowlabs/licenses/license_number_0_for_Spark-Healthcare_Spark-OCR.json\n",
            "üëå Launched \u001b[92mcpu optimized\u001b[39m session with with: üöÄSpark-NLP==4.2.4, üíäSpark-Healthcare==4.2.4, running on ‚ö° PySpark==3.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If your appliation needs different categories than the provided pretrained models can identify, what you can do is to train a new model that fits your requirements. To do that you first need to collect and label enough data. If you are not sure how to annotate (label) text data and prepare it in the CoNLL 2003 format, try our free tool [Annotation Lab](https://nlp.johnsnowlabs.com/docs/en/alab/quickstart), where you can easily label text data and export in the correct format for training.\n",
        "\n",
        "For our purposes here, we will use a sample file annotated by our team."
      ],
      "metadata": {
        "id": "i90SLv-P1JS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings_JSL/Finance/data/finance_clf_data.csv"
      ],
      "metadata": {
        "id": "ZxWh5M8J1Ivc"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head -2 finance_clf_data.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ma5zy2zaIKsM",
        "outputId": "ed27edfb-503b-4e2f-cae9-6dcf4b2e563c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text,label,len\n",
            "\"Presently we do not believe any U S or State regulatory body has taken any action or position adverse to our main cryptocurrency bitcoin with respect to its production sale and use as a medium of exchange however future changes to existing regulations or entirely new regulations may affect our business in ways it is not presently possible for us to predict with any reasonable degree of reliability \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finance_data = pd.read_csv(\"finance_clf_data.csv\")\n",
        "finance_data.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "DSEC5CTIIPjK",
        "outputId": "df8bcf36-3313-4bed-d6e5-d8119c023322"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text         label  len\n",
              "0  Presently we do not believe any U S or State r...      business  402\n",
              "1   \\nnetwork outages or performance degradation ...  risk_factors  496\n",
              "2  Available Information\\nOur reports filed with ...      business  356"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-86e885e1-f228-40b7-baf5-89f7a3199f80\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Presently we do not believe any U S or State r...</td>\n",
              "      <td>business</td>\n",
              "      <td>402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\nnetwork outages or performance degradation ...</td>\n",
              "      <td>risk_factors</td>\n",
              "      <td>496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Available Information\\nOur reports filed with ...</td>\n",
              "      <td>business</td>\n",
              "      <td>356</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-86e885e1-f228-40b7-baf5-89f7a3199f80')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-86e885e1-f228-40b7-baf5-89f7a3199f80 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-86e885e1-f228-40b7-baf5-89f7a3199f80');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finance_data[\"label\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLv28rlISPC3",
        "outputId": "558bfe0d-715a-408c-c0a0-fa148b817da0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "risk_factors               1926\n",
              "financial_statements       1888\n",
              "business                    970\n",
              "financial_conditions        346\n",
              "form_10k_summary            240\n",
              "executives_compensation     155\n",
              "controls_procedures         138\n",
              "equity                      111\n",
              "market_risk                 100\n",
              "executives                   73\n",
              "legal_proceedings            51\n",
              "properties                   48\n",
              "security_ownership           46\n",
              "exhibits                     36\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finance_data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UE5jiEP-KJsh",
        "outputId": "c96b1a4a-a41b-41a9-c86e-06c2de0cebcc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['text', 'label', 'len'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = train_test_split(\n",
        "    finance_data, train_size=0.8, stratify=finance_data.label, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "8FOT9laXLt_c"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train with Universal Encoder"
      ],
      "metadata": {
        "id": "b1k6kd7SMpBs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document_assembler = (\n",
        "    nlp.DocumentAssembler().setInputCol(\"text\").setOutputCol(\"document\")\n",
        ")\n",
        "\n",
        "embeddings = (\n",
        "    nlp.UniversalSentenceEncoder.pretrained()\n",
        "    .setInputCols(\"document\")\n",
        "    .setOutputCol(\"sentence_embeddings\")\n",
        ")\n",
        "\n",
        "classsifierdl = (\n",
        "    finance.ClassifierDLApproach()\n",
        "    .setInputCols([\"sentence_embeddings\"])\n",
        "    .setOutputCol(\"class\")\n",
        "    .setLabelColumn(\"label\")\n",
        "    .setMaxEpochs(50)\n",
        "    .setEnableOutputLogs(True)\n",
        "    .setBatchSize(4)\n",
        ")\n",
        "\n",
        "clf_pipeline = nlp.Pipeline(stages=[document_assembler, embeddings, classsifierdl])"
      ],
      "metadata": {
        "id": "oMhp5cXuLt9N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d528800-88c2-4526-bb36-4d7f6e0685d3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tfhub_use download started this may take some time.\n",
            "Approximate size to download 923.7 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = spark.createDataFrame(train_data)\n",
        "test_data = spark.createDataFrame(test_data)"
      ],
      "metadata": {
        "id": "Rli-HphUUHoo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "clf_pipelineModel = clf_pipeline.fit(train_data)"
      ],
      "metadata": {
        "id": "Mm0onFB8OA2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e0f66a9-a179-4eeb-c1c2-58bbee7b5cf1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.25 s, sys: 135 ms, total: 1.38 s\n",
            "Wall time: 5min 4s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the model"
      ],
      "metadata": {
        "id": "ZZEsbSK8ZM8C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = clf_pipelineModel.transform(test_data)\n",
        "\n",
        "preds_df = preds.select('label', 'text', \"class.result\").toPandas()\n",
        "\n",
        "# The result is an array since in Spark NLP you can have multiple sentences.\n",
        "# Let's explode the array and get the item(s) inside of result column out\n",
        "preds_df['result'] = preds_df['result'].apply(lambda x : x[0])\n",
        "\n",
        "print (classification_report(preds_df['label'], preds_df['result']))"
      ],
      "metadata": {
        "id": "OPIombL1Lt2w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c524df2f-63f2-408b-f6ef-d691ef8f9c77"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                         precision    recall  f1-score   support\n",
            "\n",
            "               business       0.62      0.76      0.68       194\n",
            "    controls_procedures       0.00      0.00      0.00        28\n",
            "                 equity       0.00      0.00      0.00        22\n",
            "             executives       0.00      0.00      0.00        15\n",
            "executives_compensation       0.00      0.00      0.00        31\n",
            "               exhibits       0.00      0.00      0.00         7\n",
            "   financial_conditions       0.00      0.00      0.00        69\n",
            "   financial_statements       0.65      0.93      0.76       378\n",
            "       form_10k_summary       0.00      0.00      0.00        48\n",
            "      legal_proceedings       0.00      0.00      0.00        10\n",
            "            market_risk       0.00      0.00      0.00        20\n",
            "             properties       0.00      0.00      0.00        10\n",
            "           risk_factors       0.77      0.88      0.82       385\n",
            "     security_ownership       0.00      0.00      0.00         9\n",
            "\n",
            "               accuracy                           0.69      1226\n",
            "              macro avg       0.15      0.18      0.16      1226\n",
            "           weighted avg       0.54      0.69      0.60      1226\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that for the classes with few observations we didn't get any prediction! This happens because we used a small dataset and trained for few epochs. Let's check the logs to see how the model was learning."
      ],
      "metadata": {
        "id": "iR-RJ992VceI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_file_name = os.listdir(\"/root/annotator_logs\")[0]\n",
        "log_file_name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ohY7QdIBWUBf",
        "outputId": "ee3b3a20-27bd-4281-c6b2-7c4da4db9f3b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'FinanceClassifierDLApproach_9e9f77b13825.log'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /root/annotator_logs/$log_file_name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsvM95BAWbeQ",
        "outputId": "d4695ca2-7e3f-4c83-dbdb-0913f5c0b154"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training started - epochs: 50 - learning_rate: 0.005 - batch_size: 4 - training_examples: 4902 - classes: 14\n",
            "Epoch 0/50 - 6.46s - loss: 2992.5574 - acc: 0.3087755 - batches: 1226\n",
            "Epoch 1/50 - 6.33s - loss: 2996.461 - acc: 0.30816326 - batches: 1226\n",
            "Epoch 2/50 - 5.62s - loss: 2996.461 - acc: 0.30816326 - batches: 1226\n",
            "Epoch 3/50 - 5.66s - loss: 2996.461 - acc: 0.30816326 - batches: 1226\n",
            "Epoch 4/50 - 5.85s - loss: 2996.461 - acc: 0.30816326 - batches: 1226\n",
            "Epoch 5/50 - 6.34s - loss: 2996.461 - acc: 0.30816326 - batches: 1226\n",
            "Epoch 6/50 - 5.49s - loss: 2996.461 - acc: 0.30816326 - batches: 1226\n",
            "Epoch 7/50 - 5.62s - loss: 2996.461 - acc: 0.30816326 - batches: 1226\n",
            "Epoch 8/50 - 5.72s - loss: 2996.461 - acc: 0.30816326 - batches: 1226\n",
            "Epoch 9/50 - 5.50s - loss: 2916.2534 - acc: 0.37938777 - batches: 1226\n",
            "Epoch 10/50 - 5.58s - loss: 2701.5913 - acc: 0.56142855 - batches: 1226\n",
            "Epoch 11/50 - 5.42s - loss: 2682.6233 - acc: 0.57265306 - batches: 1226\n",
            "Epoch 12/50 - 5.55s - loss: 2671.152 - acc: 0.5787755 - batches: 1226\n",
            "Epoch 13/50 - 5.57s - loss: 2662.353 - acc: 0.58244896 - batches: 1226\n",
            "Epoch 14/50 - 5.60s - loss: 2659.0808 - acc: 0.5834694 - batches: 1226\n",
            "Epoch 15/50 - 5.58s - loss: 2655.2021 - acc: 0.587551 - batches: 1226\n",
            "Epoch 16/50 - 5.66s - loss: 2652.3826 - acc: 0.59 - batches: 1226\n",
            "Epoch 17/50 - 5.82s - loss: 2650.5178 - acc: 0.59 - batches: 1226\n",
            "Epoch 18/50 - 5.53s - loss: 2649.0144 - acc: 0.59020406 - batches: 1226\n",
            "Epoch 19/50 - 5.41s - loss: 2647.8147 - acc: 0.5910204 - batches: 1226\n",
            "Epoch 20/50 - 5.43s - loss: 2646.8704 - acc: 0.59163266 - batches: 1226\n",
            "Epoch 21/50 - 5.51s - loss: 2646.0144 - acc: 0.5930612 - batches: 1226\n",
            "Epoch 22/50 - 5.55s - loss: 2645.1902 - acc: 0.5934694 - batches: 1226\n",
            "Epoch 23/50 - 5.47s - loss: 2644.3928 - acc: 0.59387755 - batches: 1226\n",
            "Epoch 24/50 - 5.41s - loss: 2643.7144 - acc: 0.5946939 - batches: 1226\n",
            "Epoch 25/50 - 6.17s - loss: 2640.6614 - acc: 0.5955102 - batches: 1226\n",
            "Epoch 26/50 - 5.43s - loss: 2628.527 - acc: 0.6020408 - batches: 1226\n",
            "Epoch 27/50 - 5.73s - loss: 2615.7524 - acc: 0.6142857 - batches: 1226\n",
            "Epoch 28/50 - 5.51s - loss: 2594.7769 - acc: 0.64612246 - batches: 1226\n",
            "Epoch 29/50 - 5.54s - loss: 2574.7188 - acc: 0.66591835 - batches: 1226\n",
            "Epoch 30/50 - 5.57s - loss: 2563.3086 - acc: 0.67387754 - batches: 1226\n",
            "Epoch 31/50 - 6.19s - loss: 2556.8335 - acc: 0.67530614 - batches: 1226\n",
            "Epoch 32/50 - 5.57s - loss: 2552.3901 - acc: 0.6777551 - batches: 1226\n",
            "Epoch 33/50 - 5.49s - loss: 2548.8235 - acc: 0.68163264 - batches: 1226\n",
            "Epoch 34/50 - 5.42s - loss: 2545.5276 - acc: 0.6861225 - batches: 1226\n",
            "Epoch 35/50 - 5.40s - loss: 2542.446 - acc: 0.68836737 - batches: 1226\n",
            "Epoch 36/50 - 5.45s - loss: 2539.7183 - acc: 0.6904082 - batches: 1226\n",
            "Epoch 37/50 - 5.52s - loss: 2537.338 - acc: 0.6922449 - batches: 1226\n",
            "Epoch 38/50 - 5.55s - loss: 2535.2112 - acc: 0.6932653 - batches: 1226\n",
            "Epoch 39/50 - 5.41s - loss: 2533.2703 - acc: 0.69469386 - batches: 1226\n",
            "Epoch 40/50 - 5.81s - loss: 2531.405 - acc: 0.69612247 - batches: 1226\n",
            "Epoch 41/50 - 5.67s - loss: 2529.5625 - acc: 0.6977551 - batches: 1226\n",
            "Epoch 42/50 - 5.52s - loss: 2527.727 - acc: 0.6993877 - batches: 1226\n",
            "Epoch 43/50 - 5.58s - loss: 2525.9607 - acc: 0.7012245 - batches: 1226\n",
            "Epoch 44/50 - 5.50s - loss: 2524.3 - acc: 0.7020408 - batches: 1226\n",
            "Epoch 45/50 - 5.54s - loss: 2522.806 - acc: 0.7030612 - batches: 1226\n",
            "Epoch 46/50 - 6.40s - loss: 2521.487 - acc: 0.70408165 - batches: 1226\n",
            "Epoch 47/50 - 5.48s - loss: 2520.3242 - acc: 0.70489794 - batches: 1226\n",
            "Epoch 48/50 - 5.52s - loss: 2519.256 - acc: 0.7055102 - batches: 1226\n",
            "Epoch 49/50 - 5.55s - loss: 2518.2705 - acc: 0.70612246 - batches: 1226\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the accuracy has an increasing trend, meaning that the model could continue to improve. You can try by youtself to increase the number of epochs on the pipeline and check how the model improves."
      ],
      "metadata": {
        "id": "a-Nouo1lWud-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving and loading models"
      ],
      "metadata": {
        "id": "UpKArvuJXGQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf_pipelineModel.stages"
      ],
      "metadata": {
        "id": "z_sroXZZad8O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "166365c3-3992-435a-975f-e7de81a4f44b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[DocumentAssembler_b1121d39595c,\n",
              " UNIVERSAL_SENTENCE_ENCODER_4de71669b7ec,\n",
              " FinanceClassifierDLModel_366460063901]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf_pipelineModel.stages[-1].write().overwrite().save('Clf_model')"
      ],
      "metadata": {
        "id": "LT8Hv9tzXFvS"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load back  saved Classifier Model\n",
        "ClfModel = finance.ClassifierDLModel.load('Clf_model')"
      ],
      "metadata": {
        "id": "OlCYJW4GXT32"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ld_pipeline = nlp.Pipeline(stages=[document_assembler, embeddings,ClfModel])\n",
        "ld_pipeline_model = ld_pipeline.fit(spark.createDataFrame([['']]).toDF(\"text\"))"
      ],
      "metadata": {
        "id": "T6ylYddxXVwy"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Model Transform to testData\n",
        "ld_preds = ld_pipeline_model.transform(test_data)"
      ],
      "metadata": {
        "id": "Ly5MnrZsXYPB"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ld_preds_df = ld_preds.select('text','label',\"class.result\").toPandas()\n",
        "ld_preds_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "FDzbpCAzXZmi",
        "outputId": "bc7dfade-7e87-4263-b9b1-c3ff48afffab"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  ...                  result\n",
              "0  In addition in connection with our issuance of...  ...          [risk_factors]\n",
              "1   \\nBasis for Opinion\\nThese financial statemen...  ...  [financial_statements]\n",
              "2  associated with cryptocurrencies may have had ...  ...          [risk_factors]\n",
              "3  30 416\\n \\nGoodwill\\n51 041\\n \\nTotal purchase...  ...  [financial_statements]\n",
              "4  currently receive or at all or that a lease te...  ...          [risk_factors]\n",
              "\n",
              "[5 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3342822a-3e86-45f3-81d3-6bc1d55ef257\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In addition in connection with our issuance of...</td>\n",
              "      <td>risk_factors</td>\n",
              "      <td>[risk_factors]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\nBasis for Opinion\\nThese financial statemen...</td>\n",
              "      <td>financial_statements</td>\n",
              "      <td>[financial_statements]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>associated with cryptocurrencies may have had ...</td>\n",
              "      <td>risk_factors</td>\n",
              "      <td>[risk_factors]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>30 416\\n \\nGoodwill\\n51 041\\n \\nTotal purchase...</td>\n",
              "      <td>financial_statements</td>\n",
              "      <td>[financial_statements]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>currently receive or at all or that a lease te...</td>\n",
              "      <td>risk_factors</td>\n",
              "      <td>[risk_factors]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3342822a-3e86-45f3-81d3-6bc1d55ef257')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3342822a-3e86-45f3-81d3-6bc1d55ef257 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3342822a-3e86-45f3-81d3-6bc1d55ef257');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SoJspRUoXc8H"
      },
      "execution_count": 22,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0 (tags/v3.8.0:fa919fd, Oct 14 2019, 19:37:50) [MSC v.1916 64 bit (AMD64)]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "939480ed579cbcc9bd95c0bb2f0a271d068ec362d36f1415ed941c7dadb52340"
      }
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "mNS9C_-2YJNi",
        "Fxm3OQn9YJNh"
      ],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}