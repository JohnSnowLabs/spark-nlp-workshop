{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wxZDXLDCXkk_"
   },
   "source": [
    "\n",
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "pZ6sKi8ZX1z4"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings_JSL/Finance/07.1.Training_Financial_Assertion.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KLqW6FOnEvov"
   },
   "source": [
    "# Training Finance Assertion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PcsTZJmZu7CQ"
   },
   "source": [
    "#Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4914b00f-abd2-4449-9a4f-737f317317be"
   },
   "outputs": [],
   "source": [
    "# Install the johnsnowlabs library to access Spark-OCR and Spark-NLP for Healthcare, Finance, and Legal.\n",
    "! pip install johnsnowlabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JOzbTlCRNvVd"
   },
   "outputs": [],
   "source": [
    "from johnsnowlabs import nlp, finance\n",
    "# After uploading your license run this to install all licensed Python Wheels and pre-download Jars the Spark Session JVM\n",
    "# Make sure to restart your notebook afterwards for changes to take effect\n",
    "nlp.install(force_browser=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Ki72qJQGPOz"
   },
   "source": [
    "## Start Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TZIjuI3zN1Oi"
   },
   "outputs": [],
   "source": [
    "# Automatically load license data and start a session with all jars user has access to\n",
    "spark = nlp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1669905517422,
     "user": {
      "displayName": "Vildan SarÄ±kaya",
      "userId": "07789644790967768983"
     },
     "user_tz": 300
    },
    "id": "GlmdmVsK0npI",
    "outputId": "5f146c08-2d05-42fd-a1e9-1e4135f2b756"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://46bf175d4de1:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>John-Snow-Labs-Spark-Session ðŸš€ with Jars for: ðŸš€Spark-NLP==4.2.2, ðŸ’ŠSpark-Healthcare==4.2.2, running on âš¡ PySpark==3.1.2</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f2765d7fac0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JYBQyxEd0uR0"
   },
   "source": [
    "#Data Prep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AVBmGFcQ03La"
   },
   "outputs": [],
   "source": [
    "! wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings_JSL/Finance/data/assertion_fin.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8iJF_HCw1Lgh"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "training_df = pd.read_csv('/content/assertion_fin.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13515,
     "status": "ok",
     "timestamp": 1669905544262,
     "user": {
      "displayName": "Vildan SarÄ±kaya",
      "userId": "07789644790967768983"
     },
     "user_tz": 300
    },
    "id": "JREBeTzb8ov-",
    "outputId": "c8a4bd1c-9238-48bc-9b7f-cdb5a303424c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+---------+-------+--------------------+------+---------------+\n",
      "|task_id|            sentence|tkn_start|tkn_end|               chunk|entity|assertion_label|\n",
      "+-------+--------------------+---------+-------+--------------------+------+---------------+\n",
      "|      1|The Swedish East ...|        1|      4|Swedish East Indi...|   ORG|           PAST|\n",
      "|      1|The Swedish East ...|        6|      8|Svenska Ostindisk...| ALIAS|           PAST|\n",
      "|      1|The Swedish East ...|       10|     10|                SOIC| ALIAS|           PAST|\n",
      "|      1|The Swedish East ...|       14|     14|          Gothenburg|   LOC|           PAST|\n",
      "|      1|The Swedish East ...|       15|     15|              Sweden|   LOC|           PAST|\n",
      "|      1|The Swedish East ...|       17|     17|                1731|  DATE|           PAST|\n",
      "|      1|The Swedish East ...|       25|     25|               China|   LOC|           PAST|\n",
      "|      1|The Swedish East ...|       28|     29|            Far East|   LOC|           PAST|\n",
      "|      1|The venture was i...|        9|     12|Dutch East India ...|   ORG|           PAST|\n",
      "|      1|The venture was i...|       15|     18|British East Indi...|   ORG|           PAST|\n",
      "|      1|This made Gothenb...|        2|      2|          Gothenburg|   LOC|           PAST|\n",
      "|      1|Trade with China ...|        2|      2|               China|   LOC|           PAST|\n",
      "|      1|Trade with China ...|       11|     11|              Sweden|   LOC|           PAST|\n",
      "|      1|The Chinese cultu...|       34|     34|              Sweden|   LOC|           PAST|\n",
      "|      1|The company folde...|        4|      4|                1813|  DATE|           PAST|\n",
      "|      1|nevertheless, it ...|       11|     11|          Gothenburg|   LOC|           PAST|\n",
      "|      1|Background Sweden...|       16|     17|          East India|   LOC|           PAST|\n",
      "|      1|The royal privile...|        5|      8|Swedish East Indi...|   ORG|           PAST|\n",
      "|      1|The royal privile...|        9|      9|                SOIC| ALIAS|           PAST|\n",
      "|      1|The royal privile...|       27|     28|          East India|   LOC|           PAST|\n",
      "+-------+--------------------+---------+-------+--------------------+------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data = spark.createDataFrame(training_df)\n",
    "training_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 104,
     "status": "ok",
     "timestamp": 1669905565070,
     "user": {
      "displayName": "Vildan SarÄ±kaya",
      "userId": "07789644790967768983"
     },
     "user_tz": 300
    },
    "id": "ET8GD3y3-17e",
    "outputId": "2d064145-a71e-4307-850a-874369909c1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- task_id: long (nullable = true)\n",
      " |-- sentence: string (nullable = true)\n",
      " |-- tkn_start: long (nullable = true)\n",
      " |-- tkn_end: long (nullable = true)\n",
      " |-- chunk: string (nullable = true)\n",
      " |-- entity: string (nullable = true)\n",
      " |-- assertion_label: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1390,
     "status": "ok",
     "timestamp": 1669905567213,
     "user": {
      "displayName": "Vildan SarÄ±kaya",
      "userId": "07789644790967768983"
     },
     "user_tz": 300
    },
    "id": "R6xa4jp8Szs0",
    "outputId": "f1de571e-fc1f-49e0-efbd-801b47851cdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.84 ms, sys: 2.02 ms, total: 10.9 ms\n",
      "Wall time: 1.31 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8050"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time training_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1985,
     "status": "ok",
     "timestamp": 1669905571199,
     "user": {
      "displayName": "Vildan SarÄ±kaya",
      "userId": "07789644790967768983"
     },
     "user_tz": 300
    },
    "id": "fxcHD_Q_-_lD",
    "outputId": "dde5b14d-331c-4962-9984-a2d892e4ea2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 8050\n",
      "Test Dataset Count: 786\n"
     ]
    }
   ],
   "source": [
    "(train_data, test_data) = training_data.randomSplit([0.9, 0.1], seed = 100)\n",
    "print(\"Training Dataset Count: \" + str(training_data.count()))\n",
    "print(\"Test Dataset Count: \" + str(test_data.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 308,
     "status": "ok",
     "timestamp": 1669905571501,
     "user": {
      "displayName": "Vildan SarÄ±kaya",
      "userId": "07789644790967768983"
     },
     "user_tz": 300
    },
    "id": "DFN_BuHU84HF",
    "outputId": "cbfdc2b6-609f-4838-e441-ec2186945464"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+---------+-------+--------------------+------+---------------+\n",
      "|task_id|            sentence|tkn_start|tkn_end|               chunk|entity|assertion_label|\n",
      "+-------+--------------------+---------+-------+--------------------+------+---------------+\n",
      "|      1|\"Stockholms-varve...|        6|      6|           Stockholm|   LOC|           PAST|\n",
      "|      1|\"The funny busine...|        5|      8|Swedish East Indi...|   ORG|           PAST|\n",
      "|      1|             (1998).|        0|      0|                1998|  DATE|           PAST|\n",
      "|      1|2.5 tonnes) and t...|       34|     34|              Sweden|   LOC|           PAST|\n",
      "|      1|37. Gothenburg: R...|        2|      7|Royal Society of ...|   ORG|           PAST|\n",
      "|      1|= Decline and fal...|       11|     11|                1806|  DATE|           PAST|\n",
      "|      1|= Early attempts ...|        9|     11|  Swedish East India|   ORG|           PAST|\n",
      "|      1|= Early attempts ...|       19|     19|            merchant|  ROLE|           PAST|\n",
      "|      1|= Early attempts ...|       20|     21|    Willem Usselincx|   PER|           PAST|\n",
      "|      1|= Sweden after th...|        1|      1|              Sweden|   LOC|           PAST|\n",
      "|      1|= The Royal chart...|        9|     12|Henrik KÃ¶nig & Co...|   ORG|           PAST|\n",
      "|      1|= The Royal chart...|       39|     42|   Cape of Good Hope|   LOC|           PAST|\n",
      "|      1|= The Royal chart...|       46|     46|               Japan|   LOC|           PAST|\n",
      "|      1|= The Royal chart...|       79|     79|          Gothenburg|   LOC|           PAST|\n",
      "|      1|= The first octro...|        8|      8|           directors|  ROLE|           PAST|\n",
      "|      1|= The first octro...|       11|     11|                SOIC|   ORG|           PAST|\n",
      "|      1|= The first octro...|       13|     14|        Henrik KÃ¶nig|   PER|           PAST|\n",
      "|      1|= The first octro...|       15|     16|      Colin Campbell|   PER|           PAST|\n",
      "|      1|= The first octro...|       23|     23|           Stockholm|   LOC|           PAST|\n",
      "|      1|= The fourth octr...|        6|      6|                SOIC|   ORG|           PAST|\n",
      "+-------+--------------------+---------+-------+--------------------+------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2WZDqlZA_kmb"
   },
   "source": [
    "#Using Bert Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54511,
     "status": "ok",
     "timestamp": 1669905627844,
     "user": {
      "displayName": "Vildan SarÄ±kaya",
      "userId": "07789644790967768983"
     },
     "user_tz": 300
    },
    "id": "7qfJh8ap_nI2",
    "outputId": "d5fbb217-e07e-4303-c1b1-6ff13a7066f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_embeddings_sec_bert_base download started this may take some time.\n",
      "Approximate size to download 390.4 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "bert_embeddings = nlp.BertEmbeddings.pretrained(\"bert_embeddings_sec_bert_base\", \"en\") \\\n",
    "  .setInputCols(\"document\", \"token\") \\\n",
    "  .setOutputCol(\"embeddings\")\\\n",
    "  .setMaxSentenceLength(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fe0957BT_rcy"
   },
   "outputs": [],
   "source": [
    "document = nlp.DocumentAssembler()\\\n",
    "    .setInputCol(\"sentence\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "chunk = nlp.Doc2Chunk()\\\n",
    "    .setInputCols(\"document\")\\\n",
    "    .setOutputCol(\"doc_chunk\")\\\n",
    "    .setChunkCol(\"chunk\")\\\n",
    "    .setStartCol(\"tkn_start\")\\\n",
    "    .setStartColByTokenIndex(True)\\\n",
    "    .setFailOnMissing(False)\\\n",
    "    .setLowerCase(False)\n",
    "\n",
    "token = nlp.Tokenizer()\\\n",
    "    .setInputCols(['document'])\\\n",
    "    .setOutputCol('token')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LFTO0PlI9-3e"
   },
   "source": [
    "We save the test data in parquet format to use in `AssertionDLApproach()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M9u4c65G9VaC"
   },
   "outputs": [],
   "source": [
    "assertion_pipeline = nlp.Pipeline(\n",
    "    stages = [\n",
    "    document,\n",
    "    chunk,\n",
    "    token,\n",
    "    bert_embeddings])\n",
    "\n",
    "assertion_test_data = assertion_pipeline.fit(test_data).transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1669905630825,
     "user": {
      "displayName": "Vildan SarÄ±kaya",
      "userId": "07789644790967768983"
     },
     "user_tz": 300
    },
    "id": "r-UREmtI9Vd3",
    "outputId": "c8d3a15f-25d7-4d99-9145-1721a172285c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['task_id',\n",
       " 'sentence',\n",
       " 'tkn_start',\n",
       " 'tkn_end',\n",
       " 'chunk',\n",
       " 'entity',\n",
       " 'assertion_label',\n",
       " 'document',\n",
       " 'doc_chunk',\n",
       " 'token',\n",
       " 'embeddings']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assertion_test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kBaiXx78BTLT"
   },
   "outputs": [],
   "source": [
    "assertion_test_data.write.mode('overwrite').parquet('test_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tFhN6evk9ViI"
   },
   "outputs": [],
   "source": [
    "assertion_train_data = assertion_pipeline.fit(training_data).transform(training_data)\n",
    "assertion_train_data.write.mode('overwrite').parquet('train_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1669907171908,
     "user": {
      "displayName": "Vildan SarÄ±kaya",
      "userId": "07789644790967768983"
     },
     "user_tz": 300
    },
    "id": "BtxnrvcA9VlN",
    "outputId": "d8d12b86-d6bd-47b4-d72f-311090deeb04"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['task_id',\n",
       " 'sentence',\n",
       " 'tkn_start',\n",
       " 'tkn_end',\n",
       " 'chunk',\n",
       " 'entity',\n",
       " 'assertion_label',\n",
       " 'document',\n",
       " 'doc_chunk',\n",
       " 'token',\n",
       " 'embeddings']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assertion_train_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uTishXbut1MS"
   },
   "source": [
    "##Graph setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1hTawAHemzGn"
   },
   "outputs": [],
   "source": [
    "!pip install -q tensorflow==2.7.0\n",
    "!pip install -q tensorflow-addons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ShZT8BBo4FY"
   },
   "source": [
    "We will use TFGraphBuilder annotator which can be used to create graphs in the model training pipeline. \n",
    "\n",
    "TFGraphBuilder inspects the data and creates the proper graph if a suitable version of TensorFlow (<= 2.7 ) is available. The graph is stored in the defined folder and loaded by the approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B8xGC2FLISvU"
   },
   "outputs": [],
   "source": [
    "from johnsnowlabs import nlp, finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XhU0L1OXdaLN"
   },
   "outputs": [],
   "source": [
    "graph_folder= \"./tf_graphs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "miNgoTjio0mL"
   },
   "outputs": [],
   "source": [
    "assertion_graph_builder =  finance.TFGraphBuilder()\\\n",
    "    .setModelName(\"assertion_dl\")\\\n",
    "    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "    .setLabelColumn(\"assertion_label\")\\\n",
    "    .setGraphFolder(graph_folder)\\\n",
    "    .setGraphFile(\"assertion_graph.pb\")\\\n",
    "    .setMaxSequenceLength(1200)\\\n",
    "    .setHiddenUnitsNumber(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6D0Ng7nMUjJa"
   },
   "source": [
    "**Setting the Scope Window (Target Area) Dynamically in Assertion Status Detection Models**\n",
    "\n",
    "\n",
    "This parameter allows you to train the Assertion Status Models to focus on specific context windows when resolving the status of a NER chunk. The window is in format `[X,Y]` being `X` the number of tokens to consider on the left of the chunk, and `Y` the max number of tokens to consider on the right. Letâ€™s take a look at what different windows mean:\n",
    "\n",
    "\n",
    "*   By default, the window is `[-1,-1]` which means that the Assertion Status will look at all of the tokens in the sentence/document (up to a maximum of tokens set in `setMaxSentLen()` ).\n",
    "*   `[0,0]` means â€œdonâ€™t pay attention to any token except the ner_chunkâ€, what basically is not considering any context for the Assertion resolution.\n",
    "*   `[9,15]` is what empirically seems to be the best baseline, meaning that we look up to 9 tokens on the left and 15 on the right of the ner chunk to understand the context and resolve the status.\n",
    "\n",
    "\n",
    "Check this [Scope Window Tuning Assertion Status Detection notebook](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/2.1.Scope_window_tuning_assertion_status_detection.ipynb)  that illustrates the effect of the different windows and how to properly fine-tune your AssertionDLModels to get the best of them.\n",
    "\n",
    "In our case, the best Scope Window is around [10,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BQxGbYks91go"
   },
   "outputs": [],
   "source": [
    "scope_window = [50, 50]\n",
    "\n",
    "assertionStatus = finance.AssertionDLApproach()\\\n",
    "    .setLabelCol(\"assertion_label\")\\\n",
    "    .setInputCols(\"document\", \"doc_chunk\", \"embeddings\")\\\n",
    "    .setOutputCol(\"assertion\")\\\n",
    "    .setBatchSize(128)\\\n",
    "    .setLearningRate(0.001)\\\n",
    "    .setEpochs(2)\\\n",
    "    .setStartCol(\"tkn_start\")\\\n",
    "    .setEndCol(\"tkn_end\")\\\n",
    "    .setMaxSentLen(1200)\\\n",
    "    .setEnableOutputLogs(True)\\\n",
    "    .setOutputLogsPath('training_logs/')\\\n",
    "    .setGraphFolder(graph_folder)\\\n",
    "    .setGraphFile(f\"{graph_folder}/assertion_graph.pb\")\\\n",
    "    .setTestDataset(path=\"test_data.parquet\", read_as='SPARK', options={'format': 'parquet'})\\\n",
    "    .setScopeWindow(scope_window)\n",
    "    #.setValidationSplit(0.2)\\    \n",
    "    #.setDropout(0.1)\\    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T2MZLeCYATrS"
   },
   "outputs": [],
   "source": [
    "clinical_assertion_pipeline = nlp.Pipeline(\n",
    "    stages = [\n",
    "    #document,\n",
    "    #chunk,\n",
    "    #token,\n",
    "    #embeddings,\n",
    "    assertion_graph_builder,\n",
    "    assertionStatus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 119,
     "status": "ok",
     "timestamp": 1669907438460,
     "user": {
      "displayName": "Vildan SarÄ±kaya",
      "userId": "07789644790967768983"
     },
     "user_tz": 300
    },
    "id": "yIvnuaQP91j8",
    "outputId": "2ee2e69e-b753-4690-dbfb-44f398d9c2b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- task_id: long (nullable = true)\n",
      " |-- sentence: string (nullable = true)\n",
      " |-- tkn_start: long (nullable = true)\n",
      " |-- tkn_end: long (nullable = true)\n",
      " |-- chunk: string (nullable = true)\n",
      " |-- entity: string (nullable = true)\n",
      " |-- assertion_label: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ueJz0aiJ_7l4"
   },
   "outputs": [],
   "source": [
    "assertion_train_data = spark.read.parquet('train_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j1NCZ89T_7ol"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "assertion_model = clinical_assertion_pipeline.fit(assertion_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "30SmcTiSpnWa"
   },
   "source": [
    "Checking the results saved in the log file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kOiu1vuspKut"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "log_files = os.listdir(\"/content/training_logs\")\n",
    "log_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CcQV0-fIrJHz"
   },
   "outputs": [],
   "source": [
    "with open(\"/content/training_logs/\"+log_files[0]) as log_file:\n",
    "    print(log_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bgcG00nT91nn"
   },
   "outputs": [],
   "source": [
    "assertion_test_data = spark.read.parquet('test_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-k2WrFkRyQyP"
   },
   "outputs": [],
   "source": [
    "preds = assertion_model.transform(assertion_test_data).select('assertion_label','assertion.result')\n",
    "\n",
    "preds.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4yI73lwG2xk5"
   },
   "outputs": [],
   "source": [
    "preds_df = preds.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yRXZFGlQ3Z2U"
   },
   "outputs": [],
   "source": [
    "preds_df[\"result\"] = preds_df[\"result\"].apply(lambda x: x[0] if len(x) else pd.NA)\n",
    "preds_df.dropna(inplace=True)\n",
    "\n",
    "preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1hb1kyGAE0Gn"
   },
   "outputs": [],
   "source": [
    "# We are going to use sklearn to evalute the results on test dataset\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print (classification_report( preds_df['assertion_label'], preds_df['result']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WuJ5YZ9sXU13"
   },
   "source": [
    "###Saving the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KBcoOwvwXV8p"
   },
   "outputs": [],
   "source": [
    "assertion_model.stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ioMW1jSrA-wg"
   },
   "outputs": [],
   "source": [
    "# Save a Spark NLP model\n",
    "assertion_model.stages[-1].write().overwrite().save('Assertion')\n",
    "\n",
    "# cd into saved dir and zip\n",
    "! cd /content/Assertion ; zip -r /content/Assertion.zip *"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
