{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "RDayMKT-fgKA"
      },
      "source": [
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rcomQeo8FP8K"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings_JSL/Finance/05.5.BertForTokenClassification_TrainAndSave.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PaR_Jxcek01"
      },
      "source": [
        "# Finance BertForTokenClassification\n",
        "Using Hugging Face and importing it to Finance NLP for scalability.\n",
        "\n",
        "This is a transformer-based approach, which usually returns much bigger models (10x) compared to NerModel, but it can improve the performance over NerModel. We don't carry out evaluation in this notebook, only training with full data and export into Spark NLP. To check evaluation, please check previous notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lPn3DiN72gO"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zoMfNqgRtLOg"
      },
      "outputs": [],
      "source": [
        "! pip -q install seqeval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwIqbitFoHtq",
        "outputId": "cb17480c-4960-4e3f-96df-ce2545309182"
      },
      "outputs": [],
      "source": [
        "! pip install transformers==4.8.1\n",
        "! pip install pyspark==3.1.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bp6w0FyRfIgX"
      },
      "source": [
        "# Setting name of the project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "85VnDQRj5QuX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['PROJECT_NAME'] = 'financial_operations'\n",
        "PROJECT_NAME = os.getenv('PROJECT_NAME')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "iCdSFJbE5tcw",
        "outputId": "073163cd-9357-4560-aeee-2c58e4f99791"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'financial_operations'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "PROJECT_NAME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEvXZO_TuhkH"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "F9Yxer2wuizZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertTokenizer, BertConfig\n",
        "\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import files\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "import transformers\n",
        "from transformers import BertForTokenClassification, TFBertForTokenClassification, AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZVF2kvevCGZ"
      },
      "source": [
        "## Setting up Torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "48k2DViAvEMe",
        "outputId": "66838c1f-0599-4ccf-fe3a-74e6012e4810"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.13.0+cu116'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "F3rwT34cw0Mv",
        "outputId": "6ee88d74-de31-48bc-e849-5ccbc4243004"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla T4'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "\n",
        "torch.cuda.get_device_name(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXgdr64B79_d"
      },
      "source": [
        "# Check that files are available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "J9yHnZeNepgm"
      },
      "outputs": [],
      "source": [
        "! wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings_JSL/Finance/data/conll_noO.conll"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fe7x0snlYCxY",
        "outputId": "14a1496b-28ca-4a9d-8980-05ea99f229af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "( NN NN O\n",
            "d NN NN O\n",
            ") NN NN O\n",
            "OF NN NN O\n",
            "THE NN NN O\n",
            "SECURITIES NN NN O\n",
            "EXCHANGE NN NN O\n",
            "ACT NN NN O\n",
            "OF NN NN O\n",
            "1934 NN NN O\n",
            "For NN NN O\n",
            "the NN NN O\n",
            "annual NN NN O\n",
            "period NN NN O\n",
            "ended NN NN O\n",
            "March NNP NNP B-FISCAL_YEAR\n",
            "31 NNP NNP I-FISCAL_YEAR\n",
            ", NNP NNP I-FISCAL_YEAR\n",
            "2021 NNP NNP I-FISCAL_YEAR\n",
            "March NNP NNP B-FISCAL_YEAR\n"
          ]
        }
      ],
      "source": [
        "!head -n 20 conll_noO.conll"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8H1P-jwe8CF"
      },
      "source": [
        "# Creating folders for logs and checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Tbd2bI9hkUn",
        "outputId": "0c1b3e6c-f4fe-4aca-8bc9-374bc6c98ef7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘financial_operations’: File exists\n"
          ]
        }
      ],
      "source": [
        "! mkdir {PROJECT_NAME}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUc4B7NThUK3",
        "outputId": "2ef3e0e5-365b-45be-9bf4-a46cc8248755"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘financial_operations/logs’: File exists\n"
          ]
        }
      ],
      "source": [
        "! mkdir {PROJECT_NAME}/logs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTUf3GUWuslz"
      },
      "source": [
        "# Starting a Spark Session for SparkNLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "PuCfCrbK6eWq",
        "outputId": "6668f286-737f-46a4-af0d-fa45240e429c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4829cf6c-bd77-4074-99e1-7d7d52337da5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4829cf6c-bd77-4074-99e1-7d7d52337da5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving 4.2.3.json to 4.2.3 (2).json\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "license_keys = files.upload()\n",
        "\n",
        "with open(list(license_keys.keys())[0]) as f:\n",
        "    license_keys = json.load(f)\n",
        "\n",
        "# Defining license key-value pairs as local variables\n",
        "locals().update(license_keys)\n",
        "\n",
        "# Adding license key-value pairs to environment variables\n",
        "os.environ.update(license_keys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frvjijxroKy9",
        "outputId": "888278f6-29ae-4beb-9c52-fa277fa8494f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "spark-nlp-jsl 4.2.3 requires spark-nlp==4.2.4, but you have spark-nlp 4.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Installing pyspark and spark-nlp\n",
        "! pip install --upgrade -q pyspark==3.1.2 spark-nlp==$PUBLIC_VERSION\n",
        "\n",
        "# Installing Spark NLP Healthcare\n",
        "! pip install --upgrade -q spark-nlp-jsl==$JSL_VERSION  --extra-index-url https://pypi.johnsnowlabs.com/$SECRET\n",
        "\n",
        "# Installing Spark NLP Display Library for visualization\n",
        "! pip install -q spark-nlp-display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "IJ4Dg2ZesrEi",
        "outputId": "7a662dc0-f713-42f4-de73-27b14d20be18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Spark NLP Version : 4.2.4\n",
            "Spark NLP_JSL Version : 4.2.3\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://35e501d33385:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark NLP Licensed</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7efb9398a640>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "import sparknlp\n",
        "import sparknlp_jsl\n",
        "\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp_jsl.annotator import *\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.ml import Pipeline,PipelineModel\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "params = {\"spark.driver.memory\":\"16G\", \n",
        "          \"spark.kryoserializer.buffer.max\":\"2000M\", \n",
        "          \"spark.driver.maxResultSize\":\"2000M\"} \n",
        "\n",
        "print(\"Spark NLP Version :\", sparknlp.version())\n",
        "print(\"Spark NLP_JSL Version :\", sparknlp_jsl.version())\n",
        "\n",
        "spark = sparknlp_jsl.start(license_keys['SECRET'],params=params)\n",
        "\n",
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrwN2hCR8HH6"
      },
      "source": [
        "# Convert JSL conlls in dataframe format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "lBBV98gqo90p"
      },
      "outputs": [],
      "source": [
        "from sparknlp.training import CoNLL\n",
        "\n",
        "def get_conll_df(pth):\n",
        "  data = CoNLL().readDataset(spark, pth)\n",
        "  data = data.withColumn(\"sentence_idx\", F.monotonically_increasing_id())\n",
        "\n",
        "  df = data.select('sentence_idx', F.explode(F.arrays_zip('token.result','label.result','pos.result')).alias(\"cols\")) \\\n",
        "  .select('sentence_idx',\n",
        "          F.expr(\"cols['0']\").alias(\"word\"),\n",
        "          F.expr(\"cols['1']\").alias(\"tag\"),\n",
        "          F.expr(\"cols['2']\").alias(\"pos\")).toPandas()\n",
        "  return df\n",
        "\n",
        "train_data_df = get_conll_df('./conll_noO.conll')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pg3k2mCMqsaY",
        "outputId": "4b18a355-36de-46cc-d4d5-1092ecd61d6f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "O                     51912\n",
              "I-DATE                 1932\n",
              "I-FISCAL_YEAR          1812\n",
              "B-DATE                 1797\n",
              "B-AMOUNT               1466\n",
              "B-CURRENCY             1461\n",
              "I-AMOUNT               1134\n",
              "B-FISCAL_YEAR           605\n",
              "I-EXPENSE_INCREASE      546\n",
              "I-EXPENSE_DECREASE      390\n",
              "B-PERCENTAGE            350\n",
              "I-PROFIT_INCREASE       288\n",
              "I-EXPENSE               280\n",
              "B-EXPENSE_INCREASE      274\n",
              "I-PROFIT                228\n",
              "B-EXPENSE_DECREASE      191\n",
              "B-PROFIT_INCREASE       164\n",
              "B-EXPENSE               150\n",
              "B-PROFIT                122\n",
              "I-PROFIT_DECLINE         93\n",
              "B-PROFIT_DECLINE         58\n",
              "I-PERCENTAGE             12\n",
              "Name: tag, dtype: int64"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data_df['tag'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lu_Kwnh28jMZ"
      },
      "source": [
        "# First, train / fine-tune a model on the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rmgghg5ZvQNE"
      },
      "source": [
        "## Iterating function to feed the model with sentences\n",
        "Converting conll sentence annotations to tuples (word, pos, tag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "JM2VMINvlpbM"
      },
      "outputs": [],
      "source": [
        "## convert conll file to sentences\n",
        "\n",
        "class SentenceGetter(object):\n",
        "    \n",
        "    def __init__(self, dataset):\n",
        "        self.n_sent = 1\n",
        "        self.dataset = dataset\n",
        "        self.empty = False\n",
        "        agg_func = lambda s: [(w,p, t) for w,p, t in zip(s[\"word\"].values.tolist(),\n",
        "                                                       s['pos'].values.tolist(),\n",
        "                                                        s[\"tag\"].values.tolist())]\n",
        "        self.grouped = self.dataset.groupby(\"sentence_idx\").apply(agg_func)\n",
        "        self.sentences = [s for s in self.grouped]\n",
        "    \n",
        "    def get_next(self):\n",
        "        try:\n",
        "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
        "            self.n_sent += 1\n",
        "            return s\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "train_getter = SentenceGetter(train_data_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIirptrGvzx5"
      },
      "source": [
        "## Getting sentences and labels\n",
        "- Sentences: concatenation of first element of tuple (word)\n",
        "- Labels: concatenation of second element of tuple (label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NqDzKVaqnfC",
        "outputId": "4eb604ca-f82c-44d6-b6b9-81f9f15e6d1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example of train sentence:\n",
            "['\\ufeff', 'In', '2019', ',', 'we', 'released', 'Evolution', ',', 'the', 'new', 'platform', 'that', 'supersedes', 'and', 'provides', 'an', 'upgrade', 'path', 'to', 'the', 'former', 'loyalty', 'and', 'CVM', 'platforms', 'from', 'both', 'Evolving', 'and', 'its', 'acquired', 'companies', '—', 'BLS', ',', 'Lumata', 'and', 'SSM', '.']\n",
            "Example of train sentence:\n",
            "['O', 'O', 'B-DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ],
      "source": [
        "# Sentences \n",
        "train_sentences = [[word[0] for word in sentence] for sentence in train_getter.sentences]\n",
        "print(\"Example of train sentence:\")\n",
        "print (train_sentences[5])\n",
        "\n",
        "# Labels\n",
        "train_labels = [[s[2] for s in sentence] for sentence in train_getter.sentences]\n",
        "print(\"Example of train sentence:\")\n",
        "print(train_labels[5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_348YlM6wIVF"
      },
      "source": [
        "## Converting tags to numeric values with a dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "0TQ27sykwKV9"
      },
      "outputs": [],
      "source": [
        "tag_values = list(set(train_data_df[\"tag\"].values))\n",
        "tag_values.append(\"PAD\")\n",
        "tag2idx = {t: i for i, t in enumerate(tag_values)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sRlF42ltmxP",
        "outputId": "f1b70234-98a2-473b-94ae-3bf17d739fe5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['B-EXPENSE_DECREASE', 'I-EXPENSE_DECREASE', 'B-EXPENSE', 'I-PERCENTAGE', 'I-PROFIT_INCREASE', 'B-PROFIT', 'O', 'I-AMOUNT', 'I-EXPENSE_INCREASE', 'B-DATE']\n",
            "{'B-EXPENSE_DECREASE': 0, 'I-EXPENSE_DECREASE': 1, 'B-EXPENSE': 2, 'I-PERCENTAGE': 3, 'I-PROFIT_INCREASE': 4, 'B-PROFIT': 5, 'O': 6, 'I-AMOUNT': 7, 'I-EXPENSE_INCREASE': 8, 'B-DATE': 9, 'I-FISCAL_YEAR': 10, 'B-PROFIT_DECLINE': 11, 'B-PERCENTAGE': 12, 'B-EXPENSE_INCREASE': 13, 'B-FISCAL_YEAR': 14, 'B-CURRENCY': 15, 'I-PROFIT': 16, 'I-EXPENSE': 17, 'B-PROFIT_INCREASE': 18, 'I-DATE': 19, 'I-PROFIT_DECLINE': 20, 'B-AMOUNT': 21, 'PAD': 22}\n"
          ]
        }
      ],
      "source": [
        "print(tag_values[:10])\n",
        "print(tag2idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQpgb6uNwTon"
      },
      "source": [
        "## Model metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llhtW7cwwXdp"
      },
      "source": [
        "### Bulding on top of biobert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "xRrXpP6eQvF1"
      },
      "outputs": [],
      "source": [
        "MODEL_TO_TRAIN = 'yiyanghkust/finbert-pretrain'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPQ1iXCkwdaZ"
      },
      "source": [
        "### Hyperparam settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "WY1vbXSdqyCJ"
      },
      "outputs": [],
      "source": [
        "# Defining some key variables that will be used later on in the training\n",
        "MAX_LEN = 256\n",
        "TRAIN_BATCH_SIZE = 32\n",
        "VALID_BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "LEARNING_RATE = 2e-05"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHkpIa-RuXH9"
      },
      "source": [
        "## Instantiating the proper tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHoIcg-8eFhn"
      },
      "source": [
        "IMPORTANT! Pay attention to the `do_lower_case` param, and set it to True if you have a lowercased language model. That means you will always need to do `lower()` on your inference texts!\n",
        "\n",
        "If the language model is not lowercase only, then leave it to False."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "4887269829b54478906e84acc017bd82",
            "a1675c0afb0a41249d918e73aaa9dea0",
            "a25351af83ed48948fc3bc5c18108ea3",
            "91ffc63947ae4246869c56b98edb74c2",
            "6db5e932281248c886a9efafe4823ead",
            "2c0371eb47cf419d82d819eb76ddf551",
            "75b5024e1b72464fbc07729f5b388800",
            "99f9dc239f344a37bc846ee4ca0074d2",
            "07070d80d39c4fada7e9595c18c510fd",
            "c2f5bf1c03d64ea4ac8809814950f303",
            "9a26a0bc46b640828a243de9e1b5f698"
          ]
        },
        "id": "GCNyWqxbuZ0U",
        "outputId": "defb1851-14ec-456d-8516-cb03436c83c8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4887269829b54478906e84acc017bd82",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(MODEL_TO_TRAIN, do_lower_case=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZ9qgZthxDpf"
      },
      "source": [
        "### Tokenize and extend the labels in case a word is split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "vgplIBl7xIeU"
      },
      "outputs": [],
      "source": [
        "def tokenize_and_preserve_labels(sentence, text_labels):\n",
        "    tokenized_sentence = []\n",
        "    labels = []\n",
        "\n",
        "    for word, label in zip(sentence, text_labels):\n",
        "\n",
        "        # Tokenize the word and count # of subwords the word is broken into\n",
        "        tokenized_word = tokenizer.tokenize(word)\n",
        "        n_subwords = len(tokenized_word)\n",
        "\n",
        "        # Add the tokenized word to the final tokenized word list\n",
        "        tokenized_sentence.extend(tokenized_word)\n",
        "\n",
        "        # Add the same label to the new list of labels `n_subwords` times\n",
        "        labels.extend([label] * n_subwords)\n",
        "\n",
        "    return tokenized_sentence, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wv2q3gLOxMLo"
      },
      "source": [
        "## Tokenize and get tokens and labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "It320LLkFve9"
      },
      "outputs": [],
      "source": [
        "train_tokenized_texts_and_labels = [\n",
        "    tokenize_and_preserve_labels(sent, labs)\n",
        "    for sent, labs in zip(train_sentences, train_labels)\n",
        "]\n",
        "\n",
        "train_tokenized_texts_tokens = [token_label_pair[0] for token_label_pair in train_tokenized_texts_and_labels]\n",
        "\n",
        "train_tokenized_texts_labels = [token_label_pair[1] for token_label_pair in train_tokenized_texts_and_labels]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZil3Wfrxm9y",
        "outputId": "f4bd86b9-3ade-4f56-d9e7-3887116f0a53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['[UNK]', '2019', ',', 'we', 'released', 'E', '##vol', '##ution', ',', 'the', 'new', 'platform', 'that', 'supersedes', 'and', 'provides', 'an', 'upgrade', 'path', 'to', 'the', 'former', 'loyalty', 'and', '[UNK]', 'platforms', 'from', 'both', 'E', '##vol', '##ving', 'and', 'its', 'acquired', 'companies', '—', '[UNK]', ',', 'L', '##umat', '##a', 'and', 'S', '##S', '##M', '.']\n",
            "['O', 'B-DATE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ],
      "source": [
        "print(train_tokenized_texts_tokens[5])\n",
        "print(train_tokenized_texts_labels[5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDKbLrQnxQCV"
      },
      "source": [
        "## Converting tokens to id && padding sentences to have fixed length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "6m89dg_yx5gN"
      },
      "outputs": [],
      "source": [
        "train_input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in train_tokenized_texts_tokens],\n",
        "                          maxlen=MAX_LEN, dtype=\"long\", value=0.0,\n",
        "                          truncating=\"post\", padding=\"post\")\n",
        "\n",
        "train_tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in train_tokenized_texts_labels],\n",
        "                     maxlen=MAX_LEN, value=tag2idx[\"PAD\"], padding=\"post\",\n",
        "                     dtype=\"long\", truncating=\"post\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-bX2-QMx6GJ",
        "outputId": "9aae04b9-e645-4c22-e1f6-42b24ba8f49a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[    2  2463   585    13  2688 30856 11634 16597   585     6    56  1241\n",
            "    15 23819     8   511    33  2661  4205     9     6  1971  5811     8\n",
            "     2  2937    23   209 30856 11634  6754     8    38   417   193  6318\n",
            "     2   585 30846 30157   363     8 30802 30690 30694    48     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0]\n",
            "[ 6  9  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
            "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6 22 22\n",
            " 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22\n",
            " 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22\n",
            " 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22\n",
            " 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22\n",
            " 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22\n",
            " 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22\n",
            " 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22\n",
            " 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22\n",
            " 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22]\n"
          ]
        }
      ],
      "source": [
        "print(train_input_ids[5])\n",
        "print(train_tags[5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2lX8dW0x44u"
      },
      "source": [
        "## Now that sentences are padded, I need to prevent attention from seeing pads (id=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "npO2QNUqyVM3"
      },
      "outputs": [],
      "source": [
        "train_attention_masks = [[float(i != 0.0) for i in ii] for ii in train_input_ids]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4utRy9BycD9",
        "outputId": "8a3badd6-efbc-473f-f7d9-80917b3ecffa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ]
        }
      ],
      "source": [
        "print(train_attention_masks[5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfjyEjT_z4p9"
      },
      "source": [
        "### Double checking that pairing input-mask is in place"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdVBi7wXzo-Y",
        "outputId": "6322cd09-6e11-448e-95cc-295d22df05ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token id: 2\\Token mask: 1.0\n",
            "Token id: 2463\\Token mask: 1.0\n",
            "Token id: 585\\Token mask: 1.0\n",
            "Token id: 13\\Token mask: 1.0\n",
            "Token id: 2688\\Token mask: 1.0\n",
            "Token id: 30856\\Token mask: 1.0\n",
            "Token id: 11634\\Token mask: 1.0\n",
            "Token id: 16597\\Token mask: 1.0\n",
            "Token id: 585\\Token mask: 1.0\n",
            "Token id: 6\\Token mask: 1.0\n",
            "Token id: 56\\Token mask: 1.0\n",
            "Token id: 1241\\Token mask: 1.0\n",
            "Token id: 15\\Token mask: 1.0\n",
            "Token id: 23819\\Token mask: 1.0\n",
            "Token id: 8\\Token mask: 1.0\n",
            "Token id: 511\\Token mask: 1.0\n",
            "Token id: 33\\Token mask: 1.0\n",
            "Token id: 2661\\Token mask: 1.0\n",
            "Token id: 4205\\Token mask: 1.0\n",
            "Token id: 9\\Token mask: 1.0\n",
            "Token id: 6\\Token mask: 1.0\n",
            "Token id: 1971\\Token mask: 1.0\n",
            "Token id: 5811\\Token mask: 1.0\n",
            "Token id: 8\\Token mask: 1.0\n",
            "Token id: 2\\Token mask: 1.0\n",
            "Token id: 2937\\Token mask: 1.0\n",
            "Token id: 23\\Token mask: 1.0\n",
            "Token id: 209\\Token mask: 1.0\n",
            "Token id: 30856\\Token mask: 1.0\n",
            "Token id: 11634\\Token mask: 1.0\n",
            "Token id: 6754\\Token mask: 1.0\n",
            "Token id: 8\\Token mask: 1.0\n",
            "Token id: 38\\Token mask: 1.0\n",
            "Token id: 417\\Token mask: 1.0\n",
            "Token id: 193\\Token mask: 1.0\n",
            "Token id: 6318\\Token mask: 1.0\n",
            "Token id: 2\\Token mask: 1.0\n",
            "Token id: 585\\Token mask: 1.0\n",
            "Token id: 30846\\Token mask: 1.0\n",
            "Token id: 30157\\Token mask: 1.0\n",
            "Token id: 363\\Token mask: 1.0\n",
            "Token id: 8\\Token mask: 1.0\n",
            "Token id: 30802\\Token mask: 1.0\n",
            "Token id: 30690\\Token mask: 1.0\n",
            "Token id: 30694\\Token mask: 1.0\n",
            "Token id: 48\\Token mask: 1.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n"
          ]
        }
      ],
      "source": [
        "for i,m in zip(train_input_ids[5], train_attention_masks[5]):\n",
        "  print(f\"Token id: {i}\\Token mask: {m}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDJYhS1BzTcl"
      },
      "source": [
        "## Arrays to tensors transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Y6rVCtHUxRXB"
      },
      "outputs": [],
      "source": [
        "tr_inputs = torch.tensor(train_input_ids)\n",
        "tr_tags = torch.tensor(train_tags)\n",
        "tr_masks = torch.tensor(train_attention_masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jrBOkO-dfFR",
        "outputId": "25539a03-998b-462b-fa01-3c8e7e67aad5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([    2,  2463,   585,    13,  2688, 30856, 11634, 16597,   585,     6,\n",
            "           56,  1241,    15, 23819,     8,   511,    33,  2661,  4205,     9,\n",
            "            6,  1971,  5811,     8,     2,  2937,    23,   209, 30856, 11634,\n",
            "         6754,     8,    38,   417,   193,  6318,     2,   585, 30846, 30157,\n",
            "          363,     8, 30802, 30690, 30694,    48,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0])\n",
            "tensor([ 6,  9,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
            "         6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
            "         6,  6,  6,  6,  6,  6,  6,  6,  6,  6, 22, 22, 22, 22, 22, 22, 22, 22,\n",
            "        22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22,\n",
            "        22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22,\n",
            "        22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22,\n",
            "        22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22,\n",
            "        22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22,\n",
            "        22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22,\n",
            "        22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22,\n",
            "        22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22,\n",
            "        22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22,\n",
            "        22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22,\n",
            "        22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22,\n",
            "        22, 22, 22, 22])\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0.])\n"
          ]
        }
      ],
      "source": [
        "print(tr_inputs[5])\n",
        "print(tr_tags[5])\n",
        "print(tr_masks[5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVWFGl4VeGi0"
      },
      "source": [
        "### Checking sizes match"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57W4P6CWeZ-s"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrJVCikMeSvl",
        "outputId": "84e2785b-ac8d-4330-879b-03cc9a59bcd4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "46"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len([x for x in tr_inputs[5] if x != 0]) # How many NO_PADs we have?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dbu7RaJEeUas",
        "outputId": "e9b908ef-99fa-4b8e-acb5-92bff5adac8d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len([x for x in tr_tags[5] if x != 7])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea9OBwxdeXXN",
        "outputId": "820b5e66-40f2-4853-c01e-e404e13ed466"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "46"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len([x for x in tr_masks[5] if x != 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3j86Os-Y0UpL"
      },
      "source": [
        "## Creating the DataLoaders to feed the batches during training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "EncfL9XT0YJv"
      },
      "outputs": [],
      "source": [
        "train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=TRAIN_BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Vpu3C-x0kZn"
      },
      "source": [
        "# Loading the transformer model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "b66ISUfG0yx_",
        "outputId": "ba4b64e3-57e9-46e3-b4ac-baa8236b4d22"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'4.8.1'"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformers.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e244fda67f0e4c3e898033587360edbd",
            "f26124a8c7344d6c82a7e9052e8e4571",
            "f4fa6aba1c5b428ebf19f181fd7e57a9",
            "bc3e8e672760445992e77e4fa671426d",
            "9df52867090a472d93318d499df931a4",
            "fc4f50b9cfd148fb833c3f038519176d",
            "2ea21e379ce440f98fe3126b749b65b0",
            "dc83c21f56f84a61be794ca68f1f8c17",
            "6930c57fc59b4005ab241c734419a6f2",
            "89fbc3e42d2e417f91906d44ec29a7b3",
            "9ea0e09ce7194a8889e9252f98c943c2",
            "e05c69812e3241f0a3d2fe20c4bde9c8",
            "3301aeda1c0f401da5943992679bb099",
            "80e604ddc961476ca3efeba2d9e51b4d",
            "7bdfca62bde84d7887afd371972d5f84",
            "d0120cf297b64aa5ada8a254c947d128",
            "e12cd827a9cb4266bce47bee28dab621",
            "8827f7723dd1405c86b44edacd4b6169",
            "9409cf24de454f3fb9f9e0b2a255c8e5",
            "934dd86b247440a8bd3f1f7c34359f60",
            "c7791d2f4b5d41fc83665669511f22d5",
            "7343e71991c3414eb424f974539a31a9"
          ]
        },
        "id": "ba70EsrqGD_u",
        "outputId": "4ef904a8-58c9-4cfd-e353-97c612a9f75f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e244fda67f0e4c3e898033587360edbd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/359 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e05c69812e3241f0a3d2fe20c4bde9c8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/442M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at yiyanghkust/finbert-pretrain were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at yiyanghkust/finbert-pretrain and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BertForTokenClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30873, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=23, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = transformers.BertForTokenClassification.from_pretrained(\n",
        "    MODEL_TO_TRAIN,\n",
        "    num_labels=len(tag2idx),\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False\n",
        ")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPsQIx1T1C1P"
      },
      "source": [
        "## Setting up the optimizer.\n",
        "We want to optimize weight values, so we add a decay.\n",
        "We can get all the weights from `model_named_parameters()`\n",
        "But we need to remove `bias`, `gamma` and `beta` which are Layer Normalization parameters we don't want to touch.\n",
        "\n",
        "Activate `FULL_TINETUNING` to modify weights in all the layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "i60zq9ZAGWBk"
      },
      "outputs": [],
      "source": [
        "FULL_FINETUNING = True\n",
        "if FULL_FINETUNING:\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = ['bias', 'gamma', 'beta']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.01},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.0}\n",
        "    ]\n",
        "else:\n",
        "    param_optimizer = list(model.classifier.named_parameters())\n",
        "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
        "\n",
        "optimizer = AdamW(\n",
        "    optimizer_grouped_parameters,\n",
        "    lr=3e-5,\n",
        "    eps=1e-8\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o107IXiT7e6F"
      },
      "source": [
        "## Setting up the scheduler\n",
        "It will manage Optimizer and Learning Rate changes. We use warmup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "j_XaydBy7iac"
      },
      "outputs": [],
      "source": [
        "epochs = EPOCHS\n",
        "max_grad_norm = 1.0\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYMOIBG0Jkx1"
      },
      "source": [
        "Now, let's train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XC7Fro7bGWI5",
        "outputId": "b23f0d39-a017-4b43-fbcf-c7e10c34e1ff"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  10%|█         | 1/10 [01:11<10:44, 71.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average train loss: 0.6457865564869001\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  20%|██        | 2/10 [02:19<09:15, 69.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping saving...\n",
            "Average train loss: 0.1852664268360688\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  30%|███       | 3/10 [03:26<07:59, 68.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping saving...\n",
            "Average train loss: 0.12597153292825589\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  40%|████      | 4/10 [04:34<06:48, 68.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping saving...\n",
            "Average train loss: 0.08897881331638648\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  50%|█████     | 5/10 [05:41<05:39, 67.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping saving...\n",
            "Average train loss: 0.06342067612478366\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  60%|██████    | 6/10 [06:55<04:39, 69.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average train loss: 0.050033402450096146\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  70%|███████   | 7/10 [08:03<03:27, 69.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping saving...\n",
            "Average train loss: 0.03976145678629669\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  80%|████████  | 8/10 [09:10<02:17, 68.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping saving...\n",
            "Average train loss: 0.0328724947758019\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  90%|█████████ | 9/10 [10:17<01:08, 68.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping saving...\n",
            "Average train loss: 0.028146676432627898\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 10/10 [11:25<00:00, 68.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping saving...\n",
            "Average train loss: 0.026173199580695767\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "## Store the average loss after each epoch so we can plot them.\n",
        "loss_values, validation_loss_values = [], []\n",
        "\n",
        "for EPOCH in trange(epochs, desc=\"Epoch\"):\n",
        "    # Put the model into training mode.\n",
        "    model.train()\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Training loop\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # add batch to gpu\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        # Always clear any previously calculated gradients before performing a backward pass.\n",
        "        model.zero_grad()\n",
        "        # forward pass\n",
        "        # This will return the loss (rather than the model output)\n",
        "        # because we have provided the `labels`.\n",
        "        outputs = model(b_input_ids, token_type_ids=None,\n",
        "                        attention_mask=b_input_mask, labels=b_labels)\n",
        "        # get the loss\n",
        "        loss = outputs[0]\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "        # track train loss\n",
        "        total_loss += loss.item()\n",
        "        # Clip the norm of the gradient\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    tr_loss = f\"Average train loss: {str(avg_train_loss)}\\n\"\n",
        "\n",
        "    if EPOCH % 5 == 0:\n",
        "      # Saving partial models (this creates the folder too)    \n",
        "      tokenizer.save_pretrained(f'{PROJECT_NAME}/{str(EPOCH)}/tokenizer/')\n",
        "      model.save_pretrained(save_directory=f'{PROJECT_NAME}/{str(EPOCH)}/',\n",
        "                            save_config=True, state_dict=model.state_dict)\n",
        "      # Saving checkpoint in case it crashes, to restore work\n",
        "      torch.save({\n",
        "          'epoch': EPOCH,\n",
        "          'model_state_dict': model.state_dict(),\n",
        "          'optimizer_state_dict': optimizer.state_dict(),\n",
        "          'loss': avg_train_loss,\n",
        "          }, f'{PROJECT_NAME}/{str(EPOCH)}/checkpoint.pth')\n",
        "    else:\n",
        "      print(\"Skipping saving...\")\n",
        "\n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "    \n",
        "    if EPOCH % 5 == 0:\n",
        "      # Saving losses log\n",
        "      with open(f'{PROJECT_NAME}/logs/epoch_' + str(EPOCH) + '_loss.log', 'a') as f:\n",
        "        f.write(tr_loss)\n",
        "\n",
        "    # Printing also to stdout\n",
        "    print(tr_loss)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czwipZWe-Esi"
      },
      "source": [
        "## Now load the model as TF and save properly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "HFNcOvu2MjWx"
      },
      "outputs": [],
      "source": [
        "last_successfull_epoch = len(loss_values) - 1\n",
        "if last_successfull_epoch < 0:\n",
        "  last_successfull_epoch = None "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1rQ4Dat-AVJ",
        "outputId": "0f6b4aec-a4ce-49c8-8700-5fe2777a39a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Last successfull epoch: 9\n"
          ]
        }
      ],
      "source": [
        "if last_successfull_epoch is None:\n",
        "  print(\"No epochs finished successfully.\")\n",
        "else:\n",
        "  print(f\"Last successfull epoch: {str(last_successfull_epoch)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "87TWLuiY-Gr7"
      },
      "outputs": [],
      "source": [
        "# first save the model as pytorch model (we'll cast later)\n",
        "MODEL_NAME_PYTORCH = 'model_epoch_'+str(last_successfull_epoch)+'_pytorch'\n",
        "MODEL_NAME_TF = 'model_epoch_'+str(last_successfull_epoch)+'_tf'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNgWBr2HAc27",
        "outputId": "a322c3b3-66d3-44f7-9ebd-6e003c35da00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model_epoch_9_pytorch\n",
            "model_epoch_9_tf\n"
          ]
        }
      ],
      "source": [
        "print(MODEL_NAME_PYTORCH)\n",
        "print(MODEL_NAME_TF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "-w-7q_Gm_aMQ"
      },
      "outputs": [],
      "source": [
        "# now load the model as TF and save properly\n",
        "from transformers import TFBertForTokenClassification\n",
        "\n",
        "tokenizer.save_pretrained(f'./{PROJECT_NAME}/{MODEL_NAME_PYTORCH}_tokenizer/')\n",
        "model.save_pretrained(f'./{PROJECT_NAME}/{MODEL_NAME_PYTORCH}', saved_model=True, save_format='tf')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "8Y-k7w4WfgKv"
      },
      "source": [
        "**IMPORTANT** If it's a domain-specific model, we need to use an interface to load and save it, that will change the input_signature so that it can only be loaded with sparknlp_jsl.xx.XXBertForTokenClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "HY4S985IfgKv"
      },
      "outputs": [],
      "source": [
        "from transformers import TFBertForTokenClassification\n",
        "import tensorflow as tf\n",
        "\n",
        "# Creation of a subclass in order to define a new serving signature\n",
        "class DomainSpecificModel(TFBertForTokenClassification):\n",
        "    # Decorate the serving method with the new input_signature\n",
        "    # an input_signature represents the name, the data type and the shape of an expected input\n",
        "    @tf.function(input_signature=[{\n",
        "        \"input_ids\": tf.TensorSpec((None, None), tf.int32, name=\"medical_input_ids\"),\n",
        "        \"attention_mask\": tf.TensorSpec((None, None), tf.int32, name=\"attention_mask\"),\n",
        "        \"token_type_ids\": tf.TensorSpec((None, None), tf.int32, name=\"token_type_ids\"),\n",
        "\n",
        "    }])\n",
        "    def serving(self, inputs):\n",
        "        # call the model to process the inputs\n",
        "        output = self.call(inputs)\n",
        "\n",
        "        # return the formated output\n",
        "        return self.serving_output(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-L76A2yrfgKv",
        "outputId": "34729956-e5ce-4699-f421-14465ca39a2d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model DomainSpecificModel: ['bert.embeddings.position_ids']\n",
            "- This IS expected if you are initializing DomainSpecificModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DomainSpecificModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of DomainSpecificModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use DomainSpecificModel for predictions without further training.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x7efc7ec00e20>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x7efc7ec00e20>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, add_layer_call_fn while saving (showing 5 of 418). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "loaded_model = DomainSpecificModel.from_pretrained(f'./{PROJECT_NAME}/{MODEL_NAME_PYTORCH}', from_pt=True)\n",
        "loaded_model.save_pretrained(f'./{PROJECT_NAME}/{MODEL_NAME_TF}', saved_model=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWE0rH_8KFEE"
      },
      "source": [
        "### Save label mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuJfZcF_OSaR",
        "outputId": "208b0338-6cd1-4511-ed82-60a7670a5538"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['B-EXPENSE_DECREASE', 'I-EXPENSE_DECREASE', 'B-EXPENSE', 'I-PERCENTAGE', 'I-PROFIT_INCREASE', 'B-PROFIT', 'O', 'I-AMOUNT', 'I-EXPENSE_INCREASE', 'B-DATE', 'I-FISCAL_YEAR', 'B-PROFIT_DECLINE', 'B-PERCENTAGE', 'B-EXPENSE_INCREASE', 'B-FISCAL_YEAR', 'B-CURRENCY', 'I-PROFIT', 'I-EXPENSE', 'B-PROFIT_INCREASE', 'I-DATE', 'I-PROFIT_DECLINE', 'B-AMOUNT', 'PAD']\n"
          ]
        }
      ],
      "source": [
        "labels = sorted(tag2idx, key=tag2idx.get)\n",
        "\n",
        "print (labels)\n",
        "\n",
        "with open(f'./{PROJECT_NAME}/{MODEL_NAME_TF}/saved_model/1/assets/labels.txt', 'w') as f:\n",
        "    f.write('\\n'.join(labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP_erIY_KIbS"
      },
      "source": [
        "### Copy files in tf model's assets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "eITuMKj8MxNS"
      },
      "outputs": [],
      "source": [
        "vocab_pth = f\"./{PROJECT_NAME}/{MODEL_NAME_PYTORCH}_tokenizer/vocab.txt\"\n",
        "saved_model_pth = f'./{PROJECT_NAME}/{MODEL_NAME_TF}/saved_model/1/assets/'\n",
        "\n",
        "! cp $vocab_pth $saved_model_pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mg2tkES9KQPW"
      },
      "source": [
        "# Now load the saved model in Spark NLP and save it properly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "ajwSmwj1QtIo"
      },
      "outputs": [],
      "source": [
        "domain = 'FINANCE' # or 'FINANCE' or 'OPENSOURCE'\n",
        "\n",
        "if domain == 'OPENSOURCE':\n",
        "  classifier_class = BertForTokenClassification\n",
        "elif domain == 'LEGAL':\n",
        "  classifier_class = sparknlp_jsl.legal.LegalBertForTokenClassification\n",
        "  classifier_classpath = \"com.johnsnowlabs.legal.token_classification.ner.LegalBertForTokenClassification\"\n",
        "elif domain == 'FINANCE':\n",
        "  classifier_class = sparknlp_jsl.finance.FinanceBertForTokenClassification\n",
        "  classifier_classpath = \"com.johnsnowlabs.finance.token_classification.ner.FinanceBertForTokenClassification\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwWTOxyjdCGc",
        "outputId": "f0b3463b-259e-4e1e-aec9-64998bef3d3b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "sparknlp_jsl.finance.token_classification.ner.finance_bert_for_token_classifier.FinanceBertForTokenClassification"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifier_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EhYAoarme2pT",
        "outputId": "d82debda-91b9-4afd-9346-97b50420d2f8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'com.johnsnowlabs.finance.token_classification.ner.FinanceBertForTokenClassification'"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifier_classpath"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "OqrmF3dkGWNY"
      },
      "outputs": [],
      "source": [
        "from sparknlp.annotator import *\n",
        "from sparknlp_jsl.annotator import *\n",
        "\n",
        "# For Finance\n",
        "tokenClassifier = classifier_class.loadSavedModel(\n",
        "     f'./{PROJECT_NAME}/{MODEL_NAME_TF}/saved_model/1',\n",
        "     spark\n",
        " )\\\n",
        " .setInputCols([\"sentence\",'token'])\\\n",
        "  .setOutputCol(\"ner\")\\\n",
        "  .setCaseSensitive(True)\\\n",
        "  .setMaxSentenceLength(256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "AT8Fo_lQGWP7"
      },
      "outputs": [],
      "source": [
        "tokenClassifier.write().overwrite().save(f\"./{PROJECT_NAME}/{MODEL_NAME_TF}_spark_nlp\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "uL_5pv6rd8pV"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "with open(f\"./{PROJECT_NAME}/{MODEL_NAME_TF}_spark_nlp/metadata/part-00000\", 'r') as fr:\n",
        "  metadata = json.load(fr)\n",
        "metadata['class'] = classifier_classpath\n",
        "with open(f\"./{PROJECT_NAME}/{MODEL_NAME_TF}_spark_nlp/metadata/part-00000\", 'w') as fw:\n",
        "  metadata = json.dump(metadata, fw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "tA8sNacgiBgj"
      },
      "outputs": [],
      "source": [
        "!rm ./{PROJECT_NAME}/{MODEL_NAME_TF}_spark_nlp/metadata/.*.crc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jn8AJPDxiJhc",
        "outputId": "4f8518aa-e276-402e-8303-c804be659ae4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 12K\n",
            "drwxr-xr-x 2 root root 4.0K Jan 12 18:08 .\n",
            "drwxr-xr-x 4 root root 4.0K Jan 12 18:08 ..\n",
            "-rw-r--r-- 1 root root  479 Jan 12 18:08 part-00000\n",
            "-rw-r--r-- 1 root root    0 Jan 12 18:07 _SUCCESS\n"
          ]
        }
      ],
      "source": [
        "!ls -lah ./{PROJECT_NAME}/{MODEL_NAME_TF}_spark_nlp/metadata/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54WOuCvoKaN7"
      },
      "source": [
        "# Test the imported model in Spark NLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "Qh87bK58tw5y"
      },
      "outputs": [],
      "source": [
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "documentAssembler = DocumentAssembler()\\\n",
        "  .setInputCol(\"text\")\\\n",
        "  .setOutputCol(\"document\")\n",
        "\n",
        "sparktokenizer = Tokenizer()\\\n",
        "  .setInputCols(\"document\")\\\n",
        "  .setOutputCol(\"token\")\n",
        "\n",
        "from sparknlp_jsl.annotator import *\n",
        "\n",
        "tokenClassifier = classifier_class.load(f\"./{PROJECT_NAME}/{MODEL_NAME_TF}_spark_nlp\")\\\n",
        "  .setInputCols(\"token\", \"document\")\\\n",
        "  .setOutputCol(\"label\")\\\n",
        "  .setCaseSensitive(True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "UGOV6Oik3jGc"
      },
      "outputs": [],
      "source": [
        "pipeline =  Pipeline(stages=[\n",
        "  documentAssembler,\n",
        "  sparktokenizer,\n",
        "  tokenClassifier\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "PPG-J1D6CuUj"
      },
      "outputs": [],
      "source": [
        "p_model = pipeline.fit(spark.createDataFrame(pd.DataFrame({'text': ['']})))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_nGP7YVQIxv",
        "outputId": "4d5c8243-6cc9-4fa4-9397-868153240337"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "|                text|            document|               token|               label|\n",
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "|In 2019 we releas...|[{document, 0, 65...|[{token, 0, 1, In...|[{named_entity, 0...|\n",
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "text = \"\"\"In 2019 we released Evolution, the new platform that supersedes...\"\"\"\n",
        "res = p_model.transform(spark.createDataFrame([[text]]).toDF(\"text\"))\n",
        "\n",
        "res.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhqNplVEEjs_",
        "outputId": "f6004ba0-ba3f-46e9-880a-707a4d8f6fd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+---------+\n",
            "|     token|ner_label|\n",
            "+----------+---------+\n",
            "|        In|   B-DATE|\n",
            "|      2019|   B-DATE|\n",
            "|        we|        O|\n",
            "|  released|        O|\n",
            "| Evolution|        O|\n",
            "|         ,|        O|\n",
            "|       the|        O|\n",
            "|       new|        O|\n",
            "|  platform|        O|\n",
            "|      that|        O|\n",
            "|supersedes|        O|\n",
            "|       ...|        O|\n",
            "+----------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "res.select(F.explode(F.arrays_zip('token.result', 'label.result')).alias(\"cols\")) \\\n",
        "               .select(F.expr(\"cols['0']\").alias(\"token\"),\n",
        "                       F.expr(\"cols['1']\").alias(\"ner_label\"))\\\n",
        "               .show(20, truncate=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "fsttvgU5Akgf"
      },
      "outputs": [],
      "source": [
        "os.environ['SPARKNLP_TF_MODEL'] = MODEL_NAME_TF + \"_spark_nlp\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4_1fh_tFhls",
        "outputId": "a395aca8-e5fa-48ba-d214-ce6021c58fbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: model_epoch_9_tf_spark_nlp/ (stored 0%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/bert_classification_tensorflow (deflated 8%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/metadata/ (stored 0%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/metadata/_SUCCESS (stored 0%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/metadata/part-00000 (deflated 39%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/fields/ (stored 0%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/fields/labels/ (stored 0%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/fields/labels/part-00001 (deflated 53%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/fields/labels/._SUCCESS.crc (stored 0%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/fields/labels/_SUCCESS (stored 0%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/fields/labels/part-00000 (deflated 51%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/fields/labels/.part-00000.crc (stored 0%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/fields/labels/.part-00001.crc (stored 0%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/fields/signatures/ (stored 0%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/fields/signatures/part-00001 (deflated 29%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/fields/signatures/._SUCCESS.crc (stored 0%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/fields/signatures/_SUCCESS (stored 0%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/fields/signatures/part-00000 (deflated 31%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/fields/signatures/.part-00000.crc (stored 0%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/fields/signatures/.part-00001.crc (stored 0%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/fields/vocabulary/ (stored 0%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/fields/vocabulary/part-00001 (deflated 78%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/fields/vocabulary/._SUCCESS.crc (stored 0%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/fields/vocabulary/_SUCCESS (stored 0%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/fields/vocabulary/part-00000 (deflated 78%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/fields/vocabulary/.part-00000.crc (stored 0%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/fields/vocabulary/.part-00001.crc (stored 0%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/.bert_classification_tensorflow.crc (deflated 0%)\n"
          ]
        }
      ],
      "source": [
        "!cd $PROJECT_NAME && zip -r $PROJECT_NAME.zip $SPARKNLP_TF_MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88WTHot2z2cR"
      },
      "source": [
        "# MOUNT DRIVE AND SAVE YOUR MODEL TO IT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dzn-fkwftWnP",
        "outputId": "e5903671-768b-456a-fb42-5a5a413a532b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "f66fQFr6tlKK"
      },
      "outputs": [],
      "source": [
        "!cp financial_operations/financial_operations.zip /content/gdrive/MyDrive/"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "07070d80d39c4fada7e9595c18c510fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2c0371eb47cf419d82d819eb76ddf551": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ea21e379ce440f98fe3126b749b65b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3301aeda1c0f401da5943992679bb099": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e12cd827a9cb4266bce47bee28dab621",
            "placeholder": "​",
            "style": "IPY_MODEL_8827f7723dd1405c86b44edacd4b6169",
            "value": "Downloading: 100%"
          }
        },
        "4887269829b54478906e84acc017bd82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a1675c0afb0a41249d918e73aaa9dea0",
              "IPY_MODEL_a25351af83ed48948fc3bc5c18108ea3",
              "IPY_MODEL_91ffc63947ae4246869c56b98edb74c2"
            ],
            "layout": "IPY_MODEL_6db5e932281248c886a9efafe4823ead"
          }
        },
        "6930c57fc59b4005ab241c734419a6f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6db5e932281248c886a9efafe4823ead": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7343e71991c3414eb424f974539a31a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75b5024e1b72464fbc07729f5b388800": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bdfca62bde84d7887afd371972d5f84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7791d2f4b5d41fc83665669511f22d5",
            "placeholder": "​",
            "style": "IPY_MODEL_7343e71991c3414eb424f974539a31a9",
            "value": " 442M/442M [00:06&lt;00:00, 74.1MB/s]"
          }
        },
        "80e604ddc961476ca3efeba2d9e51b4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9409cf24de454f3fb9f9e0b2a255c8e5",
            "max": 441551705,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_934dd86b247440a8bd3f1f7c34359f60",
            "value": 441551705
          }
        },
        "8827f7723dd1405c86b44edacd4b6169": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89fbc3e42d2e417f91906d44ec29a7b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91ffc63947ae4246869c56b98edb74c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2f5bf1c03d64ea4ac8809814950f303",
            "placeholder": "​",
            "style": "IPY_MODEL_9a26a0bc46b640828a243de9e1b5f698",
            "value": " 226k/226k [00:00&lt;00:00, 316kB/s]"
          }
        },
        "934dd86b247440a8bd3f1f7c34359f60": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9409cf24de454f3fb9f9e0b2a255c8e5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99f9dc239f344a37bc846ee4ca0074d2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a26a0bc46b640828a243de9e1b5f698": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9df52867090a472d93318d499df931a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ea0e09ce7194a8889e9252f98c943c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1675c0afb0a41249d918e73aaa9dea0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c0371eb47cf419d82d819eb76ddf551",
            "placeholder": "​",
            "style": "IPY_MODEL_75b5024e1b72464fbc07729f5b388800",
            "value": "Downloading: 100%"
          }
        },
        "a25351af83ed48948fc3bc5c18108ea3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99f9dc239f344a37bc846ee4ca0074d2",
            "max": 226122,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_07070d80d39c4fada7e9595c18c510fd",
            "value": 226122
          }
        },
        "bc3e8e672760445992e77e4fa671426d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89fbc3e42d2e417f91906d44ec29a7b3",
            "placeholder": "​",
            "style": "IPY_MODEL_9ea0e09ce7194a8889e9252f98c943c2",
            "value": " 359/359 [00:00&lt;00:00, 14.9kB/s]"
          }
        },
        "c2f5bf1c03d64ea4ac8809814950f303": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7791d2f4b5d41fc83665669511f22d5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0120cf297b64aa5ada8a254c947d128": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc83c21f56f84a61be794ca68f1f8c17": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e05c69812e3241f0a3d2fe20c4bde9c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3301aeda1c0f401da5943992679bb099",
              "IPY_MODEL_80e604ddc961476ca3efeba2d9e51b4d",
              "IPY_MODEL_7bdfca62bde84d7887afd371972d5f84"
            ],
            "layout": "IPY_MODEL_d0120cf297b64aa5ada8a254c947d128"
          }
        },
        "e12cd827a9cb4266bce47bee28dab621": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e244fda67f0e4c3e898033587360edbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f26124a8c7344d6c82a7e9052e8e4571",
              "IPY_MODEL_f4fa6aba1c5b428ebf19f181fd7e57a9",
              "IPY_MODEL_bc3e8e672760445992e77e4fa671426d"
            ],
            "layout": "IPY_MODEL_9df52867090a472d93318d499df931a4"
          }
        },
        "f26124a8c7344d6c82a7e9052e8e4571": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc4f50b9cfd148fb833c3f038519176d",
            "placeholder": "​",
            "style": "IPY_MODEL_2ea21e379ce440f98fe3126b749b65b0",
            "value": "Downloading: 100%"
          }
        },
        "f4fa6aba1c5b428ebf19f181fd7e57a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc83c21f56f84a61be794ca68f1f8c17",
            "max": 359,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6930c57fc59b4005ab241c734419a6f2",
            "value": 359
          }
        },
        "fc4f50b9cfd148fb833c3f038519176d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
