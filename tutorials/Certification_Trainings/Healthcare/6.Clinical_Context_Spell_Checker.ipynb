{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6.Clinical_Context_Spell_Checker.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2muvLzlqdcva"
      },
      "source": [
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2A9se0Bdcvb"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/6.Clinical_Context_Spell_Checker.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orznscn3dcvc"
      },
      "source": [
        "<H1> 6. Context Spell Checker - Medical </H1>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7bQfnRUdcvd"
      },
      "source": [
        "import json, os\n",
        "from google.colab import files\n",
        "\n",
        "license_keys = files.upload()\n",
        "\n",
        "with open(list(license_keys.keys())[0]) as f:\n",
        "    license_keys = json.load(f)\n",
        "\n",
        "# Defining license key-value pairs as local variables\n",
        "locals().update(license_keys)\n",
        "\n",
        "# Adding license key-value pairs to environment variables\n",
        "os.environ.update(license_keys)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXEqkSp9RFkN"
      },
      "source": [
        "# Installing pyspark and spark-nlp\n",
        "! pip install --upgrade -q pyspark==3.1.2 spark-nlp==$PUBLIC_VERSION\n",
        "\n",
        "# Installing Spark NLP Healthcare\n",
        "! pip install --upgrade -q spark-nlp-jsl==$JSL_VERSION  --extra-index-url https://pypi.johnsnowlabs.com/$SECRET"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2EWnyIOQZPI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cd23166-b609-450a-db73-15f281083538"
      },
      "source": [
        "import json\n",
        "import os\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp_jsl.annotator import *\n",
        "from sparknlp.base import *\n",
        "import sparknlp_jsl\n",
        "import sparknlp\n",
        "\n",
        "\n",
        "params = {\"spark.driver.memory\":\"16G\",\n",
        "\"spark.kryoserializer.buffer.max\":\"2000M\",\n",
        "\"spark.driver.maxResultSize\":\"2000M\"}\n",
        "\n",
        "spark = sparknlp_jsl.start(license_keys['SECRET'],params=params)\n",
        "\n",
        "print (\"Spark NLP Version :\", sparknlp.version())\n",
        "print (\"Spark NLP_JSL Version :\", sparknlp_jsl.version())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP Version : 3.3.0\n",
            "Spark NLP_JSL Version : 3.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l70_9DOgdcvz",
        "scrolled": true,
        "outputId": "ddb3b4b3-e6a8-4701-c8cc-d4684cacbdc8"
      },
      "source": [
        "documentAssembler = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "tokenizer = RecursiveTokenizer()\\\n",
        "    .setInputCols([\"document\"])\\\n",
        "    .setOutputCol(\"token\")\\\n",
        "    .setPrefixes([\"\\\"\", \"(\", \"[\", \"\\n\"])\\\n",
        "    .setSuffixes([\".\", \",\", \"?\", \")\",\"!\", \"'s\"])\n",
        "\n",
        "spellModel = ContextSpellCheckerModel\\\n",
        "    .pretrained('spellcheck_clinical', 'en', 'clinical/models')\\\n",
        "    .setInputCols(\"token\")\\\n",
        "    .setOutputCol(\"checked\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spellcheck_clinical download started this may take some time.\n",
            "Approximate size to download 142.2 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyqbEdoPdcv-",
        "scrolled": true
      },
      "source": [
        "pipeline = Pipeline(\n",
        "    stages = [\n",
        "    documentAssembler,\n",
        "    tokenizer,\n",
        "    spellModel\n",
        "  ])\n",
        "\n",
        "empty_ds = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
        "\n",
        "lp = LightPipeline(pipeline.fit(empty_ds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49DMo2sQdcwC"
      },
      "source": [
        "Ok!, at this point we have our spell checking pipeline as expected. Let's see what we can do with it, see these errors,\n",
        "\n",
        "_\n",
        "__Witth__ the __hell__ of __phisical__ __terapy__ the patient was __imbulated__ and on posoperative, the __impatient__ tolerating a post __curgical__ soft diet._\n",
        "\n",
        "_With __paint__ __wel__ controlled on __orall__ pain medications, she was discharged __too__ __reihabilitation__ __facilitay__._\n",
        "\n",
        "_She is to also call the __ofice__ if she has any __ever__ greater than 101, or __leeding__ __form__ the surgical wounds._\n",
        "\n",
        "_Abdomen is __sort__, nontender, and __nonintended__._\n",
        "            \n",
        "_No __cute__ distress_\n",
        "\n",
        "Check that some of the errors are valid English words, only by considering the context the right choice can be made."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2BuhiZNHGhH",
        "outputId": "0bb60a92-e58a-4347-ba60-6502210827f1"
      },
      "source": [
        "example = [\"Witth the hell of phisical terapy the patient was imbulated and on posoperative, the impatient tolerating a post curgical soft diet.\",\n",
        "            \"With paint wel controlled on orall pain medications, she was discharged too reihabilitation facilitay.\",\n",
        "            \"She is to also call the ofice if she has any ever greater than 101, or leeding form the surgical wounds.\",\n",
        "            \"Abdomen is sort, nontender, and nonintended.\",\n",
        "            \"Patient not showing pain or any wealth problems.\",\n",
        "            \"No cute distress\"\n",
        "            \n",
        "]\n",
        "\n",
        "for pairs in lp.annotate(example):\n",
        "\n",
        "  print (list(zip(pairs['token'],pairs['checked'])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Witth', 'With'), ('the', 'the'), ('hell', 'cell'), ('of', 'of'), ('phisical', 'physical'), ('terapy', 'therapy'), ('the', 'the'), ('patient', 'patient'), ('was', 'was'), ('imbulated', 'ambulated'), ('and', 'and'), ('on', 'on'), ('posoperative', 'postoperative'), (',', ','), ('the', 'the'), ('impatient', 'inpatient'), ('tolerating', 'tolerating'), ('a', 'a'), ('post', 'post'), ('curgical', 'surgical'), ('soft', 'soft'), ('diet', 'diet'), ('.', '.')]\n",
            "[('With', 'With'), ('paint', 'paint'), ('wel', 'well'), ('controlled', 'controlled'), ('on', 'on'), ('orall', 'oral'), ('pain', 'pain'), ('medications', 'medications'), (',', ','), ('she', 'she'), ('was', 'was'), ('discharged', 'discharged'), ('too', 'too'), ('reihabilitation', 'rehabilitation'), ('facilitay', 'facility'), ('.', '.')]\n",
            "[('She', 'She'), ('is', 'is'), ('to', 'to'), ('also', 'also'), ('call', 'call'), ('the', 'the'), ('ofice', 'office'), ('if', 'if'), ('she', 'she'), ('has', 'has'), ('any', 'any'), ('ever', 'ever'), ('greater', 'greater'), ('than', 'than'), ('101', '101'), (',', ','), ('or', 'or'), ('leeding', 'leading'), ('form', 'form'), ('the', 'the'), ('surgical', 'surgical'), ('wounds', 'wounds'), ('.', '.')]\n",
            "[('Abdomen', 'Abdomen'), ('is', 'is'), ('sort', 'sort'), (',', ','), ('nontender', 'nontender'), (',', ','), ('and', 'and'), ('nonintended', 'unintended'), ('.', '.')]\n",
            "[('Patient', 'Patient'), ('not', 'not'), ('showing', 'showing'), ('pain', 'pain'), ('or', 'or'), ('any', 'any'), ('wealth', 'wealth'), ('problems', 'problems'), ('.', '.')]\n",
            "[('No', 'No'), ('cute', 'acute'), ('distress', 'distress')]\n"
          ]
        }
      ]
    }
  ]
}