{"cells":[{"cell_type":"markdown","metadata":{"id":"2muvLzlqdcva"},"source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"]},{"cell_type":"markdown","metadata":{"id":"A2A9se0Bdcvb"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/6.Clinical_Context_Spell_Checker.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"orznscn3dcvc"},"source":["<H1> 6. Context Spell Checker - Medical </H1>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U7bQfnRUdcvd"},"outputs":[],"source":["import json, os\n","from google.colab import files\n","\n","if 'spark_jsl.json' not in os.listdir():\n","  license_keys = files.upload()\n","  os.rename(list(license_keys.keys())[0], 'spark_jsl.json')\n","\n","with open('spark_jsl.json') as f:\n","    license_keys = json.load(f)\n","\n","# Defining license key-value pairs as local variables\n","locals().update(license_keys)\n","os.environ.update(license_keys)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZXEqkSp9RFkN"},"outputs":[],"source":["# Installing pyspark and spark-nlp\n","! pip install --upgrade -q pyspark==3.3.0 spark-nlp==$PUBLIC_VERSION\n","\n","# Installing Spark NLP Healthcare\n","! pip install --upgrade -q spark-nlp-jsl==$JSL_VERSION  --extra-index-url https://pypi.johnsnowlabs.com/$SECRET"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"H2EWnyIOQZPI","colab":{"base_uri":"https://localhost:8080/","height":257},"executionInfo":{"status":"ok","timestamp":1680974087883,"user_tz":240,"elapsed":44806,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"}},"outputId":"75aefe8b-04e0-4d38-c2cc-40b3069c7363"},"outputs":[{"output_type":"stream","name":"stdout","text":["Spark NLP Version : 4.3.2\n","Spark NLP_JSL Version : 4.3.2\n"]},{"output_type":"execute_result","data":{"text/plain":["<pyspark.sql.session.SparkSession at 0x7fb6fb584430>"],"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://c62841d08c5d:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.3.0</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>Spark NLP Licensed</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "]},"metadata":{},"execution_count":3}],"source":["import json\n","import os\n","\n","import sparknlp\n","import sparknlp_jsl\n","\n","from sparknlp.base import *\n","from sparknlp.annotator import *\n","from sparknlp_jsl.annotator import *\n","\n","from pyspark.ml import Pipeline\n","from pyspark.sql import SparkSession\n","\n","params = {\"spark.driver.memory\":\"16G\",\n","          \"spark.kryoserializer.buffer.max\":\"2000M\",\n","          \"spark.driver.maxResultSize\":\"2000M\"}\n","\n","spark = sparknlp_jsl.start(license_keys['SECRET'],params=params)\n","\n","print(\"Spark NLP Version :\", sparknlp.version())\n","print(\"Spark NLP_JSL Version :\", sparknlp_jsl.version())\n","\n","spark"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"l70_9DOgdcvz","scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680974167473,"user_tz":240,"elapsed":79614,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"}},"outputId":"daf4ded6-c58c-4b39-d94d-810fa1c8a297"},"outputs":[{"output_type":"stream","name":"stdout","text":["spellcheck_clinical download started this may take some time.\n","Approximate size to download 134.7 MB\n","[OK!]\n"]}],"source":["documentAssembler = DocumentAssembler()\\\n","    .setInputCol(\"text\")\\\n","    .setOutputCol(\"document\")\n","\n","tokenizer = RecursiveTokenizer()\\\n","    .setInputCols([\"document\"])\\\n","    .setOutputCol(\"token\")\\\n","    .setPrefixes([\"\\\"\", \"(\", \"[\", \"\\n\"])\\\n","    .setSuffixes([\".\", \",\", \"?\", \")\",\"!\", \"'s\"])\n","\n","spellModel = ContextSpellCheckerModel\\\n","    .pretrained('spellcheck_clinical', 'en', 'clinical/models')\\\n","    .setInputCols(\"token\")\\\n","    .setOutputCol(\"checked\")"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"XyqbEdoPdcv-","scrolled":true,"executionInfo":{"status":"ok","timestamp":1680974173387,"user_tz":240,"elapsed":5930,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"}}},"outputs":[],"source":["pipeline = Pipeline(\n","    stages = [\n","    documentAssembler,\n","    tokenizer,\n","    spellModel\n","    ])\n","\n","empty_ds = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n","\n","lp = LightPipeline(pipeline.fit(empty_ds))"]},{"cell_type":"markdown","metadata":{"id":"49DMo2sQdcwC"},"source":["Ok!, at this point we have our spell checking pipeline as expected. Let's see what we can do with it, see these errors,\n","\n","_She was **treathed** with a five day course of **amoxicilin** for a **resperatory** **truct** infection._\n","\n","_With pain well controlled on **orall** **meditation**, she was discharged to **reihabilitation** **facilitay**._\n","\n","\n","_Her **adominal** examination is soft, nontender, and **nonintended**_\n","\n","_The patient was seen by the **entocrinology** service and she was discharged on 40 units of **unsilin** glargine at night_\n","      \n","_No __cute__ distress_\n","\n","Check that some of the errors are valid English words, only by considering the context the right choice can be made."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"K2BuhiZNHGhH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680974177464,"user_tz":240,"elapsed":4106,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"}},"outputId":"99d9ef75-e945-480d-d624-cfaf960e7766"},"outputs":[{"output_type":"stream","name":"stdout","text":["[('She', 'She'), ('was', 'was'), ('treathed', 'treated'), ('with', 'with'), ('a', 'a'), ('five', 'five'), ('day', 'day'), ('course', 'course'), ('of', 'of'), ('amoxicilin', 'amoxicillin'), ('for', 'for'), ('a', 'a'), ('resperatory', 'respiratory'), ('truct', 'tract'), ('infection', 'infection'), ('.', '.')]\n","[('With', 'With'), ('pain', 'pain'), ('well', 'well'), ('controlled', 'controlled'), ('on', 'on'), ('orall', 'oral'), ('meditation', 'medication'), (',', ','), ('she', 'she'), ('was', 'was'), ('discharged', 'discharged'), ('to', 'to'), ('reihabilitation', 'rehabilitation'), ('facilitay', 'facility'), ('.', '.')]\n","[('Her', 'Her'), ('adominal', 'abdominal'), ('examination', 'examination'), ('is', 'is'), ('soft', 'soft'), (',', ','), ('nontender', 'nontender'), (',', ','), ('and', 'and'), ('nonintended', 'nondistended'), ('.', '.')]\n","[('The', 'The'), ('patient', 'patient'), ('was', 'was'), ('seen', 'seen'), ('by', 'by'), ('the', 'the'), ('entocrinology', 'endocrinology'), ('service', 'service'), ('and', 'and'), ('she', 'she'), ('was', 'was'), ('discharged', 'discharged'), ('on', 'on'), ('40', '40'), ('units', 'units'), ('of', 'of'), ('unsilin', 'insulin'), ('glargine', 'glargine'), ('at', 'at'), ('night', 'night')]\n","[('No', 'No'), ('cute', 'acute'), ('distress', 'distress')]\n"]}],"source":["example = [\"She was treathed with a five day course of amoxicilin for a resperatory truct infection . \",\n","           \"With pain well controlled on orall meditation, she was discharged to reihabilitation facilitay.\",\n","           \"Her adominal examination is soft, nontender, and nonintended.\",\n","           \"The patient was seen by the entocrinology service and she was discharged on 40 units of unsilin glargine at night\",\n","           \"No cute distress\",\n","          ]\n","\n","for pairs in lp.annotate(example):\n","    print(list(zip(pairs['token'],pairs['checked'])))"]},{"cell_type":"code","source":["print(\"Corrected tokens:\\n\")\n","\n","pair_list = [list(zip(pairs['token'],pairs['checked'])) for pairs in lp.annotate(example)]\n","corrected_list = [i for pair in pair_list for i in pair if i[0] != i[1]]\n","corrected_list"],"metadata":{"id":"fO3uGXHzI8FC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680974183166,"user_tz":240,"elapsed":5717,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"}},"outputId":"fdb06d6a-3840-498d-852a-63d4d220972b"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Corrected tokens:\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["[('treathed', 'treated'),\n"," ('amoxicilin', 'amoxicillin'),\n"," ('resperatory', 'respiratory'),\n"," ('truct', 'tract'),\n"," ('orall', 'oral'),\n"," ('meditation', 'medication'),\n"," ('reihabilitation', 'rehabilitation'),\n"," ('facilitay', 'facility'),\n"," ('adominal', 'abdominal'),\n"," ('nonintended', 'nondistended'),\n"," ('entocrinology', 'endocrinology'),\n"," ('unsilin', 'insulin'),\n"," ('cute', 'acute')]"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":[],"metadata":{"id":"IwkuugRpHda3"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}