{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drug Adverse Effect Classifier\n",
    "\n",
    "Spark NLP v 2.4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import *\n",
    "from sparknlp.common import *\n",
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "      <th>description</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20178709</td>\n",
       "      <td>A case of aseptic pleuropericarditis in a pati...</td>\n",
       "      <td>AE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20178709</td>\n",
       "      <td>Methotrexate may rarely provoke serositis, eve...</td>\n",
       "      <td>AE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20178709</td>\n",
       "      <td>We report here a rare case of pleuropericardit...</td>\n",
       "      <td>AE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20178709</td>\n",
       "      <td>The effusion resolved after the withdrawal of ...</td>\n",
       "      <td>Neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7957364</td>\n",
       "      <td>Teratogenic effects in a case of maternal trea...</td>\n",
       "      <td>Neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PMID                                        description category\n",
       "0  20178709  A case of aseptic pleuropericarditis in a pati...       AE\n",
       "1  20178709  Methotrexate may rarely provoke serositis, eve...       AE\n",
       "2  20178709  We report here a rare case of pleuropericardit...       AE\n",
       "3  20178709  The effusion resolved after the withdrawal of ...      Neg\n",
       "4   7957364  Teratogenic effects in a case of maternal trea...      Neg"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ade_df = pd.read_pickle('data/ade_binary.pickle')\n",
    "ade_df.columns=['PMID','description','category']\n",
    "\n",
    "ade_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neg    16815\n",
       "AE      4262\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ade_df.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 16855\n",
      "Test Dataset Count: 4222\n"
     ]
    }
   ],
   "source": [
    "spark_df = spark.createDataFrame(ade_df)\n",
    "\n",
    "(trainingData, testData) = spark_df.randomSplit([0.8, 0.2], seed = 100)\n",
    "\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text cleaning in Spark NLP and CV + LogReg with Spark ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer, HashingTF, IDF, OneHotEncoder, StringIndexer, VectorAssembler, SQLTransformer\n",
    "\n",
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"description\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "    \n",
    "tokenizer = Tokenizer() \\\n",
    "  .setInputCols([\"document\"]) \\\n",
    "  .setOutputCol(\"token\")\n",
    "    \n",
    "normalizer = Normalizer() \\\n",
    "    .setInputCols([\"token\"]) \\\n",
    "    .setOutputCol(\"normalized\")\n",
    "\n",
    "stopwords_cleaner = StopWordsCleaner()\\\n",
    "      .setInputCols(\"normalized\")\\\n",
    "      .setOutputCol(\"cleanTokens\")\\\n",
    "      .setCaseSensitive(False)\n",
    "\n",
    "stemmer = Stemmer() \\\n",
    "    .setInputCols([\"cleanTokens\"]) \\\n",
    "    .setOutputCol(\"stem\")\n",
    "\n",
    "finisher = Finisher() \\\n",
    "    .setInputCols([\"stem\"]) \\\n",
    "    .setOutputCols([\"token_features\"]) \\\n",
    "    .setOutputAsArray(True) \\\n",
    "    .setCleanAnnotations(False)\n",
    "\n",
    "countVectors = CountVectorizer(inputCol=\"token_features\", outputCol=\"features\", vocabSize=10000, minDF=5)\n",
    "\n",
    "label_stringIdx = StringIndexer(inputCol = \"category\", outputCol = \"label\")\n",
    "\n",
    "nlp_pipeline = Pipeline(\n",
    "    stages=[document_assembler, \n",
    "            tokenizer,\n",
    "            normalizer,\n",
    "            stopwords_cleaner, \n",
    "            stemmer, \n",
    "            finisher,\n",
    "           countVectors,\n",
    "           label_stringIdx])\n",
    "\n",
    "nlp_model = nlp_pipeline.fit(spark_df)\n",
    "\n",
    "processed = nlp_model.transform(spark_df)\n",
    "\n",
    "processed.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData, testData) = processed.randomSplit([0.8, 0.2], seed = 100)\n",
    "\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "|                   description|category|                   probability|label|prediction|\n",
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "|Prolonged responses were ac...|      AE|[0.4991510707783345,0.50084...|  1.0|       1.0|\n",
      "|Renal failure associated wi...|      AE|[0.4979399562669633,0.50206...|  1.0|       1.0|\n",
      "|These case reports provide ...|      AE|[0.49751709783971115,0.5024...|  1.0|       1.0|\n",
      "|We describe a patient with ...|      AE|[0.49728770031579433,0.5027...|  1.0|       1.0|\n",
      "|An adverse drug reaction (A...|     Neg|[0.4969665704009515,0.50303...|  0.0|       1.0|\n",
      "|Insulin-induced lipoatrophy...|      AE|[0.49694014629365413,0.5030...|  1.0|       1.0|\n",
      "|Insulin-induced cardiac fai...|      AE|[0.49693765166754705,0.5030...|  1.0|       1.0|\n",
      "|The incidence of RS among c...|     Neg|[0.4964544530237935,0.50354...|  0.0|       1.0|\n",
      "|We describe the development...|      AE|[0.4952091663041609,0.50479...|  1.0|       1.0|\n",
      "|PURPOSE: To describe spectr...|      AE|[0.4948690684166503,0.50513...|  1.0|       1.0|\n",
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0)\n",
    "\n",
    "lrModel = lr.fit(trainingData)\n",
    "\n",
    "predictions = lrModel.transform(testData)\n",
    "\n",
    "predictions.filter(predictions['prediction'] == 1) \\\n",
    "    .select(\"description\",\"category\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.99      0.90      3341\n",
      "         1.0       0.83      0.21      0.34       881\n",
      "\n",
      "    accuracy                           0.83      4222\n",
      "   macro avg       0.83      0.60      0.62      4222\n",
      "weighted avg       0.83      0.83      0.78      4222\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds_df = predictions.select('category','description',\"prediction\",'label').toPandas()\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print (classification_report(preds_df['label'], preds_df['prediction']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text cleaning in Spark NLP and TfIDF + LogReg with Spark ML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21077"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "\n",
    "hashingTF = HashingTF(inputCol=\"token_features\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
    "\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
    "\n",
    "nlp_pipeline_tf = Pipeline(\n",
    "    stages=[document_assembler, \n",
    "            tokenizer,\n",
    "            normalizer,\n",
    "            stopwords_cleaner, \n",
    "            stemmer, \n",
    "            finisher,\n",
    "            hashingTF,\n",
    "           idf,\n",
    "           label_stringIdx])\n",
    "\n",
    "nlp_model_tf = nlp_pipeline_tf.fit(spark_df)\n",
    "\n",
    "processed_tf = nlp_model_tf.transform(spark_df)\n",
    "\n",
    "processed_tf.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 16855\n",
      "Test Dataset Count: 4222\n"
     ]
    }
   ],
   "source": [
    "(trainingData, testData) = processed_tf.randomSplit([0.8, 0.2], seed = 100)\n",
    "\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "|                   description|category|                   probability|label|prediction|\n",
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "|Final treatment plans for t...|     Neg|[0.9950398737908789,0.00496...|  0.0|       0.0|\n",
      "|To know the histochemical e...|     Neg|[0.9923850017908431,0.00761...|  0.0|       0.0|\n",
      "|By searching for the key wo...|     Neg|[0.9882074032992472,0.01179...|  0.0|       0.0|\n",
      "|The diagnosis was made on t...|     Neg|[0.9850888810925544,0.01491...|  0.0|       0.0|\n",
      "|Moreover, this case illustr...|     Neg|[0.9840292455069913,0.01597...|  0.0|       0.0|\n",
      "|Pediatric and cardiovascula...|     Neg|[0.9818585325650826,0.01814...|  0.0|       0.0|\n",
      "|In conclusion, the in vitro...|     Neg|[0.9810434185311695,0.01895...|  0.0|       0.0|\n",
      "|Calcimimetics are a new cla...|     Neg|[0.9809039513660356,0.01909...|  0.0|       0.0|\n",
      "|She was patch tested to Eur...|     Neg|[0.9797460113042422,0.02025...|  0.0|       0.0|\n",
      "|Donor hearts were transport...|     Neg|[0.9767703557109646,0.02322...|  0.0|       0.0|\n",
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0)\n",
    "\n",
    "lrModel = lr.fit(trainingData)\n",
    "\n",
    "predictions = lrModel.transform(testData)\n",
    "\n",
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"description\",\"category\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.99      0.90      3341\n",
      "         1.0       0.82      0.16      0.27       881\n",
      "\n",
      "    accuracy                           0.82      4222\n",
      "   macro avg       0.82      0.58      0.58      4222\n",
      "weighted avg       0.82      0.82      0.77      4222\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds_df = predictions.select('category','description',\"prediction\",'label').toPandas()\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print (classification_report(preds_df['label'], preds_df['prediction']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text cleaning and featurizing in Spark NLP and LogReg with Spark ML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21077"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"description\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "    \n",
    "tokenizer = Tokenizer() \\\n",
    "  .setInputCols([\"document\"]) \\\n",
    "  .setOutputCol(\"token\")\n",
    "    \n",
    "normalizer = Normalizer() \\\n",
    "    .setInputCols([\"token\"]) \\\n",
    "    .setOutputCol(\"normalized\")\n",
    "\n",
    "stopwords_cleaner = StopWordsCleaner()\\\n",
    "      .setInputCols(\"normalized\")\\\n",
    "      .setOutputCol(\"cleanTokens\")\\\n",
    "      .setCaseSensitive(False)\n",
    "\n",
    "clinical_embeddings = WordEmbeddingsModel.pretrained('embeddings_clinical', 'en', 'clinical/models')\\\n",
    "          .setInputCols([\"document\", \"cleanTokens\"])\\\n",
    "          .setOutputCol(\"embeddings\")\\\n",
    "        .setCaseSensitive(False)\n",
    "\n",
    "embeddingsSentence = SentenceEmbeddings() \\\n",
    "      .setInputCols([\"document\", \"embeddings\"]) \\\n",
    "      .setOutputCol(\"sentence_embeddings\") \\\n",
    "      .setPoolingStrategy(\"AVERAGE\")\n",
    "    \n",
    "embeddings_finisher = EmbeddingsFinisher() \\\n",
    "    .setInputCols([\"sentence_embeddings\"]) \\\n",
    "    .setOutputCols([\"finished_sentence_embeddings\"]) \\\n",
    "    .setOutputAsVector(True)\\\n",
    "    .setCleanAnnotations(False)\n",
    "\n",
    "explodeVectors = SQLTransformer(statement=\n",
    "      \"SELECT EXPLODE(finished_sentence_embeddings) AS features, * FROM __THIS__\")\n",
    "\n",
    "label_stringIdx = StringIndexer(inputCol = \"category\", outputCol = \"label\")\n",
    "\n",
    "\n",
    "nlp_pipeline_w2v = Pipeline(\n",
    "    stages=[document_assembler, \n",
    "            tokenizer,\n",
    "            normalizer,\n",
    "            stopwords_cleaner, \n",
    "            clinical_embeddings,\n",
    "            embeddingsSentence,\n",
    "            embeddings_finisher,\n",
    "            explodeVectors,\n",
    "           label_stringIdx])\n",
    "\n",
    "nlp_model_w2v = nlp_pipeline_w2v.fit(spark_df)\n",
    "\n",
    "processed_w2v = nlp_model_w2v.transform(spark_df)\n",
    "\n",
    "processed_w2v.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 16855\n",
      "Test Dataset Count: 4222\n"
     ]
    }
   ],
   "source": [
    "(trainingData, testData) = processed_w2v.randomSplit([0.8, 0.2], seed = 100)\n",
    "\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4218"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "\n",
    "@udf(\"long\")\n",
    "def num_nonzeros(v):\n",
    "    return v.numNonzeros()\n",
    "\n",
    "testData = testData.where(num_nonzeros(\"features\") != 0)\n",
    "testData.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16837"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData = trainingData.where(num_nonzeros(\"features\") != 0)\n",
    "trainingData.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "|                   description|category|                   probability|label|prediction|\n",
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "|Stool specimen was streaked...|     Neg|[0.9936647913503851,0.00633...|  0.0|       0.0|\n",
      "|The remainder of the proced...|     Neg|[0.9873591734885967,0.01264...|  0.0|       0.0|\n",
      "| Phone followup was attempted.|     Neg|[0.9855274628487091,0.01447...|  0.0|       0.0|\n",
      "|According to American Socie...|     Neg|[0.9848900941325706,0.01510...|  0.0|       0.0|\n",
      "|The catheter was removed an...|     Neg|[0.9839529110339125,0.01604...|  0.0|       0.0|\n",
      "|All of the studies were car...|     Neg|[0.9829156330527493,0.01708...|  0.0|       0.0|\n",
      "|Chest drainage was required...|     Neg|[0.982723987355742,0.017276...|  0.0|       0.0|\n",
      "|In December 1998, he applie...|     Neg|[0.9824635580152413,0.01753...|  0.0|       0.0|\n",
      "|Diagnosis was confirmed by ...|     Neg|[0.9823634981852983,0.01763...|  0.0|       0.0|\n",
      "|Corneal scrapings were take...|     Neg|[0.9809702736458813,0.01902...|  0.0|       0.0|\n",
      "+------------------------------+--------+------------------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0)\n",
    "\n",
    "lrModel = lr.fit(trainingData)\n",
    "\n",
    "predictions = lrModel.transform(testData)\n",
    "\n",
    "predictions\\\n",
    "    .select(\"description\",\"category\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.98      0.89      3375\n",
      "         1.0       0.63      0.11      0.19       843\n",
      "\n",
      "    accuracy                           0.81      4218\n",
      "   macro avg       0.72      0.55      0.54      4218\n",
      "weighted avg       0.78      0.81      0.75      4218\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds_df = predictions.select('category','description',\"prediction\",'label').toPandas()\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print (classification_report(preds_df['label'], preds_df['prediction']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text cleaning, featurizing and classification in Spark NLP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-04-28 01:47:52--  https://raw.githubusercontent.com/kavgan/clinical-concepts/master/clinical-stopwords.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.36.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.36.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6582 (6.4K) [text/plain]\n",
      "Saving to: ‘clinical-stopwords.txt’\n",
      "\n",
      "clinical-stopwords. 100%[===================>]   6.43K  --.-KB/s    in 0.001s  \n",
      "\n",
      "2020-04-28 01:47:52 (10.9 MB/s) - ‘clinical-stopwords.txt’ saved [6582/6582]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/kavgan/clinical-concepts/master/clinical-stopwords.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x', 'y', 'your']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open ('clinical-stopwords.txt', 'r') as f:\n",
    "    stops = f.readlines()\n",
    "\n",
    "stops = [s.strip() for s in stops[1:]]\n",
    "stops[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"description\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "    \n",
    "tokenizer = Tokenizer() \\\n",
    "  .setInputCols([\"document\"]) \\\n",
    "  .setOutputCol(\"token\")\n",
    "    \n",
    "normalizer = Normalizer() \\\n",
    "    .setInputCols([\"token\"]) \\\n",
    "    .setOutputCol(\"normalized\")\n",
    "\n",
    "stopwords_cleaner = StopWordsCleaner()\\\n",
    "      .setInputCols(\"normalized\")\\\n",
    "      .setOutputCol(\"cleanTokens\")\\\n",
    "      .setStopWords(stops)\\\n",
    "      .setCaseSensitive(False)\n",
    "\n",
    "lemma = LemmatizerModel.pretrained('lemma_antbnc') \\\n",
    "    .setInputCols([\"cleanTokens\"]) \\\n",
    "    .setOutputCol(\"lemma\")\n",
    "\n",
    "clinical_embeddings = WordEmbeddingsModel.pretrained('embeddings_clinical', 'en', 'clinical/models')\\\n",
    "          .setInputCols([\"document\", \"lemma\"])\\\n",
    "          .setOutputCol(\"embeddings\")\\\n",
    ".setCaseSensitive(False)\n",
    "\n",
    "embeddingsSentence = SentenceEmbeddings() \\\n",
    "      .setInputCols([\"document\", \"embeddings\"]) \\\n",
    "      .setOutputCol(\"sentence_embeddings\") \\\n",
    "      .setPoolingStrategy(\"AVERAGE\")\n",
    "\n",
    "classsifierdl = ClassifierDLApproach()\\\n",
    "  .setInputCols([\"sentence_embeddings\"])\\\n",
    "  .setOutputCol(\"class\")\\\n",
    "  .setLabelColumn(\"category\")\\\n",
    "  .setMaxEpochs(10)\\\n",
    "  .setBatchSize(8)\\\n",
    "  .setEnableOutputLogs(True)\n",
    "\n",
    "clf_pipeline = Pipeline(\n",
    "    stages=[document_assembler, \n",
    "            tokenizer,\n",
    "            normalizer,\n",
    "            stopwords_cleaner, \n",
    "            lemma, \n",
    "            clinical_embeddings,\n",
    "            embeddingsSentence,\n",
    "            classsifierdl])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 133 ms, sys: 32.8 ms, total: 166 ms\n",
      "Wall time: 1min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "clf_pipelineModel = clf_pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ~/annotator_logs/ && ls -lt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started - total epochs: 10 - learning rate: 0.005 - batch size: 8 - training examples: 16855\n",
      "Epoch 0/10 - 11.451147705%.2fs - loss: 1093.3795 - accuracy: 0.7997812 - batches: 2107\n",
      "Epoch 1/10 - 10.773950661%.2fs - loss: 1093.0107 - accuracy: 0.7997812 - batches: 2107\n",
      "Epoch 2/10 - 10.779547923%.2fs - loss: 1093.0107 - accuracy: 0.7997812 - batches: 2107\n",
      "Epoch 3/10 - 10.760296186%.2fs - loss: 1093.0107 - accuracy: 0.7997812 - batches: 2107\n",
      "Epoch 4/10 - 10.870541052%.2fs - loss: 1093.0107 - accuracy: 0.7997812 - batches: 2107\n",
      "Epoch 5/10 - 9.632701774%.2fs - loss: 1093.0107 - accuracy: 0.7997812 - batches: 2107\n",
      "Epoch 6/10 - 9.310860832%.2fs - loss: 1093.0107 - accuracy: 0.7997812 - batches: 2107\n",
      "Epoch 7/10 - 9.241400512%.2fs - loss: 1093.0107 - accuracy: 0.7997812 - batches: 2107\n",
      "Epoch 8/10 - 9.453594857%.2fs - loss: 1093.0107 - accuracy: 0.7997812 - batches: 2107\n",
      "Epoch 9/10 - 8.986367391%.2fs - loss: 1093.0107 - accuracy: 0.7997812 - batches: 2107\n"
     ]
    }
   ],
   "source": [
    "!cat ~/annotator_logs/ClassifierDLApproach_65b53e5737e5.log \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------------------------------------------------------------------+------+\n",
      "|category|                                                                     description|result|\n",
      "+--------+--------------------------------------------------------------------------------+------+\n",
      "|     Neg|It can be caused by infection of the donor or by contamination of the organ d...| [Neg]|\n",
      "|     Neg|We report the clinical outcome of liver, heart, and kidney recipients from a ...| [Neg]|\n",
      "|     Neg|With current donor evaluation protocols, the risk of transmitting infections ...| [Neg]|\n",
      "|     Neg|Alertness returned over the 24 hr following by the discontinuation of BH-AC a...| [Neg]|\n",
      "|     Neg|                              She was discharged without any neurologic sequela.| [Neg]|\n",
      "|     Neg|                                                    Jarisch-Herxheimer reaction.| [Neg]|\n",
      "|     Neg|The most common findings are fever, malaise, headache, and exacerbation of cu...| [Neg]|\n",
      "|     Neg|                      Adverse reactions, however, are relatively common as well.| [Neg]|\n",
      "|     Neg|Aspirin is one of the world's most commonly used medications and its use bene...| [Neg]|\n",
      "|     Neg|In humans, 80-90% of an administered dose of 5-fluorouracil (5-FU) is degrade...| [Neg]|\n",
      "+--------+--------------------------------------------------------------------------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = clf_pipelineModel.transform(testData)\n",
    "\n",
    "preds.select('category','description',\"class.result\").show(10, truncate=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preds_df = preds.select('category','description',\"class.result\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The result is an array since in Spark NLP you can have multiple sentences.\n",
    "# Let's explode the array and get the item(s) inside of result column out\n",
    "preds_df['result'] = preds_df['result'].apply(lambda x : x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>description</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4177</th>\n",
       "      <td>Neg</td>\n",
       "      <td>CONCLUSIONS: Confocal microscopy can be a usef...</td>\n",
       "      <td>Neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>Neg</td>\n",
       "      <td>BCG therapy prevents, or at least delays, tumo...</td>\n",
       "      <td>Neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>Neg</td>\n",
       "      <td>No severe side effects were observed in the li...</td>\n",
       "      <td>Neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>Neg</td>\n",
       "      <td>RESULTS: Thirteen patients had died; 1 of thes...</td>\n",
       "      <td>Neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>AE</td>\n",
       "      <td>Anterior ischemic optic neuropathy secondary t...</td>\n",
       "      <td>Neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3249</th>\n",
       "      <td>Neg</td>\n",
       "      <td>Both phenotypic and genotypic virologic analys...</td>\n",
       "      <td>Neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1662</th>\n",
       "      <td>AE</td>\n",
       "      <td>This is a rare case of ARDS associated with li...</td>\n",
       "      <td>Neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>Neg</td>\n",
       "      <td>Granulocyte colony stimulating factor (GCSF) w...</td>\n",
       "      <td>Neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3278</th>\n",
       "      <td>Neg</td>\n",
       "      <td>No systemic antibiotics would be given.</td>\n",
       "      <td>Neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Neg</td>\n",
       "      <td>Cultures became negative 10-37 days after the ...</td>\n",
       "      <td>Neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     category                                        description result\n",
       "4177      Neg  CONCLUSIONS: Confocal microscopy can be a usef...    Neg\n",
       "1215      Neg  BCG therapy prevents, or at least delays, tumo...    Neg\n",
       "3000      Neg  No severe side effects were observed in the li...    Neg\n",
       "1002      Neg  RESULTS: Thirteen patients had died; 1 of thes...    Neg\n",
       "940        AE  Anterior ischemic optic neuropathy secondary t...    Neg\n",
       "3249      Neg  Both phenotypic and genotypic virologic analys...    Neg\n",
       "1662       AE  This is a rare case of ARDS associated with li...    Neg\n",
       "613       Neg  Granulocyte colony stimulating factor (GCSF) w...    Neg\n",
       "3278      Neg            No systemic antibiotics would be given.    Neg\n",
       "102       Neg  Cultures became negative 10-37 days after the ...    Neg"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AE       0.00      0.00      0.00       881\n",
      "         Neg       0.79      1.00      0.88      3341\n",
      "\n",
      "    accuracy                           0.79      4222\n",
      "   macro avg       0.40      0.50      0.44      4222\n",
      "weighted avg       0.63      0.79      0.70      4222\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vkocaman/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print (classification_report(preds_df['category'], preds_df['result']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ClassifierDL with Universal Sentence Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfhub_use download started this may take some time.\n",
      "Approximate size to download 923.7 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "# actual content is inside description column\n",
    "document = DocumentAssembler()\\\n",
    "    .setInputCol(\"description\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "    \n",
    "# we can also use sentece detector here if we want to train on and get predictions for each sentence\n",
    "\n",
    "use = UniversalSentenceEncoder.pretrained()\\\n",
    " .setInputCols([\"document\"])\\\n",
    " .setOutputCol(\"sentence_embeddings\")\n",
    "\n",
    "# the classes/labels/categories are in category column\n",
    "classsifierdl = ClassifierDLApproach()\\\n",
    "  .setInputCols([\"sentence_embeddings\"])\\\n",
    "  .setOutputCol(\"class\")\\\n",
    "  .setLabelColumn(\"category\")\\\n",
    "    .setBatchSize(8)\\\n",
    "    .setMaxEpochs(200)\\\n",
    "    .setLr(0.001)\\\n",
    "  .setEnableOutputLogs(True)\n",
    "\n",
    "use_clf_pipeline = Pipeline(\n",
    "    stages = [\n",
    "        document,\n",
    "        use,\n",
    "        classsifierdl\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 217 ms, sys: 130 ms, total: 347 ms\n",
      "Wall time: 40min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "use_clf_pipelineModel = use_clf_pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ~/annotator_logs/ && ls -lt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started - total epochs: 10 - learning rate: 0.005 - batch size: 64 - training examples: 16855\n",
      "Epoch 0/10 - 3.99512087%.2fs - loss: 135.09169 - accuracy: 0.80234593 - batches: 264\n",
      "Epoch 1/10 - 4.766252183%.2fs - loss: 135.70131 - accuracy: 0.80240536 - batches: 264\n",
      "Epoch 2/10 - 4.469659096%.2fs - loss: 135.69331 - accuracy: 0.80240536 - batches: 264\n",
      "Epoch 3/10 - 4.600433395%.2fs - loss: 134.59521 - accuracy: 0.802333 - batches: 264\n",
      "Epoch 4/10 - 3.730208099%.2fs - loss: 130.32632 - accuracy: 0.8104594 - batches: 264\n",
      "Epoch 5/10 - 3.557576017%.2fs - loss: 126.97921 - accuracy: 0.8159716 - batches: 264\n",
      "Epoch 6/10 - 3.795263992%.2fs - loss: 124.651344 - accuracy: 0.81983334 - batches: 264\n",
      "Epoch 7/10 - 3.359740149%.2fs - loss: 123.539375 - accuracy: 0.823695 - batches: 264\n",
      "Epoch 8/10 - 3.303243652%.2fs - loss: 122.89158 - accuracy: 0.8252397 - batches: 264\n",
      "Epoch 9/10 - 3.300559809%.2fs - loss: 122.46075 - accuracy: 0.8275567 - batches: 264\n"
     ]
    }
   ],
   "source": [
    "!cat ~/annotator_logs/ClassifierDLApproach_c36fd6c33b58.log\n",
    "# with 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50 - 7.241297522%.2fs - loss: 509.01236 - accuracy: 0.85082585 - batches: 1054\n",
      "Epoch 41/50 - 7.430544655%.2fs - loss: 508.6808 - accuracy: 0.85147876 - batches: 1054\n",
      "Epoch 42/50 - 7.475286196%.2fs - loss: 508.36176 - accuracy: 0.8517755 - batches: 1054\n",
      "Epoch 43/50 - 7.275063993%.2fs - loss: 508.0474 - accuracy: 0.85213166 - batches: 1054\n",
      "Epoch 44/50 - 7.053398349%.2fs - loss: 507.73767 - accuracy: 0.8527252 - batches: 1054\n",
      "Epoch 45/50 - 7.019040194%.2fs - loss: 507.4303 - accuracy: 0.85331875 - batches: 1054\n",
      "Epoch 46/50 - 6.971686473%.2fs - loss: 507.12305 - accuracy: 0.85355616 - batches: 1054\n",
      "Epoch 47/50 - 7.245352824%.2fs - loss: 506.8202 - accuracy: 0.8542684 - batches: 1054\n",
      "Epoch 48/50 - 7.451507109%.2fs - loss: 506.52145 - accuracy: 0.85474324 - batches: 1054\n",
      "Epoch 49/50 - 7.284613728%.2fs - loss: 506.2306 - accuracy: 0.8551587 - batches: 1054\n"
     ]
    }
   ],
   "source": [
    "!tail -10 ~/annotator_logs/ClassifierDLApproach_c38c29ef6024.log\n",
    "# with 50 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AE       0.59      0.34      0.43       881\n",
      "         Neg       0.84      0.94      0.89      3341\n",
      "\n",
      "    accuracy                           0.81      4222\n",
      "   macro avg       0.72      0.64      0.66      4222\n",
      "weighted avg       0.79      0.81      0.79      4222\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = use_clf_pipelineModel.transform(testData)\n",
    "\n",
    "preds_df = preds.select('category','description',\"class.result\").toPandas()\n",
    "\n",
    "preds_df['result'] = preds_df['result'].apply(lambda x : x[0])\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print (classification_report(preds_df['category'], preds_df['result']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100 - 7.107793742%.2fs - loss: 490.2443 - accuracy: 0.8437627 - batches: 1054\n",
      "Epoch 91/100 - 7.449995695%.2fs - loss: 490.06836 - accuracy: 0.84411883 - batches: 1054\n",
      "Epoch 92/100 - 7.232593671%.2fs - loss: 489.8934 - accuracy: 0.8442969 - batches: 1054\n",
      "Epoch 93/100 - 6.972248433%.2fs - loss: 489.71902 - accuracy: 0.8442969 - batches: 1054\n",
      "Epoch 94/100 - 7.115250338%.2fs - loss: 489.5486 - accuracy: 0.844475 - batches: 1054\n",
      "Epoch 95/100 - 7.230228216%.2fs - loss: 489.37936 - accuracy: 0.844653 - batches: 1054\n",
      "Epoch 96/100 - 7.105980567%.2fs - loss: 489.2125 - accuracy: 0.8449498 - batches: 1054\n",
      "Epoch 97/100 - 7.289306271%.2fs - loss: 489.0479 - accuracy: 0.84483105 - batches: 1054\n",
      "Epoch 98/100 - 7.182141736%.2fs - loss: 488.88452 - accuracy: 0.84524655 - batches: 1054\n",
      "Epoch 99/100 - 7.612609609%.2fs - loss: 488.72177 - accuracy: 0.8453059 - batches: 1054\n"
     ]
    }
   ],
   "source": [
    "!tail -10 ~/annotator_logs/ClassifierDLApproach_917e76dbeb16.log\n",
    "# with 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AE       0.60      0.32      0.42       881\n",
      "         Neg       0.84      0.94      0.89      3341\n",
      "\n",
      "    accuracy                           0.81      4222\n",
      "   macro avg       0.72      0.63      0.65      4222\n",
      "weighted avg       0.79      0.81      0.79      4222\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = use_clf_pipelineModel.transform(testData)\n",
    "\n",
    "preds_df = preds.select('category','description',\"class.result\").toPandas()\n",
    "\n",
    "preds_df['result'] = preds_df['result'].apply(lambda x : x[0])\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print (classification_report(preds_df['category'], preds_df['result']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50 - 9.369026172%.2fs - loss: 930.22797 - accuracy: 0.8653253 - batches: 2107\n",
      "Epoch 41/50 - 9.31812987%.2fs - loss: 929.064 - accuracy: 0.8658001 - batches: 2107\n",
      "Epoch 42/50 - 9.304147095%.2fs - loss: 927.9366 - accuracy: 0.86633426 - batches: 2107\n",
      "Epoch 43/50 - 10.075942242%.2fs - loss: 926.831 - accuracy: 0.8663936 - batches: 2107\n",
      "Epoch 44/50 - 9.685581395%.2fs - loss: 925.7427 - accuracy: 0.86716527 - batches: 2107\n",
      "Epoch 45/50 - 9.554822793%.2fs - loss: 924.67346 - accuracy: 0.8675807 - batches: 2107\n",
      "Epoch 46/50 - 9.912348859%.2fs - loss: 923.62415 - accuracy: 0.8680556 - batches: 2107\n",
      "Epoch 47/50 - 10.988392763%.2fs - loss: 922.58044 - accuracy: 0.86835235 - batches: 2107\n",
      "Epoch 48/50 - 10.980015198%.2fs - loss: 921.5505 - accuracy: 0.86912394 - batches: 2107\n",
      "Epoch 49/50 - 9.983640328%.2fs - loss: 920.54 - accuracy: 0.8697175 - batches: 2107\n"
     ]
    }
   ],
   "source": [
    "!tail -10 ~/annotator_logs/ClassifierDLApproach_5c1c2243eac0.log\n",
    "# with 50 epochs, bathc 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AE       0.62      0.33      0.44       881\n",
      "         Neg       0.84      0.95      0.89      3341\n",
      "\n",
      "    accuracy                           0.82      4222\n",
      "   macro avg       0.73      0.64      0.66      4222\n",
      "weighted avg       0.80      0.82      0.80      4222\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = use_clf_pipelineModel.transform(testData)\n",
    "\n",
    "preds_df = preds.select('category','description',\"class.result\").toPandas()\n",
    "\n",
    "preds_df['result'] = preds_df['result'].apply(lambda x : x[0])\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print (classification_report(preds_df['category'], preds_df['result']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100 - 9.787622493%.2fs - loss: 895.67804 - accuracy: 0.8953585 - batches: 2107\n",
      "Epoch 91/100 - 9.489642055%.2fs - loss: 895.2891 - accuracy: 0.89553654 - batches: 2107\n",
      "Epoch 92/100 - 9.617070758%.2fs - loss: 894.90814 - accuracy: 0.8955959 - batches: 2107\n",
      "Epoch 93/100 - 9.910288144%.2fs - loss: 894.5366 - accuracy: 0.895774 - batches: 2107\n",
      "Epoch 94/100 - 9.540695458%.2fs - loss: 894.17566 - accuracy: 0.8958927 - batches: 2107\n",
      "Epoch 95/100 - 9.49872604%.2fs - loss: 893.8174 - accuracy: 0.8960708 - batches: 2107\n",
      "Epoch 96/100 - 9.478969646%.2fs - loss: 893.4732 - accuracy: 0.8962488 - batches: 2107\n",
      "Epoch 97/100 - 9.4266269%.2fs - loss: 893.12933 - accuracy: 0.89660496 - batches: 2107\n",
      "Epoch 98/100 - 9.133465759%.2fs - loss: 892.7991 - accuracy: 0.8966643 - batches: 2107\n",
      "Epoch 99/100 - 9.811887598%.2fs - loss: 892.47284 - accuracy: 0.8967236 - batches: 2107\n"
     ]
    }
   ],
   "source": [
    "!tail -10 ~/annotator_logs/ClassifierDLApproach_5ba60b31eed5.log\n",
    "# with 100 epochs, bathc 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AE       0.62      0.30      0.40       881\n",
      "         Neg       0.84      0.95      0.89      3341\n",
      "\n",
      "    accuracy                           0.82      4222\n",
      "   macro avg       0.73      0.62      0.65      4222\n",
      "weighted avg       0.79      0.82      0.79      4222\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = use_clf_pipelineModel.transform(testData)\n",
    "\n",
    "preds_df = preds.select('category','description',\"class.result\").toPandas()\n",
    "\n",
    "preds_df['result'] = preds_df['result'].apply(lambda x : x[0])\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print (classification_report(preds_df['category'], preds_df['result']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190/200 - 9.844052978%.2fs - loss: 882.0651 - accuracy: 0.9003358 - batches: 2107\n",
      "Epoch 191/200 - 9.282441487%.2fs - loss: 881.87054 - accuracy: 0.90039515 - batches: 2107\n",
      "Epoch 192/200 - 21.047282111%.2fs - loss: 881.67017 - accuracy: 0.9004545 - batches: 2107\n",
      "Epoch 193/200 - 9.818631247%.2fs - loss: 881.4752 - accuracy: 0.9005138 - batches: 2107\n",
      "Epoch 194/200 - 10.841587139%.2fs - loss: 881.2806 - accuracy: 0.9005732 - batches: 2107\n",
      "Epoch 195/200 - 9.234538668%.2fs - loss: 881.0885 - accuracy: 0.90063256 - batches: 2107\n",
      "Epoch 196/200 - 8.885203833%.2fs - loss: 880.89844 - accuracy: 0.90063256 - batches: 2107\n",
      "Epoch 197/200 - 9.499566853%.2fs - loss: 880.71045 - accuracy: 0.9007513 - batches: 2107\n",
      "Epoch 198/200 - 9.331700172%.2fs - loss: 880.5219 - accuracy: 0.9007513 - batches: 2107\n",
      "Epoch 199/200 - 9.764149199%.2fs - loss: 880.3384 - accuracy: 0.9008106 - batches: 2107\n"
     ]
    }
   ],
   "source": [
    "!tail -10 ~/annotator_logs/ClassifierDLApproach_79a3a02f42b1.log\n",
    "# with 200 epochs, bathc 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AE       0.60      0.34      0.43       881\n",
      "         Neg       0.84      0.94      0.89      3341\n",
      "\n",
      "    accuracy                           0.82      4222\n",
      "   macro avg       0.72      0.64      0.66      4222\n",
      "weighted avg       0.79      0.82      0.79      4222\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = use_clf_pipelineModel.transform(testData)\n",
    "\n",
    "preds_df = preds.select('category','description',\"class.result\").toPandas()\n",
    "\n",
    "preds_df['result'] = preds_df['result'].apply(lambda x : x[0])\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print (classification_report(preds_df['category'], preds_df['result']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
