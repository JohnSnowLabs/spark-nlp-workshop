{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1.5.Resume_MedicalNer_Model_Training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I08sFJYCxR0Z"
      },
      "source": [
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwJ-P56kq6FU"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.5.Resume_MedicalNer_Model_Training.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ztGkR5mb6zN"
      },
      "source": [
        "# 1.5 Resume MedicalNer Model Training\n",
        "\n",
        "Steps:\n",
        "- Train a new model for a few epochs.\n",
        "- Load the same model and train for more epochs on the same taxnonomy, and check stats.\n",
        "- Train a model already trained on a different data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-68NMdHxJIco"
      },
      "source": [
        "## Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9Mn1PNTNJTq"
      },
      "source": [
        "import json\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "license_keys = files.upload()\n",
        "\n",
        "with open(list(license_keys.keys())[0]) as f:\n",
        "    license_keys = json.load(f)\n",
        "\n",
        "# Defining license key-value pairs as local variables\n",
        "locals().update(license_keys)\n",
        "\n",
        "# Adding license key-value pairs to environment variables\n",
        "import os\n",
        "os.environ.update(license_keys)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvHraBK7b-LU"
      },
      "source": [
        "# Installing pyspark and spark-nlp\n",
        "! pip install --upgrade -q pyspark==3.1.2 spark-nlp==$PUBLIC_VERSION\n",
        "\n",
        "# Installing Spark NLP Healthcare\n",
        "! pip install --upgrade -q spark-nlp-jsl==$JSL_VERSION  --extra-index-url https://pypi.johnsnowlabs.com/$SECRET\n",
        "\n",
        "# Installing Spark NLP Display Library for visualization\n",
        "! pip install -q spark-nlp-display"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIp1yLCWNWsn"
      },
      "source": [
        "# if you want to start the session with custom params as in start function above\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "def start(SECRET):\n",
        "    builder = SparkSession.builder \\\n",
        "        .appName(\"Spark NLP Licensed\") \\\n",
        "        .master(\"local[*]\") \\\n",
        "        .config(\"spark.driver.memory\", \"16G\") \\\n",
        "        .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
        "        .config(\"spark.kryoserializer.buffer.max\", \"2000M\") \\\n",
        "        .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:\"+PUBLIC_VERSION) \\\n",
        "        .config(\"spark.jars\", \"https://pypi.johnsnowlabs.com/\"+SECRET+\"/spark-nlp-jsl-\"+JSL_VERSION+\".jar\")\n",
        "      \n",
        "    return builder.getOrCreate()\n",
        "\n",
        "#spark = start(SECRET)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1t5Kp93GcH7z",
        "outputId": "063ee555-6026-464f-8912-beeba71e335e"
      },
      "source": [
        "import json\n",
        "import os\n",
        "from pyspark.ml import Pipeline,PipelineModel\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp_jsl.annotator import *\n",
        "from sparknlp.base import *\n",
        "import sparknlp_jsl\n",
        "import sparknlp\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "params = {\"spark.driver.memory\":\"16G\", # Amount of memory to use for the driver process, i.e. where SparkContext is initialized\n",
        "          \"spark.kryoserializer.buffer.max\":\"2000M\", # Maximum allowable size of Kryo serialization buffer, in MiB unless otherwise specified. \n",
        "          \"spark.driver.maxResultSize\":\"2000M\"} # Limit of total size of serialized results of all partitions for each Spark action (e.g. collect) in bytes. \n",
        "                                                # Should be at least 1M, or 0 for unlimited. \n",
        "\n",
        "spark = sparknlp_jsl.start(license_keys['SECRET'],params=params)\n",
        "\n",
        "print (\"Spark NLP Version :\", sparknlp.version())\n",
        "print (\"Spark NLP_JSL Version :\", sparknlp_jsl.version())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP Version : 3.3.0\n",
            "Spark NLP_JSL Version : 3.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeWhvSsHRXsf"
      },
      "source": [
        "## Download Clinical Word Embeddings for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ua5dHNeyRWQc",
        "outputId": "19f91b60-fb4f-4d8f-e5c9-306a8e41d292"
      },
      "source": [
        "clinical_embeddings = WordEmbeddingsModel.pretrained('embeddings_clinical', \"en\", \"clinical/models\")\\\n",
        "    .setInputCols([\"sentence\", \"token\"])\\\n",
        "    .setOutputCol(\"embeddings\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embeddings_clinical download started this may take some time.\n",
            "Approximate size to download 1.6 GB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfT1AaKvOG4J"
      },
      "source": [
        "## Download Data for Training (NCBI Disease Dataset)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMOycTPUcty7"
      },
      "source": [
        "!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Healthcare/data/NCBI_disease_official_test.conll\n",
        "!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Healthcare/data/NCBI_disease_official_train_dev.conll"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FetZIfagc-eh",
        "outputId": "66230226-4d74-405d-f8ca-15f56933b976"
      },
      "source": [
        "from sparknlp.training import CoNLL\n",
        "\n",
        "training_data = CoNLL().readDataset(spark, 'NCBI_disease_official_train_dev.conll')\n",
        "\n",
        "training_data.show(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                text|            document|            sentence|               token|                 pos|               label|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|Identification of...|[{document, 0, 89...|[{document, 0, 89...|[{token, 0, 13, I...|[{pos, 0, 13, NN,...|[{named_entity, 0...|\n",
            "|The adenomatous p...|[{document, 0, 21...|[{document, 0, 21...|[{token, 0, 2, Th...|[{pos, 0, 2, NN, ...|[{named_entity, 0...|\n",
            "|Complex formation...|[{document, 0, 63...|[{document, 0, 63...|[{token, 0, 6, Co...|[{pos, 0, 6, NN, ...|[{named_entity, 0...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fm1bfPJidC9X",
        "outputId": "a246fbd1-6552-4fd2-eb5e-addfbc318990"
      },
      "source": [
        "from sparknlp.training import CoNLL\n",
        "\n",
        "test_data = CoNLL().readDataset(spark, 'NCBI_disease_official_test.conll')\n",
        "\n",
        "test_data.show(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                text|            document|            sentence|               token|                 pos|               label|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|Clustering of mis...|[{document, 0, 10...|[{document, 0, 10...|[{token, 0, 9, Cl...|[{pos, 0, 9, NN, ...|[{named_entity, 0...|\n",
            "|Ataxia - telangie...|[{document, 0, 13...|[{document, 0, 13...|[{token, 0, 5, At...|[{pos, 0, 5, NN, ...|[{named_entity, 0...|\n",
            "|The risk of cance...|[{document, 0, 15...|[{document, 0, 15...|[{token, 0, 2, Th...|[{pos, 0, 2, NN, ...|[{named_entity, 0...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaTp5atqc_C-"
      },
      "source": [
        "## Split the test data into two parts:\n",
        "- We Keep the first part separate and use it for training the model further, as it will be totally unseen data from the same taxonomy.\n",
        "\n",
        "- The second part will be used to testing and evaluating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_gInTNZRhnC"
      },
      "source": [
        "(test_data_1, test_data_2) = test_data.randomSplit([0.5, 0.5], seed = 100)\n",
        "\n",
        "# save the test data as parquet for easy testing\n",
        "clinical_embeddings.transform(test_data_1).write.parquet('test_1.parquet')\n",
        "\n",
        "clinical_embeddings.transform(test_data_2).write.parquet('test_2.parquet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WX2jO2FPRo6Q"
      },
      "source": [
        "## Train a new model, pause, and resume training on the same dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tc2Uoh_YR3dA"
      },
      "source": [
        "### Create a graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFzmo-JzRs3x",
        "outputId": "98be816b-cafe-40ee-b9c6-eca1bda8a9db"
      },
      "source": [
        "from sparknlp_jsl.training import tf_graph\n",
        "%tensorflow_version 1.x\n",
        "tf_graph.print_model_params(\"ner_dl\")\n",
        "\n",
        "tf_graph.build(\"ner_dl\", build_params={\"embeddings_dim\": 200, \"nchars\": 128, \"ntags\": 12, \"is_medical\": 1}, model_location=\"./medical_ner_graphs\", model_filename=\"auto\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n",
            "ner_dl parameters.\n",
            "Parameter            Required   Default value        Description\n",
            "ntags                yes        -                    Number of tags.\n",
            "embeddings_dim       no         200                  Embeddings dimension.\n",
            "nchars               no         100                  Number of chars.\n",
            "lstm_size            no         128                  Number of LSTM units.\n",
            "gpu_device           no         0                    Device for training.\n",
            "is_medical           no         0                    Build a Medical Ner graph.\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/sparknlp_jsl/_tf_graph_builders/ner_dl/ner_model.py:14: The name tf.disable_v2_behavior is deprecated. Please use tf.compat.v1.disable_v2_behavior instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/keras/backend.py:3994: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/rnn/python/ops/lstm_ops.py:597: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/crf/python/ops/crf.py:213: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "ner_dl graph exported to ./medical_ner_graphs/blstm_12_200_128_128.pb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PT5pF7V7R69G"
      },
      "source": [
        "### Train for 2 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7J4j069R9ty"
      },
      "source": [
        "nerTagger = MedicalNerApproach()\\\n",
        "      .setInputCols([\"sentence\", \"token\", \"embeddings\"])\\\n",
        "      .setLabelColumn(\"label\")\\\n",
        "      .setOutputCol(\"ner\")\\\n",
        "      .setMaxEpochs(2)\\\n",
        "      .setLr(0.003)\\\n",
        "      .setBatchSize(8)\\\n",
        "      .setRandomSeed(0)\\\n",
        "      .setVerbose(1)\\\n",
        "      .setEvaluationLogExtended(True) \\\n",
        "      .setEnableOutputLogs(True)\\\n",
        "      .setIncludeConfidence(True)\\\n",
        "      .setTestDataset('./test_2.parquet')\\\n",
        "      .setGraphFolder('./medical_ner_graphs')\\\n",
        "      .setOutputLogsPath('./ner_logs')\n",
        "\n",
        "ner_pipeline = Pipeline(stages=[\n",
        "      clinical_embeddings,\n",
        "      nerTagger\n",
        " ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5Phv3rFSBR_",
        "outputId": "1495b5a5-98fd-4052-aac3-339941431635"
      },
      "source": [
        "\n",
        "%%time\n",
        "ner_model = ner_pipeline.fit(training_data)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.58 s, sys: 267 ms, total: 2.85 s\n",
            "Wall time: 8min 13s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPZ2tmHFSBUy",
        "outputId": "53c9b45b-0a47-40f9-ccab-3b7acdda1029"
      },
      "source": [
        "# Training Logs\n",
        "! cat ner_logs/MedicalNerApproach_a6231a3fe051.log"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat: ner_logs/MedicalNerApproach_a6231a3fe051.log: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2onzNGuP_QH"
      },
      "source": [
        "# Logs of 4 consecutive epochs to compare with 2+2 epochs on separate datasets from same taxonomy\n",
        "\n",
        "#!cat ner_logs/MedicalNerApproach_4d3d69967c3f.log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLKJpTfKWLwC"
      },
      "source": [
        "### Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ec5aux5DSBXE",
        "outputId": "1187fdc8-3efe-45f0-f6dc-b938ae76cd08"
      },
      "source": [
        "from sparknlp_jsl.eval import NerDLMetrics\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "pred_df = ner_model.stages[1].transform(clinical_embeddings.transform(test_data_2))\n",
        "\n",
        "evaler = NerDLMetrics(mode=\"full_chunk\", dropO=True)\n",
        "\n",
        "eval_result = evaler.computeMetricsFromDF(pred_df.select(\"label\",\"ner\"), prediction_col=\"ner\", label_col=\"label\").cache()\n",
        "\n",
        "eval_result.withColumn(\"precision\", F.round(eval_result[\"precision\"],4))\\\n",
        "    .withColumn(\"recall\", F.round(eval_result[\"recall\"],4))\\\n",
        "    .withColumn(\"f1\", F.round(eval_result[\"f1\"],4)).show(100)\n",
        "\n",
        "print(eval_result.selectExpr(\"avg(f1) as macro\").show())\n",
        "print (eval_result.selectExpr(\"sum(f1*total) as sumprod\",\"sum(total) as sumtotal\").selectExpr(\"sumprod/sumtotal as micro\").show())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+----+----+-----+---------+------+------+\n",
            "| entity|   tp|  fp|  fn|total|precision|recall|    f1|\n",
            "+-------+-----+----+----+-----+---------+------+------+\n",
            "|Disease|367.0|66.0|93.0|460.0|   0.8476|0.7978|0.8219|\n",
            "+-------+-----+----+----+-----+---------+------+------+\n",
            "\n",
            "+------------------+\n",
            "|             macro|\n",
            "+------------------+\n",
            "|0.8219484882418813|\n",
            "+------------------+\n",
            "\n",
            "None\n",
            "+------------------+\n",
            "|             micro|\n",
            "+------------------+\n",
            "|0.8219484882418813|\n",
            "+------------------+\n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77HQ3yYyT-RZ"
      },
      "source": [
        "### Save the model to disk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KEUa1yaSBZW"
      },
      "source": [
        "ner_model.stages[1].write().overwrite().save('models/NCBI_NER_2_epoch')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_U4mQcXUTg7"
      },
      "source": [
        "### Train using the saved model on unseen dataset\n",
        "#### We use unseen data from same taxonomy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgFviuf5SBei"
      },
      "source": [
        "\n",
        "nerTagger = MedicalNerApproach()\\\n",
        "      .setInputCols([\"sentence\", \"token\", \"embeddings\"])\\\n",
        "      .setLabelColumn(\"label\")\\\n",
        "      .setOutputCol(\"ner\")\\\n",
        "      .setMaxEpochs(2)\\\n",
        "      .setLr(0.003)\\\n",
        "      .setBatchSize(8)\\\n",
        "      .setRandomSeed(0)\\\n",
        "      .setVerbose(1)\\\n",
        "      .setEvaluationLogExtended(True) \\\n",
        "      .setEnableOutputLogs(True)\\\n",
        "      .setIncludeConfidence(True)\\\n",
        "      .setTestDataset('/content/test_2.parquet')\\\n",
        "      .setOutputLogsPath('ner_logs')\\\n",
        "      .setGraphFolder('medical_ner_graphs')\\\n",
        "      .setPretrainedModelPath(\"models/NCBI_NER_2_epoch\") ## load exisitng model\n",
        "    \n",
        "ner_pipeline = Pipeline(stages=[\n",
        "      clinical_embeddings,\n",
        "      nerTagger\n",
        " ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVZGKEsKUSrS",
        "outputId": "f3a7aa6b-2c67-42e1-e14f-1d490305816f"
      },
      "source": [
        "\n",
        "%%time\n",
        "ner_model_retrained = ner_pipeline.fit(test_data_1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 332 ms, sys: 40.8 ms, total: 373 ms\n",
            "Wall time: 57.7 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVTfOVnIgwpP",
        "outputId": "ed866f20-b0fa-49da-ff9b-5ca70a9086f0"
      },
      "source": [
        "!cat ./ner_logs/MedicalNerApproach_f7726480b5ef.log"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat: ./ner_logs/MedicalNerApproach_f7726480b5ef.log: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_vg2Ajse6aZ",
        "outputId": "52d09ee5-6c55-48ea-b150-804b3bfdfdf9"
      },
      "source": [
        "from sparknlp_jsl.eval import NerDLMetrics\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "pred_df = ner_model_retrained.stages[1].transform(clinical_embeddings.transform(test_data_2))\n",
        "\n",
        "evaler = NerDLMetrics(mode=\"full_chunk\", dropO=True)\n",
        "\n",
        "eval_result = evaler.computeMetricsFromDF(pred_df.select(\"label\",\"ner\"), prediction_col=\"ner\", label_col=\"label\").cache()\n",
        "\n",
        "eval_result.withColumn(\"precision\", F.round(eval_result[\"precision\"],4))\\\n",
        "    .withColumn(\"recall\", F.round(eval_result[\"recall\"],4))\\\n",
        "    .withColumn(\"f1\", F.round(eval_result[\"f1\"],4)).show(100)\n",
        "\n",
        "print(eval_result.selectExpr(\"avg(f1) as macro\").show())\n",
        "print (eval_result.selectExpr(\"sum(f1*total) as sumprod\",\"sum(total) as sumtotal\").selectExpr(\"sumprod/sumtotal as micro\").show())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+----+----+-----+---------+------+------+\n",
            "| entity|   tp|  fp|  fn|total|precision|recall|    f1|\n",
            "+-------+-----+----+----+-----+---------+------+------+\n",
            "|Disease|418.0|65.0|42.0|460.0|   0.8654|0.9087|0.8865|\n",
            "+-------+-----+----+----+-----+---------+------+------+\n",
            "\n",
            "+------------------+\n",
            "|             macro|\n",
            "+------------------+\n",
            "|0.8865323435843054|\n",
            "+------------------+\n",
            "\n",
            "None\n",
            "+------------------+\n",
            "|             micro|\n",
            "+------------------+\n",
            "|0.8865323435843054|\n",
            "+------------------+\n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rw0jTK2RbMAi"
      },
      "source": [
        "## Now let's take a model trained on a different dataset and train on this dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2eVAVhfUSt0",
        "outputId": "80567602-414f-4b88-8341-54a311ce2308"
      },
      "source": [
        "jsl_ner = MedicalNerModel.pretrained('ner_jsl','en','clinical/models')\n",
        "\n",
        "jsl_ner.getClasses()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ner_jsl download started this may take some time.\n",
            "Approximate size to download 14.5 MB\n",
            "[OK!]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O',\n",
              " 'B-Injury_or_Poisoning',\n",
              " 'B-Direction',\n",
              " 'B-Test',\n",
              " 'I-Route',\n",
              " 'B-Admission_Discharge',\n",
              " 'B-Death_Entity',\n",
              " 'I-Oxygen_Therapy',\n",
              " 'I-Drug_BrandName',\n",
              " 'B-Relationship_Status',\n",
              " 'B-Duration',\n",
              " 'I-Alcohol',\n",
              " 'I-Triglycerides',\n",
              " 'I-Date',\n",
              " 'B-Respiration',\n",
              " 'B-Hyperlipidemia',\n",
              " 'I-Test',\n",
              " 'B-Birth_Entity',\n",
              " 'I-VS_Finding',\n",
              " 'B-Age',\n",
              " 'I-Social_History_Header',\n",
              " 'B-Labour_Delivery',\n",
              " 'I-Medical_Device',\n",
              " 'B-Family_History_Header',\n",
              " 'B-BMI',\n",
              " 'I-Fetus_NewBorn',\n",
              " 'I-BMI',\n",
              " 'B-Temperature',\n",
              " 'I-Section_Header',\n",
              " 'I-Communicable_Disease',\n",
              " 'I-ImagingFindings',\n",
              " 'I-Psychological_Condition',\n",
              " 'I-Obesity',\n",
              " 'I-Sexually_Active_or_Sexual_Orientation',\n",
              " 'I-Modifier',\n",
              " 'B-Alcohol',\n",
              " 'I-Temperature',\n",
              " 'I-Vaccine',\n",
              " 'I-Symptom',\n",
              " 'B-Kidney_Disease',\n",
              " 'I-Pulse',\n",
              " 'B-Oncological',\n",
              " 'I-EKG_Findings',\n",
              " 'B-Medical_History_Header',\n",
              " 'I-Relationship_Status',\n",
              " 'I-Blood_Pressure',\n",
              " 'B-Cerebrovascular_Disease',\n",
              " 'I-Diabetes',\n",
              " 'B-Oxygen_Therapy',\n",
              " 'B-O2_Saturation',\n",
              " 'B-Psychological_Condition',\n",
              " 'B-Heart_Disease',\n",
              " 'I-Frequency',\n",
              " 'B-Employment',\n",
              " 'B-Obesity',\n",
              " 'B-Disease_Syndrome_Disorder',\n",
              " 'I-Oncological',\n",
              " 'B-Pregnancy',\n",
              " 'I-RelativeDate',\n",
              " 'I-Procedure',\n",
              " 'B-ImagingFindings',\n",
              " 'I-Overweight',\n",
              " 'B-Procedure',\n",
              " 'I-Labour_Delivery',\n",
              " 'B-Medical_Device',\n",
              " 'I-Family_History_Header',\n",
              " 'B-Race_Ethnicity',\n",
              " 'I-Hypertension',\n",
              " 'I-External_body_part_or_region',\n",
              " 'I-Imaging_Technique',\n",
              " 'I-Kidney_Disease',\n",
              " 'B-Section_Header',\n",
              " 'I-Medical_History_Header',\n",
              " 'I-Test_Result',\n",
              " 'I-Direction',\n",
              " 'I-Treatment',\n",
              " 'B-Symptom',\n",
              " 'I-Substance',\n",
              " 'B-Treatment',\n",
              " 'B-Substance',\n",
              " 'I-Clinical_Dept',\n",
              " 'I-Death_Entity',\n",
              " 'B-Route',\n",
              " 'B-Drug_Ingredient',\n",
              " 'I-LDL',\n",
              " 'I-Heart_Disease',\n",
              " 'I-Duration',\n",
              " 'B-Blood_Pressure',\n",
              " 'I-Respiration',\n",
              " 'B-Diet',\n",
              " 'I-Age',\n",
              " 'B-External_body_part_or_region',\n",
              " 'B-LDL',\n",
              " 'B-VS_Finding',\n",
              " 'I-O2_Saturation',\n",
              " 'I-Race_Ethnicity',\n",
              " 'I-Substance_Quantity',\n",
              " 'B-Allergen',\n",
              " 'B-EKG_Findings',\n",
              " 'B-Imaging_Technique',\n",
              " 'I-Diet',\n",
              " 'I-Gender',\n",
              " 'I-Allergen',\n",
              " 'B-Triglycerides',\n",
              " 'B-RelativeTime',\n",
              " 'I-Disease_Syndrome_Disorder',\n",
              " 'B-Gender',\n",
              " 'I-Injury_or_Poisoning',\n",
              " 'B-Pulse',\n",
              " 'I-Total_Cholesterol',\n",
              " 'B-Social_History_Header',\n",
              " 'I-Cerebrovascular_Disease',\n",
              " 'B-Substance_Quantity',\n",
              " 'B-Diabetes',\n",
              " 'I-Admission_Discharge',\n",
              " 'B-Modifier',\n",
              " 'B-Internal_organ_or_component',\n",
              " 'B-Clinical_Dept',\n",
              " 'I-Internal_organ_or_component',\n",
              " 'I-RelativeTime',\n",
              " 'I-Vital_Signs_Header',\n",
              " 'I-Hyperlipidemia',\n",
              " 'I-Smoking',\n",
              " 'I-Height',\n",
              " 'I-Drug_Ingredient',\n",
              " 'B-Form',\n",
              " 'I-Employment',\n",
              " 'B-Drug_BrandName',\n",
              " 'B-Strength',\n",
              " 'B-Fetus_NewBorn',\n",
              " 'B-RelativeDate',\n",
              " 'I-Weight',\n",
              " 'B-Height',\n",
              " 'B-Test_Result',\n",
              " 'B-Sexually_Active_or_Sexual_Orientation',\n",
              " 'B-Frequency',\n",
              " 'B-Time',\n",
              " 'I-Strength',\n",
              " 'B-Weight',\n",
              " 'B-Vaccine',\n",
              " 'I-Pregnancy',\n",
              " 'I-Form',\n",
              " 'B-Vital_Signs_Header',\n",
              " 'I-Dosage',\n",
              " 'I-Time',\n",
              " 'B-Communicable_Disease',\n",
              " 'B-Dosage',\n",
              " 'B-Overweight',\n",
              " 'B-Hypertension',\n",
              " 'B-HDL',\n",
              " 'B-Total_Cholesterol',\n",
              " 'I-HDL',\n",
              " 'B-Smoking',\n",
              " 'B-Date']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EL0NQ88ofMur"
      },
      "source": [
        "### Now train a model using this model as base"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-zM49XJbb2j"
      },
      "source": [
        "\n",
        "nerTagger = MedicalNerApproach()\\\n",
        "      .setInputCols([\"sentence\", \"token\", \"embeddings\"])\\\n",
        "      .setLabelColumn(\"label\")\\\n",
        "      .setOutputCol(\"ner\")\\\n",
        "      .setMaxEpochs(2)\\\n",
        "      .setLr(0.003)\\\n",
        "      .setBatchSize(8)\\\n",
        "      .setRandomSeed(0)\\\n",
        "      .setVerbose(1)\\\n",
        "      .setEvaluationLogExtended(True) \\\n",
        "      .setEnableOutputLogs(True)\\\n",
        "      .setIncludeConfidence(True)\\\n",
        "      .setTestDataset('/content/test_2.parquet')\\\n",
        "      .setOutputLogsPath('ner_logs')\\\n",
        "      .setGraphFolder('medical_ner_graphs')\\\n",
        "      .setPretrainedModelPath(\"/root/cache_pretrained/ner_jsl_en_3.1.0_2.4_1624566960534\")\\\n",
        "      .setOverrideExistingTags(True) # since the tags do not align, set this flag to true\n",
        "    \n",
        "# do hyperparameter by tuning the params above (max epoch, LR, dropout etc.) to get better results\n",
        "ner_pipeline = Pipeline(stages=[\n",
        "      clinical_embeddings,\n",
        "      nerTagger\n",
        " ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXKmO-MJbb5N",
        "outputId": "54020a1c-c360-4174-a513-e8b8b9a599d5"
      },
      "source": [
        "\n",
        "%%time\n",
        "ner_jsl_retrained = ner_pipeline.fit(training_data)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4.14 s, sys: 438 ms, total: 4.58 s\n",
            "Wall time: 14min\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ra_btnoXgvnF",
        "outputId": "d29e6f4e-1448-490d-ea6f-243e49c47677"
      },
      "source": [
        "!cat ./ner_logs/MedicalNerApproach_880049ba07d7.log"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat: ./ner_logs/MedicalNerApproach_880049ba07d7.log: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKeO-Kqcbb7i",
        "outputId": "927ad5a4-f1bb-431b-c97b-7b31ce0e64bb"
      },
      "source": [
        "from sparknlp_jsl.eval import NerDLMetrics\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "pred_df = ner_jsl_retrained.stages[1].transform(clinical_embeddings.transform(test_data_2))\n",
        "\n",
        "evaler = NerDLMetrics(mode=\"full_chunk\", dropO=True)\n",
        "\n",
        "eval_result = evaler.computeMetricsFromDF(pred_df.select(\"label\",\"ner\"), prediction_col=\"ner\", label_col=\"label\").cache()\n",
        "\n",
        "eval_result.withColumn(\"precision\", F.round(eval_result[\"precision\"],4))\\\n",
        "    .withColumn(\"recall\", F.round(eval_result[\"recall\"],4))\\\n",
        "    .withColumn(\"f1\", F.round(eval_result[\"f1\"],4)).show(100)\n",
        "\n",
        "print(eval_result.selectExpr(\"avg(f1) as macro\").show())\n",
        "print (eval_result.selectExpr(\"sum(f1*total) as sumprod\",\"sum(total) as sumtotal\").selectExpr(\"sumprod/sumtotal as micro\").show())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+----+----+-----+---------+------+------+\n",
            "| entity|   tp|  fp|  fn|total|precision|recall|    f1|\n",
            "+-------+-----+----+----+-----+---------+------+------+\n",
            "|Disease|384.0|80.0|76.0|460.0|   0.8276|0.8348|0.8312|\n",
            "+-------+-----+----+----+-----+---------+------+------+\n",
            "\n",
            "+------------------+\n",
            "|             macro|\n",
            "+------------------+\n",
            "|0.8311688311688312|\n",
            "+------------------+\n",
            "\n",
            "None\n",
            "+------------------+\n",
            "|             micro|\n",
            "+------------------+\n",
            "|0.8311688311688312|\n",
            "+------------------+\n",
            "\n",
            "None\n"
          ]
        }
      ]
    }
  ]
}