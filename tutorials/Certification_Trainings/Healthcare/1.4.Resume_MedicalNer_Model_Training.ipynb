{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I08sFJYCxR0Z"
      },
      "source": [
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwJ-P56kq6FU"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.4.Resume_MedicalNer_Model_Training.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ztGkR5mb6zN"
      },
      "source": [
        "# 1.4 Resume MedicalNer Model Training\n",
        "\n",
        "Steps:\n",
        "- Train a new model for a few epochs.\n",
        "- Load the same model and train for more epochs on the same taxnonomy, and check stats.\n",
        "- Train a model already trained on a different data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-68NMdHxJIco"
      },
      "source": [
        "## Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9Mn1PNTNJTq"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "if 'spark_jsl.json' not in os.listdir():\n",
        "  license_keys = files.upload()\n",
        "  os.rename(list(license_keys.keys())[0], 'spark_jsl.json')\n",
        "\n",
        "with open('spark_jsl.json') as f:\n",
        "    license_keys = json.load(f)\n",
        "\n",
        "# Defining license key-value pairs as local variables\n",
        "locals().update(license_keys)\n",
        "os.environ.update(license_keys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvHraBK7b-LU"
      },
      "outputs": [],
      "source": [
        "# Installing pyspark and spark-nlp\n",
        "! pip install --upgrade -q pyspark==3.1.2 spark-nlp==$PUBLIC_VERSION\n",
        "\n",
        "# Installing Spark NLP Healthcare\n",
        "! pip install --upgrade -q spark-nlp-jsl==$JSL_VERSION  --extra-index-url https://pypi.johnsnowlabs.com/$SECRET\n",
        "\n",
        "# Installing Spark NLP Display Library for visualization\n",
        "! pip install -q spark-nlp-display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIp1yLCWNWsn"
      },
      "outputs": [],
      "source": [
        "# if you want to start the session with custom params as in start function above\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "def start(SECRET):\n",
        "    builder = SparkSession.builder \\\n",
        "        .appName(\"Spark NLP Licensed\") \\\n",
        "        .master(\"local[*]\") \\\n",
        "        .config(\"spark.driver.memory\", \"16G\") \\\n",
        "        .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
        "        .config(\"spark.kryoserializer.buffer.max\", \"2000M\") \\\n",
        "        .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:\"+PUBLIC_VERSION) \\\n",
        "        .config(\"spark.jars\", \"https://pypi.johnsnowlabs.com/\"+SECRET+\"/spark-nlp-jsl-\"+JSL_VERSION+\".jar\")\n",
        "      \n",
        "    return builder.getOrCreate()\n",
        "\n",
        "#spark = start(SECRET)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "1t5Kp93GcH7z",
        "outputId": "7b989fab-8638-42d4-f8ca-a69a69418bcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Spark NLP Version : 4.2.4\n",
            "Spark NLP_JSL Version : 4.2.3\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://cfcf75c7cb77:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark NLP Licensed</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f7f753f6130>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "from pyspark.ml import Pipeline,PipelineModel\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "import sparknlp_jsl\n",
        "import sparknlp\n",
        "\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp_jsl.annotator import *\n",
        "from sparknlp.base import *\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "params = {\"spark.driver.memory\":\"16G\", # Amount of memory to use for the driver process, i.e. where SparkContext is initialized\n",
        "          \"spark.kryoserializer.buffer.max\":\"2000M\", # Maximum allowable size of Kryo serialization buffer, in MiB unless otherwise specified. \n",
        "          \"spark.driver.maxResultSize\":\"2000M\"} # Limit of total size of serialized results of all partitions for each Spark action (e.g. collect) in bytes. \n",
        "                                                # Should be at least 1M, or 0 for unlimited. \n",
        "\n",
        "spark = sparknlp_jsl.start(license_keys['SECRET'],params=params)\n",
        "\n",
        "print (\"Spark NLP Version :\", sparknlp.version())\n",
        "print (\"Spark NLP_JSL Version :\", sparknlp_jsl.version())\n",
        "\n",
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeWhvSsHRXsf"
      },
      "source": [
        "## Download Clinical Word Embeddings for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ua5dHNeyRWQc",
        "outputId": "6120bdb3-091f-48c3-b56e-0c9ffb4cab88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "embeddings_clinical download started this may take some time.\n",
            "Approximate size to download 1.6 GB\n",
            "[OK!]\n"
          ]
        }
      ],
      "source": [
        "clinical_embeddings = WordEmbeddingsModel.pretrained('embeddings_clinical', \"en\", \"clinical/models\")\\\n",
        "    .setInputCols([\"sentence\", \"token\"])\\\n",
        "    .setOutputCol(\"embeddings\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfT1AaKvOG4J"
      },
      "source": [
        "## Download Data for Training (NCBI Disease Dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMOycTPUcty7"
      },
      "outputs": [],
      "source": [
        "!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Healthcare/data/NCBI_disease_official_test.conll\n",
        "!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Healthcare/data/NCBI_disease_official_train_dev.conll"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FetZIfagc-eh",
        "outputId": "515d46c0-1def-4b99-e242-214ae4f37f1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                text|            document|            sentence|               token|                 pos|               label|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|Identification of...|[{document, 0, 89...|[{document, 0, 89...|[{token, 0, 13, I...|[{pos, 0, 13, NN,...|[{named_entity, 0...|\n",
            "|The adenomatous p...|[{document, 0, 21...|[{document, 0, 21...|[{token, 0, 2, Th...|[{pos, 0, 2, NN, ...|[{named_entity, 0...|\n",
            "|Complex formation...|[{document, 0, 63...|[{document, 0, 63...|[{token, 0, 6, Co...|[{pos, 0, 6, NN, ...|[{named_entity, 0...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sparknlp.training import CoNLL\n",
        "\n",
        "training_data = CoNLL().readDataset(spark, 'NCBI_disease_official_train_dev.conll')\n",
        "\n",
        "training_data.show(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fm1bfPJidC9X",
        "outputId": "bea04f77-1045-467d-fcea-86424681a240"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                text|            document|            sentence|               token|                 pos|               label|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|Clustering of mis...|[{document, 0, 10...|[{document, 0, 10...|[{token, 0, 9, Cl...|[{pos, 0, 9, NN, ...|[{named_entity, 0...|\n",
            "|Ataxia - telangie...|[{document, 0, 13...|[{document, 0, 13...|[{token, 0, 5, At...|[{pos, 0, 5, NN, ...|[{named_entity, 0...|\n",
            "|The risk of cance...|[{document, 0, 15...|[{document, 0, 15...|[{token, 0, 2, Th...|[{pos, 0, 2, NN, ...|[{named_entity, 0...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sparknlp.training import CoNLL\n",
        "\n",
        "test_data = CoNLL().readDataset(spark, 'NCBI_disease_official_test.conll')\n",
        "\n",
        "test_data.show(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaTp5atqc_C-"
      },
      "source": [
        "## Split the test data into two parts:\n",
        "- We Keep the first part separate and use it for training the model further, as it will be totally unseen data from the same taxonomy.\n",
        "\n",
        "- The second part will be used to testing and evaluating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_gInTNZRhnC"
      },
      "outputs": [],
      "source": [
        "(test_data_1, test_data_2) = test_data.randomSplit([0.5, 0.5], seed = 100)\n",
        "\n",
        "# save the test data as parquet for easy testing\n",
        "clinical_embeddings.transform(test_data_1).write.parquet('test_1.parquet')\n",
        "\n",
        "clinical_embeddings.transform(test_data_2).write.parquet('test_2.parquet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WX2jO2FPRo6Q"
      },
      "source": [
        "## Train a new model, pause, and resume training on the same dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tc2Uoh_YR3dA"
      },
      "source": [
        "### Create a graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fk-SQ7Xng6An"
      },
      "source": [
        "We will use `TFGraphBuilder` annotator which can be used to create graphs in the model training pipeline. `TFGraphBuilder` inspects the data and creates the proper graph if a suitable version of TensorFlow (<= 2.7 ) is available. The graph is stored in the defined folder and loaded by the approach."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xn9AfwXOhIAA",
        "outputId": "5cd1c950-38cf-4874-be6d-5d4f48b45ffa"
      },
      "outputs": [],
      "source": [
        "!pip install -q tensorflow==2.7.0\n",
        "!pip install -q tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jp7luV4-wRsc"
      },
      "outputs": [],
      "source": [
        "from sparknlp_jsl.annotator import TFGraphBuilder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSQ4X33bwZL1"
      },
      "outputs": [],
      "source": [
        "graph_folder_path = \"medical_ner_graphs\"\n",
        "\n",
        "ner_graph_builder = TFGraphBuilder()\\\n",
        "    .setModelName(\"ner_dl\")\\\n",
        "    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
        "    .setLabelColumn(\"label\")\\\n",
        "    .setGraphFolder(graph_folder_path)\\\n",
        "    .setGraphFile(\"auto\")\\\n",
        "    .setHiddenUnitsNumber(24)\\\n",
        "    .setIsMedical(True) # False -> if you want to use TFGraphBuilder with NerDLApproach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "WFzmo-JzRs3x",
        "outputId": "8b452ed5-8f41-48e3-816b-c42695a0a42d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nfrom sparknlp_jsl.training import tf_graph\\n\\ntf_graph.print_model_params(\"ner_dl\")\\n\\ngraph_folder_path = \"medical_ner_graphs\"\\ntf_graph.build(\"ner_dl\",\\n               build_params={\"embeddings_dim\": 200,\\n                             \"nchars\": 128,\\n                             \"ntags\": 12,\\n                             \"is_medical\": 1},\\n                model_location=graph_folder_path,\\n                model_filename=\"auto\")\\n'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# You can create custom TensorFlow graph file (`.pb` extension) for NER model training externally by using the script below. \n",
        "# If this method is used, graph folder should be added to MedicalNerApproach as  `.setGraphFolder(graph_folder_path)` .\n",
        "\n",
        "'''\n",
        "from sparknlp_jsl.training import tf_graph\n",
        "\n",
        "tf_graph.print_model_params(\"ner_dl\")\n",
        "\n",
        "graph_folder_path = \"medical_ner_graphs\"\n",
        "tf_graph.build(\"ner_dl\",\n",
        "               build_params={\"embeddings_dim\": 200,\n",
        "                             \"nchars\": 128,\n",
        "                             \"ntags\": 12,\n",
        "                             \"is_medical\": 1},\n",
        "                model_location=graph_folder_path,\n",
        "                model_filename=\"auto\")\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PT5pF7V7R69G"
      },
      "source": [
        "### Train for 2 epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7J4j069R9ty"
      },
      "outputs": [],
      "source": [
        "nerTagger = MedicalNerApproach()\\\n",
        "      .setInputCols([\"sentence\", \"token\", \"embeddings\"])\\\n",
        "      .setLabelColumn(\"label\")\\\n",
        "      .setOutputCol(\"ner\")\\\n",
        "      .setMaxEpochs(2)\\\n",
        "      .setLr(0.003)\\\n",
        "      .setBatchSize(8)\\\n",
        "      .setRandomSeed(0)\\\n",
        "      .setVerbose(1)\\\n",
        "      .setEvaluationLogExtended(True) \\\n",
        "      .setEnableOutputLogs(True)\\\n",
        "      .setIncludeConfidence(True)\\\n",
        "      .setTestDataset('./test_2.parquet')\\\n",
        "      .setGraphFolder(graph_folder_path)\\\n",
        "      .setOutputLogsPath('./ner_logs')\n",
        "\n",
        "ner_pipeline = Pipeline(stages=[\n",
        "      clinical_embeddings,\n",
        "      ner_graph_builder,\n",
        "      nerTagger\n",
        " ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5Phv3rFSBR_",
        "outputId": "886b06a1-b5de-4018-fa6c-827c5534845c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TF Graph Builder configuration:\n",
            "Model name: ner_dl\n",
            "Graph folder: medical_ner_graphs\n",
            "Graph file name: auto\n",
            "Build params: {'ntags': 3, 'embeddings_dim': 200, 'nchars': 85, 'is_medical': True, 'lstm_size': 24}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ner_dl graph exported to medical_ner_graphs/blstm_3_200_24_85.pb\n",
            "CPU times: user 13.4 s, sys: 1.32 s, total: 14.7 s\n",
            "Wall time: 2min 6s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "ner_model = ner_pipeline.fit(training_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYc5M2JHNTrQ",
        "outputId": "29f0cc1a-56ad-40fe-852c-6e4c0a35346e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ner_logs/MedicalNerApproach_6d303ccf6ea4.log\n"
          ]
        }
      ],
      "source": [
        "!ls ner_logs/MedicalNerApproach*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPZ2tmHFSBUy",
        "outputId": "07f6409b-5666-4677-9c4c-4a5ee16927ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name of the selected graph: /content/medical_ner_graphs/blstm_3_200_24_85.pb\n",
            "Training started - total epochs: 2 - lr: 0.003 - batch size: 8 - labels: 3 - chars: 84 - training examples: 6347\n",
            "\n",
            "\n",
            "Epoch 1/2 started, lr: 0.003, dataset size: 6347\n",
            "\n",
            "\n",
            "Epoch 1/2 - 42.49s - loss: 2712.2107 - avg training loss: 3.4115858 - batches: 795\n",
            "Quality on test dataset: \n",
            "time to finish evaluation: 1.76s\n",
            "Total test loss: 95.0218\tAvg test loss: 1.4397\n",
            "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
            "I-Disease\t 477\t 57\t 106\t 0.89325845\t 0.8181818\t 0.8540734\n",
            "B-Disease\t 430\t 95\t 88\t 0.81904763\t 0.83011585\t 0.82454455\n",
            "tp: 907 fp: 152 fn: 194 labels: 2\n",
            "Macro-average\t prec: 0.856153, rec: 0.82414883, f1: 0.83984613\n",
            "Micro-average\t prec: 0.8564684, rec: 0.8237966, f1: 0.83981484\n",
            "\n",
            "\n",
            "Epoch 2/2 started, lr: 0.0029850747, dataset size: 6347\n",
            "\n",
            "\n",
            "Epoch 2/2 - 39.88s - loss: 1117.19 - avg training loss: 1.4052703 - batches: 795\n",
            "Quality on test dataset: \n",
            "time to finish evaluation: 1.06s\n",
            "Total test loss: 64.9433\tAvg test loss: 0.9840\n",
            "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
            "I-Disease\t 501\t 67\t 82\t 0.8820422\t 0.8593482\t 0.8705473\n",
            "B-Disease\t 439\t 95\t 79\t 0.82209736\t 0.8474904\t 0.83460075\n",
            "tp: 940 fp: 162 fn: 161 labels: 2\n",
            "Macro-average\t prec: 0.8520698, rec: 0.8534193, f1: 0.852744\n",
            "Micro-average\t prec: 0.85299456, rec: 0.8537693, f1: 0.85338175\n"
          ]
        }
      ],
      "source": [
        "# Training Logs\n",
        "! cat ner_logs/MedicalNerApproach*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2onzNGuP_QH"
      },
      "outputs": [],
      "source": [
        "# Logs of 4 consecutive epochs to compare with 2+2 epochs on separate datasets from same taxonomy\n",
        "\n",
        "#!cat ner_logs/MedicalNerApproach_4d3d69967c3f.log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLKJpTfKWLwC"
      },
      "source": [
        "### Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1vuNwvOAdqr",
        "outputId": "0ebee96f-672f-4b8f-f9cf-bbbbdfb7dcf0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+-----+-----+----+-----+---------+------+------+\n",
            "| entity|   tp|   fp|  fn|total|precision|recall|    f1|\n",
            "+-------+-----+-----+----+-----+---------+------+------+\n",
            "|Disease|423.0|111.0|92.0|515.0|   0.7921|0.8214|0.8065|\n",
            "+-------+-----+-----+----+-----+---------+------+------+\n",
            "\n",
            "+------------------+\n",
            "|             macro|\n",
            "+------------------+\n",
            "|0.8064823641563393|\n",
            "+------------------+\n",
            "\n",
            "None\n",
            "+------------------+\n",
            "|             micro|\n",
            "+------------------+\n",
            "|0.8064823641563393|\n",
            "+------------------+\n",
            "\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "from sparknlp_jsl.eval import NerDLMetrics\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "pred_df = ner_model.stages[2].transform(clinical_embeddings.transform(test_data_2))\n",
        "\n",
        "evaler = NerDLMetrics(mode=\"full_chunk\")\n",
        "\n",
        "eval_result = evaler.computeMetricsFromDF(pred_df.select(\"label\",\"ner\"), prediction_col=\"ner\", label_col=\"label\", drop_o = True, case_sensitive = True).cache()\n",
        "\n",
        "eval_result.withColumn(\"precision\", F.round(eval_result[\"precision\"],4))\\\n",
        "           .withColumn(\"recall\", F.round(eval_result[\"recall\"],4))\\\n",
        "           .withColumn(\"f1\", F.round(eval_result[\"f1\"],4)).show(100)\n",
        "\n",
        "print(eval_result.selectExpr(\"avg(f1) as macro\").show())\n",
        "print (eval_result.selectExpr(\"sum(f1*total) as sumprod\",\"sum(total) as sumtotal\").selectExpr(\"sumprod/sumtotal as micro\").show())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`ner_utils`: This new module is used after NER training to calculate mertic chunkbase and plot training logs.\n",
        "\n",
        "`evaluate`: if verbose, returns overall performance, as well as performance per chunk type; otherwise, simply returns overall precision, recall, f1 scores\n",
        "\n",
        "`loss_plot`: Plots the figure of loss vs epochs\n",
        "\n",
        "`get_charts` : Plots the figures of metrics ( precision, recall, f1) vs epochs\n",
        "\n",
        "```\n",
        "from sparknlp_jsl.utils.ner_utils import get_charts, loss_plot, evaluate\n",
        "\n",
        "metrics = evaluate(preds_df['prediction'].values, preds_df['ground_truth'].values)\n",
        "\n",
        "loss_plot(f\"./ner_logs/{log_file}\")\n",
        "\n",
        "get_charts('./ner_logs/'+log_files[0])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77HQ3yYyT-RZ"
      },
      "source": [
        "### Save the model to disk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KEUa1yaSBZW"
      },
      "outputs": [],
      "source": [
        "ner_model.stages[2].write().overwrite().save('models/NCBI_NER_2_epoch')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_U4mQcXUTg7"
      },
      "source": [
        "### Train using the saved model on unseen dataset\n",
        "#### We use unseen data from same taxonomy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgFviuf5SBei"
      },
      "outputs": [],
      "source": [
        "nerTagger = MedicalNerApproach()\\\n",
        "      .setInputCols([\"sentence\", \"token\", \"embeddings\"])\\\n",
        "      .setLabelColumn(\"label\")\\\n",
        "      .setOutputCol(\"ner\")\\\n",
        "      .setMaxEpochs(2)\\\n",
        "      .setLr(0.003)\\\n",
        "      .setBatchSize(8)\\\n",
        "      .setRandomSeed(0)\\\n",
        "      .setVerbose(1)\\\n",
        "      .setEvaluationLogExtended(True) \\\n",
        "      .setEnableOutputLogs(True)\\\n",
        "      .setIncludeConfidence(True)\\\n",
        "      .setTestDataset('/content/test_2.parquet')\\\n",
        "      .setOutputLogsPath('ner_logs')\\\n",
        "      .setGraphFolder(graph_folder_path)\\\n",
        "      .setPretrainedModelPath(\"models/NCBI_NER_2_epoch\") ## load existing model\n",
        "    \n",
        "ner_pipeline = Pipeline(stages=[\n",
        "      clinical_embeddings,\n",
        "      ner_graph_builder,\n",
        "      nerTagger\n",
        " ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kics80lUTXTG"
      },
      "outputs": [],
      "source": [
        "# remove the existing logs\n",
        "\n",
        "! rm -r ./ner_logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVZGKEsKUSrS",
        "outputId": "ad811e57-915e-4ead-f639-af136d9b4679"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TF Graph Builder configuration:\n",
            "Model name: ner_dl\n",
            "Graph folder: medical_ner_graphs\n",
            "Graph file name: auto\n",
            "Build params: {'ntags': 3, 'embeddings_dim': 200, 'nchars': 79, 'is_medical': True, 'lstm_size': 24}\n",
            "ner_dl graph exported to medical_ner_graphs/blstm_3_200_24_79.pb\n",
            "CPU times: user 7.78 s, sys: 224 ms, total: 8.01 s\n",
            "Wall time: 23.1 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "ner_model_retrained = ner_pipeline.fit(test_data_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEvNYEXGTTE3",
        "outputId": "4aa0f5b4-183f-456f-da9b-12dbcf38b28b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ner_logs/MedicalNerApproach_04c1df1e3bbb.log\n"
          ]
        }
      ],
      "source": [
        "!ls ner_logs/MedicalNerApproach*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVTfOVnIgwpP",
        "outputId": "e2d08dda-e418-4520-d010-13923161e698"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name of the selected graph: pretrained graph\n",
            "Training started - total epochs: 2 - lr: 0.003 - batch size: 8 - labels: 3 - chars: 84 - training examples: 434\n",
            "\n",
            "\n",
            "Epoch 1/2 started, lr: 0.003, dataset size: 434\n",
            "\n",
            "\n",
            "Epoch 1/2 - 5.11s - loss: 81.33374 - avg training loss: 1.4523882 - batches: 56\n",
            "Quality on test dataset: \n",
            "time to finish evaluation: 1.67s\n",
            "Total test loss: 62.4788\tAvg test loss: 0.9466\n",
            "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
            "I-Disease\t 491\t 55\t 92\t 0.8992674\t 0.8421955\t 0.8697963\n",
            "B-Disease\t 446\t 85\t 72\t 0.8399247\t 0.8610039\t 0.85033363\n",
            "tp: 937 fp: 140 fn: 164 labels: 2\n",
            "Macro-average\t prec: 0.869596, rec: 0.8515997, f1: 0.8605038\n",
            "Micro-average\t prec: 0.8700093, rec: 0.8510445, f1: 0.8604223\n",
            "\n",
            "\n",
            "Epoch 2/2 started, lr: 0.0029850747, dataset size: 434\n",
            "\n",
            "\n",
            "Epoch 2/2 - 3.10s - loss: 69.974945 - avg training loss: 1.2495526 - batches: 56\n",
            "Quality on test dataset: \n",
            "time to finish evaluation: 1.12s\n",
            "Total test loss: 63.6119\tAvg test loss: 0.9638\n",
            "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
            "I-Disease\t 514\t 103\t 69\t 0.8330632\t 0.88164663\t 0.8566666\n",
            "B-Disease\t 463\t 91\t 55\t 0.8357401\t 0.8938224\t 0.86380595\n",
            "tp: 977 fp: 194 fn: 124 labels: 2\n",
            "Macro-average\t prec: 0.8344016, rec: 0.88773453, f1: 0.86024225\n",
            "Micro-average\t prec: 0.8343296, rec: 0.8873751, f1: 0.86003524\n"
          ]
        }
      ],
      "source": [
        "!cat ./ner_logs/MedicalNerApproach*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_vg2Ajse6aZ",
        "outputId": "cdf95650-8cc0-4023-f58b-8c98acff517c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+-----+-----+----+-----+---------+------+------+\n",
            "| entity|   tp|   fp|  fn|total|precision|recall|    f1|\n",
            "+-------+-----+-----+----+-----+---------+------+------+\n",
            "|Disease|443.0|113.0|72.0|515.0|   0.7968|0.8602|0.8273|\n",
            "+-------+-----+-----+----+-----+---------+------+------+\n",
            "\n",
            "+------------------+\n",
            "|             macro|\n",
            "+------------------+\n",
            "|0.8272642390289449|\n",
            "+------------------+\n",
            "\n",
            "None\n",
            "+------------------+\n",
            "|             micro|\n",
            "+------------------+\n",
            "|0.8272642390289449|\n",
            "+------------------+\n",
            "\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "from sparknlp_jsl.eval import NerDLMetrics\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "pred_df = ner_model_retrained.stages[2].transform(clinical_embeddings.transform(test_data_2))\n",
        "\n",
        "evaler = NerDLMetrics(mode=\"full_chunk\")\n",
        "\n",
        "eval_result = evaler.computeMetricsFromDF(pred_df.select(\"label\",\"ner\"), prediction_col=\"ner\", label_col=\"label\", drop_o = True, case_sensitive = True).cache()\n",
        "\n",
        "eval_result.withColumn(\"precision\", F.round(eval_result[\"precision\"],4))\\\n",
        "           .withColumn(\"recall\", F.round(eval_result[\"recall\"],4))\\\n",
        "           .withColumn(\"f1\", F.round(eval_result[\"f1\"],4)).show(100)\n",
        "\n",
        "print(eval_result.selectExpr(\"avg(f1) as macro\").show())\n",
        "print (eval_result.selectExpr(\"sum(f1*total) as sumprod\",\"sum(total) as sumtotal\").selectExpr(\"sumprod/sumtotal as micro\").show())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8u8us0sQl3v-"
      },
      "source": [
        "### Train a Model Choosing Best Model\n",
        "\n",
        "`useBestModel`:  This param preserves and restores the model that has achieved the best performance at the end of the training. The priority is metrics from testDataset (micro F1), metrics from validationSplit (micro F1), and if none is set it will keep track of loss during the training. <br/>\n",
        "\n",
        "`earlyStopping`: You can stop training at the point when the perforfmance on test/validation dataset starts to degrage. Two params are used in order to use this feature: <br/> \n",
        "\n",
        "- `earlyStoppingCriterion`: This is used set the minimal improvement of the test metric to terminate training. The metric monitored is the same as the metrics used in `useBestModel` (micro F1 when using test/validation set, loss otherwise). Default is 0 which means no early stopping is applied. \n",
        "\n",
        "- `earlyStoppingPatience`:  The number of epoch without improvement which will be tolerated. Default is 0, which means that early stopping will occur at the first time when performance in the current epoch is no better than in the previous epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zJQnhWDu2Qb"
      },
      "outputs": [],
      "source": [
        "# remove the existing logs\n",
        "\n",
        "! rm -r ./ner_logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5RXqqaMncrr"
      },
      "outputs": [],
      "source": [
        "nerTagger = MedicalNerApproach()\\\n",
        "      .setInputCols([\"sentence\", \"token\", \"embeddings\"])\\\n",
        "      .setLabelColumn(\"label\")\\\n",
        "      .setOutputCol(\"ner\")\\\n",
        "      .setMaxEpochs(20)\\\n",
        "      .setLr(0.003)\\\n",
        "      .setBatchSize(8)\\\n",
        "      .setRandomSeed(0)\\\n",
        "      .setVerbose(1)\\\n",
        "      .setEvaluationLogExtended(True) \\\n",
        "      .setEnableOutputLogs(True)\\\n",
        "      .setIncludeConfidence(True)\\\n",
        "      .setTestDataset('./test_2.parquet')\\\n",
        "      .setGraphFolder(graph_folder_path)\\\n",
        "      .setOutputLogsPath('./ner_logs')\\\n",
        "      .setValidationSplit(0.2)\\\n",
        "      .setUseBestModel(True)\\\n",
        "      .setEarlyStoppingCriterion(0.04)\\\n",
        "      .setEarlyStoppingPatience(3)\n",
        "\n",
        "\n",
        "ner_pipeline = Pipeline(stages=[\n",
        "      clinical_embeddings,\n",
        "      ner_graph_builder,\n",
        "      nerTagger\n",
        " ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNGGu4O8ncoL",
        "outputId": "4e91cde3-06f5-48e3-a654-456fcc10ec51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TF Graph Builder configuration:\n",
            "Model name: ner_dl\n",
            "Graph folder: medical_ner_graphs\n",
            "Graph file name: auto\n",
            "Build params: {'ntags': 3, 'embeddings_dim': 200, 'nchars': 85, 'is_medical': True, 'lstm_size': 24}\n",
            "ner_dl graph exported to medical_ner_graphs/blstm_3_200_24_85.pb\n",
            "CPU times: user 8.49 s, sys: 277 ms, total: 8.76 s\n",
            "Wall time: 2min 53s\n"
          ]
        }
      ],
      "source": [
        "\n",
        "%%time\n",
        "ner_model = ner_pipeline.fit(training_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cQp6GMml3d2",
        "outputId": "75a3cac3-1a94-4811-c64f-d6e119dc61aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ner_logs/MedicalNerApproach_4975a485ce12.log\n"
          ]
        }
      ],
      "source": [
        "!ls ner_logs/MedicalNerApproach*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sq-Erbk7l3a1",
        "outputId": "4ed5c5c0-3f6e-4eab-e8fd-65cd73de90d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name of the selected graph: /content/medical_ner_graphs/blstm_3_200_24_85.pb\n",
            "Training started - total epochs: 20 - lr: 0.003 - batch size: 8 - labels: 3 - chars: 84 - training examples: 5087\n",
            "\n",
            "\n",
            "Epoch 1/20 started, lr: 0.003, dataset size: 5087\n",
            "\n",
            "\n",
            "Epoch 1/20 - 37.51s - loss: 2562.8733 - avg training loss: 4.0107565 - batches: 639\n",
            "Quality on validation dataset (20.0%), validation examples = 1017\n",
            "time to finish evaluation: 3.39s\n",
            "Total validation loss: 238.5660\tAvg validation loss: 1.4910\n",
            "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
            "I-Disease\t 1132\t 197\t 273\t 0.85176826\t 0.8056939\t 0.8280907\n",
            "B-Disease\t 981\t 257\t 160\t 0.7924071\t 0.85977215\t 0.82471627\n",
            "tp: 2113 fp: 454 fn: 433 labels: 2\n",
            "Macro-average\t prec: 0.82208765, rec: 0.83273304, f1: 0.8273761\n",
            "Micro-average\t prec: 0.82313985, rec: 0.8299293, f1: 0.8265206\n",
            "Quality on test dataset: \n",
            "time to finish evaluation: 1.15s\n",
            "Total test loss: 125.1689\tAvg test loss: 1.8965\n",
            "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
            "I-Disease\t 471\t 97\t 112\t 0.82922536\t 0.80789024\t 0.81841874\n",
            "B-Disease\t 417\t 133\t 101\t 0.7581818\t 0.8050193\t 0.78089887\n",
            "tp: 888 fp: 230 fn: 213 labels: 2\n",
            "Macro-average\t prec: 0.79370356, rec: 0.8064548, f1: 0.8000283\n",
            "Micro-average\t prec: 0.79427546, rec: 0.80653954, f1: 0.8003605\n",
            "\n",
            "\n",
            "Epoch 2/20 started, lr: 0.0029850747, dataset size: 5087\n",
            "\n",
            "\n",
            "Epoch 2/20 - 33.00s - loss: 1082.8433 - avg training loss: 1.6945904 - batches: 639\n",
            "Quality on validation dataset (20.0%), validation examples = 1017\n",
            "time to finish evaluation: 2.50s\n",
            "Total validation loss: 172.2258\tAvg validation loss: 1.0764\n",
            "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
            "I-Disease\t 1117\t 100\t 288\t 0.9178307\t 0.7950178\t 0.8520214\n",
            "B-Disease\t 979\t 144\t 162\t 0.87177205\t 0.8580193\t 0.864841\n",
            "tp: 2096 fp: 244 fn: 450 labels: 2\n",
            "Macro-average\t prec: 0.8948014, rec: 0.82651854, f1: 0.85930556\n",
            "Micro-average\t prec: 0.8957265, rec: 0.82325214, f1: 0.85796154\n",
            "Quality on test dataset: \n",
            "time to finish evaluation: 1.01s\n",
            "Total test loss: 88.6895\tAvg test loss: 1.3438\n",
            "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
            "I-Disease\t 449\t 57\t 134\t 0.88735175\t 0.77015436\t 0.82460976\n",
            "B-Disease\t 415\t 92\t 103\t 0.81854045\t 0.8011583\t 0.8097561\n",
            "tp: 864 fp: 149 fn: 237 labels: 2\n",
            "Macro-average\t prec: 0.8529461, rec: 0.78565633, f1: 0.81791955\n",
            "Micro-average\t prec: 0.8529121, rec: 0.78474116, f1: 0.8174078\n",
            "\n",
            "\n",
            "Epoch 3/20 started, lr: 0.0029702971, dataset size: 5087\n",
            "\n",
            "\n",
            "Epoch 3/20 - 32.73s - loss: 740.55194 - avg training loss: 1.1589233 - batches: 639\n",
            "Quality on validation dataset (20.0%), validation examples = 1017\n",
            "time to finish evaluation: 2.52s\n",
            "Total validation loss: 125.4768\tAvg validation loss: 0.7842\n",
            "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
            "I-Disease\t 1271\t 231\t 134\t 0.84620506\t 0.9046263\t 0.87444097\n",
            "B-Disease\t 989\t 117\t 152\t 0.8942134\t 0.8667835\t 0.88028485\n",
            "tp: 2260 fp: 348 fn: 286 labels: 2\n",
            "Macro-average\t prec: 0.8702092, rec: 0.8857049, f1: 0.8778887\n",
            "Micro-average\t prec: 0.8665644, rec: 0.88766694, f1: 0.87698877\n",
            "Quality on test dataset: \n",
            "time to finish evaluation: 1.02s\n",
            "Total test loss: 65.4780\tAvg test loss: 0.9921\n",
            "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
            "I-Disease\t 517\t 128\t 66\t 0.8015504\t 0.8867925\t 0.8420196\n",
            "B-Disease\t 428\t 74\t 90\t 0.85258967\t 0.82625484\t 0.8392157\n",
            "tp: 945 fp: 202 fn: 156 labels: 2\n",
            "Macro-average\t prec: 0.82707, rec: 0.85652363, f1: 0.8415392\n",
            "Micro-average\t prec: 0.8238884, rec: 0.85831064, f1: 0.84074736\n",
            "\n",
            "\n",
            "Epoch 4/20 started, lr: 0.002955665, dataset size: 5087\n",
            "\n",
            "\n",
            "Epoch 4/20 - 33.19s - loss: 642.25024 - avg training loss: 1.0050864 - batches: 639\n",
            "Quality on validation dataset (20.0%), validation examples = 1017\n",
            "time to finish evaluation: 2.56s\n",
            "Total validation loss: 120.0682\tAvg validation loss: 0.7504\n",
            "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
            "I-Disease\t 1236\t 124\t 169\t 0.90882355\t 0.8797153\t 0.89403254\n",
            "B-Disease\t 1024\t 154\t 117\t 0.86926997\t 0.8974584\t 0.88313925\n",
            "tp: 2260 fp: 278 fn: 286 labels: 2\n",
            "Macro-average\t prec: 0.8890468, rec: 0.8885869, f1: 0.8888168\n",
            "Micro-average\t prec: 0.89046496, rec: 0.88766694, f1: 0.8890637\n",
            "Quality on test dataset: \n",
            "time to finish evaluation: 0.99s\n",
            "Total test loss: 61.2244\tAvg test loss: 0.9276\n",
            "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
            "I-Disease\t 515\t 55\t 68\t 0.9035088\t 0.88336194\t 0.89332175\n",
            "B-Disease\t 461\t 86\t 57\t 0.8427788\t 0.88996136\t 0.8657277\n",
            "tp: 976 fp: 141 fn: 125 labels: 2\n",
            "Macro-average\t prec: 0.8731438, rec: 0.88666165, f1: 0.8798508\n",
            "Micro-average\t prec: 0.87376904, rec: 0.88646686, f1: 0.8800722\n",
            "Early stopping: test set macro F1 has not improved for more than 3 epochs\n"
          ]
        }
      ],
      "source": [
        "# Training Logs\n",
        "! cat ner_logs/MedicalNerApproach*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcTi3HZ-vMpY"
      },
      "source": [
        "As you see above, training was stopped before 20th epoch since there were not improvement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwMDoW2wxiOL"
      },
      "source": [
        "**Evaluate**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRMQ8XuT1qxp",
        "outputId": "1f3ca6fa-2636-46d1-b778-062ad00f5900"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+-----+----+----+-----+---------+------+------+\n",
            "| entity|   tp|  fp|  fn|total|precision|recall|    f1|\n",
            "+-------+-----+----+----+-----+---------+------+------+\n",
            "|Disease|386.0|85.0|54.0|440.0|   0.8195|0.8773|0.8474|\n",
            "+-------+-----+----+----+-----+---------+------+------+\n",
            "\n",
            "+------------------+\n",
            "|             macro|\n",
            "+------------------+\n",
            "|0.8474204171240395|\n",
            "+------------------+\n",
            "\n",
            "None\n",
            "+------------------+\n",
            "|             micro|\n",
            "+------------------+\n",
            "|0.8474204171240395|\n",
            "+------------------+\n",
            "\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "from sparknlp_jsl.eval import NerDLMetrics\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "pred_df = ner_model.stages[2].transform(clinical_embeddings.transform(test_data_1))\n",
        "\n",
        "evaler = NerDLMetrics(mode=\"full_chunk\")\n",
        "\n",
        "eval_result = evaler.computeMetricsFromDF(pred_df.select(\"label\",\"ner\"), prediction_col=\"ner\", label_col=\"label\", drop_o = True, case_sensitive = True).cache()\n",
        "\n",
        "eval_result.withColumn(\"precision\", F.round(eval_result[\"precision\"],4))\\\n",
        "           .withColumn(\"recall\", F.round(eval_result[\"recall\"],4))\\\n",
        "           .withColumn(\"f1\", F.round(eval_result[\"f1\"],4)).show(100)\n",
        "\n",
        "print(eval_result.selectExpr(\"avg(f1) as macro\").show())\n",
        "print (eval_result.selectExpr(\"sum(f1*total) as sumprod\",\"sum(total) as sumtotal\").selectExpr(\"sumprod/sumtotal as micro\").show())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqTsr865oD3H",
        "outputId": "e3eff831-1d0b-4ad5-edfa-9742538e443c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+-----+----+----+-----+---------+------+------+\n",
            "| entity|   tp|  fp|  fn|total|precision|recall|    f1|\n",
            "+-------+-----+----+----+-----+---------+------+------+\n",
            "|Disease|456.0|92.0|59.0|515.0|   0.8321|0.8854|0.8579|\n",
            "+-------+-----+----+----+-----+---------+------+------+\n",
            "\n",
            "+------------------+\n",
            "|             macro|\n",
            "+------------------+\n",
            "|0.8579492003762935|\n",
            "+------------------+\n",
            "\n",
            "None\n",
            "+------------------+\n",
            "|             micro|\n",
            "+------------------+\n",
            "|0.8579492003762935|\n",
            "+------------------+\n",
            "\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "pred_df = ner_model.stages[2].transform(clinical_embeddings.transform(test_data_2))\n",
        "\n",
        "evaler = NerDLMetrics(mode=\"full_chunk\")\n",
        "\n",
        "eval_result = evaler.computeMetricsFromDF(pred_df.select(\"label\",\"ner\"), prediction_col=\"ner\", label_col=\"label\", drop_o = True, case_sensitive = True).cache()\n",
        "\n",
        "eval_result.withColumn(\"precision\", F.round(eval_result[\"precision\"],4))\\\n",
        "           .withColumn(\"recall\", F.round(eval_result[\"recall\"],4))\\\n",
        "           .withColumn(\"f1\", F.round(eval_result[\"f1\"],4)).show(100)\n",
        "\n",
        "print(eval_result.selectExpr(\"avg(f1) as macro\").show())\n",
        "print (eval_result.selectExpr(\"sum(f1*total) as sumprod\",\"sum(total) as sumtotal\").selectExpr(\"sumprod/sumtotal as micro\").show())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rw0jTK2RbMAi"
      },
      "source": [
        "## Now let's take a model trained on a different dataset and train on this dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2eVAVhfUSt0",
        "outputId": "51467913-f2e5-4d73-8665-ad068659c567"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ner_jsl download started this may take some time.\n",
            "[OK!]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['O',\n",
              " 'B-Injury_or_Poisoning',\n",
              " 'B-Direction',\n",
              " 'B-Test',\n",
              " 'I-Route',\n",
              " 'B-Admission_Discharge',\n",
              " 'B-Death_Entity',\n",
              " 'I-Oxygen_Therapy',\n",
              " 'B-Relationship_Status',\n",
              " 'I-Drug_BrandName',\n",
              " 'B-Duration',\n",
              " 'I-Alcohol',\n",
              " 'I-Triglycerides',\n",
              " 'I-Date',\n",
              " 'B-Hyperlipidemia',\n",
              " 'B-Respiration',\n",
              " 'I-Test',\n",
              " 'B-Birth_Entity',\n",
              " 'I-VS_Finding',\n",
              " 'B-Age',\n",
              " 'I-Vaccine_Name',\n",
              " 'I-Social_History_Header',\n",
              " 'B-Labour_Delivery',\n",
              " 'I-Medical_Device',\n",
              " 'B-Family_History_Header',\n",
              " 'B-BMI',\n",
              " 'I-Fetus_NewBorn',\n",
              " 'I-BMI',\n",
              " 'B-Temperature',\n",
              " 'I-Section_Header',\n",
              " 'I-Communicable_Disease',\n",
              " 'I-ImagingFindings',\n",
              " 'I-Psychological_Condition',\n",
              " 'I-Obesity',\n",
              " 'I-Sexually_Active_or_Sexual_Orientation',\n",
              " 'I-Modifier',\n",
              " 'B-Alcohol',\n",
              " 'I-Temperature',\n",
              " 'I-Vaccine',\n",
              " 'I-Symptom',\n",
              " 'I-Pulse',\n",
              " 'B-Kidney_Disease',\n",
              " 'B-Oncological',\n",
              " 'I-EKG_Findings',\n",
              " 'B-Medical_History_Header',\n",
              " 'I-Relationship_Status',\n",
              " 'B-Cerebrovascular_Disease',\n",
              " 'I-Blood_Pressure',\n",
              " 'I-Diabetes',\n",
              " 'B-Oxygen_Therapy',\n",
              " 'B-O2_Saturation',\n",
              " 'B-Psychological_Condition',\n",
              " 'B-Heart_Disease',\n",
              " 'I-Frequency',\n",
              " 'B-Employment',\n",
              " 'B-Obesity',\n",
              " 'B-Disease_Syndrome_Disorder',\n",
              " 'I-Oncological',\n",
              " 'B-Pregnancy',\n",
              " 'I-RelativeDate',\n",
              " 'I-Procedure',\n",
              " 'B-ImagingFindings',\n",
              " 'B-Procedure',\n",
              " 'I-Labour_Delivery',\n",
              " 'B-Medical_Device',\n",
              " 'I-Family_History_Header',\n",
              " 'B-Race_Ethnicity',\n",
              " 'I-Hypertension',\n",
              " 'I-External_body_part_or_region',\n",
              " 'I-Imaging_Technique',\n",
              " 'I-Kidney_Disease',\n",
              " 'B-Section_Header',\n",
              " 'I-Medical_History_Header',\n",
              " 'I-Test_Result',\n",
              " 'I-Direction',\n",
              " 'I-Substance',\n",
              " 'B-Symptom',\n",
              " 'I-Treatment',\n",
              " 'B-Treatment',\n",
              " 'B-Substance',\n",
              " 'I-Clinical_Dept',\n",
              " 'I-Death_Entity',\n",
              " 'B-Route',\n",
              " 'B-Drug_Ingredient',\n",
              " 'I-LDL',\n",
              " 'I-Heart_Disease',\n",
              " 'I-Duration',\n",
              " 'B-Blood_Pressure',\n",
              " 'I-Respiration',\n",
              " 'B-Diet',\n",
              " 'I-Age',\n",
              " 'B-External_body_part_or_region',\n",
              " 'B-LDL',\n",
              " 'B-Vaccine_Name',\n",
              " 'B-VS_Finding',\n",
              " 'I-O2_Saturation',\n",
              " 'I-Race_Ethnicity',\n",
              " 'I-Substance_Quantity',\n",
              " 'B-Allergen',\n",
              " 'B-EKG_Findings',\n",
              " 'B-Imaging_Technique',\n",
              " 'I-Diet',\n",
              " 'I-Gender',\n",
              " 'I-Allergen',\n",
              " 'B-Triglycerides',\n",
              " 'B-RelativeTime',\n",
              " 'I-Disease_Syndrome_Disorder',\n",
              " 'B-Gender',\n",
              " 'B-Pulse',\n",
              " 'I-Injury_or_Poisoning',\n",
              " 'I-Total_Cholesterol',\n",
              " 'B-Social_History_Header',\n",
              " 'I-Cerebrovascular_Disease',\n",
              " 'B-Substance_Quantity',\n",
              " 'B-Diabetes',\n",
              " 'I-Admission_Discharge',\n",
              " 'B-Modifier',\n",
              " 'B-Internal_organ_or_component',\n",
              " 'B-Clinical_Dept',\n",
              " 'I-Internal_organ_or_component',\n",
              " 'I-Vital_Signs_Header',\n",
              " 'I-Height',\n",
              " 'I-Hyperlipidemia',\n",
              " 'I-RelativeTime',\n",
              " 'I-Smoking',\n",
              " 'I-Drug_Ingredient',\n",
              " 'B-Form',\n",
              " 'I-Employment',\n",
              " 'B-Drug_BrandName',\n",
              " 'B-Strength',\n",
              " 'I-Weight',\n",
              " 'B-RelativeDate',\n",
              " 'B-Fetus_NewBorn',\n",
              " 'B-Height',\n",
              " 'B-Test_Result',\n",
              " 'B-Time',\n",
              " 'B-Frequency',\n",
              " 'B-Sexually_Active_or_Sexual_Orientation',\n",
              " 'I-Strength',\n",
              " 'B-Weight',\n",
              " 'B-Vaccine',\n",
              " 'I-Pregnancy',\n",
              " 'I-Form',\n",
              " 'B-Vital_Signs_Header',\n",
              " 'I-Dosage',\n",
              " 'I-Time',\n",
              " 'B-Communicable_Disease',\n",
              " 'B-Dosage',\n",
              " 'B-Overweight',\n",
              " 'B-Hypertension',\n",
              " 'B-HDL',\n",
              " 'B-Total_Cholesterol',\n",
              " 'I-HDL',\n",
              " 'B-Smoking',\n",
              " 'B-Date']"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jsl_ner = MedicalNerModel.pretrained('ner_jsl','en','clinical/models')\n",
        "\n",
        "jsl_ner.getClasses()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EL0NQ88ofMur"
      },
      "source": [
        "### Now train a model using this model as base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-zM49XJbb2j"
      },
      "outputs": [],
      "source": [
        "\n",
        "nerTagger = MedicalNerApproach()\\\n",
        "      .setInputCols([\"sentence\", \"token\", \"embeddings\"])\\\n",
        "      .setLabelColumn(\"label\")\\\n",
        "      .setOutputCol(\"ner\")\\\n",
        "      .setMaxEpochs(2)\\\n",
        "      .setLr(0.003)\\\n",
        "      .setBatchSize(8)\\\n",
        "      .setRandomSeed(0)\\\n",
        "      .setVerbose(1)\\\n",
        "      .setEvaluationLogExtended(True) \\\n",
        "      .setEnableOutputLogs(True)\\\n",
        "      .setIncludeConfidence(True)\\\n",
        "      .setTestDataset('/content/test_2.parquet')\\\n",
        "      .setOutputLogsPath('ner_logs')\\\n",
        "      .setGraphFolder(graph_folder_path)\\\n",
        "      .setPretrainedModelPath(\"/root/cache_pretrained/ner_jsl_en_4.2.0_3.0_1666181370373\")\\\n",
        "      .setOverrideExistingTags(True) # since the tags do not align, set this flag to true\n",
        "    \n",
        "# do hyperparameter by tuning the params above (max epoch, LR, dropout etc.) to get better results\n",
        "ner_pipeline = Pipeline(stages=[\n",
        "      clinical_embeddings,\n",
        "      ner_graph_builder,\n",
        "      nerTagger\n",
        " ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBzX1rcny7X1",
        "outputId": "f65aa10e-98bd-4fa9-b90f-1446dd0403db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rm: cannot remove './ner_logs': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# remove the existing logs\n",
        "\n",
        "! rm -r ./ner_logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXKmO-MJbb5N",
        "outputId": "c0b96b5d-5207-4981-9c04-aeb8b7dc709d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TF Graph Builder configuration:\n",
            "Model name: ner_dl\n",
            "Graph folder: medical_ner_graphs\n",
            "Graph file name: auto\n",
            "Build params: {'ntags': 3, 'embeddings_dim': 200, 'nchars': 85, 'is_medical': True, 'lstm_size': 24}\n",
            "ner_dl graph exported to medical_ner_graphs/blstm_3_200_24_85.pb\n",
            "CPU times: user 9.73 s, sys: 396 ms, total: 10.1 s\n",
            "Wall time: 7min 7s\n"
          ]
        }
      ],
      "source": [
        "\n",
        "%%time\n",
        "ner_jsl_retrained = ner_pipeline.fit(training_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ra_btnoXgvnF",
        "outputId": "da87178d-e669-49be-cb8e-3a1c0abed1d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name of the selected graph: pretrained graph\n",
            "Training started - total epochs: 2 - lr: 0.003 - batch size: 8 - labels: 3 - chars: 103 - training examples: 6347\n",
            "\n",
            "\n",
            "Epoch 1/2 started, lr: 0.003, dataset size: 6347\n",
            "\n",
            "\n",
            "Epoch 1/2 - 196.64s - loss: 1347.1907 - avg training loss: 1.6945795 - batches: 795\n",
            "Quality on test dataset: \n",
            "time to finish evaluation: 8.98s\n",
            "Total test loss: 57.7890\tAvg test loss: 0.8756\n",
            "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
            "I-Disease\t 496\t 48\t 87\t 0.9117647\t 0.85077184\t 0.88021296\n",
            "B-Disease\t 435\t 66\t 83\t 0.8682635\t 0.83976835\t 0.85377824\n",
            "tp: 931 fp: 114 fn: 170 labels: 2\n",
            "Macro-average\t prec: 0.89001405, rec: 0.8452701, f1: 0.86706525\n",
            "Micro-average\t prec: 0.8909091, rec: 0.84559494, f1: 0.86766076\n",
            "\n",
            "\n",
            "Epoch 2/2 started, lr: 0.0029850747, dataset size: 6347\n",
            "\n",
            "\n",
            "Epoch 2/2 - 194.27s - loss: 641.4073 - avg training loss: 0.8068016 - batches: 795\n",
            "Quality on test dataset: \n",
            "time to finish evaluation: 8.46s\n",
            "Total test loss: 56.0495\tAvg test loss: 0.8492\n",
            "label\t tp\t fp\t fn\t prec\t rec\t f1\n",
            "I-Disease\t 536\t 90\t 47\t 0.85623\t 0.9193825\t 0.88668317\n",
            "B-Disease\t 473\t 88\t 45\t 0.84313726\t 0.9131274\t 0.8767377\n",
            "tp: 1009 fp: 178 fn: 92 labels: 2\n",
            "Macro-average\t prec: 0.84968364, rec: 0.916255, f1: 0.8817146\n",
            "Micro-average\t prec: 0.8500421, rec: 0.9164396, f1: 0.88199306\n"
          ]
        }
      ],
      "source": [
        "!cat ./ner_logs/MedicalNerApproach*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPcRwhmDI9y8",
        "outputId": "b2ad3bfe-eb15-4227-8e91-741e9b85129d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+-----+----+----+-----+---------+------+-----+\n",
            "| entity|   tp|  fp|  fn|total|precision|recall|   f1|\n",
            "+-------+-----+----+----+-----+---------+------+-----+\n",
            "|Disease|463.0|95.0|52.0|515.0|   0.8297| 0.899|0.863|\n",
            "+-------+-----+----+----+-----+---------+------+-----+\n",
            "\n",
            "+------------------+\n",
            "|             macro|\n",
            "+------------------+\n",
            "|0.8630009319664492|\n",
            "+------------------+\n",
            "\n",
            "None\n",
            "+------------------+\n",
            "|             micro|\n",
            "+------------------+\n",
            "|0.8630009319664492|\n",
            "+------------------+\n",
            "\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "pred_df = ner_jsl_retrained.stages[2].transform(clinical_embeddings.transform(test_data_2))\n",
        "\n",
        "evaler = NerDLMetrics(mode=\"full_chunk\")\n",
        "\n",
        "eval_result = evaler.computeMetricsFromDF(pred_df.select(\"label\",\"ner\"), prediction_col=\"ner\", label_col=\"label\", drop_o = True, case_sensitive = True).cache()\n",
        "\n",
        "eval_result.withColumn(\"precision\", F.round(eval_result[\"precision\"],4))\\\n",
        "           .withColumn(\"recall\", F.round(eval_result[\"recall\"],4))\\\n",
        "           .withColumn(\"f1\", F.round(eval_result[\"f1\"],4)).show(100)\n",
        "\n",
        "print(eval_result.selectExpr(\"avg(f1) as macro\").show())\n",
        "print (eval_result.selectExpr(\"sum(f1*total) as sumprod\",\"sum(total) as sumtotal\").selectExpr(\"sumprod/sumtotal as micro\").show())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_b2TQEnKEQ7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
