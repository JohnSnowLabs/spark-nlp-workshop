{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
      ],
      "metadata": {
        "id": "BfzsuGYbvEGN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/26.Chunk_Mapping.ipynb)"
      ],
      "metadata": {
        "id": "BKXV6gOzvG-B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chunk Mapping"
      ],
      "metadata": {
        "id": "Rx8ANMi103y2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Colab Setup"
      ],
      "metadata": {
        "id": "-DggoJ4cvwsP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "license_keys = files.upload()\n",
        "\n",
        "with open(list(license_keys.keys())[0]) as f:\n",
        "    license_keys = json.load(f)\n",
        "\n",
        "# Defining license key-value pairs as local variables\n",
        "locals().update(license_keys)\n",
        "\n",
        "# Adding license key-value pairs to environment variables\n",
        "os.environ.update(license_keys)"
      ],
      "metadata": {
        "id": "ZAvL7qtju8JM",
        "outputId": "5069b33d-4c5c-4791-87b0-963365ed0dc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a20598d7-5e51-45cf-bb70-57ac132fbfa4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a20598d7-5e51-45cf-bb70-57ac132fbfa4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 4.2.0.spark_nlp_for_healthcare.json to 4.2.0.spark_nlp_for_healthcare.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "# Installing pyspark and spark-nlp\n",
        "! pip install --upgrade -q pyspark==3.1.2 spark-nlp==$PUBLIC_VERSION\n",
        "\n",
        "# Installing Spark NLP Healthcare\n",
        "! pip install --upgrade -q spark-nlp-jsl==$JSL_VERSION  --extra-index-url https://pypi.johnsnowlabs.com/$SECRET"
      ],
      "metadata": {
        "id": "M-DLb0ZMu8Ev"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "from pyspark.ml import Pipeline, PipelineModel\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp_jsl.annotator import *\n",
        "from sparknlp.base import *\n",
        "import sparknlp_jsl\n",
        "import sparknlp\n",
        "import pandas as pd\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "params = {\"spark.driver.memory\":\"16G\", \n",
        "          \"spark.kryoserializer.buffer.max\":\"2000M\", \n",
        "          \"spark.driver.maxResultSize\":\"2000M\"} \n",
        "\n",
        "print (\"Spark NLP Version :\", sparknlp.version())\n",
        "print (\"Spark NLP_JSL Version :\", sparknlp_jsl.version())\n",
        "\n",
        "\n",
        "spark = sparknlp_jsl.start(license_keys['SECRET'],params=params)\n",
        "\n",
        "spark"
      ],
      "metadata": {
        "id": "YvYsq4B1u8A6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "outputId": "e1fe87d9-f5f8-43f0-ed39-e4bf3fcbf598"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP Version : 4.2.0\n",
            "Spark NLP_JSL Version : 4.2.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fc0b0775f10>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://7685eb853aac:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark NLP Licensed</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1- Pretrained Chunk Mapper Models and Pretrained Pipelines"
      ],
      "metadata": {
        "id": "H7Go2B1RvP0C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<center>MAPPER MODELS**\n",
        "\n",
        "|index|model|index|model|index|model|index|model|\n",
        "|-----:|:-----|-----:|:-----|-----:|:-----|-----:|:-----|\n",
        "| 1| [abbreviation_mapper](https://nlp.johnsnowlabs.com/2022/05/11/abbreviation_mapper_en_3_0.html)  | 2| [cvx_code_mapper](https://nlp.johnsnowlabs.com/2022/10/12/cvx_code_mapper_en.html)  | 3| [cvx_name_mapper](https://nlp.johnsnowlabs.com/2022/10/12/cvx_name_mapper_en.html)  | 4| [drug_action_treatment_mapper](https://nlp.johnsnowlabs.com/2022/03/31/drug_action_treatment_mapper_en_3_0.html)  |\n",
        "| 5| [drug_ade_mapper](https://nlp.johnsnowlabs.com/2022/08/23/drug_ade_mapper_en.html)  | 6| [drug_brandname_ndc_mapper](https://nlp.johnsnowlabs.com/2022/05/11/drug_brandname_ndc_mapper_en_3_0.html)  | 7| [icd10_icd9_mapper](https://nlp.johnsnowlabs.com/2022/09/30/icd10_icd9_mapper_en.html)  | 8| [icd10cm_snomed_mapper](https://nlp.johnsnowlabs.com/2022/06/26/icd10cm_snomed_mapper_en_3_0.html)  |\n",
        "| 9| [icd10cm_umls_mapper](https://nlp.johnsnowlabs.com/2022/06/26/icd10cm_umls_mapper_en_3_0.html)  | 10| [icd9_icd10_mapper](https://nlp.johnsnowlabs.com/2022/09/30/icd9_icd10_mapper_en.html)  | 11| [icd9_mapper](https://nlp.johnsnowlabs.com/2022/09/30/icd9_mapper_en.html)  | 12| [icdo_snomed_mapper](https://nlp.johnsnowlabs.com/2022/06/26/icdo_snomed_mapper_en_3_0.html)  |\n",
        "| 13| [mesh_umls_mapper](https://nlp.johnsnowlabs.com/2022/06/26/mesh_umls_mapper_en_3_0.html)  | 14| [normalized_section_header_mapper](https://nlp.johnsnowlabs.com/2022/06/26/normalized_section_header_mapper_en_3_0.html)  | 15| [rxnorm_action_treatment_mapper](https://nlp.johnsnowlabs.com/2022/05/08/rxnorm_action_treatment_mapper_en_3_0.html)  | 16| [rxnorm_mapper](https://nlp.johnsnowlabs.com/2022/06/27/rxnorm_mapper_en_3_0.html)  |\n",
        "| 17| [rxnorm_ndc_mapper](https://nlp.johnsnowlabs.com/2022/05/20/rxnorm_ndc_mapper_en_3_0.html)  | 18| [rxnorm_normalized_mapper](https://nlp.johnsnowlabs.com/2022/09/29/rxnorm_normalized_mapper_en.html)  | 19| [rxnorm_umls_mapper](https://nlp.johnsnowlabs.com/2022/06/26/rxnorm_umls_mapper_en_3_0.html)  | 20| [snomed_icd10cm_mapper](https://nlp.johnsnowlabs.com/2022/06/26/snomed_icd10cm_mapper_en_3_0.html)  |\n",
        "| 21| [snomed_icdo_mapper](https://nlp.johnsnowlabs.com/2022/06/26/snomed_icdo_mapper_en_3_0.html)  | 22| [snomed_umls_mapper](https://nlp.johnsnowlabs.com/2022/06/27/snomed_umls_mapper_en_3_0.html)  | 23| [umls_clinical_drugs_mapper](https://nlp.johnsnowlabs.com/2022/07/06/umls_clinical_drugs_mapper_en_3_0.html)  | 24| [umls_clinical_findings_mapper](https://nlp.johnsnowlabs.com/2022/07/08/umls_clinical_findings_mapper_en_3_0.html)  |\n",
        "| 25| [umls_disease_syndrome_mapper](https://nlp.johnsnowlabs.com/2022/07/11/umls_disease_syndrome_mapper_en_3_0.html)  | 26| [umls_drug_substance_mapper](https://nlp.johnsnowlabs.com/2022/07/11/umls_drug_substance_mapper_en_3_0.html)  | 27| [umls_major_concepts_mapper](https://nlp.johnsnowlabs.com/2022/07/11/umls_major_concepts_mapper_en_3_0.html)  | 28| []()|\n",
        "\n",
        "**You can find all these models and more [NLP Models Hub](https://nlp.johnsnowlabs.com/models?q=Chunk+Mapping&edition=Spark+NLP+for+Healthcare)**\n",
        "\n",
        "<br>\n",
        "\n",
        "**<center>PRETRAINED MAPPER PIPELINES**\n",
        "\n",
        "|index|model|\n",
        "|-----:|:-----|\n",
        "| 1| [icd10_icd9_mapping](https://nlp.johnsnowlabs.com/2022/09/30/icd10_icd9_mapping_en.html)   |\n",
        "| 2| [icdo_snomed_mapping](https://nlp.johnsnowlabs.com/2022/06/27/icdo_snomed_mapping_en_3_0.html)   |\n",
        "| 3| [icd10cm_snomed_mapping](https://nlp.johnsnowlabs.com/2022/06/27/icd10cm_snomed_mapping_en_3_0.html)   |\n",
        "| 4| [rxnorm_ndc_mapping](https://nlp.johnsnowlabs.com/2022/06/27/rxnorm_ndc_mapping_en_3_0.html)   |\n",
        "| 5| [rxnorm_umls_mapping](https://nlp.johnsnowlabs.com/2022/06/27/rxnorm_umls_mapping_en_3_0.html)   |\n",
        "| 6| [snomed_icd10cm_mapping](https://nlp.johnsnowlabs.com/2022/06/27/snomed_icd10cm_mapping_en_3_0.html)   |\n",
        "| 7| [snomed_icdo_mapping](https://nlp.johnsnowlabs.com/2022/06/27/snomed_icdo_mapping_en_3_0.html)   |\n",
        "| 8| [snomed_umls_mapping](https://nlp.johnsnowlabs.com/2022/06/27/snomed_umls_mapping_en_3_0.html)   |\n",
        "| 9| [icd10cm_umls_mapping](https://nlp.johnsnowlabs.com/2022/06/27/icd10cm_umls_mapping_en_3_0.html)   |\n",
        "| 10| [mesh_umls_mapping](https://nlp.johnsnowlabs.com/2021/07/01/mesh_umls_mapping_en.html)   |\n",
        "| 11| [rxnorm_mesh_mapping](https://nlp.johnsnowlabs.com/2021/07/01/rxnorm_mesh_mapping_en.html)   |\n",
        "\n",
        "\n",
        "\n",
        "You can check [Healthcare Code Mapping Notebook](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings_JSL/Healthcare/11.1.Healthcare_Code_Mapping.ipynb) for the examples of pretrained mapper pipelines."
      ],
      "metadata": {
        "id": "RjnUYOjvbVEc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1- Drug Action Treatment Mapper"
      ],
      "metadata": {
        "id": "tun6FxO1V443"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pretrained `drug_action_treatment_mapper` model maps drugs with their corresponding `action` and `treatment` through `ChunkMapperModel()` annotator. <br/>\n",
        "\n",
        "\n",
        "**Action** of drug refers to the function of a drug in various body systems. <br/>\n",
        "**Treatment** refers to which disease the drug is used to treat. \n",
        "\n",
        "We can choose which option we want to use by setting `setRels()` parameter of `ChunkMapperModel()`\n",
        " "
      ],
      "metadata": {
        "id": "NbpIBoXl94ii"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will create a pipeline consisting `bert_token_classifier_drug_development_trials` ner model to extract ner chunk as well as `ChunkMapperModel()`. <br/>\n",
        " Also, we will set the `.setRels()` parameter with `action` and see the results. "
      ],
      "metadata": {
        "id": "rioaJXFnS-q2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ChunkMapper Pipeline\n",
        "document_assembler = DocumentAssembler()\\\n",
        "      .setInputCol('text')\\\n",
        "      .setOutputCol('document')\n",
        "\n",
        "sentence_detector = SentenceDetector()\\\n",
        "      .setInputCols([\"document\"])\\\n",
        "      .setOutputCol(\"sentence\")\n",
        "\n",
        "tokenizer = Tokenizer()\\\n",
        "      .setInputCols(\"sentence\")\\\n",
        "      .setOutputCol(\"token\")\n",
        "\n",
        "ner =  MedicalBertForTokenClassifier.pretrained(\"bert_token_classifier_drug_development_trials\", \"en\", \"clinical/models\")\\\n",
        "      .setInputCols(\"token\",\"sentence\")\\\n",
        "      .setOutputCol(\"ner\")\n",
        "\n",
        "nerconverter = NerConverter()\\\n",
        "      .setInputCols(\"sentence\", \"token\", \"ner\")\\\n",
        "      .setOutputCol(\"ner_chunk\")\n",
        "\n",
        "#drug_action_treatment_mapper with \"action\" mappings\n",
        "chunkerMapper= ChunkMapperModel().pretrained(\"drug_action_treatment_mapper\", \"en\", \"clinical/models\")\\\n",
        "    .setInputCols([\"ner_chunk\"])\\\n",
        "    .setOutputCol(\"action_mappings\")\\\n",
        "    .setRels([\"action\"])\n",
        "    \n",
        "\n",
        "pipeline = Pipeline().setStages([document_assembler,\n",
        "                                 sentence_detector,\n",
        "                                 tokenizer,\n",
        "                                 ner, \n",
        "                                 nerconverter, \n",
        "                                 chunkerMapper])\n",
        "\n",
        "text = [[\"\"\"The patient was female and patient of Dr. X. and she was given Dermovate, Aspagin\"\"\"]]\n",
        "\n",
        "\n",
        "test_data = spark.createDataFrame(text).toDF(\"text\")\n",
        "\n",
        "res = pipeline.fit(test_data).transform(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDE0GMq8xYin",
        "outputId": "f72b4f03-8e93-4cbc-f600-5bfa961d924a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_token_classifier_drug_development_trials download started this may take some time.\n",
            "[OK!]\n",
            "drug_action_treatment_mapper download started this may take some time.\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chunks detected by ner model"
      ],
      "metadata": {
        "id": "0jetN39Hzj63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res.select(F.explode('ner_chunk.result').alias(\"chunks\")).show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDwLFe-QxYdr",
        "outputId": "c846169b-85e1-427c-d0f7-c0f1c5180597"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|chunks   |\n",
            "+---------+\n",
            "|Dermovate|\n",
            "|Aspagin  |\n",
            "+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking mapping results"
      ],
      "metadata": {
        "id": "lCLMKbAOTqTl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res.select(\"action_mappings.result\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAFTxkiaXNTs",
        "outputId": "4bae8d38-b51b-489e-cdde-45ef87bbb613"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------+\n",
            "|result                        |\n",
            "+------------------------------+\n",
            "|[anti-inflammatory, analgesic]|\n",
            "+------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res.selectExpr(\"action_mappings.metadata\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFcIWEa7BSXV",
        "outputId": "fe692e3b-6929-46ef-d80b-c3ce2a78453f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|metadata                                                                                                                                                                                                                                                                                                                      |\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|[{chunk -> 0, relation -> action, confidence -> 0.9997595, all_relations -> corticosteroids::: dermatological preparations:::very strong, entity -> Dermovate, sentence -> 0}, {chunk -> 1, relation -> action, confidence -> 0.99668664, all_relations -> anti-inflammatory:::antipyretic, entity -> Aspagin, sentence -> 0}]|\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you see above under the ***metadata*** column, if exist, we can see all the relations for each chunk. <br/>\n"
      ],
      "metadata": {
        "id": "T25yMbYkVVKI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res.select(F.explode(F.arrays_zip(res.ner_chunk.result, \n",
        "                                  res.action_mappings.result, \n",
        "                                  res.action_mappings.metadata)).alias(\"col\"))\\\n",
        "    .select(F.expr(\"col['0']\").alias(\"ner_chunk\"),\n",
        "            F.expr(\"col['1']\").alias(\"mapping_result\"),\n",
        "            F.expr(\"col['2']['all_relations']\").alias(\"all_relations\")).show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGG75W5JQ8Ds",
        "outputId": "e5be9ec6-2379-48ec-83c8-9fb1bdf4fcce"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------------+------------------------------------------------------------+\n",
            "|ner_chunk|mapping_result   |all_relations                                               |\n",
            "+---------+-----------------+------------------------------------------------------------+\n",
            "|Dermovate|anti-inflammatory|corticosteroids::: dermatological preparations:::very strong|\n",
            "|Aspagin  |analgesic        |anti-inflammatory:::antipyretic                             |\n",
            "+---------+-----------------+------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's set the `.setRels([\"treatment\"])` and see the results. "
      ],
      "metadata": {
        "id": "YsTnjIm90IT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#drug_action_treatment_mapper with \"treatment\" mappings\n",
        "chunkerMapper= ChunkMapperModel().pretrained(\"drug_action_treatment_mapper\", \"en\", \"clinical/models\")\\\n",
        "    .setInputCols([\"ner_chunk\"])\\\n",
        "    .setOutputCol(\"action_mappings\")\\\n",
        "    .setRels([\"treatment\"])\n",
        "\n",
        "pipeline = Pipeline().setStages([document_assembler,\n",
        "                                 sentence_detector,\n",
        "                                 tokenizer,\n",
        "                                 ner, \n",
        "                                 nerconverter, \n",
        "                                 chunkerMapper])\n",
        "\n",
        "text = [\n",
        "    [\"\"\"The patient was female and patient of Dr. X. and she was given Dermovate, Aspagin\"\"\"]\n",
        "]\n",
        "\n",
        "test_data = spark.createDataFrame(text).toDF(\"text\")\n",
        "\n",
        "res = pipeline.fit(test_data).transform(test_data)\n"
      ],
      "metadata": {
        "id": "2UQk9dIKzp_v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3764b92b-a230-4b2c-9e09-0e688852b062"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drug_action_treatment_mapper download started this may take some time.\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res.select(F.explode('ner_chunk.result').alias(\"chunks\")).show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIa_Lioxzp5V",
        "outputId": "c39013f0-d07e-4c1e-dcb9-387457f1045b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|chunks   |\n",
            "+---------+\n",
            "|Dermovate|\n",
            "|Aspagin  |\n",
            "+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res.selectExpr(\"action_mappings.metadata\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6YxxPlOSGAF",
        "outputId": "48e9e44a-7149-40ae-ebd9-3ef4a969fc40"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|metadata                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|[{chunk -> 0, relation -> treatment, confidence -> 0.9997595, all_relations -> discoid lupus erythematosus:::empeines:::psoriasis:::eczema, entity -> Dermovate, sentence -> 0}, {chunk -> 1, relation -> treatment, confidence -> 0.99668664, all_relations -> arthralgia:::pain:::bursitis:::headache:::migraine:::myositis:::neuralgia:::osteoarthritis:::gout:::rheumatoid arthritis:::spondylitis:::spondyloarthritis:::tendinitis:::tenosynovitis:::crush injury:::golfer's elbow, entity -> Aspagin, sentence -> 0}]|\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are the ***treatment*** mappings and all relations under the metadata column. "
      ],
      "metadata": {
        "id": "YFpNGIVzWNl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res.select(F.explode(F.arrays_zip(res.ner_chunk.result, \n",
        "                                  res.action_mappings.result, \n",
        "                                  res.action_mappings.metadata)).alias(\"col\"))\\\n",
        "    .select(F.expr(\"col['0']\").alias(\"ner_chunk\"),\n",
        "            F.expr(\"col['1']\").alias(\"mapping_result\"),\n",
        "            F.expr(\"col['2']['all_relations']\").alias(\"all_relations\")).show(truncate=False)"
      ],
      "metadata": {
        "id": "WaHUwXn8RCeu",
        "outputId": "edb9e430-6cc5-49ac-f368-2ca712c7f9d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|ner_chunk|mapping_result        |all_relations                                                                                                                                                                                                          |\n",
            "+---------+----------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|Dermovate|lupus                 |discoid lupus erythematosus:::empeines:::psoriasis:::eczema                                                                                                                                                            |\n",
            "|Aspagin  |ankylosing spondylitis|arthralgia:::pain:::bursitis:::headache:::migraine:::myositis:::neuralgia:::osteoarthritis:::gout:::rheumatoid arthritis:::spondylitis:::spondyloarthritis:::tendinitis:::tenosynovitis:::crush injury:::golfer's elbow|\n",
            "+---------+----------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2- Section Header Normalizer Mapper"
      ],
      "metadata": {
        "id": "iQMHFp1TvRVX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have `normalized_section_header_mapper` model that normalizes the section headers in clinical notes. It returns two levels of normalization called `level_1` and `level_2`. <br/>\n",
        "\n",
        "**level_1** refers to the most comprehensive \"section header\" for the corresponding chunk while **level_2** refers to the second comprehensive one.\n",
        "\n",
        "Let's create a piepline with `normalized_section_header_mapper` and see how it works"
      ],
      "metadata": {
        "id": "tue53lJXvfdK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document_assembler = DocumentAssembler()\\\n",
        "       .setInputCol('text')\\\n",
        "       .setOutputCol('document')\n",
        "\n",
        "sentence_detector = SentenceDetector()\\\n",
        "       .setInputCols([\"document\"])\\\n",
        "       .setOutputCol(\"sentence\")\n",
        "\n",
        "tokenizer = Tokenizer()\\\n",
        "      .setInputCols(\"sentence\")\\\n",
        "      .setOutputCol(\"token\")\n",
        "\n",
        "embeddings = WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\",\"clinical/models\")\\\n",
        "      .setInputCols([\"sentence\", \"token\"])\\\n",
        "      .setOutputCol(\"word_embeddings\")\n",
        "\n",
        "clinical_ner = MedicalNerModel.pretrained(\"ner_jsl_slim\", \"en\", \"clinical/models\")\\\n",
        "      .setInputCols([\"sentence\",\"token\", \"word_embeddings\"])\\\n",
        "      .setOutputCol(\"ner\")\n",
        "\n",
        "ner_converter = NerConverter()\\\n",
        "      .setInputCols([\"sentence\", \"token\", \"ner\"])\\\n",
        "      .setOutputCol(\"ner_chunk\")\\\n",
        "      .setWhiteList([\"Header\"])\n",
        "\n",
        "chunkerMapper = ChunkMapperModel.pretrained(\"normalized_section_header_mapper\", \"en\", \"clinical/models\") \\\n",
        "       .setInputCols(\"ner_chunk\")\\\n",
        "       .setOutputCol(\"mappings\")\\\n",
        "       .setRels([\"level_1\"]) #or level_2\n",
        "\n",
        "pipeline = Pipeline().setStages([document_assembler,\n",
        "                                sentence_detector,\n",
        "                                tokenizer, \n",
        "                                embeddings,\n",
        "                                clinical_ner, \n",
        "                                ner_converter, \n",
        "                                chunkerMapper])\n",
        "\n",
        "sentences = [\n",
        "    [\"\"\"ADMISSION DIAGNOSIS Right pleural effusion and suspected malignant mesothelioma.\n",
        "        PRINCIPAL DIAGNOSIS Right pleural effusion, suspected malignant mesothelioma.\n",
        "        GENERAL REVIEW Right pleural effusion, firm nodules, diffuse scattered throughout the right pleura and diaphragmatic surface.\n",
        "    \"\"\"]]\n",
        "\n",
        "test_data = spark.createDataFrame(sentences).toDF(\"text\")\n",
        "res = pipeline.fit(test_data).transform(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26Ih_X1JvSV_",
        "outputId": "fffee2cb-25ac-44a7-a792-e5b4b3b51d1a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embeddings_clinical download started this may take some time.\n",
            "Approximate size to download 1.6 GB\n",
            "[OK!]\n",
            "ner_jsl_slim download started this may take some time.\n",
            "[OK!]\n",
            "normalized_section_header_mapper download started this may take some time.\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the headers detected by ner model"
      ],
      "metadata": {
        "id": "3fTn2JPWyxOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res.select(F.explode('ner_chunk.result').alias(\"chunks\")).show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfgyrLomxXv_",
        "outputId": "0bfd3153-0d41-4ffd-af17-7601677b3b05"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+\n",
            "|chunks             |\n",
            "+-------------------+\n",
            "|ADMISSION DIAGNOSIS|\n",
            "|PRINCIPAL DIAGNOSIS|\n",
            "|GENERAL REVIEW     |\n",
            "+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking mapping results"
      ],
      "metadata": {
        "id": "6pv_4VLWzFw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res.select(\"mappings.result\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYZdPVHwxXr9",
        "outputId": "827a8789-0922-4488-8add-38172ad9cbe9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------------+\n",
            "|result                             |\n",
            "+-----------------------------------+\n",
            "|[DIAGNOSIS, DIAGNOSIS, REVIEW TYPE]|\n",
            "+-----------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res.select(F.explode(F.arrays_zip(res.ner_chunk.result, \n",
        "                                  res.mappings.result)).alias(\"col\"))\\\n",
        "    .select(F.expr(\"col['0']\").alias(\"ner_chunk\"),\n",
        "            F.expr(\"col['1']\").alias(\"mapping_result\")).show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqgpO0ANvSOu",
        "outputId": "32a4dc3f-db70-458d-c11e-96581dc67336"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------------+\n",
            "|ner_chunk          |mapping_result|\n",
            "+-------------------+--------------+\n",
            "|ADMISSION DIAGNOSIS|DIAGNOSIS     |\n",
            "|PRINCIPAL DIAGNOSIS|DIAGNOSIS     |\n",
            "|GENERAL REVIEW     |REVIEW TYPE   |\n",
            "+-------------------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you see above, we can see the \"level_1\" based normalized version of each section header."
      ],
      "metadata": {
        "id": "w5OHH23MzjDl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3- Drug Brand Name NDC Mapper"
      ],
      "metadata": {
        "id": "KIUlv3Ka_iwy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have `drug_brandname_ndc_mapper` model that maps drug brand names to corresponding National Drug Codes (NDC). Product NDCs for each strength are returned in result and metadata. <br/>\n",
        "\n",
        "It has one relation type called `Strength_NDC`"
      ],
      "metadata": {
        "id": "JfYOYPF0ALiH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a pipeline with `drug_brandname_ndc_mapper` and see how it works."
      ],
      "metadata": {
        "id": "nsdyOYV1DHdU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document_assembler = DocumentAssembler()\\\n",
        "      .setInputCol(\"text\")\\\n",
        "      .setOutputCol(\"chunk\")\n",
        "\n",
        "chunkerMapper = ChunkMapperModel.pretrained(\"drug_brandname_ndc_mapper\", \"en\", \"clinical/models\")\\\n",
        "      .setInputCols([\"chunk\"])\\\n",
        "      .setOutputCol(\"ndc\")\\\n",
        "      .setRels([\"Strength_NDC\"])\n",
        "\n",
        "pipeline = Pipeline().setStages([document_assembler,\n",
        "                                 chunkerMapper])  \n",
        "\n",
        "model = pipeline.fit(spark.createDataFrame([['']]).toDF('text')) \n",
        "\n",
        "lp = LightPipeline(model)\n",
        "\n",
        "res = lp.fullAnnotate('ZYVOX')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wGtPSK4_ikU",
        "outputId": "830f8800-7944-47e8-a078-f9bce035ebc8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drug_brandname_ndc_mapper download started this may take some time.\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chunks = []\n",
        "mappings = []\n",
        "all_re= []\n",
        "\n",
        "for m, n in list(zip(res[0]['chunk'], res[0][\"ndc\"])):\n",
        "        \n",
        "    chunks.append(m.result)\n",
        "    mappings.append(n.result) \n",
        "    all_re.append(n.metadata[\"all_relations\"])\n",
        "    \n",
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "df = pd.DataFrame({'Brand_Name':chunks, 'Strenth_NDC': mappings, 'Other_NDC':all_re})\n",
        "\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "ArYNThd1DxLr",
        "outputId": "14e2c244-30fa-4222-a69b-376514c8c2ab"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Brand_Name               Strenth_NDC  \\\n",
              "0      ZYVOX  600 mg/300mL | 0009-4992   \n",
              "\n",
              "                                                                                                                                                                                                                                    Other_NDC  \n",
              "0  600 mg/300mL | 66298-7807:::600 mg/300mL | 0009-7807:::600 mg/300mL | 0009-5140:::100 mg/5mL | 0009-5136:::600 mg/1 | 70518-1226:::600 mg/300mL | 66298-5140:::200 mg/100mL | 66298-5137:::200 mg/100mL | 0009-5137:::600 mg/1 | 0009-5138  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-72dba275-13bc-4517-a180-65b5b1d1ce71\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Brand_Name</th>\n",
              "      <th>Strenth_NDC</th>\n",
              "      <th>Other_NDC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ZYVOX</td>\n",
              "      <td>600 mg/300mL | 0009-4992</td>\n",
              "      <td>600 mg/300mL | 66298-7807:::600 mg/300mL | 0009-7807:::600 mg/300mL | 0009-5140:::100 mg/5mL | 0009-5136:::600 mg/1 | 70518-1226:::600 mg/300mL | 66298-5140:::200 mg/100mL | 66298-5137:::200 mg/100mL | 0009-5137:::600 mg/1 | 0009-5138</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-72dba275-13bc-4517-a180-65b5b1d1ce71')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-72dba275-13bc-4517-a180-65b5b1d1ce71 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-72dba275-13bc-4517-a180-65b5b1d1ce71');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you see, we can see corresponding \"NDC\" mappings of each \"brand names\". "
      ],
      "metadata": {
        "id": "Ntq2uH7lDkAq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4- RxNorm NDC Mapper"
      ],
      "metadata": {
        "id": "zBKhGobLESSP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have `rxnorm_ndc_mapper` model that maps RxNorm and RxNorm Extension codes with corresponding National Drug Codes (NDC).\n",
        "\n",
        "It has two relation types that can be defined in `setRel()` parameter; **Product NDC** and **Package NDC**"
      ],
      "metadata": {
        "id": "ODX-0_GxEbFF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a pipeline with `rxnorm_ndc_mapper` model by setting the  relation as `setRel(\"Product NDC\")` and see the results. "
      ],
      "metadata": {
        "id": "fRNTaLYFFET9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document_assembler = DocumentAssembler()\\\n",
        "      .setInputCol('text')\\\n",
        "      .setOutputCol('ner_chunk')\n",
        "\n",
        "sbert_embedder = BertSentenceEmbeddings.pretrained('sbiobert_base_cased_mli', 'en','clinical/models')\\\n",
        "      .setInputCols([\"ner_chunk\"])\\\n",
        "      .setOutputCol(\"sentence_embeddings\")\\\n",
        "      .setCaseSensitive(False)\n",
        "    \n",
        "rxnorm_resolver = SentenceEntityResolverModel.pretrained(\"sbiobertresolve_rxnorm_augmented\",\"en\", \"clinical/models\") \\\n",
        "      .setInputCols([\"ner_chunk\", \"sentence_embeddings\"]) \\\n",
        "      .setOutputCol(\"rxnorm_code\")\\\n",
        "      .setDistanceFunction(\"EUCLIDEAN\")\n",
        "\n",
        "chunkerMapper_product = ChunkMapperModel.pretrained(\"rxnorm_ndc_mapper\", \"en\", \"clinical/models\")\\\n",
        "      .setInputCols([\"rxnorm_code\"])\\\n",
        "      .setOutputCol(\"Product NDC\")\\\n",
        "      .setRels([\"Product NDC\"]) #or Package NDC\n",
        "\n",
        "pipeline = Pipeline().setStages([document_assembler,\n",
        "                                 sbert_embedder,\n",
        "                                 rxnorm_resolver,\n",
        "                                 chunkerMapper_product\n",
        "                                 ])\n",
        "\n",
        "model = pipeline.fit(spark.createDataFrame([['']]).toDF('text')) \n",
        "\n",
        "lp = LightPipeline(model)\n",
        "\n",
        "result = lp.fullAnnotate('macadamia nut 100 MG/ML')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bR1XvJzKEM3n",
        "outputId": "c3398cf0-078d-4576-ef92-7dd63a3709d6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sbiobert_base_cased_mli download started this may take some time.\n",
            "Approximate size to download 384.3 MB\n",
            "[OK!]\n",
            "sbiobertresolve_rxnorm_augmented download started this may take some time.\n",
            "[OK!]\n",
            "rxnorm_ndc_mapper download started this may take some time.\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the results"
      ],
      "metadata": {
        "id": "IeGDZ0-vSRp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chunks = []\n",
        "rxnorm_code = []\n",
        "product= []\n",
        "\n",
        "\n",
        "for m, n, j in list(zip(result[0]['ner_chunk'], result[0][\"rxnorm_code\"], result[0][\"Product NDC\"])):\n",
        "\n",
        "    chunks.append(m.result)\n",
        "    rxnorm_code.append(n.result) \n",
        "    product.append(j.result)\n",
        "    \n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({'ner_chunk':chunks,\n",
        "                   'rxnorm_code': rxnorm_code,\n",
        "                   'Product NDC': product})\n",
        "\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "uw8vKIysl2Gu",
        "outputId": "a9ba35b7-411e-43f3-d823-d0092c030106"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 ner_chunk rxnorm_code Product NDC\n",
              "0  macadamia nut 100 MG/ML      212433  00187-1474"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a52ced4a-da6e-4444-b12d-d4dd588139ee\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ner_chunk</th>\n",
              "      <th>rxnorm_code</th>\n",
              "      <th>Product NDC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>macadamia nut 100 MG/ML</td>\n",
              "      <td>212433</td>\n",
              "      <td>00187-1474</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a52ced4a-da6e-4444-b12d-d4dd588139ee')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a52ced4a-da6e-4444-b12d-d4dd588139ee button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a52ced4a-da6e-4444-b12d-d4dd588139ee');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you see, we can see corresponding \"Product NDC\" mappings of each \"RxNorm codes\"."
      ],
      "metadata": {
        "id": "fvGK4Z7PSns8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5- RxNorm Action Treatment Mapper"
      ],
      "metadata": {
        "id": "ci6QTFAaNvon"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have `rxnorm_action_treatment_mapper` model that maps RxNorm and RxNorm Extension codes with their corresponding action and treatment. It has two relation types that can be defined in `setRel()` parameter; <br/>\n",
        "\n",
        "**Action** of drug refers to the function of a drug in various body systems. <br/>\n",
        "**Treatment** refers to which disease the drug is used to treat."
      ],
      "metadata": {
        "id": "x2L7A0ruN4JD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a pipeline and see how it works. "
      ],
      "metadata": {
        "id": "kX0S24f7cA3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document_assembler = DocumentAssembler()\\\n",
        "      .setInputCol('text')\\\n",
        "      .setOutputCol('ner_chunk')\n",
        "\n",
        "sbert_embedder = BertSentenceEmbeddings.pretrained('sbiobert_base_cased_mli', 'en','clinical/models')\\\n",
        "      .setInputCols([\"ner_chunk\"])\\\n",
        "      .setOutputCol(\"sentence_embeddings\")\\\n",
        "      .setCaseSensitive(False)\n",
        "    \n",
        "rxnorm_resolver = SentenceEntityResolverModel.pretrained(\"sbiobertresolve_rxnorm_augmented\",\"en\", \"clinical/models\") \\\n",
        "      .setInputCols([\"ner_chunk\", \"sentence_embeddings\"]) \\\n",
        "      .setOutputCol(\"rxnorm_code\")\\\n",
        "      .setDistanceFunction(\"EUCLIDEAN\")\n",
        "\n",
        "chunkerMapper_action = ChunkMapperModel.pretrained(\"rxnorm_action_treatment_mapper\", \"en\", \"clinical/models\")\\\n",
        "      .setInputCols([\"rxnorm_code\"])\\\n",
        "      .setOutputCol(\"Action\")\\\n",
        "      .setRels([\"action\"]) #or treatment\n",
        "\n",
        "pipeline = Pipeline().setStages([document_assembler,\n",
        "                                 sbert_embedder,\n",
        "                                 rxnorm_resolver,\n",
        "                                 chunkerMapper_action\n",
        "                                 ])\n",
        "\n",
        "model = pipeline.fit(spark.createDataFrame([['']]).toDF('text')) \n",
        "\n",
        "lp = LightPipeline(model)\n",
        "\n",
        "res = lp.fullAnnotate('Zonalon 50 mg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NndvMrLFNmjk",
        "outputId": "d5795b38-37bd-4e19-a7a0-ac113eb0649a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sbiobert_base_cased_mli download started this may take some time.\n",
            "Approximate size to download 384.3 MB\n",
            "[OK!]\n",
            "sbiobertresolve_rxnorm_augmented download started this may take some time.\n",
            "[OK!]\n",
            "rxnorm_action_treatment_mapper download started this may take some time.\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the results"
      ],
      "metadata": {
        "id": "cFRzialBWYmM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chunks = []\n",
        "rxnorm_code = []\n",
        "action= []\n",
        "\n",
        "\n",
        "for m, n, j in list(zip(res[0]['ner_chunk'], res[0][\"rxnorm_code\"], res[0][\"Action\"])):\n",
        "\n",
        "    chunks.append(m.result)\n",
        "    rxnorm_code.append(n.result) \n",
        "    action.append(j.result)\n",
        "    \n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({'ner_chunk':chunks,\n",
        "                   'rxnorm_code': rxnorm_code,\n",
        "                   'Action': action})\n",
        "\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "MHWdg3_bmiwF",
        "outputId": "6a609c8d-7cb0-4769-acde-e712aa2e7b25"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       ner_chunk rxnorm_code     Action\n",
              "0  Zonalon 50 mg      103971  Analgesic"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-31211fa6-deae-4fdb-bb2a-649597733418\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ner_chunk</th>\n",
              "      <th>rxnorm_code</th>\n",
              "      <th>Action</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Zonalon 50 mg</td>\n",
              "      <td>103971</td>\n",
              "      <td>Analgesic</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-31211fa6-deae-4fdb-bb2a-649597733418')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-31211fa6-deae-4fdb-bb2a-649597733418 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-31211fa6-deae-4fdb-bb2a-649597733418');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you see, we can see corresponding \"Action\" mappings of each \"RxNorm codes\"."
      ],
      "metadata": {
        "id": "1lOTEXeeWSyW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.6- Abbreviation Mapper"
      ],
      "metadata": {
        "id": "TTKofeLuWj42"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have `abbreviation_mapper` model that maps abbreviations and acronyms of medical regulatory activities with their definitions. <br/> It has one relation type that can be defined in `setRels([\"definition\"])` parameter."
      ],
      "metadata": {
        "id": "kwYOGi8DXCp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a pipeline consisting `ner_abbreviation_clinical` to extract abbreviations from text, and feed the `abbreviation_mapper` with it. "
      ],
      "metadata": {
        "id": "gHW9JxRjXZFy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document_assembler = DocumentAssembler()\\\n",
        "      .setInputCol('text')\\\n",
        "      .setOutputCol('document')\n",
        "\n",
        "sentence_detector = SentenceDetector()\\\n",
        "      .setInputCols([\"document\"])\\\n",
        "      .setOutputCol(\"sentence\")\n",
        "\n",
        "tokenizer = Tokenizer()\\\n",
        "      .setInputCols(\"sentence\")\\\n",
        "      .setOutputCol(\"token\")\n",
        "\n",
        "word_embeddings = WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n",
        "      .setInputCols([\"sentence\", \"token\"])\\\n",
        "      .setOutputCol(\"embeddings\")\n",
        "\n",
        "#NER model to detect abbreviations in the text\n",
        "abbr_ner = MedicalNerModel.pretrained('ner_abbreviation_clinical', 'en', 'clinical/models') \\\n",
        "      .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
        "      .setOutputCol(\"abbr_ner\")\n",
        "\n",
        "abbr_converter = NerConverter() \\\n",
        "      .setInputCols([\"sentence\", \"token\", \"abbr_ner\"]) \\\n",
        "      .setOutputCol(\"abbr_ner_chunk\")\\\n",
        "\n",
        "chunkerMapper = ChunkMapperModel.pretrained(\"abbreviation_mapper\", \"en\", \"clinical/models\")\\\n",
        "      .setInputCols([\"abbr_ner_chunk\"])\\\n",
        "      .setOutputCol(\"mappings\")\\\n",
        "      .setRels([\"definition\"]) \n",
        "\n",
        "pipeline = Pipeline().setStages([document_assembler,\n",
        "                                 sentence_detector,\n",
        "                                 tokenizer, \n",
        "                                 word_embeddings,\n",
        "                                 abbr_ner, \n",
        "                                 abbr_converter, \n",
        "                                 chunkerMapper])\n",
        "\n",
        "text = [\"\"\"Gravid with estimated fetal weight of 6-6/12 pounds.\n",
        "           LABORATORY DATA: Laboratory tests include a CBC which is normal. \n",
        "           HIV: Negative. One-Hour Glucose: 117. Group B strep has not been done as yet.\"\"\"]\n",
        "\n",
        "test_data = spark.createDataFrame([text]).toDF(\"text\")\n",
        "\n",
        "model = pipeline.fit(test_data)\n",
        "res= model.transform(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6TcC8MvPHZE",
        "outputId": "43482187-1930-4f02-c217-233c343da6f0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embeddings_clinical download started this may take some time.\n",
            "Approximate size to download 1.6 GB\n",
            "[OK!]\n",
            "ner_abbreviation_clinical download started this may take some time.\n",
            "[OK!]\n",
            "abbreviation_mapper download started this may take some time.\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the results"
      ],
      "metadata": {
        "id": "icqK31njXpbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#abbreviations extracted by ner model\n",
        "res.select(\"abbr_ner_chunk.result\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15gReqinY1Y3",
        "outputId": "28f51892-b9f9-46cf-8d76-00c31ecbe9e8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+\n",
            "|    result|\n",
            "+----------+\n",
            "|[CBC, HIV]|\n",
            "+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res.select(F.explode(F.arrays_zip(res.abbr_ner_chunk.result, res.mappings.result)).alias(\"col\"))\\\n",
        "    .select(F.expr(\"col['0']\").alias(\"Abbreviation\"),\n",
        "            F.expr(\"col['1']\").alias(\"Definition\")).show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fH_PG8ntXePz",
        "outputId": "e97a7c4c-8bac-4385-fb7c-c6adb88733f3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+----------------------------+\n",
            "|Abbreviation|Definition                  |\n",
            "+------------+----------------------------+\n",
            "|CBC         |complete blood count        |\n",
            "|HIV         |human immunodeficiency virus|\n",
            "+------------+----------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you see, we can see corresponding \"definition\" mappings of each \"abbreviation\"."
      ],
      "metadata": {
        "id": "hB4S4r_eYNUc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2- Creating a Mapper Model"
      ],
      "metadata": {
        "id": "tTo9cdLBfyG9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is a `ChunkMapperApproach()` to create your own mapper model. <br/>\n",
        "\n",
        "This receives an `ner_chunk` and a Json with a mapping of ner entities and relations, and returns the `ner_chunk` augmented with the relations from the Json ontology. <br/> We give the path of json file to the `setDictionary()` parameter.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SW9g1bjtgFQM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create an example Json, then create a drug mapper model. This model will match the given drug name (only \"metformin\" for our example) with correpsonding action and treatment.  \n",
        "\n",
        "The format of json file should be like following:\n"
      ],
      "metadata": {
        "id": "eFDHG9EVgayJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_set= {\n",
        "  \"mappings\": [\n",
        "    {\n",
        "      \"key\": \"metformin\",\n",
        "      \"relations\": [\n",
        "        {\n",
        "          \"key\": \"action\",\n",
        "          \"values\" : [\"hypoglycemic\", \"Drugs Used In Diabetes\"]\n",
        "        },\n",
        "        {\n",
        "          \"key\": \"treatment\",\n",
        "          \"values\" : [\"diabetes\", \"t2dm\"]\n",
        "        }\n",
        "      ]\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "\n",
        "import json\n",
        "with open('sample_drug.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(data_set, f, ensure_ascii=False, indent=4)"
      ],
      "metadata": {
        "id": "ekp8gF4wgjLs"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By using `setRel()` parameter, we tell the model which type of mapping we want. In our case, if we want from our model to return **action** mapping, we set the parameter as `setRels([\"action\"])`,  we set as `setRels([\"treatment\"])` for **treatment**\n",
        "\n",
        "Let's create a pipeline and see it in action. "
      ],
      "metadata": {
        "id": "JqjQ7rj_hxch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document_assembler = DocumentAssembler()\\\n",
        "      .setInputCol('text')\\\n",
        "      .setOutputCol('document')\n",
        "\n",
        "sentence_detector = SentenceDetector()\\\n",
        "      .setInputCols([\"document\"])\\\n",
        "      .setOutputCol(\"sentence\")\n",
        "\n",
        "tokenizer = Tokenizer()\\\n",
        "      .setInputCols(\"sentence\")\\\n",
        "      .setOutputCol(\"token\")\n",
        "\n",
        "word_embeddings = WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n",
        "      .setInputCols([\"sentence\", \"token\"])\\\n",
        "      .setOutputCol(\"embeddings\")\n",
        "\n",
        "#NER model to detect drug in the text\n",
        "clinical_ner = MedicalNerModel.pretrained(\"ner_posology_small\",\"en\",\"clinical/models\")\\\n",
        "\t    .setInputCols([\"sentence\",\"token\",\"embeddings\"])\\\n",
        "\t    .setOutputCol(\"ner\")\\\n",
        "      .setLabelCasing(\"upper\")\n",
        " \n",
        "ner_converter = NerConverter()\\\n",
        "      .setInputCols([\"sentence\", \"token\", \"ner\"])\\\n",
        "      .setOutputCol(\"ner_chunk\")\\\n",
        "      .setWhiteList([\"DRUG\"])\n",
        "\n",
        "chunkerMapper = ChunkMapperApproach()\\\n",
        "      .setInputCols([\"ner_chunk\"])\\\n",
        "      .setOutputCol(\"mappings\")\\\n",
        "      .setDictionary(\"/content/sample_drug.json\")\\\n",
        "      .setRels([\"action\"]) #or treatment\n",
        "\n",
        "pipeline = Pipeline().setStages([document_assembler,\n",
        "                                 sentence_detector,\n",
        "                                 tokenizer, \n",
        "                                 word_embeddings,\n",
        "                                 clinical_ner, \n",
        "                                 ner_converter, \n",
        "                                 chunkerMapper])\n",
        "\n",
        "text = [\"The patient was given 1 unit of metformin daily.\"]\n",
        "\n",
        "test_data = spark.createDataFrame([text]).toDF(\"text\")\n",
        "\n",
        "model = pipeline.fit(test_data)\n",
        "res= model.transform(test_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbuDGXzKf2r7",
        "outputId": "b2beb2f3-a19b-460e-8a17-940f0f0ca49d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embeddings_clinical download started this may take some time.\n",
            "Approximate size to download 1.6 GB\n",
            "[OK!]\n",
            "ner_posology_small download started this may take some time.\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDPk6Uhtrwbf",
        "outputId": "bf2e0c0b-31e4-4e2c-ec54-fa1358785272"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- text: string (nullable = true)\n",
            " |-- document: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- sentence: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- token: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- embeddings: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- ner: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- ner_chunk: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- mappings: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the ner result"
      ],
      "metadata": {
        "id": "nWe7PtYLrQT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res.select(F.explode('ner_chunk.result').alias(\"chunks\")).show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bG41lCKTf89Y",
        "outputId": "9589f618-4b84-4a97-d502-e4d285942506"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|chunks   |\n",
            "+---------+\n",
            "|metformin|\n",
            "+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the mapper result"
      ],
      "metadata": {
        "id": "4AsGy0OXshpV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res.selectExpr(\"mappings.metadata\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTRODkcHhzgw",
        "outputId": "aed9fd80-51fb-4263-f20a-67e4e1a3a49b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|metadata                                                                                                                             |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|[{chunk -> 0, relation -> action, confidence -> 0.9994, all_relations -> Drugs Used In Diabetes, entity -> metformin, sentence -> 0}]|\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res.select(F.explode(F.arrays_zip(res.ner_chunk.result, \n",
        "                                  res.mappings.result, \n",
        "                                  res.mappings.metadata)).alias(\"col\"))\\\n",
        "    .select(F.expr(\"col['0']\").alias(\"ner_chunk\"),\n",
        "            F.expr(\"col['1']\").alias(\"mapping_result\"),\n",
        "            F.expr(\"col['2']['all_relations']\").alias(\"all_relations\")).show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpWUhBkmDeve",
        "outputId": "d7bca783-47e1-4781-958e-ce2b0a6947e4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------------+----------------------+\n",
            "|ner_chunk|mapping_result|all_relations         |\n",
            "+---------+--------------+----------------------+\n",
            "|metformin|hypoglycemic  |Drugs Used In Diabetes|\n",
            "+---------+--------------+----------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you see, the model that we created with `ChunkMapperApproach()` succesfully mapped \"metformin\". Under the metadata, we can see all relations that we defined in the Json. "
      ],
      "metadata": {
        "id": "6hdWLMiss7uT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1- Save the model to disk "
      ],
      "metadata": {
        "id": "UJPH_FaOtqpP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will save our model and use it with `ChunkMapperModel()`"
      ],
      "metadata": {
        "id": "S5SHrUZcu2iR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.stages[-1].write().save(\"models/drug_mapper\")"
      ],
      "metadata": {
        "id": "EaNF5kWUs46N"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the saved model. This time we will check 'treatment' mappings results\n"
      ],
      "metadata": {
        "id": "VEBFO85yuw07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document_assembler = DocumentAssembler()\\\n",
        "      .setInputCol('text')\\\n",
        "      .setOutputCol('document')\n",
        "\n",
        "sentence_detector = SentenceDetector()\\\n",
        "      .setInputCols([\"document\"])\\\n",
        "      .setOutputCol(\"sentence\")\n",
        "\n",
        "tokenizer = Tokenizer()\\\n",
        "      .setInputCols(\"sentence\")\\\n",
        "      .setOutputCol(\"token\")\n",
        "\n",
        "word_embeddings = WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n",
        "      .setInputCols([\"sentence\", \"token\"])\\\n",
        "      .setOutputCol(\"embeddings\")\n",
        "\n",
        "#NER model to detect drug in the text\n",
        "clinical_ner = MedicalNerModel.pretrained(\"ner_posology_small\",\"en\",\"clinical/models\")\\\n",
        "\t    .setInputCols([\"sentence\",\"token\",\"embeddings\"])\\\n",
        "\t    .setOutputCol(\"ner\")\\\n",
        "      .setLabelCasing(\"upper\")\n",
        " \n",
        "ner_converter = NerConverter()\\\n",
        "      .setInputCols([\"sentence\", \"token\", \"ner\"])\\\n",
        "      .setOutputCol(\"ner_chunk\")\\\n",
        "      .setWhiteList([\"DRUG\"])\n",
        "\n",
        "chunkerMapper = ChunkMapperModel.load(\"/content/models/drug_mapper\")\\\n",
        "      .setInputCols([\"ner_chunk\"])\\\n",
        "      .setOutputCol(\"mappings\")\\\n",
        "      .setRels([\"treatment\"]) \n",
        "\n",
        "pipeline = Pipeline().setStages([document_assembler,\n",
        "                                 sentence_detector,\n",
        "                                 tokenizer, \n",
        "                                 word_embeddings,\n",
        "                                 clinical_ner, \n",
        "                                 ner_converter, \n",
        "                                 chunkerMapper])\n",
        "\n",
        "text = [\"The patient was given 1 unit of metformin daily.\"]\n",
        "\n",
        "test_data = spark.createDataFrame([text]).toDF(\"text\")\n",
        "\n",
        "model = pipeline.fit(test_data)\n",
        "res= model.transform(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xdx4s-MuutS",
        "outputId": "4e7adf1a-76b9-40de-cc04-245dc870981c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embeddings_clinical download started this may take some time.\n",
            "Approximate size to download 1.6 GB\n",
            "[OK!]\n",
            "ner_posology_small download started this may take some time.\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res.selectExpr(\"mappings.metadata\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pl3Wbxe1uugR",
        "outputId": "2b88333c-f89c-4a68-df27-4383a2505107"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------------------------------------------------------------------------------------------+\n",
            "|metadata                                                                                                              |\n",
            "+----------------------------------------------------------------------------------------------------------------------+\n",
            "|[{chunk -> 0, relation -> treatment, confidence -> 0.9994, all_relations -> t2dm, entity -> metformin, sentence -> 0}]|\n",
            "+----------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res.select(F.explode(F.arrays_zip(res.ner_chunk.result, \n",
        "                                  res.mappings.result, \n",
        "                                  res.mappings.metadata)).alias(\"col\"))\\\n",
        "    .select(F.expr(\"col['0']\").alias(\"ner_chunk\"),\n",
        "            F.expr(\"col['1']\").alias(\"mapping_result\"),\n",
        "            F.expr(\"col['2']['all_relations']\").alias(\"all_relations\")).show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-DCeMsjDnw0",
        "outputId": "32a04b22-637c-4b79-f85d-b0557f3f7d0e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------------+-------------+\n",
            "|ner_chunk|mapping_result|all_relations|\n",
            "+---------+--------------+-------------+\n",
            "|metformin|diabetes      |t2dm         |\n",
            "+---------+--------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you see above, we created our own drug mapper model successfully. "
      ],
      "metadata": {
        "id": "cJW7n4Resju8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2- Create a Model with Upper Cased or Lower Cased"
      ],
      "metadata": {
        "id": "s3SlO9WCfu79"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can set the case status of `ChunkMapperApproach` while creating a model by using `setLowerCase()` parameter.\n",
        "\n",
        "Let's create a new mapping dictionary and see how it works. "
      ],
      "metadata": {
        "id": "zqbPFVfAf7Je"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_set= {\n",
        "    \"mappings\": [\n",
        "        {\n",
        "            \"key\": \"Warfarina lusa\",\n",
        "            \"relations\": [\n",
        "                {\n",
        "                    \"key\": \"action\",\n",
        "                    \"values\": [\n",
        "                        \"Analgesic\",\n",
        "                        \"Antipyretic\"\n",
        "                    ]\n",
        "                },\n",
        "                {\n",
        "                    \"key\": \"treatment\",\n",
        "                    \"values\": [\n",
        "                        \"diabetes\",\n",
        "                        \"t2dm\"\n",
        "                    ]\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "import json\n",
        "with open('mappings.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(data_set, f, ensure_ascii=False, indent=4)"
      ],
      "metadata": {
        "id": "XaN7B3YJiTut"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "        [\"\"\"The patient was given Warfarina Lusa and amlodipine 10 MG.The patient was given Aspagin, coumadin 5 mg, coumadin, and he has metamorfin\"\"\"]\n",
        "    ]\n",
        "\n",
        "\n",
        "test_data = spark.createDataFrame(sentences).toDF(\"text\")"
      ],
      "metadata": {
        "id": "DBxQ1kJfmEA_"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`setLowerCase(True)`**"
      ],
      "metadata": {
        "id": "fUlSk0y9mnyC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chunkerMapper = ChunkMapperApproach() \\\n",
        "        .setInputCols([\"ner_chunk\"]) \\\n",
        "        .setOutputCol(\"mappings\") \\\n",
        "        .setDictionary(\"mappings.json\") \\\n",
        "        .setRels([\"action\"]) \\\n",
        "        .setLowerCase(True) \\\n",
        "\n",
        "pipeline = Pipeline().setStages([document_assembler,\n",
        "                                 sentence_detector,\n",
        "                                 tokenizer, \n",
        "                                 word_embeddings,\n",
        "                                 clinical_ner, \n",
        "                                 ner_converter, \n",
        "                                 chunkerMapper])\n",
        "\n",
        "\n",
        "result_df = pipeline.fit(test_data).transform(test_data)\n",
        "result_df.selectExpr(\"explode(mappings)\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwTkmZUcfnDB",
        "outputId": "635abf6c-e870-4445-952d-e8f33bd42b3c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|col                                                                                                                                                                        |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|{labeled_dependency, 22, 35, Analgesic, {chunk -> 0, relation -> action, confidence -> 0.66565, all_relations -> Antipyretic, entity -> Warfarina Lusa, sentence -> 0}, []}|\n",
            "|{labeled_dependency, 41, 50, NONE, {entity -> amlodipine, sentence -> 0, chunk -> 1, confidence -> 0.9999}, []}                                                            |\n",
            "|{labeled_dependency, 80, 86, NONE, {entity -> Aspagin, sentence -> 0, chunk -> 2, confidence -> 0.9905}, []}                                                               |\n",
            "|{labeled_dependency, 89, 96, NONE, {entity -> coumadin, sentence -> 0, chunk -> 3, confidence -> 0.9997}, []}                                                              |\n",
            "|{labeled_dependency, 104, 111, NONE, {entity -> coumadin, sentence -> 0, chunk -> 4, confidence -> 0.9994}, []}                                                            |\n",
            "|{labeled_dependency, 125, 134, NONE, {entity -> metamorfin, sentence -> 0, chunk -> 5, confidence -> 0.9989}, []}                                                          |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Warfarina lusa\" is in lower case in the source json file, and in upper case(Warfarina Lusa) in our example training sentence. We trained that model in lower case, the model mapped the entity even though our training sentence is uppercased. <br/>\n",
        "\n",
        "Let's check with `setLowerCase(False)` and see the difference. "
      ],
      "metadata": {
        "id": "QhByE9vSm_to"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chunkerMapper = ChunkMapperApproach() \\\n",
        "        .setInputCols([\"ner_chunk\"]) \\\n",
        "        .setOutputCol(\"mappings\") \\\n",
        "        .setDictionary(\"mappings.json\") \\\n",
        "        .setRels([\"action\"]) \\\n",
        "        .setLowerCase(False) \\\n",
        "\n",
        "pipeline = Pipeline().setStages([document_assembler,\n",
        "                                 sentence_detector,\n",
        "                                 tokenizer, \n",
        "                                 word_embeddings,\n",
        "                                 clinical_ner, \n",
        "                                 ner_converter, \n",
        "                                 chunkerMapper])\n",
        "\n",
        "\n",
        "result_df = pipeline.fit(test_data).transform(test_data)\n",
        "result_df.selectExpr(\"explode(mappings)\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pv3UQrGZfm-I",
        "outputId": "d7965ad4-57ca-4a8f-a37b-f5e27d2439d0"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------------------------------------------------------------------+\n",
            "|col                                                                                                                 |\n",
            "+--------------------------------------------------------------------------------------------------------------------+\n",
            "|{labeled_dependency, 22, 35, NONE, {entity -> Warfarina Lusa, sentence -> 0, chunk -> 0, confidence -> 0.66565}, []}|\n",
            "|{labeled_dependency, 41, 50, NONE, {entity -> amlodipine, sentence -> 0, chunk -> 1, confidence -> 0.9999}, []}     |\n",
            "|{labeled_dependency, 80, 86, NONE, {entity -> Aspagin, sentence -> 0, chunk -> 2, confidence -> 0.9905}, []}        |\n",
            "|{labeled_dependency, 89, 96, NONE, {entity -> coumadin, sentence -> 0, chunk -> 3, confidence -> 0.9997}, []}       |\n",
            "|{labeled_dependency, 104, 111, NONE, {entity -> coumadin, sentence -> 0, chunk -> 4, confidence -> 0.9994}, []}     |\n",
            "|{labeled_dependency, 125, 134, NONE, {entity -> metamorfin, sentence -> 0, chunk -> 5, confidence -> 0.9989}, []}   |\n",
            "+--------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you see, our model couldn't map the given uppercased \"Warfarine Lura\"."
      ],
      "metadata": {
        "id": "ooQvQ2YJp1ae"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3- Selecting Multiple Relations "
      ],
      "metadata": {
        "id": "5iORj5g_rAV7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can select multiple relations for the same chunk with the `setRels()` parameter."
      ],
      "metadata": {
        "id": "xp4fqhZPrWG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chunkerMapper = ChunkMapperApproach() \\\n",
        "        .setInputCols([\"ner_chunk\"]) \\\n",
        "        .setOutputCol(\"mappings\") \\\n",
        "        .setDictionary(\"mappings.json\") \\\n",
        "        .setLowerCase(True) \\\n",
        "        .setRels([\"action\", \"treatment\"])\n",
        "\n",
        "pipeline = Pipeline().setStages([document_assembler,\n",
        "                                 sentence_detector,\n",
        "                                 tokenizer, \n",
        "                                 word_embeddings,\n",
        "                                 clinical_ner, \n",
        "                                 ner_converter, \n",
        "                                 chunkerMapper])\n",
        "\n",
        "\n",
        "result_df = pipeline.fit(test_data).transform(test_data)\n",
        "result_df.selectExpr(\"explode(mappings)\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38I9ft6BfmxY",
        "outputId": "71d7f4a1-cfe6-4e4d-bbe0-777caf380646"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|col                                                                                                                                                                        |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|{labeled_dependency, 22, 35, Analgesic, {chunk -> 0, relation -> action, confidence -> 0.66565, all_relations -> Antipyretic, entity -> Warfarina Lusa, sentence -> 0}, []}|\n",
            "|{labeled_dependency, 22, 35, diabetes, {chunk -> 0, relation -> treatment, confidence -> 0.66565, all_relations -> t2dm, entity -> Warfarina Lusa, sentence -> 0}, []}     |\n",
            "|{labeled_dependency, 41, 50, NONE, {entity -> amlodipine, sentence -> 0, chunk -> 1, confidence -> 0.9999}, []}                                                            |\n",
            "|{labeled_dependency, 80, 86, NONE, {entity -> Aspagin, sentence -> 0, chunk -> 2, confidence -> 0.9905}, []}                                                               |\n",
            "|{labeled_dependency, 89, 96, NONE, {entity -> coumadin, sentence -> 0, chunk -> 3, confidence -> 0.9997}, []}                                                              |\n",
            "|{labeled_dependency, 104, 111, NONE, {entity -> coumadin, sentence -> 0, chunk -> 4, confidence -> 0.9994}, []}                                                            |\n",
            "|{labeled_dependency, 125, 134, NONE, {entity -> metamorfin, sentence -> 0, chunk -> 5, confidence -> 0.9989}, []}                                                          |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you see, we are able to see all the relations(action, treatment) at the same time. "
      ],
      "metadata": {
        "id": "LU7XurIxrz4T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.4- Filtering Multi-token Chunks"
      ],
      "metadata": {
        "id": "fYgl8fvAsELm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the chunk includes multi-tokens splitted by a whitespace, we can filter that chunk by using `setAllowMultiTokenChunk()` parameter."
      ],
      "metadata": {
        "id": "p1-8izXXsnDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chunkerMapper = ChunkMapperApproach() \\\n",
        "        .setInputCols([\"ner_chunk\"]) \\\n",
        "        .setOutputCol(\"mappings\") \\\n",
        "        .setDictionary(\"mappings.json\") \\\n",
        "        .setLowerCase(True) \\\n",
        "        .setRels([\"action\", \"treatment\"]) \\\n",
        "        .setAllowMultiTokenChunk(False)\n",
        "\n",
        "pipeline = Pipeline().setStages([document_assembler,\n",
        "                                 sentence_detector,\n",
        "                                 tokenizer, \n",
        "                                 word_embeddings,\n",
        "                                 clinical_ner, \n",
        "                                 ner_converter, \n",
        "                                 chunkerMapper])\n",
        "\n",
        "\n",
        "result_df = pipeline.fit(test_data).transform(test_data)\n",
        "result_df.selectExpr(\"explode(mappings)\").show(truncate=False)"
      ],
      "metadata": {
        "id": "_yzlVT23sKvA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a82d54b-3cdf-431d-9531-397a7e319946"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------------------------------------------------------------------+\n",
            "|col                                                                                                                 |\n",
            "+--------------------------------------------------------------------------------------------------------------------+\n",
            "|{labeled_dependency, 22, 35, NONE, {entity -> Warfarina Lusa, sentence -> 0, chunk -> 0, confidence -> 0.66565}, []}|\n",
            "|{labeled_dependency, 41, 50, NONE, {entity -> amlodipine, sentence -> 0, chunk -> 1, confidence -> 0.9999}, []}     |\n",
            "|{labeled_dependency, 80, 86, NONE, {entity -> Aspagin, sentence -> 0, chunk -> 2, confidence -> 0.9905}, []}        |\n",
            "|{labeled_dependency, 89, 96, NONE, {entity -> coumadin, sentence -> 0, chunk -> 3, confidence -> 0.9997}, []}       |\n",
            "|{labeled_dependency, 104, 111, NONE, {entity -> coumadin, sentence -> 0, chunk -> 4, confidence -> 0.9994}, []}     |\n",
            "|{labeled_dependency, 125, 134, NONE, {entity -> metamorfin, sentence -> 0, chunk -> 5, confidence -> 0.9989}, []}   |\n",
            "+--------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chunk \"Warfarina Lusa\" is a multi-token. Therefore, our mapper model skip that entity. <br/>\n",
        "So, let's set `.setAllowMultiTokenChunk(True)` and see the difference. "
      ],
      "metadata": {
        "id": "QkYb6byStDTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chunkerMapper = ChunkMapperApproach() \\\n",
        "        .setInputCols([\"ner_chunk\"]) \\\n",
        "        .setOutputCol(\"mappings\") \\\n",
        "        .setDictionary(\"mappings.json\") \\\n",
        "        .setLowerCase(True) \\\n",
        "        .setRels([\"action\", \"treatment\"]) \\\n",
        "        .setAllowMultiTokenChunk(True)\n",
        "\n",
        "pipeline = Pipeline().setStages([document_assembler,\n",
        "                                 sentence_detector,\n",
        "                                 tokenizer, \n",
        "                                 word_embeddings,\n",
        "                                 clinical_ner, \n",
        "                                 ner_converter, \n",
        "                                 chunkerMapper])\n",
        "\n",
        "\n",
        "result_df = pipeline.fit(test_data).transform(test_data)\n",
        "result_df.selectExpr(\"explode(mappings)\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pTV_9BLtifw",
        "outputId": "b62ef8d9-763a-4d71-a078-5c0bb2b89b15"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|col                                                                                                                                                                        |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|{labeled_dependency, 22, 35, Analgesic, {chunk -> 0, relation -> action, confidence -> 0.66565, all_relations -> Antipyretic, entity -> Warfarina Lusa, sentence -> 0}, []}|\n",
            "|{labeled_dependency, 22, 35, diabetes, {chunk -> 0, relation -> treatment, confidence -> 0.66565, all_relations -> t2dm, entity -> Warfarina Lusa, sentence -> 0}, []}     |\n",
            "|{labeled_dependency, 41, 50, NONE, {entity -> amlodipine, sentence -> 0, chunk -> 1, confidence -> 0.9999}, []}                                                            |\n",
            "|{labeled_dependency, 80, 86, NONE, {entity -> Aspagin, sentence -> 0, chunk -> 2, confidence -> 0.9905}, []}                                                               |\n",
            "|{labeled_dependency, 89, 96, NONE, {entity -> coumadin, sentence -> 0, chunk -> 3, confidence -> 0.9997}, []}                                                              |\n",
            "|{labeled_dependency, 104, 111, NONE, {entity -> coumadin, sentence -> 0, chunk -> 4, confidence -> 0.9994}, []}                                                            |\n",
            "|{labeled_dependency, 125, 134, NONE, {entity -> metamorfin, sentence -> 0, chunk -> 5, confidence -> 0.9989}, []}                                                          |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3- ChunkMapperFilterer"
      ],
      "metadata": {
        "id": "J-ZTtXsmtzJM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`ChunkMapperFilterer` annotator allows filtering of the chunks that were passed through the ChunkMapperModel. <br/>\n",
        "\n",
        "We can filter chunks by setting the `.setReturnCriteria()` parameter. It has 2 options; <br/>\n",
        "\n",
        "\n",
        "**success:** Returns the chunks which are mapped by ChunkMapper <br/>\n",
        "\n",
        "**fail:** Returns the chunks which are not mapped by ChunkMapper <br/>"
      ],
      "metadata": {
        "id": "pm2VP4MXuDSK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's apply the both options and check the results. "
      ],
      "metadata": {
        "id": "I5gJw22BvZ5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chunkerMapper = ChunkMapperApproach() \\\n",
        "        .setInputCols([\"ner_chunk\"]) \\\n",
        "        .setOutputCol(\"mappings\") \\\n",
        "        .setDictionary(\"mappings.json\") \\\n",
        "        .setRel(\"action\") \\\n",
        "        .setLowerCase(True) \\\n",
        "        .setRels([\"action\", \"treatment\"]) \\\n",
        "\n",
        "pipeline = Pipeline().setStages([document_assembler,\n",
        "                                 sentence_detector,\n",
        "                                 tokenizer, \n",
        "                                 word_embeddings,\n",
        "                                 clinical_ner, \n",
        "                                 ner_converter, \n",
        "                                 chunkerMapper])\n",
        "\n",
        "\n",
        "result_df = pipeline.fit(test_data).transform(test_data)\n",
        "result_df.selectExpr(\"explode(mappings)\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8MUfkhRtiZK",
        "outputId": "70a0eea1-3017-4f93-ab62-35dfeefe400d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|col                                                                                                                                                                        |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|{labeled_dependency, 22, 35, Analgesic, {chunk -> 0, relation -> action, confidence -> 0.66565, all_relations -> Antipyretic, entity -> Warfarina Lusa, sentence -> 0}, []}|\n",
            "|{labeled_dependency, 22, 35, diabetes, {chunk -> 0, relation -> treatment, confidence -> 0.66565, all_relations -> t2dm, entity -> Warfarina Lusa, sentence -> 0}, []}     |\n",
            "|{labeled_dependency, 41, 50, NONE, {entity -> amlodipine, sentence -> 0, chunk -> 1, confidence -> 0.9999}, []}                                                            |\n",
            "|{labeled_dependency, 80, 86, NONE, {entity -> Aspagin, sentence -> 0, chunk -> 2, confidence -> 0.9905}, []}                                                               |\n",
            "|{labeled_dependency, 89, 96, NONE, {entity -> coumadin, sentence -> 0, chunk -> 3, confidence -> 0.9997}, []}                                                              |\n",
            "|{labeled_dependency, 104, 111, NONE, {entity -> coumadin, sentence -> 0, chunk -> 4, confidence -> 0.9994}, []}                                                            |\n",
            "|{labeled_dependency, 125, 134, NONE, {entity -> metamorfin, sentence -> 0, chunk -> 5, confidence -> 0.9989}, []}                                                          |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`.setReturnCriteria(\"success\")`**"
      ],
      "metadata": {
        "id": "M2V0T1b7vuFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfModel = ChunkMapperFilterer() \\\n",
        "        .setInputCols([\"ner_chunk\",\"mappings\"]) \\\n",
        "        .setOutputCol(\"chunks_filtered\")\\\n",
        "        .setReturnCriteria(\"success\")\n",
        "\n",
        "cfModel.transform(result_df).selectExpr(\"explode(chunks_filtered)\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IssbtA3Xqsgm",
        "outputId": "13674a35-bf36-4b52-9d78-6b70beb4812f"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------------------------------------------------------------------+\n",
            "|col                                                                                                    |\n",
            "+-------------------------------------------------------------------------------------------------------+\n",
            "|{chunk, 22, 35, Warfarina Lusa, {entity -> DRUG, sentence -> 0, chunk -> 0, confidence -> 0.66565}, []}|\n",
            "+-------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`.setReturnCriteria(\"fail\")`**"
      ],
      "metadata": {
        "id": "YTODYW0pvyl_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfModel = ChunkMapperFilterer() \\\n",
        "        .setInputCols([\"ner_chunk\",\"mappings\"]) \\\n",
        "        .setOutputCol(\"chunks_filtered\")\\\n",
        "        .setReturnCriteria(\"fail\")\n",
        "\n",
        "cfModel.transform(result_df).selectExpr(\"explode(chunks_filtered)\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZ9UNFk4qsaS",
        "outputId": "fb3730e6-8cd5-4216-c43e-a2a59bd8e834"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------------------------------------------------------------------------+\n",
            "|col                                                                                                 |\n",
            "+----------------------------------------------------------------------------------------------------+\n",
            "|{chunk, 41, 50, amlodipine, {entity -> DRUG, sentence -> 0, chunk -> 1, confidence -> 0.9999}, []}  |\n",
            "|{chunk, 80, 86, Aspagin, {entity -> DRUG, sentence -> 0, chunk -> 2, confidence -> 0.9905}, []}     |\n",
            "|{chunk, 89, 96, coumadin, {entity -> DRUG, sentence -> 0, chunk -> 3, confidence -> 0.9997}, []}    |\n",
            "|{chunk, 104, 111, coumadin, {entity -> DRUG, sentence -> 0, chunk -> 4, confidence -> 0.9994}, []}  |\n",
            "|{chunk, 125, 134, metamorfin, {entity -> DRUG, sentence -> 0, chunk -> 5, confidence -> 0.9989}, []}|\n",
            "+----------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4- ResolverMerger - Using Sentence Entity Resolver and `ChunkMapperModel` Together"
      ],
      "metadata": {
        "id": "kWhSQPYT7GnV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can merge the results of `ChunkMapperModel` and `SentenceEntityResolverModel` by using `ResolverMerger` annotator. \n",
        "\n",
        "We can detect our results that fail by `ChunkMapperModel` with `ChunkMapperFilterer` and then merge the resolver and mapper results with `ResolverMerger`"
      ],
      "metadata": {
        "id": "ZuEYFmIN7T4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document_assembler = DocumentAssembler()\\\n",
        "      .setInputCol('text')\\\n",
        "      .setOutputCol('document')\n",
        "\n",
        "sentence_detector = SentenceDetector()\\\n",
        "      .setInputCols([\"document\"])\\\n",
        "      .setOutputCol(\"sentence\")\n",
        "\n",
        "tokenizer = Tokenizer()\\\n",
        "      .setInputCols(\"sentence\")\\\n",
        "      .setOutputCol(\"token\")\n",
        "\n",
        "word_embeddings = WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n",
        "      .setInputCols([\"sentence\", \"token\"])\\\n",
        "      .setOutputCol(\"embeddings\")\n",
        "\n",
        "ner_model = MedicalNerModel.pretrained(\"ner_posology_greedy\", \"en\", \"clinical/models\")\\\n",
        "      .setInputCols([\"sentence\", \"token\", \"embeddings\"])\\\n",
        "      .setOutputCol(\"ner\")\n",
        "\n",
        "ner_converter = NerConverter()\\\n",
        "      .setInputCols(\"sentence\", \"token\", \"ner\")\\\n",
        "      .setOutputCol(\"chunk\")\n",
        "\n",
        "chunkerMapper = ChunkMapperModel.pretrained(\"rxnorm_mapper\", \"en\", \"clinical/models\")\\\n",
        "      .setInputCols([\"chunk\"])\\\n",
        "      .setOutputCol(\"RxNorm_Mapper\")\\\n",
        "      .setRels([\"rxnorm_code\"])\n",
        "\n",
        "cfModel = ChunkMapperFilterer() \\\n",
        "      .setInputCols([\"chunk\", \"RxNorm_Mapper\"]) \\\n",
        "      .setOutputCol(\"chunks_fail\") \\\n",
        "      .setReturnCriteria(\"fail\")\n",
        "\n",
        "chunk2doc = Chunk2Doc() \\\n",
        "      .setInputCols(\"chunks_fail\") \\\n",
        "      .setOutputCol(\"chunk_doc\")\n",
        "\n",
        "sbert_embedder = BertSentenceEmbeddings.pretrained('sbiobert_base_cased_mli', 'en','clinical/models')\\\n",
        "      .setInputCols([\"chunk_doc\"])\\\n",
        "      .setOutputCol(\"sentence_embeddings\")\\\n",
        "      .setCaseSensitive(False)\n",
        "\n",
        "resolver = SentenceEntityResolverModel.pretrained(\"sbiobertresolve_rxnorm_augmented\", \"en\", \"clinical/models\") \\\n",
        "      .setInputCols([\"chunks_fail\", \"sentence_embeddings\"]) \\\n",
        "      .setOutputCol(\"resolver_code\") \\\n",
        "      .setDistanceFunction(\"EUCLIDEAN\")\n",
        "\n",
        "resolverMerger = ResolverMerger()\\\n",
        "      .setInputCols([\"resolver_code\",\"RxNorm_Mapper\"])\\\n",
        "      .setOutputCol(\"RxNorm\")\n",
        "\n",
        "mapper_pipeline = Pipeline(\n",
        "      stages = [\n",
        "          document_assembler,\n",
        "          sentence_detector,\n",
        "          tokenizer,\n",
        "          word_embeddings,\n",
        "          ner_model,\n",
        "          ner_converter,\n",
        "          chunkerMapper,\n",
        "          chunkerMapper,\n",
        "          cfModel,\n",
        "          chunk2doc,\n",
        "          sbert_embedder,\n",
        "          resolver,\n",
        "          resolverMerger\n",
        "      ])\n",
        "\n",
        "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
        "\n",
        "model = mapper_pipeline.fit(empty_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wEep8op7GVH",
        "outputId": "cec599d2-2fdf-4830-8a8a-4edd16283b57"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embeddings_clinical download started this may take some time.\n",
            "Approximate size to download 1.6 GB\n",
            "[OK!]\n",
            "ner_posology_greedy download started this may take some time.\n",
            "[OK!]\n",
            "rxnorm_mapper download started this may take some time.\n",
            "[OK!]\n",
            "sbiobert_base_cased_mli download started this may take some time.\n",
            "Approximate size to download 384.3 MB\n",
            "[OK!]\n",
            "sbiobertresolve_rxnorm_augmented download started this may take some time.\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "samples = [['The patient was given Adapin 10 MG, coumadn 5 mg'],\n",
        "           ['The patient was given Avandia 4 mg, Tegretol, zitiga'] ]\n",
        "\n",
        "result = model.transform(spark.createDataFrame(samples).toDF(\"text\"))"
      ],
      "metadata": {
        "id": "40s4u0yA7dhn"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.selectExpr('chunk.result as chunk', \n",
        "                  'RxNorm_Mapper.result as RxNorm_Mapper', \n",
        "                  'chunks_fail.result as chunks_fail', \n",
        "                  'resolver_code.result as resolver_code',\n",
        "                  'RxNorm.result as RxNorm'\n",
        "              ).show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCDft7KiX2Yr",
        "outputId": "b1638cd9-73e8-4c31-892f-b51c9bdbabb7"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------+----------------------+--------------+-------------+------------------------+\n",
            "|chunk                           |RxNorm_Mapper         |chunks_fail   |resolver_code|RxNorm                  |\n",
            "+--------------------------------+----------------------+--------------+-------------+------------------------+\n",
            "|[Adapin 10 MG, coumadn 5 mg]    |[1000049, NONE]       |[coumadn 5 mg]|[200883]     |[1000049, 200883]       |\n",
            "|[Avandia 4 mg, Tegretol, zitiga]|[261242, 203029, NONE]|[zitiga]      |[220989]     |[261242, 203029, 220989]|\n",
            "+--------------------------------+----------------------+--------------+-------------+------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5- Section Header Normalizer Mapper with ChunkSentenceSplitter"
      ],
      "metadata": {
        "id": "HJ9tNW9Gt5Sb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`ChunkSentenceSplitter()` annotator splits documents or sentences by chunks provided. <br/> For detailed usage of this annotator, visit [this notebook](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/18.Chunk_Sentence_Splitter.ipynb) <br/>\n",
        "\n",
        "In this section, we will do the following steps; \n",
        "- Detect \"section headers\" in given text through Ner model\n",
        "- Split the given text by headers with `ChunkSentenceSplitter()`\n",
        "- Normalize the `ChunkSentenceSplitter()` outputs with `normalized_section_header_mapper` model. "
      ],
      "metadata": {
        "id": "0tlEvAPvu6Lb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's start with creating Ner pipeline to detect \"Header\" "
      ],
      "metadata": {
        "id": "xlNR3ioQYQPc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\n",
        "    [\"\"\"ADMISSION DIAGNOSIS Right pleural effusion and suspected malignant mesothelioma.\n",
        "        PRINCIPAL DIAGNOSIS Right pleural effusion, suspected malignant mesothelioma.\n",
        "        REVIEW OF SYSTEMS Right pleural effusion, firm nodules, diffuse scattered throughout the right pleura and diaphragmatic surface.\n",
        "    \"\"\"]]\n",
        "\n",
        "df= spark.createDataFrame(sentences).toDF(\"text\")"
      ],
      "metadata": {
        "id": "e3ABtM79mf86"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documentAssembler = DocumentAssembler()\\\n",
        "      .setInputCol(\"text\")\\\n",
        "      .setOutputCol(\"document\")\n",
        "\n",
        "tokenizer= Tokenizer()\\\n",
        "      .setInputCols([\"document\"])\\\n",
        "      .setOutputCol(\"token\")\n",
        "\n",
        "tokenClassifier = MedicalBertForTokenClassifier.pretrained(\"bert_token_classifier_ner_jsl_slim\", \"en\", \"clinical/models\")\\\n",
        "      .setInputCols(\"token\", \"document\")\\\n",
        "      .setOutputCol(\"ner\")\\\n",
        "      .setCaseSensitive(True)\n",
        "\n",
        "ner_converter = NerConverter() \\\n",
        "      .setInputCols([\"document\", \"token\", \"ner\"]) \\\n",
        "      .setOutputCol(\"ner_chunk\")\\\n",
        "      .setWhiteList([\"Header\"])\n",
        "\n",
        "pipeline = Pipeline(\n",
        "    stages = [\n",
        "        documentAssembler,\n",
        "        tokenizer,\n",
        "        tokenClassifier,\n",
        "        ner_converter\n",
        "    ])\n",
        " \n",
        "empty_df = spark.createDataFrame([[\"\"]]).toDF('text')\n",
        "pipeline_model = pipeline.fit(empty_df)"
      ],
      "metadata": {
        "id": "Wuab7yVluOLY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5913652-9e28-4d41-f49e-b10447288ee4"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_token_classifier_ner_jsl_slim download started this may take some time.\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = pipeline_model.transform(df)\n",
        "result.selectExpr('explode(ner_chunk)').show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIXG6SUiGGib",
        "outputId": "e56ac78d-9370-4c0c-f574-1ca5bb9ac8f7"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------------------------------------------------------------------------------------+\n",
            "|col                                                                                                               |\n",
            "+------------------------------------------------------------------------------------------------------------------+\n",
            "|{chunk, 0, 18, ADMISSION DIAGNOSIS, {entity -> Header, sentence -> 0, chunk -> 0, confidence -> 0.9994346}, []}   |\n",
            "|{chunk, 89, 107, PRINCIPAL DIAGNOSIS, {entity -> Header, sentence -> 0, chunk -> 1, confidence -> 0.99020165}, []}|\n",
            "|{chunk, 175, 191, REVIEW OF SYSTEMS, {entity -> Header, sentence -> 0, chunk -> 2, confidence -> 0.9989373}, []}  |\n",
            "+------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we have our header entities. We will split the text by the headers."
      ],
      "metadata": {
        "id": "ymUF_0f1ct7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#applying ChunkSentenceSplitter \n",
        "chunkSentenceSplitter = ChunkSentenceSplitter()\\\n",
        "    .setInputCols(\"document\",\"ner_chunk\")\\\n",
        "    .setOutputCol(\"paragraphs\")\\\n",
        "    .setGroupBySentences(False)\n",
        "\n",
        "paragraphs = chunkSentenceSplitter.transform(result)"
      ],
      "metadata": {
        "id": "jM7vMBDAZg3_"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paragraphs.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCJL4x0ybatJ",
        "outputId": "5767e52d-dc2c-4e50-dd94-bb872b9fe7eb"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                text|            document|               token|                 ner|           ner_chunk|          paragraphs|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|ADMISSION DIAGNOS...|[{document, 0, 30...|[{token, 0, 8, AD...|[{named_entity, 0...|[{chunk, 0, 18, A...|[{document, 0, 89...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_colwidth', None)\n",
        "result_df = paragraphs.selectExpr(\"explode(paragraphs) as result\").selectExpr(\"result.result\",\"result.metadata.entity\", \"result.metadata.splitter_chunk\").toPandas()\n",
        "result_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "g2D2hD1IYczD",
        "outputId": "2262420f-22ff-4f65-e1a5-8fd2fd229c27"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                                  result  \\\n",
              "0                                             ADMISSION DIAGNOSIS Right pleural effusion and suspected malignant mesothelioma.\\n           \n",
              "1                                                PRINCIPAL DIAGNOSIS Right pleural effusion, suspected malignant mesothelioma.\\n           \n",
              "2  REVIEW OF SYSTEMS Right pleural effusion, firm nodules, diffuse scattered throughout the right pleura and diaphragmatic surface.\\n      \n",
              "\n",
              "   entity       splitter_chunk  \n",
              "0  Header  ADMISSION DIAGNOSIS  \n",
              "1  Header  PRINCIPAL DIAGNOSIS  \n",
              "2  Header    REVIEW OF SYSTEMS  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a320d2d7-bd2e-4037-9cb1-7bdb0bd5bf8d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>result</th>\n",
              "      <th>entity</th>\n",
              "      <th>splitter_chunk</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ADMISSION DIAGNOSIS Right pleural effusion and suspected malignant mesothelioma.\\n</td>\n",
              "      <td>Header</td>\n",
              "      <td>ADMISSION DIAGNOSIS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PRINCIPAL DIAGNOSIS Right pleural effusion, suspected malignant mesothelioma.\\n</td>\n",
              "      <td>Header</td>\n",
              "      <td>PRINCIPAL DIAGNOSIS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>REVIEW OF SYSTEMS Right pleural effusion, firm nodules, diffuse scattered throughout the right pleura and diaphragmatic surface.\\n</td>\n",
              "      <td>Header</td>\n",
              "      <td>REVIEW OF SYSTEMS</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a320d2d7-bd2e-4037-9cb1-7bdb0bd5bf8d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a320d2d7-bd2e-4037-9cb1-7bdb0bd5bf8d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a320d2d7-bd2e-4037-9cb1-7bdb0bd5bf8d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you see, we have our splitted text and **section headers**. <br/>\n",
        "Now we will normalize this section headers with `normalized_section_header_mapper`"
      ],
      "metadata": {
        "id": "1aO6pVkheYYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chunkerMapper = ChunkMapperModel.pretrained(\"normalized_section_header_mapper\", \"en\", \"clinical/models\") \\\n",
        "       .setInputCols(\"ner_chunk\")\\\n",
        "       .setOutputCol(\"mappings\")\\\n",
        "       .setRels([\"level_1\"]) #or level_2\n",
        "\n",
        "normalized_df= chunkerMapper.transform(paragraphs)"
      ],
      "metadata": {
        "id": "v3e8FeqUcCRc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a73d9dbf-4a6d-4b14-9f09-4196a518c773"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "normalized_section_header_mapper download started this may take some time.\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4mdVzaTiQWP",
        "outputId": "029ab4c9-c748-4939-c14b-6c8e290e45f5"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                text|            document|               token|                 ner|           ner_chunk|          paragraphs|            mappings|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|ADMISSION DIAGNOS...|[{document, 0, 30...|[{token, 0, 8, AD...|[{named_entity, 0...|[{chunk, 0, 18, A...|[{document, 0, 89...|[{labeled_depende...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_df= normalized_df.select(F.explode(F.arrays_zip(normalized_df.ner_chunk.result, \n",
        "                                                           normalized_df.mappings.result)).alias(\"col\"))\\\n",
        "                            .select(F.expr(\"col['0']\").alias(\"ner_chunk\"),\n",
        "                                    F.expr(\"col['1']\").alias(\"normalized_headers\")).toPandas()\n",
        "normalized_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "W39fNYQiiQR-",
        "outputId": "ec85fe89-0df5-40c1-c1d6-cdd2a825fcc0"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             ner_chunk normalized_headers\n",
              "0  ADMISSION DIAGNOSIS          DIAGNOSIS\n",
              "1  PRINCIPAL DIAGNOSIS          DIAGNOSIS\n",
              "2    REVIEW OF SYSTEMS        REVIEW TYPE"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a181e341-9f9c-4dfa-a2c8-5f25b8124e47\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ner_chunk</th>\n",
              "      <th>normalized_headers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ADMISSION DIAGNOSIS</td>\n",
              "      <td>DIAGNOSIS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PRINCIPAL DIAGNOSIS</td>\n",
              "      <td>DIAGNOSIS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>REVIEW OF SYSTEMS</td>\n",
              "      <td>REVIEW TYPE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a181e341-9f9c-4dfa-a2c8-5f25b8124e47')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a181e341-9f9c-4dfa-a2c8-5f25b8124e47 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a181e341-9f9c-4dfa-a2c8-5f25b8124e47');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we have our normalized headers. We will merge it with `ChunkSentenceSplitter()` output"
      ],
      "metadata": {
        "id": "ZNYTXNAMKgl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_df= normalized_df.rename(columns={\"ner_chunk\": \"splitter_chunk\"})\n",
        "df= pd.merge(result_df, normalized_df, on=[\"splitter_chunk\"])"
      ],
      "metadata": {
        "id": "84dbZufZ1f0a"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "bSSafH2snO5j",
        "outputId": "3adba17f-c11e-47cf-fddc-b0dfbe19152c"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                                  result  \\\n",
              "0                                             ADMISSION DIAGNOSIS Right pleural effusion and suspected malignant mesothelioma.\\n           \n",
              "1                                                PRINCIPAL DIAGNOSIS Right pleural effusion, suspected malignant mesothelioma.\\n           \n",
              "2  REVIEW OF SYSTEMS Right pleural effusion, firm nodules, diffuse scattered throughout the right pleura and diaphragmatic surface.\\n      \n",
              "\n",
              "   entity       splitter_chunk normalized_headers  \n",
              "0  Header  ADMISSION DIAGNOSIS          DIAGNOSIS  \n",
              "1  Header  PRINCIPAL DIAGNOSIS          DIAGNOSIS  \n",
              "2  Header    REVIEW OF SYSTEMS        REVIEW TYPE  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-94362033-ca26-4617-8e96-6a51ea0d3415\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>result</th>\n",
              "      <th>entity</th>\n",
              "      <th>splitter_chunk</th>\n",
              "      <th>normalized_headers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ADMISSION DIAGNOSIS Right pleural effusion and suspected malignant mesothelioma.\\n</td>\n",
              "      <td>Header</td>\n",
              "      <td>ADMISSION DIAGNOSIS</td>\n",
              "      <td>DIAGNOSIS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PRINCIPAL DIAGNOSIS Right pleural effusion, suspected malignant mesothelioma.\\n</td>\n",
              "      <td>Header</td>\n",
              "      <td>PRINCIPAL DIAGNOSIS</td>\n",
              "      <td>DIAGNOSIS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>REVIEW OF SYSTEMS Right pleural effusion, firm nodules, diffuse scattered throughout the right pleura and diaphragmatic surface.\\n</td>\n",
              "      <td>Header</td>\n",
              "      <td>REVIEW OF SYSTEMS</td>\n",
              "      <td>REVIEW TYPE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-94362033-ca26-4617-8e96-6a51ea0d3415')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-94362033-ca26-4617-8e96-6a51ea0d3415 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-94362033-ca26-4617-8e96-6a51ea0d3415');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ultimately, we have splitted paragraphs, headers and normalized headers. "
      ],
      "metadata": {
        "id": "r2x7vehZL1zD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5- Pretrained Mapper Pipelines\n",
        "\n",
        "We will show an example of `rxnorm_umls_mapping` pipeline here. But you can check [Healthcare Code Mapping Notebook](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/11.1.Healthcare_Code_Mapping.ipynb) for the examples of pretrained mapper pipelines. "
      ],
      "metadata": {
        "id": "kYQZjb7H4PAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "\n",
        "rxnorm_umls_pipeline= PretrainedPipeline(\"rxnorm_umls_mapping\", \"en\", \"clinical/models\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKz2nJtc4Mp1",
        "outputId": "874c781d-c877-436d-eb68-0a3e40def8ed"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rxnorm_umls_mapping download started this may take some time.\n",
            "Approx size to download 1.8 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rxnorm_umls_pipeline.annotate(\"1161611 315677 343663\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyFDnF2s4MeQ",
        "outputId": "79341418-3270-451d-945b-07fe15ca3256"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'document': ['1161611 315677 343663'],\n",
              " 'rxnorm_code': ['1161611', '315677', '343663'],\n",
              " 'umls_code': ['C3215948', 'C0984912', 'C1146501']}"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "|**RxNorm Code** | **RxNorm Details** | **UMLS Code** | **UMLS Details** |\n",
        "| ---------- | -----------:| ---------- | -----------:|\n",
        "| 1161611 |  metformin Pill | C3215948 | metformin pill |\n",
        "| 315677 | cimetidine 100 mg | C0984912 | cimetidine 100 mg |\n",
        "| 343663 | insulin lispro 50 UNT/ML | C1146501 | insulin lispro 50 unt/ml |"
      ],
      "metadata": {
        "id": "Fl3nevsU--Pi"
      }
    }
  ]
}