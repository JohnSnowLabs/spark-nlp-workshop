{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yHOpLhhitZ8m"
   },
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n78iNvcMtZ9g"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/5.2.Spark_OCR_Deidentification.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Niy3mZAjoayg"
   },
   "source": [
    "# Spark OCR "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YNJUQPsXvuSV"
   },
   "source": [
    "\n",
    "## Blogposts and videos\n",
    "\n",
    "- [How to Setup Spark OCR on UBUNTU - Video](https://www.youtube.com/watch?v=cmt4WIcL0nI)\n",
    "\n",
    "- [Installing Spark NLP and Spark OCR in air-gapped networks (offline mode)\n",
    "](https://medium.com/spark-nlp/installing-spark-nlp-and-spark-ocr-in-air-gapped-networks-offline-mode-f42a1ee6b7a8)\n",
    "\n",
    "- [Table Detection & Extraction in Spark OCR](https://medium.com/spark-nlp/table-detection-extraction-in-spark-ocr-50765c6cedc9)\n",
    "\n",
    "- [Signature Detection in Spark OCR](https://medium.com/spark-nlp/signature-detection-in-spark-ocr-32f9e6f91e3c)\n",
    "\n",
    "- [GPU image pre-processing in Spark OCR](https://medium.com/spark-nlp/gpu-image-pre-processing-in-spark-ocr-3-1-0-6fc27560a9bb)\n",
    "\n",
    "**More examples here**\n",
    "\n",
    "https://github.com/JohnSnowLabs/spark-ocr-workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "okhT7AcXxben"
   },
   "source": [
    "**Colab Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MVf_2iqGIJ4B"
   },
   "outputs": [],
   "source": [
    "import json, os\n",
    "from google.colab import files\n",
    "\n",
    "if 'spark_jsl.json' not in os.listdir():\n",
    "  license_keys = files.upload()\n",
    "  os.rename(list(license_keys.keys())[0], 'spark_ocr.json')\n",
    "\n",
    "with open('spark_ocr.json') as f:\n",
    "    license_keys = json.load(f)\n",
    "\n",
    "# Defining license key-value pairs as local variables\n",
    "locals().update(license_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WkylJaGx-COY"
   },
   "outputs": [],
   "source": [
    "# Installing pyspark and spark-nlp\n",
    "! pip install --upgrade -q pyspark==3.2.1 spark-nlp==$PUBLIC_VERSION\n",
    "\n",
    "# Installing Spark NLP Healthcare\n",
    "!pip -q install --upgrade spark-nlp-jsl==$JSL_VERSION  --extra-index-url https://pypi.johnsnowlabs.com/$SECRET\n",
    "\n",
    "# Installing Spark OCR\n",
    "! pip install spark-ocr==$OCR_VERSION --extra-index-url=https://pypi.johnsnowlabs.com/$SPARK_OCR_SECRET --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X31h1agcPBrh"
   },
   "source": [
    "<b><h1><font color='darkred'>!!! ATTENTION !!! </font><h1><b>\n",
    "\n",
    "<b>After running previous cell, <font color='darkred'>RESTART the COLAB RUNTIME </font> and go ahead.<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c4XF5vP5GhOw"
   },
   "outputs": [],
   "source": [
    "import json, os\n",
    "\n",
    "with open(\"spark_ocr.json\", 'r') as f:\n",
    "  license_keys = json.load(f)\n",
    "\n",
    "# Adding license key-value pairs to environment variables\n",
    "os.environ.update(license_keys)\n",
    "\n",
    "# Defining license key-value pairs as local variables\n",
    "locals().update(license_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qK5UBzv7nHOe"
   },
   "outputs": [],
   "source": [
    "import sparkocr\n",
    "import sys\n",
    "from pyspark.sql import SparkSession\n",
    "from sparkocr import start\n",
    "import os\n",
    "import base64\n",
    "from sparkocr.transformers import *\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.sql import functions as F\n",
    "from sparkocr.enums import *\n",
    "from sparkocr.utils import display_images\n",
    "\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp_jsl.annotator import *\n",
    "from sparknlp.base import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "id": "vDIzhpKkF4Aq",
    "outputId": "cc3edcd4-bac4-4057-c881-1a96bbf05f21"
   },
   "outputs": [],
   "source": [
    "spark = sparkocr.start(secret=SPARK_OCR_SECRET, \n",
    "                       nlp_version=PUBLIC_VERSION,\n",
    "                       nlp_secret=SECRET,\n",
    "                       nlp_internal=JSL_VERSION\n",
    "                       )\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SfzwFIw3aU0q"
   },
   "source": [
    "## Dicom Image Deidentifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PonKwnyLzhw5"
   },
   "source": [
    "**Define deidentification pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1hw1gTUOxtfw"
   },
   "outputs": [],
   "source": [
    "def deidentification_nlp_pipeline(input_column, prefix = \"\"):\n",
    "    document_assembler = DocumentAssembler() \\\n",
    "        .setInputCol(input_column) \\\n",
    "        .setOutputCol(prefix + \"document\")\n",
    "\n",
    "    # Sentence Detector annotator, processes various sentences per line\n",
    "    sentence_detector = SentenceDetector() \\\n",
    "        .setInputCols([prefix + \"document\"]) \\\n",
    "        .setOutputCol(prefix + \"sentence\")\n",
    "\n",
    "    tokenizer = Tokenizer() \\\n",
    "        .setInputCols([prefix + \"sentence\"]) \\\n",
    "        .setOutputCol(prefix + \"token\")\n",
    "\n",
    "    # Clinical word embeddings\n",
    "    word_embeddings = WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\") \\\n",
    "        .setInputCols([prefix + \"sentence\", prefix + \"token\"]) \\\n",
    "        .setOutputCol(prefix + \"embeddings\")\n",
    "    # NER model trained on i2b2 (sampled from MIMIC) dataset\n",
    "    clinical_ner = MedicalNerModel.pretrained(\"ner_deid_large\", \"en\", \"clinical/models\") \\\n",
    "        .setInputCols([prefix + \"sentence\", prefix + \"token\", prefix + \"embeddings\"]) \\\n",
    "        .setOutputCol(prefix + \"ner\")\n",
    "\n",
    "    custom_ner_converter = NerConverter() \\\n",
    "        .setInputCols([prefix + \"sentence\", prefix + \"token\", prefix + \"ner\"]) \\\n",
    "        .setOutputCol(prefix + \"ner_chunk\") \\\n",
    "        .setWhiteList(['NAME', 'AGE', 'CONTACT', 'LOCATION', 'PROFESSION', 'PERSON', 'DATE'])\n",
    "\n",
    "    nlp_pipeline = Pipeline(stages=[\n",
    "            document_assembler,\n",
    "            sentence_detector,\n",
    "            tokenizer,\n",
    "            word_embeddings,\n",
    "            clinical_ner,\n",
    "            custom_ner_converter\n",
    "        ])\n",
    "    empty_data = spark.createDataFrame([[\"\"]]).toDF(input_column)\n",
    "    nlp_model = nlp_pipeline.fit(empty_data)\n",
    "    return nlp_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YS1Nsk9Mzgc1"
   },
   "source": [
    "**Define OCR transformers and pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "coDVf-qdx2Xy",
    "outputId": "9cf9fc41-0c95-47bc-8c96-e8ef0d5edda4"
   },
   "outputs": [],
   "source": [
    "# Read dicom as image\n",
    "dicom_to_image = DicomToImage() \\\n",
    "    .setInputCol(\"content\") \\\n",
    "    .setOutputCol(\"image_raw\") \\\n",
    "    .setMetadataCol(\"metadata\") \\\n",
    "    .setDeIdentifyMetadata(True)\n",
    "\n",
    "adaptive_thresholding = ImageAdaptiveThresholding() \\\n",
    "    .setInputCol(\"image_raw\") \\\n",
    "    .setOutputCol(\"corrected_image\") \\\n",
    "    .setBlockSize(47) \\\n",
    "    .setOffset(4) \\\n",
    "    .setKeepInput(True)\n",
    "\n",
    "# Extract text from image\n",
    "ocr = ImageToText() \\\n",
    "    .setInputCol(\"corrected_image\") \\\n",
    "    .setOutputCol(\"text\")\n",
    "\n",
    "# Found coordinates of sensitive data\n",
    "position_finder = PositionFinder() \\\n",
    "    .setInputCols(\"ner_chunk\") \\\n",
    "    .setOutputCol(\"coordinates\") \\\n",
    "    .setPageMatrixCol(\"positions\") \\\n",
    "    .setMatchingWindow(100) \\\n",
    "    .setPadding(1)\n",
    "\n",
    "# Found sensitive data using DeIdentificationModel\n",
    "deidentification_rules = DeIdentificationModel.pretrained(\"deidentify_rb_no_regex\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"metadata_sentence\", \"metadata_token\", \"metadata_ner_chunk\"]) \\\n",
    "    .setOutputCol(\"deidentified_metadata_raw\")\n",
    "\n",
    "finisher = Finisher() \\\n",
    "    .setInputCols([\"deidentified_metadata_raw\"]) \\\n",
    "    .setOutputCols(\"deidentified_metadata\") \\\n",
    "    .setOutputAsArray(False) \\\n",
    "    .setValueSplitSymbol(\"\") \\\n",
    "    .setAnnotationSplitSymbol(\"\")\n",
    "\n",
    "# Draw filled rectangle for hide sensitive data\n",
    "drawRegions = ImageDrawRegions()  \\\n",
    "    .setInputCol(\"image_raw\")  \\\n",
    "    .setInputRegionsCol(\"coordinates\")  \\\n",
    "    .setOutputCol(\"image_with_regions\")  \\\n",
    "    .setFilledRect(True) \\\n",
    "    .setRectColor(Color.black)\n",
    "\n",
    "# Store image back to Dicom document\n",
    "imageToDicom = ImageToDicom() \\\n",
    "    .setInputCol(\"image_with_regions\") \\\n",
    "    .setOutputCol(\"dicom\") \n",
    "    \n",
    "# OCR pipeline\n",
    "deid_pipeline = PipelineModel(stages=[\n",
    "    dicom_to_image,\n",
    "    adaptive_thresholding,\n",
    "    ocr,\n",
    "    deidentification_nlp_pipeline(input_column=\"text\"),\n",
    "    position_finder,\n",
    "    drawRegions,\n",
    "    #imageToDicom  # Commented for able to demonstrate intermidiate results before aggregation\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-1dvtHvWyDny",
    "outputId": "dbda9bd8-1241-4bf0-b4fd-8a7af685ff3c"
   },
   "outputs": [],
   "source": [
    "!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-ocr-workshop/master/jupyter/data/dicom/deidentify-medical-2.dcm  -P content/dicom/\n",
    "!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-ocr-workshop/master/jupyter/data/dicom/deidentify-brains-front-medical-3.dcm -P content/dicom/\n",
    "\n",
    "\n",
    "file_path='content/dicom/*.dcm'\n",
    "dicom_df = spark.read.format(\"binaryFile\").load(file_path)\n",
    "dicom_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "hY4sKDbJynRN",
    "outputId": "1059368c-8ef0-430e-9cf0-376d2710369e"
   },
   "outputs": [],
   "source": [
    "display_images(DicomToImage().transform(dicom_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2NEpeLhOypjn"
   },
   "outputs": [],
   "source": [
    "deid_results = deid_pipeline.transform(dicom_df).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "eBCTNNmMy0jG",
    "outputId": "0fa932f8-09cf-4de4-9ccf-8234358c97b3"
   },
   "outputs": [],
   "source": [
    "from sparkocr.utils import display_image, to_pil_image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for r in deid_results.select(\"image_raw\", \"image_with_regions\").collect():\n",
    "  img_orig = r.image_raw\n",
    "  img_deid = r.image_with_regions\n",
    "\n",
    "  img_pil_orig = to_pil_image(img_orig, img_orig.mode)\n",
    "  img_pil_deid = to_pil_image(img_deid, img_deid.mode)\n",
    "\n",
    "  plt.figure(figsize=(24,16))\n",
    "  plt.subplot(1, 2, 1)\n",
    "  plt.imshow(img_pil_orig, cmap='gray')\n",
    "  plt.title('original')\n",
    "  plt.subplot(1, 2, 2)\n",
    "  plt.imshow(img_pil_deid, cmap='gray')\n",
    "  plt.title(\"de-id'd\")\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RRlppvfyaYR-"
   },
   "source": [
    "## PDF Document Deidentifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OUzwlZ4NuWXm"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from sparkocr.transformers import *\n",
    "from sparkocr.enums import *\n",
    "from sparkocr.utils import display_image, display_images\n",
    "from sparkocr.metrics import score\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp_jsl.annotator import *\n",
    "from sparknlp.base import *\n",
    "import sparknlp_jsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JPnDWTYu6oim"
   },
   "outputs": [],
   "source": [
    "from sparkocr.transformers import *\n",
    "from sparkocr.utils import display_image, to_pil_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2SgIcnWNafMZ"
   },
   "source": [
    "**Define OCR transformers and pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PSDZ8_qxaloZ",
    "outputId": "ee1ba4ef-9457-494c-bd24-aaadce430663"
   },
   "outputs": [],
   "source": [
    "# Read Pdf as image\n",
    "pdf_to_image = PdfToImage()\\\n",
    "    .setInputCol(\"content\")\\\n",
    "    .setOutputCol(\"image_raw\")\\\n",
    "    .setResolution(400)\n",
    "\n",
    "# Extract text from image\n",
    "ocr = ImageToText() \\\n",
    "    .setInputCol(\"image_raw\") \\\n",
    "    .setOutputCol(\"text\") \\\n",
    "    .setIgnoreResolution(False) \\\n",
    "    .setPageIteratorLevel(PageIteratorLevel.SYMBOL) \\\n",
    "    .setPageSegMode(PageSegmentationMode.SPARSE_TEXT) \\\n",
    "    .setWithSpaces(True) \\\n",
    "    .setConfidenceThreshold(70)\n",
    "\n",
    "hocr = ImageToHocr() \\\n",
    "    .setInputCol(\"image_raw\") \\\n",
    "    .setOutputCol(\"hocr\") \\\n",
    "    .setIgnoreResolution(False) \\\n",
    "    .setOcrParams([\"preserve_interword_spaces=0\"])\\\n",
    "    .setPageIteratorLevel(PageIteratorLevel.SYMBOL)\\\n",
    "    .setPageSegMode(PageSegmentationMode.SPARSE_TEXT) \\\n",
    "\n",
    "# Found coordinates of sensitive data\n",
    "position_finder = PositionFinder() \\\n",
    "    .setInputCols(\"ner_chunk\") \\\n",
    "    .setOutputCol(\"coordinates\") \\\n",
    "    .setPageMatrixCol(\"positions\") \\\n",
    "    .setMatchingWindow(100) \\\n",
    "    .setPadding(1)\n",
    "\n",
    "# Draw filled rectangle for hide sensitive data\n",
    "drawRegions = ImageDrawRegions()  \\\n",
    "    .setInputCol(\"image_raw\")  \\\n",
    "    .setInputRegionsCol(\"coordinates\")  \\\n",
    "    .setOutputCol(\"image_with_regions\")  \\\n",
    "    .setFilledRect(True) \\\n",
    "    .setRectColor(Color.black)\n",
    "    \n",
    "# OCR pipeline\n",
    "deid_pipeline = PipelineModel(stages=[\n",
    "    pdf_to_image,\n",
    "    ocr,\n",
    "    hocr,\n",
    "    deidentification_nlp_pipeline(input_column=\"text\"),\n",
    "    position_finder,\n",
    "    drawRegions\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GSZWULLQva1Z"
   },
   "outputs": [],
   "source": [
    "!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Healthcare/data/ocr/MT_00.pdf -P content/deid/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lkKJLHuCapmx"
   },
   "outputs": [],
   "source": [
    "import pkg_resources\n",
    "image_path = pkg_resources.resource_filename('sparkocr', 'resources/ocr/images/p1.jpg')\n",
    "image_df = spark.read.format(\"binaryFile\").load(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HI7R_ABxwekS",
    "outputId": "482134f9-dbb7-46bb-b266-0fd97da13c7c"
   },
   "outputs": [],
   "source": [
    "file_path='content/deid/*.pdf'\n",
    "pdfs = spark.read.format(\"binaryFile\").load(file_path)\n",
    "pdfs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MN56kfHHwoks"
   },
   "outputs": [],
   "source": [
    "deid_results = deid_pipeline.transform(pdfs).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vsdKtTIFwpkp",
    "outputId": "f1a37a6e-6337-4166-8e6a-d09b5dd447a1"
   },
   "outputs": [],
   "source": [
    "deid_results.select(\"ner_chunk\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_AjzeOzbw_e6",
    "outputId": "a5dddb3d-3b01-4daf-d5c1-f5ebeba4c2d3"
   },
   "outputs": [],
   "source": [
    "deid_results.select('coordinates').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZgwJcsnojaJh"
   },
   "outputs": [],
   "source": [
    "!wget -q -O jsl_utils.py https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Healthcare/utils/jsl_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 787
    },
    "id": "kWRYi6EsxKf6",
    "outputId": "c9f31ac7-7647-4381-d3b7-825302697eb2"
   },
   "outputs": [],
   "source": [
    "from sparkocr.utils import display_image, to_pil_image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "r = deid_results.select(\"image_raw\", \"image_with_regions\").collect()[0]\n",
    "img_orig = r.image_raw\n",
    "img_deid = r.image_with_regions\n",
    "\n",
    "img_pil_orig = to_pil_image(img_orig, img_orig.mode)\n",
    "img_pil_deid = to_pil_image(img_deid, img_deid.mode)\n",
    "\n",
    "plt.figure(figsize=(24,16))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img_pil_orig, cmap='gray')\n",
    "plt.title('original')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(img_pil_deid, cmap='gray')\n",
    "plt.title(\"de-id'd\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9Wbde-GaowxY",
    "outputId": "5cf2e34b-4ede-4262-8ac5-acb1f7a973e9"
   },
   "outputs": [],
   "source": [
    "from jsl_utils import *\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "image_list = []  # append images\n",
    "\n",
    "for row in range(0,1):\n",
    "    text = deid_results.select('text').collect()[row][0]\n",
    "    hocr =  deid_results.select('hocr').collect()[row][0]\n",
    "\n",
    "    lmodel = LightPipeline(deidentification_nlp_pipeline('text'))\n",
    "    ner_result = lmodel.fullAnnotate(text)\n",
    "    ent_dict_list = [{'begin':x.begin, 'end':x.end, 'chunk':x.result, 'ner_label':x.metadata['entity'], 'sentence_id':x.metadata['sentence']} for x in ner_result[0]['ner_chunk']]\n",
    "    \n",
    "    coord_df = get_coordinates_frame(ent_dict_list, text, hocr)\n",
    "\n",
    "    img_deid = deid_results.select('image_raw').collect()[row][0]\n",
    "    img_pil_orig = to_pil_image(img_deid, img_deid.mode)\n",
    "    img_pil_orig = img_pil_orig.convert(\"RGBA\")\n",
    "\n",
    "    img_deid = deid_results.select('image_raw').collect()[row][0]\n",
    "    img_pil_deid = to_pil_image(img_deid, img_deid.mode)\n",
    "    img_pil_deid = img_pil_deid.convert(\"RGBA\")\n",
    "\n",
    "    draw_outline(img_pil_deid, coord_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Q21h4gZyD21a",
    "outputId": "74af4824-4320-491b-fe06-f33c74495ca0"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "highlighted_image_list = []  # append highlighted images\n",
    "\n",
    "for row in range(0,1):\n",
    "    text = deid_results.select('text').collect()[row][0]\n",
    "    hocr =  deid_results.select('hocr').collect()[row][0]\n",
    "\n",
    "    lmodel = LightPipeline(deidentification_nlp_pipeline('text'))\n",
    "    ner_result = lmodel.fullAnnotate(text)\n",
    "    ent_dict_list = [{'begin':x.begin, 'end':x.end, 'chunk':x.result, 'ner_label':x.metadata['entity'], 'sentence_id':x.metadata['sentence']} for x in ner_result[0]['ner_chunk']]\n",
    "    \n",
    "    coord_df = get_coordinates_frame(ent_dict_list, text, hocr)\n",
    "\n",
    "    img_deid = deid_results.select('image_raw').collect()[row][0]\n",
    "    img_pil_orig = to_pil_image(img_deid, img_deid.mode)\n",
    "    img_pil_orig = img_pil_orig.convert(\"RGBA\")\n",
    "\n",
    "    img_deid = deid_results.select('image_raw').collect()[row][0]\n",
    "    img_pil_deid = to_pil_image(img_deid, img_deid.mode)\n",
    "    img_pil_deid = img_pil_deid.convert(\"RGBA\")\n",
    "\n",
    "    highlight(img_pil_deid, coord_df)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}