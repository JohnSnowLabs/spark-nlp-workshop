{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5bHs35r8vp4O"
   },
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bpXE1HYWvwIP"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/17.Graph_builder_for_DL_models.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using the `johnsnowlabs` library, please use this  [17.0.Graph_builder_for_DL_models](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/healthcare-nlp/17.0.Graph_builder_for_DL_models.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h5_oUOFZ8oz9"
   },
   "outputs": [],
   "source": [
    "import json, os\n",
    "from google.colab import files\n",
    "\n",
    "if 'spark_jsl.json' not in os.listdir():\n",
    "  license_keys = files.upload()\n",
    "  os.rename(list(license_keys.keys())[0], 'spark_jsl.json')\n",
    "\n",
    "with open('spark_jsl.json') as f:\n",
    "    license_keys = json.load(f)\n",
    "\n",
    "# Defining license key-value pairs as local variables\n",
    "locals().update(license_keys)\n",
    "os.environ.update(license_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mqav-nsJOPkO"
   },
   "outputs": [],
   "source": [
    "# Installing pyspark and spark-nlp\n",
    "! pip install --upgrade -q pyspark==3.4.1 spark-nlp==$PUBLIC_VERSION\n",
    "\n",
    "# Installing Spark NLP Healthcare\n",
    "! pip install --upgrade -q spark-nlp-jsl==$JSL_VERSION  --extra-index-url https://pypi.johnsnowlabs.com/$SECRET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "executionInfo": {
     "elapsed": 226740,
     "status": "ok",
     "timestamp": 1758659088568,
     "user": {
      "displayName": "Vildan Sarıkaya",
      "userId": "07789644790967768983"
     },
     "user_tz": 420
    },
    "id": "X0xtiehgFT9w",
    "outputId": "86d70307-4625-4f87-cebe-d2cb967ee11b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP Version : 6.1.3\n",
      "Spark NLP_JSL Version : 6.1.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://c686c254bf2b:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark NLP Licensed</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fe1efb428d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import sparknlp\n",
    "import sparknlp_jsl\n",
    "\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp_jsl.annotator import *\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml import Pipeline,PipelineModel\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "params = {\"spark.driver.memory\":\"16G\",\n",
    "          \"spark.kryoserializer.buffer.max\":\"2000M\",\n",
    "          \"spark.driver.maxResultSize\":\"2000M\"}\n",
    "\n",
    "spark = sparknlp_jsl.start(license_keys['SECRET'],params=params)\n",
    "\n",
    "print(\"Spark NLP Version :\", sparknlp.version())\n",
    "print(\"Spark NLP_JSL Version :\", sparknlp_jsl.version())\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2b0M2oYqEBHW"
   },
   "outputs": [],
   "source": [
    "!pip install -q tensorflow==2.12.0\n",
    "!pip install -q tensorflow_addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11610,
     "status": "ok",
     "timestamp": 1758659127053,
     "user": {
      "displayName": "Vildan Sarıkaya",
      "userId": "07789644790967768983"
     },
     "user_tz": 420
    },
    "id": "aDn1lRtoUlqG",
    "outputId": "7b98d3e9-85d4-4720-a151-93ccb7165589"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Version : 2129\n",
      "TF Version    : 2.19.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "print('Graph Version :', tensorflow.version.GRAPH_DEF_VERSION)\n",
    "print('TF Version    :', tensorflow.version.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uAfR76lDOWM8"
   },
   "source": [
    "## Healthcare NLP for Data Scientists Course\n",
    "\n",
    "If you are not familiar with the components in this notebook, you can check [Healthcare NLP for Data Scientists Udemy Course](https://www.udemy.com/course/healthcare-nlp-for-data-scientists/) and the [MOOC Notebooks](https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP) for each components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PBfdXEA1RgSC"
   },
   "source": [
    "# **TF Graph Builder**\n",
    "\n",
    "`TFGraphBuilder` annotator can be used to create graphs in the model training pipeline. `TFGraphBuilder` inspects the data and creates the proper graph if a suitable version of TensorFlow (=> 2.8 ) is available. The graph is stored in the defined folder and loaded by the approach.\n",
    "\n",
    "You can use this builder with `MedicalNerApproach`, `RelationExtractionApproach`, `AssertionDLApproach`, and `GenericClassifierApproach`.\n",
    "\n",
    "**ATTENTION:** Playing with the parameters of `TFGraphBuilder` may affect the model performance that you want to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xb5UGgS9UwUk"
   },
   "outputs": [],
   "source": [
    "from sparknlp_jsl.annotator import TFGraphBuilder\n",
    "\n",
    "graph_folder = \"./medical_graphs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LP0V1viUSSn5"
   },
   "source": [
    "## **NER_DL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SblpzUsBU4FX"
   },
   "source": [
    "**Create a Medical NER graph.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mKyHz-v_T7o6"
   },
   "outputs": [],
   "source": [
    "med_ner_graph_builder = TFGraphBuilder()\\\n",
    "    .setModelName(\"ner_dl\")\\\n",
    "    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "    .setLabelColumn(\"label\")\\\n",
    "    .setGraphFile(\"auto\")\\\n",
    "    .setHiddenUnitsNumber(20)\\\n",
    "    .setGraphFolder(graph_folder)\\\n",
    "    .setIsLicensed(True)  # False -> for NerDLApproach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6kiX3VU5VDRm"
   },
   "source": [
    "**Train the model with `MedicalNerApproach` and let it use the graph generated by the builder**\n",
    "\n",
    "```python\n",
    "...\n",
    "med_ner = MedicalNerApproach() \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "    .setLabelColumn(\"label\") \\\n",
    "    .setOutputCol(\"ner\") \\\n",
    "    .setMaxEpochs(5) \\\n",
    "    .setLr(0.003) \\\n",
    "    .setBatchSize(8) \\\n",
    "    .setRandomSeed(0) \\\n",
    "    .setVerbose(1) \\\n",
    "    .setEvaluationLogExtended(False) \\\n",
    "    .setEnableOutputLogs(False) \\\n",
    "    .setIncludeConfidence(True) \\\n",
    "    .setEarlyStoppingCriterion(0.5) \\\n",
    "    .setEarlyStoppingPatience(2) \\\n",
    "    .setTestDataset(test_data_parquet_path) \\\n",
    "    .setGraphFolder(graph_folder)\n",
    "\n",
    "medner_pipeline = sparknlp.base.Pipeline().setStages([\n",
    "    embeddings,\n",
    "    med_ner_graph_builder,\n",
    "    med_ner    \n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IYFyOBFgSSn6"
   },
   "source": [
    "## **AssertionDL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-g6kBPGP299"
   },
   "source": [
    "**Create an Assertion DL graph.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ofjJFy87WaKX"
   },
   "outputs": [],
   "source": [
    "assertion_graph_builder = TFGraphBuilder()\\\n",
    "    .setModelName(\"assertion_dl\")\\\n",
    "    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "    .setLabelColumn(\"label\")\\\n",
    "    .setGraphFolder(graph_folder)\\\n",
    "    .setGraphFile(\"assertion_graph.pb\")\\\n",
    "    .setMaxSequenceLength(100)\\\n",
    "    .setHiddenUnitsNumber(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYEz-be-P6sP"
   },
   "source": [
    "**Train the model with `AssertionDLApproach` and let it use the graph generated by the builder**\n",
    "\n",
    "```python\n",
    "...\n",
    "assertion_status = sparknlp_jsl.annotators.AssertionDLApproach() \\\n",
    "    .setGraphFolder(graph_folder) \\\n",
    "    .setGraphFile(f\"{graph_folder}/assertion_graph.pb\")\\\n",
    "    .setInputCols(\"sentence\", \"chunk\", \"embeddings\") \\\n",
    "    .setOutputCol(\"assertion\") \\\n",
    "    .setStartCol(\"start\") \\\n",
    "    .setEndCol(\"end\") \\\n",
    "    .setLabelCol(\"label\") \\\n",
    "    .setLearningRate(0.01) \\\n",
    "    .setDropout(0.15) \\\n",
    "    .setBatchSize(16) \\\n",
    "    .setEpochs(3) \\\n",
    "    .setScopeWindow([9, 15])\\\n",
    "    .setValidationSplit(0.2) \\\n",
    "    .setIncludeConfidence(True)\n",
    "    \n",
    "assertion_pipeline = Pipeline(\n",
    "    stages=[\n",
    "        document_assembler,\n",
    "        sentence_detector,\n",
    "        tokenizer,\n",
    "        POSTag,\n",
    "        chunker,\n",
    "        embeddings,\n",
    "        assertion_graph_builder,\n",
    "        assertion_status])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rQNZOCeSSn6"
   },
   "source": [
    "## **GenericClassifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QC9kemHpQJr2"
   },
   "source": [
    "**Create Generic Classifier the pipeline with a graph builder in it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GMqCR6xVSZTq"
   },
   "outputs": [],
   "source": [
    "gcf_graph_builder = TFGraphBuilder()\\\n",
    "    .setModelName(\"generic_classifier\")\\\n",
    "    .setInputCols([\"feature_vector\"]) \\\n",
    "    .setLabelColumn(\"class\")\\\n",
    "    .setGraphFolder(graph_folder)\\\n",
    "    .setGraphFile(\"gcf_graph.pb\")\\\n",
    "    .setHiddenLayers([10, 5, 3])\\\n",
    "    .setHiddenAct(\"tanh\")\\\n",
    "    .setHiddenActL2(False)\\\n",
    "    .setHiddenWeightsL2(False)\\\n",
    "    .setBatchNorm(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "haDr5vqE1F5h"
   },
   "source": [
    "```python\n",
    "...\n",
    "gcf_approach = sparknlp_jsl.annotators.GenericClassifierApproach()\\\n",
    "    .setLabelColumn(\"class\")\\\n",
    "    .setInputCols([\"feature_vector\"])\\\n",
    "    .setOutputCol(\"prediction\")\\\n",
    "    .setModelFile(f\"{graph_folder}/gcf_graph.pb\")\\\n",
    "    .setEpochsNumber(5)\\\n",
    "    .setBatchSize(100)\\\n",
    "    .setFeatureScaling(\"zscore\")\\\n",
    "    .setFixImbalance(True)\\\n",
    "    .setLearningRate(0.001)\\\n",
    "\n",
    "gcf_pipeline = Pipeline(stages=[\n",
    "    features_asm,\n",
    "    gcf_graph_builder,\n",
    "    gcf_approach])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9jP3M8XlSSn7"
   },
   "source": [
    "## **RelationExtraction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZrD3U0PjQYcx"
   },
   "source": [
    "**Create RE graph builder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SaT7l2hw-iI_"
   },
   "outputs": [],
   "source": [
    "re_graph_builder = TFGraphBuilder()\\\n",
    "    .setModelName(\"relation_extraction\")\\\n",
    "    .setInputCols([\"embeddings\", \"pos_tags\", \"train_ner_chunks\", \"dependencies\"]) \\\n",
    "    .setLabelColumn(\"target_rel\")\\\n",
    "    .setGraphFolder(graph_folder)\\\n",
    "    .setGraphFile(\"re_graph.pb\")\\\n",
    "    .setHiddenLayers([20, 10])\\\n",
    "    .setHiddenAct(\"sigmoid\")\\\n",
    "    .setHiddenActL2(True)\\\n",
    "    .setHiddenWeightsL2(False)\\\n",
    "    .setBatchNorm(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tlqIuhZx1ZoH"
   },
   "source": [
    "```python\n",
    "...\n",
    "re_approach = sparknlp_jsl.annotators.RelationExtractionApproach()\\\n",
    "    .setInputCols([\"embeddings\", \"pos_tags\", \"train_ner_chunks\", \"dependencies\"])\\\n",
    "    .setOutputCol(\"relations\")\\\n",
    "    .setLabelColumn(\"target_rel\")\\\n",
    "    .setEpochsNumber(20)\\\n",
    "    .setDropout(0.5)\\\n",
    "    .setLearningRate(0.001)\\\n",
    "    .setModelFile(f\"{graph_folder}/re_graph.pb\")\\\n",
    "    .setFixImbalance(True)\\\n",
    "    .setFromEntity(\"from_begin\", \"from_end\", \"from_label\")\\\n",
    "    .setToEntity(\"to_begin\", \"to_end\", \"to_label\")\n",
    "\n",
    "re_pipeline = Pipeline(stages=[\n",
    "    documenter,\n",
    "    tokenizer,\n",
    "    words_embedder,\n",
    "    pos_tagger,\n",
    "    dependency_parser,\n",
    "    re_graph_builder,\n",
    "    re_approach])\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D4fYc-D_L4tZ"
   },
   "source": [
    "# **MedicalNerDLGraphChecker**\n",
    "\n",
    "The MedicalNerDLGraphChecker processes the dataset to extract required graph parameters (tokens, labels, embedding dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 136654,
     "status": "ok",
     "timestamp": 1758659264649,
     "user": {
      "displayName": "Vildan Sarıkaya",
      "userId": "07789644790967768983"
     },
     "user_tz": 420
    },
    "id": "aG5DVUnWj_U3",
    "outputId": "e70cf3ed-2cd8-4d96-fadc-fa46cd3c6ccb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "embeddings = (WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\n",
    "            .setInputCols([\"splitter\", \"token\"])\n",
    "            .setOutputCol(\"embeddings\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hFvFqQz9EjxW"
   },
   "outputs": [],
   "source": [
    "nerDLGraphChecker = MedicalNerDLGraphChecker()\\\n",
    "    .setInputCols([\"splitter\", \"token\"])\\\n",
    "    .setLabelColumn(\"ner_label\")\\\n",
    "    .setEmbeddingsModel(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S1gMiKrZPWDk"
   },
   "source": [
    "```python\n",
    "nerTagger = MedicalNerApproach()\\\n",
    "    .setInputCols([\"splitter\", \"token\", \"embeddings\"])\\\n",
    "    .setLabelColumn(\"ner_label\")\\\n",
    "    .setOutputCol(\"ner\")\\\n",
    "    .setMaxEpochs(30)\\\n",
    "    .setBatchSize(8)\\\n",
    "    .setRandomSeed(0)\\\n",
    "    .setVerbose(1)\\\n",
    "    .setValidationSplit(0.2)\\\n",
    "    .setEvaluationLogExtended(True) \\\n",
    "    .setEnableOutputLogs(True)\\\n",
    "    .setIncludeConfidence(True)\\\n",
    "    .setOutputLogsPath('ner_logs')\\\n",
    "    .setEarlyStoppingCriterion(0.01)\\\n",
    "    .setEarlyStoppingPatience(5)\\\n",
    "    .setUseBestModel(False)\\\n",
    "    #.setTestDataset(\"./data/test_df.parquet\")\\\n",
    "    #.setEnableMemoryOptimizer(True) #>> if you have a limited memory and a large conll file, you can set this True to train batch by batch\n",
    "    #.setDatasetInfo(\"NCBI_sample_short dataset\") #You can add details regarding the dataset\n",
    "\n",
    "ner_pipeline = Pipeline(\n",
    "    stages=[\n",
    "          nerDLGraphChecker,\n",
    "          nerTagger\n",
    " ])\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9tVfGDp9RAN4"
   },
   "source": [
    "# **Generating Custom Graphs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WEreWOOOtANE"
   },
   "outputs": [],
   "source": [
    "from sparknlp_jsl.training import tf_graph\n",
    "\n",
    "# before sparknlp_jsl 3.2.1 version run the code below\n",
    "# %tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1711656414664,
     "user": {
      "displayName": "Bugra",
      "userId": "12474083375271086689"
     },
     "user_tz": -180
    },
    "id": "JN0iIGRAtI_w",
    "outputId": "8bafc3a6-500d-4348-add5-cf643c2be257"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ner_dl',\n",
       " 'generic_classifier',\n",
       " 'assertion_dl',\n",
       " 'relation_extraction',\n",
       " 'logreg_classifier',\n",
       " 'svm_classifier',\n",
       " 'fewshot_classifier']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_graph.get_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PmLZFHewvapj"
   },
   "source": [
    "## **NER_DL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 478,
     "status": "ok",
     "timestamp": 1711656415132,
     "user": {
      "displayName": "Bugra",
      "userId": "12474083375271086689"
     },
     "user_tz": -180
    },
    "id": "FNW8EJ-ht7-4",
    "outputId": "63f6b49c-ecfb-4920-b404-f1b706f7bbc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_dl parameters.\n",
      "Parameter            Required   Default value        Description\n",
      "ntags                yes        -                    Number of tags.\n",
      "embeddings_dim       no         200                  Embeddings dimension.\n",
      "nchars               no         100                  Number of chars.\n",
      "lstm_size            no         128                  Number of LSTM units.\n",
      "gpu_device           no         0                    Device for training.\n",
      "is_medical           no         0                    Build a Medical Ner graph.\n"
     ]
    }
   ],
   "source": [
    "tf_graph.print_model_params(\"ner_dl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jPOjkADCt9U8"
   },
   "outputs": [],
   "source": [
    "tf_graph.build(\"ner_dl\",\n",
    "               build_params={\"embeddings_dim\": 200,\n",
    "                             \"nchars\": 80,\n",
    "                             \"ntags\": 12,\n",
    "                             \"is_medical\": 1},\n",
    "               model_location=\"./medical_ner_graphs\",\n",
    "               model_filename=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "peKE7_zLvdwg"
   },
   "source": [
    "## **AssertionDL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1711656435165,
     "user": {
      "displayName": "Bugra",
      "userId": "12474083375271086689"
     },
     "user_tz": -180
    },
    "id": "92En8saVuGRk",
    "outputId": "c7286606-97f1-41a8-d46f-4d7ddd40f29c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assertion_dl parameters.\n",
      "Parameter            Required   Default value        Description\n",
      "max_seq_len          no         250                  Maximum sequence length.\n",
      "feat_size            no         200                  Feature size.\n",
      "n_classes            yes        -                    Number of classes.\n",
      "device               no         /cpu:0               Device for training.\n",
      "n_hidden             no         34                   Number of hidden units.\n"
     ]
    }
   ],
   "source": [
    "tf_graph.print_model_params(\"assertion_dl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FZ0aQhKnuxxC"
   },
   "outputs": [],
   "source": [
    "tf_graph.build(\"assertion_dl\",\n",
    "               build_params={\"n_classes\": 10},\n",
    "               model_location=\"./assertion_graph\",\n",
    "               model_filename=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DUb9viOAvgcj"
   },
   "source": [
    "## **GenericClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1711656441526,
     "user": {
      "displayName": "Bugra",
      "userId": "12474083375271086689"
     },
     "user_tz": -180
    },
    "id": "u9pi5wt9uzDM",
    "outputId": "9d3ef6b2-0f8f-4694-d695-a9476ad90690"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generic_classifier parameters.\n",
      "Parameter            Required   Default value        Description\n",
      "hidden_layers        no         [200]                List of integers indicating the size of each hidden layer. For example: [100, 200, 300].\n",
      "input_dim            yes        -                    Input dimension.\n",
      "output_dim           yes        -                    Output dimension.\n",
      "hidden_act           no         relu                 Activation function of hidden layers: relu, sigmoid, tanh or linear.\n",
      "hidden_act_l2        no         0                    L2 regularization of hidden layer activations. Boolean (0 or 1).\n",
      "hidden_weights_l2    no         0                    L2 regularization of hidden layer weights. Boolean (0 or 1).\n",
      "batch_norm           no         0                    Batch normalization. Boolean (0 or 1).\n",
      "output_act           no         softmax              Output activation function: softmax, sigmoid or linear.\n",
      "loss_func            no         cross_entropy        Loss function: cross_entropy, mean_squares or hinge\n"
     ]
    }
   ],
   "source": [
    "tf_graph.print_model_params(\"generic_classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 923,
     "status": "ok",
     "timestamp": 1711656442433,
     "user": {
      "displayName": "Bugra",
      "userId": "12474083375271086689"
     },
     "user_tz": -180
    },
    "id": "ZGJTbbjvvO-P",
    "outputId": "58ed359e-fe84-4512-e941-dde2c840cea0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generic_classifier graph exported to generic_graph/gcl.100.10.pb\n"
     ]
    }
   ],
   "source": [
    "tf_graph.build(\"generic_classifier\",\n",
    "               build_params={\"input_dim\": 100,\n",
    "                             \"output_dim\": 10,\n",
    "                             \"hidden_layers\": [300, 200, 100],\n",
    "                             \"hidden_act\": \"tanh\"},\n",
    "               model_location=\"generic_graph\",\n",
    "               model_filename=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hVJ4-hNHvjVU"
   },
   "source": [
    "## **RelationExtraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1711656442433,
     "user": {
      "displayName": "Bugra",
      "userId": "12474083375271086689"
     },
     "user_tz": -180
    },
    "id": "ib9kczwzvQkQ",
    "outputId": "3d7bc643-07d4-4bf4-e79a-5bda49de1c57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation_extraction parameters.\n",
      "Parameter            Required   Default value        Description\n",
      "hidden_layers        no         [200]                List of integers indicating the size of each hidden layer. For example: [100, 200, 300].\n",
      "input_dim            yes        -                    Input dimension.\n",
      "output_dim           yes        -                    Output dimension.\n",
      "hidden_act           no         relu                 Activation function of hidden layers: relu, sigmoid, tanh or linear.\n",
      "hidden_act_l2        no         0                    L2 regularization of hidden layer activations. Boolean (0 or 1).\n",
      "hidden_weights_l2    no         0                    L2 regularization of hidden layer weights. Boolean (0 or 1).\n",
      "batch_norm           no         0                    Batch normalization. Boolean (0 or 1).\n",
      "output_act           no         softmax              Output activation function: softmax, sigmoid or linear.\n",
      "loss_func            no         cross_entropy        Loss function: cross_entropy, mean_squares or hinge\n"
     ]
    }
   ],
   "source": [
    "tf_graph.print_model_params(\"relation_extraction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2536,
     "status": "ok",
     "timestamp": 1711656444964,
     "user": {
      "displayName": "Bugra",
      "userId": "12474083375271086689"
     },
     "user_tz": -180
    },
    "id": "uoa_et-YvTmc",
    "outputId": "b968cdb5-dc48-4737-b0be-6eb0fa499b4f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/layers/normalization/batch_normalization.py:581: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation_extraction graph exported to relation_graph/re_with_BN.pb\n"
     ]
    }
   ],
   "source": [
    "tf_graph.build(\"relation_extraction\",\n",
    "               build_params={\"input_dim\": 6000,\n",
    "                             \"output_dim\": 3,\n",
    "                             'batch_norm':1,\n",
    "                             \"hidden_layers\": [300, 200],\n",
    "                             \"hidden_act\": \"relu\",\n",
    "                             'hidden_act_l2':1},\n",
    "               model_location=\"relation_graph\",\n",
    "               model_filename=\"re_with_BN.pb\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
