{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "17.Graph_builder_for_DL_models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bHs35r8vp4O"
      },
      "source": [
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpXE1HYWvwIP"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/17.Graph_builder_for_DL_models.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPvDMna9-lEA"
      },
      "source": [
        "import json, os\n",
        "from google.colab import files\n",
        "\n",
        "if 'spark_jsl.json' not in os.listdir():\n",
        "  license_keys = files.upload()\n",
        "  os.rename(list(license_keys.keys())[0], 'spark_jsl.json')\n",
        "\n",
        "with open('spark_jsl.json') as f:\n",
        "    license_keys = json.load(f)\n",
        "\n",
        "# Defining license key-value pairs as local variables\n",
        "locals().update(license_keys)\n",
        "os.environ.update(license_keys)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mqav-nsJOPkO"
      },
      "source": [
        "# Installing pyspark and spark-nlp\n",
        "! pip install --upgrade -q pyspark==3.1.2 spark-nlp==$PUBLIC_VERSION\n",
        "\n",
        "# Installing Spark NLP Healthcare\n",
        "! pip install --upgrade -q spark-nlp-jsl==$JSL_VERSION  --extra-index-url https://pypi.johnsnowlabs.com/$SECRET"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "import sparknlp\n",
        "import sparknlp_jsl\n",
        "\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp_jsl.annotator import *\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.ml import Pipeline,PipelineModel\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "params = {\"spark.driver.memory\":\"16G\", \n",
        "          \"spark.kryoserializer.buffer.max\":\"2000M\", \n",
        "          \"spark.driver.maxResultSize\":\"2000M\"} \n",
        "\n",
        "spark = sparknlp_jsl.start(license_keys['SECRET'],params=params)\n",
        "\n",
        "print(\"Spark NLP Version :\", sparknlp.version())\n",
        "print(\"Spark NLP_JSL Version :\", sparknlp_jsl.version())\n",
        "\n",
        "spark"
      ],
      "metadata": {
        "id": "X0xtiehgFT9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2b0M2oYqEBHW"
      },
      "source": [
        "!pip install -q tensorflow==2.7.0\n",
        "!pip install -q tensorflow_addons"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "print('Graph Version :', tensorflow.version.GRAPH_DEF_VERSION)\n",
        "print('TF Version    :', tensorflow.version.VERSION)"
      ],
      "metadata": {
        "id": "aDn1lRtoUlqG",
        "outputId": "dd5cbd1d-58e0-4d9a-c2a5-974a8b7fd5d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph Version : 898\n",
            "TF Version    : 2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TF Graph Builder\n",
        "\n",
        "`TFGraphBuilder` annotator can be used to create graphs in the model training pipeline. `TFGraphBuilder` inspects the data and creates the proper graph if a suitable version of TensorFlow (<= 2.7 ) is available. The graph is stored in the defined folder and loaded by the approach.\n",
        "\n",
        "You can use this builder with `MedicalNerApproach`, `RelationExtractionApproach`, `AssertionDLApproach`, and `GenericClassifierApproach`."
      ],
      "metadata": {
        "id": "PBfdXEA1RgSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sparknlp_jsl.annotator import TFGraphBuilder\n",
        "\n",
        "graph_folder = \"./medical_graphs\""
      ],
      "metadata": {
        "id": "Xb5UGgS9UwUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP0V1viUSSn5"
      },
      "source": [
        "## **NER_DL**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create a Medical NER graph.**"
      ],
      "metadata": {
        "id": "SblpzUsBU4FX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "med_ner_graph_builder = TFGraphBuilder()\\\n",
        "    .setModelName(\"ner_dl\")\\\n",
        "    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
        "    .setLabelColumn(\"label\")\\\n",
        "    .setGraphFile(\"auto\")\\\n",
        "    .setHiddenUnitsNumber(20)\\\n",
        "    .setGraphFolder(graph_folder)\\"
      ],
      "metadata": {
        "id": "mKyHz-v_T7o6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train the model with `MedicalNerApproach` and let it use the graph generated by the builder**\n",
        "\n",
        "```python\n",
        "...\n",
        "med_ner = MedicalNerApproach() \\\n",
        "    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
        "    .setLabelColumn(\"label\") \\\n",
        "    .setOutputCol(\"ner\") \\\n",
        "    .setMaxEpochs(5) \\\n",
        "    .setLr(0.003) \\\n",
        "    .setBatchSize(8) \\\n",
        "    .setRandomSeed(0) \\\n",
        "    .setVerbose(1) \\\n",
        "    .setEvaluationLogExtended(False) \\\n",
        "    .setEnableOutputLogs(False) \\\n",
        "    .setIncludeConfidence(True) \\\n",
        "    .setEarlyStoppingCriterion(0.5) \\\n",
        "    .setEarlyStoppingPatience(2) \\\n",
        "    .setTestDataset(test_data_parquet_path) \\\n",
        "    .setGraphFolder(graph_folder)\n",
        "\n",
        "medner_pipeline = sparknlp.base.Pipeline().setStages([\n",
        "    embeddings, \n",
        "    med_ner_graph_builder, \n",
        "    med_ner    \n",
        "])\n",
        "```"
      ],
      "metadata": {
        "id": "6kiX3VU5VDRm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYFyOBFgSSn6"
      },
      "source": [
        "## **AssertionDL**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create an Assertion DL graph.**"
      ],
      "metadata": {
        "id": "8-g6kBPGP299"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assertion_graph_builder = sparknlp_jsl.annotators.TFGraphBuilder()\\\n",
        "    .setModelName(\"assertion_dl\")\\\n",
        "    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
        "    .setLabelColumn(\"label\")\\\n",
        "    .setGraphFolder(graph_folder)\\\n",
        "    .setGraphFile(\"assertion_graph.pb\")\\\n",
        "    .setMaxSequenceLength(100)\\\n",
        "    .setHiddenUnitsNumber(16)\n"
      ],
      "metadata": {
        "id": "ofjJFy87WaKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train the model with `AssertionDLApproach` and let it use the graph generated by the builder**\n",
        "\n",
        "```python\n",
        "...\n",
        "assertion_status = sparknlp_jsl.annotators.AssertionDLApproach() \\\n",
        "    .setGraphFolder(graph_folder) \\\n",
        "    .setGraphFile(f\"{graph_folder}/assertion_graph.pb\")\\\n",
        "    .setInputCols(\"sentence\", \"chunk\", \"embeddings\") \\\n",
        "    .setOutputCol(\"assertion\") \\\n",
        "    .setStartCol(\"start\") \\\n",
        "    .setEndCol(\"end\") \\\n",
        "    .setLabelCol(\"label\") \\\n",
        "    .setLearningRate(0.01) \\\n",
        "    .setDropout(0.15) \\\n",
        "    .setBatchSize(16) \\\n",
        "    .setEpochs(3) \\\n",
        "    .setScopeWindow([9, 15])\\\n",
        "    .setValidationSplit(0.2) \\\n",
        "    .setIncludeConfidence(True)\n",
        "    \n",
        "assertion_pipeline = Pipeline(\n",
        "    stages=[\n",
        "        document_assembler, \n",
        "        sentence_detector, \n",
        "        tokenizer, \n",
        "        POSTag, \n",
        "        chunker, \n",
        "        embeddings, \n",
        "        assertion_graph_builder, \n",
        "        assertion_status])\n",
        "```"
      ],
      "metadata": {
        "id": "RYEz-be-P6sP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rQNZOCeSSn6"
      },
      "source": [
        "## **GenericClassifier**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create Generic Classifier the pipeline with a graph builder in it**"
      ],
      "metadata": {
        "id": "QC9kemHpQJr2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gcf_graph_builder = sparknlp_jsl.annotators.TFGraphBuilder()\\\n",
        "    .setModelName(\"generic_classifier\")\\\n",
        "    .setInputCols([\"feature_vector\"]) \\\n",
        "    .setLabelColumn(\"class\")\\\n",
        "    .setGraphFolder(graph_folder)\\\n",
        "    .setGraphFile(\"gcf_graph.pb\")\\\n",
        "    .setHiddenLayers([10, 5, 3])\\\n",
        "    .setHiddenAct(\"tanh\")\\\n",
        "    .setHiddenActL2(False)\\\n",
        "    .setHiddenWeightsL2(False)\\\n",
        "    .setBatchNorm(False)"
      ],
      "metadata": {
        "id": "GMqCR6xVSZTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "...\n",
        "gcf_approach = sparknlp_jsl.annotators.GenericClassifierApproach()\\\n",
        "    .setLabelColumn(\"class\")\\\n",
        "    .setInputCols([\"feature_vector\"])\\\n",
        "    .setOutputCol(\"prediction\")\\\n",
        "    .setModelFile(f\"{graph_folder}/gcf_graph.pb\")\\\n",
        "    .setEpochsNumber(5)\\\n",
        "    .setBatchSize(100)\\\n",
        "    .setFeatureScaling(\"zscore\")\\\n",
        "    .setFixImbalance(True)\\\n",
        "    .setLearningRate(0.001)\\\n",
        "\n",
        "gcf_pipeline = Pipeline(stages=[\n",
        "    features_asm, \n",
        "    gcf_graph_builder, \n",
        "    gcf_approach])\n",
        "```"
      ],
      "metadata": {
        "id": "haDr5vqE1F5h"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jP3M8XlSSn7"
      },
      "source": [
        "## **RelationExtraction**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create RE graph builder**"
      ],
      "metadata": {
        "id": "ZrD3U0PjQYcx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "re_graph_builder = sparknlp_jsl.annotators.TFGraphBuilder()\\\n",
        "    .setModelName(\"relation_extraction\")\\\n",
        "    .setInputCols([\"embeddings\", \"pos_tags\", \"train_ner_chunks\", \"dependencies\"]) \\\n",
        "    .setLabelColumn(\"target_rel\")\\\n",
        "    .setGraphFolder(graph_folder)\\\n",
        "    .setGraphFile(\"re_graph.pb\")\\\n",
        "    .setHiddenLayers([20, 10])\\\n",
        "    .setHiddenAct(\"sigmoid\")\\\n",
        "    .setHiddenActL2(True)\\\n",
        "    .setHiddenWeightsL2(False)\\\n",
        "    .setBatchNorm(False)"
      ],
      "metadata": {
        "id": "SaT7l2hw-iI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "...\n",
        "re_approach = sparknlp_jsl.annotators.RelationExtractionApproach()\\\n",
        "    .setInputCols([\"embeddings\", \"pos_tags\", \"train_ner_chunks\", \"dependencies\"])\\\n",
        "    .setOutputCol(\"relations\")\\\n",
        "    .setLabelColumn(\"target_rel\")\\\n",
        "    .setEpochsNumber(20)\\\n",
        "    .setDropout(0.5)\\\n",
        "    .setLearningRate(0.001)\\\n",
        "    .setModelFile(f\"{graph_folder}/re_graph.pb\")\\\n",
        "    .setFixImbalance(True)\\\n",
        "    .setFromEntity(\"from_begin\", \"from_end\", \"from_label\")\\\n",
        "    .setToEntity(\"to_begin\", \"to_end\", \"to_label\")\n",
        "\n",
        "re_pipeline = Pipeline(stages=[\n",
        "    documenter, \n",
        "    tokenizer, \n",
        "    words_embedder, \n",
        "    pos_tagger, \n",
        "    dependency_parser,\n",
        "    re_graph_builder,\n",
        "    re_approach])\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "tlqIuhZx1ZoH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Generating Custom Graphs**"
      ],
      "metadata": {
        "id": "9tVfGDp9RAN4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEreWOOOtANE"
      },
      "source": [
        "from sparknlp_jsl.training import tf_graph\n",
        "\n",
        "# before sparknlp_jsl 3.2.1 version run the code below\n",
        "# %tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JN0iIGRAtI_w",
        "outputId": "164a0718-dbd3-4ec4-ef6f-c28d5a31486e"
      },
      "source": [
        "tf_graph.get_models()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ner_dl', 'generic_classifier', 'assertion_dl', 'relation_extraction']"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmLZFHewvapj"
      },
      "source": [
        "## **NER_DL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNW8EJ-ht7-4",
        "outputId": "1aa97395-c6e1-4e87-d422-e332c3ba274a"
      },
      "source": [
        "tf_graph.print_model_params(\"ner_dl\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ner_dl parameters.\n",
            "Parameter            Required   Default value        Description\n",
            "ntags                yes        -                    Number of tags.\n",
            "embeddings_dim       no         200                  Embeddings dimension.\n",
            "nchars               no         100                  Number of chars.\n",
            "lstm_size            no         128                  Number of LSTM units.\n",
            "gpu_device           no         0                    Device for training.\n",
            "is_medical           no         0                    Build a Medical Ner graph.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPOjkADCt9U8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b648d03d-1703-4800-dfca-c84c8b646498"
      },
      "source": [
        "tf_graph.build(\"ner_dl\",\n",
        "               build_params={\"embeddings_dim\": 200, \n",
        "                             \"nchars\": 80, \n",
        "                             \"ntags\": 12, \n",
        "                             \"is_medical\": 1}, \n",
        "               model_location=\"./medical_ner_graphs\",\n",
        "               model_filename=\"auto\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1702: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ner_dl graph exported to ./medical_ner_graphs/blstm_12_200_128_80.pb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peKE7_zLvdwg"
      },
      "source": [
        "## **AssertionDL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92En8saVuGRk",
        "outputId": "fdbe888b-6ee8-4c47-81d1-739c5014eb68"
      },
      "source": [
        "tf_graph.print_model_params(\"assertion_dl\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "assertion_dl parameters.\n",
            "Parameter            Required   Default value        Description\n",
            "max_seq_len          no         250                  Maximum sequence length.\n",
            "feat_size            no         200                  Feature size.\n",
            "n_classes            yes        -                    Number of classes.\n",
            "device               no         /cpu:0               Device for training.\n",
            "n_hidden             no         34                   Number of hidden units.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZ0aQhKnuxxC"
      },
      "source": [
        "tf_graph.build(\"assertion_dl\",\n",
        "               build_params={\"n_classes\": 10}, \n",
        "               model_location=\"./assertion_graph\",\n",
        "               model_filename=\"auto\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUb9viOAvgcj"
      },
      "source": [
        "## **GenericClassifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9pi5wt9uzDM",
        "outputId": "144f5aae-2dbb-4c55-c06f-ec9626b91936"
      },
      "source": [
        "tf_graph.print_model_params(\"generic_classifier\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generic_classifier parameters.\n",
            "Parameter            Required   Default value        Description\n",
            "hidden_layers        no         [200]                List of integers indicating the size of each hidden layer. For example: [100, 200, 300].\n",
            "input_dim            yes        -                    Input dimension.\n",
            "output_dim           yes        -                    Output dimension.\n",
            "hidden_act           no         relu                 Activation function of hidden layers: relu, sigmoid, tanh or linear.\n",
            "hidden_act_l2        no         0                    L2 regularization of hidden layer activations. Boolean (0 or 1).\n",
            "hidden_weights_l2    no         0                    L2 regularization of hidden layer weights. Boolean (0 or 1).\n",
            "batch_norm           no         0                    Batch normalization. Boolean (0 or 1).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGJTbbjvvO-P"
      },
      "source": [
        "tf_graph.build(\"generic_classifier\",\n",
        "               build_params={\"input_dim\": 100, \n",
        "                             \"output_dim\": 10, \n",
        "                             \"hidden_layers\": [300, 200, 100], \n",
        "                             \"hidden_act\": \"tanh\"}, \n",
        "               model_location=\"generic_graph\", \n",
        "               model_filename=\"auto\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVJ4-hNHvjVU"
      },
      "source": [
        "## **RelationExtraction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ib9kczwzvQkQ",
        "outputId": "dcb515f2-836f-482a-9d40-862121c43b07"
      },
      "source": [
        "tf_graph.print_model_params(\"relation_extraction\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "relation_extraction parameters.\n",
            "Parameter            Required   Default value        Description\n",
            "hidden_layers        no         [200]                List of integers indicating the size of each hidden layer. For example: [100, 200, 300].\n",
            "input_dim            yes        -                    Input dimension.\n",
            "output_dim           yes        -                    Output dimension.\n",
            "hidden_act           no         relu                 Activation function of hidden layers: relu, sigmoid, tanh or linear.\n",
            "hidden_act_l2        no         0                    L2 regularization of hidden layer activations. Boolean (0 or 1).\n",
            "hidden_weights_l2    no         0                    L2 regularization of hidden layer weights. Boolean (0 or 1).\n",
            "batch_norm           no         0                    Batch normalization. Boolean (0 or 1).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoa_et-YvTmc"
      },
      "source": [
        "tf_graph.build(\"relation_extraction\",\n",
        "               build_params={\"input_dim\": 6000, \n",
        "                             \"output_dim\": 3, \n",
        "                             'batch_norm':1, \n",
        "                             \"hidden_layers\": [300, 200], \n",
        "                             \"hidden_act\": \"relu\", \n",
        "                             'hidden_act_l2':1}, \n",
        "               model_location=\"relation_graph\", \n",
        "               model_filename=\"re_with_BN.pb\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}