{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Wfq4tie-OVj"
   },
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7OpNxxcL-P2G"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/38.InternalDocumentSplitter.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using the `johnsnowlabs` library, please use this Â [30.0.InternalDocumentSplitter](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/healthcare-nlp/30.0.InternalDocumentSplitter.ipynb) notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQ2JWggt-UYX"
   },
   "source": [
    "#   **ðŸ“œ InternalDocumentSplitter**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RXIkmcBVbAZQ"
   },
   "source": [
    "This Annotator splits large documents into small documents. `InternalDocumentSplitter` has setSplitMode method to decide how to split documents.\n",
    "\n",
    "If splitMode is `recursive`, It takes the separators in order and splits subtexts if they are over the chunk length, considering optional overlap of the chunks.\n",
    "\n",
    "Additionally, you can set\n",
    "- custom patterns with setSplitPatterns\n",
    "- whether patterns should be interpreted as regex with setPatternsAreRegex\n",
    "- whether to keep the separators with setKeepSeparators\n",
    "- whether to trim whitespaces with setTrimWhitespace\n",
    "- whether to explode the splits to individual rows with setExplodeSplits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sEyNop0Vo70p"
   },
   "source": [
    "## Healthcare NLP for Data Scientists Course\n",
    "\n",
    "If you are not familiar with the components in this notebook, you can check [Healthcare NLP for Data Scientists Udemy Course](https://www.udemy.com/course/healthcare-nlp-for-data-scientists/) and the [MOOC Notebooks](https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP) for each components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "okhT7AcXxben"
   },
   "source": [
    "## **ðŸŽ¬ Colab Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "REmprZQ8Mbrr"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from google.colab import files\n",
    "\n",
    "license_keys = files.upload()\n",
    "\n",
    "with open(list(license_keys.keys())[0]) as f:\n",
    "    license_keys = json.load(f)\n",
    "\n",
    "# Defining license key-value pairs as local variables\n",
    "locals().update(license_keys)\n",
    "\n",
    "# Adding license key-value pairs to environment variables\n",
    "os.environ.update(license_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_wRTzAtKjXpo"
   },
   "outputs": [],
   "source": [
    "# Installing pyspark and spark-nlp\n",
    "! pip install --upgrade -q pyspark==3.4.1 spark-nlp==$PUBLIC_VERSION\n",
    "\n",
    "# Installing Spark NLP Healthcare\n",
    "! pip install --upgrade -q spark-nlp-jsl==$JSL_VERSION  --extra-index-url https://pypi.johnsnowlabs.com/$SECRET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "executionInfo": {
     "elapsed": 139637,
     "status": "ok",
     "timestamp": 1759303433773,
     "user": {
      "displayName": "Mehmet DaÄŸ",
      "userId": "14052875917891496135"
     },
     "user_tz": -180
    },
    "id": "ziwjuhAV7DYH",
    "outputId": "8707ffee-20ee-4ae0-ecc5-fe0ea9dcd610"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP Version : 6.1.3\n",
      "Spark NLP_JSL Version : 6.1.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://e70471b66bf3:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark NLP Licensed</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x789f314ae4e0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import sparknlp\n",
    "import sparknlp_jsl\n",
    "\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp_jsl.annotator import *\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml import Pipeline,PipelineModel\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "params = {\"spark.driver.memory\":\"16G\",\n",
    "          \"spark.kryoserializer.buffer.max\":\"2000M\",\n",
    "          \"spark.driver.maxResultSize\":\"2000M\"}\n",
    "\n",
    "print(\"Spark NLP Version :\", sparknlp.version())\n",
    "print(\"Spark NLP_JSL Version :\", sparknlp_jsl.version())\n",
    "\n",
    "spark = sparknlp_jsl.start(license_keys['SECRET'],params=params)\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBTuAaNIaE-n"
   },
   "source": [
    "## **ðŸ–¨ï¸ Input/Output Annotation Types**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnFxBtrjaJyP"
   },
   "source": [
    "- Input: `DOCUMENT`\n",
    "\n",
    "- Output: `DOCUMENT`\n",
    "\n",
    "Optionaly `TOKEN` and one more `DOCUMENT` (sentence) can be additional input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RLbYplk2a30Z"
   },
   "source": [
    "## **ðŸ”Ž Parameters**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uzlkaWUZa7KN"
   },
   "source": [
    "**Parameters**:\n",
    "\n",
    "- `chunkSize`: Size of each chunk of text. This param is applicable only for \"recursive\" splitMode.\n",
    "- `chunkOverlap`: Length of the overlap between text chunks, by default `0`. This param is applicable only for `recursive` splitMode.\n",
    "- `splitPatterns`: Patterns to split the document.\n",
    "patternsAreRegex. Whether to interpret the split patterns as regular expressions, by default `True`.\n",
    "- `keepSeparators`: Whether to keep the separators in the final result , by default `True`. This param is applicable only for \"recursive\" splitMode.\n",
    "- `explodeSplits`: Whether to explode split chunks to separate rows , by default `False`.\n",
    "- `trimWhitespace`: Whether to trim whitespaces of extracted chunks , by default `True`.\n",
    "- `splitMode`: The split mode to determine how text should be segmented. Default: 'regex'. It should be one of the following values:\n",
    "  - \"char\": Split text based on individual characters.\n",
    "  - \"token\": Split text based on tokens. You should supply tokens from inputCols.\n",
    "  - \"sentence\": Split text based on sentences. You should supply sentences from inputCols.\n",
    "  - \"recursive\": Split text recursively using a specific algorithm.\n",
    "  - \"regex\": Split text based on a regular expression pattern.\n",
    "- `sentenceAwareness`: Whether to split the document by sentence awareness if possible.\n",
    "  - If true, it can stop the split process before maxLength.\n",
    "  - If true, you should supply sentences from inputCols. Default: `False`.\n",
    "  - This param is not applicable only for `regex` and `recursive` splitMode.\n",
    "- `maxLength`: The maximum length allowed for spitting. The mode in which the maximum length is specified:\n",
    "  - \"char\": Maximum length is measured in characters. Default: `512`\n",
    "  - \"token\": Maximum length is measured in tokens. Default: `128`\n",
    "  - \"sentence\": Maximum length is measured in sentences. Default: `8`\n",
    "- `customBoundsStrategy`: The custom bounds strategy for text splitting using regular expressions. This param is applicable only for `regex` splitMode.\n",
    "- `caseSensitive`: Whether to use case sensitive when matching regex, by default `False`. This param is applicable only for `regex` splitMode.\n",
    "-  `metaDataFields`: Metadata fields to add specified data in columns to the metadata of the split documents.         You should set column names to read columns.\n",
    "\n",
    "- `enableSentenceIncrement`: Whether the sentence index should be incremented in the metadata of the annotator.When set to true, the annotator will increment the sentence index in the metadata for each split documents. Default: `False`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ICcnDujCGv5G"
   },
   "source": [
    "## `inputCols` and `outputCol`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 6218,
     "status": "ok",
     "timestamp": 1759303440012,
     "user": {
      "displayName": "Mehmet DaÄŸ",
      "userId": "14052875917891496135"
     },
     "user_tz": -180
    },
    "id": "5_ATrtfxfh6G"
   },
   "outputs": [],
   "source": [
    "text = \"\"\"(Medical Transcription Sample Report)\n",
    "\n",
    "PRESENT ILLNESS:\n",
    "Patient with hypertension, syncope, and spinal stenosis - for recheck.\n",
    "\n",
    "SUBJECTIVE:\n",
    "The patient is a 78-year-old female who returns for recheck. She has hypertension. She denies difficulty with chest pain, palpations, orthopnea, nocturnal dyspnea, or edema.\n",
    "\n",
    "MEDICAL HISTORY:\n",
    "Reviewed and unchanged from the dictation on 12/03/2003.\n",
    "\n",
    "MEDICATIONS:\n",
    "Atenolol 50 mg daily, Premarin 0.625 mg daily, calcium with vitamin D two to three pills daily, multivitamin daily, aspirin as needed, and TriViFlor 25 mg two pills daily.\n",
    "She also has Elocon cream 0.1% and Synalar cream 0.01% that she uses as needed for rash.\"\"\"\n",
    "\n",
    "textDF = spark.createDataFrame([[text]]).toDF(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19070,
     "status": "ok",
     "timestamp": 1759303459100,
     "user": {
      "displayName": "Mehmet DaÄŸ",
      "userId": "14052875917891496135"
     },
     "user_tz": -180
    },
    "id": "oq5gCIvZIQN3",
    "outputId": "d6fbbad5-c68e-4921-c2d0-c73af9aea11d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|splits                                                                                                                                                                                                                                                                                                                                                                                       |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[{document, 0, 37, (Medical Transcription Sample Report), {sentence -> 0, document -> 0, uuid -> 16d4a73f-b17b-4f30-b5ee-687b136b187f}, []}]                                                                                                                                                                                                                                                 |\n",
      "|[{document, 39, 126, PRESENT ILLNESS:\\nPatient with hypertension, syncope, and spinal stenosis - for recheck., {sentence -> 0, document -> 1, uuid -> 2128930b-6a5f-46a7-80be-f944a7cd4b6d}, []}]                                                                                                                                                                                            |\n",
      "|[{document, 128, 313, SUBJECTIVE:\\nThe patient is a 78-year-old female who returns for recheck. She has hypertension. She denies difficulty with chest pain, palpations, orthopnea, nocturnal dyspnea, or edema., {sentence -> 0, document -> 2, uuid -> fb3d54f2-8086-4b64-93a3-47f65a4972a7}, []}]                                                                                         |\n",
      "|[{document, 315, 388, MEDICAL HISTORY:\\nReviewed and unchanged from the dictation on 12/03/2003., {sentence -> 0, document -> 3, uuid -> a47adccd-cb18-4578-ac1e-ac7959212f03}, []}]                                                                                                                                                                                                         |\n",
      "|[{document, 390, 663, MEDICATIONS:\\nAtenolol 50 mg daily, Premarin 0.625 mg daily, calcium with vitamin D two to three pills daily, multivitamin daily, aspirin as needed, and TriViFlor 25 mg two pills daily.\\nShe also has Elocon cream 0.1% and Synalar cream 0.01% that she uses as needed for rash., {sentence -> 0, document -> 4, uuid -> 26db9269-c31b-42af-9bd9-37d22b7c9ea4}, []}]|\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "document_assembler = DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "document_splitter = InternalDocumentSplitter() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"splits\") \\\n",
    "    .setExplodeSplits(True) \\\n",
    "\n",
    "pipeline = Pipeline().setStages([\n",
    "    document_assembler,\n",
    "     document_splitter\n",
    "])\n",
    "\n",
    "pipeline = pipeline.fit(textDF).transform(textDF).select(\"splits\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jojvfPOEXTb_"
   },
   "source": [
    "## Recursive Mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tsefWmunKBi_"
   },
   "source": [
    "Recursive Mode supports Spark NLP `DocumentCharacterTextSplitter`, which allows users to split large documents into smaller chunks. This splitter accepts a list of separators in sequence and divides subtexts if they exceed the chunk length, while optionally overlapping chunks. Our inspiration came from the `CharacterTextSplitter` and `RecursiveCharacterTextSplitter` implementations within the `LangChain` library. As always, we've ensured that it's optimized, ready for production, and scalable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2383,
     "status": "ok",
     "timestamp": 1759303461488,
     "user": {
      "displayName": "Mehmet DaÄŸ",
      "userId": "14052875917891496135"
     },
     "user_tz": -180
    },
    "id": "LT49IjZA3bgh",
    "outputId": "d5f7ef24-8657-4c63-86c0-a0d2aa25f4f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|splits                                                                                                                                                                                                       |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[{document, 0, 92, The patient is a 28-year-old, who is status post gastric bypass surgery nearly one year ago., {sentence -> 0, document -> 0, uuid -> 20c2c70f-d14c-4c15-96cc-eebc7b9bff84}, []}]          |\n",
      "|[{document, 94, 192, He has lost about 200 pounds and was otherwise doing well until yesterday evening around 7:00-8:00, {sentence -> 0, document -> 1, uuid -> e6df400a-f518-4403-b0d3-eee80f367e9d}, []}]  |\n",
      "|[{document, 193, 291, when he developed nausea and right upper quadrant pain, which apparently wrapped around toward his, {sentence -> 0, document -> 2, uuid -> 8bf91ede-f159-4958-a6f7-4ea0263f7840}, []}] |\n",
      "|[{document, 288, 387, his right side and back. He feels like he was on it but has not done so. He has overall malaise and, {sentence -> 0, document -> 3, uuid -> eabbcfbf-5834-4755-bf33-d9a0e5fd8b94}, []}]|\n",
      "|[{document, 384, 421, and a low-grade temperature of 100.3., {sentence -> 0, document -> 4, uuid -> e51dd5a8-7087-4ffd-9ede-a9c32d9adb65}, []}]                                                              |\n",
      "|[{document, 424, 520, He denies any prior similar or lesser symptoms. His last normal bowel movement was yesterday. He, {sentence -> 0, document -> 5, uuid -> b44be852-b59d-494b-8cae-36a13f5eab91}, []}]   |\n",
      "|[{document, 518, 568, He denies any outright chills or blood per rectum., {sentence -> 0, document -> 6, uuid -> c9bd784f-4bf6-40e6-8614-227f327a85b7}, []}]                                                 |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([[(\n",
    "    \"The patient is a 28-year-old, who is status post gastric bypass surgery\"\n",
    "    \" nearly one year ago. \\nHe has lost about 200 pounds and was otherwise doing well\"\n",
    "    \" until yesterday evening around 7:00-8:00 when he developed nausea and right upper quadrant pain,\"\n",
    "    \" which apparently wrapped around toward his right side and back. He feels like he was on it\"\n",
    "    \" but has not done so. He has overall malaise and a low-grade temperature of 100.3.\"\n",
    "    \" \\n\\nHe denies any prior similar or lesser symptoms. His last normal bowel movement was yesterday.\"\n",
    "    \" He denies any outright chills or blood per rectum.\"\n",
    ")]]).toDF(\"text\")\n",
    "\n",
    "\n",
    "document_assembler = DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "document_splitter = InternalDocumentSplitter()\\\n",
    "    .setInputCols(\"document\")\\\n",
    "    .setOutputCol(\"splits\")\\\n",
    "    .setSplitMode(\"recursive\")\\\n",
    "    .setChunkSize(100)\\\n",
    "    .setChunkOverlap(3)\\\n",
    "    .setExplodeSplits(True)\\\n",
    "    .setPatternsAreRegex(False)\\\n",
    "    .setSplitPatterns([\"\\n\\n\", \"\\n\", \" \"])\\\n",
    "    .setKeepSeparators(False)\\\n",
    "    .setTrimWhitespace(True)\n",
    "\n",
    "pipeline = Pipeline().setStages([\n",
    "    document_assembler,\n",
    "    document_splitter\n",
    "])\n",
    "\n",
    "pipeline_df = pipeline.fit(df).transform(df).select(\"splits\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ca0u7Q8C5_Uu"
   },
   "source": [
    "## Regex Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 61,
     "status": "ok",
     "timestamp": 1759303461562,
     "user": {
      "displayName": "Mehmet DaÄŸ",
      "userId": "14052875917891496135"
     },
     "user_tz": -180
    },
    "id": "kuY-AfqSLIlv"
   },
   "outputs": [],
   "source": [
    "data = \"\"\"\n",
    "Beyond OpenAI in Commercial LLM Landscape\n",
    "Exploring the Innovators and Challengers in the Commercial LLM Landscape beyond OpenAI: Anthropic, Cohere, Mosaic ML, Cerebras, Aleph Alpha, AI21 Labs and John Snow Labs.\n",
    "Veysel Kocaman\n",
    "John Snow Labs\n",
    "Veysel Kocaman\n",
    "\n",
    "This blog post explores the emerging players in the commercial large language model (LLM) landscape, namely Anthropic, Cohere, Mosaic ML, Cerebras, Aleph Alpha, AI21 Labs and John Snow Labs. While OpenAI is well-known, these companies bring fresh ideas and tools to the LLM world. We discuss their unique offerings, compliance with the EU AI Act, pricing, and performance on various tasks.\n",
    "\n",
    "In the burgeoning world of artificial intelligence, large language models (LLMs) are the new vanguard, shaping how we interact with machines and expanding the boundaries of what technology can achieve. As the field evolves, a dynamic set of companies have emerged, each contributing unique perspectives and solutions to the landscape. They range from established tech giants flexing their AI muscles, to innovative start-ups pushing the boundaries of whatâ€™s possible.\n",
    "\n",
    "This landscape is a vibrant blend of commercial entities and open-source advocates, with a wealth of diversity in their origin stories, funding, and the models they have developed. From licensed models delivered via APIs to open-source alternatives available for local deployment, the offerings span a broad spectrum, meeting the varied needs of developers, businesses, and researchers worldwide.\n",
    "\n",
    "In this blog post, we will dive into the fascinating ecosystem of LLM companies. Weâ€™ll start with an overview, presenting a snapshot of the current landscape. Weâ€™ll then delve into more detailed profiles of each major player, exploring their unique contributions, the models theyâ€™ve brought to life, and the strategic decisions that have shaped their paths. So, whether youâ€™re an AI enthusiast, a developer navigating the LLM waters, or just a curious mind, join us as we journey through the bustling landscape of LLM companies.\n",
    "\n",
    "The landscape of large language models (LLMs) companies\n",
    "The landscape of large language models (LLMs) companies is diverse, featuring both well-established organizations and dynamic newcomers. Dominating the industry are leading LLM companies, such as OpenAI, which was founded in 2015 and has accumulated $11.3 billion in funding by June 2023. Known for their GPT-3.5 and GPT-4 (ChatGPT) models, OpenAI provides access to these tools through a licensed API.\n",
    "\"\"\"\n",
    "mediumDF = spark.createDataFrame([[data]]).toDF(\"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PIa5pmNDhCQ6"
   },
   "source": [
    "**default regex**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2052,
     "status": "ok",
     "timestamp": 1759303463621,
     "user": {
      "displayName": "Mehmet DaÄŸ",
      "userId": "14052875917891496135"
     },
     "user_tz": -180
    },
    "id": "zPI-Ooe93ASB",
    "outputId": "ed2dfd29-eede-41b2-c512-241a72bafc6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|splits                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[{document, 1, 258, Beyond OpenAI in Commercial LLM Landscape\\nExploring the Innovators and Challengers in the Commercial LLM Landscape beyond OpenAI: Anthropic, Cohere, Mosaic ML, Cerebras, Aleph Alpha, AI21 Labs and John Snow Labs.\\nVeysel Kocaman\\nJohn Snow Labs\\nVeysel Kocaman, {sentence -> 0, document -> 0, uuid -> 50d3444c-71cb-4df7-9c19-5a791cc8c9e1}, []}]                                                                                                                                                                                                                                                                               |\n",
      "|[{document, 260, 649, This blog post explores the emerging players in the commercial large language model (LLM) landscape, namely Anthropic, Cohere, Mosaic ML, Cerebras, Aleph Alpha, AI21 Labs and John Snow Labs. While OpenAI is well-known, these companies bring fresh ideas and tools to the LLM world. We discuss their unique offerings, compliance with the EU AI Act, pricing, and performance on various tasks., {sentence -> 0, document -> 1, uuid -> a3b0a9e3-d5a3-47b2-ba41-cb7c119d3a21}, []}]                                                                                                                                             |\n",
      "|[{document, 651, 1118, In the burgeoning world of artificial intelligence, large language models (LLMs) are the new vanguard, shaping how we interact with machines and expanding the boundaries of what technology can achieve. As the field evolves, a dynamic set of companies have emerged, each contributing unique perspectives and solutions to the landscape. They range from established tech giants flexing their AI muscles, to innovative start-ups pushing the boundaries of whatâ€™s possible., {sentence -> 0, document -> 2, uuid -> 1fba875a-6dc4-458b-9a07-26471177f94f}, []}]                                                              |\n",
      "|[{document, 1120, 1516, This landscape is a vibrant blend of commercial entities and open-source advocates, with a wealth of diversity in their origin stories, funding, and the models they have developed. From licensed models delivered via APIs to open-source alternatives available for local deployment, the offerings span a broad spectrum, meeting the varied needs of developers, businesses, and researchers worldwide., {sentence -> 0, document -> 3, uuid -> fc866e62-7502-4a21-98eb-764eec974288}, []}]                                                                                                                                    |\n",
      "|[{document, 1518, 2046, In this blog post, we will dive into the fascinating ecosystem of LLM companies. Weâ€™ll start with an overview, presenting a snapshot of the current landscape. Weâ€™ll then delve into more detailed profiles of each major player, exploring their unique contributions, the models theyâ€™ve brought to life, and the strategic decisions that have shaped their paths. So, whether youâ€™re an AI enthusiast, a developer navigating the LLM waters, or just a curious mind, join us as we journey through the bustling landscape of LLM companies., {sentence -> 0, document -> 4, uuid -> 7fa4ab3a-dcd2-4d45-80bd-6f13bcb738cf}, []}]|\n",
      "|[{document, 2048, 2506, The landscape of large language models (LLMs) companies\\nThe landscape of large language models (LLMs) companies is diverse, featuring both well-established organizations and dynamic newcomers. Dominating the industry are leading LLM companies, such as OpenAI, which was founded in 2015 and has accumulated $11.3 billion in funding by June 2023. Known for their GPT-3.5 and GPT-4 (ChatGPT) models, OpenAI provides access to these tools through a licensed API., {sentence -> 0, document -> 5, uuid -> e9fc6b1b-ca14-41b9-a153-463fdd809757}, []}]                                                                     |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "document_assembler = DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "document_splitter = InternalDocumentSplitter()\\\n",
    "    .setInputCols(\"document\")\\\n",
    "    .setOutputCol(\"splits\")\\\n",
    "    .setSplitMode(\"regex\")\\\n",
    "    .setExplodeSplits(True)\n",
    "\n",
    "pipeline = Pipeline().setStages([\n",
    "    document_assembler,\n",
    "    document_splitter\n",
    "])\n",
    "\n",
    "pipeline_df = pipeline.fit(mediumDF).transform(mediumDF).select(\"splits\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LpXx5yQBhH2i"
   },
   "source": [
    "**Custom Regex Split Patterns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2276,
     "status": "ok",
     "timestamp": 1759303465909,
     "user": {
      "displayName": "Mehmet DaÄŸ",
      "userId": "14052875917891496135"
     },
     "user_tz": -180
    },
    "id": "tXA89DbXcQFI",
    "outputId": "d4460f59-4627-4506-fdda-a972789c5df2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|splits                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[{document, 1, 42, Beyond OpenAI in Commercial LLM Landscape, {sentence -> 0, document -> 0, uuid -> 82e449f6-1bd5-4672-aca5-98e32f849483}, []}]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
      "|[{document, 43, 213, Exploring the Innovators and Challengers in the Commercial LLM Landscape beyond OpenAI: Anthropic, Cohere, Mosaic ML, Cerebras, Aleph Alpha, AI21 Labs and John Snow Labs., {sentence -> 0, document -> 1, uuid -> 26cc784e-1a48-4dc1-a7fc-1dc7ee2831f0}, []}]                                                                                                                                                                                                                                                                                                                                                                         |\n",
      "|[{document, 214, 228, Veysel Kocaman, {sentence -> 0, document -> 2, uuid -> 4a94be57-eb4e-4ac0-b729-41f39cb7a678}, []}]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n",
      "|[{document, 229, 243, John Snow Labs, {sentence -> 0, document -> 3, uuid -> 49db41c1-bab6-450c-a0c1-765a873ab48b}, []}]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n",
      "|[{document, 244, 258, Veysel Kocaman, {sentence -> 0, document -> 4, uuid -> 80d68a75-56d3-4bd5-9d3f-9d55eb268b47}, []}]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n",
      "|[{document, 260, 649, This blog post explores the emerging players in the commercial large language model (LLM) landscape, namely Anthropic, Cohere, Mosaic ML, Cerebras, Aleph Alpha, AI21 Labs and John Snow Labs. While OpenAI is well-known, these companies bring fresh ideas and tools to the LLM world. We discuss their unique offerings, compliance with the EU AI Act, pricing, and performance on various tasks., {sentence -> 0, document -> 5, uuid -> 077dfea2-1870-4ec7-8e12-4ead49ebb7d6}, []}]                                                                                                                                             |\n",
      "|[{document, 651, 1118, In the burgeoning world of artificial intelligence, large language models (LLMs) are the new vanguard, shaping how we interact with machines and expanding the boundaries of what technology can achieve. As the field evolves, a dynamic set of companies have emerged, each contributing unique perspectives and solutions to the landscape. They range from established tech giants flexing their AI muscles, to innovative start-ups pushing the boundaries of whatâ€™s possible., {sentence -> 0, document -> 6, uuid -> b1e71a4c-b67b-4866-bdad-2670efaee351}, []}]                                                              |\n",
      "|[{document, 1120, 1516, This landscape is a vibrant blend of commercial entities and open-source advocates, with a wealth of diversity in their origin stories, funding, and the models they have developed. From licensed models delivered via APIs to open-source alternatives available for local deployment, the offerings span a broad spectrum, meeting the varied needs of developers, businesses, and researchers worldwide., {sentence -> 0, document -> 7, uuid -> de6e3784-0d7e-447e-9de1-42eb282ddbd8}, []}]                                                                                                                                    |\n",
      "|[{document, 1518, 2046, In this blog post, we will dive into the fascinating ecosystem of LLM companies. Weâ€™ll start with an overview, presenting a snapshot of the current landscape. Weâ€™ll then delve into more detailed profiles of each major player, exploring their unique contributions, the models theyâ€™ve brought to life, and the strategic decisions that have shaped their paths. So, whether youâ€™re an AI enthusiast, a developer navigating the LLM waters, or just a curious mind, join us as we journey through the bustling landscape of LLM companies., {sentence -> 0, document -> 8, uuid -> 00ac7841-f38c-47af-89cf-05f2c9fdfa2f}, []}]|\n",
      "|[{document, 2048, 2103, The landscape of large language models (LLMs) companies, {sentence -> 0, document -> 9, uuid -> 20aafcf2-e746-4a93-a9bd-045cdd432ed9}, []}]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
      "|[{document, 2104, 2506, The landscape of large language models (LLMs) companies is diverse, featuring both well-established organizations and dynamic newcomers. Dominating the industry are leading LLM companies, such as OpenAI, which was founded in 2015 and has accumulated $11.3 billion in funding by June 2023. Known for their GPT-3.5 and GPT-4 (ChatGPT) models, OpenAI provides access to these tools through a licensed API., {sentence -> 0, document -> 10, uuid -> 62f27e2b-c709-4e49-a82b-557e865d60a4}, []}]                                                                                                                             |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# with SplitPatterns\n",
    "document_splitter = InternalDocumentSplitter()\\\n",
    "    .setInputCols(\"document\")\\\n",
    "    .setOutputCol(\"splits\")\\\n",
    "    .setSplitMode(\"regex\")\\\n",
    "    .setSplitPatterns([\"\\n\\n\",\"\\n\"])\\\n",
    "    .setExplodeSplits(True)\n",
    "\n",
    "pipeline = Pipeline().setStages([\n",
    "    document_assembler,\n",
    "    document_splitter\n",
    "])\n",
    "\n",
    "pipeline_df = pipeline.fit(mediumDF).transform(mediumDF).select(\"splits\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h89kVHo5Naa8"
   },
   "source": [
    "**Custom Phrase/Words Split Patterns**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1759303465945,
     "user": {
      "displayName": "Mehmet DaÄŸ",
      "userId": "14052875917891496135"
     },
     "user_tz": -180
    },
    "id": "Hhb56QpcoQmS"
   },
   "outputs": [],
   "source": [
    "text = \"\"\"(Medical Transcription Sample Report)\n",
    "\n",
    "PRESENT ILLNESS:\n",
    "Patient with hypertension, syncope, and spinal stenosis - for recheck.\n",
    "\n",
    "SUBJECTIVE:\n",
    "The patient is a 78-year-old female who returns for recheck. She has hypertension. She denies difficulty with chest pain, palpations, orthopnea, nocturnal dyspnea, or edema.\n",
    "\n",
    "MEDICAL HISTORY:\n",
    "Reviewed and unchanged from the dictation on 12/03/2003.\n",
    "\n",
    "MEDICATIONS:\n",
    "Atenolol 50 mg daily, Premarin 0.625 mg daily, calcium with vitamin D two to three pills daily, multivitamin daily, aspirin as needed, and TriViFlor 25 mg two pills daily.\n",
    "She also has Elocon cream 0.1% and Synalar cream 0.01% that she uses as needed for rash.\"\"\"\n",
    "\n",
    "textDF = spark.createDataFrame([[text]]).toDF(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2000,
     "status": "ok",
     "timestamp": 1759303467981,
     "user": {
      "displayName": "Mehmet DaÄŸ",
      "userId": "14052875917891496135"
     },
     "user_tz": -180
    },
    "id": "2YuUNXBCNg7S",
    "outputId": "398b0d60-ff4f-4bfd-e251-ae365423e20d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|splits                                                                                                                                                                                                                                                                                                                                                                                       |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[{document, 0, 37, (Medical Transcription Sample Report), {sentence -> 0, document -> 0, uuid -> 6ac279d6-4a04-4fc8-bca6-5a913ae52d19}, []}]                                                                                                                                                                                                                                                 |\n",
      "|[{document, 39, 126, PRESENT ILLNESS:\\nPatient with hypertension, syncope, and spinal stenosis - for recheck., {sentence -> 0, document -> 1, uuid -> a6d8769f-4355-4732-af29-f40880244a49}, []}]                                                                                                                                                                                            |\n",
      "|[{document, 128, 313, SUBJECTIVE:\\nThe patient is a 78-year-old female who returns for recheck. She has hypertension. She denies difficulty with chest pain, palpations, orthopnea, nocturnal dyspnea, or edema., {sentence -> 0, document -> 2, uuid -> 205ae3a9-746e-4314-a09f-320baebb8fc0}, []}]                                                                                         |\n",
      "|[{document, 315, 388, MEDICAL HISTORY:\\nReviewed and unchanged from the dictation on 12/03/2003., {sentence -> 0, document -> 3, uuid -> c63a0ed0-d045-4278-938d-fd8c4e535a92}, []}]                                                                                                                                                                                                         |\n",
      "|[{document, 390, 663, MEDICATIONS:\\nAtenolol 50 mg daily, Premarin 0.625 mg daily, calcium with vitamin D two to three pills daily, multivitamin daily, aspirin as needed, and TriViFlor 25 mg two pills daily.\\nShe also has Elocon cream 0.1% and Synalar cream 0.01% that she uses as needed for rash., {sentence -> 0, document -> 4, uuid -> 4e1d97f0-ea6a-4145-b34c-d57fcd7188fe}, []}]|\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "document_splitter = InternalDocumentSplitter()\\\n",
    "    .setInputCols(\"document\")\\\n",
    "    .setOutputCol(\"splits\")\\\n",
    "    .setSplitMode(\"regex\")\\\n",
    "    .setSplitPatterns([\"PRESENT ILLNESS:\", \"SUBJECTIVE:\", \"MEDICAL HISTORY:\", \"MEDICATIONS:\"])\\\n",
    "    .setCaseSensitive(True) \\\n",
    "    .setExplodeSplits(True)\n",
    "\n",
    "pipeline = Pipeline().setStages([\n",
    "    document_assembler,\n",
    "    document_splitter\n",
    "])\n",
    "\n",
    "pipeline_df = pipeline.fit(textDF).transform(textDF).select(\"splits\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9YljH2SYONQQ"
   },
   "source": [
    "**setCustomBoundsStrategy** can be `none`, `prepend`, `append`. Default is \"none\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2847,
     "status": "ok",
     "timestamp": 1759303470834,
     "user": {
      "displayName": "Mehmet DaÄŸ",
      "userId": "14052875917891496135"
     },
     "user_tz": -180
    },
    "id": "HZUKbMkGOKP5",
    "outputId": "f1e234e0-5733-42dd-c792-c1e4bffa8b75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|splits                                                                                                                                                                                                                                                                                                                                                                                       |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[{document, 0, 37, (Medical Transcription Sample Report), {sentence -> 0, document -> 0, uuid -> a4e66dfd-0a40-4647-9a18-6b96e5135c0c}, []}]                                                                                                                                                                                                                                                 |\n",
      "|[{document, 39, 126, PRESENT ILLNESS:\\nPatient with hypertension, syncope, and spinal stenosis - for recheck., {sentence -> 0, document -> 1, uuid -> 0f6c5235-b43f-4e9e-a305-985229f5e4c1}, []}]                                                                                                                                                                                            |\n",
      "|[{document, 128, 313, SUBJECTIVE:\\nThe patient is a 78-year-old female who returns for recheck. She has hypertension. She denies difficulty with chest pain, palpations, orthopnea, nocturnal dyspnea, or edema., {sentence -> 0, document -> 2, uuid -> 6df546c6-1aef-40f8-a4b4-44f1f8b57386}, []}]                                                                                         |\n",
      "|[{document, 315, 388, MEDICAL HISTORY:\\nReviewed and unchanged from the dictation on 12/03/2003., {sentence -> 0, document -> 3, uuid -> 9da7840a-6171-4bf4-81dc-181cb3088fbf}, []}]                                                                                                                                                                                                         |\n",
      "|[{document, 390, 663, MEDICATIONS:\\nAtenolol 50 mg daily, Premarin 0.625 mg daily, calcium with vitamin D two to three pills daily, multivitamin daily, aspirin as needed, and TriViFlor 25 mg two pills daily.\\nShe also has Elocon cream 0.1% and Synalar cream 0.01% that she uses as needed for rash., {sentence -> 0, document -> 4, uuid -> f73f71a2-f602-4e77-b257-704062f89476}, []}]|\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "document_splitter = InternalDocumentSplitter()\\\n",
    "    .setInputCols(\"document\")\\\n",
    "    .setOutputCol(\"splits\")\\\n",
    "    .setSplitMode(\"regex\")\\\n",
    "    .setSplitPatterns([\"PRESENT ILLNESS:\", \"SUBJECTIVE:\", \"MEDICAL HISTORY:\", \"MEDICATIONS:\"])\\\n",
    "    .setCaseSensitive(True) \\\n",
    "    .setCustomBoundsStrategy(\"prepend\")\\\n",
    "    .setExplodeSplits(True) \\\n",
    "\n",
    "pipeline = Pipeline().setStages([\n",
    "    document_assembler,\n",
    "    document_splitter\n",
    "])\n",
    "\n",
    "pipeline_df = pipeline.fit(textDF).transform(textDF).select(\"splits\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TI8fs_FzPjHf"
   },
   "source": [
    "**setCaseSensitive**  True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2289,
     "status": "ok",
     "timestamp": 1759303473127,
     "user": {
      "displayName": "Mehmet DaÄŸ",
      "userId": "14052875917891496135"
     },
     "user_tz": -180
    },
    "id": "mWRcg0vKPnyg",
    "outputId": "d5c0d5ec-57c9-4e4f-d6ab-558864174acf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|splits                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[{document, 0, 663, (Medical Transcription Sample Report)\\n\\nPRESENT ILLNESS:\\nPatient with hypertension, syncope, and spinal stenosis - for recheck.\\n\\nSUBJECTIVE:\\nThe patient is a 78-year-old female who returns for recheck. She has hypertension. She denies difficulty with chest pain, palpations, orthopnea, nocturnal dyspnea, or edema.\\n\\nMEDICAL HISTORY:\\nReviewed and unchanged from the dictation on 12/03/2003.\\n\\nMEDICATIONS:\\nAtenolol 50 mg daily, Premarin 0.625 mg daily, calcium with vitamin D two to three pills daily, multivitamin daily, aspirin as needed, and TriViFlor 25 mg two pills daily.\\nShe also has Elocon cream 0.1% and Synalar cream 0.01% that she uses as needed for rash., {sentence -> 0, document -> 0, uuid -> fc77aba7-e782-40c4-940a-1619eb067e64}, []}]|\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# [\"firstly,\", \"secondly,\", \"thirdly,\", \"in conclusion,\"]\n",
    "document_splitter = InternalDocumentSplitter()\\\n",
    "    .setInputCols(\"document\")\\\n",
    "    .setOutputCol(\"splits\")\\\n",
    "    .setSplitMode(\"regex\")\\\n",
    "    .setSplitPatterns([\"present illness:\", \"subjective:\", \"medical history:\", \"medications:\"])\\\n",
    "    .setCaseSensitive(True) \\\n",
    "    .setCustomBoundsStrategy(\"prepend\")\\\n",
    "    .setExplodeSplits(True) \\\n",
    "\n",
    "pipeline = Pipeline().setStages([\n",
    "    document_assembler,\n",
    "    document_splitter\n",
    "])\n",
    "\n",
    "pipeline_df = pipeline.fit(textDF).transform(textDF).select(\"splits\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kNTsvfUrQM3U"
   },
   "source": [
    "**setCaseSensitive** False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1701,
     "status": "ok",
     "timestamp": 1759303474831,
     "user": {
      "displayName": "Mehmet DaÄŸ",
      "userId": "14052875917891496135"
     },
     "user_tz": -180
    },
    "id": "hbyELo9SQLa6",
    "outputId": "4f9594fc-72cb-4132-d9bf-7e39e6c0ac7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|splits                                                                                                                                                                                                                                                                                                                                                                                       |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[{document, 0, 37, (Medical Transcription Sample Report), {sentence -> 0, document -> 0, uuid -> cbafd4f9-4119-4eee-9e2f-dfadb65e8f48}, []}]                                                                                                                                                                                                                                                 |\n",
      "|[{document, 39, 126, PRESENT ILLNESS:\\nPatient with hypertension, syncope, and spinal stenosis - for recheck., {sentence -> 0, document -> 1, uuid -> 16759139-e26d-44a8-b9c0-000140f81b6e}, []}]                                                                                                                                                                                            |\n",
      "|[{document, 128, 313, SUBJECTIVE:\\nThe patient is a 78-year-old female who returns for recheck. She has hypertension. She denies difficulty with chest pain, palpations, orthopnea, nocturnal dyspnea, or edema., {sentence -> 0, document -> 2, uuid -> f6cce0cc-637b-4e9b-9fe3-47343b4a469c}, []}]                                                                                         |\n",
      "|[{document, 315, 388, MEDICAL HISTORY:\\nReviewed and unchanged from the dictation on 12/03/2003., {sentence -> 0, document -> 3, uuid -> 461404d5-cea0-4c8f-940d-c37979514cd4}, []}]                                                                                                                                                                                                         |\n",
      "|[{document, 390, 663, MEDICATIONS:\\nAtenolol 50 mg daily, Premarin 0.625 mg daily, calcium with vitamin D two to three pills daily, multivitamin daily, aspirin as needed, and TriViFlor 25 mg two pills daily.\\nShe also has Elocon cream 0.1% and Synalar cream 0.01% that she uses as needed for rash., {sentence -> 0, document -> 4, uuid -> a7f2da02-30fe-4979-8bdc-b377f2b48fa5}, []}]|\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# [\"firstly,\", \"secondly,\", \"thirdly,\", \"in conclusion,\"]\n",
    "document_splitter = InternalDocumentSplitter()\\\n",
    "    .setInputCols(\"document\")\\\n",
    "    .setOutputCol(\"splits\")\\\n",
    "    .setSplitMode(\"regex\")\\\n",
    "    .setSplitPatterns([\"present illness:\", \"subjective:\", \"medical history:\", \"medications:\"])\\\n",
    "    .setCaseSensitive(False) \\\n",
    "    .setCustomBoundsStrategy(\"prepend\")\\\n",
    "    .setExplodeSplits(True) \\\n",
    "\n",
    "pipeline = Pipeline().setStages([\n",
    "    document_assembler,\n",
    "    document_splitter\n",
    "])\n",
    "\n",
    "pipeline_df = pipeline.fit(textDF).transform(textDF).select(\"splits\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3xzKHpM06EWJ"
   },
   "source": [
    "## Char Mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 50,
     "status": "ok",
     "timestamp": 1759303474891,
     "user": {
      "displayName": "Mehmet DaÄŸ",
      "userId": "14052875917891496135"
     },
     "user_tz": -180
    },
    "id": "J5alxo_i0Z2S"
   },
   "outputs": [],
   "source": [
    "ai = \"\"\"AI advancements impact fields, improving data analysis. Ethical concerns, like privacy and bias, shape academic discussions.\n",
    "Scholars explore AI's responsible development. Ongoing research navigates evolving challenges.\"\"\"\n",
    "\n",
    "df = spark.createDataFrame([[ai]]).toDF(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1563,
     "status": "ok",
     "timestamp": 1759303476458,
     "user": {
      "displayName": "Mehmet DaÄŸ",
      "userId": "14052875917891496135"
     },
     "user_tz": -180
    },
    "id": "mvvEpOuyZXmx",
    "outputId": "b8ff2e8f-b3c8-4dc0-b1c9-827f304b03cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|splits                                                                                                                                                                                                                                   |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[{document, 0, 128, AI advancements impact fields, improving data analysis. Ethical concerns, like privacy and bias, shape academic discussions.\\nSch, {sentence -> 0, document -> 0, uuid -> 08254914-e950-44ed-8a8e-55a72d3a16b5}, []}]|\n",
      "|[{document, 128, 219, olars explore AI's responsible development. Ongoing research navigates evolving challenges., {sentence -> 0, document -> 1, uuid -> 755c4947-eeb1-4b74-a991-b0e692e75a0b}, []}]                                    |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "document_assembler = DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "document_splitter = InternalDocumentSplitter()\\\n",
    "    .setInputCols(\"document\")\\\n",
    "    .setOutputCol(\"splits\")\\\n",
    "    .setSplitMode(\"char\")\\\n",
    "    .setMaxLength(128)\\\n",
    "    .setExplodeSplits(True)\n",
    "\n",
    "pipeline = Pipeline().setStages([\n",
    "    document_assembler,\n",
    "    document_splitter\n",
    "])\n",
    "\n",
    "pipeline_df = pipeline.fit(df).transform(df).select(\"splits\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XLNtPoybZQ9T"
   },
   "source": [
    "**sentenceAwareness**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2014,
     "status": "ok",
     "timestamp": 1759303478476,
     "user": {
      "displayName": "Mehmet DaÄŸ",
      "userId": "14052875917891496135"
     },
     "user_tz": -180
    },
    "id": "0PIKcUrF3Cp6",
    "outputId": "d2385c47-b665-4c81-c815-eef692f360da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|splits                                                                                                                                                                                                                              |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[{document, 0, 124, AI advancements impact fields, improving data analysis. Ethical concerns, like privacy and bias, shape academic discussions., {sentence -> 0, document -> 0, uuid -> fc8a44bc-77ac-4d17-8701-2f315deb39b5}, []}]|\n",
      "|[{document, 125, 219, Scholars explore AI's responsible development. Ongoing research navigates evolving challenges., {sentence -> 0, document -> 1, uuid -> 27ab4cba-975c-48f0-9526-611c8798e338}, []}]                            |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "document_assembler = DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "sentence_detector = SentenceDetector()\\\n",
    "    .setInputCols(\"document\")\\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "document_splitter = InternalDocumentSplitter()\\\n",
    "    .setInputCols(\"document\", \"sentence\")\\\n",
    "    .setOutputCol(\"splits\")\\\n",
    "    .setSplitMode(\"char\")\\\n",
    "    .setMaxLength(128)\\\n",
    "    .setSentenceAwareness(True)\\\n",
    "    .setExplodeSplits(True)\n",
    "\n",
    "pipeline = Pipeline().setStages([\n",
    "    document_assembler,\n",
    "    sentence_detector,\n",
    "    document_splitter\n",
    "])\n",
    "\n",
    "pipeline_df = pipeline.fit(df).transform(df).select(\"splits\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VpHpGwbd6Iig"
   },
   "source": [
    "##  Token Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1902,
     "status": "ok",
     "timestamp": 1759303480383,
     "user": {
      "displayName": "Mehmet DaÄŸ",
      "userId": "14052875917891496135"
     },
     "user_tz": -180
    },
    "id": "CoFfv7933DU9",
    "outputId": "23e74d57-a607-40d5-f4da-81119eafd1fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|splits                                                                                                                                                                            |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[{document, 0, 73, AI advancements impact fields, improving data analysis. Ethical concerns,, {sentence -> 0, document -> 0, uuid -> 99551266-dca3-43ce-bc28-53d30c47a25b}, []}]  |\n",
      "|[{document, 74, 146, like privacy and bias, shape academic discussions.\\nScholars explore AI's, {sentence -> 0, document -> 1, uuid -> 13915d22-cd53-4dec-acb0-9166ed48d8e6}, []}]|\n",
      "|[{document, 147, 219, responsible development. Ongoing research navigates evolving challenges., {sentence -> 0, document -> 2, uuid -> a8b775d4-4311-4fea-963e-b2cd603cb909}, []}]|\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "document_assembler = DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "tokenizer = Tokenizer()\\\n",
    "    .setInputCols(\"document\")\\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "document_splitter = InternalDocumentSplitter()\\\n",
    "    .setInputCols(\"document\", \"token\")\\\n",
    "    .setOutputCol(\"splits\")\\\n",
    "    .setSplitMode(\"token\")\\\n",
    "    .setMaxLength(12)\\\n",
    "    .setExplodeSplits(True)\n",
    "\n",
    "pipeline = Pipeline().setStages([\n",
    "    document_assembler,\n",
    "    tokenizer,\n",
    "    document_splitter\n",
    "])\n",
    "\n",
    "pipeline_df = pipeline.fit(df).transform(df).select(\"splits\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ShTuq2pnaLiz"
   },
   "source": [
    "**sentenceAwareness**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3157,
     "status": "ok",
     "timestamp": 1759303483563,
     "user": {
      "displayName": "Mehmet DaÄŸ",
      "userId": "14052875917891496135"
     },
     "user_tz": -180
    },
    "id": "vVTTZTEVaHod",
    "outputId": "98c47cd6-1964-4832-da24-89a1074abc78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|splits                                                                                                                                                                                                  |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[{document, 0, 55, AI advancements impact fields, improving data analysis., {sentence -> 0, document -> 0, uuid -> c963ef8e-0716-466a-8854-e0371116bb67}, []}]                                          |\n",
      "|[{document, 56, 124, Ethical concerns, like privacy and bias, shape academic discussions., {sentence -> 0, document -> 1, uuid -> 8a9e84f6-50c9-433e-ac20-01694761e49a}, []}]                           |\n",
      "|[{document, 125, 219, Scholars explore AI's responsible development. Ongoing research navigates evolving challenges., {sentence -> 0, document -> 2, uuid -> 6a860402-ad4e-4387-aded-ed6adf92c170}, []}]|\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "document_assembler = DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "sentence_detector = SentenceDetector()\\\n",
    "    .setInputCols(\"document\")\\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "tokenizer = Tokenizer()\\\n",
    "    .setInputCols(\"document\")\\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "document_splitter = InternalDocumentSplitter()\\\n",
    "    .setInputCols(\"document\", \"sentence\", \"token\")\\\n",
    "    .setOutputCol(\"splits\")\\\n",
    "    .setSplitMode(\"token\")\\\n",
    "    .setSentenceAwareness(True)\\\n",
    "    .setMaxLength(12)\\\n",
    "    .setExplodeSplits(True)\n",
    "\n",
    "pipeline = Pipeline().setStages([\n",
    "    document_assembler,\n",
    "    sentence_detector,\n",
    "    tokenizer,\n",
    "    document_splitter\n",
    "])\n",
    "\n",
    "\n",
    "pipeline_df = pipeline.fit(df).transform(df).select(\"splits\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZjcHqTKR6LIL"
   },
   "source": [
    "##  Sentence Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17747,
     "status": "ok",
     "timestamp": 1759303501327,
     "user": {
      "displayName": "Mehmet DaÄŸ",
      "userId": "14052875917891496135"
     },
     "user_tz": -180
    },
    "id": "eL99-abG6P4t",
    "outputId": "cafaf3ab-344a-4510-b27d-5f68f1700bb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence_detector_dl_healthcare download started this may take some time.\n",
      "Approximate size to download 367.3 KB\n",
      "[OK!]\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|splits                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[{document, 1, 243, Beyond OpenAI in Commercial LLM Landscape\\nExploring the Innovators and Challengers in the Commercial LLM Landscape beyond OpenAI: Anthropic, Cohere, Mosaic ML, Cerebras, Aleph Alpha, AI21 Labs and John Snow Labs.\\nVeysel Kocaman\\nJohn Snow Labs, {sentence -> 0, document -> 0, uuid -> 572c9841-53a7-404a-98a4-9c1c7e377d23}, []}]                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
      "|[{document, 244, 649, Veysel Kocaman\\n\\nThis blog post explores the emerging players in the commercial large language model (LLM) landscape, namely Anthropic, Cohere, Mosaic ML, Cerebras, Aleph Alpha, AI21 Labs and John Snow Labs. While OpenAI is well-known, these companies bring fresh ideas and tools to the LLM world. We discuss their unique offerings, compliance with the EU AI Act, pricing, and performance on various tasks., {sentence -> 0, document -> 1, uuid -> 57c57243-cf4c-441c-89ea-0d9459df62bd}, []}]                                                                                                                                                                                                                                                     |\n",
      "|[{document, 651, 1300, In the burgeoning world of artificial intelligence, large language models (LLMs) are the new vanguard, shaping how we interact with machines and expanding the boundaries of what technology can achieve. As the field evolves, a dynamic set of companies have emerged, each contributing unique perspectives and solutions to the landscape. They range from established tech giants flexing their AI muscles, to innovative start-ups pushing the boundaries of whatâ€™s possible.\\n\\nThis landscape is a vibrant blend of commercial entities and open-source advocates, with a wealth of diversity in their origin stories, funding, and the models they have developed., {sentence -> 0, document -> 2, uuid -> b0d9b592-9418-4bfe-b975-09a9c26ab82a}, []}]|\n",
      "|[{document, 1301, 1875, From licensed models delivered via APIs to open-source alternatives available for local deployment, the offerings span a broad spectrum, meeting the varied needs of developers, businesses, and researchers worldwide.\\n\\nIn this blog post, we will dive into the fascinating ecosystem of LLM companies. Weâ€™ll start with an overview, presenting a snapshot of the current landscape. Weâ€™ll then delve into more detailed profiles of each major player, exploring their unique contributions, the models theyâ€™ve brought to life, and the strategic decisions that have shaped their paths., {sentence -> 0, document -> 3, uuid -> 56c0cb73-aa3d-4b77-a840-a3f4466c6654}, []}]                                                                          |\n",
      "|[{document, 1876, 2392, So, whether youâ€™re an AI enthusiast, a developer navigating the LLM waters, or just a curious mind, join us as we journey through the bustling landscape of LLM companies.\\n\\nThe landscape of large language models (LLMs) companies\\nThe landscape of large language models (LLMs) companies is diverse, featuring both well-established organizations and dynamic newcomers. Dominating the industry are leading LLM companies, such as OpenAI, which was founded in 2015 and has accumulated $11.3 billion in funding by June 2023., {sentence -> 0, document -> 4, uuid -> 6012eb41-ff00-4b32-a476-a3f7c5373198}, []}]                                                                                                                                   |\n",
      "|[{document, 2393, 2506, Known for their GPT-3.5 and GPT-4 (ChatGPT) models, OpenAI provides access to these tools through a licensed API., {sentence -> 0, document -> 5, uuid -> e7f49dd9-83f6-4f84-b9cd-bf581ebdf768}, []}]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "document_assembler = DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "sentence_detector_dl = SentenceDetectorDLModel\\\n",
    "    .pretrained(\"sentence_detector_dl_healthcare\", \"en\", \"clinical/models\")\\\n",
    "    .setInputCols(\"document\")\\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "document_splitter = InternalDocumentSplitter() \\\n",
    "    .setInputCols([\"document\", \"sentence\"]) \\\n",
    "    .setOutputCol(\"splits\") \\\n",
    "    .setSplitMode(\"sentence\") \\\n",
    "    .setMaxLength(4)\\\n",
    "    .setExplodeSplits(True)\n",
    "\n",
    "pipeline = Pipeline().setStages([\n",
    "    document_assembler,\n",
    "    sentence_detector_dl,\n",
    "    document_splitter\n",
    "])\n",
    "\n",
    "pipeline_df = pipeline.fit(mediumDF).transform(mediumDF).select(\"splits\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Et2fRhognXbV"
   },
   "source": [
    "## Meta Data Fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wYdkSjdwnd_4"
   },
   "source": [
    "**setMetaDataFields**\n",
    "\n",
    "Metadata fields to add specified data in columns to the metadata of the split documents. You should set column names to read columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 2252,
     "status": "ok",
     "timestamp": 1759303503583,
     "user": {
      "displayName": "Mehmet DaÄŸ",
      "userId": "14052875917891496135"
     },
     "user_tz": -180
    },
    "id": "z325iiHfnrFw"
   },
   "outputs": [],
   "source": [
    "!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/healthcare-nlp/data/mt_data.csv -O ./mt_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1853,
     "status": "ok",
     "timestamp": 1759303505448,
     "user": {
      "displayName": "Mehmet DaÄŸ",
      "userId": "14052875917891496135"
     },
     "user_tz": -180
    },
    "id": "pd9eATHtpzRP",
    "outputId": "4384ffb0-281a-44c3-aa6d-4cba21180688"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+--------------------+\n",
      "|PATIENT_ID|  medical_speciality|           file_name|                text|\n",
      "+----------+--------------------+--------------------+--------------------+\n",
      "|    #45585|             Surgery|     Surgery_363.txt|\\nMedical Special...|\n",
      "|    #59629|             Surgery|     Surgery_333.txt|\\nMedical Special...|\n",
      "|    #72192|Emergency_Room_Re...|Emergency_Room_Re...|\\nMedical Special...|\n",
      "|    #29536|    General_Medicine|General_Medicine_...|\\nMedical Special...|\n",
      "|    #28487|             Surgery|     Surgery_629.txt|\\nMedical Special...|\n",
      "|    #45267|             Surgery|      Surgery_85.txt|\\nMedical Special...|\n",
      "|    #31127|    Gastroenterology|Gastroenterology_...|\\nMedical Special...|\n",
      "|    #72806|    Gastroenterology|Gastroenterology_...|\\nMedical Special...|\n",
      "|    #71981|             Surgery|     Surgery_506.txt|\\nMedical Special...|\n",
      "|    #41186|           Radiology|   Radiology_207.txt|\\nMedical Special...|\n",
      "+----------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mt_data_df = spark.createDataFrame(pd.read_csv(\"mt_data.csv\").sample(10))\n",
    "mt_data_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7498,
     "status": "ok",
     "timestamp": 1759303512952,
     "user": {
      "displayName": "Mehmet DaÄŸ",
      "userId": "14052875917891496135"
     },
     "user_tz": -180
    },
    "id": "4YCRcv1cndsy",
    "outputId": "5c4c8898-20f8-40ca-9cc0-0ed1c6cc06ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence_detector_dl_healthcare download started this may take some time.\n",
      "Approximate size to download 367.3 KB\n",
      "[OK!]\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|splits                                                                                                                                                                                                                                                                                                                                                                                                              |metadata                                                                                                                                                          |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[Medical Specialty:Surgery\\nSample Name:Â Delivery Note\\nDescription:Â Delivery is a normal spontaneous vaginal delivery of an intrauterine fetal demise.]                                                                                                                                                                                                                                                            |[{sentence -> 0, document -> 0, uuid -> 8a09dbea-8bdf-4d67-a933-a746f770df49, PATIENT_ID -> #45585, medical_speciality -> Surgery, file_name -> Surgery_363.txt}] |\n",
      "|[Fetal position is right occiput anterior.\\n(Medical Transcription Sample Report)\\nHISTORY:  This patient with prenatal care in my office who did have some preterm labor and was treated with nifedipine and was stable on nifedipine and bed rest; unfortunately, felt decreased fetal movement yesterday, 12/29/08, presented to the hospital for evaluation on the evening of 12/29/08.]                        |[{sentence -> 0, document -> 1, uuid -> 8bb6fba7-b57b-466c-8f5c-5e32307edba2, PATIENT_ID -> #45585, medical_speciality -> Surgery, file_name -> Surgery_363.txt}] |\n",
      "|[At approximately 2030 hours and on admission, no cardiac activity was noted by my on-call partner, Dr. X. This was confirmed by Dr. Y with ultrasound and the patient was admitted with a diagnosis of intrauterine fetal demise at 36 weeks' gestation.SUMMARY: She was admitted. She was 3 cm dilated on admission.]                                                                                             |[{sentence -> 0, document -> 2, uuid -> 55c52ce4-ca54-46fc-bc29-9478a96f2241, PATIENT_ID -> #45585, medical_speciality -> Surgery, file_name -> Surgery_363.txt}] |\n",
      "|[She desired induction of labor. Therefore, Pitocin was started. Epidural was placed for labor pain.]                                                                                                                                                                                                                                                                                                               |[{sentence -> 0, document -> 3, uuid -> f3843743-df1b-4b76-bba4-63d9a1dfff8a, PATIENT_ID -> #45585, medical_speciality -> Surgery, file_name -> Surgery_363.txt}] |\n",
      "|[She did have a temperature of 100.7 and antibiotics were ordered including gentamicin and clindamycin secondary to penicillin allergy. She remained febrile, approximately 100.3. She then progressed.]                                                                                                                                                                                                            |[{sentence -> 0, document -> 4, uuid -> d0163afc-6c71-4414-994c-710d30b964f5, PATIENT_ID -> #45585, medical_speciality -> Surgery, file_name -> Surgery_363.txt}] |\n",
      "|[On my initial exam at approximately 0730 hours, she was 3 to 4 cm dilated. She had reported previously some mucous discharge with no ruptured membranes. Upon my exam, no membranes were noted.]                                                                                                                                                                                                                   |[{sentence -> 0, document -> 5, uuid -> 53e45d86-02f1-4cd1-aade-7eaeee6bd634, PATIENT_ID -> #45585, medical_speciality -> Surgery, file_name -> Surgery_363.txt}] |\n",
      "|[Attempted artificial rupture of membranes was performed. No fluid noted and there was no fluid discharge noted all the way until the time of delivery. Intrauterine pressure catheter was placed at that time to document there are adequate pressures on contraction secondary to induction of labor.]                                                                                                            |[{sentence -> 0, document -> 6, uuid -> 26ae339c-829e-49c7-989a-427387ceac65, PATIENT_ID -> #45585, medical_speciality -> Surgery, file_name -> Surgery_363.txt}] |\n",
      "|[She progressed well and completely dilated, pushed approximately three times, and proceeded with delivery.DELIVERY NOTE: Delivery is a normal spontaneous vaginal delivery of an intrauterine fetal demise. Fetal position is right occiput anterior.]                                                                                                                                                             |[{sentence -> 0, document -> 7, uuid -> ed9007d0-e3b5-4c89-89a7-31b2664e7ce2, PATIENT_ID -> #45585, medical_speciality -> Surgery, file_name -> Surgery_363.txt}] |\n",
      "|[COMPLICATIONS:  Again, intrauterine fetal demise. Placenta delivery spontaneous. Condition was intact with a three-vessel cord.]                                                                                                                                                                                                                                                                                   |[{sentence -> 0, document -> 8, uuid -> cc4ee6d4-8a5f-4165-896e-58739197d9ed, PATIENT_ID -> #45585, medical_speciality -> Surgery, file_name -> Surgery_363.txt}] |\n",
      "|[Lacerations; she had a small right periurethral laceration as well as a small second-degree midline laceration. These were both repaired postdelivery with 4-0 Vicryl on an SH and a 3-0 Vicryl on a CT-1 respectively. Estimated blood loss was 200 mL.]                                                                                                                                                          |[{sentence -> 0, document -> 9, uuid -> 80e27682-9279-4a0b-aae6-b8051a78f9b9, PATIENT_ID -> #45585, medical_speciality -> Surgery, file_name -> Surgery_363.txt}] |\n",
      "|[Infant is a male infant, appears grossly morphologically normal. Apgars were 0 and 0. Weight pending at this time.\\nNARRATIVE OF DELIVERY: I was called.]                                                                                                                                                                                                                                                          |[{sentence -> 0, document -> 10, uuid -> 97a72fe6-2550-4abe-817e-5499c8a500a7, PATIENT_ID -> #45585, medical_speciality -> Surgery, file_name -> Surgery_363.txt}]|\n",
      "|[This patient was completely dilated. I arrived. She pushed for three contractions.]                                                                                                                                                                                                                                                                                                                                |[{sentence -> 0, document -> 11, uuid -> 43f2f52a-8625-478f-9e09-4d8a6e0765cd, PATIENT_ID -> #45585, medical_speciality -> Surgery, file_name -> Surgery_363.txt}]|\n",
      "|[She was very comfortable. She delivered the fetal vertex in the right occiput anterior position followed by the remainder of the infant. There was a tight nuchal cord x1 that was reduced after delivery of the fetus.]                                                                                                                                                                                           |[{sentence -> 0, document -> 12, uuid -> 9e9cb18c-6308-421d-915c-948dfaf54cd1, PATIENT_ID -> #45585, medical_speciality -> Surgery, file_name -> Surgery_363.txt}]|\n",
      "|[Cord was doubly clamped. The infant was transferred to a bassinet cleaned by the nursing staff en route. The placenta delivered spontaneously, was carefully examined, found to be intact.]                                                                                                                                                                                                                        |[{sentence -> 0, document -> 13, uuid -> ed2c5d7e-18e5-41fb-82ea-397520e48017, PATIENT_ID -> #45585, medical_speciality -> Surgery, file_name -> Surgery_363.txt}]|\n",
      "|[No signs of abruption. No signs of abnormal placentation or abnormal cord insertion. The cord was examined and a three-vessel cord was confirmed.]                                                                                                                                                                                                                                                                 |[{sentence -> 0, document -> 14, uuid -> e6033e43-da01-43a6-8b79-82c20f50c3ad, PATIENT_ID -> #45585, medical_speciality -> Surgery, file_name -> Surgery_363.txt}]|\n",
      "|[At this time, IV Pitocin and bimanual massage. Fundus firm as above with minimal postpartum bleeding. The vagina and perineum were carefully inspected.]                                                                                                                                                                                                                                                           |[{sentence -> 0, document -> 15, uuid -> 9e226822-dc29-45d8-8ec5-e08d3800ce1e, PATIENT_ID -> #45585, medical_speciality -> Surgery, file_name -> Surgery_363.txt}]|\n",
      "|[A small right periurethral laceration was noted, was repaired with a 4-0 Vicryl on an SH needle followed by a small second-degree midline laceration, was repaired in a normal running fashion with a 3-0 Vicryl suture. At this time, the repair is intact. She is hemostatic.]                                                                                                                                   |[{sentence -> 0, document -> 16, uuid -> ced6ccac-d52d-4857-8e45-54db0d7b6823, PATIENT_ID -> #45585, medical_speciality -> Surgery, file_name -> Surgery_363.txt}]|\n",
      "|[All instruments and sponges were removed from the vagina and the procedure was ended.Father of the baby has seen the baby at this time and the mother is waiting to hold the baby at this time. We have called pastor in to baptize the baby as well as calling social work.]                                                                                                                                      |[{sentence -> 0, document -> 17, uuid -> 754af603-7a97-4f14-bf33-8362a8b848bd, PATIENT_ID -> #45585, medical_speciality -> Surgery, file_name -> Surgery_363.txt}]|\n",
      "|[They are deciding on a burial versus cremation, have decided against autopsy at this time. She will be transferred to postpartum for her recovery. She will be continued on antibiotics secondary to fever to eliminate endometritis and hopefully will be discharged home tomorrow morning.]                                                                                                                      |[{sentence -> 0, document -> 18, uuid -> 54a10745-3414-4847-8147-2f016876cc5f, PATIENT_ID -> #45585, medical_speciality -> Surgery, file_name -> Surgery_363.txt}]|\n",
      "|[All of the care and findings were discussed in detail with Christine and Bryan and at this time obviously they are very upset and grieving, but grieving appropriately and understanding the findings and the fact that there is not always a known cause for a term fetal demise. I have discussed with her that we will do some blood workup postdelivery for infectious disease profile and clotting disorders.]|[{sentence -> 0, document -> 19, uuid -> aff9b300-7f9a-4ba6-a7a0-a9fe96b60d89, PATIENT_ID -> #45585, medical_speciality -> Surgery, file_name -> Surgery_363.txt}]|\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "document_assembler = DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "sentence_detector_dl = SentenceDetectorDLModel\\\n",
    "    .pretrained(\"sentence_detector_dl_healthcare\", \"en\", \"clinical/models\")\\\n",
    "    .setInputCols(\"document\")\\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "document_splitter = InternalDocumentSplitter() \\\n",
    "    .setInputCols([\"document\", \"sentence\"]) \\\n",
    "    .setOutputCol(\"splits\") \\\n",
    "    .setSplitMode(\"sentence\") \\\n",
    "    .setMaxLength(3)\\\n",
    "    .setExplodeSplits(True)\\\n",
    "    .setMetaDataFields([\"PATIENT_ID\",\"medical_speciality\",\"file_name\"])\n",
    "\n",
    "pipeline = Pipeline().setStages([\n",
    "    document_assembler,\n",
    "    sentence_detector_dl,\n",
    "     document_splitter\n",
    "])\n",
    "\n",
    "pipeline = pipeline.fit(mt_data_df)\\\n",
    "                    .transform(mt_data_df)\\\n",
    "                    .selectExpr(\"splits.result as splits\", \"splits.metadata as metadata\")\\\n",
    "                    .show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
