{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1HXhgLGseRIz2B5BG3kUj95IVZ24sGC5Z","timestamp":1667841484913},{"file_id":"https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.4.Resume_MedicalNer_Model_Training.ipynb","timestamp":1667833202493}],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","metadata":{"id":"I08sFJYCxR0Z"},"source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"]},{"cell_type":"markdown","metadata":{"id":"FwJ-P56kq6FU"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/10.4.Resume_RelationExtractionApproach_Training.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"7ztGkR5mb6zN"},"source":["# 10.4 Resume RelationExtractionApproach Model Training\n","\n","Steps:\n","- Train a new model for a few epochs.\n","- Load the same model and train for more epochs on the same taxnonomy, and evaluate.\n","- Train a model already trained on a different dataset."]},{"cell_type":"markdown","metadata":{"id":"-68NMdHxJIco"},"source":["## Colab Setup"]},{"cell_type":"code","metadata":{"id":"h9Mn1PNTNJTq"},"source":["import json\n","import os\n","\n","from google.colab import files\n","\n","if 'spark_jsl.json' not in os.listdir():\n","  license_keys = files.upload()\n","  os.rename(list(license_keys.keys())[0], 'spark_jsl.json')\n","\n","with open('spark_jsl.json') as f:\n","    license_keys = json.load(f)\n","\n","# Defining license key-value pairs as local variables\n","locals().update(license_keys)\n","os.environ.update(license_keys)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yvHraBK7b-LU"},"source":["# Installing pyspark and spark-nlp\n","! pip install --upgrade -q pyspark==3.1.2 spark-nlp==$PUBLIC_VERSION\n","\n","# Installing Spark NLP Healthcare\n","! pip install --upgrade -q spark-nlp-jsl==$JSL_VERSION  --extra-index-url https://pypi.johnsnowlabs.com/$SECRET\n","\n","# Installing Spark NLP Display Library for visualization\n","! pip install -q spark-nlp-display"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1t5Kp93GcH7z"},"source":["import json\n","import os\n","\n","import sparknlp\n","import sparknlp_jsl\n","\n","from sparknlp.base import *\n","from sparknlp.annotator import *\n","from sparknlp_jsl.annotator import *\n","\n","from pyspark.ml import Pipeline,PipelineModel\n","from pyspark.sql import SparkSession\n","import pyspark.sql.functions as F\n","import pyspark.sql.types as T\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","params = {\"spark.driver.memory\":\"16G\", # Amount of memory to use for the driver process, i.e. where SparkContext is initialized\n","          \"spark.kryoserializer.buffer.max\":\"2000M\", # Maximum allowable size of Kryo serialization buffer, in MiB unless otherwise specified. \n","          \"spark.driver.maxResultSize\":\"2000M\"} # Limit of total size of serialized results of all partitions for each Spark action (e.g. collect) in bytes. \n","                                                # Should be at least 1M, or 0 for unlimited. \n","\n","spark = sparknlp_jsl.start(license_keys['SECRET'],params=params)\n","\n","print (\"Spark NLP Version :\", sparknlp.version())\n","print (\"Spark NLP_JSL Version :\", sparknlp_jsl.version())\n","\n","spark"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bfT1AaKvOG4J"},"source":["## Download Data for Training (NCBI Disease Dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cEYXlTzbPMB7"},"outputs":[],"source":["!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Healthcare/data/i2b2_clinical_rel_dataset.csv"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rYLFjUJLEMsN","outputId":"fd2ccdda-71bc-47c8-a386-dc1a5a5638a6","executionInfo":{"status":"ok","timestamp":1671547540151,"user_tz":300,"elapsed":8208,"user":{"displayName":"Vildan Sarıkaya","userId":"07789644790967768983"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------+-------------+-------------+------------+------------+--------------------+--------------------+---------+---------+-----+-------+\n","|            sentence|firstCharEnt1|firstCharEnt2|lastCharEnt1|lastCharEnt2|              chunk1|              chunk2|   label1|   label2|  rel|dataset|\n","+--------------------+-------------+-------------+------------+------------+--------------------+--------------------+---------+---------+-----+-------+\n","|VITAL SIGNS - Tem...|           49|           75|          64|          84|    respiratory rate|          saturation|     test|     test|    O|   test|\n","|No lotions , crea...|            3|           34|           9|          42|             lotions|           incisions|treatment|  problem|TrNAP|   test|\n","|Because of expect...|           11|           58|          54|          68|expected long ter...|         a picc line|treatment|treatment|    O|  train|\n","|She states this l...|           16|           82|          31|          92|    light-headedness|         diaphoresis|  problem|  problem|  PIP|  train|\n","|Initial electroca...|          196|          145|         239|         176|an inferior and r...|1-mm st depressio...|  problem|  problem|  PIP|   test|\n","|Abdominal ultraso...|            1|           54|          20|          71|abdominal ultrasound|  gallbladder sludge|     test|  problem| TeRP|   test|\n","|At that time he w...|           99|          139|         133|         173|ir placement of a...|his abdominopelvi...|treatment|  problem| TrAP|   test|\n","|He was transferre...|          143|          195|         154|         213|        reintubation| worsening pneumonia|treatment|  problem| TrAP|   test|\n","|5) Anemia - previ...|           12|           35|          23|          47|        previous w/u|       elev ferritin|     test|  problem| TeRP|   test|\n","|The patient &apos...|          161|          149|         179|         156| po pain medications|            his pain|treatment|  problem| TrAP|  train|\n","+--------------------+-------------+-------------+------------+------------+--------------------+--------------------+---------+---------+-----+-------+\n","only showing top 10 rows\n","\n"]}],"source":["data = spark.read.option(\"header\",\"true\").format(\"csv\").load(\"i2b2_clinical_rel_dataset.csv\")\n","\n","data = data.select( 'sentence','firstCharEnt1','firstCharEnt2','lastCharEnt1','lastCharEnt2', \"chunk1\", \"chunk2\", \"label1\", \"label2\",'rel','dataset')\n","\n","data.show(10)\n","\n","# you only need these columns>> 'sentence','firstCharEnt1','firstCharEnt2','lastCharEnt1','lastCharEnt2', \"chunk1\", \"chunk2\", \"label1\", \"label2\",'rel'\n","# ('dataset' column is optional)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OarAr_EryZDe","outputId":"c5e1f462-9792-44bd-f63b-d620485e079a","executionInfo":{"status":"ok","timestamp":1671547544542,"user_tz":300,"elapsed":4395,"user":{"displayName":"Vildan Sarıkaya","userId":"07789644790967768983"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["+-------+-----+\n","|dataset|count|\n","+-------+-----+\n","|  train|  350|\n","|   test|  650|\n","+-------+-----+\n","\n"]}],"source":["data.groupby('dataset').count().show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jpxiJ2LZDhQv","outputId":"5daab7c6-b757-49cf-f6fa-667949e1917e","executionInfo":{"status":"ok","timestamp":1671547546400,"user_tz":300,"elapsed":1863,"user":{"displayName":"Vildan Sarıkaya","userId":"07789644790967768983"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["+-----+-----+\n","|  rel|count|\n","+-----+-----+\n","| TrIP|   14|\n","| TrAP|  164|\n","| TeCP|   26|\n","|    O|  414|\n","|TrNAP|   14|\n","| TrCP|   28|\n","|  PIP|  153|\n","| TrWP|   11|\n","| TeRP|  176|\n","+-----+-----+\n","\n"]}],"source":["data.groupby('rel').count().show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BeahQHQ_gAu6"},"outputs":[],"source":["#Annotation structure\n","annotationType = T.StructType([\n","            T.StructField('annotatorType', T.StringType(), False),\n","            T.StructField('begin', T.IntegerType(), False),\n","            T.StructField('end', T.IntegerType(), False),\n","            T.StructField('result', T.StringType(), False),\n","            T.StructField('metadata', T.MapType(T.StringType(), T.StringType()), False),\n","            T.StructField('embeddings', T.ArrayType(T.FloatType()), False)\n","        ])\n","\n","#UDF function to convert train data to names entitities\n","\n","@F.udf(T.ArrayType(annotationType))\n","def createTrainAnnotations(begin1, end1, begin2, end2, chunk1, chunk2, label1, label2):\n","    \n","    entity1 = sparknlp.annotation.Annotation(\"chunk\", begin1, end1, chunk1, {'entity': label1.upper(), 'sentence': '0'}, [])\n","    entity2 = sparknlp.annotation.Annotation(\"chunk\", begin2, end2, chunk2, {'entity': label2.upper(), 'sentence': '0'}, [])    \n","        \n","    entity1.annotatorType = \"chunk\"\n","    entity2.annotatorType = \"chunk\"\n","\n","    return [entity1, entity2]    \n","\n","#list of valid relations\n","rels = [\"TrIP\", \"TrAP\", \"TeCP\", \"TrNAP\", \"TrCP\", \"PIP\", \"TrWP\", \"TeRP\"]\n","\n","#a query to select list of valid relations\n","#valid_rel_query = \"(\" + \" OR \".join([\"rel = '{}'\".format(rel) for rel in rels]) + \")\"\n","#.where(valid_rel_query)\\\n","\n","data = data\\\n","  .withColumn(\"begin1i\", F.expr(\"cast(firstCharEnt1 AS Int)\"))\\\n","  .withColumn(\"end1i\", F.expr(\"cast(lastCharEnt1 AS Int)\"))\\\n","  .withColumn(\"begin2i\", F.expr(\"cast(firstCharEnt2 AS Int)\"))\\\n","  .withColumn(\"end2i\", F.expr(\"cast(lastCharEnt2 AS Int)\"))\\\n","  .where(\"begin1i IS NOT NULL\")\\\n","  .where(\"end1i IS NOT NULL\")\\\n","  .where(\"begin2i IS NOT NULL\")\\\n","  .where(\"end2i IS NOT NULL\")\\\n","  .withColumn(\n","      \"train_ner_chunks\", \n","      createTrainAnnotations(\n","          \"begin1i\", \"end1i\", \"begin2i\", \"end2i\", \"chunk1\", \"chunk2\", \"label1\", \"label2\"\n","      ).alias(\"train_ner_chunks\", metadata={'annotatorType': \"chunk\"}))\n","    \n","@F.udf(T.StringType())\n","def encodeRelationDirection(rel, begin1, begin2):\n","    if rel != \"O\":\n","        if begin1 > begin2:\n","            return \"leftwards\"\n","        else:\n","            return \"rightwards\"\n","    else:\n","        return \"both\"\n","\n","data = data.withColumn(\"rel_dir\", encodeRelationDirection(\"rel\", \"begin1i\", \"begin2i\"))\n","\n","train_data = data.where(\"dataset='train'\")\n","test_data = data.where(\"dataset='test'\")"]},{"cell_type":"markdown","metadata":{"id":"AaTp5atqc_C-"},"source":["## Split the test data into two parts:\n","- We Keep the first part separate and use it for training the model further, as it will be totally unseen data from the same taxonomy.\n","\n","- The second part will be used to testing and evaluating"]},{"cell_type":"code","metadata":{"id":"D_gInTNZRhnC"},"source":["(test_data_1, test_data_2) = test_data.randomSplit([0.5, 0.5], seed = 100)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WX2jO2FPRo6Q"},"source":["## Train a new model, pause, and resume training on the same dataset."]},{"cell_type":"markdown","metadata":{"id":"d0cfKTrcI37q"},"source":["### Create graph \n","\n","We will use `TFGraphBuilder` annotator which can be used to create graphs automatically in the model training pipeline. \n","\n","`TFGraphBuilder` inspects the data and creates the proper graph if a suitable version of TensorFlow is available. The graph is stored in the defined folder and loaded by the approach.\n","\n","You can also create a custom graph by using `tf_graph` module in Spark NLP for Healthcare."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fYmAbLdPxey8"},"outputs":[],"source":["!pip install -q tensorflow==2.7.0 tensorflow-addons"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qDYA5aEnfLtz"},"outputs":[],"source":["from sparknlp_jsl.annotator import TFGraphBuilder\n","\n","graph_folder= \"./tf_graphs\"\n","\n","re_graph_builder = TFGraphBuilder()\\\n","    .setModelName(\"relation_extraction\")\\\n","    .setInputCols([\"embeddings\", \"pos_tags\", \"train_ner_chunks\", \"dependencies\"]) \\\n","    .setLabelColumn(\"rel\")\\\n","    .setGraphFolder(graph_folder)\\\n","    .setGraphFile(\"re_graph.pb\")\\\n","    .setHiddenLayers([300, 200])\\\n","    .setHiddenAct(\"relu\")\\\n","    .setHiddenActL2(True)\\\n","    .setHiddenWeightsL2(False)\\\n","    .setBatchNorm(False)"]},{"cell_type":"markdown","source":["### Train for 30 epochs"],"metadata":{"id":"u_T4EGRzqKp7"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9bv8j-tgEMsX","outputId":"4ae66402-6f8a-4935-b312-6ca6333991f3","executionInfo":{"status":"ok","timestamp":1671547718512,"user_tz":300,"elapsed":93001,"user":{"displayName":"Vildan Sarıkaya","userId":"07789644790967768983"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["embeddings_clinical download started this may take some time.\n","Approximate size to download 1.6 GB\n","[OK!]\n","pos_clinical download started this may take some time.\n","Approximate size to download 1.5 MB\n","[OK!]\n","dependency_conllu download started this may take some time.\n","Approximate size to download 16.7 MB\n","[OK!]\n"]}],"source":["documenter = DocumentAssembler()\\\n","    .setInputCol(\"sentence\")\\\n","    .setOutputCol(\"sentences\")\n","\n","tokenizer = Tokenizer()\\\n","    .setInputCols([\"sentences\"])\\\n","    .setOutputCol(\"tokens\")\\\n","\n","words_embedder = WordEmbeddingsModel()\\\n","    .pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n","    .setInputCols([\"sentences\", \"tokens\"])\\\n","    .setOutputCol(\"embeddings\")\n","\n","pos_tagger = PerceptronModel()\\\n","    .pretrained(\"pos_clinical\", \"en\", \"clinical/models\") \\\n","    .setInputCols([\"sentences\", \"tokens\"])\\\n","    .setOutputCol(\"pos_tags\")\n","    \n","dependency_parser = DependencyParserModel()\\\n","    .pretrained(\"dependency_conllu\", \"en\")\\\n","    .setInputCols([\"sentences\", \"pos_tags\", \"tokens\"])\\\n","    .setOutputCol(\"dependencies\")\n","\n","reApproach = RelationExtractionApproach()\\\n","    .setInputCols([\"embeddings\", \"pos_tags\", \"train_ner_chunks\", \"dependencies\"])\\\n","    .setOutputCol(\"relations\")\\\n","    .setLabelColumn(\"rel\")\\\n","    .setEpochsNumber(30)\\\n","    .setBatchSize(200)\\\n","    .setDropout(0.5)\\\n","    .setLearningRate(0.001)\\\n","    .setModelFile(f\"{graph_folder}/re_graph.pb\")\\\n","    .setFixImbalance(True)\\\n","    .setFromEntity(\"begin1i\", \"end1i\", \"label1\")\\\n","    .setToEntity(\"begin2i\", \"end2i\", \"label2\")\\\n","    .setOutputLogsPath('/content')\\\n","    .setRelationDirectionCol(\"rel_dir\")\\\n","    .setMaxSyntacticDistance(10)\n","\n","finisher = Finisher()\\\n","    .setInputCols([\"relations\"])\\\n","    .setOutputCols([\"relations_out\"])\\\n","    .setCleanAnnotations(False)\\\n","    .setValueSplitSymbol(\",\")\\\n","    .setAnnotationSplitSymbol(\",\")\\\n","    .setOutputAsArray(False)\n","\n","train_pipeline = Pipeline(stages=[\n","    documenter, \n","    tokenizer, \n","    words_embedder, \n","    pos_tagger, \n","    dependency_parser, \n","    re_graph_builder,\n","    reApproach, \n","    finisher\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xxPmTN5KEXwq","outputId":"1375486f-b6b9-4988-8bf8-3a0e91cf4fb4","executionInfo":{"status":"ok","timestamp":1671547743965,"user_tz":300,"elapsed":25463,"user":{"displayName":"Vildan Sarıkaya","userId":"07789644790967768983"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["TF Graph Builder configuration:\n","Model name: relation_extraction\n","Graph folder: ./tf_graphs\n","Graph file name: re_graph.pb\n","Build params: {'input_dim': 1149, 'output_dim': 27, 'hidden_layers': [300, 200], 'hidden_act': 'relu', 'hidden_act_l2': True, 'hidden_weights_l2': False, 'batch_norm': False}\n","relation_extraction graph exported to ./tf_graphs/re_graph.pb\n","CPU times: user 8.39 s, sys: 905 ms, total: 9.29 s\n","Wall time: 26.7 s\n"]}],"source":["%%time \n","rel_model = train_pipeline.fit(train_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oIieSDdUgrZ1"},"outputs":[],"source":["result = rel_model.transform(test_data_2)"]},{"cell_type":"markdown","metadata":{"id":"guC15OYd2Xqd"},"source":["### Evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qEzv30cIg6a3","outputId":"f4e00e0c-91be-4c4f-f9f5-210f08c9f257","executionInfo":{"status":"ok","timestamp":1671547760422,"user_tz":300,"elapsed":12406,"user":{"displayName":"Vildan Sarıkaya","userId":"07789644790967768983"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["+-----+-------+-------+----+-------+\n","|  rel|Rel_ACC|Arg_ACC| ACC|support|\n","+-----+-------+-------+----+-------+\n","| TrIP|    0.0|    1.0| 0.0|      5|\n","| TrAP|   0.75|   0.92|0.69|     55|\n","| TeCP|    0.0|    1.0| 0.0|      7|\n","|    O|   0.95|   0.89|0.84|    133|\n","|TrNAP|   null|   null|null|      4|\n","| TrCP|   null|   null|null|     10|\n","|  PIP|    0.4|    0.8|0.32|     41|\n","| TrWP|    0.0|    1.0| 0.0|      4|\n","| TeRP|   0.75|   0.75|0.56|     55|\n","+-----+-------+-------+----+-------+\n","\n"]}],"source":["results_without_dir = result\\\n","    .selectExpr(\n","        \"rel\", \n","        \"INT(rel == relations.result[0]) AS acc1\", \n","        \"INT(lower(chunk1) == lower(relations.metadata[0].chunk1)) AS acc2\",)\\\n","    .groupBy(\"rel\")\\\n","    .agg(F.avg(\"acc1\").alias(\"mACC1\"), F.avg(\"acc2\").alias(\"mACC2\"), F.count(\"rel\").alias(\"support\"))\\\n","    .selectExpr(\n","        \"rel\", \n","        \"round(mACC1, 2) AS Rel_ACC\", \n","        \"round(mACC2, 2) AS Arg_ACC\",\n","        \"round(mACC1 * mACC2, 2) AS ACC\",\n","        \"support\")\n","\n","results_without_dir.show()"]},{"cell_type":"markdown","source":["### Save to disk"],"metadata":{"id":"O5zV8T9zs0HV"}},{"cell_type":"code","source":["rel_model.stages[-2].write().overwrite().save('RE_model_30e')"],"metadata":{"id":"_4R8lYb7s1HU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y_U4mQcXUTg7"},"source":["### Train using the saved model on unseen dataset\n","\n","We use unseen data from the same taxonomy"]},{"cell_type":"code","metadata":{"id":"dgFviuf5SBei"},"source":["reApproach_finetune = RelationExtractionApproach()\\\n","    .setInputCols([\"embeddings\", \"pos_tags\", \"train_ner_chunks\", \"dependencies\"])\\\n","    .setOutputCol(\"relations\")\\\n","    .setLabelColumn(\"rel\")\\\n","    .setEpochsNumber(30)\\\n","    .setBatchSize(200)\\\n","    .setDropout(0.5)\\\n","    .setLearningRate(0.001)\\\n","    .setFixImbalance(True)\\\n","    .setFromEntity(\"begin1i\", \"end1i\", \"label1\")\\\n","    .setToEntity(\"begin2i\", \"end2i\", \"label2\")\\\n","    .setRelationDirectionCol(\"rel_dir\")\\\n","    .setPretrainedModelPath(\"RE_model_30e\")\\\n","    .setОverrideExistingLabels(False)\n","\n","finetune_pipeline = Pipeline(stages=[\n","    documenter, \n","    tokenizer, \n","    words_embedder, \n","    pos_tagger, \n","    dependency_parser, \n","    re_graph_builder,\n","    reApproach_finetune, \n","    finisher\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3d65eebf-aec5-473f-8203-f792afbca282","executionInfo":{"status":"ok","timestamp":1671547770866,"user_tz":300,"elapsed":9687,"user":{"displayName":"Vildan Sarıkaya","userId":"07789644790967768983"}},"id":"SXbPrzHFyih3"},"outputs":[{"output_type":"stream","name":"stdout","text":["TF Graph Builder configuration:\n","Model name: relation_extraction\n","Graph folder: ./tf_graphs\n","Graph file name: re_graph.pb\n","Build params: {'input_dim': 1149, 'output_dim': 27, 'hidden_layers': [300, 200], 'hidden_act': 'relu', 'hidden_act_l2': True, 'hidden_weights_l2': False, 'batch_norm': False}\n","relation_extraction graph exported to ./tf_graphs/re_graph.pb\n","CPU times: user 968 ms, sys: 59.4 ms, total: 1.03 s\n","Wall time: 9.69 s\n"]}],"source":["%%time \n","rel_model = finetune_pipeline.fit(test_data_1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NK18o6fmyiiU"},"outputs":[],"source":["result = rel_model.transform(test_data_2)"]},{"cell_type":"markdown","metadata":{"id":"GNduihulyiiV"},"source":["### Evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4ccdf65f-c9a9-4a49-921f-ab6f638492d9","executionInfo":{"status":"ok","timestamp":1671547785731,"user_tz":300,"elapsed":11006,"user":{"displayName":"Vildan Sarıkaya","userId":"07789644790967768983"}},"id":"6FX1Tp6tyiiV"},"outputs":[{"output_type":"stream","name":"stdout","text":["+-----+-------+-------+----+-------+\n","|  rel|Rel_ACC|Arg_ACC| ACC|support|\n","+-----+-------+-------+----+-------+\n","| TrIP|    0.5|    1.0| 0.5|      5|\n","| TrAP|   0.86|   0.92|0.79|     55|\n","| TeCP|    0.0|    1.0| 0.0|      7|\n","|    O|   0.93|   0.82|0.76|    133|\n","|TrNAP|    0.5|    1.0| 0.5|      4|\n","| TrCP|    0.4|    0.8|0.32|     10|\n","|  PIP|   0.77|    0.5|0.39|     41|\n","| TrWP|   0.33|    1.0|0.33|      4|\n","| TeRP|   0.76|   0.89|0.67|     55|\n","+-----+-------+-------+----+-------+\n","\n"]}],"source":["results_without_dir = result\\\n","    .selectExpr(\n","        \"rel\", \n","        \"INT(rel == relations.result[0]) AS acc1\", \n","        \"INT(lower(chunk1) == lower(relations.metadata[0].chunk1)) AS acc2\",)\\\n","    .groupBy(\"rel\")\\\n","    .agg(F.avg(\"acc1\").alias(\"mACC1\"), F.avg(\"acc2\").alias(\"mACC2\"), F.count(\"rel\").alias(\"support\"))\\\n","    .selectExpr(\n","        \"rel\", \n","        \"round(mACC1, 2) AS Rel_ACC\", \n","        \"round(mACC2, 2) AS Arg_ACC\",\n","        \"round(mACC1 * mACC2, 2) AS ACC\",\n","        \"support\")\n","\n","results_without_dir.show()"]},{"cell_type":"markdown","source":["### Save to disk"],"metadata":{"id":"G-YUHOvGyiiY"}},{"cell_type":"code","source":["rel_model.stages[-2].write().overwrite().save('RE_model_finetuned')"],"metadata":{"id":"Fsxtd5ciyiiY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rw0jTK2RbMAi"},"source":["## Now let's take a model trained on a different dataset and train on this dataset"]},{"cell_type":"code","source":["clinical_re_Model = RelationExtractionModel()\\\n","    .pretrained(\"re_clinical\", \"en\", 'clinical/models')\\\n","    .setInputCols([\"embeddings\", \"pos_tags\", \"ner_chunks\", \"dependencies\"])\\\n","    .setOutputCol(\"relations\")\n","\n","clinical_re_Model.getClasses()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8WOaJeOy0RlE","executionInfo":{"status":"ok","timestamp":1671547788381,"user_tz":300,"elapsed":2657,"user":{"displayName":"Vildan Sarıkaya","userId":"07789644790967768983"}},"outputId":"ba201ff6-f63b-4ac4-8f7f-b7114141797f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["re_clinical download started this may take some time.\n","Approximate size to download 6 MB\n","[OK!]\n"]},{"output_type":"execute_result","data":{"text/plain":["['TrWP', 'TrNAP', 'TrCP', 'PIP', 'TeCP', 'TeRP', 'TrIP', 'TrAP', 'O']"]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"EL0NQ88ofMur"},"source":["### Now train a model using this model as base"]},{"cell_type":"code","metadata":{"id":"f-zM49XJbb2j"},"source":["reApproach_finetune = RelationExtractionApproach()\\\n","    .setInputCols([\"embeddings\", \"pos_tags\", \"train_ner_chunks\", \"dependencies\"])\\\n","    .setOutputCol(\"relations\")\\\n","    .setLabelColumn(\"rel\")\\\n","    .setEpochsNumber(30)\\\n","    .setBatchSize(200)\\\n","    .setDropout(0.5)\\\n","    .setLearningRate(0.001)\\\n","    .setFixImbalance(True)\\\n","    .setFromEntity(\"begin1i\", \"end1i\", \"label1\")\\\n","    .setToEntity(\"begin2i\", \"end2i\", \"label2\")\\\n","    .setPretrainedModelPath(\"/root/cache_pretrained/re_clinical_en_2.5.5_2.4_1596928426753\")\\\n","    .setОverrideExistingLabels(False)\n","\n","finetune_pipeline = Pipeline(stages=[\n","    documenter, \n","    tokenizer, \n","    words_embedder, \n","    pos_tagger, \n","    dependency_parser, \n","    re_graph_builder,\n","    reApproach_finetune, \n","    finisher\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e79f7c96-8755-43d7-ae52-3a298715af77","executionInfo":{"status":"ok","timestamp":1671547797370,"user_tz":300,"elapsed":8993,"user":{"displayName":"Vildan Sarıkaya","userId":"07789644790967768983"}},"id":"BmneS8z-1423"},"outputs":[{"output_type":"stream","name":"stdout","text":["TF Graph Builder configuration:\n","Model name: relation_extraction\n","Graph folder: ./tf_graphs\n","Graph file name: re_graph.pb\n","Build params: {'input_dim': 1149, 'output_dim': 27, 'hidden_layers': [300, 200], 'hidden_act': 'relu', 'hidden_act_l2': True, 'hidden_weights_l2': False, 'batch_norm': False}\n","relation_extraction graph exported to ./tf_graphs/re_graph.pb\n","CPU times: user 1.34 s, sys: 45.9 ms, total: 1.38 s\n","Wall time: 8.92 s\n"]}],"source":["%%time\n","rel_model = finetune_pipeline.fit(train_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R0CCBm8U142-"},"outputs":[],"source":["result = rel_model.transform(test_data_2)"]},{"cell_type":"markdown","metadata":{"id":"J-kMkP8D142-"},"source":["### Evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3a1bdf9b-3ddc-4a4c-ed5b-d9642979e5ef","executionInfo":{"status":"ok","timestamp":1671547810627,"user_tz":300,"elapsed":10810,"user":{"displayName":"Vildan Sarıkaya","userId":"07789644790967768983"}},"id":"nf9RkE3c142-"},"outputs":[{"output_type":"stream","name":"stdout","text":["+-----+-------+-------+----+-------+\n","|  rel|Rel_ACC|Arg_ACC| ACC|support|\n","+-----+-------+-------+----+-------+\n","| TrIP|    1.0|    0.0| 0.0|      5|\n","| TrAP|   0.41|   0.41|0.17|     55|\n","| TeCP|    0.0|    1.0| 0.0|      7|\n","|    O|   0.73|   0.83| 0.6|    133|\n","|TrNAP|    0.0|    1.0| 0.0|      4|\n","| TrCP|    0.0|    0.0| 0.0|     10|\n","|  PIP|   0.31|   0.54|0.17|     41|\n","| TrWP|    0.0|    0.0| 0.0|      4|\n","| TeRP|   0.54|   0.88|0.48|     55|\n","+-----+-------+-------+----+-------+\n","\n"]}],"source":["results_without_dir = result\\\n","    .selectExpr(\n","        \"rel\", \n","        \"INT(rel == relations.result[0]) AS acc1\", \n","        \"INT(lower(chunk1) == lower(relations.metadata[0].chunk1)) AS acc2\",)\\\n","    .groupBy(\"rel\")\\\n","    .agg(F.avg(\"acc1\").alias(\"mACC1\"), F.avg(\"acc2\").alias(\"mACC2\"), F.count(\"rel\").alias(\"support\"))\\\n","    .selectExpr(\n","        \"rel\", \n","        \"round(mACC1, 2) AS Rel_ACC\", \n","        \"round(mACC2, 2) AS Arg_ACC\",\n","        \"round(mACC1 * mACC2, 2) AS ACC\",\n","        \"support\")\n","\n","results_without_dir.show()"]},{"cell_type":"markdown","source":["### Save to disk"],"metadata":{"id":"XD4dxFZ0142-"}},{"cell_type":"code","source":["rel_model.stages[-2].write().overwrite().save('RE_pretrained_model_finetuned')"],"metadata":{"id":"E5NPkAuh142_"},"execution_count":null,"outputs":[]}]}