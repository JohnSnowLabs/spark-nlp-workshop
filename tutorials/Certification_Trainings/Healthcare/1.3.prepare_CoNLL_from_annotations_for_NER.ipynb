{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1.3.prepare_CoNLL_from_annotations_for_NER.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6utBvJyWhWCv"
      },
      "source": [
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvhqEj7xhWC3"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.3.prepare_CoNLL_from_annotations_for_NER.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jaVe0VshWC4"
      },
      "source": [
        "# 1.3. Prepare CoNLL file from annotations for NER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJ-ynlgKElH1"
      },
      "source": [
        "import json, os\n",
        "from google.colab import files\n",
        "\n",
        "license_keys = files.upload()\n",
        "\n",
        "with open(list(license_keys.keys())[0]) as f:\n",
        "    license_keys = json.load(f)\n",
        "\n",
        "# Defining license key-value pairs as local variables\n",
        "locals().update(license_keys)\n",
        "\n",
        "# Adding license key-value pairs to environment variables\n",
        "os.environ.update(license_keys)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnklDYTOEu9h"
      },
      "source": [
        "# Installing pyspark and spark-nlp\n",
        "! pip install --upgrade -q pyspark==3.1.2 spark-nlp==$PUBLIC_VERSION\n",
        "\n",
        "# Installing Spark NLP Healthcare\n",
        "! pip install --upgrade -q spark-nlp-jsl==$JSL_VERSION  --extra-index-url https://pypi.johnsnowlabs.com/$SECRET"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDGJfbpoVATe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36fc4f15-cbf1-4f3e-fda9-a1aace747d8e"
      },
      "source": [
        "import json\n",
        "import os\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp_jsl.annotator import *\n",
        "from sparknlp.base import *\n",
        "import sparknlp_jsl\n",
        "import sparknlp\n",
        "\n",
        "params = {\"spark.driver.memory\":\"16G\",\n",
        "\"spark.kryoserializer.buffer.max\":\"2000M\",\n",
        "\"spark.driver.maxResultSize\":\"2000M\"}\n",
        "\n",
        "spark = sparknlp_jsl.start(license_keys['SECRET'],params=params)\n",
        "\n",
        "print (\"Spark NLP Version :\", sparknlp.version())\n",
        "print (\"Spark NLP_JSL Version :\", sparknlp_jsl.version())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP Version : 3.3.0\n",
            "Spark NLP_JSL Version : 3.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "6rIoMtnZhWC5",
        "outputId": "26a93e57-623d-48eb-976b-6a87c90ed264"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Healthcare/data/ChemProt/chemprot_train_entities.csv\n",
        "\n",
        "train_entities_df = pd.read_csv('chemprot_train_entities.csv')\n",
        "train_entities_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_id</th>\n",
              "      <th>entity</th>\n",
              "      <th>begin</th>\n",
              "      <th>end</th>\n",
              "      <th>chunk</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11319232</td>\n",
              "      <td>CHEMICAL</td>\n",
              "      <td>242</td>\n",
              "      <td>250</td>\n",
              "      <td>acyl-CoAs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11319232</td>\n",
              "      <td>CHEMICAL</td>\n",
              "      <td>1193</td>\n",
              "      <td>1200</td>\n",
              "      <td>triacsin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11319232</td>\n",
              "      <td>CHEMICAL</td>\n",
              "      <td>1441</td>\n",
              "      <td>1447</td>\n",
              "      <td>sucrose</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11319232</td>\n",
              "      <td>CHEMICAL</td>\n",
              "      <td>1637</td>\n",
              "      <td>1651</td>\n",
              "      <td>triacylglycerol</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11319232</td>\n",
              "      <td>CHEMICAL</td>\n",
              "      <td>1702</td>\n",
              "      <td>1710</td>\n",
              "      <td>acyl-CoAs</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    text_id    entity  begin   end            chunk\n",
              "0  11319232  CHEMICAL    242   250        acyl-CoAs\n",
              "1  11319232  CHEMICAL   1193  1200         triacsin\n",
              "2  11319232  CHEMICAL   1441  1447          sucrose\n",
              "3  11319232  CHEMICAL   1637  1651  triacylglycerol\n",
              "4  11319232  CHEMICAL   1702  1710        acyl-CoAs"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "ERnGMn2FhWC6",
        "outputId": "770cf11e-e340-4835-da8d-1f58f242c849"
      },
      "source": [
        "!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Healthcare/data/ChemProt/chemprot_train_text.csv\n",
        "train_text_df = pd.read_csv('chemprot_train_text.csv')\n",
        "train_text_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>16357751</td>\n",
              "      <td>Selective costimulation modulators: a novel ap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14967461</td>\n",
              "      <td>Emerging role of epidermal growth factor recep...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>23468099</td>\n",
              "      <td>Effects of chronic social defeat stress on beh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>23293962</td>\n",
              "      <td>Hepatocyte growth factor activator inhibitor t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7678677</td>\n",
              "      <td>Alprenolol and bromoacetylalprenololmenthane a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    text_id                                               text\n",
              "0  16357751  Selective costimulation modulators: a novel ap...\n",
              "1  14967461  Emerging role of epidermal growth factor recep...\n",
              "2  23468099  Effects of chronic social defeat stress on beh...\n",
              "3  23293962  Hepatocyte growth factor activator inhibitor t...\n",
              "4   7678677  Alprenolol and bromoacetylalprenololmenthane a..."
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6f0jWKYhWC7",
        "outputId": "8e0ad98a-1079-49b8-9cd9-37b9ef1ed110"
      },
      "source": [
        "def get_nlp_pipeline ():\n",
        "\n",
        "    document_assembler = DocumentAssembler() \\\n",
        "            .setInputCol(\"text\")\\\n",
        "            .setOutputCol('document')\n",
        "\n",
        "    sentence = SentenceDetector()\\\n",
        "            .setInputCols([\"document\"])\\\n",
        "            .setOutputCol(\"sentence\")\\\n",
        "            .setDetectLists(False) \n",
        "\n",
        "    # modify the tokenizer as you wish depending on your data specs\n",
        "    tokenizer = Tokenizer() \\\n",
        "            .setInputCols([\"sentence\"]) \\\n",
        "            .setOutputCol(\"token\")\n",
        "    \n",
        "    pos = PerceptronModel.pretrained() \\\n",
        "            .setInputCols([\"sentence\", \"token\"]) \\\n",
        "            .setOutputCol(\"pos\")\n",
        "    \n",
        "    pipeline = Pipeline(\n",
        "        stages = [\n",
        "            document_assembler,\n",
        "            sentence,\n",
        "            tokenizer,\n",
        "            pos]\n",
        "    )\n",
        "\n",
        "    empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
        "\n",
        "    pipelineFit = pipeline.fit(empty_data)\n",
        "\n",
        "    lp_pipeline = LightPipeline(pipelineFit)\n",
        "    \n",
        "    print (\"Spark NLP lightpipeline is created\")\n",
        "    \n",
        "    return lp_pipeline\n",
        "\n",
        "\n",
        "lp_pipeline =  get_nlp_pipeline()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pos_anc download started this may take some time.\n",
            "Approximate size to download 3.9 MB\n",
            "[OK!]\n",
            "Spark NLP lightpipeline is created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "318Og6gYhWC7"
      },
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import string\n",
        "\n",
        "def get_conll_per_doc (lp_pipeline, single_entities_df, text, first_doc=True):\n",
        "    \n",
        "    if first_doc:\n",
        "        conll_lines=[\"-DOCSTART- -X- -X- O\\n\\n\"]\n",
        "    else:\n",
        "        conll_lines = []\n",
        "\n",
        "    n = lp_pipeline.fullAnnotate(text)\n",
        "\n",
        "    parsed = [(int(x.metadata['sentence']), x.result, x.begin, x.end, y.result) for x,y in zip(n[0][\"token\"],n[0][\"pos\"])]\n",
        "\n",
        "    ents = []\n",
        "\n",
        "    ann_results = single_entities_df\n",
        "\n",
        "\n",
        "    for i, row in single_entities_df.iterrows(): \n",
        "\n",
        "\n",
        "        temp_text = row['chunk']\n",
        "        start = row['begin']\n",
        "        end = row['end']\n",
        "\n",
        "        if len(temp_text)!=len(temp_text.rstrip()):\n",
        "            end = end-(len(temp_text)-len(temp_text.rstrip()))\n",
        "            temp_text = temp_text.rstrip()\n",
        "\n",
        "        if len(temp_text)!=len(temp_text.lstrip()):\n",
        "            start = start+(len(temp_text)-len(temp_text.lstrip())) \n",
        "            temp_text = temp_text.lstrip()\n",
        "\n",
        "        ents.append((temp_text, row['entity'], start, end))\n",
        "\n",
        "    df = pd.DataFrame(ents, columns=['chunk','label','start','end'])    \n",
        "    \n",
        "    ix_list=[]\n",
        "    token_list=[]\n",
        "    tag_list=[]\n",
        "\n",
        "    for i,row in df.iterrows():\n",
        "\n",
        "        base_ix= row[\"start\"]\n",
        "\n",
        "        w_len = 0\n",
        "\n",
        "        punc_flag = False\n",
        "\n",
        "        try:\n",
        "            if row[\"chunk\"][-1] in string.punctuation:\n",
        "                punc_flag=True\n",
        "                chunk = row[\"chunk\"][:-1]+' '+row[\"chunk\"][-1]\n",
        "            else:\n",
        "                chunk = row[\"chunk\"]\n",
        "        except:\n",
        "            chunk = row[\"chunk\"]\n",
        "\n",
        "        last_ix = len(chunk.split())\n",
        "\n",
        "\n",
        "        for i,t in enumerate(chunk.split()):\n",
        "\n",
        "            if i==0:\n",
        "                ix=base_ix\n",
        "                iob = \"B-\"\n",
        "            else:\n",
        "                ix=ix+w_len+1\n",
        "                iob = \"I-\"\n",
        "\n",
        "            token_list.append(t)\n",
        "            if punc_flag and i == last_ix-1:\n",
        "                ix_list.append(ix-1)\n",
        "            else:\n",
        "                ix_list.append(ix)\n",
        "\n",
        "            tag_list.append(iob+row['label'])\n",
        "\n",
        "            w_len = len(t)\n",
        "\n",
        "    tagged= list(zip(ix_list,token_list,tag_list))\n",
        "\n",
        "    tag_dict = {(ix,token):tag for ix,token,tag in tagged}\n",
        "\n",
        "    s=0\n",
        "\n",
        "    for i, p in enumerate(parsed):\n",
        "\n",
        "        if p[0]!=s:\n",
        "            conll_lines.append(\"\\n\")\n",
        "            s+=1\n",
        "\n",
        "        conll_lines.append(\"{} {} {} {}\\n\".format(p[1], p[4], p[4], tag_dict.get((p[2],p[1]),\"O\")))\n",
        "\n",
        "    conll_lines.append(\"\\n\")\n",
        "\n",
        "    return conll_lines\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTP-5gmchWC8"
      },
      "source": [
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "\n",
        "def get_Conll_file (text_df, entities_df, path=None, limit = None):\n",
        "    \n",
        "    if limit is not None:\n",
        "    \n",
        "        text_df = text_df[:limit]\n",
        "    \n",
        "    conll_lines_list = []\n",
        "    \n",
        "    for i, row in tqdm(text_df.iterrows(), total=text_df.shape[0]):\n",
        "        \n",
        "        single_entities_df = entities_df[entities_df.text_id==row['text_id']]\n",
        "        \n",
        "        if i==0:\n",
        "            first_doc = True\n",
        "        else:\n",
        "            first_doc = False\n",
        "            \n",
        "        lines = get_conll_per_doc (lp_pipeline, single_entities_df, row['text'], first_doc)\n",
        "    \n",
        "        conll_lines_list.extend(lines)\n",
        "        \n",
        "    if path is not None:\n",
        "        \n",
        "        \n",
        "        conll_filename = '{}/ner_annotations_{}.conll'.format(path, str(datetime.now().date()))\n",
        "        \n",
        "        with open(conll_filename, 'w') as f:\n",
        "            for i in conll_lines_list:\n",
        "                f.write(i)\n",
        "\n",
        "        print (conll_filename,  'is saved.')\n",
        "\n",
        "    else:\n",
        "        \n",
        "        return conll_lines_list\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X98U8ZIjhWC8"
      },
      "source": [
        "## Get CoNLL from annotations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "fTlumo07hWC9",
        "outputId": "06eb7f7b-c4ea-4ed6-9b8f-e18a6568bf6f"
      },
      "source": [
        "train_entities_df = pd.read_csv('chemprot_train_entities.csv')\n",
        "train_entities_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_id</th>\n",
              "      <th>entity</th>\n",
              "      <th>begin</th>\n",
              "      <th>end</th>\n",
              "      <th>chunk</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11319232</td>\n",
              "      <td>CHEMICAL</td>\n",
              "      <td>242</td>\n",
              "      <td>250</td>\n",
              "      <td>acyl-CoAs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11319232</td>\n",
              "      <td>CHEMICAL</td>\n",
              "      <td>1193</td>\n",
              "      <td>1200</td>\n",
              "      <td>triacsin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11319232</td>\n",
              "      <td>CHEMICAL</td>\n",
              "      <td>1441</td>\n",
              "      <td>1447</td>\n",
              "      <td>sucrose</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11319232</td>\n",
              "      <td>CHEMICAL</td>\n",
              "      <td>1637</td>\n",
              "      <td>1651</td>\n",
              "      <td>triacylglycerol</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11319232</td>\n",
              "      <td>CHEMICAL</td>\n",
              "      <td>1702</td>\n",
              "      <td>1710</td>\n",
              "      <td>acyl-CoAs</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    text_id    entity  begin   end            chunk\n",
              "0  11319232  CHEMICAL    242   250        acyl-CoAs\n",
              "1  11319232  CHEMICAL   1193  1200         triacsin\n",
              "2  11319232  CHEMICAL   1441  1447          sucrose\n",
              "3  11319232  CHEMICAL   1637  1651  triacylglycerol\n",
              "4  11319232  CHEMICAL   1702  1710        acyl-CoAs"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "7LRpYp5BhWC9",
        "outputId": "44b3e60e-73e7-49e8-9c92-e6ac5088f06a"
      },
      "source": [
        "train_text_df = pd.read_csv('chemprot_train_text.csv')\n",
        "train_text_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>16357751</td>\n",
              "      <td>Selective costimulation modulators: a novel ap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14967461</td>\n",
              "      <td>Emerging role of epidermal growth factor recep...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>23468099</td>\n",
              "      <td>Effects of chronic social defeat stress on beh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>23293962</td>\n",
              "      <td>Hepatocyte growth factor activator inhibitor t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7678677</td>\n",
              "      <td>Alprenolol and bromoacetylalprenololmenthane a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    text_id                                               text\n",
              "0  16357751  Selective costimulation modulators: a novel ap...\n",
              "1  14967461  Emerging role of epidermal growth factor recep...\n",
              "2  23468099  Effects of chronic social defeat stress on beh...\n",
              "3  23293962  Hepatocyte growth factor activator inhibitor t...\n",
              "4   7678677  Alprenolol and bromoacetylalprenololmenthane a..."
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEzJfrhGhWC9",
        "outputId": "fc4106e5-1fb3-4c2b-ab51-c1b0005580b4"
      },
      "source": [
        "conll = get_Conll_file (train_text_df, train_entities_df, path=None, limit=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:05<00:00,  1.75it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PzOMAnVhWC-",
        "outputId": "6f87bdb9-1663-465b-ed09-7bc14161f448"
      },
      "source": [
        "conll[:20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['-DOCSTART- -X- -X- O\\n\\n',\n",
              " 'Selective NNP NNP O\\n',\n",
              " 'costimulation NN NN O\\n',\n",
              " 'modulators NNS NNS O\\n',\n",
              " ': : : O\\n',\n",
              " 'a DT DT O\\n',\n",
              " 'novel NN NN O\\n',\n",
              " 'approach NN NN O\\n',\n",
              " 'for IN IN O\\n',\n",
              " 'the DT DT O\\n',\n",
              " 'treatment NN NN O\\n',\n",
              " 'of IN IN O\\n',\n",
              " 'rheumatoid NN NN O\\n',\n",
              " 'arthritis NN NN O\\n',\n",
              " '. . . O\\n',\n",
              " '\\n',\n",
              " 'T NN NN O\\n',\n",
              " 'cells NNS NNS O\\n',\n",
              " 'have VBP VBP O\\n',\n",
              " 'a DT DT O\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fkm1lmShWC-",
        "outputId": "ab81a7b6-43d2-4ea9-d044-1a73a36da237"
      },
      "source": [
        "conll = get_Conll_file (train_text_df, train_entities_df, path='', limit=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:05<00:00,  1.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/ner_annotations_2021-10-17.conll is saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}