{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6utBvJyWhWCv"
   },
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EvhqEj7xhWC3"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.3.prepare_CoNLL_from_annotations_for_NER.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6jaVe0VshWC4"
   },
   "source": [
    "# 1.3. Prepare CoNLL file from annotations for NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BnklDYTOEu9h"
   },
   "outputs": [],
   "source": [
    "# Installing pyspark and spark-nlp\n",
    "! pip install --upgrade -q pyspark==3.1.2 spark-nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fDGJfbpoVATe",
    "outputId": "0a04b9c5-7602-4f44-dce6-71ad9ed67e4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP Version : 3.3.4\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import sparknlp\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import *\n",
    "from sparknlp.common import *\n",
    "from sparknlp.training import CoNLL\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "spark = sparknlp.start()\n",
    "\n",
    "print (\"Spark NLP Version :\", sparknlp.version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "id": "cFRay22YEcOB",
    "outputId": "0bfd98e5-84fc-42e4-9dd6-db5203eb35a9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://971d66767b2c:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark NLP</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fd54033e450>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kKtgj8q1qaQg"
   },
   "source": [
    "### Entity File\n",
    "This dataframe should include at least five  below columns in order:\n",
    "*   ['text_id','begin','end','chunk','entity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "6rIoMtnZhWC5",
    "outputId": "ca2bdc08-ea38-4eb6-9bce-6b27c98967c8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>begin</th>\n",
       "      <th>end</th>\n",
       "      <th>chunk</th>\n",
       "      <th>entity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11319232</td>\n",
       "      <td>242</td>\n",
       "      <td>250</td>\n",
       "      <td>acyl-CoAs</td>\n",
       "      <td>CHEMICAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11319232</td>\n",
       "      <td>1193</td>\n",
       "      <td>1200</td>\n",
       "      <td>triacsin</td>\n",
       "      <td>CHEMICAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11319232</td>\n",
       "      <td>1441</td>\n",
       "      <td>1447</td>\n",
       "      <td>sucrose</td>\n",
       "      <td>CHEMICAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11319232</td>\n",
       "      <td>1637</td>\n",
       "      <td>1651</td>\n",
       "      <td>triacylglycerol</td>\n",
       "      <td>CHEMICAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11319232</td>\n",
       "      <td>1702</td>\n",
       "      <td>1710</td>\n",
       "      <td>acyl-CoAs</td>\n",
       "      <td>CHEMICAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    text_id  begin   end            chunk    entity\n",
       "0  11319232    242   250        acyl-CoAs  CHEMICAL\n",
       "1  11319232   1193  1200         triacsin  CHEMICAL\n",
       "2  11319232   1441  1447          sucrose  CHEMICAL\n",
       "3  11319232   1637  1651  triacylglycerol  CHEMICAL\n",
       "4  11319232   1702  1710        acyl-CoAs  CHEMICAL"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Healthcare/data/ChemProt/chemprot_train_entities.csv\n",
    "\n",
    "train_entities_df = pd.read_csv('chemprot_train_entities.csv')\n",
    "train_entities_df= train_entities_df[[\"text_id\", \"begin\", \"end\", \"chunk\", \"entity\"]]\n",
    "train_entities_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W_KLbJNWqfxZ"
   },
   "source": [
    "###Â Text File\n",
    "This dataframe should include at least two below columns in order:\n",
    "*   ['text_id','text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ERnGMn2FhWC6",
    "outputId": "f8f28931-be4d-4f08-8ff9-12682eea9a1f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16357751</td>\n",
       "      <td>Selective costimulation modulators: a novel ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14967461</td>\n",
       "      <td>Emerging role of epidermal growth factor recep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23468099</td>\n",
       "      <td>Effects of chronic social defeat stress on beh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23293962</td>\n",
       "      <td>Hepatocyte growth factor activator inhibitor t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7678677</td>\n",
       "      <td>Alprenolol and bromoacetylalprenololmenthane a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    text_id                                               text\n",
       "0  16357751  Selective costimulation modulators: a novel ap...\n",
       "1  14967461  Emerging role of epidermal growth factor recep...\n",
       "2  23468099  Effects of chronic social defeat stress on beh...\n",
       "3  23293962  Hepatocyte growth factor activator inhibitor t...\n",
       "4   7678677  Alprenolol and bromoacetylalprenololmenthane a..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Healthcare/data/ChemProt/chemprot_train_text.csv\n",
    "train_text_df = pd.read_csv('chemprot_train_text.csv')\n",
    "train_text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "A1m1UWirBXXe"
   },
   "outputs": [],
   "source": [
    "def make_conll(text:pd.DataFrame, entity:pd.DataFrame, \n",
    "               save_tag:bool=None, \n",
    "               save_conll:bool=None, \n",
    "               verbose:bool=None, \n",
    "               begin_deviation:int=0, \n",
    "               end_deviation:int=0 )->str:\n",
    "\n",
    "    df_text = text.iloc[:,[0,1]]\n",
    "    df_entity = entity.iloc[:,[0,1,2,3,4]]\n",
    "    df_text.columns = ['text_id','text']\n",
    "    df_entity.columns = ['text_id','begin','end','chunk','entity']\n",
    "    entity_list = list(df_entity.entity.unique())\n",
    "\n",
    "\n",
    "    ########--------------1.tag transformation function------------########\n",
    "\n",
    "    def transform_text(text, entities, verbose=None):\n",
    "\n",
    "        tag_list=[]\n",
    "        for entity in entities.iterrows():\n",
    "\n",
    "            begin = entity[1][1] + begin_deviation \n",
    "            end = entity[1][2] + end_deviation\n",
    "            chunk = entity[1][3]\n",
    "            tag = entity[1][4]\n",
    "            text = text[:end] + f' </END_NER:{tag}> ' + text[end:]\n",
    "            text = text[:begin] + f' <START_NER:{tag}> ' + text[begin:]\n",
    "            tag_list.append(tag)\n",
    "\n",
    "        sum_of_added_entity = Counter(tag_list)\n",
    "        sum_of_entity = Counter(entities['entity'].values)\n",
    "\n",
    "        if verbose:\n",
    "            print(f'Processed text id   : {entities.text_id.values[:1]}')\n",
    "            print(f'Original Entities   : {sum_of_entity}\\nAdded Entities      : {sum_of_added_entity}')\n",
    "            print(f'Number Equality     : {sum_of_added_entity == sum_of_entity}')\n",
    "            print(\"==\"*40)\n",
    "\n",
    "        if not sum_of_entity == sum_of_added_entity:\n",
    "            print(\"There is a problem in text id:\")\n",
    "            print(entities.text_id.values[0])\n",
    "            raise Exception(\"Check this text!\")\n",
    "\n",
    "        return text\n",
    "\n",
    "\n",
    "    ######---------------2.apply_transform_text function ----------------#######\n",
    "\n",
    "    def apply_tag_ner(df_text, df_entity, save=None, verbose=None):\n",
    "\n",
    "        for text_id in tqdm(df_text.text_id):\n",
    "            text  = df_text.loc[df_text['text_id']==text_id]['text'].values[0] \n",
    "            entities  = df_entity.loc[(df_entity['text_id']==text_id)].sort_values(by='begin',ascending=False) \n",
    "\n",
    "            df_text.loc[df_text['text_id']==text_id, 'text'] = transform_text(text, entities, verbose=verbose)\n",
    "\n",
    "        if save:\n",
    "            df_text.to_csv(\"text_with_ner_tag.csv\", index=False, encoding='utf8')\n",
    "\n",
    "        return df_text\n",
    "\n",
    "\n",
    "    ##########----------------3.RUNNING TAG FUNCTION---------------#############\n",
    "    \n",
    "    print(\"Text tagging starting. Applying entities to whole text...\\n\")\n",
    "    df = apply_tag_ner(df_text, df_entity, save=save_tag, verbose=verbose)\n",
    "\n",
    "\n",
    "    ###########---------------4.Spark Pipeline-----------------------###########\n",
    "\n",
    "    def spark_pipeline(df):\n",
    "        spark_df = spark.createDataFrame(df)\n",
    "\n",
    "        documentAssembler = DocumentAssembler()\\\n",
    "            .setInputCol(\"text\")\\\n",
    "            .setOutputCol(\"document\")\\\n",
    "            .setCleanupMode(\"shrink\")\n",
    "\n",
    "        sentenceDetector = SentenceDetector()\\\n",
    "            .setInputCols(['document'])\\\n",
    "            .setOutputCol('sentences')\\\n",
    "            .setExplodeSentences(True)\n",
    "\n",
    "        tokenizer = Tokenizer() \\\n",
    "            .setInputCols([\"sentences\"]) \\\n",
    "            .setOutputCol(\"token\")\n",
    "\n",
    "        nlpPipeline = Pipeline(stages=[documentAssembler, sentenceDetector, tokenizer ])\n",
    "\n",
    "        empty_df = spark.createDataFrame([['']]).toDF(\"text\")\n",
    "        pipelineModel = nlpPipeline.fit(empty_df)\n",
    "\n",
    "        result = pipelineModel.transform(spark_df.select(['text']))\n",
    "\n",
    "\n",
    "        return result.select('token.result').toPandas()\n",
    "    print(\"\\n\\nSpark pipeline is running...\")\n",
    "    df_final = spark_pipeline(df)\n",
    "\n",
    "\n",
    "    #########--------------5.CoNLL Function--------------------#############\n",
    "\n",
    "    def build_conll(df_final, tag_list, save=None):\n",
    "\n",
    "        header = \"-DOCSTART- -X- -X- O\\n\\n\"\n",
    "        conll_text = \"\"\n",
    "        chunks = []\n",
    "        tag_list = tag_list\n",
    "        tag = 'O'      # token tag \n",
    "        ct = 'B'       # chunk tag part B or I\n",
    "\n",
    "        for sentence_tokens in tqdm(df_final.result[:]):\n",
    "            for token in sentence_tokens:\n",
    "                if token.startswith(\"<START_NER:\"):\n",
    "                    tag = token.split(':')[1][:-1]\n",
    "                    if tag not in tag_list:\n",
    "                        tag = 'O'\n",
    "                        conll_text += f'{token} NN NN {tag}\\n'\n",
    "\n",
    "                    continue\n",
    "\n",
    "                if token.startswith(\"</END_NER:\") and tag != 'O':\n",
    "                    for i, chunk in enumerate(chunks):\n",
    "                        ct = 'B' if i == 0 else 'I' \n",
    "                        conll_text += f'{chunk} NNP NNP {ct}-{tag}\\n'\n",
    "                    \n",
    "                    chunks=[]\n",
    "                    tag='O'\n",
    "                    continue\n",
    "\n",
    "                if tag != 'O':    \n",
    "                    chunks.append(token)\n",
    "                    continue\n",
    "\n",
    "                if tag == 'O':\n",
    "                    conll_text += f'{token} NN NN {tag}\\n'             \n",
    "                    continue\n",
    "\n",
    "            conll_text += '\\n'                                         \n",
    "\n",
    "        if save:\n",
    "            with open(\"conll2003_text_file.conll\", \"w+\", encoding='utf8') as f:\n",
    "                f.write(header)\n",
    "                f.write(conll_text)\n",
    "\n",
    "        print(\"\\nDONE!\")    \n",
    "        return conll_text\n",
    "\n",
    "        \n",
    "    ########----------------6.RUNNING CONLL FUNCTION--------------------########\n",
    "\n",
    "    print(\"Conll file is being created...\\n\")\n",
    "    return build_conll(df_final, tag_list=entity_list, save=save_conll)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UnAJDiw3rBXQ"
   },
   "source": [
    "## Running the Create CoNLL Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xFbWMCRxCdHk",
    "outputId": "34f65655-bf85-4eca-be0f-020c92b1058c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text tagging starting. Applying entities to whole text...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 1020/1020 [00:04<00:00, 219.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Spark pipeline is running...\n",
      "Conll file is being created...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 10835/10835 [00:00<00:00, 42768.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DONE!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# if you want tagged text or conll file saved in the current directory: just make default 'save_tag' or 'save_conll' parameters True.\n",
    "conll_text = make_conll(train_text_df, train_entities_df, save_conll=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f2xEw2NaCW-J",
    "outputId": "5735c412-c47f-47ad-bd27-b6104f106ace"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selective NN NN O\n",
      "costimulation NN NN O\n",
      "modulators NN NN O\n",
      ": NN NN O\n",
      "a NN NN O\n",
      "novel NN NN O\n",
      "approach NN NN O\n",
      "for NN NN O\n",
      "the NN NN O\n",
      "treatment NN NN O\n",
      "of NN NN O\n",
      "rheumatoid NN NN O\n",
      "arthritis NN NN O\n",
      ". NN NN O\n",
      "\n",
      "T NN NN O\n",
      "cells NN NN O\n",
      "have NN NN O\n",
      "a NN NN O\n",
      "central NN NN O\n",
      "role NN NN O\n",
      "in NN NN O\n",
      "the NN NN O\n",
      "orchestration NN NN O\n",
      "of NN NN O\n",
      "the NN NN O\n",
      "immune NN NN O\n",
      "pathways NN NN O\n",
      "that NN NN O\n",
      "contribute NN NN O\n",
      "to NN NN O\n",
      "the NN NN O\n",
      "inflammation NN NN O\n",
      "and NN NN O\n",
      "joint NN NN O\n",
      "destruction\n"
     ]
    }
   ],
   "source": [
    "# Checking conll string\n",
    "print(conll_text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tKXYbn1AGWt1"
   },
   "source": [
    "### Saving CoNLL File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "VpCiOLd5EAn7"
   },
   "outputs": [],
   "source": [
    "with open(\"conll2003_text_file.conll\", \"w+\", encoding='utf8') as f:\n",
    "    f.write(\"-DOCSTART- -X- -X- O\\n\\n\")\n",
    "    f.write(conll_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qu94xuq7Djpj"
   },
   "source": [
    "# Reading CoNLL File by Using CoNLL Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6CZr3ELVEAkH",
    "outputId": "764cc9af-4e49-429a-e3b0-9655c435c762"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|            document|            sentence|               token|                 pos|               label|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|Selective costimu...|[{document, 0, 96...|[{document, 0, 96...|[{token, 0, 8, Se...|[{pos, 0, 8, NN, ...|[{named_entity, 0...|\n",
      "|T cells have a ce...|[{document, 0, 17...|[{document, 0, 17...|[{token, 0, 0, T,...|[{pos, 0, 0, NN, ...|[{named_entity, 0...|\n",
      "|The requirement f...|[{document, 0, 22...|[{document, 0, 22...|[{token, 0, 2, Th...|[{pos, 0, 2, NN, ...|[{named_entity, 0...|\n",
      "|This approach is ...|[{document, 0, 78...|[{document, 0, 78...|[{token, 0, 3, Th...|[{pos, 0, 3, NN, ...|[{named_entity, 0...|\n",
      "|it targets events...|[{document, 0, 13...|[{document, 0, 13...|[{token, 0, 1, it...|[{pos, 0, 1, NN, ...|[{named_entity, 0...|\n",
      "|The fusion protei...|[{document, 0, 23...|[{document, 0, 23...|[{token, 0, 2, Th...|[{pos, 0, 2, NN, ...|[{named_entity, 0...|\n",
      "|Abatacept dose-de...|[{document, 0, 19...|[{document, 0, 19...|[{token, 0, 8, Ab...|[{pos, 0, 8, NN, ...|[{named_entity, 0...|\n",
      "|Recent studies ha...|[{document, 0, 26...|[{document, 0, 26...|[{token, 0, 5, Re...|[{pos, 0, 5, NN, ...|[{named_entity, 0...|\n",
      "|This efficacy inc...|[{document, 0, 10...|[{document, 0, 10...|[{token, 0, 3, Th...|[{pos, 0, 3, NN, ...|[{named_entity, 0...|\n",
      "|Abatacept has als...|[{document, 0, 72...|[{document, 0, 72...|[{token, 0, 8, Ab...|[{pos, 0, 8, NN, ...|[{named_entity, 0...|\n",
      "|This article revi...|[{document, 0, 16...|[{document, 0, 16...|[{token, 0, 3, Th...|[{pos, 0, 3, NN, ...|[{named_entity, 0...|\n",
      "|This clinical exp...|[{document, 0, 14...|[{document, 0, 14...|[{token, 0, 3, Th...|[{pos, 0, 3, NN, ...|[{named_entity, 0...|\n",
      "|Emerging role of ...|[{document, 0, 11...|[{document, 0, 11...|[{token, 0, 7, Em...|[{pos, 0, 7, NN, ...|[{named_entity, 0...|\n",
      "|Combination chemo...|[{document, 0, 11...|[{document, 0, 11...|[{token, 0, 10, C...|[{pos, 0, 10, NN,...|[{named_entity, 0...|\n",
      "|Meta-analyses hav...|[{document, 0, 18...|[{document, 0, 18...|[{token, 0, 12, M...|[{pos, 0, 12, NN,...|[{named_entity, 0...|\n",
      "|Just as important...|[{document, 0, 10...|[{document, 0, 10...|[{token, 0, 3, Ju...|[{pos, 0, 3, NN, ...|[{named_entity, 0...|\n",
      "|Newer agents , in...|[{document, 0, 18...|[{document, 0, 18...|[{token, 0, 4, Ne...|[{pos, 0, 4, NN, ...|[{named_entity, 0...|\n",
      "|Despite their con...|[{document, 0, 19...|[{document, 0, 19...|[{token, 0, 6, De...|[{pos, 0, 6, NN, ...|[{named_entity, 0...|\n",
      "|It is doubtful th...|[{document, 0, 13...|[{document, 0, 13...|[{token, 0, 1, It...|[{pos, 0, 1, NN, ...|[{named_entity, 0...|\n",
      "|The thrust of cur...|[{document, 0, 16...|[{document, 0, 16...|[{token, 0, 2, Th...|[{pos, 0, 2, NN, ...|[{named_entity, 0...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = CoNLL().readDataset(spark, \"/content/conll2003_text_file.conll\")\n",
    "data.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "1.3.prepare_CoNLL_from_annotations_for_NER.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
