{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"25.Date_Normalizer.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"cells":[{"cell_type":"markdown","metadata":{"id":"I08sFJYCxR0Z"},"source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"]},{"cell_type":"markdown","metadata":{"id":"LKI5K1wQrSe9"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/25.Date_Normalizer.ipynb)"]},{"cell_type":"markdown","source":["# 25. Date Normalizer"],"metadata":{"id":"YiRjfE_SHmQI"}},{"cell_type":"markdown","metadata":{"id":"okhT7AcXxben"},"source":["## Colab Setup"]},{"cell_type":"code","metadata":{"id":"I8Ytt2LLp2rj"},"source":["import json, os\n","from google.colab import files\n","\n","if 'spark_jsl.json' not in os.listdir():\n","  license_keys = files.upload()\n","  os.rename(list(license_keys.keys())[0], 'spark_jsl.json')\n","\n","with open('spark_jsl.json') as f:\n","    license_keys = json.load(f)\n","\n","# Defining license key-value pairs as local variables\n","locals().update(license_keys)\n","os.environ.update(license_keys)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9-PzVG9KYfxa"},"source":["# Installing pyspark and spark-nlp\n","! pip install --upgrade -q pyspark==3.1.2 spark-nlp==$PUBLIC_VERSION\n","\n","# Installing Spark NLP Healthcare\n","! pip install --upgrade -q spark-nlp-jsl==$JSL_VERSION  --extra-index-url https://pypi.johnsnowlabs.com/$SECRET"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VtLIEJtPf88T","colab":{"base_uri":"https://localhost:8080/","height":314},"outputId":"9a1a7826-9c8a-4ac5-fda8-24c39d2d2277","executionInfo":{"status":"ok","timestamp":1649503790101,"user_tz":-120,"elapsed":69424,"user":{"displayName":"Damla","userId":"03285166568766987047"}}},"source":["import json\n","import os\n","import pandas as pd\n","\n","from pyspark.ml import Pipeline, PipelineModel\n","from pyspark.sql import SparkSession\n","from pyspark.sql import functions as F\n","\n","import sparknlp_jsl\n","import sparknlp\n","\n","from sparknlp.annotator import *\n","from sparknlp_jsl.annotator import *\n","from sparknlp.base import *\n","from sparknlp.util import *\n","from sparknlp.pretrained import ResourceDownloader\n","\n","\n","spark = sparknlp_jsl.start(license_keys['SECRET'])\n","\n","print (\"Spark NLP Version :\", sparknlp.version())\n","print (\"Spark NLP_JSL Version :\", sparknlp_jsl.version())\n","\n","spark"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Spark NLP Version : 3.4.2\n","Spark NLP_JSL Version : 3.5.0\n"]},{"output_type":"execute_result","data":{"text/plain":["<pyspark.sql.session.SparkSession at 0x7f6d032b4190>"],"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://dcf19cb16d72:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.1.2</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>Spark NLP Licensed</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"kqlcNe7FJr31"},"source":["## **Date Normalizer**\n","\n","New Annotator that transforms chunks Dates to a normalized Date with format YYYY/MM/DD. This annotator identifies dates in chunk annotations and transforms those dates to the format YYYY/MM/DD. \n","\n"]},{"cell_type":"markdown","metadata":{"id":"YPvA603jL3TV"},"source":["We going to create a chunks dates with different formats:"]},{"cell_type":"code","metadata":{"id":"Cnf_s2yFLpXC","executionInfo":{"status":"ok","timestamp":1649503802448,"user_tz":-120,"elapsed":419,"user":{"displayName":"Damla","userId":"03285166568766987047"}}},"source":["dates = [\n","'08/02/2018',\n","'11/2018',\n","'11/01/2018',\n","'12Mar2021',\n","'Jan 30, 2018',\n","'13.04.1999', \n","'3April 2020',\n","]\n","\n"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"SW-ND2BjONF_","executionInfo":{"status":"ok","timestamp":1649503808236,"user_tz":-120,"elapsed":3127,"user":{"displayName":"Damla","userId":"03285166568766987047"}}},"source":["from pyspark.sql.types import StringType\n","df_dates = spark.createDataFrame(dates,StringType()).toDF('ner_chunk')"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JiIqDdHDPkQV"},"source":["We going to transform that text to documents in spark-nlp."]},{"cell_type":"code","metadata":{"id":"13wTh48FPcG-","executionInfo":{"status":"ok","timestamp":1649503812666,"user_tz":-120,"elapsed":1049,"user":{"displayName":"Damla","userId":"03285166568766987047"}}},"source":["document_assembler = DocumentAssembler().setInputCol('ner_chunk').setOutputCol('document')\n","documents_DF = document_assembler.transform(df_dates)"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VelhLulcPxbx"},"source":["After that we going to transform that documents to chunks."]},{"cell_type":"code","metadata":{"id":"lR6bSlXTPvqK","executionInfo":{"status":"ok","timestamp":1649503817654,"user_tz":-120,"elapsed":414,"user":{"displayName":"Damla","userId":"03285166568766987047"}}},"source":["from sparknlp.functions import map_annotations_col\n","\n","chunks_df = map_annotations_col(documents_DF.select(\"document\",\"ner_chunk\"),\n","                    lambda x: [Annotation('chunk', a.begin, a.end, a.result, a.metadata, a.embeddings) for a in x], \"document\",\n","                    \"chunk_date\", \"chunk\")"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3NqyhuNCQWC2","outputId":"ad694c26-af7c-4195-cc87-164843316359","executionInfo":{"status":"ok","timestamp":1649503825790,"user_tz":-120,"elapsed":4965,"user":{"displayName":"Damla","userId":"03285166568766987047"}}},"source":["chunks_df.select('chunk_date').show(truncate=False)"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["+---------------------------------------------------+\n","|chunk_date                                         |\n","+---------------------------------------------------+\n","|[{chunk, 0, 9, 08/02/2018, {sentence -> 0}, []}]   |\n","|[{chunk, 0, 6, 11/2018, {sentence -> 0}, []}]      |\n","|[{chunk, 0, 9, 11/01/2018, {sentence -> 0}, []}]   |\n","|[{chunk, 0, 8, 12Mar2021, {sentence -> 0}, []}]    |\n","|[{chunk, 0, 11, Jan 30, 2018, {sentence -> 0}, []}]|\n","|[{chunk, 0, 9, 13.04.1999, {sentence -> 0}, []}]   |\n","|[{chunk, 0, 10, 3April 2020, {sentence -> 0}, []}] |\n","+---------------------------------------------------+\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"iE1wA-Y1QyeI"},"source":["Now we going to normalize that chunks using the DateNormalizer."]},{"cell_type":"code","metadata":{"id":"k9E0T8mjQo0Y","executionInfo":{"status":"ok","timestamp":1649503836080,"user_tz":-120,"elapsed":613,"user":{"displayName":"Damla","userId":"03285166568766987047"}}},"source":["date_normalizer = DateNormalizer().setInputCols('chunk_date').setOutputCol('date')"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"JVX_QlglR9yR","executionInfo":{"status":"ok","timestamp":1649503839561,"user_tz":-120,"elapsed":511,"user":{"displayName":"Damla","userId":"03285166568766987047"}}},"source":["date_normalized_df = date_normalizer.transform(chunks_df)"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L8IxAZxXRihE"},"source":["We going to show how the date is normalized."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LB2yoHDqRVy-","outputId":"383818d3-c43d-4e53-e0e7-5de894399b12","executionInfo":{"status":"ok","timestamp":1649503842733,"user_tz":-120,"elapsed":1569,"user":{"displayName":"Damla","userId":"03285166568766987047"}}},"source":["dateNormalizedClean = date_normalized_df.selectExpr(\"ner_chunk\",\"date.result as dateresult\",\"date.metadata as metadata\")\n","\n","dateNormalizedClean.withColumn(\"dateresult\", dateNormalizedClean[\"dateresult\"]\n","                               .getItem(0)).withColumn(\"metadata\", dateNormalizedClean[\"metadata\"]\n","                                                       .getItem(0)['normalized']).show(truncate=False)"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["+------------+----------+--------+\n","|ner_chunk   |dateresult|metadata|\n","+------------+----------+--------+\n","|08/02/2018  |2018/08/02|true    |\n","|11/2018     |2018/11/DD|true    |\n","|11/01/2018  |2018/11/01|true    |\n","|12Mar2021   |2021/03/12|true    |\n","|Jan 30, 2018|2018/01/30|true    |\n","|13.04.1999  |1999/04/13|true    |\n","|3April 2020 |2020/04/03|true    |\n","+------------+----------+--------+\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"dwgt4QtgSf6g"},"source":["## Relative Date\n","\n","We can configure the `anchorDateYear`,`anchorDateMonth` and `anchorDateDay` for the relatives dates."]},{"cell_type":"code","metadata":{"id":"gxHErp-K7ssl","executionInfo":{"status":"ok","timestamp":1649503860908,"user_tz":-120,"elapsed":456,"user":{"displayName":"Damla","userId":"03285166568766987047"}}},"source":["rel_dates = [\n","'next monday',\n","'today',\n","'next week'\n","]\n","\n","rel_dates_df = spark.createDataFrame(rel_dates,StringType()).toDF('ner_chunk')"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"JN4QVnrD7ssu","executionInfo":{"status":"ok","timestamp":1649503863552,"user_tz":-120,"elapsed":545,"user":{"displayName":"Damla","userId":"03285166568766987047"}}},"source":["rel_documents_DF = document_assembler.transform(rel_dates_df)\n","\n","rel_chunks_df = map_annotations_col(rel_documents_DF.select(\"document\",\"ner_chunk\"),\n","                    lambda x: [Annotation('chunk', a.begin, a.end, a.result, a.metadata, a.embeddings) for a in x], \"document\",\n","                    \"chunk_date\", \"chunk\")"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b3b1a223-552f-4722-e05c-66028fe0ca0d","id":"QYnWQMSj7ssw","executionInfo":{"status":"ok","timestamp":1649503867235,"user_tz":-120,"elapsed":1052,"user":{"displayName":"Damla","userId":"03285166568766987047"}}},"source":["rel_chunks_df.select('chunk_date').show(truncate=False)"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------------------------------------+\n","|chunk_date                                        |\n","+--------------------------------------------------+\n","|[{chunk, 0, 10, next monday, {sentence -> 0}, []}]|\n","|[{chunk, 0, 4, today, {sentence -> 0}, []}]       |\n","|[{chunk, 0, 8, next week, {sentence -> 0}, []}]   |\n","+--------------------------------------------------+\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"-WrTv3SLTIe7"},"source":["In the following example we will use as a relative date 2021/02/15, to make that possible we need to set up the `anchorDateYear` to 2021, the `anchorDateMonth` to 2 and the `anchorDateDay` to 16. We will show you the configuration with the following example."]},{"cell_type":"code","metadata":{"id":"zttFZDgJSdZi","executionInfo":{"status":"ok","timestamp":1649503881932,"user_tz":-120,"elapsed":474,"user":{"displayName":"Damla","userId":"03285166568766987047"}}},"source":["rel_date_normalizer = DateNormalizer().setInputCols('chunk_date').setOutputCol('date')\\\n","    .setAnchorDateDay(16)\\\n","    .setAnchorDateMonth(2)\\\n","    .setAnchorDateYear(2021)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HvBFcvVnUge3","outputId":"e89b0a6e-9603-41ee-b4db-8cbc3b809361","executionInfo":{"status":"ok","timestamp":1649503893141,"user_tz":-120,"elapsed":1276,"user":{"displayName":"Damla","userId":"03285166568766987047"}}},"source":["rel_date_normalized_df = rel_date_normalizer.transform(rel_chunks_df)\n","relDateNormalizedClean = rel_date_normalized_df.selectExpr(\"ner_chunk\",\"date.result as dateresult\",\"date.metadata as metadata\")\n","relDateNormalizedClean.withColumn(\"dateresult\", relDateNormalizedClean[\"dateresult\"].getItem(0))\\\n","                      .withColumn(\"metadata\", relDateNormalizedClean[\"metadata\"].getItem(0)['normalized']).show(truncate=False)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------+----------+--------+\n","|ner_chunk  |dateresult|metadata|\n","+-----------+----------+--------+\n","|next monday|2021/02/22|true    |\n","|today      |2021/02/16|true    |\n","|next week  |2021/02/23|true    |\n","+-----------+----------+--------+\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"HiQke1C2VGuH"},"source":["As you see the relatives dates like `next monday` , `today` and `next week` takes the `2021/02/16` as reference date.\n"]}]}