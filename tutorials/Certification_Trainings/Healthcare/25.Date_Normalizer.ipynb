{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"cells":[{"cell_type":"markdown","metadata":{"id":"I08sFJYCxR0Z"},"source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"]},{"cell_type":"markdown","metadata":{"id":"LKI5K1wQrSe9"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/25.Date_Normalizer.ipynb)"]},{"cell_type":"markdown","source":["# 25. Date Normalizer"],"metadata":{"id":"YiRjfE_SHmQI"}},{"cell_type":"markdown","metadata":{"id":"okhT7AcXxben"},"source":["## Colab Setup"]},{"cell_type":"code","metadata":{"id":"I8Ytt2LLp2rj"},"source":["import json, os\n","from google.colab import files\n","\n","if 'spark_jsl.json' not in os.listdir():\n","  license_keys = files.upload()\n","  os.rename(list(license_keys.keys())[0], 'spark_jsl.json')\n","\n","with open('spark_jsl.json') as f:\n","    license_keys = json.load(f)\n","\n","# Defining license key-value pairs as local variables\n","locals().update(license_keys)\n","os.environ.update(license_keys)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9-PzVG9KYfxa"},"source":["# Installing pyspark and spark-nlp\n","! pip install --upgrade -q pyspark==3.1.2 spark-nlp==$PUBLIC_VERSION\n","\n","# Installing Spark NLP Healthcare\n","! pip install --upgrade -q spark-nlp-jsl==$JSL_VERSION  --extra-index-url https://pypi.johnsnowlabs.com/$SECRET"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VtLIEJtPf88T","colab":{"base_uri":"https://localhost:8080/","height":254},"outputId":"7ab3b820-7b8f-465d-9f51-105aafa9bdd1","executionInfo":{"status":"ok","timestamp":1664956771778,"user_tz":-330,"elapsed":32108,"user":{"displayName":"Gadde Sai Shailesh","userId":"15899666125549248205"}}},"source":["import json\n","import os\n","import pandas as pd\n","\n","from pyspark.ml import Pipeline, PipelineModel\n","from pyspark.sql import SparkSession\n","from pyspark.sql import functions as F\n","\n","import sparknlp_jsl\n","import sparknlp\n","\n","from sparknlp.annotator import *\n","from sparknlp_jsl.annotator import *\n","from sparknlp.base import *\n","from sparknlp.util import *\n","from sparknlp.pretrained import ResourceDownloader\n","\n","\n","spark = sparknlp_jsl.start(license_keys['SECRET'])\n","\n","print (\"Spark NLP Version :\", sparknlp.version())\n","print (\"Spark NLP_JSL Version :\", sparknlp_jsl.version())\n","\n","spark"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Spark NLP Version : 4.2.0\n","Spark NLP_JSL Version : 4.2.0\n"]},{"output_type":"execute_result","data":{"text/plain":["<pyspark.sql.session.SparkSession at 0x7f63f785e590>"],"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://9e4ee12dc80b:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.1.2</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>Spark NLP Licensed</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"kqlcNe7FJr31"},"source":["## **Date Normalizer**\n","\n","New Annotator that transforms chunks Dates to a normalized Date with format YYYY/MM/DD. This annotator identifies dates in chunk annotations and transforms those dates to the format YYYY/MM/DD. \n","\n"]},{"cell_type":"markdown","metadata":{"id":"YPvA603jL3TV"},"source":["We are going to create a chunks dates with different formats:"]},{"cell_type":"code","metadata":{"id":"Cnf_s2yFLpXC"},"source":["dates = [\n","'08/02/2018',\n","'11/2018',\n","'11/01/2018',\n","'12Mar2021',\n","'Jan 30, 2018',\n","'13.04.1999', \n","'3April 2020',\n","]\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SW-ND2BjONF_"},"source":["from pyspark.sql.types import StringType\n","df_dates = spark.createDataFrame(dates,StringType()).toDF('ner_chunk')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JiIqDdHDPkQV"},"source":["We are going to transform that text to documents in spark-nlp."]},{"cell_type":"code","metadata":{"id":"13wTh48FPcG-"},"source":["document_assembler = DocumentAssembler().setInputCol('ner_chunk').setOutputCol('document')\n","documents_DF = document_assembler.transform(df_dates)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VelhLulcPxbx"},"source":["After that we are going to transform that documents to chunks."]},{"cell_type":"code","metadata":{"id":"lR6bSlXTPvqK"},"source":["from sparknlp.functions import map_annotations_col\n","\n","chunks_df = map_annotations_col(documents_DF.select(\"document\",\"ner_chunk\"),\n","                    lambda x: [Annotation('chunk', a.begin, a.end, a.result, a.metadata, a.embeddings) for a in x], \"document\",\n","                    \"chunk_date\", \"chunk\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3NqyhuNCQWC2","outputId":"72145872-39c5-4a2d-a43c-417b5d58f0e5","executionInfo":{"status":"ok","timestamp":1664956780608,"user_tz":-330,"elapsed":5213,"user":{"displayName":"Gadde Sai Shailesh","userId":"15899666125549248205"}}},"source":["chunks_df.select('chunk_date').show(truncate=False)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+---------------------------------------------------+\n","|chunk_date                                         |\n","+---------------------------------------------------+\n","|[{chunk, 0, 9, 08/02/2018, {sentence -> 0}, []}]   |\n","|[{chunk, 0, 6, 11/2018, {sentence -> 0}, []}]      |\n","|[{chunk, 0, 9, 11/01/2018, {sentence -> 0}, []}]   |\n","|[{chunk, 0, 8, 12Mar2021, {sentence -> 0}, []}]    |\n","|[{chunk, 0, 11, Jan 30, 2018, {sentence -> 0}, []}]|\n","|[{chunk, 0, 9, 13.04.1999, {sentence -> 0}, []}]   |\n","|[{chunk, 0, 10, 3April 2020, {sentence -> 0}, []}] |\n","+---------------------------------------------------+\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"iE1wA-Y1QyeI"},"source":["Now we are going to normalize those chunks using the DateNormalizer."]},{"cell_type":"code","metadata":{"id":"k9E0T8mjQo0Y"},"source":["date_normalizer = DateNormalizer().setInputCols('chunk_date').setOutputCol('date')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JVX_QlglR9yR"},"source":["date_normalized_df = date_normalizer.transform(chunks_df)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L8IxAZxXRihE"},"source":["We are going to show how the date is normalized."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LB2yoHDqRVy-","outputId":"8d642e8b-b135-4d7d-a4c7-1c0a2e0e1dcc","executionInfo":{"status":"ok","timestamp":1664956782391,"user_tz":-330,"elapsed":1793,"user":{"displayName":"Gadde Sai Shailesh","userId":"15899666125549248205"}}},"source":["dateNormalizedClean = date_normalized_df.selectExpr(\"ner_chunk\",\"date.result as dateresult\",\"date.metadata as metadata\")\n","\n","dateNormalizedClean.withColumn(\"dateresult\", dateNormalizedClean[\"dateresult\"]\n","                               .getItem(0)).withColumn(\"metadata\", dateNormalizedClean[\"metadata\"]\n","                                                       .getItem(0)['normalized']).show(truncate=False)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+------------+----------+--------+\n","|ner_chunk   |dateresult|metadata|\n","+------------+----------+--------+\n","|08/02/2018  |2018/08/02|true    |\n","|11/2018     |2018/11/DD|true    |\n","|11/01/2018  |2018/11/01|true    |\n","|12Mar2021   |2021/03/12|true    |\n","|Jan 30, 2018|2018/01/30|true    |\n","|13.04.1999  |1999/04/13|true    |\n","|3April 2020 |2020/04/03|true    |\n","+------------+----------+--------+\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"dwgt4QtgSf6g"},"source":["## Relative Date\n","\n","We can configure the `anchorDateYear`,`anchorDateMonth` and `anchorDateDay` for the relatives dates."]},{"cell_type":"code","metadata":{"id":"gxHErp-K7ssl"},"source":["rel_dates = [\n","'next monday',\n","'today',\n","'next week'\n","]\n","\n","rel_dates_df = spark.createDataFrame(rel_dates,StringType()).toDF('ner_chunk')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JN4QVnrD7ssu"},"source":["rel_documents_DF = document_assembler.transform(rel_dates_df)\n","\n","rel_chunks_df = map_annotations_col(rel_documents_DF.select(\"document\",\"ner_chunk\"),\n","                    lambda x: [Annotation('chunk', a.begin, a.end, a.result, a.metadata, a.embeddings) for a in x], \"document\",\n","                    \"chunk_date\", \"chunk\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"40b2c016-ffa1-4ac0-9299-a58562303a05","id":"QYnWQMSj7ssw","executionInfo":{"status":"ok","timestamp":1664956782392,"user_tz":-330,"elapsed":4,"user":{"displayName":"Gadde Sai Shailesh","userId":"15899666125549248205"}}},"source":["rel_chunks_df.select('chunk_date').show(truncate=False)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------------------------------------+\n","|chunk_date                                        |\n","+--------------------------------------------------+\n","|[{chunk, 0, 10, next monday, {sentence -> 0}, []}]|\n","|[{chunk, 0, 4, today, {sentence -> 0}, []}]       |\n","|[{chunk, 0, 8, next week, {sentence -> 0}, []}]   |\n","+--------------------------------------------------+\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"-WrTv3SLTIe7"},"source":["In the following example we will use as a relative date 2021/02/16, to make that possible we need to set up the `anchorDateYear` to 2021, the `anchorDateMonth` to 2 and the `anchorDateDay` to 16. We will show you the configuration with the following example."]},{"cell_type":"code","metadata":{"id":"zttFZDgJSdZi"},"source":["rel_date_normalizer = DateNormalizer()\\\n","                        .setInputCols('chunk_date')\\\n","                        .setOutputCol('date')\\\n","                        .setAnchorDateDay(16)\\\n","                        .setAnchorDateMonth(2)\\\n","                        .setAnchorDateYear(2021)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HvBFcvVnUge3","outputId":"f7d25a4b-4f93-4760-f86d-37adf375f27f","executionInfo":{"status":"ok","timestamp":1664956784449,"user_tz":-330,"elapsed":1282,"user":{"displayName":"Gadde Sai Shailesh","userId":"15899666125549248205"}}},"source":["rel_date_normalized_df = rel_date_normalizer.transform(rel_chunks_df)\n","relDateNormalizedClean = rel_date_normalized_df.selectExpr(\"ner_chunk\",\"date.result as dateresult\",\"date.metadata as metadata\")\n","relDateNormalizedClean.withColumn(\"dateresult\", relDateNormalizedClean[\"dateresult\"].getItem(0))\\\n","                      .withColumn(\"metadata\", relDateNormalizedClean[\"metadata\"].getItem(0)['normalized']).show(truncate=False)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------+----------+--------+\n","|ner_chunk  |dateresult|metadata|\n","+-----------+----------+--------+\n","|next monday|2021/02/22|true    |\n","|today      |2021/02/16|true    |\n","|next week  |2021/02/23|true    |\n","+-----------+----------+--------+\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"HiQke1C2VGuH"},"source":["As you see the relatives dates like `next monday` , `today` and `next week` takes the `2021/02/16` as reference date.\n"]}]}