{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"a3819ec05d0445269843f6307a32cc9a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e66a89321d164caba7e0469b84631e4b","IPY_MODEL_7c4e8da87d92434e81f2a9b503333b45","IPY_MODEL_f2a85c11e63a4c19b16ba4ff72224bbc"],"layout":"IPY_MODEL_9042685f8a7241daa5c10d2c3fd34534"}},"e66a89321d164caba7e0469b84631e4b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_03377b2637d243f38bc1c6bcfdb372ec","placeholder":"​","style":"IPY_MODEL_ff8369e9715f41f58275b05bc5b903bc","value":"Downloading: 100%"}},"7c4e8da87d92434e81f2a9b503333b45":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a639824cc1164c66a305553245fdf90d","max":213450,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2fb48a8c33fa49f7a9a01c9bdf13ee52","value":213450}},"f2a85c11e63a4c19b16ba4ff72224bbc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2e8c5447fb8430fb57b395ba5708ae7","placeholder":"​","style":"IPY_MODEL_e7a7dd39939b4eeab83894ee2f96d9a9","value":" 213k/213k [00:00&lt;00:00, 253kB/s]"}},"9042685f8a7241daa5c10d2c3fd34534":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03377b2637d243f38bc1c6bcfdb372ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff8369e9715f41f58275b05bc5b903bc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a639824cc1164c66a305553245fdf90d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2fb48a8c33fa49f7a9a01c9bdf13ee52":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e2e8c5447fb8430fb57b395ba5708ae7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7a7dd39939b4eeab83894ee2f96d9a9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"87dbacb6e83746c2a53669d6dabfd0a5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d7d5e0fb83e247f78add4de0d6f6c8de","IPY_MODEL_8c46a94fca2e4881a4b2b966e6e1f675","IPY_MODEL_b8d3ecaf17c143ffb571e05a5ca66b6a"],"layout":"IPY_MODEL_bd8ce2a30b484446912f431b4394ec11"}},"d7d5e0fb83e247f78add4de0d6f6c8de":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aab0cc67d5e8442895eb4eab01cc22e7","placeholder":"​","style":"IPY_MODEL_eb63cb45fea6456f9ad9646087a1b977","value":"Downloading: 100%"}},"8c46a94fca2e4881a4b2b966e6e1f675":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_aef6eb91a41d48e9ab0338178922f9f2","max":1110,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f525a394e24643a1925508ebd533b900","value":1110}},"b8d3ecaf17c143ffb571e05a5ca66b6a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_067aa5e0e91a42f792880c9963cbc1e1","placeholder":"​","style":"IPY_MODEL_028db644fff640e78ee49821c8f2aaec","value":" 1.11k/1.11k [00:00&lt;00:00, 38.6kB/s]"}},"bd8ce2a30b484446912f431b4394ec11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aab0cc67d5e8442895eb4eab01cc22e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb63cb45fea6456f9ad9646087a1b977":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aef6eb91a41d48e9ab0338178922f9f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f525a394e24643a1925508ebd533b900":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"067aa5e0e91a42f792880c9963cbc1e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"028db644fff640e78ee49821c8f2aaec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"23a7942d7c424f3baf3e3d81da19a14b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e6435c0b2c814cb096e0d3c4542be640","IPY_MODEL_8fa730ccd2fd4c3384939c3d5c997cad","IPY_MODEL_2eb613638ab74f088aecac1b73255431"],"layout":"IPY_MODEL_e6ec9006eaad441ba00c1ebc5829e11d"}},"e6435c0b2c814cb096e0d3c4542be640":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a79e3130b2fd44f181adcdc51a5c8cc6","placeholder":"​","style":"IPY_MODEL_61e0195a5f0b4a46a748619204bdc484","value":"Downloading: 100%"}},"8fa730ccd2fd4c3384939c3d5c997cad":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab44873b8bfa423a9d316c0f51333de5","max":435783451,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6259f9ea0f30405ead4d28455eb04037","value":435783451}},"2eb613638ab74f088aecac1b73255431":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f5df4defea3441dac167cd650979c58","placeholder":"​","style":"IPY_MODEL_bb00205a9f284610929c12f8bb2a8f05","value":" 436M/436M [00:06&lt;00:00, 68.6MB/s]"}},"e6ec9006eaad441ba00c1ebc5829e11d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a79e3130b2fd44f181adcdc51a5c8cc6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61e0195a5f0b4a46a748619204bdc484":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ab44873b8bfa423a9d316c0f51333de5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6259f9ea0f30405ead4d28455eb04037":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3f5df4defea3441dac167cd650979c58":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb00205a9f284610929c12f8bb2a8f05":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","metadata":{"id":"gbt8Q6j3RJxW"},"source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"]},{"cell_type":"markdown","metadata":{"id":"xZOMrR1fRZq3"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.5.BertForTokenClassification_NER_SparkNLP_with_Transformers.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"dhiz8WdthoJm"},"source":["# 1.5 BertForTokenClassification NER Model Training with Transformers\n","\n","In this notebook, you will find how to train BertForTokenClassification NER model with transformers and then import into Spark NLP. (There is no Approach() in this notebook, so you can use only transformers for training.)"]},{"cell_type":"code","source":["%%capture\n","\n","! pip -q install seqeval\n","! pip install transformers==4.8.1\n","! pip install pyspark==3.1.2\n","! pip install spark-nlp"],"metadata":{"id":"D5W96WSqSPOc","executionInfo":{"status":"ok","timestamp":1664965004381,"user_tz":-60,"elapsed":61139,"user":{"displayName":"Ahmet Emin Tek","userId":"14855809472179427810"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"SqSpuOmV6dQE","executionInfo":{"status":"ok","timestamp":1664965106191,"user_tz":-60,"elapsed":80196,"user":{"displayName":"Ahmet Emin Tek","userId":"14855809472179427810"}},"colab":{"base_uri":"https://localhost:8080/","height":233},"outputId":"b975ac4d-8e1c-44ad-b9d9-4805b94980e5"},"source":["import torch\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from transformers import BertTokenizer, BertConfig\n","\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","\n","import sparknlp\n","from pyspark.sql import functions as F\n","\n","from sparknlp.training import CoNLL\n","from google.colab import files\n","\n","import pandas as pd\n","import numpy as np\n","from tqdm import tqdm, trange\n","\n","import transformers\n","from transformers import BertForTokenClassification, TFBertForTokenClassification, AdamW\n","from transformers import get_linear_schedule_with_warmup\n","\n","from sklearn.metrics import classification_report\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","n_gpu = torch.cuda.device_count()\n","\n","torch.cuda.get_device_name(0)\n","\n","spark = sparknlp.start()\n","\n","print (\"Spark NLP Version :\", sparknlp.version())\n","\n","spark"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Spark NLP Version : 4.2.0\n"]},{"output_type":"execute_result","data":{"text/plain":["<pyspark.sql.session.SparkSession at 0x7fca763ce550>"],"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://cad2cceb4e14:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.1.2</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>Spark NLP</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"5kKaWwaX6Pos"},"source":["## Download NCBI Disease CoNLL Dataset"]},{"cell_type":"code","metadata":{"id":"iBEuXQnw6VPG","executionInfo":{"status":"ok","timestamp":1664965114050,"user_tz":-60,"elapsed":1573,"user":{"displayName":"Ahmet Emin Tek","userId":"14855809472179427810"}}},"source":["!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Healthcare/data/NER_NCBIconlltrain.txt\n","!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Healthcare/data/NER_NCBIconlltest.txt"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"hO0VnBGa81Wb","executionInfo":{"status":"ok","timestamp":1664965321307,"user_tz":-60,"elapsed":481,"user":{"displayName":"Ahmet Emin Tek","userId":"14855809472179427810"}}},"source":["PROJECT_NAME = 'ner_disease_main'\n","\n","train_set =  \"NER_NCBIconlltrain.txt\"\n","test_set = \"NER_NCBIconlltest.txt\"\n","\n","test_metrics = True\n","\n","# select any Bert model from >> https://huggingface.co/models?pipeline_tag=token-classification&sort=downloads&search=bert\n","\n","MODEL_TO_TRAIN = 'dmis-lab/biobert-base-cased-v1.2'\n","# emilyalsentzer/Bio_ClinicalBERT\n","\n","# Defining some key variables that will be used later on in the training\n","MAX_LEN = 128 # 512\n","TRAIN_BATCH_SIZE = 64 # 8\n","VALID_BATCH_SIZE = 64 # 8\n","EPOCHS = 5\n","LEARNING_RATE = 2e-05\n","\n","!mkdir {PROJECT_NAME}\n","!mkdir {PROJECT_NAME}/logs"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iebvp7r-t4tl"},"source":["## Run the follwing cells with no change"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["a3819ec05d0445269843f6307a32cc9a","e66a89321d164caba7e0469b84631e4b","7c4e8da87d92434e81f2a9b503333b45","f2a85c11e63a4c19b16ba4ff72224bbc","9042685f8a7241daa5c10d2c3fd34534","03377b2637d243f38bc1c6bcfdb372ec","ff8369e9715f41f58275b05bc5b903bc","a639824cc1164c66a305553245fdf90d","2fb48a8c33fa49f7a9a01c9bdf13ee52","e2e8c5447fb8430fb57b395ba5708ae7","e7a7dd39939b4eeab83894ee2f96d9a9","87dbacb6e83746c2a53669d6dabfd0a5","d7d5e0fb83e247f78add4de0d6f6c8de","8c46a94fca2e4881a4b2b966e6e1f675","b8d3ecaf17c143ffb571e05a5ca66b6a","bd8ce2a30b484446912f431b4394ec11","aab0cc67d5e8442895eb4eab01cc22e7","eb63cb45fea6456f9ad9646087a1b977","aef6eb91a41d48e9ab0338178922f9f2","f525a394e24643a1925508ebd533b900","067aa5e0e91a42f792880c9963cbc1e1","028db644fff640e78ee49821c8f2aaec","23a7942d7c424f3baf3e3d81da19a14b","e6435c0b2c814cb096e0d3c4542be640","8fa730ccd2fd4c3384939c3d5c997cad","2eb613638ab74f088aecac1b73255431","e6ec9006eaad441ba00c1ebc5829e11d","a79e3130b2fd44f181adcdc51a5c8cc6","61e0195a5f0b4a46a748619204bdc484","ab44873b8bfa423a9d316c0f51333de5","6259f9ea0f30405ead4d28455eb04037","3f5df4defea3441dac167cd650979c58","bb00205a9f284610929c12f8bb2a8f05"]},"id":"XvUBSCIo9ZWR","outputId":"196022b0-dc8f-4b93-a7e4-d312a724309c","executionInfo":{"status":"ok","timestamp":1664965571068,"user_tz":-60,"elapsed":243650,"user":{"displayName":"Ahmet Emin Tek","userId":"14855809472179427810"}}},"source":["def get_conll_df(pth):\n","  data = CoNLL().readDataset(spark, pth)\n","  data = data.withColumn(\"sentence_idx\", F.monotonically_increasing_id())\n","  data = data.withColumn('unique', F.array_distinct(\"label.result\"))\\\n","              .withColumn('c', F.size('unique'))\\\n","              .filter(F.col('c')>1)\n","\n","  df = data.select('sentence_idx', F.explode(F.arrays_zip(data.token.result,data.label.result,data.pos.result)).alias(\"cols\")) \\\n","          .select('sentence_idx',\n","                  F.expr(\"cols['0']\").alias(\"word\"),\n","                  F.expr(\"cols['1']\").alias(\"tag\"),\n","                  F.expr(\"cols['2']\").alias(\"pos\")).toPandas()\n","  \n","  return df\n","\n","\n","train_data_df = get_conll_df(train_set)\n","test_data_df = get_conll_df(test_set)\n","\n","print ('=== TRAINING SET DISTRIBUTION ===')\n","print (train_data_df['tag'].value_counts())\n","\n","print ('=== TEST SET DISTRIBUTION ===')\n","print (test_data_df['tag'].value_counts())\n","\n","if not test_metrics:\n","\n","  train_data_df = pd.concat([train_data_df, test_data_df])\n","\n","\n","## convert conll file to sentences\n","\n","class SentenceGetter(object):\n","    \n","    def __init__(self, dataset):\n","        self.n_sent = 1\n","        self.dataset = dataset\n","        self.empty = False\n","        agg_func = lambda s: [(w,p, t) for w,p, t in zip(s[\"word\"].values.tolist(),\n","                                                       s['pos'].values.tolist(),\n","                                                        s[\"tag\"].values.tolist())]\n","        self.grouped = self.dataset.groupby(\"sentence_idx\").apply(agg_func)\n","        self.sentences = [s for s in self.grouped]\n","    \n","    def get_next(self):\n","        try:\n","            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n","            self.n_sent += 1\n","            return s\n","        except:\n","            return None\n","\n","train_getter = SentenceGetter(train_data_df)\n","\n","if test_metrics:  \n","  test_getter = SentenceGetter(test_data_df)\n","\n","\n","print ('=== Getting sentences and labels ===')\n","\n","# Sentences \n","train_sentences = [[word[0] for word in sentence] for sentence in train_getter.sentences]\n","print(\"Example of train sentence:\")\n","print (train_sentences[5])\n","\n","if test_metrics:\n","  test_sentences = [[word[0] for word in sentence] for sentence in test_getter.sentences]\n","  print(\"Example of test sentence:\")\n","  print (test_sentences[5])\n","\n","# Labels\n","train_labels = [[s[2] for s in sentence] for sentence in train_getter.sentences]\n","print(\"Example of train sentence:\")\n","print(train_labels[5])\n","\n","if test_metrics:\n","  test_labels = [[s[2] for s in sentence] for sentence in test_getter.sentences]\n","  print(\"Example of test sentence:\")\n","  print(test_labels[5])\n","\n","\n","tag_values = list(set(train_data_df[\"tag\"].values))\n","tag_values.append(\"PAD\")\n","tag2idx = {t: i for i, t in enumerate(tag_values)}\n","\n","print(tag_values[:10])\n","print(tag2idx)\n","\n","tokenizer = BertTokenizer.from_pretrained(MODEL_TO_TRAIN, do_lower_case=False)\n","\n","\n","def tokenize_and_preserve_labels(sentence, text_labels):\n","    tokenized_sentence = []\n","    labels = []\n","\n","    for word, label in zip(sentence, text_labels):\n","\n","        # Tokenize the word and count # of subwords the word is broken into\n","        tokenized_word = tokenizer.tokenize(word)\n","        n_subwords = len(tokenized_word)\n","\n","        # Add the tokenized word to the final tokenized word list\n","        tokenized_sentence.extend(tokenized_word)\n","\n","        # Add the same label to the new list of labels `n_subwords` times\n","        labels.extend([label] * n_subwords)\n","\n","    return tokenized_sentence, labels\n","\n","\n","train_tokenized_texts_and_labels = [\n","    tokenize_and_preserve_labels(sent, labs)\n","    for sent, labs in zip(train_sentences, train_labels)\n","]\n","\n","if test_metrics:\n","\n","  test_tokenized_texts_and_labels = [\n","      tokenize_and_preserve_labels(sent, labs)\n","      for sent, labs in zip(test_sentences, test_labels)\n","  ]\n","\n","train_tokenized_texts_tokens = [token_label_pair[0] for token_label_pair in train_tokenized_texts_and_labels]\n","\n","if test_metrics:\n","  test_tokenized_texts_tokens = [token_label_pair[0] for token_label_pair in test_tokenized_texts_and_labels]\n","  print(test_tokenized_texts_tokens[5])\n","\n","train_tokenized_texts_labels = [token_label_pair[1] for token_label_pair in train_tokenized_texts_and_labels]\n","\n","if test_metrics:\n","  test_tokenized_texts_labels = [token_label_pair[1] for token_label_pair in test_tokenized_texts_and_labels]\n","  print(test_tokenized_texts_labels[5])\n","\n","\n","\n","train_input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in train_tokenized_texts_tokens],\n","                          maxlen=MAX_LEN, dtype=\"long\", value=0.0,\n","                          truncating=\"post\", padding=\"post\")\n","\n","if test_metrics:\n","\n","  test_input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in test_tokenized_texts_tokens],\n","                          maxlen=MAX_LEN, dtype=\"long\", value=0.0,\n","                          truncating=\"post\", padding=\"post\")\n","\n","train_tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in train_tokenized_texts_labels],\n","                     maxlen=MAX_LEN, value=tag2idx[\"PAD\"], padding=\"post\",\n","                     dtype=\"long\", truncating=\"post\")\n","\n","train_attention_masks = [[float(i != 0.0) for i in ii] for ii in train_input_ids]\n","\n","if test_metrics:\n","\n","  test_tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in test_tokenized_texts_labels],\n","                     maxlen=MAX_LEN, value=tag2idx[\"PAD\"], padding=\"post\",\n","                     dtype=\"long\", truncating=\"post\")\n","  test_attention_masks = [[float(i != 0.0) for i in ii] for ii in test_input_ids]\n","\n","\n","\n","\n","tr_inputs = torch.tensor(train_input_ids)\n","tr_tags = torch.tensor(train_tags)\n","tr_masks = torch.tensor(train_attention_masks)\n","\n","if test_metrics:\n","\n","  val_inputs = torch.tensor(test_input_ids)\n","  val_tags = torch.tensor(test_tags)\n","  val_masks = torch.tensor(test_attention_masks)\n","\n","\n","train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=TRAIN_BATCH_SIZE)\n","\n","if test_metrics:\n","\n","  valid_data = TensorDataset(val_inputs, val_masks, val_tags)\n","  valid_sampler = SequentialSampler(valid_data)\n","  valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=TRAIN_BATCH_SIZE)\n","\n","\n","\n","model = BertForTokenClassification.from_pretrained(\n","    MODEL_TO_TRAIN,\n","    num_labels=len(tag2idx),\n","    output_attentions = False,\n","    output_hidden_states = False\n",")\n","model.to(device)\n","\n","FULL_FINETUNING = True\n","if FULL_FINETUNING:\n","    param_optimizer = list(model.named_parameters())\n","    no_decay = ['bias', 'gamma', 'beta']\n","    optimizer_grouped_parameters = [\n","        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n","         'weight_decay_rate': 0.01},\n","        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n","         'weight_decay_rate': 0.0}\n","    ]\n","else:\n","    param_optimizer = list(model.classifier.named_parameters())\n","    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n","\n","optimizer = AdamW(\n","    optimizer_grouped_parameters,\n","    lr=3e-5,\n","    eps=1e-8\n",")\n","\n","\n","epochs = EPOCHS\n","max_grad_norm = 1.0\n","\n","# Total number of training steps is number of batches * number of epochs.\n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(\n","    optimizer,\n","    num_warmup_steps=0,\n","    num_training_steps=total_steps\n",")\n","\n","\n","## Store the average loss after each epoch so we can plot them.\n","loss_values, validation_loss_values = [], []\n","\n","for EPOCH in trange(epochs, desc=\"Epoch\"):\n","    # Put the model into training mode.\n","    model.train()\n","    # Reset the total loss for this epoch.\n","    total_loss = 0\n","\n","    # Training loop\n","    for step, batch in enumerate(train_dataloader):\n","        # add batch to gpu\n","        batch = tuple(t.to(device) for t in batch)\n","        b_input_ids, b_input_mask, b_labels = batch\n","        # Always clear any previously calculated gradients before performing a backward pass.\n","        model.zero_grad()\n","        # forward pass\n","        # This will return the loss (rather than the model output)\n","        # because we have provided the `labels`.\n","        outputs = model(b_input_ids, token_type_ids=None,\n","                        attention_mask=b_input_mask, labels=b_labels)\n","        # get the loss\n","        loss = outputs[0]\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","        # track train loss\n","        total_loss += loss.item()\n","        # Clip the norm of the gradient\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n","        # update parameters\n","        optimizer.step()\n","        # Update the learning rate.\n","        scheduler.step()\n","\n","    # Calculate the average loss over the training data.\n","    avg_train_loss = total_loss / len(train_dataloader)\n","    tr_loss = f\"Average train loss: {str(avg_train_loss)}\\n\"\n","\n","    # Saving partial models (this creates the folder too)    \n","    tokenizer.save_pretrained(f'{PROJECT_NAME}/{str(EPOCH)}/tokenizer/')\n","    model.save_pretrained(save_directory=f'{PROJECT_NAME}/{str(EPOCH)}/',\n","                          save_config=True, state_dict=model.state_dict)\n","    # Saving checkpoint in case it crashes, to restore work\n","    torch.save({\n","        'epoch': EPOCH,\n","        'model_state_dict': model.state_dict(),\n","        'optimizer_state_dict': optimizer.state_dict(),\n","        'loss': avg_train_loss,\n","        }, f'{PROJECT_NAME}/{str(EPOCH)}/checkpoint.pth')\n","\n","    # Store the loss value for plotting the learning curve.\n","    loss_values.append(avg_train_loss)\n","    \n","    if test_metrics:\n","\n","      # Put the model into evaluation mode\n","      model.eval()\n","      # Reset the validation loss for this epoch.\n","      eval_loss, eval_accuracy = 0, 0\n","      nb_eval_steps, nb_eval_examples = 0, 0\n","      predictions , true_labels = [], []\n","      for batch in valid_dataloader:\n","          batch = tuple(t.to(device) for t in batch)\n","          b_input_ids, b_input_mask, b_labels = batch\n","\n","          # Telling the model not to compute or store gradients,\n","          # saving memory and speeding up validation\n","          with torch.no_grad():\n","              # Forward pass, calculate logit predictions.\n","              # This will return the logits rather than the loss because we have not provided labels.\n","              outputs = model(b_input_ids, token_type_ids=None,\n","                              attention_mask=b_input_mask, labels=b_labels)\n","          # Move logits and labels to CPU\n","          logits = outputs[1].detach().cpu().numpy()\n","          label_ids = b_labels.to('cpu').numpy()\n","\n","          # Calculate the accuracy for this batch of test sentences.\n","          eval_loss += outputs[0].mean().item()\n","          predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n","          true_labels.extend(label_ids)\n","\n","      eval_loss = eval_loss / len(valid_dataloader)\n","      validation_loss_values.append(eval_loss)\n","\n","      val_loss = f\"Validation loss: {str(eval_loss)}\\n\"\n","      \n","    # Saving losses log\n","    with open(f'{PROJECT_NAME}/logs/epoch_' + str(EPOCH) + '_loss.log', 'a') as f:\n","      f.write(tr_loss)\n","      f.write('')\n","      if test_metrics:\n","          f.write(val_loss)\n","\n","    # Calculating metrics\n","    pred_tags = [tag_values[p_i] for p, l in zip(predictions, true_labels)\n","                                 for p_i, l_i in zip(p, l) if tag_values[l_i] != \"PAD\"]\n","    valid_tags = [tag_values[l_i] for l in true_labels\n","                                  for l_i in l if tag_values[l_i] != \"PAD\"]\n","    \n","    report = classification_report(valid_tags, pred_tags)\n","    \n","    # Saving metrics\n","    with open(f'{PROJECT_NAME}/logs/epoch_' + str(EPOCH) + '_metrics.log', 'a') as f:\n","      f.write(report)\n","\n","    # Printing also to stdout\n","    print(tr_loss)\n","\n","    if test_metrics:\n","      print(val_loss)\n","      print(report)\n","    "],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["=== TRAINING SET DISTRIBUTION ===\n","O            39427\n","I-Disease     3547\n","B-Disease     3093\n","Name: tag, dtype: int64\n","=== TEST SET DISTRIBUTION ===\n","O            9316\n","I-Disease     789\n","B-Disease     708\n","Name: tag, dtype: int64\n","=== Getting sentences and labels ===\n","Example of train sentence:\n","['A', 'common', 'MSH2', 'mutation', 'in', 'English', 'and', 'North', 'American', 'HNPCC', 'families', ':', 'origin', ',', 'phenotypic', 'expression', ',', 'and', 'sex', 'specific', 'differences', 'in', 'colorectal', 'cancer', '.']\n","Example of test sentence:\n","['Two', 'of', 'seventeen', 'mutated', 'T', '-', 'PLL', 'samples', 'had', 'a', 'previously', 'reported', 'A', '-', 'T', 'allele', '.']\n","Example of train sentence:\n","['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Disease', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Disease', 'I-Disease', 'O']\n","Example of test sentence:\n","['O', 'O', 'O', 'O', 'B-Disease', 'I-Disease', 'I-Disease', 'O', 'O', 'O', 'O', 'O', 'B-Disease', 'I-Disease', 'I-Disease', 'O', 'O']\n","['B-Disease', 'I-Disease', 'O', 'PAD']\n","{'B-Disease': 0, 'I-Disease': 1, 'O': 2, 'PAD': 3}\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3819ec05d0445269843f6307a32cc9a"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["['Two', 'of', 'seventeen', 'm', '##uta', '##ted', 'T', '-', 'P', '##LL', 'samples', 'had', 'a', 'previously', 'reported', 'A', '-', 'T', 'all', '##ele', '.']\n","['O', 'O', 'O', 'O', 'O', 'O', 'B-Disease', 'I-Disease', 'I-Disease', 'I-Disease', 'O', 'O', 'O', 'O', 'O', 'B-Disease', 'I-Disease', 'I-Disease', 'O', 'O', 'O']\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.11k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87dbacb6e83746c2a53669d6dabfd0a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/436M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23a7942d7c424f3baf3e3d81da19a14b"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at dmis-lab/biobert-base-cased-v1.2 were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Epoch:  20%|██        | 1/5 [00:40<02:43, 40.86s/it]"]},{"output_type":"stream","name":"stdout","text":["Average train loss: 0.42007024586200714\n","\n","Validation loss: 0.19089141488075256\n","\n","              precision    recall  f1-score   support\n","\n","   B-Disease       0.70      0.82      0.76      1718\n","   I-Disease       0.78      0.65      0.71      1560\n","           O       0.98      0.97      0.97     11654\n","\n","    accuracy                           0.92     14932\n","   macro avg       0.82      0.81      0.81     14932\n","weighted avg       0.92      0.92      0.92     14932\n","\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  40%|████      | 2/5 [01:19<01:59, 39.84s/it]"]},{"output_type":"stream","name":"stdout","text":["Average train loss: 0.14670091977825872\n","\n","Validation loss: 0.1282198429107666\n","\n","              precision    recall  f1-score   support\n","\n","   B-Disease       0.87      0.85      0.86      1718\n","   I-Disease       0.84      0.87      0.85      1560\n","           O       0.98      0.98      0.98     11654\n","\n","    accuracy                           0.95     14932\n","   macro avg       0.89      0.90      0.90     14932\n","weighted avg       0.95      0.95      0.95     14932\n","\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  60%|██████    | 3/5 [01:59<01:19, 39.73s/it]"]},{"output_type":"stream","name":"stdout","text":["Average train loss: 0.08037628840517115\n","\n","Validation loss: 0.13134088154350007\n","\n","              precision    recall  f1-score   support\n","\n","   B-Disease       0.88      0.90      0.89      1718\n","   I-Disease       0.82      0.92      0.87      1560\n","           O       0.99      0.97      0.98     11654\n","\n","    accuracy                           0.96     14932\n","   macro avg       0.90      0.93      0.91     14932\n","weighted avg       0.96      0.96      0.96     14932\n","\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  80%|████████  | 4/5 [02:40<00:40, 40.24s/it]"]},{"output_type":"stream","name":"stdout","text":["Average train loss: 0.05160373863246706\n","\n","Validation loss: 0.13211968008960998\n","\n","              precision    recall  f1-score   support\n","\n","   B-Disease       0.90      0.86      0.88      1718\n","   I-Disease       0.85      0.92      0.88      1560\n","           O       0.98      0.98      0.98     11654\n","\n","    accuracy                           0.96     14932\n","   macro avg       0.91      0.92      0.91     14932\n","weighted avg       0.96      0.96      0.96     14932\n","\n"]},{"output_type":"stream","name":"stderr","text":["Epoch: 100%|██████████| 5/5 [03:23<00:00, 40.72s/it]"]},{"output_type":"stream","name":"stdout","text":["Average train loss: 0.04036214823524157\n","\n","Validation loss: 0.1324809417128563\n","\n","              precision    recall  f1-score   support\n","\n","   B-Disease       0.89      0.89      0.89      1718\n","   I-Disease       0.85      0.92      0.88      1560\n","           O       0.99      0.98      0.98     11654\n","\n","    accuracy                           0.96     14932\n","   macro avg       0.91      0.93      0.92     14932\n","weighted avg       0.96      0.96      0.96     14932\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","metadata":{"id":"uCXnULJwMwW-","executionInfo":{"status":"ok","timestamp":1664965580891,"user_tz":-60,"elapsed":1347,"user":{"displayName":"Ahmet Emin Tek","userId":"14855809472179427810"}}},"source":["!rm -rf /content/ner_disease_main/0\n","!rm -rf /content/ner_disease_main/1\n","!rm -rf /content/ner_disease_main/2\n","!rm -rf /content/ner_disease_main/3"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AJQEdfA0Npmz"},"source":["## Load the model as TF and save properly\n"]},{"cell_type":"code","metadata":{"id":"er8xdlkKNqZ4","colab":{"base_uri":"https://localhost:8080/"},"outputId":"96c96ad2-0c1a-4061-e1e9-0b2afb3298b6","executionInfo":{"status":"ok","timestamp":1664965647560,"user_tz":-60,"elapsed":64311,"user":{"displayName":"Ahmet Emin Tek","userId":"14855809472179427810"}}},"source":["last_successfull_epoch = len(loss_values) - 1\n","if last_successfull_epoch < 0:\n","  last_successfull_epoch = None\n","\n","if last_successfull_epoch is None:\n","  print(\"No epochs finished successfully.\")\n","else:\n","  print(f\"Last successfull epoch: {str(last_successfull_epoch)}\")\n","\n","# first save the model as pytorch model (we'll cast later)\n","MODEL_NAME_PYTORCH = 'model_epoch_'+str(last_successfull_epoch)+'_pytorch'\n","MODEL_NAME_TF = 'model_epoch_'+str(last_successfull_epoch)+'_tf'\n","\n","print(MODEL_NAME_PYTORCH)\n","print(MODEL_NAME_TF)\n","\n","# now load the model as TF and save properly\n","from transformers import TFBertForTokenClassification\n","\n","tokenizer.save_pretrained(f'./{PROJECT_NAME}/{MODEL_NAME_PYTORCH}_tokenizer/')\n","model.save_pretrained(f'./{PROJECT_NAME}/{MODEL_NAME_PYTORCH}', saved_model=True, save_format='tf')\n","loaded_model = TFBertForTokenClassification.from_pretrained(f'./{PROJECT_NAME}/{MODEL_NAME_PYTORCH}', from_pt=True)\n","loaded_model.save_pretrained(f'./{PROJECT_NAME}/{MODEL_NAME_TF}', saved_model=True)\n","\n","labels = sorted(tag2idx, key=tag2idx.get)\n","\n","print (labels)\n","\n","with open(f'./{PROJECT_NAME}/{MODEL_NAME_TF}/saved_model/1/assets/labels.txt', 'w') as f:\n","    f.write('\\n'.join(labels))\n","\n","vocab_pth = f\"./{PROJECT_NAME}/{MODEL_NAME_PYTORCH}_tokenizer/vocab.txt\"\n","saved_model_pth = f'./{PROJECT_NAME}/{MODEL_NAME_TF}/saved_model/1/assets/'\n","\n","! cp $vocab_pth $saved_model_pth"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Last successfull epoch: 4\n","model_epoch_4_pytorch\n","model_epoch_4_tf\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForTokenClassification: ['bert.embeddings.position_ids']\n","- This IS expected if you are initializing TFBertForTokenClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertForTokenClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertForTokenClassification were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForTokenClassification for predictions without further training.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x7fcb63253280>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x7fcb63253280>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7fcb7529fc20> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"]},{"output_type":"stream","name":"stdout","text":["WARNING: AutoGraph could not transform <function wrap at 0x7fcb7529fc20> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, add_layer_call_fn while saving (showing 5 of 418). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["['B-Disease', 'I-Disease', 'O', 'PAD']\n"]}]},{"cell_type":"markdown","metadata":{"id":"IcQNjWOeN83V"},"source":["## Load the saved model in Spark NLP and save it properly¶\n"]},{"cell_type":"code","metadata":{"id":"A7lvrYkvOC3L","executionInfo":{"status":"ok","timestamp":1664965680438,"user_tz":-60,"elapsed":13435,"user":{"displayName":"Ahmet Emin Tek","userId":"14855809472179427810"}}},"source":["from sparknlp.annotator import *\n","\n","tokenClassifier = BertForTokenClassification.loadSavedModel(\n","     f'./{PROJECT_NAME}/{MODEL_NAME_TF}/saved_model/1',\n","     spark)\\\n","  .setInputCols([\"sentence\",'token'])\\\n","  .setOutputCol(\"ner\")\\\n","  .setCaseSensitive(True)\\\n","  .setMaxSentenceLength(128) # 512\n","\n","tokenClassifier.write().overwrite().save(f\"./{PROJECT_NAME}/{MODEL_NAME_TF}_spark_nlp\")"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tYDq9D-cOGbo"},"source":["## Test the imported model in Spark NLP¶\n"]},{"cell_type":"code","metadata":{"id":"fugqP283OG6u","colab":{"base_uri":"https://localhost:8080/"},"outputId":"07ae3f4a-e737-4033-8a07-86c0e8013d58","executionInfo":{"status":"ok","timestamp":1664965790597,"user_tz":-60,"elapsed":16489,"user":{"displayName":"Ahmet Emin Tek","userId":"14855809472179427810"}}},"source":["from sparknlp.base import *\n","from sparknlp.annotator import *\n","from pyspark.ml import Pipeline\n","\n","documentAssembler = DocumentAssembler()\\\n","  .setInputCol(\"text\")\\\n","  .setOutputCol(\"document\")\n","\n","sentenceDetector = SentenceDetectorDLModel.pretrained()\\\n","  .setInputCols([\"document\"])\\\n","  .setOutputCol(\"sentence\")\n","\n","tokenizer = Tokenizer()\\\n","  .setInputCols(\"sentence\")\\\n","  .setOutputCol(\"token\")\n","\n","tokenClassifier = BertForTokenClassification.load(f\"./{PROJECT_NAME}/{MODEL_NAME_TF}_spark_nlp\")\\\n","  .setInputCols(\"token\", \"sentence\")\\\n","  .setOutputCol(\"label\")\\\n","  .setCaseSensitive(True)\n","\n","ner_converter = NerConverter()\\\n","  .setInputCols([\"sentence\",\"token\",\"label\"])\\\n","  .setOutputCol(\"ner_chunk\")\n","\n","\n","pipeline =  Pipeline(\n","    stages=[\n","  documentAssembler,\n","  sentenceDetector,\n","  tokenizer,\n","  tokenClassifier,\n","  ner_converter\n","    ]\n",")\n","\n","p_model = pipeline.fit(spark.createDataFrame(pd.DataFrame({'text': ['']})))"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["sentence_detector_dl download started this may take some time.\n","Approximate size to download 354.6 KB\n","[OK!]\n"]}]},{"cell_type":"code","metadata":{"id":"k808iCsakEfn","executionInfo":{"status":"ok","timestamp":1664965804626,"user_tz":-60,"elapsed":538,"user":{"displayName":"Ahmet Emin Tek","userId":"14855809472179427810"}}},"source":["text = 'A 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus ( T2DM ), one prior episode of HTG-induced pancreatitis three years prior to presentation , associated with an acute hepatitis , and obesity with a body mass index ( BMI ) of 33.5 kg/m2 , presented with a one-week history of polyuria , polydipsia , poor appetite , and vomiting . Two weeks prior to presentation , she was treated with a five-day course of amoxicillin for a respiratory tract infection . She was on metformin , glipizide , and dapagliflozin for T2DM and atorvastatin and gemfibrozil for HTG . She had been on dapagliflozin for six months at the time of presentation . Physical examination on presentation was significant for dry oral mucosa ; significantly , her abdominal examination was benign with no tenderness , guarding , or rigidity . Pertinent laboratory findings on admission were : serum glucose 111 mg/dl , bicarbonate 18 mmol/l , anion gap 20 , creatinine 0.4 mg/dL , triglycerides 508 mg/dL , total cholesterol 122 mg/dL , glycated hemoglobin ( HbA1c ) 10% , and venous pH 7.27 . Serum lipase was normal at 43 U/L . Serum acetone levels could not be assessed as blood samples kept hemolyzing due to significant lipemia . The patient was initially admitted for starvation ketosis , as she reported poor oral intake for three days prior to admission . However , serum chemistry obtained six hours after presentation revealed her glucose was 186 mg/dL , the anion gap was still elevated at 21 , serum bicarbonate was 16 mmol/L , triglyceride level peaked at 2050 mg/dL , and lipase was 52 U/L . The β-hydroxybutyrate level was obtained and found to be elevated at 5.29 mmol/L - the original sample was centrifuged and the chylomicron layer removed prior to analysis due to interference from turbidity caused by lipemia again . The patient was treated with an insulin drip for euDKA and HTG with a reduction in the anion gap to 13 and triglycerides to 1400 mg/dL , within 24 hours . Her euDKA was thought to be precipitated by her respiratory tract infection in the setting of SGLT2 inhibitor use . The patient was seen by the endocrinology service and she was discharged on 40 units of insulin glargine at night , 12 units of insulin lispro with meals , and metformin 1000 mg two times a day . It was determined that all SGLT2 inhibitors should be discontinued indefinitely . She had close follow-up with endocrinology post discharge .'\n","\n","result = p_model.transform(spark.createDataFrame([[text]]).toDF('text'))"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mx1Qio5_LzKx","outputId":"f9945d87-6065-4d01-d3b8-9acf920fae82","executionInfo":{"status":"ok","timestamp":1664965814461,"user_tz":-60,"elapsed":4640,"user":{"displayName":"Ahmet Emin Tek","userId":"14855809472179427810"}}},"source":["result.select(F.explode(F.arrays_zip(result.token.result, result.label.result)).alias(\"cols\")) \\\n","      .select(F.expr(\"cols['0']\").alias(\"token\"),\n","              F.expr(\"cols['1']\").alias(\"label\")).show(50, truncate=False)"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["+------------+---------+\n","|token       |label    |\n","+------------+---------+\n","|A           |O        |\n","|28-year-old |O        |\n","|female      |O        |\n","|with        |O        |\n","|a           |O        |\n","|history     |O        |\n","|of          |O        |\n","|gestational |B-Disease|\n","|diabetes    |I-Disease|\n","|mellitus    |I-Disease|\n","|diagnosed   |O        |\n","|eight       |O        |\n","|years       |O        |\n","|prior       |O        |\n","|to          |O        |\n","|presentation|O        |\n","|and         |O        |\n","|subsequent  |O        |\n","|type        |B-Disease|\n","|two         |I-Disease|\n","|diabetes    |I-Disease|\n","|mellitus    |I-Disease|\n","|(           |O        |\n","|T2DM        |B-Disease|\n","|),          |O        |\n","|one         |O        |\n","|prior       |O        |\n","|episode     |O        |\n","|of          |O        |\n","|HTG-induced |B-Disease|\n","|pancreatitis|I-Disease|\n","|three       |O        |\n","|years       |O        |\n","|prior       |O        |\n","|to          |O        |\n","|presentation|O        |\n","|,           |O        |\n","|associated  |O        |\n","|with        |O        |\n","|an          |O        |\n","|acute       |B-Disease|\n","|hepatitis   |B-Disease|\n","|,           |O        |\n","|and         |O        |\n","|obesity     |B-Disease|\n","|with        |O        |\n","|a           |O        |\n","|body        |O        |\n","|mass        |O        |\n","|index       |O        |\n","+------------+---------+\n","only showing top 50 rows\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pPtJkXRlkHD7","outputId":"47021ff7-541a-4848-d5d9-70cd6ace3dcf","executionInfo":{"status":"ok","timestamp":1664965849794,"user_tz":-60,"elapsed":4486,"user":{"displayName":"Ahmet Emin Tek","userId":"14855809472179427810"}}},"source":["result.select(F.explode(F.arrays_zip(result.ner_chunk.result, result.ner_chunk.metadata)).alias(\"cols\")) \\\n","      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n","              F.expr(\"cols['1']['entity']\").alias(\"ner_label\")).show(truncate=False)"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------------------------+---------+\n","|chunk                        |ner_label|\n","+-----------------------------+---------+\n","|gestational diabetes mellitus|Disease  |\n","|type two diabetes mellitus   |Disease  |\n","|T2DM                         |Disease  |\n","|HTG-induced pancreatitis     |Disease  |\n","|acute                        |Disease  |\n","|hepatitis                    |Disease  |\n","|obesity                      |Disease  |\n","|polyuria                     |Disease  |\n","|polydipsia                   |Disease  |\n","|respiratory tract infection  |Disease  |\n","|T2DM                         |Disease  |\n","|HTG                          |Disease  |\n","|mucosa                       |Disease  |\n","|tenderness                   |Disease  |\n","|lipemia                      |Disease  |\n","|starvation ketosis           |Disease  |\n","|lipemia                      |Disease  |\n","|HTG                          |Disease  |\n","|respiratory tract infection  |Disease  |\n","+-----------------------------+---------+\n","\n"]}]}]}