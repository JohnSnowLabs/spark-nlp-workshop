{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sQFJ6aT4nfhw"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/23.Drug_Normalizer.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 23.Clinical Drug normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotator that transforms text to the format used in the RxNorm and SNOMED standards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes in input annotated documents of type Array\\[AnnotatorType\\](DOCUMENT) and gives as output annotated document of type AnnotatorType.DOCUMENT .\n",
    "\n",
    "Parameters are:\n",
    "- inputCol: input column name string which targets a column of type Array(AnnotatorType.DOCUMENT).\n",
    "- outputCol: output column name string which targets a column of type AnnotatorType.DOCUMENT.\n",
    "- lowercase: whether to convert strings to lowercase. Default is False.\n",
    "- policy: rule to remove patterns from text. Valid policy values are: \"all\", \"abbreviations\", \"dosages\". Defaults is \"all\". \"abbreviation\" policy used to expend common drugs abbreviations, \"dosages\" policy used to convert drugs dosages and values to the standard form (see examples bellow)."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Examples of transformation:\n",
    "    \n",
    "1) \"Sodium Chloride/Potassium Chloride 13bag\", \"Sodium Chloride / Potassium Chloride 13 bag\" - add extra spaces in the form entity\n",
    "\n",
    "2) \"interferon alfa-2b 10 million unit ( 1 ml ) injec\", \"interferon alfa - 2b 10000000 unt ( 1 ml ) injection \" - convert **10 million unit** to the **10000000 unt**, replace **injec** with **injection**\n",
    "\n",
    "3) \"aspirin 10 meq/ 5 ml oral sol\", \"aspirin 2 meq/ml oral solution\" - normalize **10 meq/ 5 ml** to the **2 meq/ml**, extend abbreviation **oral sol** to the **oral solution**\n",
    "\n",
    "4) \"adalimumab 54.5 + 43.2 gm\", \"adalimumab 97700 mg\" - combine **54.5 + 43.2** and normalize **gm** to **mg**\n",
    "\n",
    "5) \"Agnogenic one  half cup\", \"Agnogenic 0.5 oral solution\" - replace **one  half** to the **0.5**, normalize **cup** to the **oral solution**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "MdE588BiY3z1",
    "outputId": "280d3fef-92f6-4dff-e226-466368d1478c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['SECRET', 'SPARK_NLP_LICENSE', 'JSL_OCR_LICENSE', 'AWS_ACCESS_KEY_ID', 'AWS_SECRET_ACCESS_KEY', 'JSL_OCR_SECRET', 'JSL_VERSION', 'JSL_OCR_VERSION', 'PUBLIC_VERSION'])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('workshop_license_keys_Aug2020.json') as f:\n",
    "    license_keys = json.load(f)\n",
    "\n",
    "license_keys.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "F7BN6q-8UNc7",
    "outputId": "e418ea43-61e9-4374-d0df-3c88371235e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "license_keys['JSL_VERSION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'JSL_VERSION': 'jjj',\n",
       " 'PUBLIC_VERSION': 'vvv',\n",
       " 'SECRET': 'xxx',\n",
       " 'SPARK_NLP_LICENSE': 'aaa',\n",
       " 'JSL_OCR_LICENSE': 'bbb',\n",
       " 'AWS_ACCESS_KEY_ID': 'ccc',\n",
       " 'AWS_SECRET_ACCESS_KEY': 'ddd',\n",
       " 'JSL_OCR_SECRET': 'eee'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# template for license_key.json\n",
    "\n",
    "{'JSL_VERSION':'jjj',\n",
    "'PUBLIC_VERSION':'vvv',\n",
    "'SECRET':\"xxx\",\n",
    "'SPARK_NLP_LICENSE': 'aaa',\n",
    "'JSL_OCR_LICENSE': 'bbb',\n",
    "'AWS_ACCESS_KEY_ID':\"ccc\",\n",
    "'AWS_SECRET_ACCESS_KEY':\"ddd\",\n",
    "'JSL_OCR_SECRET':\"eee\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FVFdvGChZDDP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n",
      "openjdk version \"1.8.0_275\"\n",
      "OpenJDK Runtime Environment (build 1.8.0_275-8u275-b01-0ubuntu1~18.04-b01)\n",
      "OpenJDK 64-Bit Server VM (build 25.275-b01, mixed mode)\n",
      "2.6.5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Install java\n",
    "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
    "! java -version\n",
    "\n",
    "secret = license_keys['SECRET']\n",
    "\n",
    "os.environ['SPARK_NLP_LICENSE'] = license_keys['SPARK_NLP_LICENSE']\n",
    "os.environ['AWS_ACCESS_KEY_ID']= license_keys['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = license_keys['AWS_SECRET_ACCESS_KEY']\n",
    "jsl_version = license_keys['JSL_VERSION']\n",
    "version = license_keys['PUBLIC_VERSION']\n",
    "\n",
    "! pip install --ignore-installed -q pyspark==2.4.4\n",
    "\n",
    "! python -m pip install --upgrade spark-nlp-jsl==$jsl_version  --extra-index-url https://pypi.johnsnowlabs.com/$secret\n",
    "\n",
    "! pip install --ignore-installed -q spark-nlp==$version\n",
    "\n",
    "import sparknlp\n",
    "\n",
    "print (sparknlp.version())\n",
    "\n",
    "import json\n",
    "import os\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp_jsl.annotator import *\n",
    "from sparknlp.base import *\n",
    "import sparknlp_jsl\n",
    "\n",
    "spark = sparknlp_jsl.start(secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hx2jxxCaVlOV"
   },
   "outputs": [],
   "source": [
    " # if you want to start the session with custom params as in start function above\n",
    "\n",
    "def start(secret):\n",
    "    builder = SparkSession.builder \\\n",
    "        .appName(\"Spark NLP Licensed\") \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .config(\"spark.driver.memory\", \"16G\") \\\n",
    "        .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "        .config(\"spark.kryoserializer.buffer.max\", \"2000M\") \\\n",
    "        .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.11:\"+version)  \\\n",
    "        .config(\"spark.jars\", \"https://pypi.johnsnowlabs.com/\"+secret+\"/spark-nlp-jsl-\"+jsl_version+\".jar\")\n",
    "      \n",
    "    return builder.getOrCreate()\n",
    "\n",
    "# spark = start(secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "colab_type": "code",
    "id": "7zP-9FcXVzx7",
    "outputId": "d00384ec-22c3-4e18-c20b-7a551516f839"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.43.10:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.7</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark NLP Licensed</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f164d6927f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "1zgsiTxjaiMd",
    "outputId": "1bec6ac0-7236-4222-9f0b-4b185efdeb97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------------------------------------+--------------------------------------------------+\n",
      "|cuid|                                             text|                            target_normalized_text|\n",
      "+----+-------------------------------------------------+--------------------------------------------------+\n",
      "|   A|         Sodium Chloride/Potassium Chloride 13bag|       Sodium Chloride / Potassium Chloride 13 bag|\n",
      "|   B|interferon alfa-2b 10 million unit ( 1 ml ) injec|interferon alfa - 2b 10000000 unt ( 1 ml ) inje...|\n",
      "|   C|                    aspirin 10 meq/ 5 ml oral sol|                    aspirin 2 meq/ml oral solution|\n",
      "+----+-------------------------------------------------+--------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample data\n",
    "data_to_normalize = spark.createDataFrame([\n",
    "            (\"A\", \"Sodium Chloride/Potassium Chloride 13bag\", \"Sodium Chloride / Potassium Chloride 13 bag\"),\n",
    "            (\"B\", \"interferon alfa-2b 10 million unit ( 1 ml ) injec\", \"interferon alfa - 2b 10000000 unt ( 1 ml ) injection\"),\n",
    "            (\"C\", \"aspirin 10 meq/ 5 ml oral sol\", \"aspirin 2 meq/ml oral solution\")\n",
    "        ]).toDF(\"cuid\", \"text\", \"target_normalized_text\")\n",
    "\n",
    "data_to_normalize.show(truncate=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "r2Yr96wrWPUH",
    "outputId": "41a8c44e-fdf5-4bcd-ce9b-164f940c32ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------------+--------------------+\n",
      "|            document|target_normalized_text| all_normalized_text|\n",
      "+--------------------+----------------------+--------------------+\n",
      "|[[document, 0, 39...|  Sodium Chloride /...|Sodium Chloride /...|\n",
      "|[[document, 0, 48...|  interferon alfa -...|interferon alfa -...|\n",
      "|[[document, 0, 28...|  aspirin 2 meq/ml ...|aspirin 2 meq/ml ...|\n",
      "+--------------------+----------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Annotator that transforms a text column from dataframe into normalized text (with all policy)\n",
    "\n",
    "document_assembler = DocumentAssembler()\\\n",
    "  .setInputCol(\"text\")\\\n",
    "  .setOutputCol(\"document\")\n",
    "\n",
    "policy = \"all\"\n",
    "\n",
    "drug_normalizer = DrugNormalizer() \\\n",
    "    .setInputCols(\"document\") \\\n",
    "    .setOutputCol(\"document_normalized\") \\\n",
    "    .setPolicy(policy)\n",
    "\n",
    "drug_normalizer_pipeline = \\\n",
    "    Pipeline().setStages([document_assembler, drug_normalizer])\n",
    "\n",
    "ds = drug_normalizer_pipeline.fit(data_to_normalize).transform(data_to_normalize)\n",
    "\n",
    "ds = ds.selectExpr(\"document\", \"target_normalized_text\", \"explode(document_normalized.result) as all_normalized_text\")\n",
    "ds.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------+----------------------------------------------------+-----------------------------------------------------+\n",
      "|                              target_normalized_text|                                 all_normalized_text|                                 abbr_normalized_text|\n",
      "+----------------------------------------------------+----------------------------------------------------+-----------------------------------------------------+\n",
      "|         Sodium Chloride / Potassium Chloride 13 bag|         Sodium Chloride / Potassium Chloride 13 bag|             Sodium Chloride/Potassium Chloride 13bag|\n",
      "|interferon alfa - 2b 10000000 unt ( 1 ml ) injection|interferon alfa - 2b 10000000 unt ( 1 ml ) injection|interferon alfa-2b 10 million unit ( 1 ml ) injection|\n",
      "|                      aspirin 2 meq/ml oral solution|                      aspirin 2 meq/ml oral solution|                   aspirin 10 meq/ 5 ml oral solution|\n",
      "+----------------------------------------------------+----------------------------------------------------+-----------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Annotator that transforms a text column from dataframe into normalized text (with abbreviations only policy)\n",
    "\n",
    "policy = \"abbreviations\"\n",
    "\n",
    "drug_normalizer_abb = DrugNormalizer() \\\n",
    "    .setInputCols(\"document\") \\\n",
    "    .setOutputCol(\"document_normalized_abbreviations\") \\\n",
    "    .setPolicy(policy)\n",
    "\n",
    "ds = drug_normalizer_abb.transform(ds)\n",
    "\n",
    "ds = ds.selectExpr(\"document\", \"target_normalized_text\", \"all_normalized_text\", \"explode(document_normalized_abbreviations.result) as abbr_normalized_text\")\n",
    "ds.select(\"target_normalized_text\", \"all_normalized_text\", \"abbr_normalized_text\").show(truncate=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "JtsRZL_ybwhb",
    "outputId": "8e34e5ee-9b3a-4857-ad72-2708f89a5c8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------+----------------------------------------------------+------------------------------------------------+\n",
      "|                              target_normalized_text|                                 all_normalized_text|                             dos_normalized_text|\n",
      "+----------------------------------------------------+----------------------------------------------------+------------------------------------------------+\n",
      "|         Sodium Chloride / Potassium Chloride 13 bag|         Sodium Chloride / Potassium Chloride 13 bag|     Sodium Chloride / Potassium Chloride 13 bag|\n",
      "|interferon alfa - 2b 10000000 unt ( 1 ml ) injection|interferon alfa - 2b 10000000 unt ( 1 ml ) injection|interferon alfa - 2b 10000000 unt ( 1 ml ) injec|\n",
      "|                      aspirin 2 meq/ml oral solution|                      aspirin 2 meq/ml oral solution|                       aspirin 2 meq/ml oral sol|\n",
      "+----------------------------------------------------+----------------------------------------------------+------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Transform a text column from dataframe into normalized text (with dosages only policy)\n",
    "\n",
    "policy = \"dosages\"\n",
    "\n",
    "drug_normalizer_abb = DrugNormalizer() \\\n",
    "    .setInputCols(\"document\") \\\n",
    "    .setOutputCol(\"document_normalized_dosages\") \\\n",
    "    .setPolicy(policy)\n",
    "\n",
    "ds = drug_normalizer_abb.transform(ds)\n",
    "\n",
    "ds.selectExpr(\"target_normalized_text\", \"all_normalized_text\", \"explode(document_normalized_dosages.result) as dos_normalized_text\").show(truncate=1000)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply normalizer only on NER chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[OK!]\n",
      "ner_posology_large download started this may take some time.\n",
      "Approximate size to download 13.8 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "documentAssembler = DocumentAssembler()\\\n",
    "  .setInputCol(\"text\")\\\n",
    "  .setOutputCol(\"document\")\n",
    " \n",
    "# Sentence Detector annotator, processes various sentences per line\n",
    "sentenceDetector = SentenceDetector()\\\n",
    "  .setInputCols([\"document\"])\\\n",
    "  .setOutputCol(\"sentence\")\n",
    " \n",
    "# Tokenizer splits words in a relevant format for NLP\n",
    "tokenizer = Tokenizer()\\\n",
    "  .setInputCols([\"sentence\"])\\\n",
    "  .setOutputCol(\"token\")\\\n",
    "  .addSplitChars(\";\")\n",
    "  \n",
    "# Clinical word embeddings trained on PubMED dataset\n",
    "word_embeddings = WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n",
    "  .setInputCols([\"sentence\", \"token\"])\\\n",
    "  .setOutputCol(\"embeddings\")\n",
    " \n",
    "# Extract entities with NER model posology\n",
    "posology_ner = NerDLModel.pretrained(\"ner_posology_large\", \"en\", \"clinical/models\") \\\n",
    "  .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "  .setOutputCol(\"ner_posology\")\n",
    "  \n",
    "# Group extracted entities into the chunks\n",
    "ner_converter = NerConverter()\\\n",
    "  .setInputCols([\"sentence\", \"token\", \"ner_posology\"])\\\n",
    "  .setOutputCol(\"ner_chunk_posology\")\n",
    " \n",
    "# Convert extracted entities to the doc with chunks in metadata\n",
    "c2doc = Chunk2Doc().setInputCols(\"ner_chunk_posology\").setOutputCol(\"chunk_doc\") \n",
    "\n",
    "# Transform a chunk document into normalized text\n",
    "drug_normalizer = DrugNormalizer() \\\n",
    "    .setInputCols(\"chunk_doc\") \\\n",
    "    .setOutputCol(\"document_normalized_dosages\")\n",
    "\n",
    "nlpPipeline = Pipeline(stages=[\n",
    "    documentAssembler, \n",
    "    sentenceDetector,\n",
    "    tokenizer,\n",
    "    word_embeddings,\n",
    "    posology_ner,\n",
    "    ner_converter,\n",
    "    c2doc,\n",
    "    drug_normalizer])\n",
    "\n",
    "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "model = nlpPipeline.fit(empty_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget -q https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/pubmed/pubmed_sample_text_small.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------+\n",
      "|                                              text|\n",
      "+--------------------------------------------------+\n",
      "|The human KCNJ9 (Kir 3.3, GIRK3) is a member of...|\n",
      "|BACKGROUND: At present, it is one of the most i...|\n",
      "|OBJECTIVE: To investigate the relationship betw...|\n",
      "|Combined EEG/fMRI recording has been used to lo...|\n",
      "|Kohlschutter syndrome is a rare neurodegenerati...|\n",
      "|Statistical analysis of neuroimages is commonly...|\n",
      "|The synthetic DOX-LNA conjugate was characteriz...|\n",
      "|Our objective was to compare three different me...|\n",
      "|We conducted a phase II study to assess the eff...|\n",
      "|\"\"\"Monomeric sarcosine oxidase (MSOX) is a flav...|\n",
      "|We presented the tachinid fly Exorista japonica...|\n",
      "|The literature dealing with the water conductin...|\n",
      "|A novel approach to synthesize chitosan-O-isopr...|\n",
      "|An HPLC-ESI-MS-MS method has been developed for...|\n",
      "|The localizing and lateralizing values of eye a...|\n",
      "|OBJECTIVE: To evaluate the effectiveness and ac...|\n",
      "|For the construction of new combinatorial libra...|\n",
      "|We report the results of a screen for genetic a...|\n",
      "|Intraparenchymal pericatheter cyst is rarely re...|\n",
      "|It is known that patients with Klinefelter's sy...|\n",
      "+--------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "pubMedDF = spark.read\\\n",
    "                .option(\"header\", \"true\")\\\n",
    "                .csv(\"pubmed_sample_text_small.csv\")\\\n",
    "                \n",
    "pubMedDF.show(truncate=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.transform(pubMedDF.limit(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------+\n",
      "|                                            result|\n",
      "+--------------------------------------------------+\n",
      "|[G - protein - activated inwardly rectifying po...|\n",
      "|[anthracyclines, taxanes, usefulnessof, vinorel...|\n",
      "|                                                []|\n",
      "|                                                []|\n",
      "|                                                []|\n",
      "|                   [testsperformed, statisticfrom]|\n",
      "|[synthetic DOX - LNA conjugate, tetrazolium dye...|\n",
      "|[trandolapril, losartan, placebo, 2, mgtrandola...|\n",
      "|[ofirinotecan, cisplatin, chemotherapy, 5 - flu...|\n",
      "|[\"\"\"Monomeric sarcosine oxidase ( MSOX ), sarco...|\n",
      "|                                                []|\n",
      "|                                   [fromconfusion]|\n",
      "|                                             [d4T]|\n",
      "|[dihydrotanshin1 I , cryptotanshin1, tanshin1 I...|\n",
      "|                                                []|\n",
      "| [misoprostol, Expectantmanagement, ofmisoprostol]|\n",
      "|                              [forantitumor drugs]|\n",
      "|              [ratiosin, arsenic pharmacogenetics]|\n",
      "|                                                []|\n",
      "|     [Klinefelter'ssyndrome, elevatedgonadotropin]|\n",
      "+--------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.select('document_normalized_dosages.result').show(truncate=50)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "7.Clinical_NER_Chunk_Merger.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
