{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sQFJ6aT4nfhw"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/7.Clinical_NER_Chunk_Merger.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clinical NER Chunk Merger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "MdE588BiY3z1",
    "outputId": "280d3fef-92f6-4dff-e226-466368d1478c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['JSL_VERSION', 'PUBLIC_VERSION', 'SECRET', 'SPARK_NLP_LICENSE', 'AWS_ACCESS_KEY_ID', 'AWS_SECRET_ACCESS_KEY', 'JSL_OCR_SECRET', 'SPARK_OCR_LICENSE'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('workshop_license_keys_Aug2020.json') as f:\n",
    "    license_keys = json.load(f)\n",
    "\n",
    "license_keys.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "F7BN6q-8UNc7",
    "outputId": "e418ea43-61e9-4374-d0df-3c88371235e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.4rc3'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "license_keys['JSL_VERSION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'JSL_VERSION': 'jjj',\n",
       " 'PUBLIC_VERSION': 'vvv',\n",
       " 'SECRET': 'xxx',\n",
       " 'SPARK_NLP_LICENSE': 'aaa',\n",
       " 'JSL_OCR_LICENSE': 'bbb',\n",
       " 'AWS_ACCESS_KEY_ID': 'ccc',\n",
       " 'AWS_SECRET_ACCESS_KEY': 'ddd',\n",
       " 'JSL_OCR_SECRET': 'eee'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# template for license_key.json\n",
    "\n",
    "{'JSL_VERSION':'jjj',\n",
    "'PUBLIC_VERSION':'vvv',\n",
    "'SECRET':\"xxx\",\n",
    "'SPARK_NLP_LICENSE': 'aaa',\n",
    "'JSL_OCR_LICENSE': 'bbb',\n",
    "'AWS_ACCESS_KEY_ID':\"ccc\",\n",
    "'AWS_SECRET_ACCESS_KEY':\"ddd\",\n",
    "'JSL_OCR_SECRET':\"eee\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FVFdvGChZDDP"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Install java\n",
    "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
    "! java -version\n",
    "\n",
    "secret = license_keys['SECRET']\n",
    "\n",
    "os.environ['SPARK_NLP_LICENSE'] = license_keys['SPARK_NLP_LICENSE']\n",
    "os.environ['SPARK_OCR_LICENSE'] = license_keys['SPARK_OCR_LICENSE']\n",
    "os.environ['AWS_ACCESS_KEY_ID']= license_keys['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = license_keys['AWS_SECRET_ACCESS_KEY']\n",
    "jsl_version = license_keys['JSL_VERSION']\n",
    "version = license_keys['PUBLIC_VERSION']\n",
    "\n",
    "! pip install --ignore-installed -q pyspark==2.4.4\n",
    "\n",
    "! python -m pip install --upgrade spark-nlp-jsl==$jsl_version  --extra-index-url https://pypi.johnsnowlabs.com/$secret\n",
    "\n",
    "! pip install --ignore-installed -q spark-nlp==$version\n",
    "\n",
    "import sparknlp\n",
    "\n",
    "print (sparknlp.version())\n",
    "\n",
    "import json\n",
    "import os\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp_jsl.annotator import *\n",
    "from sparknlp.base import *\n",
    "import sparknlp_jsl\n",
    "\n",
    "spark = sparknlp_jsl.start(secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hx2jxxCaVlOV"
   },
   "outputs": [],
   "source": [
    " # if you want to start the session with custom params as in start function above\n",
    "\n",
    "def start(secret):\n",
    "    builder = SparkSession.builder \\\n",
    "        .appName(\"Spark NLP Licensed\") \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .config(\"spark.driver.memory\", \"16G\") \\\n",
    "        .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "        .config(\"spark.kryoserializer.buffer.max\", \"2000M\") \\\n",
    "        .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.11:\"+version) \\\n",
    "        .config(\"spark.jars\", \"https://pypi.johnsnowlabs.com/\"+secret+\"/spark-nlp-jsl-\"+jsl_version+\".jar\")\n",
    "      \n",
    "    return builder.getOrCreate()\n",
    "\n",
    "\n",
    "#spark = start(secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "colab_type": "code",
    "id": "7zP-9FcXVzx7",
    "outputId": "d00384ec-22c3-4e18-c20b-7a551516f839"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://1bb05a133e51:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark NLP Licensed</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7efcbbd89320>"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "1zgsiTxjaiMd",
    "outputId": "1bec6ac0-7236-4222-9f0b-4b185efdeb97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------------------------------------+\n",
      "| id|                                              text|\n",
      "+---+--------------------------------------------------+\n",
      "|  1|A 63-year-old man presents to the hospital with...|\n",
      "+---+--------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample data\n",
    "data_chunk_merge = spark.createDataFrame([\n",
    "  (1,\"\"\"A 63-year-old man presents to the hospital with a history of recurrent infections that include cellulitis, pneumonias, and upper respiratory tract infections. He reports subjective fevers at home along with unintentional weight loss and occasional night sweats. The patient has a remote history of arthritis, which was diagnosed approximately 20 years ago and treated intermittently with methotrexate (MTX) and prednisone. On physical exam, he is found to be febrile at 102Â°F, rather cachectic, pale, and have hepatosplenomegaly. Several swollen joints that are tender to palpation and have decreased range of motion are also present. His laboratory values show pancytopenia with the most severe deficiency in neutrophils.\n",
    "\"\"\")]).toDF(\"id\",\"text\")\n",
    "\n",
    "data_chunk_merge.show(truncate=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "r2Yr96wrWPUH",
    "outputId": "41a8c44e-fdf5-4bcd-ce9b-164f940c32ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[OK!]\n",
      "ner_deid_large download started this may take some time.\n",
      "Approximate size to download 13.9 MB\n",
      "[OK!]\n",
      "ner_bionlp download started this may take some time.\n",
      "Approximate size to download 13.9 MB\n",
      "[OK!]\n",
      "ner_jsl download started this may take some time.\n",
      "Approximate size to download 14 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "# Annotator that transforms a text column from dataframe into an Annotation ready for NLP\n",
    "\n",
    "documentAssembler = DocumentAssembler()\\\n",
    "  .setInputCol(\"text\")\\\n",
    "  .setOutputCol(\"document\")\n",
    "\n",
    "# Sentence Detector annotator, processes various sentences per line\n",
    "sentenceDetector = SentenceDetector()\\\n",
    "  .setInputCols([\"document\"])\\\n",
    "  .setOutputCol(\"sentence\")\n",
    "\n",
    "# Tokenizer splits words in a relevant format for NLP\n",
    "tokenizer = Tokenizer()\\\n",
    "  .setInputCols([\"sentence\"])\\\n",
    "  .setOutputCol(\"token\")\n",
    "\n",
    "# Clinical word embeddings trained on PubMED dataset\n",
    "word_embeddings = WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n",
    "  .setInputCols([\"sentence\", \"token\"])\\\n",
    "  .setOutputCol(\"embeddings\")\n",
    "\n",
    "# NER model trained on i2b2 (sampled from MIMIC) dataset\n",
    "clinical_ner = NerDLModel.pretrained(\"ner_deid_large\", \"en\", \"clinical/models\") \\\n",
    "  .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "  .setOutputCol(\"clinical_ner\")\n",
    "\n",
    "clinical_ner_converter = NerConverter() \\\n",
    "  .setInputCols([\"sentence\", \"token\", \"clinical_ner\"]) \\\n",
    "  .setOutputCol(\"clinical_ner_chunk\")\n",
    "\n",
    "# Cancer Genetics NER\n",
    "bionlp_ner = NerDLModel.pretrained(\"ner_bionlp\", \"en\", \"clinical/models\") \\\n",
    "  .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "  .setOutputCol(\"bionlp_ner\")\n",
    "\n",
    "bionlp_ner_converter = NerConverter() \\\n",
    "  .setInputCols([\"sentence\", \"token\", \"bionlp_ner\"]) \\\n",
    "  .setOutputCol(\"bionlp_ner_chunk\")\n",
    "\n",
    "chunk_merger_1 = ChunkMergeApproach()\\\n",
    "  .setInputCols('clinical_ner_chunk', \"bionlp_ner_chunk\")\\\n",
    "  .setOutputCol('bionlp_ner_chunk')\n",
    "\n",
    "# internal clinical NER (general terms)\n",
    "jsl_ner = NerDLModel.pretrained(\"ner_jsl\", \"en\", \"clinical/models\") \\\n",
    "  .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "  .setOutputCol(\"jsl_ner\")\n",
    "\n",
    "jsl_ner_converter = NerConverter() \\\n",
    "  .setInputCols([\"sentence\", \"token\", \"jsl_ner\"]) \\\n",
    "  .setOutputCol(\"jsl_ner_chunk\")\n",
    "\n",
    "chunk_merger_2 = ChunkMergeApproach()\\\n",
    "  .setInputCols('bionlp_ner_chunk', \"jsl_ner_chunk\")\\\n",
    "  .setOutputCol('final_ner_chunk')\n",
    "\n",
    "nlpPipeline = Pipeline(stages=[\n",
    "    documentAssembler, \n",
    "    sentenceDetector,\n",
    "    tokenizer,\n",
    "    word_embeddings,\n",
    "    clinical_ner,\n",
    "    clinical_ner_converter,\n",
    "    bionlp_ner,\n",
    "    bionlp_ner_converter,\n",
    "    chunk_merger_1,\n",
    "    jsl_ner,\n",
    "    jsl_ner_converter,\n",
    "    chunk_merger_2])\n",
    "\n",
    "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "model = nlpPipeline.fit(empty_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "JtsRZL_ybwhb",
    "outputId": "8e34e5ee-9b3a-4857-ad72-2708f89a5c8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_deid_large download started this may take some time.\n",
      "Approximate size to download 13.9 MB\n",
      "[OK!]\n",
      "ner_bionlp download started this may take some time.\n",
      "Approximate size to download 13.9 MB\n",
      "[OK!]\n",
      "deid_chunk bio_chunk bio_chunk\n",
      "ner_jsl download started this may take some time.\n",
      "Approximate size to download 14 MB\n",
      "[OK!]\n",
      "bio_chunk jsl_chunk jsl_chunk\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "ners_to_merge = OrderedDict({\"ner_deid_large\":\"deid\", \"ner_bionlp\":\"bio\", \"ner_jsl\":\"jsl\"})\n",
    "\n",
    "# Build the graph\n",
    "ner_pl = []\n",
    "for ner, out in ners_to_merge.items():\n",
    "    first = len(ner_pl)==0\n",
    "    ner_pl.append(NerDLModel.pretrained(ner,\"en\",\"clinical/models\").setInputCols(\"sentence\",\"token\",\"embs\").setOutputCol(out))\n",
    "    ner_pl.append(NerConverter().setInputCols(\"sentence\",\"token\",out).setOutputCol(out+\"_chunk\"))\n",
    "    if not first:\n",
    "      print (prev+\"_chunk\", out+\"_chunk\", out+\"_chunk\")\n",
    "      ner_pl.append(ChunkMergeApproach().setInputCols(prev+\"_chunk\", out+\"_chunk\").setOutputCol(out+\"_chunk\"))\n",
    "    prev = out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JMI6QDcunfjI"
   },
   "outputs": [],
   "source": [
    "merged_data = model.transform(data_chunk_merge).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "h3zcTo_GgHoO",
    "outputId": "7fd10be8-c788-4a3f-99b2-dce3fa99bbff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+----------------------------------+----------------------+\n",
      "| id|begin|end|                             chunk|                entity|\n",
      "+---+-----+---+----------------------------------+----------------------+\n",
      "|  1|    2| 12|                       63-year-old|                   AGE|\n",
      "|  1|   14| 16|                               man|              Organism|\n",
      "|  1|   61| 69|                         recurrent|              Modifier|\n",
      "|  1|   95|104|                        cellulitis|             Diagnosis|\n",
      "|  1|  107|116|                        pneumonias|             Diagnosis|\n",
      "|  1|  123|156|upper respiratory tract infections|             Diagnosis|\n",
      "|  1|  159|160|                                He|                Gender|\n",
      "|  1|  170|179|                        subjective|              Modifier|\n",
      "|  1|  181|186|                            fevers|          Symptom_Name|\n",
      "|  1|  237|246|                        occasional|              Modifier|\n",
      "|  1|  248|259|                      night sweats|          Symptom_Name|\n",
      "|  1|  266|272|                           patient|              Organism|\n",
      "|  1|  298|306|                         arthritis|             Diagnosis|\n",
      "|  1|  343|344|                                20|                   Age|\n",
      "|  1|  388|399|                      methotrexate|       Simple_chemical|\n",
      "|  1|  402|405|                              MTX)|             Drug_Name|\n",
      "|  1|  411|420|                        prednisone|       Simple_chemical|\n",
      "|  1|  441|442|                                he|                Gender|\n",
      "|  1|  459|465|                           febrile|          Symptom_Name|\n",
      "|  1|  510|527|                hepatosplenomegaly|          Symptom_Name|\n",
      "|  1|  530|536|                           Several|              Modifier|\n",
      "|  1|  538|551|                    swollen joints|Multi-tissue_structure|\n",
      "|  1|  635|637|                               His|                Gender|\n",
      "|  1|  662|673|                      pancytopenia|          Symptom_Name|\n",
      "|  1|  710|720|                       neutrophils|                  Cell|\n",
      "+---+-----+---+----------------------------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "result_df = merged_data.select('id',F.explode('final_ner_chunk').alias(\"cols\")) \\\n",
    ".select('id',F.expr(\"cols.begin\").alias(\"begin\"),\n",
    "        F.expr(\"cols.end\").alias(\"end\"),\n",
    "        F.expr(\"cols.result\").alias(\"chunk\"),\n",
    "        F.expr(\"cols.metadata.entity\").alias(\"entity\"))\n",
    "\n",
    "result_df.show(50, truncate=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NYsZ3KsCnw0y"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "7.Clinical_NER_Chunk_Merger.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
