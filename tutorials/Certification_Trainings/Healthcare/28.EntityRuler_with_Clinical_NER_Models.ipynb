{"cells":[{"cell_type":"markdown","metadata":{"id":"6KvNW4MU5rrF","outputId":"d5299652-c828-48d3-e7ee-c10c9f733586"},"source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n","\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/28.EntityRuler_with_Clinical_NER_Models.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"P_GiBDlsja-o"},"source":["# EntityRuler\n","\n","`EntityRuler` fits to match exact strings or regex patterns provided in a file against a document and assigns them a named entity. The definitions can contain any number of named entities.\n","\n","There are multiple ways and formats to set the extraction resource. It is possible to set it either as a “JSON”, “JSONL” or “CSV” file.\n","\n","This notebook showcases the `EntityRuler` annotator with the Healthcare library. For detailed usage of `EntityRuler` itself please check [here](https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/e3d3d942a75752d8040f73538c7f8ce5430e80d9/jupyter/training/english/entity-ruler).\n","\n","**For the licensed users, `ContextualParser` is a more capable annotator. You can check [here](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings_JSL/Healthcare/1.2.Contextual_Parser_Rule_Based_NER.ipynb) for more info on `ContextualParser`.**\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"_JKVMATIFVvR"},"source":["## Colab Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"166_oTSpJKGG"},"outputs":[],"source":["import json, os\n","from google.colab import files\n","\n","if 'spark_jsl.json' not in os.listdir():\n","  license_keys = files.upload()\n","  os.rename(list(license_keys.keys())[0], 'spark_jsl.json')\n","\n","with open('spark_jsl.json') as f:\n","    license_keys = json.load(f)\n","\n","# Defining license key-value pairs as local variables\n","locals().update(license_keys)\n","os.environ.update(license_keys)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pza56D-ublfg"},"outputs":[],"source":["# Installing pyspark and spark-nlp\n","! pip install --upgrade -q pyspark==3.3.0 spark-nlp==$PUBLIC_VERSION\n","\n","# Installing Spark NLP Healthcare\n","! pip install --upgrade -q spark-nlp-jsl==$JSL_VERSION  --extra-index-url https://pypi.johnsnowlabs.com/$SECRET"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":254},"id":"NY16q61Rblfe","outputId":"b7e28066-71e6-492d-eea1-0fdaf14f5119","executionInfo":{"status":"ok","timestamp":1680624164014,"user_tz":-180,"elapsed":30449,"user":{"displayName":"Halil SAGLAMLAR","userId":"07259164328506563794"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Spark NLP Version : 4.3.2\n","Spark NLP_JSL Version : 4.3.2\n"]},{"output_type":"execute_result","data":{"text/plain":["<pyspark.sql.session.SparkSession at 0x7fc669149fa0>"],"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://ef77839d4fd0:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.3.0</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>Spark NLP Licensed</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "]},"metadata":{},"execution_count":3}],"source":["import sparknlp\n","import sparknlp_jsl\n","\n","from sparknlp.base import *\n","from sparknlp.annotator import *\n","from sparknlp_jsl.annotator import *\n","\n","from pyspark.sql import SparkSession\n","from pyspark.ml import Pipeline, PipelineModel\n","\n","import pandas as pd\n","\n","params = {\"spark.driver.memory\":\"16G\",\n","          \"spark.kryoserializer.buffer.max\":\"2000M\",\n","          \"spark.driver.maxResultSize\":\"2000M\"}\n","\n","spark = sparknlp_jsl.start(license_keys['SECRET'],params=params)\n","\n","print(\"Spark NLP Version :\", sparknlp.version())\n","print(\"Spark NLP_JSL Version :\", sparknlp_jsl.version())\n","\n","spark"]},{"cell_type":"markdown","metadata":{"id":"3xvioX5cFhe3"},"source":["## Define EntityRuler"]},{"cell_type":"markdown","metadata":{"id":"FlGbrPLWFRQm"},"source":["Now let's define keyword patterns for entities to use in `EntityRuler`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OmOTCKpV84Xs"},"outputs":[],"source":["import json\n","\n","person = [\n","          {\n","            \"label\": \"Person\",\n","            \"patterns\": [\"Jon\", \"John\", \"John Snow\", \"Jon Snow\"]\n","          },\n","          {\n","            \"label\": \"Person\",\n","            \"patterns\": [\"Eddard\", \"Eddard Stark\"]\n","          },\n","          {\n","            \"label\": \"Clinical_Department\",\n","            \"patterns\": [\"St. John Hospital\", \"St. Jon Hospital\" ]\n","          },\n","         ]\n","\n","with open('./keywords.json', 'w') as jsonfile:\n","    json.dump(person, jsonfile)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZQ8I9iPPvpS_"},"outputs":[],"source":["def get_ner_table(result, column):\n","    \"\"\" \n","    Helper function to get a ner table in Pandas dataframe from result\n","    \"\"\"\n","    out = result.select(F.explode(F.arrays_zip(eval(f\"result.{column}.result\"),\n","                                               eval(f\"result.{column}.begin\"),\n","                                               eval(f\"result.{column}.end\"),\n","                                               eval(f\"result.{column}.metadata\"))).alias(\"cols\")) \\\n","      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n","              F.expr(\"cols['3']['entity']\").alias(\"ner_label\"),\n","              F.expr(\"cols['3']['sentence']\").alias(\"sentence\"),\n","              F.expr(\"cols['1']\").alias(\"begin\"),\n","              F.expr(\"cols['2']\").alias(\"end\"))\n","      \n","    return out.toPandas()\n","      "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tRyju8D-6XJ1"},"outputs":[],"source":["# Define an EntityRule with EntityRulerApproach\n","entity_ruler = EntityRulerApproach() \\\n","                  .setInputCols([\"document\"]) \\\n","                  .setOutputCol(\"entity\") \\\n","                  .setPatternsResource(\"./keywords.json\")\\\n","                  .setCaseSensitive(False)\n","\n","data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n","\n","entity_ruler_model = entity_ruler.fit(data)\n","\n","# Save EntityRule model\n","entity_ruler_model.write().overwrite().save(\"tmp_entity_ruler_model\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jtMK0ZekjSeB"},"outputs":[],"source":["document_assembler = DocumentAssembler()\\\n","                        .setInputCol(\"text\")\\\n","                        .setOutputCol(\"document\")\n","\n","sentence_detector = SentenceDetector()\\\n","                       .setInputCols(\"document\")\\\n","                       .setOutputCol(\"sentence\")\n","\n","# Extracting entities using the saved model with EntityRulerModel\n","entity_ruler_loaded = EntityRulerModel().load(\"tmp_entity_ruler_model\")\\\n","                       .setInputCols([\"sentence\"]) \\\n","                       .setOutputCol(\"entity_ruler\") \\\n","\n","\n","# Build Pipeline\n","pipeline = Pipeline(stages=[document_assembler,\n","                            sentence_detector, \n","                            entity_ruler_loaded])\n","\n","\n","pipeline_model = pipeline.fit(data)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d7qy0hxlkX3u"},"outputs":[],"source":["text=\"Lord Eddard Stark was the head of St. John Hospital. John Snow lives in Winterfell and is a doctor at St. john Hospital.\"\n","\n","data = spark.createDataFrame([[text]]).toDF(\"text\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wr22PwW5B9Rg","outputId":"da6f4b34-573b-4b6d-84a1-43b267e05e63","executionInfo":{"status":"ok","timestamp":1680624184684,"user_tz":-180,"elapsed":11233,"user":{"displayName":"Halil SAGLAMLAR","userId":"07259164328506563794"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|entity_ruler                                                                                                                                                                                                                                                                                                              |\n","+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|[{chunk, 5, 16, Eddard Stark, {entity -> Person, sentence -> 0}, []}, {chunk, 34, 50, St. John Hospital, {entity -> Clinical_Department, sentence -> 0}, []}, {chunk, 53, 61, John Snow, {entity -> Person, sentence -> 1}, []}, {chunk, 102, 118, St. john Hospital, {entity -> Clinical_Department, sentence -> 1}, []}]|\n","+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","\n"]}],"source":["result = pipeline_model.transform(data).cache()\n","\n","result.select(result.entity_ruler).show(truncate=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":175},"id":"SlMAE9ZayuZ7","outputId":"4501ccb4-bec6-4d25-ca5e-c8b7a4cda142","executionInfo":{"status":"ok","timestamp":1680624186216,"user_tz":-180,"elapsed":1546,"user":{"displayName":"Halil SAGLAMLAR","userId":"07259164328506563794"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["               chunk            ner_label sentence  begin  end\n","0       Eddard Stark               Person        0      5   16\n","1  St. John Hospital  Clinical_Department        0     34   50\n","2          John Snow               Person        1     53   61\n","3  St. john Hospital  Clinical_Department        1    102  118"],"text/html":["\n","  <div id=\"df-a0ab7834-3aae-4ce9-905c-35ad3c1d3b10\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>chunk</th>\n","      <th>ner_label</th>\n","      <th>sentence</th>\n","      <th>begin</th>\n","      <th>end</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Eddard Stark</td>\n","      <td>Person</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>St. John Hospital</td>\n","      <td>Clinical_Department</td>\n","      <td>0</td>\n","      <td>34</td>\n","      <td>50</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>John Snow</td>\n","      <td>Person</td>\n","      <td>1</td>\n","      <td>53</td>\n","      <td>61</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>St. john Hospital</td>\n","      <td>Clinical_Department</td>\n","      <td>1</td>\n","      <td>102</td>\n","      <td>118</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0ab7834-3aae-4ce9-905c-35ad3c1d3b10')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a0ab7834-3aae-4ce9-905c-35ad3c1d3b10 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a0ab7834-3aae-4ce9-905c-35ad3c1d3b10');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":10}],"source":["get_ner_table(result, \"entity_ruler\")"]},{"cell_type":"markdown","metadata":{"id":"DHWEGT7K8_MB"},"source":["## Combining EntityRuler with Pretrained NER Models\n","\n","\n","Now we will use pretrained NER models with the `EntityRuler` annotator. Sometimes NER models fail to extract some chunks or some entity labels may be missing in that model. In that case, `EntityRuler` can be used to enhance or improve the NER coverage like `ContextualParser`. In the example below we will add `ID`, `Female`, and `Male` entities that are not a part of a ner_jsl NER model.  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tTqvYXGb00Yb"},"outputs":[],"source":["entities =\"\"\" \n","[   \n","    {\n","        \"id\": \"person\",\n","        \"label\": \"Female\",\n","        \"patterns\": [\"she\", \"her\", \"girl\", \"woman\", \"women\", \"womanish\", \"womanlike\", \"womanly\", \"madam\", \"madame\", \"senora\", \"lady\", \"miss\", \"girlfriend\", \"wife\", \"bride\", \"misses\", \"mrs.\", \"female\"],\n","        \"regex\": false\n","    },\n","    {\n","        \"id\": \"person\",\n","        \"label\": \"Male\",\n","        \"patterns\": [\"he\", \"him\", \"masculine\", \"boy\", \"father\", \"guy\", \"macho\", \"brother\", \"fellow\", \"gent\", \"gentleman\", \"grandfather\", \"husband\", \"sir\", \"son\", \"manful\", \"manlike\", \"manly\"],\n","        \"regex\": false\n","    },\n","    {\n","        \"id\": \"id-regex\",\n","        \"label\": \"ID\",\n","        \"patterns\": [\"[0-9]{7}\"],\n","        \"regex\": true\n","    }\n","]\"\"\"\n","\n","\n","patterns_obj = json.loads(entities)\n","\n","with open('./entities.json', 'w') as jsonfile:\n","    json.dump(patterns_obj, jsonfile)"]},{"cell_type":"markdown","metadata":{"id":"DMUCdd8AdOw2"},"source":["When defining a regex pattern in `EntityRuler`, we need to define `Tokenizer` annotator in the pipeline."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1BGExTU6547O","outputId":"bb5d28c9-c74b-4507-80f7-29732dffc9e2","executionInfo":{"status":"ok","timestamp":1680624282604,"user_tz":-180,"elapsed":96392,"user":{"displayName":"Halil SAGLAMLAR","userId":"07259164328506563794"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["sentence_detector_dl download started this may take some time.\n","Approximate size to download 354.6 KB\n","[OK!]\n","embeddings_clinical download started this may take some time.\n","Approximate size to download 1.6 GB\n","[OK!]\n","ner_jsl download started this may take some time.\n","[OK!]\n"]}],"source":["document_assembler = DocumentAssembler()\\\n","                .setInputCol(\"text\")\\\n","                .setOutputCol(\"document\")\n","\n","sentence_detector = SentenceDetectorDLModel.pretrained()\\\n","                .setInputCols(\"document\")\\\n","                .setOutputCol(\"sentence\")\n","\n","tokenizer = Tokenizer().setInputCols(\"sentence\").setOutputCol(\"token\")\n","\n","# Extracting entities by EntityRuler\n","entity_ruler = EntityRulerApproach() \\\n","                .setInputCols([\"document\"]) \\\n","                .setOutputCol(\"ner_entity_ruler\") \\\n","                .setPatternsResource(\"./entities.json\")\\\n","                .setCaseSensitive(False)\\\n","\n","# Clinical word embeddings \n","word_embeddings = WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n","                .setInputCols([\"sentence\", \"token\"])\\\n","                .setOutputCol(\"embeddings\")\n","\n","# Extracting entities by ner_jsl\n","ner_model = MedicalNerModel.pretrained(\"ner_jsl\",\"en\",\"clinical/models\") \\\n","                .setInputCols(\"sentence\",\"token\",\"embeddings\") \\\n","                .setOutputCol(\"ner_jsl\")\n","\n","ner_converter= NerConverterInternal()\\\n","                .setInputCols([\"sentence\", \"token\", \"ner_jsl\"])\\\n","                .setOutputCol(\"ner_jsl_chunk\")\\\n","\n","# Chunkmerger; prioritize EntityRuler entities\n","merger= ChunkMergeApproach()\\\n","                .setInputCols([\"ner_entity_ruler\", \"ner_jsl_chunk\"])\\\n","                .setOutputCol(\"ner_chunk\")\n","\n","# Build Pipeline\n","pipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, entity_ruler,\n","                            word_embeddings,ner_model, ner_converter, merger ])\n","\n","data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n","\n","pipeline_model = pipeline.fit(data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xABDDdstsMlS"},"outputs":[],"source":["sample_text = \"\"\"Patient # 5874651 is a 28 year old female with a history of gestational diabetes mellitus diagnosed eight years prior to \n","presentation and subsequent type two diabetes mellitus ( T2DM ), one prior episode of HTG-induced pancreatitis \n","three years prior to presentation , associated with an acute hepatitis , and obesity with a body mass index \n","( BMI ) of 33.5 kg/m2 , presented with a one-week history of polyuria , polydipsia , poor appetite , and vomiting.\n","Two weeks prior to presentation , she was treated with a five-day course of amoxicillin for a respiratory tract infection . \n","She was on metformin , glipizide , and dapagliflozin for T2DM and atorvastatin and gemfibrozil for HTG . \n","She had been on dapagliflozin for six months at the time of presentation . Physical examination on presentation was \n","significant for dry oral mucosa ; significantly , her abdominal examination was benign with no tenderness , guarding , \n","or rigidity . findings on admission were : serum glucose 111 mg/dl , bicarbonate 18 mmol/l , \n","anion gap 20 , creatinine 0.4 mg/dL , triglycerides 508 mg/dL , total cholesterol 122 mg/dL , glycated hemoglobin \n","( HbA1c ) 10% , and venous pH 7.27 . Serum lipase was normal at 43 U/L . Serum acetone levels could not be assessed \n","as blood samples kept hemolyzing due to significant lipemia .\n","The patient was initially admitted for starvation ketosis , as she reported poor oral intake for three days prior \n","to admission . However , serum chemistry obtained six hours after presentation revealed her glucose was 186 mg/dL , \n","the anion gap was still elevated at 21 , serum bicarbonate was 16 mmol/L , triglyceride level peaked at 2050 mg/dL , \n","and lipase was 52 U/L .\n","β-hydroxybutyrate level was obtained and found to be elevated at 5.29 mmol/L - the original sample was centrifuged \n","and the chylomicron layer removed prior to analysis due to interference from turbidity caused by lipemia again . \n","This madame was treated with an insulin drip for euDKA and HTG with a reduction in the anion gap to 13 and triglycerides \n","to 1400 mg/dL , within 24 hours .\n","Twenty days ago.\n","Her euDKA was thought to be precipitated by her respiratory tract infection in the setting of SGLT2 inhibitor use . \n","At birth the typical boy is growing slightly faster than the typical girl, but the velocities become equal at about \n","seven months, and then the girl grows faster until four years. \n","From then until adolescence no differences in velocity \n","can be detected. 21-02-2020 \n","21/04/2020\n","\"\"\"\n","\n","data = spark.createDataFrame([[sample_text]]).toDF(\"text\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dsytJVut543l"},"outputs":[],"source":["result = pipeline_model.transform(data)"]},{"cell_type":"markdown","metadata":{"id":"_jDXZwQcQCfg"},"source":["### Error Handling Caused by Missing Alphabet"]},{"cell_type":"markdown","source":["❗**Attention** The below code will fail, please read following explanations."],"metadata":{"id":"GwFYlGjMjNN7"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"58Qg9CF4vdC-","outputId":"2fa24621-6c7e-4cb1-b723-c98f96274265","executionInfo":{"status":"error","timestamp":1680624288474,"user_tz":-180,"elapsed":5493,"user":{"displayName":"Halil SAGLAMLAR","userId":"07259164328506563794"}}},"outputs":[{"output_type":"error","ename":"Py4JJavaError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-7887ea106724>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# This code will fail, please read following explanations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mget_ner_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ner_chunk\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-5-fc50bf9c48bd>\u001b[0m in \u001b[0;36mget_ner_table\u001b[0;34m(result, column)\u001b[0m\n\u001b[1;32m     13\u001b[0m               F.expr(\"cols['2']\").alias(\"end\"))\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/sql/pandas/conversion.py\u001b[0m in \u001b[0;36mtoPandas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;31m# Below is toPandas without Arrow optimization.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0mpdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0mcolumn_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    815\u001b[0m         \"\"\"\n\u001b[1;32m    816\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 817\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectToPython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    818\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n","\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o1268.collectToPython.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 15.0 failed 1 times, most recent failure: Lost task 1.0 in stage 15.0 (TID 29) (ef77839d4fd0 executor driver): org.apache.spark.SparkException: Failed to execute user defined function (HasSimpleAnnotate$$Lambda$2891/0x000000084127c040: (array<array<struct<annotatorType:string,begin:int,end:int,result:string,metadata:map<string,string>,embeddings:array<float>>>>) => array<struct<annotatorType:string,begin:int,end:int,result:string,metadata:map<string,string>,embeddings:array<float>>>)\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.failedExecuteUserDefinedFunctionError(QueryExecutionErrors.scala:177)\n\tat org.apache.spark.sql.errors.QueryExecutionErrors.failedExecuteUserDefinedFunctionError(QueryExecutionErrors.scala)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1211)\n\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1217)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:364)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:890)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:890)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: java.lang.UnsupportedOperationException: Char β not found in the alphabet. Your data could have unusual characters not found\nin your document's language, which requires setting up a custom alphabet.\n\nPlease set alphabet using setAlphabetResource parameter and make sure it has all\ncharacters that can be found in your documents.\n\nYou can check an example in Spark NLP Examples: https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/annotation/text/english/entity-ruler/EntityRuler_Alphabet.ipynb\n\tat com.johnsnowlabs.nlp.annotators.er.AhoCorasickAutomaton.findNextState(AhoCorasickAutomaton.scala:154)\n\tat com.johnsnowlabs.nlp.annotators.er.AhoCorasickAutomaton.$anonfun$searchPatternsInText$1(AhoCorasickAutomaton.scala:118)\n\tat com.johnsnowlabs.nlp.annotators.er.AhoCorasickAutomaton.$anonfun$searchPatternsInText$1$adapted(AhoCorasickAutomaton.scala:116)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n\tat com.johnsnowlabs.nlp.annotators.er.AhoCorasickAutomaton.searchPatternsInText(AhoCorasickAutomaton.scala:116)\n\tat com.johnsnowlabs.nlp.annotators.er.EntityRulerModel.$anonfun$annotate$1(EntityRulerModel.scala:169)\n\tat scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:293)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableLike.flatMap(TraversableLike.scala:293)\n\tat scala.collection.TraversableLike.flatMap$(TraversableLike.scala:290)\n\tat scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)\n\tat com.johnsnowlabs.nlp.annotators.er.EntityRulerModel.annotate(EntityRulerModel.scala:168)\n\tat com.johnsnowlabs.nlp.HasSimpleAnnotate.$anonfun$dfAnnotate$1(HasSimpleAnnotate.scala:46)\n\t... 28 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2860)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2228)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2268)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2293)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1021)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:406)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1020)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:424)\n\tat org.apache.spark.sql.Dataset.$anonfun$collectToPython$1(Dataset.scala:3688)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:3858)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:510)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3856)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:109)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:169)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:95)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3856)\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3685)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: org.apache.spark.SparkException: Failed to execute user defined function (HasSimpleAnnotate$$Lambda$2891/0x000000084127c040: (array<array<struct<annotatorType:string,begin:int,end:int,result:string,metadata:map<string,string>,embeddings:array<float>>>>) => array<struct<annotatorType:string,begin:int,end:int,result:string,metadata:map<string,string>,embeddings:array<float>>>)\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.failedExecuteUserDefinedFunctionError(QueryExecutionErrors.scala:177)\n\tat org.apache.spark.sql.errors.QueryExecutionErrors.failedExecuteUserDefinedFunctionError(QueryExecutionErrors.scala)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1211)\n\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1217)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:364)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:890)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:890)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\nCaused by: java.lang.UnsupportedOperationException: Char β not found in the alphabet. Your data could have unusual characters not found\nin your document's language, which requires setting up a custom alphabet.\n\nPlease set alphabet using setAlphabetResource parameter and make sure it has all\ncharacters that can be found in your documents.\n\nYou can check an example in Spark NLP Examples: https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/annotation/text/english/entity-ruler/EntityRuler_Alphabet.ipynb\n\tat com.johnsnowlabs.nlp.annotators.er.AhoCorasickAutomaton.findNextState(AhoCorasickAutomaton.scala:154)\n\tat com.johnsnowlabs.nlp.annotators.er.AhoCorasickAutomaton.$anonfun$searchPatternsInText$1(AhoCorasickAutomaton.scala:118)\n\tat com.johnsnowlabs.nlp.annotators.er.AhoCorasickAutomaton.$anonfun$searchPatternsInText$1$adapted(AhoCorasickAutomaton.scala:116)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n\tat com.johnsnowlabs.nlp.annotators.er.AhoCorasickAutomaton.searchPatternsInText(AhoCorasickAutomaton.scala:116)\n\tat com.johnsnowlabs.nlp.annotators.er.EntityRulerModel.$anonfun$annotate$1(EntityRulerModel.scala:169)\n\tat scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:293)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableLike.flatMap(TraversableLike.scala:293)\n\tat scala.collection.TraversableLike.flatMap$(TraversableLike.scala:290)\n\tat scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)\n\tat com.johnsnowlabs.nlp.annotators.er.EntityRulerModel.annotate(EntityRulerModel.scala:168)\n\tat com.johnsnowlabs.nlp.HasSimpleAnnotate.$anonfun$dfAnnotate$1(HasSimpleAnnotate.scala:46)\n\t... 28 more\n"]}],"source":["get_ner_table(result, \"ner_chunk\")"]},{"cell_type":"markdown","metadata":{"id":"LcUXto8gFGKW"},"source":["The above code will fail. Since Spark NLP version 4.2.0, `EntityRuler` requires defining an alphabet for some cases. The above sample text includes a non-standard character `β`, for particular use cases we will need to proceed like the example below. In the below case, we will define a new alphabet including all characters and the `β` char.  \n","\n","For standart English documents, you won't need to define it, because under the hood `EntityRuler` annotator uses an English alphabet by default."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mi3XVuDI54yT"},"outputs":[],"source":["# Define a new alphabet\n","\n","symbols = \"\"\":$&(){}[]?/\\\\!><@=#-;,%_“.|'`\"*#^+~€\"\"\"\n","numbers = \"0123456789\"\n","englishAlphabet = \"abcdefghijklmnopqrstuvwxyz\"\n","special = \"β\"\n","\n","chars = symbols + numbers + englishAlphabet + special\n","\n","with open('./custom_alphabet.txt', 'w') as alphabet_file:\n","    alphabet_file.write(chars)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_FBI9zJ_54vH"},"outputs":[],"source":["entity_ruler_custom_alphabet = EntityRulerApproach() \\\n","                                .setInputCols([\"document\"]) \\\n","                                .setOutputCol(\"ner_entity_ruler\") \\\n","                                .setPatternsResource(\"./entities.json\")\\\n","                                .setCaseSensitive(False)\\\n","                                .setAlphabetResource('./custom_alphabet.txt')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"fQ1sCxXp54rv","outputId":"b4ff5762-d815-4ac0-9536-4f9c1c585a5c","executionInfo":{"status":"ok","timestamp":1680633339143,"user_tz":-180,"elapsed":9257,"user":{"displayName":"Halil SAGLAMLAR","userId":"07259164328506563794"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                             chunk     ner_label sentence  begin   end\n","0                      28 year old           Age        0     23    33\n","1                           female        Female        0     35    40\n","2    gestational diabetes mellitus      Diabetes        0     60    88\n","3                eight years prior  RelativeDate        0    100   116\n","4       type two diabetes mellitus      Diabetes        0    150   175\n","..                             ...           ...      ...    ...   ...\n","119                           girl        Female        0   2352  2355\n","120                     four years           Age       15   2376  2385\n","121                             he          Male        0   2395  2396\n","122        differences in velocity       Symptom       16   2420  2442\n","123                     21/04/2020          Date       17   2474  2483\n","\n","[124 rows x 5 columns]"],"text/html":["\n","  <div id=\"df-a11f1242-b7f6-48eb-84eb-36e26de873d9\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>chunk</th>\n","      <th>ner_label</th>\n","      <th>sentence</th>\n","      <th>begin</th>\n","      <th>end</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>28 year old</td>\n","      <td>Age</td>\n","      <td>0</td>\n","      <td>23</td>\n","      <td>33</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>female</td>\n","      <td>Female</td>\n","      <td>0</td>\n","      <td>35</td>\n","      <td>40</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>gestational diabetes mellitus</td>\n","      <td>Diabetes</td>\n","      <td>0</td>\n","      <td>60</td>\n","      <td>88</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>eight years prior</td>\n","      <td>RelativeDate</td>\n","      <td>0</td>\n","      <td>100</td>\n","      <td>116</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>type two diabetes mellitus</td>\n","      <td>Diabetes</td>\n","      <td>0</td>\n","      <td>150</td>\n","      <td>175</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>119</th>\n","      <td>girl</td>\n","      <td>Female</td>\n","      <td>0</td>\n","      <td>2352</td>\n","      <td>2355</td>\n","    </tr>\n","    <tr>\n","      <th>120</th>\n","      <td>four years</td>\n","      <td>Age</td>\n","      <td>15</td>\n","      <td>2376</td>\n","      <td>2385</td>\n","    </tr>\n","    <tr>\n","      <th>121</th>\n","      <td>he</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>2395</td>\n","      <td>2396</td>\n","    </tr>\n","    <tr>\n","      <th>122</th>\n","      <td>differences in velocity</td>\n","      <td>Symptom</td>\n","      <td>16</td>\n","      <td>2420</td>\n","      <td>2442</td>\n","    </tr>\n","    <tr>\n","      <th>123</th>\n","      <td>21/04/2020</td>\n","      <td>Date</td>\n","      <td>17</td>\n","      <td>2474</td>\n","      <td>2483</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>124 rows × 5 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a11f1242-b7f6-48eb-84eb-36e26de873d9')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a11f1242-b7f6-48eb-84eb-36e26de873d9 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a11f1242-b7f6-48eb-84eb-36e26de873d9');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":18}],"source":["pipeline_custom_alphabet = Pipeline(stages=[document_assembler, \n","                                            sentence_detector, \n","                                            tokenizer, \n","                                            entity_ruler_custom_alphabet, \n","                                            word_embeddings,\n","                                            ner_model, \n","                                            ner_converter, \n","                                            merger ])\n","\n","\n","model_custom_alphabet = pipeline_custom_alphabet.fit(data)\n","\n","result_custom_alphabet = model_custom_alphabet.transform(data)\n","\n","# get combined ner entities of EntityRuler and ner_jsl\n","get_ner_table(result_custom_alphabet, \"ner_chunk\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"H2PnWPj0P8_d","outputId":"6b3c29e8-ea27-40dd-9b30-9d7cb674f68b","executionInfo":{"status":"ok","timestamp":1680633341218,"user_tz":-180,"elapsed":2078,"user":{"displayName":"Halil SAGLAMLAR","userId":"07259164328506563794"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                             chunk     ner_label sentence  begin   end\n","0                      28 year old           Age        0     23    33\n","1                           female        Gender        0     35    40\n","2    gestational diabetes mellitus      Diabetes        0     60    88\n","3                eight years prior  RelativeDate        0    100   116\n","4       type two diabetes mellitus      Diabetes        0    150   175\n","..                             ...           ...      ...    ...   ...\n","105        at about \\nseven months  RelativeDate       15   2315  2336\n","106                           girl        Gender       15   2352  2355\n","107                     four years           Age       15   2376  2385\n","108        differences in velocity       Symptom       16   2420  2442\n","109                     21/04/2020          Date       17   2474  2483\n","\n","[110 rows x 5 columns]"],"text/html":["\n","  <div id=\"df-b7429a8c-15f1-4a8b-a9cc-9ea65210962c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>chunk</th>\n","      <th>ner_label</th>\n","      <th>sentence</th>\n","      <th>begin</th>\n","      <th>end</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>28 year old</td>\n","      <td>Age</td>\n","      <td>0</td>\n","      <td>23</td>\n","      <td>33</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>female</td>\n","      <td>Gender</td>\n","      <td>0</td>\n","      <td>35</td>\n","      <td>40</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>gestational diabetes mellitus</td>\n","      <td>Diabetes</td>\n","      <td>0</td>\n","      <td>60</td>\n","      <td>88</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>eight years prior</td>\n","      <td>RelativeDate</td>\n","      <td>0</td>\n","      <td>100</td>\n","      <td>116</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>type two diabetes mellitus</td>\n","      <td>Diabetes</td>\n","      <td>0</td>\n","      <td>150</td>\n","      <td>175</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>105</th>\n","      <td>at about \\nseven months</td>\n","      <td>RelativeDate</td>\n","      <td>15</td>\n","      <td>2315</td>\n","      <td>2336</td>\n","    </tr>\n","    <tr>\n","      <th>106</th>\n","      <td>girl</td>\n","      <td>Gender</td>\n","      <td>15</td>\n","      <td>2352</td>\n","      <td>2355</td>\n","    </tr>\n","    <tr>\n","      <th>107</th>\n","      <td>four years</td>\n","      <td>Age</td>\n","      <td>15</td>\n","      <td>2376</td>\n","      <td>2385</td>\n","    </tr>\n","    <tr>\n","      <th>108</th>\n","      <td>differences in velocity</td>\n","      <td>Symptom</td>\n","      <td>16</td>\n","      <td>2420</td>\n","      <td>2442</td>\n","    </tr>\n","    <tr>\n","      <th>109</th>\n","      <td>21/04/2020</td>\n","      <td>Date</td>\n","      <td>17</td>\n","      <td>2474</td>\n","      <td>2483</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>110 rows × 5 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b7429a8c-15f1-4a8b-a9cc-9ea65210962c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b7429a8c-15f1-4a8b-a9cc-9ea65210962c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b7429a8c-15f1-4a8b-a9cc-9ea65210962c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":19}],"source":["# Get ner entities of ner_jsl only\n","get_ner_table(result_custom_alphabet, \"ner_jsl_chunk\")"]},{"cell_type":"markdown","metadata":{"id":"ca5Hk5c18tnT"},"source":["Comparing above two tables (`ner_chunk` vs `ner_chunk_jsl`) , we have  added new `ID` entity and more granular of `Gender` entity as `Male` and `Female`."]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.9.5 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"},"vscode":{"interpreter":{"hash":"6bb3ceeb2510fad60e2138ee9cd2459f6834ef474162207c6ff5eee06d0ca3e4"}}},"nbformat":4,"nbformat_minor":0}