{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KvNW4MU5rrF",
        "outputId": "d5299652-c828-48d3-e7ee-c10c9f733586"
      },
      "source": [
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/28.EntityRuler_with_Clinical_NER_Models.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_GiBDlsja-o"
      },
      "source": [
        "# EntityRuler\n",
        "\n",
        "`EntityRuler` fits to match exact strings or regex patterns provided in a file against a document and assigns them a named entity. The definitions can contain any number of named entities.\n",
        "\n",
        "There are multiple ways and formats to set the extraction resource. It is possible to set it either as a “JSON”, “JSONL” or “CSV” file.\n",
        "\n",
        "This notebook showcases the `EntityRuler` annotator with the Healthcare library. For detailed usage of `EntityRuler` itself please check [here](https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/e3d3d942a75752d8040f73538c7f8ce5430e80d9/jupyter/training/english/entity-ruler).\n",
        "\n",
        "**For the licensed users, `ContextualParser` is a more capable annotator. You can check [here](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings_JSL/Healthcare/1.2.Contextual_Parser_Rule_Based_NER.ipynb) for more info on `ContextualParser`.**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JKVMATIFVvR"
      },
      "source": [
        "## Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "166_oTSpJKGG"
      },
      "outputs": [],
      "source": [
        "import json, os\n",
        "from google.colab import files\n",
        "\n",
        "if 'spark_jsl.json' not in os.listdir():\n",
        "  license_keys = files.upload()\n",
        "  os.rename(list(license_keys.keys())[0], 'spark_jsl.json')\n",
        "\n",
        "with open('spark_jsl.json') as f:\n",
        "    license_keys = json.load(f)\n",
        "\n",
        "# Defining license key-value pairs as local variables\n",
        "locals().update(license_keys)\n",
        "os.environ.update(license_keys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Pza56D-ublfg"
      },
      "outputs": [],
      "source": [
        "# Installing pyspark and spark-nlp\n",
        "! pip install --upgrade -q pyspark==3.1.2 spark-nlp==$PUBLIC_VERSION\n",
        "\n",
        "# Installing Spark NLP Healthcare\n",
        "! pip install --upgrade -q spark-nlp-jsl==$JSL_VERSION  --extra-index-url https://pypi.johnsnowlabs.com/$SECRET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "NY16q61Rblfe",
        "outputId": "1c659303-7f51-493d-84f5-86966d9a322a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning::Spark Session already created, some configs may not take.\n",
            "Spark NLP Version : 4.2.0\n",
            "Spark NLP_JSL Version : 4.2.0\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://18822270ad43:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark NLP Licensed</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f9c8c209a90>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import sparknlp\n",
        "import sparknlp_jsl\n",
        "\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp_jsl.annotator import *\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml import Pipeline, PipelineModel\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "params = {\"spark.driver.memory\":\"16G\",\n",
        "          \"spark.kryoserializer.buffer.max\":\"2000M\",\n",
        "          \"spark.driver.maxResultSize\":\"2000M\"}\n",
        "\n",
        "spark = sparknlp_jsl.start(license_keys['SECRET'],params=params)\n",
        "\n",
        "print(\"Spark NLP Version :\", sparknlp.version())\n",
        "print(\"Spark NLP_JSL Version :\", sparknlp_jsl.version())\n",
        "\n",
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xvioX5cFhe3"
      },
      "source": [
        "## Define EntityRuler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlGbrPLWFRQm"
      },
      "source": [
        "Now let's define keyword patterns for entities to use in `EntityRuler`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "OmOTCKpV84Xs"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "person = [\n",
        "          {\n",
        "            \"label\": \"Person\",\n",
        "            \"patterns\": [\"Jon\", \"John\", \"John Snow\", \"Jon Snow\"]\n",
        "          },\n",
        "          {\n",
        "            \"label\": \"Person\",\n",
        "            \"patterns\": [\"Eddard\", \"Eddard Stark\"]\n",
        "          },\n",
        "          {\n",
        "            \"label\": \"Clinical_Department\",\n",
        "            \"patterns\": [\"St. John Hospital\", \"St. Jon Hospital\" ]\n",
        "          },\n",
        "         ]\n",
        "\n",
        "with open('./keywords.json', 'w') as jsonfile:\n",
        "    json.dump(person, jsonfile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ZQ8I9iPPvpS_"
      },
      "outputs": [],
      "source": [
        "def get_ner_table(result, column):\n",
        "    \"\"\" \n",
        "    Helper function to get a ner table in Pandas dataframe from result\n",
        "    \"\"\"\n",
        "    out = result.select(F.explode(F.arrays_zip(result[column + \".result\"],\n",
        "                                               result[column + \".begin\"],\n",
        "                                               result[column + \".end\"],\n",
        "                                               result[column + \".metadata\"])).alias(\"cols\")) \\\n",
        "      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
        "              F.expr(\"cols['3']['entity']\").alias(\"ner_label\"),\n",
        "              F.expr(\"cols['3']['sentence']\").alias(\"sentence\"),\n",
        "              F.expr(\"cols['1']\").alias(\"begin\"),\n",
        "              F.expr(\"cols['2']\").alias(\"end\"))\n",
        "      \n",
        "    return out.toPandas()\n",
        "      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "tRyju8D-6XJ1"
      },
      "outputs": [],
      "source": [
        "# Define an EntityRule with EntityRulerApproach\n",
        "entity_ruler = EntityRulerApproach() \\\n",
        "                  .setInputCols([\"document\"]) \\\n",
        "                  .setOutputCol(\"entity\") \\\n",
        "                  .setPatternsResource(\"./keywords.json\")\\\n",
        "                  .setCaseSensitive(False)\n",
        "\n",
        "data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
        "\n",
        "entity_ruler_model = entity_ruler.fit(data)\n",
        "\n",
        "# Save EntityRule model\n",
        "entity_ruler_model.write().overwrite().save(\"tmp_entity_ruler_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "jtMK0ZekjSeB"
      },
      "outputs": [],
      "source": [
        "document_assembler = DocumentAssembler()\\\n",
        "                        .setInputCol(\"text\")\\\n",
        "                        .setOutputCol(\"document\")\n",
        "\n",
        "sentence_detector = SentenceDetector()\\\n",
        "                       .setInputCols(\"document\")\\\n",
        "                       .setOutputCol(\"sentence\")\n",
        "\n",
        "# Extracting entities using the saved model with EntityRulerModel\n",
        "entity_ruler_loaded = EntityRulerModel().load(\"tmp_entity_ruler_model\")\\\n",
        "                         .setInputCols([\"sentence\"]) \\\n",
        "                         .setOutputCol(\"entity_ruler\") \\\n",
        "\n",
        "\n",
        "# Build Pipeline\n",
        "pipeline = Pipeline(stages=[document_assembler,\n",
        "                            sentence_detector, \n",
        "                            entity_ruler_loaded])\n",
        "\n",
        "\n",
        "pipeline_model = pipeline.fit(data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "d7qy0hxlkX3u"
      },
      "outputs": [],
      "source": [
        "text=\"Lord Eddard Stark was the head of St. John Hospital. John Snow lives in Winterfell and is a doctor at St. john Hospital.\"\n",
        "\n",
        "data = spark.createDataFrame([[text]]).toDF(\"text\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wr22PwW5B9Rg",
        "outputId": "33c6ad5d-9318-4ca4-d91f-17dbac9d7bd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|entity_ruler                                                                                                                                                                                                                                                                                                              |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|[{chunk, 5, 16, Eddard Stark, {entity -> Person, sentence -> 0}, []}, {chunk, 34, 50, St. John Hospital, {entity -> Clinical_Department, sentence -> 0}, []}, {chunk, 53, 61, John Snow, {entity -> Person, sentence -> 1}, []}, {chunk, 102, 118, St. john Hospital, {entity -> Clinical_Department, sentence -> 1}, []}]|\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result = pipeline_model.transform(data).cache()\n",
        "\n",
        "result.select(\"entity_ruler\").show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "SlMAE9ZayuZ7",
        "outputId": "a2dbbd81-a5b4-479b-ff0b-3c940a739c88"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d123839f-782c-41e7-858d-745ddd5c8e60\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>chunk</th>\n",
              "      <th>ner_label</th>\n",
              "      <th>sentence</th>\n",
              "      <th>begin</th>\n",
              "      <th>end</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Eddard Stark</td>\n",
              "      <td>Person</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>St. John Hospital</td>\n",
              "      <td>Clinical_Department</td>\n",
              "      <td>0</td>\n",
              "      <td>34</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>John Snow</td>\n",
              "      <td>Person</td>\n",
              "      <td>1</td>\n",
              "      <td>53</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>St. john Hospital</td>\n",
              "      <td>Clinical_Department</td>\n",
              "      <td>1</td>\n",
              "      <td>102</td>\n",
              "      <td>118</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d123839f-782c-41e7-858d-745ddd5c8e60')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d123839f-782c-41e7-858d-745ddd5c8e60 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d123839f-782c-41e7-858d-745ddd5c8e60');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "               chunk            ner_label sentence  begin  end\n",
              "0       Eddard Stark               Person        0      5   16\n",
              "1  St. John Hospital  Clinical_Department        0     34   50\n",
              "2          John Snow               Person        1     53   61\n",
              "3  St. john Hospital  Clinical_Department        1    102  118"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_ner_table(result, \"entity_ruler\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHWEGT7K8_MB"
      },
      "source": [
        "## Combining EntityRuler with Pretrained NER Models\n",
        "\n",
        "\n",
        "Now we will use pretrained NER models with the `EntityRuler` annotator. Sometimes NER models fail to extract some chunks or some entity labels may be missing in that model. In that case, `EntityRuler` can be used to enhance or improve the NER coverage like `ContextualParser`. In the example below we will add `ID`, `Female`, and `Male` entities that are not a part of a ner_jsl NER model.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "tTqvYXGb00Yb"
      },
      "outputs": [],
      "source": [
        "entities =\"\"\" \n",
        "[   \n",
        "    {\n",
        "        \"id\": \"person\",\n",
        "        \"label\": \"Female\",\n",
        "        \"patterns\": [\"she\", \"her\", \"girl\", \"woman\", \"women\", \"womanish\", \"womanlike\", \"womanly\", \"madam\", \"madame\", \"senora\", \"lady\", \"miss\", \"girlfriend\", \"wife\", \"bride\", \"misses\", \"mrs.\", \"female\"],\n",
        "        \"regex\": false\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"person\",\n",
        "        \"label\": \"Male\",\n",
        "        \"patterns\": [\"he\", \"him\", \"masculine\", \"boy\", \"father\", \"guy\", \"macho\", \"brother\", \"fellow\", \"gent\", \"gentleman\", \"grandfather\", \"husband\", \"sir\", \"son\", \"manful\", \"manlike\", \"manly\"],\n",
        "        \"regex\": false\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"id-regex\",\n",
        "        \"label\": \"ID\",\n",
        "        \"patterns\": [\"[0-9]{7}\"],\n",
        "        \"regex\": true\n",
        "    }\n",
        "]\"\"\"\n",
        "\n",
        "\n",
        "patterns_obj = json.loads(entities)\n",
        "\n",
        "with open('./entities.json', 'w') as jsonfile:\n",
        "    json.dump(patterns_obj, jsonfile)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMUCdd8AdOw2"
      },
      "source": [
        "When defining a regex pattern in `EntityRuler`, we need to define `Tokenizer` annotator in the pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BGExTU6547O",
        "outputId": "d3412649-cece-4ccd-c980-b4fd0fba8ef1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sentence_detector_dl download started this may take some time.\n",
            "Approximate size to download 354.6 KB\n",
            "[OK!]\n",
            "embeddings_clinical download started this may take some time.\n",
            "Approximate size to download 1.6 GB\n",
            "[OK!]\n",
            "ner_jsl download started this may take some time.\n",
            "[OK!]\n"
          ]
        }
      ],
      "source": [
        "document_assembler = DocumentAssembler()\\\n",
        "                        .setInputCol(\"text\")\\\n",
        "                        .setOutputCol(\"document\")\n",
        "\n",
        "sentence_detector = SentenceDetectorDLModel.pretrained().setInputCols(\"document\").setOutputCol(\"sentence\")\n",
        "\n",
        "tokenizer = Tokenizer().setInputCols(\"sentence\").setOutputCol(\"token\")\n",
        "\n",
        "# Extracting entities by EntityRuler\n",
        "entity_ruler = EntityRulerApproach() \\\n",
        "                .setInputCols([\"sentence\", \"token\"]) \\\n",
        "                .setOutputCol(\"ner_entity_ruler\") \\\n",
        "                .setPatternsResource(\"./entities.json\")\\\n",
        "                .setCaseSensitive(False)\\\n",
        "\n",
        "# Clinical word embeddings \n",
        "word_embeddings = WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n",
        "                .setInputCols([\"sentence\", \"token\"])\\\n",
        "                .setOutputCol(\"embeddings\")\n",
        "\n",
        "# Extracting entities by ner_jsl\n",
        "ner_model = MedicalNerModel.pretrained(\"ner_jsl\",\"en\",\"clinical/models\") \\\n",
        "                .setInputCols(\"sentence\",\"token\",\"embeddings\") \\\n",
        "                .setOutputCol(\"ner_jsl\")\n",
        "\n",
        "ner_converter= NerConverterInternal()\\\n",
        "                .setInputCols([\"sentence\", \"token\", \"ner_jsl\"])\\\n",
        "                .setOutputCol(\"ner_jsl_chunk\")\\\n",
        "\n",
        "# Chunkmerger; prioritize EntityRuler entities\n",
        "merger= ChunkMergeApproach()\\\n",
        "                .setInputCols([\"ner_entity_ruler\", \"ner_jsl_chunk\"])\\\n",
        "                .setOutputCol(\"ner_chunk\")\n",
        "\n",
        "# Build Pipeline\n",
        "pipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, entity_ruler,\n",
        "                            word_embeddings,ner_model, ner_converter, merger ])\n",
        "\n",
        "data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
        "\n",
        "pipeline_model = pipeline.fit(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "xABDDdstsMlS"
      },
      "outputs": [],
      "source": [
        "sample_text = \"\"\"Patient # 5874651 is a 28 year old female with a history of gestational diabetes mellitus diagnosed eight years prior to \n",
        "presentation and subsequent type two diabetes mellitus ( T2DM ), one prior episode of HTG-induced pancreatitis \n",
        "three years prior to presentation , associated with an acute hepatitis , and obesity with a body mass index \n",
        "( BMI ) of 33.5 kg/m2 , presented with a one-week history of polyuria , polydipsia , poor appetite , and vomiting.\n",
        "Two weeks prior to presentation , she was treated with a five-day course of amoxicillin for a respiratory tract infection . \n",
        "She was on metformin , glipizide , and dapagliflozin for T2DM and atorvastatin and gemfibrozil for HTG . \n",
        "She had been on dapagliflozin for six months at the time of presentation . Physical examination on presentation was \n",
        "significant for dry oral mucosa ; significantly , her abdominal examination was benign with no tenderness , guarding , \n",
        "or rigidity . findings on admission were : serum glucose 111 mg/dl , bicarbonate 18 mmol/l , \n",
        "anion gap 20 , creatinine 0.4 mg/dL , triglycerides 508 mg/dL , total cholesterol 122 mg/dL , glycated hemoglobin \n",
        "( HbA1c ) 10% , and venous pH 7.27 . Serum lipase was normal at 43 U/L . Serum acetone levels could not be assessed \n",
        "as blood samples kept hemolyzing due to significant lipemia .\n",
        "The patient was initially admitted for starvation ketosis , as she reported poor oral intake for three days prior \n",
        "to admission . However , serum chemistry obtained six hours after presentation revealed her glucose was 186 mg/dL , \n",
        "the anion gap was still elevated at 21 , serum bicarbonate was 16 mmol/L , triglyceride level peaked at 2050 mg/dL , \n",
        "and lipase was 52 U/L .\n",
        "β-hydroxybutyrate level was obtained and found to be elevated at 5.29 mmol/L - the original sample was centrifuged \n",
        "and the chylomicron layer removed prior to analysis due to interference from turbidity caused by lipemia again . \n",
        "This madame was treated with an insulin drip for euDKA and HTG with a reduction in the anion gap to 13 and triglycerides \n",
        "to 1400 mg/dL , within 24 hours .\n",
        "Twenty days ago.\n",
        "Her euDKA was thought to be precipitated by her respiratory tract infection in the setting of SGLT2 inhibitor use . \n",
        "At birth the typical boy is growing slightly faster than the typical girl, but the velocities become equal at about \n",
        "seven months, and then the girl grows faster until four years. \n",
        "From then until adolescence no differences in velocity \n",
        "can be detected. 21-02-2020 \n",
        "21/04/2020\n",
        "\"\"\"\n",
        "\n",
        "data = spark.createDataFrame([[sample_text]]).toDF(\"text\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "dsytJVut543l"
      },
      "outputs": [],
      "source": [
        "result = pipeline_model.transform(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jDXZwQcQCfg"
      },
      "source": [
        "### Error Handling Caused by Missing Alphabet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "58Qg9CF4vdC-",
        "outputId": "cf3ce35e-8ab2-43b7-fc5e-5b7e8282f512"
      },
      "outputs": [
        {
          "ename": "Py4JJavaError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-7887ea106724>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# This code will fail, please read following explanations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mget_ner_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ner_chunk\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-26-4150af9b2493>\u001b[0m in \u001b[0;36mget_ner_table\u001b[0;34m(result, column)\u001b[0m\n\u001b[1;32m     13\u001b[0m               F.expr(\"cols['2']\").alias(\"end\"))\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/pandas/conversion.py\u001b[0m in \u001b[0;36mtoPandas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;31m# Below is toPandas without Arrow optimization.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0mpdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0mcolumn_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m         \"\"\"\n\u001b[1;32m    676\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectToPython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o2831.collectToPython.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 31.0 failed 1 times, most recent failure: Lost task 1.0 in stage 31.0 (TID 58) (18822270ad43 executor driver): org.apache.spark.SparkException: Failed to execute user defined function(HasSimpleAnnotate$$Lambda$2623/0x0000000841089840: (array<array<struct<annotatorType:string,begin:int,end:int,result:string,metadata:map<string,string>,embeddings:array<float>>>>) => array<struct<annotatorType:string,begin:int,end:int,result:string,metadata:map<string,string>,embeddings:array<float>>>)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1209)\n\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1215)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:489)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:489)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:222)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:345)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: java.lang.UnsupportedOperationException: Char β not found on alphabet. Please check alphabet\n\tat com.johnsnowlabs.nlp.annotators.er.AhoCorasickAutomaton.findNextState(AhoCorasickAutomaton.scala:153)\n\tat com.johnsnowlabs.nlp.annotators.er.AhoCorasickAutomaton.$anonfun$searchPatternsInText$1(AhoCorasickAutomaton.scala:117)\n\tat com.johnsnowlabs.nlp.annotators.er.AhoCorasickAutomaton.$anonfun$searchPatternsInText$1$adapted(AhoCorasickAutomaton.scala:115)\n\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n\tat com.johnsnowlabs.nlp.annotators.er.AhoCorasickAutomaton.searchPatternsInText(AhoCorasickAutomaton.scala:115)\n\tat com.johnsnowlabs.nlp.annotators.er.EntityRulerModel.$anonfun$annotate$1(EntityRulerModel.scala:169)\n\tat scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:245)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableLike.flatMap(TraversableLike.scala:245)\n\tat scala.collection.TraversableLike.flatMap$(TraversableLike.scala:242)\n\tat scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)\n\tat com.johnsnowlabs.nlp.annotators.er.EntityRulerModel.annotate(EntityRulerModel.scala:168)\n\tat com.johnsnowlabs.nlp.HasSimpleAnnotate.$anonfun$dfAnnotate$1(HasSimpleAnnotate.scala:46)\n\t... 34 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1079)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1079)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1079)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2445)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2261)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1029)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:390)\n\tat org.apache.spark.sql.Dataset.$anonfun$collectToPython$1(Dataset.scala:3519)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3516)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: org.apache.spark.SparkException: Failed to execute user defined function(HasSimpleAnnotate$$Lambda$2623/0x0000000841089840: (array<array<struct<annotatorType:string,begin:int,end:int,result:string,metadata:map<string,string>,embeddings:array<float>>>>) => array<struct<annotatorType:string,begin:int,end:int,result:string,metadata:map<string,string>,embeddings:array<float>>>)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.project_doConsume_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1209)\n\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1215)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:489)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:489)\n\tat scala.collection.Iterator$ConcatIterator.hasNext(Iterator.scala:222)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:345)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\nCaused by: java.lang.UnsupportedOperationException: Char β not found on alphabet. Please check alphabet\n\tat com.johnsnowlabs.nlp.annotators.er.AhoCorasickAutomaton.findNextState(AhoCorasickAutomaton.scala:153)\n\tat com.johnsnowlabs.nlp.annotators.er.AhoCorasickAutomaton.$anonfun$searchPatternsInText$1(AhoCorasickAutomaton.scala:117)\n\tat com.johnsnowlabs.nlp.annotators.er.AhoCorasickAutomaton.$anonfun$searchPatternsInText$1$adapted(AhoCorasickAutomaton.scala:115)\n\tat scala.collection.Iterator.foreach(Iterator.scala:941)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:941)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1429)\n\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n\tat com.johnsnowlabs.nlp.annotators.er.AhoCorasickAutomaton.searchPatternsInText(AhoCorasickAutomaton.scala:115)\n\tat com.johnsnowlabs.nlp.annotators.er.EntityRulerModel.$anonfun$annotate$1(EntityRulerModel.scala:169)\n\tat scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:245)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableLike.flatMap(TraversableLike.scala:245)\n\tat scala.collection.TraversableLike.flatMap$(TraversableLike.scala:242)\n\tat scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)\n\tat com.johnsnowlabs.nlp.annotators.er.EntityRulerModel.annotate(EntityRulerModel.scala:168)\n\tat com.johnsnowlabs.nlp.HasSimpleAnnotate.$anonfun$dfAnnotate$1(HasSimpleAnnotate.scala:46)\n\t... 34 more\n"
          ]
        }
      ],
      "source": [
        "# This code will fail, please read following explanations.\n",
        "get_ner_table(result, \"ner_chunk\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcUXto8gFGKW"
      },
      "source": [
        "The above code will fail. Since Spark NLP version 4.2.0, `EntityRuler` requires defining an alphabet for some cases. The above sample text includes a non-standard character `β`, for particular use cases we will need to proceed like the example below. In the below case, we will define a new alphabet including all characters and the `β` char.  \n",
        "\n",
        "For standart English documents, you won't need to define it, because under the hood `EntityRuler` annotator uses an English alphabet by default."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "mi3XVuDI54yT"
      },
      "outputs": [],
      "source": [
        "# Define a new alphabet\n",
        "\n",
        "symbols = \"\"\":$&(){}[]?/\\\\!><@=#-;,%_“.|'`\"*#^+~€\"\"\"\n",
        "numbers = \"0123456789\"\n",
        "englishAlphabet = \"abcdefghijklmnopqrstuvwxyz\"\n",
        "special = \"β\"\n",
        "\n",
        "chars = symbols + numbers + englishAlphabet + special\n",
        "\n",
        "with open('./custom_alphabet.txt', 'w') as alphabet_file:\n",
        "    alphabet_file.write(chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "_FBI9zJ_54vH"
      },
      "outputs": [],
      "source": [
        "entity_ruler_custom_alphabet = EntityRulerApproach() \\\n",
        "                                .setInputCols([\"sentence\", \"token\"]) \\\n",
        "                                .setOutputCol(\"ner_entity_ruler\") \\\n",
        "                                .setPatternsResource(\"./entities.json\")\\\n",
        "                                .setCaseSensitive(False)\\\n",
        "                                .setAlphabetResource('./custom_alphabet.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "fQ1sCxXp54rv",
        "outputId": "6d1ce548-a3cd-4e55-a4a0-2ab584d4cdde"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-dbb681fd-4e77-4957-87ed-a5ed2eb1824b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>chunk</th>\n",
              "      <th>ner_label</th>\n",
              "      <th>sentence</th>\n",
              "      <th>begin</th>\n",
              "      <th>end</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5874651</td>\n",
              "      <td>ID</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>28 year old</td>\n",
              "      <td>Age</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>female</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gestational diabetes mellitus</td>\n",
              "      <td>Diabetes</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>eight years prior</td>\n",
              "      <td>RelativeDate</td>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>girl</td>\n",
              "      <td>Female</td>\n",
              "      <td>15</td>\n",
              "      <td>2352</td>\n",
              "      <td>2355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>until four years</td>\n",
              "      <td>RelativeDate</td>\n",
              "      <td>15</td>\n",
              "      <td>2370</td>\n",
              "      <td>2385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>he</td>\n",
              "      <td>Male</td>\n",
              "      <td>16</td>\n",
              "      <td>2395</td>\n",
              "      <td>2396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>differences in velocity</td>\n",
              "      <td>Symptom</td>\n",
              "      <td>16</td>\n",
              "      <td>2420</td>\n",
              "      <td>2442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>21/04/2020</td>\n",
              "      <td>Date</td>\n",
              "      <td>17</td>\n",
              "      <td>2474</td>\n",
              "      <td>2483</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>123 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dbb681fd-4e77-4957-87ed-a5ed2eb1824b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dbb681fd-4e77-4957-87ed-a5ed2eb1824b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dbb681fd-4e77-4957-87ed-a5ed2eb1824b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                             chunk     ner_label sentence  begin   end\n",
              "0                          5874651            ID        0     10    16\n",
              "1                      28 year old           Age        0     23    33\n",
              "2                           female        Female        0     35    40\n",
              "3    gestational diabetes mellitus      Diabetes        0     60    88\n",
              "4                eight years prior  RelativeDate        0    100   116\n",
              "..                             ...           ...      ...    ...   ...\n",
              "118                           girl        Female       15   2352  2355\n",
              "119               until four years  RelativeDate       15   2370  2385\n",
              "120                             he          Male       16   2395  2396\n",
              "121        differences in velocity       Symptom       16   2420  2442\n",
              "122                     21/04/2020          Date       17   2474  2483\n",
              "\n",
              "[123 rows x 5 columns]"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipeline_custom_alphabet = Pipeline(stages=[document_assembler, sentence_detector, \n",
        "                                            tokenizer, entity_ruler_custom_alphabet, \n",
        "                                            word_embeddings,ner_model, ner_converter, merger ])\n",
        "\n",
        "\n",
        "model_custom_alphabet = pipeline_custom_alphabet.fit(data)\n",
        "\n",
        "result_custom_alphabet = model_custom_alphabet.transform(data)\n",
        "\n",
        "# get combined ner entities of EntityRuler and ner_jsl\n",
        "get_ner_table(result_custom_alphabet, \"ner_chunk\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "H2PnWPj0P8_d",
        "outputId": "e6a6d447-47f0-46ed-fc53-7c5de5ccc383"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-fdc0375c-82a5-408d-a6d0-0d536aec990f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>chunk</th>\n",
              "      <th>ner_label</th>\n",
              "      <th>sentence</th>\n",
              "      <th>begin</th>\n",
              "      <th>end</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>28 year old</td>\n",
              "      <td>Age</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>female</td>\n",
              "      <td>Gender</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gestational diabetes mellitus</td>\n",
              "      <td>Diabetes</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>eight years prior</td>\n",
              "      <td>RelativeDate</td>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>subsequent</td>\n",
              "      <td>Modifier</td>\n",
              "      <td>0</td>\n",
              "      <td>139</td>\n",
              "      <td>148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>about \\nseven months</td>\n",
              "      <td>RelativeDate</td>\n",
              "      <td>15</td>\n",
              "      <td>2318</td>\n",
              "      <td>2336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>girl</td>\n",
              "      <td>Gender</td>\n",
              "      <td>15</td>\n",
              "      <td>2352</td>\n",
              "      <td>2355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>until four years</td>\n",
              "      <td>RelativeDate</td>\n",
              "      <td>15</td>\n",
              "      <td>2370</td>\n",
              "      <td>2385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>differences in velocity</td>\n",
              "      <td>Symptom</td>\n",
              "      <td>16</td>\n",
              "      <td>2420</td>\n",
              "      <td>2442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>21/04/2020</td>\n",
              "      <td>Date</td>\n",
              "      <td>17</td>\n",
              "      <td>2474</td>\n",
              "      <td>2483</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>109 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fdc0375c-82a5-408d-a6d0-0d536aec990f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fdc0375c-82a5-408d-a6d0-0d536aec990f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fdc0375c-82a5-408d-a6d0-0d536aec990f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                             chunk     ner_label sentence  begin   end\n",
              "0                      28 year old           Age        0     23    33\n",
              "1                           female        Gender        0     35    40\n",
              "2    gestational diabetes mellitus      Diabetes        0     60    88\n",
              "3                eight years prior  RelativeDate        0    100   116\n",
              "4                       subsequent      Modifier        0    139   148\n",
              "..                             ...           ...      ...    ...   ...\n",
              "104           about \\nseven months  RelativeDate       15   2318  2336\n",
              "105                           girl        Gender       15   2352  2355\n",
              "106               until four years  RelativeDate       15   2370  2385\n",
              "107        differences in velocity       Symptom       16   2420  2442\n",
              "108                     21/04/2020          Date       17   2474  2483\n",
              "\n",
              "[109 rows x 5 columns]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get ner entities of ner_jsl only\n",
        "get_ner_table(result_custom_alphabet, \"ner_jsl_chunk\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca5Hk5c18tnT"
      },
      "source": [
        "Comparing above two tables (`ner_chunk` vs `ner_chunk_jsl`) , we have  added new `ID` entity and more granular of `Gender` entity as `Male` and `Female`."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.9.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "6bb3ceeb2510fad60e2138ee9cd2459f6834ef474162207c6ff5eee06d0ca3e4"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
