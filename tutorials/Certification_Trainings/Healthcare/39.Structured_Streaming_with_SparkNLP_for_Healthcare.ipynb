{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Sf4WOaxShVD"
   },
   "source": [
    "![JohnSnowLabs](https://sparknlp.org/assets/images/logo.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/39.Structured_Streaming_with_SparkNLP_for_Healthcare.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using the `johnsnowlabs` library, please use this  [31.0.Structured_Streaming_with_SparkNLP_for_Healthcare](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/healthcare-nlp/31.0.Structured_Streaming_with_SparkNLP_for_Healthcare.ipynb) notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQWrDCi6ShVG"
   },
   "source": [
    "# Structured Streaming with Spark NLP for Healthcare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QbQ9JCLtHCPO"
   },
   "source": [
    "This notebook demonstrates the integration of Spark NLP for Healthcare with Spark Structured Streaming. We'll illustrate a straightforward example that performs real-time clinical entity duplication counting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jb_SjMcjpV02"
   },
   "source": [
    "## Healthcare NLP for Data Scientists Course\n",
    "\n",
    "If you are not familiar with the components in this notebook, you can check [Healthcare NLP for Data Scientists Udemy Course](https://www.udemy.com/course/healthcare-nlp-for-data-scientists/) and the [MOOC Notebooks](https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP) for each components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8izefQ43Aaj"
   },
   "source": [
    "## Start Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e8UK-UQ0jIhg"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from google.colab import files\n",
    "\n",
    "license_keys = files.upload()\n",
    "\n",
    "with open(list(license_keys.keys())[0]) as f:\n",
    "    license_keys = json.load(f)\n",
    "\n",
    "# Defining license key-value pairs as local variables\n",
    "locals().update(license_keys)\n",
    "\n",
    "# Adding license key-value pairs to environment variables\n",
    "os.environ.update(license_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CTnWHJThjOh2"
   },
   "outputs": [],
   "source": [
    "# Installing pyspark and spark-nlp\n",
    "! pip install --upgrade -q pyspark==3.5.1 spark-nlp==$PUBLIC_VERSION\n",
    "\n",
    "# Installing Spark NLP Healthcare\n",
    "! pip install --upgrade -q spark-nlp-jsl==$JSL_VERSION  --extra-index-url https://pypi.johnsnowlabs.com/$SECRET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "executionInfo": {
     "elapsed": 98462,
     "status": "ok",
     "timestamp": 1759303445180,
     "user": {
      "displayName": "Mehmet Dağ",
      "userId": "14052875917891496135"
     },
     "user_tz": -180
    },
    "id": "cagD5DSSjUOr",
    "outputId": "d1558e31-ea3d-4e32-8b0a-8310dea3a643"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP Version : 6.1.3\n",
      "Spark NLP_JSL Version : 6.1.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://d75a18b020dd:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark NLP Licensed</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7b0aa6396e70>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import sparknlp\n",
    "import sparknlp_jsl\n",
    "\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp_jsl.annotator import *\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml import Pipeline,PipelineModel\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "params = {\"spark.driver.memory\":\"16G\",\n",
    "          \"spark.kryoserializer.buffer.max\":\"2000M\",\n",
    "          \"spark.driver.maxResultSize\":\"2000M\"}\n",
    "\n",
    "print(\"Spark NLP Version :\", sparknlp.version())\n",
    "print(\"Spark NLP_JSL Version :\", sparknlp_jsl.version())\n",
    "\n",
    "spark = sparknlp_jsl.start(license_keys['SECRET'],params=params)\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N1T9lgiv3Ocb"
   },
   "source": [
    "## Read Streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K_DFTLK4HLhF"
   },
   "source": [
    "First, we create a directory where the files for streaming will reside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 59,
     "status": "ok",
     "timestamp": 1759303445232,
     "user": {
      "displayName": "Mehmet Dağ",
      "userId": "14052875917891496135"
     },
     "user_tz": -180
    },
    "id": "5DeGx0cax5V8"
   },
   "outputs": [],
   "source": [
    "!mkdir oncology_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 284,
     "status": "ok",
     "timestamp": 1759303445518,
     "user": {
      "displayName": "Mehmet Dağ",
      "userId": "14052875917891496135"
     },
     "user_tz": -180
    },
    "id": "dIPVh-eVfMNC"
   },
   "outputs": [],
   "source": [
    "# Downloading sample datasets.\n",
    "! wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Healthcare/data/oncology_notes/mt_oncology_0.txt -P oncology_notes/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXC9hb9Czhc6"
   },
   "source": [
    "The core syntax for reading the streaming data in Apache Spark:\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "spark.readStream \\\n",
    "     .format() \\ # this is the raw format you are reading from\n",
    "     .option(\"key\", \"value\") \\\n",
    "     .schema() \\ # require to specify the schema\n",
    "     .load(path)\n",
    "```\n",
    "\n",
    "The core syntax to read the static and streaming data are pretty similar; there are two main differences:\n",
    "\n",
    "- We are using read in static read mode but using readStream in streaming read mode.\n",
    "- By default, Structured Streaming from file-based sources requires you to specify the schema rather than rely on Spark to infer it automatically. This restriction ensures a consistent schema will be used for the streaming query, even in the case of failures. You can reenable schema inference by setting `spark.sql.streaming.schemaInference` to true for the ad-hoc use case.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 2813,
     "status": "ok",
     "timestamp": 1759303448314,
     "user": {
      "displayName": "Mehmet Dağ",
      "userId": "14052875917891496135"
     },
     "user_tz": -180
    },
    "id": "mHDz7ZYlg9NH"
   },
   "outputs": [],
   "source": [
    "# Create DataFrame representing the stream of input lines\n",
    "\n",
    "from pyspark.sql.types import StructType\n",
    "\n",
    "userSchema = StructType()\\\n",
    "    .add(\"index\", \"string\")\\\n",
    "    .add(\"text\", \"string\")\n",
    "\n",
    "lines = spark \\\n",
    "    .readStream \\\n",
    "    .option(\"sep\", \",\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(userSchema) \\\n",
    "    .csv(\"oncology_notes/\", multiLine=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 132,
     "status": "ok",
     "timestamp": 1759303448453,
     "user": {
      "displayName": "Mehmet Dağ",
      "userId": "14052875917891496135"
     },
     "user_tz": -180
    },
    "id": "75HfeztbiHIp",
    "outputId": "8c621b72-56ff-43a0-ebe9-cc95447cfb60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- index: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lines.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1759303448652,
     "user": {
      "displayName": "Mehmet Dağ",
      "userId": "14052875917891496135"
     },
     "user_tz": -180
    },
    "id": "i0265q0vyPmE"
   },
   "outputs": [],
   "source": [
    "# Split the lines into sentences\n",
    "text_df = lines.select(lines.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FUfiMfUr3Lao"
   },
   "source": [
    "## NER Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 141871,
     "status": "ok",
     "timestamp": 1759303590546,
     "user": {
      "displayName": "Mehmet Dağ",
      "userId": "14052875917891496135"
     },
     "user_tz": -180
    },
    "id": "dYMzfqbkiq1D",
    "outputId": "7430f6e4-3014-4d8d-e61f-4ef5057dc09f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence_detector_dl_healthcare download started this may take some time.\n",
      "Approximate size to download 367.3 KB\n",
      "[OK!]\n",
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[OK!]\n",
      "ner_jsl download started this may take some time.\n",
      "Approximate size to download 14.5 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "# Annotator that transforms a text column from dataframe into an Annotation ready for NLP\n",
    "documentAssembler = DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "sentenceDetector = SentenceDetectorDLModel.pretrained(\"sentence_detector_dl_healthcare\",\"en\",\"clinical/models\")\\\n",
    "    .setInputCols([\"document\"])\\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "# Tokenizer splits words in a relevant format for NLP\n",
    "tokenizer = Tokenizer()\\\n",
    "    .setInputCols([\"sentence\"])\\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "# Clinical word embeddings trained on PubMED dataset\n",
    "word_embeddings = WordEmbeddingsModel.pretrained(\"embeddings_clinical\",\"en\",\"clinical/models\")\\\n",
    "    .setInputCols([\"sentence\",\"token\"])\\\n",
    "    .setOutputCol(\"embeddings\")\n",
    "\n",
    "# NER model trained on i2b2 (sampled from MIMIC) dataset\n",
    "jsl_ner = MedicalNerModel.pretrained(\"ner_jsl\",\"en\",\"clinical/models\")\\\n",
    "    .setInputCols([\"sentence\",\"token\",\"embeddings\"])\\\n",
    "    .setOutputCol(\"ner\")\n",
    "\n",
    "ner_converter = NerConverterInternal()\\\n",
    "    .setInputCols([\"sentence\",\"token\",\"ner\"])\\\n",
    "    .setOutputCol(\"ner_chunk\")\n",
    "\n",
    "# Assemble the pipeline\n",
    "nlpPipeline = Pipeline(\n",
    "    stages=[\n",
    "        documentAssembler,\n",
    "        sentenceDetector,\n",
    "        tokenizer,\n",
    "        word_embeddings,\n",
    "        jsl_ner,\n",
    "        ner_converter\n",
    "        ])\n",
    "\n",
    "# Fit the pipeline on the data\n",
    "model = nlpPipeline.fit(text_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 956,
     "status": "ok",
     "timestamp": 1759303591512,
     "user": {
      "displayName": "Mehmet Dağ",
      "userId": "14052875917891496135"
     },
     "user_tz": -180
    },
    "id": "HxtFXbAlyUar"
   },
   "outputs": [],
   "source": [
    "# Transform the data\n",
    "result_df = model.transform(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 276,
     "status": "ok",
     "timestamp": 1759303591794,
     "user": {
      "displayName": "Mehmet Dağ",
      "userId": "14052875917891496135"
     },
     "user_tz": -180
    },
    "id": "6qV6Peon44WJ",
    "outputId": "cbc80628-0cc7-43f1-8c9e-e050d43a9c04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- entity: string (nullable = true)\n",
      " |-- ner_label: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Explode the entities and their labels\n",
    "entities_df = result_df.select(F.explode(F.arrays_zip(result_df.ner_chunk.result,\n",
    "                                                      result_df.ner_chunk.metadata)).alias(\"cols\"))\\\n",
    "                  .select(F.expr(\"cols['0']\").alias(\"entity\"),\n",
    "                          F.expr(\"cols['1']['entity']\").alias(\"ner_label\"))\n",
    "\n",
    "entities_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t2g_ZbULz_b_"
   },
   "source": [
    "## Write Streaming\n",
    "The core syntax for writing the streaming data in Apache Spark:\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "df.writeStream \\\n",
    "  .outputMode('complete') \\ # by default is append\n",
    "  .format('parquet') \\ # this is optional, parquet is default\n",
    "  .option(\"key\", \"value\") \\\n",
    "  .start(path)\n",
    "```\n",
    "\n",
    "Pyspark has a method `outputMode()` to specify the saving mode:\n",
    "\n",
    "The “Output” is defined as what gets written out to the external storage. The output can be defined in a different mode:\n",
    "\n",
    "- **Complete Mode** - The entire updated Result Table will be written to the external storage. It is up to the storage connector to decide how to handle writing of the entire table.\n",
    "\n",
    "- **Append Mode** - Only the new rows appended in the Result Table since the last trigger will be written to the external storage. This is applicable only on the queries where existing rows in the Result Table are not expected to change.\n",
    "\n",
    "- **Update Mode** - Only the rows that were updated in the Result Table since the last trigger will be written to the external storage (available since Spark 2.1.1). Note that this is different from the Complete Mode in that this mode only outputs the rows that have changed since the last trigger. If the query doesn’t contain aggregations, it will be equivalent to Append mode.\n",
    "\n",
    "* `memory` : Store the results of your streaming query in memory for debugging, testing, or interactive analysis purposes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jV3NkCYJ7wFp"
   },
   "source": [
    "We will create a streaming that shows the entity occurences in the dataset we have. We will add new data later and check how streaming work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 2049,
     "status": "ok",
     "timestamp": 1759303593845,
     "user": {
      "displayName": "Mehmet Dağ",
      "userId": "14052875917891496135"
     },
     "user_tz": -180
    },
    "id": "fKYfsbAh5ucu"
   },
   "outputs": [],
   "source": [
    "# Group by 'entity' and 'tag', and count the occurrences\n",
    "entity_counts_df = entities_df.groupBy(\"entity\", \"ner_label\").count() \\\n",
    "        .writeStream \\\n",
    "        .queryName(\"entity_counts_table\") \\\n",
    "        .outputMode(\"complete\") \\\n",
    "        .format(\"memory\") \\\n",
    "        .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45047,
     "status": "ok",
     "timestamp": 1759303638901,
     "user": {
      "displayName": "Mehmet Dağ",
      "userId": "14052875917891496135"
     },
     "user_tz": -180
    },
    "id": "BGOB5m8EA0tJ",
    "outputId": "ffd30f13-6981-482c-8e91-251c64a919aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import threading\n",
    "threading.Event().wait(45)  # Pauses the execution for 45 seconds to allow refreshing streaming to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 593,
     "status": "ok",
     "timestamp": 1759303639466,
     "user": {
      "displayName": "Mehmet Dağ",
      "userId": "14052875917891496135"
     },
     "user_tz": -180
    },
    "id": "huYthxVQ-J_Y",
    "outputId": "f9946ad6-3b54-4333-8ad3-3873b72f9ffa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------------+-----+\n",
      "|entity             |ner_label                |count|\n",
      "+-------------------+-------------------------+-----+\n",
      "|Phenergan          |Drug_BrandName           |1    |\n",
      "|August 14          |Date                     |1    |\n",
      "|hospital           |Clinical_Dept            |1    |\n",
      "|illicit drug       |Substance                |1    |\n",
      "|pleural effusion   |Disease_Syndrome_Disorder|2    |\n",
      "|heart rate 83      |Pulse                    |1    |\n",
      "|alcohol            |Alcohol                  |1    |\n",
      "|urgent care center |Clinical_Dept            |1    |\n",
      "|CVA                |Cerebrovascular_Disease  |1    |\n",
      "|pericardial window |Procedure                |1    |\n",
      "|clubbing           |Symptom                  |1    |\n",
      "|nondistended       |Symptom                  |1    |\n",
      "|atrial fibrillation|Heart_Disease            |1    |\n",
      "|2007               |Date                     |3    |\n",
      "|Chest x-ray        |Test                     |1    |\n",
      "|right-sided        |Direction                |1    |\n",
      "+-------------------+-------------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from entity_counts_table\").show(truncate=False)   # interactively query in-memory table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 292,
     "status": "ok",
     "timestamp": 1759303639759,
     "user": {
      "displayName": "Mehmet Dağ",
      "userId": "14052875917891496135"
     },
     "user_tz": -180
    },
    "id": "9ro5qjW-yjTB",
    "outputId": "3c4a1e34-1005-48e0-e91b-0f91ca87f703"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# entity counts in the table\n",
    "spark.sql(\"select * from entity_counts_table\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R_virzMC82Fy"
   },
   "source": [
    "Lets check the entities that occurs in the table more than one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 571,
     "status": "ok",
     "timestamp": 1759303640333,
     "user": {
      "displayName": "Mehmet Dağ",
      "userId": "14052875917891496135"
     },
     "user_tz": -180
    },
    "id": "PdlrXa8K0eQo",
    "outputId": "4bf3602a-6df5-4dcc-8df3-c7d91c72bd7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+-----+\n",
      "|          entity|           ner_label|count|\n",
      "+----------------+--------------------+-----+\n",
      "|            2007|                Date|    3|\n",
      "|pleural effusion|Disease_Syndrome_...|    2|\n",
      "+----------------+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the entities occured more than one time\n",
    "spark.sql(f\"SELECT * FROM entity_counts_table WHERE count > 1 ORDER BY count DESC\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WL6Q1zHOjW9V"
   },
   "source": [
    "Add another file for streaming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 270,
     "status": "ok",
     "timestamp": 1759303640598,
     "user": {
      "displayName": "Mehmet Dağ",
      "userId": "14052875917891496135"
     },
     "user_tz": -180
    },
    "id": "ffbFkPLxjY4H"
   },
   "outputs": [],
   "source": [
    "# Downloading sample datasets.\n",
    "! wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Healthcare/data/oncology_notes/mt_oncology_5.txt -P oncology_notes/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30295,
     "status": "ok",
     "timestamp": 1759303670896,
     "user": {
      "displayName": "Mehmet Dağ",
      "userId": "14052875917891496135"
     },
     "user_tz": -180
    },
    "id": "EYoHknGQja0T",
    "outputId": "1c241286-42bd-4dd8-c6b2-3f4e5cb82839"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threading.Event().wait(30)  # Pauses the execution for 30 seconds to allow refreshing streaming to process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "42afWyK28kUf"
   },
   "source": [
    "Lets check how the entity count table changed after adding the new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1759303670911,
     "user": {
      "displayName": "Mehmet Dağ",
      "userId": "14052875917891496135"
     },
     "user_tz": -180
    },
    "id": "aLb7cZ_MjfEp",
    "outputId": "2da04123-bb33-49df-e06d-ef7fef13e169"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select * from entity_counts_table\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 133,
     "status": "ok",
     "timestamp": 1759303671046,
     "user": {
      "displayName": "Mehmet Dağ",
      "userId": "14052875917891496135"
     },
     "user_tz": -180
    },
    "id": "1ZRaedtsjhpi",
    "outputId": "ef8638ff-348a-4a76-b32d-2e229b79e0e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------------------+-----+\n",
      "|entity          |ner_label                |count|\n",
      "+----------------+-------------------------+-----+\n",
      "|him             |Gender                   |5    |\n",
      "|he              |Gender                   |4    |\n",
      "|2007            |Date                     |3    |\n",
      "|his             |Gender                   |2    |\n",
      "|rectal bleeding |Symptom                  |2    |\n",
      "|endoscopy       |Procedure                |2    |\n",
      "|pleural effusion|Disease_Syndrome_Disorder|2    |\n",
      "+----------------+-------------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(f\"SELECT * FROM entity_counts_table WHERE count > 1 ORDER BY count DESC\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXChxSF_plst"
   },
   "source": [
    "Lets add a new file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 233,
     "status": "ok",
     "timestamp": 1759303671282,
     "user": {
      "displayName": "Mehmet Dağ",
      "userId": "14052875917891496135"
     },
     "user_tz": -180
    },
    "id": "Ke97WCzbph7S"
   },
   "outputs": [],
   "source": [
    "# add another file\n",
    "! wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Healthcare/data/oncology_notes/mt_oncology_9.txt -P oncology_notes/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30048,
     "status": "ok",
     "timestamp": 1759303701338,
     "user": {
      "displayName": "Mehmet Dağ",
      "userId": "14052875917891496135"
     },
     "user_tz": -180
    },
    "id": "ulVQcZORpe0h",
    "outputId": "7b678001-9513-4418-82fd-b6cff788770b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threading.Event().wait(30)  # Pauses the execution for 30 seconds to allow refreshing streaming to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 113,
     "status": "ok",
     "timestamp": 1759303701415,
     "user": {
      "displayName": "Mehmet Dağ",
      "userId": "14052875917891496135"
     },
     "user_tz": -180
    },
    "id": "EfzN3ONzpe1C",
    "outputId": "55a603bc-7aaf-4f58-ed17-26f6f4fed8e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select * from entity_counts_table\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 117,
     "status": "ok",
     "timestamp": 1759303701533,
     "user": {
      "displayName": "Mehmet Dağ",
      "userId": "14052875917891496135"
     },
     "user_tz": -180
    },
    "id": "GDib_Kpfpe1D",
    "outputId": "a1ea0265-2c1b-46fc-819a-5fc4f2f173a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------------------+-----+\n",
      "|entity          |ner_label                   |count|\n",
      "+----------------+----------------------------+-----+\n",
      "|he              |Gender                      |5    |\n",
      "|him             |Gender                      |5    |\n",
      "|2007            |Date                        |3    |\n",
      "|acute           |Modifier                    |2    |\n",
      "|rectal bleeding |Symptom                     |2    |\n",
      "|his             |Gender                      |2    |\n",
      "|endoscopy       |Procedure                   |2    |\n",
      "|right           |Direction                   |2    |\n",
      "|pleural effusion|Disease_Syndrome_Disorder   |2    |\n",
      "|lower extremity |External_body_part_or_region|2    |\n",
      "|hemoglobin      |Test                        |2    |\n",
      "+----------------+----------------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(f\"SELECT * FROM entity_counts_table WHERE count > 1 ORDER BY count DESC\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MdVuxTRHl6HX"
   },
   "source": [
    "# Stop And Restart Streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rdO3qkAShVP"
   },
   "source": [
    "You may need to refresh the query cells to visualize the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 151,
     "status": "ok",
     "timestamp": 1759303701687,
     "user": {
      "displayName": "Mehmet Dağ",
      "userId": "14052875917891496135"
     },
     "user_tz": -180
    },
    "id": "fvW0xfDnmHAP"
   },
   "outputs": [],
   "source": [
    "entity_counts_df.stop()  # Stop the current query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1759303701688,
     "user": {
      "displayName": "Mehmet Dağ",
      "userId": "14052875917891496135"
     },
     "user_tz": -180
    },
    "id": "LV5_4kG9lyY_"
   },
   "outputs": [],
   "source": [
    "# Optionally, you may want to wait for the query to complete before restarting\n",
    "entity_counts_df.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 130,
     "status": "ok",
     "timestamp": 1759303701815,
     "user": {
      "displayName": "Mehmet Dağ",
      "userId": "14052875917891496135"
     },
     "user_tz": -180
    },
    "id": "ADzHGkHrmD6C"
   },
   "outputs": [],
   "source": [
    "# start the query\n",
    "new_query = entities_df.groupBy(\"entity\", \"ner_label\").count() \\\n",
    "        .writeStream \\\n",
    "        .queryName(\"entity_counts_table\") \\\n",
    "        .outputMode(\"complete\") \\\n",
    "        .format(\"memory\") \\\n",
    "        .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30078,
     "status": "ok",
     "timestamp": 1759303731898,
     "user": {
      "displayName": "Mehmet Dağ",
      "userId": "14052875917891496135"
     },
     "user_tz": -180
    },
    "id": "6AgiNQEvn_-G",
    "outputId": "518c78b2-12cd-45aa-94f8-78bc2b242bdf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threading.Event().wait(30)  # Pauses the execution for 30 seconds to allow refreshing streaming to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 59,
     "status": "ok",
     "timestamp": 1759303731962,
     "user": {
      "displayName": "Mehmet Dağ",
      "userId": "14052875917891496135"
     },
     "user_tz": -180
    },
    "id": "bDbkNGQuoATE",
    "outputId": "98dbf1d6-a791-4c0f-9fe1-7610aad50032"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select * from entity_counts_table\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 149,
     "status": "ok",
     "timestamp": 1759303732116,
     "user": {
      "displayName": "Mehmet Dağ",
      "userId": "14052875917891496135"
     },
     "user_tz": -180
    },
    "id": "AmiN5FWooCv6",
    "outputId": "fa5dcda6-4c83-40ab-94c2-06481dd4d649"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------------------+-----+\n",
      "|entity          |ner_label                   |count|\n",
      "+----------------+----------------------------+-----+\n",
      "|he              |Gender                      |5    |\n",
      "|him             |Gender                      |5    |\n",
      "|2007            |Date                        |3    |\n",
      "|acute           |Modifier                    |2    |\n",
      "|rectal bleeding |Symptom                     |2    |\n",
      "|his             |Gender                      |2    |\n",
      "|endoscopy       |Procedure                   |2    |\n",
      "|right           |Direction                   |2    |\n",
      "|pleural effusion|Disease_Syndrome_Disorder   |2    |\n",
      "|lower extremity |External_body_part_or_region|2    |\n",
      "|hemoglobin      |Test                        |2    |\n",
      "+----------------+----------------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(f\"SELECT * FROM entity_counts_table WHERE count > 1 ORDER BY count DESC\").show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
