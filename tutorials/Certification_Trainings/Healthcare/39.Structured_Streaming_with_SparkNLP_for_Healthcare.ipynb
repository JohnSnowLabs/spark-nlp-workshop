{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Sf4WOaxShVD"
      },
      "source": [
        "![JohnSnowLabs](https://sparknlp.org/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp/blob/master/examples/util/39.Structured_Streaming_With_Spark_NLP_for_Healthcare.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQWrDCi6ShVG"
      },
      "source": [
        "# Structured Streaming with Spark NLP for Healthcare"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbQ9JCLtHCPO"
      },
      "source": [
        "This notebook demonstrates the integration of Spark NLP for Healthcare with Spark Structured Streaming. We'll illustrate a straightforward example that performs real-time clinical entity duplication counting."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Start Spark Session"
      ],
      "metadata": {
        "id": "Q8izefQ43Aaj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "license_keys = files.upload()\n",
        "\n",
        "with open(list(license_keys.keys())[0]) as f:\n",
        "    license_keys = json.load(f)\n",
        "\n",
        "# Defining license key-value pairs as local variables\n",
        "locals().update(license_keys)\n",
        "\n",
        "# Adding license key-value pairs to environment variables\n",
        "os.environ.update(license_keys)"
      ],
      "metadata": {
        "id": "e8UK-UQ0jIhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing pyspark and spark-nlp\n",
        "! pip install --upgrade -q pyspark==3.4.1 spark-nlp==$PUBLIC_VERSION\n",
        "\n",
        "# Installing Spark NLP Healthcare\n",
        "! pip install --upgrade -q spark-nlp-jsl==$JSL_VERSION  --extra-index-url https://pypi.johnsnowlabs.com/$SECRET"
      ],
      "metadata": {
        "id": "CTnWHJThjOh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "import sparknlp\n",
        "import sparknlp_jsl\n",
        "\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp_jsl.annotator import *\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.ml import Pipeline,PipelineModel\n",
        "\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth', 200)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "params = {\"spark.driver.memory\":\"16G\",\n",
        "          \"spark.kryoserializer.buffer.max\":\"2000M\",\n",
        "          \"spark.driver.maxResultSize\":\"2000M\"}\n",
        "\n",
        "print(\"Spark NLP Version :\", sparknlp.version())\n",
        "print(\"Spark NLP_JSL Version :\", sparknlp_jsl.version())\n",
        "\n",
        "spark = sparknlp_jsl.start(license_keys['SECRET'],params=params)\n",
        "\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "cagD5DSSjUOr",
        "outputId": "9bad1afd-f6b2-46ae-8285-e384227c96bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP Version : 5.1.2\n",
            "Spark NLP_JSL Version : 5.1.2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x791023b8d450>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://c4776d8c2e35:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.4.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark NLP Licensed</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read Streaming"
      ],
      "metadata": {
        "id": "N1T9lgiv3Ocb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_DFTLK4HLhF"
      },
      "source": [
        "First, we create a directory where the files for streaming will reside"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DeGx0cax5V8"
      },
      "outputs": [],
      "source": [
        "!mkdir oncology_notes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading sample datasets.\n",
        "! wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Healthcare/data/oncology_notes/mt_oncology_0.txt -P oncology_notes/"
      ],
      "metadata": {
        "id": "dIPVh-eVfMNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The core syntax for reading the streaming data in Apache Spark:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "spark.readStream \\\n",
        "     .format() \\ # this is the raw format you are reading from\n",
        "     .option(\"key\", \"value\") \\\n",
        "     .schema() \\ # require to specify the schema\n",
        "     .load(path)\n",
        "```\n",
        "\n",
        "The core syntax to read the static and streaming data are pretty similar; there are two main differences:\n",
        "\n",
        "- We are using read in static read mode but using readStream in streaming read mode.\n",
        "- By default, Structured Streaming from file-based sources requires you to specify the schema rather than rely on Spark to infer it automatically. This restriction ensures a consistent schema will be used for the streaming query, even in the case of failures. You can reenable schema inference by setting `spark.sql.streaming.schemaInference` to true for the ad-hoc use case.\n",
        "\n"
      ],
      "metadata": {
        "id": "rXC9hb9Czhc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrame representing the stream of input lines\n",
        "\n",
        "from pyspark.sql.types import StructType\n",
        "\n",
        "userSchema = StructType()\\\n",
        "    .add(\"index\", \"string\")\\\n",
        "    .add(\"text\", \"string\")\n",
        "\n",
        "lines = spark \\\n",
        "    .readStream \\\n",
        "    .option(\"sep\", \",\") \\\n",
        "    .option(\"header\", \"true\") \\\n",
        "    .schema(userSchema) \\\n",
        "    .csv(\"oncology_notes/\", multiLine=True)"
      ],
      "metadata": {
        "id": "mHDz7ZYlg9NH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75HfeztbiHIp",
        "outputId": "b4580e42-e360-4485-8d00-e96d9aee23b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- index: string (nullable = true)\n",
            " |-- text: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0265q0vyPmE"
      },
      "outputs": [],
      "source": [
        "# Split the lines into sentences\n",
        "text_df = lines.select(lines.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NER Pipeline"
      ],
      "metadata": {
        "id": "FUfiMfUr3Lao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Annotator that transforms a text column from dataframe into an Annotation ready for NLP\n",
        "documentAssembler = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "sentenceDetector = SentenceDetectorDLModel.pretrained(\"sentence_detector_dl_healthcare\",\"en\",\"clinical/models\")\\\n",
        "    .setInputCols([\"document\"])\\\n",
        "    .setOutputCol(\"sentence\")\n",
        "\n",
        "# Tokenizer splits words in a relevant format for NLP\n",
        "tokenizer = Tokenizer()\\\n",
        "    .setInputCols([\"sentence\"])\\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "# Clinical word embeddings trained on PubMED dataset\n",
        "word_embeddings = WordEmbeddingsModel.pretrained(\"embeddings_clinical\",\"en\",\"clinical/models\")\\\n",
        "    .setInputCols([\"sentence\",\"token\"])\\\n",
        "    .setOutputCol(\"embeddings\")\n",
        "\n",
        "# NER model trained on i2b2 (sampled from MIMIC) dataset\n",
        "jsl_ner = MedicalNerModel.pretrained(\"ner_jsl\",\"en\",\"clinical/models\")\\\n",
        "    .setInputCols([\"sentence\",\"token\",\"embeddings\"])\\\n",
        "    .setOutputCol(\"ner\")\n",
        "\n",
        "ner_converter = NerConverterInternal()\\\n",
        "    .setInputCols([\"sentence\",\"token\",\"ner\"])\\\n",
        "    .setOutputCol(\"ner_chunk\")\n",
        "\n",
        "# Assemble the pipeline\n",
        "nlpPipeline = Pipeline(\n",
        "    stages=[\n",
        "        documentAssembler,\n",
        "        sentenceDetector,\n",
        "        tokenizer,\n",
        "        word_embeddings,\n",
        "        jsl_ner,\n",
        "        ner_converter\n",
        "        ])\n",
        "\n",
        "# Fit the pipeline on the data\n",
        "model = nlpPipeline.fit(text_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYMzfqbkiq1D",
        "outputId": "a29bf15c-27b8-4918-a25a-c808136d41f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentence_detector_dl_healthcare download started this may take some time.\n",
            "Approximate size to download 367.3 KB\n",
            "[OK!]\n",
            "embeddings_clinical download started this may take some time.\n",
            "Approximate size to download 1.6 GB\n",
            "[OK!]\n",
            "ner_jsl download started this may take some time.\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxtFXbAlyUar"
      },
      "outputs": [],
      "source": [
        "# Transform the data\n",
        "result_df = model.transform(lines)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Explode the entities and their labels\n",
        "entities_df = result_df.select(F.explode(F.arrays_zip(result_df.ner_chunk.result,\n",
        "                                                      result_df.ner_chunk.metadata)).alias(\"cols\"))\\\n",
        "                  .select(F.expr(\"cols['0']\").alias(\"entity\"),\n",
        "                          F.expr(\"cols['1']['entity']\").alias(\"ner_label\"))\n",
        "\n",
        "entities_df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qV6Peon44WJ",
        "outputId": "ce601278-635d-47fa-cfd6-10f980fb50e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- entity: string (nullable = true)\n",
            " |-- ner_label: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Write Streaming\n",
        "The core syntax for writing the streaming data in Apache Spark:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "df.writeStream \\\n",
        "  .outputMode('complete') \\ # by default is append\n",
        "  .format('parquet') \\ # this is optional, parquet is default\n",
        "  .option(\"key\", \"value\") \\\n",
        "  .start(path)\n",
        "```\n",
        "\n",
        "Pyspark has a method `outputMode()` to specify the saving mode:\n",
        "\n",
        "The “Output” is defined as what gets written out to the external storage. The output can be defined in a different mode:\n",
        "\n",
        "- **Complete Mode** - The entire updated Result Table will be written to the external storage. It is up to the storage connector to decide how to handle writing of the entire table.\n",
        "\n",
        "- **Append Mode** - Only the new rows appended in the Result Table since the last trigger will be written to the external storage. This is applicable only on the queries where existing rows in the Result Table are not expected to change.\n",
        "\n",
        "- **Update Mode** - Only the rows that were updated in the Result Table since the last trigger will be written to the external storage (available since Spark 2.1.1). Note that this is different from the Complete Mode in that this mode only outputs the rows that have changed since the last trigger. If the query doesn’t contain aggregations, it will be equivalent to Append mode.\n",
        "\n",
        "*`memory` : Store the results of your streaming query in memory for debugging, testing, or interactive analysis purposes.\n",
        "\n"
      ],
      "metadata": {
        "id": "t2g_ZbULz_b_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will create a streaming that shows the entity occurences in the dataset we have. We will add new data later and check how streaming work."
      ],
      "metadata": {
        "id": "jV3NkCYJ7wFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by 'entity' and 'tag', and count the occurrences\n",
        "entity_counts_df = entities_df.groupBy(\"entity\", \"ner_label\").count() \\\n",
        "        .writeStream \\\n",
        "        .queryName(\"entity_counts_table\") \\\n",
        "        .outputMode(\"complete\") \\\n",
        "        .format(\"memory\") \\\n",
        "        .start()"
      ],
      "metadata": {
        "id": "fKYfsbAh5ucu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGOB5m8EA0tJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67f3e7b1-4643-4dea-ba13-52d3fbb2f855"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "import threading\n",
        "threading.Event().wait(45)  # Pauses the execution for 45 seconds to allow refreshing streaming to process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huYthxVQ-J_Y",
        "outputId": "973ecb57-e2c0-43a7-be59-ca0e55c6542d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+-------------------------+-----+\n",
            "|entity             |ner_label                |count|\n",
            "+-------------------+-------------------------+-----+\n",
            "|Phenergan          |Drug_BrandName           |1    |\n",
            "|August 14          |Date                     |1    |\n",
            "|hospital           |Clinical_Dept            |1    |\n",
            "|illicit drug       |Substance                |1    |\n",
            "|pleural effusion   |Disease_Syndrome_Disorder|2    |\n",
            "|heart rate 83      |Pulse                    |1    |\n",
            "|alcohol            |Alcohol                  |1    |\n",
            "|urgent care center |Clinical_Dept            |1    |\n",
            "|CVA                |Cerebrovascular_Disease  |1    |\n",
            "|pericardial window |Procedure                |1    |\n",
            "|clubbing           |Symptom                  |1    |\n",
            "|nondistended       |Symptom                  |1    |\n",
            "|atrial fibrillation|Heart_Disease            |1    |\n",
            "|2007               |Date                     |3    |\n",
            "|Chest x-ray        |Test                     |1    |\n",
            "|right-sided        |Direction                |1    |\n",
            "+-------------------+-------------------------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark.sql(\"select * from entity_counts_table\").show(truncate=False)   # interactively query in-memory table"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# entity counts in the table\n",
        "spark.sql(\"select * from entity_counts_table\").count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ro5qjW-yjTB",
        "outputId": "b36a9119-666e-421a-c924-47c17774f227"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets check the entities that occurs in the table more than one."
      ],
      "metadata": {
        "id": "R_virzMC82Fy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check the entities occured more than one time\n",
        "spark.sql(f\"SELECT * FROM entity_counts_table WHERE count > 1 ORDER BY count DESC\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdlrXa8K0eQo",
        "outputId": "8bba47b1-ff69-4c3d-df52-d85f3d33d39e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+--------------------+-----+\n",
            "|          entity|           ner_label|count|\n",
            "+----------------+--------------------+-----+\n",
            "|            2007|                Date|    3|\n",
            "|pleural effusion|Disease_Syndrome_...|    2|\n",
            "+----------------+--------------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add another file for streaming."
      ],
      "metadata": {
        "id": "WL6Q1zHOjW9V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading sample datasets.\n",
        "! wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Healthcare/data/oncology_notes/mt_oncology_5.txt -P oncology_notes/"
      ],
      "metadata": {
        "id": "ffbFkPLxjY4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threading.Event().wait(30)  # Pauses the execution for 30 seconds to allow refreshing streaming to process"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYoHknGQja0T",
        "outputId": "1b5987ef-3e2c-4f51-c714-30dd5325999f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets check how the entity count table changed after adding the new data."
      ],
      "metadata": {
        "id": "42afWyK28kUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"select * from entity_counts_table\").count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLb7cZ_MjfEp",
        "outputId": "596fe532-e17f-4c82-f3e6-366a281ae99d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(f\"SELECT * FROM entity_counts_table WHERE count > 1 ORDER BY count DESC\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZRaedtsjhpi",
        "outputId": "2ee59b96-a793-4aee-d9de-c98dc3a9f5c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+-------------------------+-----+\n",
            "|entity          |ner_label                |count|\n",
            "+----------------+-------------------------+-----+\n",
            "|him             |Gender                   |5    |\n",
            "|he              |Gender                   |4    |\n",
            "|2007            |Date                     |3    |\n",
            "|his             |Gender                   |2    |\n",
            "|rectal bleeding |Symptom                  |2    |\n",
            "|endoscopy       |Procedure                |2    |\n",
            "|pleural effusion|Disease_Syndrome_Disorder|2    |\n",
            "+----------------+-------------------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets add a new file."
      ],
      "metadata": {
        "id": "rXChxSF_plst"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# add another file\n",
        "! wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Healthcare/data/oncology_notes/mt_oncology_9.txt -P oncology_notes/"
      ],
      "metadata": {
        "id": "Ke97WCzbph7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threading.Event().wait(30)  # Pauses the execution for 30 seconds to allow refreshing streaming to process"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0318e626-1aa7-4a2a-cb3b-db33e002589c",
        "id": "ulVQcZORpe0h"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"select * from entity_counts_table\").count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c35d58c-bbb3-4400-af0e-162a45c32caf",
        "id": "EfzN3ONzpe1C"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(f\"SELECT * FROM entity_counts_table WHERE count > 1 ORDER BY count DESC\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41e4e55e-0c9d-4035-f776-a95bb241a482",
        "id": "GDib_Kpfpe1D"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+----------------------------+-----+\n",
            "|entity          |ner_label                   |count|\n",
            "+----------------+----------------------------+-----+\n",
            "|he              |Gender                      |5    |\n",
            "|him             |Gender                      |5    |\n",
            "|2007            |Date                        |3    |\n",
            "|acute           |Modifier                    |2    |\n",
            "|rectal bleeding |Symptom                     |2    |\n",
            "|his             |Gender                      |2    |\n",
            "|endoscopy       |Procedure                   |2    |\n",
            "|right           |Direction                   |2    |\n",
            "|pleural effusion|Disease_Syndrome_Disorder   |2    |\n",
            "|lower extremity |External_body_part_or_region|2    |\n",
            "|hemoglobin      |Test                        |2    |\n",
            "+----------------+----------------------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stop And Restart Streaming"
      ],
      "metadata": {
        "id": "MdVuxTRHl6HX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rdO3qkAShVP"
      },
      "source": [
        "You may need to refresh the query cells to visualize the result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "entity_counts_df.stop()  # Stop the current query"
      ],
      "metadata": {
        "id": "fvW0xfDnmHAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optionally, you may want to wait for the query to complete before restarting\n",
        "entity_counts_df.awaitTermination()"
      ],
      "metadata": {
        "id": "LV5_4kG9lyY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# start the query\n",
        "new_query = entities_df.groupBy(\"entity\", \"ner_label\").count() \\\n",
        "        .writeStream \\\n",
        "        .queryName(\"entity_counts_table\") \\\n",
        "        .outputMode(\"complete\") \\\n",
        "        .format(\"memory\") \\\n",
        "        .start()"
      ],
      "metadata": {
        "id": "ADzHGkHrmD6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threading.Event().wait(30)  # Pauses the execution for 30 seconds to allow refreshing streaming to process"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AgiNQEvn_-G",
        "outputId": "f932b790-1656-4200-d133-f08d0f3c31db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"select * from entity_counts_table\").count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDbkNGQuoATE",
        "outputId": "602fa6f8-e601-4d27-91b9-9d311eca3e59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(f\"SELECT * FROM entity_counts_table WHERE count > 1 ORDER BY count DESC\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmiN5FWooCv6",
        "outputId": "63223f7b-b331-47c1-df03-f8b378aa293c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+----------------------------+-----+\n",
            "|entity          |ner_label                   |count|\n",
            "+----------------+----------------------------+-----+\n",
            "|he              |Gender                      |5    |\n",
            "|him             |Gender                      |5    |\n",
            "|2007            |Date                        |3    |\n",
            "|acute           |Modifier                    |2    |\n",
            "|rectal bleeding |Symptom                     |2    |\n",
            "|his             |Gender                      |2    |\n",
            "|endoscopy       |Procedure                   |2    |\n",
            "|right           |Direction                   |2    |\n",
            "|pleural effusion|Disease_Syndrome_Disorder   |2    |\n",
            "|lower extremity |External_body_part_or_region|2    |\n",
            "|hemoglobin      |Test                        |2    |\n",
            "+----------------+----------------------------+-----+\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}