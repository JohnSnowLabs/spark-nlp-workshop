{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rZNvKPHPgrYg"
   },
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A4HVg4gwgxCR"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/2.3.Contextual_Assertion.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h6tS8JrcFV4R"
   },
   "source": [
    "# üìúContextual Assertion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NzQ-FurKg5j7"
   },
   "source": [
    "\n",
    "\n",
    "This model identifies  contextual cues within text data, such as negation, uncertainty etc. It is used\n",
    "clinical assertion detection, etc. It annotates text chunks with assertions based on configurable rules,\n",
    "prefix and suffix patterns, and exception patterns.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6WOk4eXRFwgT"
   },
   "source": [
    "## **üé¨ Colab Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q2mnGTQQWvYv"
   },
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "from google.colab import files\n",
    "\n",
    "if 'spark_jsl.json' not in os.listdir():\n",
    "  license_keys = files.upload()\n",
    "  os.rename(list(license_keys.keys())[0], 'spark_jsl.json')\n",
    "\n",
    "with open('spark_jsl.json') as f:\n",
    "    license_keys = json.load(f)\n",
    "\n",
    "# Defining license key-value pairs as local variables\n",
    "locals().update(license_keys)\n",
    "os.environ.update(license_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HnRQizBbhnQn"
   },
   "outputs": [],
   "source": [
    "# Installing pyspark and spark-nlp\n",
    "! pip install --upgrade -q pyspark==3.4.0  spark-nlp==$PUBLIC_VERSION\n",
    "\n",
    "# Installing Spark NLP Healthcare\n",
    "! pip install --upgrade -q spark-nlp-jsl==$JSL_VERSION  --extra-index-url https://pypi.johnsnowlabs.com/$SECRET\n",
    "\n",
    "# Installing Spark NLP Display Library for visualization\n",
    "! pip install --upgrade -q spark-nlp-display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256
    },
    "executionInfo": {
     "elapsed": 68086,
     "status": "ok",
     "timestamp": 1733912236146,
     "user": {
      "displayName": "G√∂khan T√úRER",
      "userId": "17886843627290606834"
     },
     "user_tz": -180
    },
    "id": "3QB68-iqhttM",
    "outputId": "68c0513f-4f6e-4347-e321-46f1c9af1799"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP Version : 5.5.1\n",
      "Spark NLP_JSL Version : 5.5.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://c3e989b9f1f2:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark NLP Licensed</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7e7290ce70d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import sparknlp\n",
    "import sparknlp_jsl\n",
    "\n",
    "from sparknlp.base import *\n",
    "from sparknlp.common import *\n",
    "from sparknlp.training import *\n",
    "from sparknlp.annotator import *\n",
    "\n",
    "from sparknlp_jsl.base import *\n",
    "from sparknlp_jsl.annotator import *\n",
    "from sparknlp_jsl.annotator.flattener import *\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.types import StringType\n",
    "import pyspark.sql.types as T\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "spark = sparknlp_jsl.start(license_keys['SECRET'] #gpu=True\n",
    "                           )\n",
    "print(\"Spark NLP Version :\", sparknlp.version())\n",
    "print(\"Spark NLP_JSL Version :\", sparknlp_jsl.version())\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1XbF4N-JGQdM"
   },
   "source": [
    "\n",
    "\n",
    "## **üñ®Ô∏è Input/Output Annotation Types**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qsk1TC4DGXkK"
   },
   "source": [
    "- Input: `SENTECE`, `TOKEN`, `CHUNK`\n",
    "\n",
    "- Output: `ASSERTION`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HWaUgBgMG85p"
   },
   "source": [
    "## **üîé Parameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IEgbOUgpHFFd"
   },
   "source": [
    "**Parameters**:\n",
    "\n",
    "- `inputCols` : Input columns containing DOCUMENT, TOKEN, and CHUNK annotations.\n",
    "- `outputCol` : Output column name for ASSERTION annotations.\n",
    "- `assertion` : Assertion label to assign when matched (default: \"absent\").\n",
    "- `caseSensitive` : Whether matching is case-sensitive (default: false).\n",
    "- `prefixAndSuffixMatch` : Whether both prefix and suffix must match to annotate (default: false).\n",
    "- `prefixKeywords` : List of prefix keywords to match before a chunk.\n",
    "- `suffixKeywords` : List of suffix keywords to match after a chunk.\n",
    "- `exceptionKeywords` : List of exception keywords to exclude from matches.\n",
    "- `prefixRegexPatterns` : Regex patterns to match as prefixes.\n",
    "- `suffixRegexPatterns` : Regex patterns to match as suffixes.\n",
    "- `exceptionRegexPatterns` : Regex patterns to exclude from matches.\n",
    "- `scopeWindow` : Number of tokens to the left and right of a chunk to search (default: [-1, -1]).\n",
    "- `scopeWindowDelimiters` : Delimiters that restrict the scope window.\n",
    "- `includeChunkToScope` : Whether to include the chunk text itself in scope (default: false).\n",
    "- `confidenceCalculationDirection` : Direction for confidence calculation ‚Äî \"left\", \"right\", or \"both\" (default: \"left\").\n",
    "- `doExceptionHandling` : If true, emits error annotations instead of failing on exceptions (default: false)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hZeqQv5gOv5o"
   },
   "source": [
    "## PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 116276,
     "status": "ok",
     "timestamp": 1733912352413,
     "user": {
      "displayName": "G√∂khan T√úRER",
      "userId": "17886843627290606834"
     },
     "user_tz": -180
    },
    "id": "p_F8kbGPOvJA",
    "outputId": "9d9dc19b-4d9a-494f-c4cc-cf4a0a1db4e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[OK!]\n",
      "ner_clinical download started this may take some time.\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "sentence_detector = SentenceDetector() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols([\"sentence\"]) \\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "word_embeddings = WordEmbeddingsModel \\\n",
    "    .pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\", \"token\"]) \\\n",
    "    .setOutputCol(\"embeddings\")\n",
    "\n",
    "clinical_ner = MedicalNerModel \\\n",
    "    .pretrained(\"ner_clinical\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"ner\")\n",
    "\n",
    "ner_converter = NerConverter() \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"ner\"]) \\\n",
    "    .setOutputCol(\"ner_chunk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0G-4wtokSWNN"
   },
   "source": [
    "### GENERAL USAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PRp3tEuwSzna"
   },
   "source": [
    "To configure assertions using specific keywords and regex patterns, you can use the methods `setPrefixKeywords`, `setSuffixKeywords`, `setPrefixRegexPatterns`, and `setSuffixRegexPatterns`.\n",
    "\n",
    "If you want to exclude certain keywords and patterns from being detected, use `setExceptionKeywords` and `setExceptionRegexPatterns`.\n",
    "\n",
    "To add to the default keywords and regex patterns, or to include pretrained model keywords and patterns, use the methods `addPrefixKeywords` and `addSuffixKeywords`.\n",
    "\n",
    "If case sensitivity is important for the keywords being searched, you can enable this by setting `setCaseSensitive` to `True`.\n",
    "\n",
    "To search for matches at both the beginning and end of chunks, activate this feature by setting `setPrefixAndSuffixMatch` to `True`.\n",
    "\n",
    "You can define the name of the assertion being searched for using the `setAssertion` method.\n",
    "\n",
    "To specify the number of tokens before and after the chunk within which keywords and regex patterns should be searched, use the `setScopeWindow` method. By default, the search is conducted throughout the entire sentence.\n",
    "\n",
    "If you want to include chunk in the search of keywords and regex patterns, the `setIncludeChunkToScope` method is used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j_HV3wwnSrJ3"
   },
   "outputs": [],
   "source": [
    "text = \"\"\"Patient resting in bed. Patient given azithromycin without any difficulty. Patient has audible wheezing, states chest tightness.\n",
    "     No evidence of hypertension. Patient denies nausea at this time. zofran declined. Patient is also having intermittent sweating\n",
    "     associated with pneumonia. Patient refused pain but tylenol still given. Neither substance abuse nor alcohol use however cocaine\n",
    "     once used in the last year. Alcoholism unlikely. Patient has headache and fever. Patient is not diabetic. Not clearly of diarrhea.\n",
    "     Lab reports confirm lymphocytopenia. Cardaic rhythm is Sinus bradycardia. Patient also has a history of cardiac injury.\n",
    "     No kidney injury reported. No abnormal rashes or ulcers. Patient might not have liver disease. Confirmed absence of hemoptysis.\n",
    "     Although patient has severe pneumonia and fever, test reports are negative for COVID-19 infection. COVID-19 viral infection absent.\n",
    "    \"\"\"\n",
    "data = spark.createDataFrame([[text]]).toDF(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17016,
     "status": "ok",
     "timestamp": 1733912375050,
     "user": {
      "displayName": "G√∂khan T√úRER",
      "userId": "17886843627290606834"
     },
     "user_tz": -180
    },
    "id": "OUI269-NSVsX",
    "outputId": "09977c30-e41c-4aa0-bfa5-6ae6803eff45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------------+-------------+-----------------------------------+------------------------+----------------------------+-----------------------------+----------------------------+---------------------------+\n",
      "|assertion_result|assertion_begin|assertion_end|assertion_metadata_assertion_source|assertion_metadata_chunk|assertion_metadata_ner_chunk|assertion_metadata_confidence|assertion_metadata_ner_label|assertion_metadata_sentence|\n",
      "+----------------+---------------+-------------+-----------------------------------+------------------------+----------------------------+-----------------------------+----------------------------+---------------------------+\n",
      "|absent          |178            |183          |assertion                          |5                       |nausea                      |0.8694                       |PROBLEM                     |4                          |\n",
      "|absent          |428            |437          |assertion                          |11                      |Alcoholism                  |0.0                          |PROBLEM                     |9                          |\n",
      "|absent          |496            |503          |assertion                          |14                      |diabetic                    |0.8353                       |PROBLEM                     |11                         |\n",
      "|absent          |664            |676          |assertion                          |19                      |kidney injury               |0.7558                       |PROBLEM                     |16                         |\n",
      "|absent          |691            |705          |assertion                          |20                      |abnormal rashes             |0.7261                       |PROBLEM                     |17                         |\n",
      "|absent          |741            |753          |assertion                          |22                      |liver disease               |0.6839                       |PROBLEM                     |18                         |\n",
      "|absent          |873            |890          |assertion                          |26                      |COVID-19 infection          |0.6839                       |PROBLEM                     |20                         |\n",
      "|absent          |902            |916          |assertion                          |27                      |viral infection             |0.0                          |PROBLEM                     |21                         |\n",
      "+----------------+---------------+-------------+-----------------------------------+------------------------+----------------------------+-----------------------------+----------------------------+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "contextual_assertion = ContextualAssertion() \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"ner_chunk\"]) \\\n",
    "    .setOutputCol(\"assertion\") \\\n",
    "    .setPrefixKeywords([\"no\", \"not\"]) \\\n",
    "    .setSuffixKeywords([\"unlikely\",\"negative\",\"no\"]) \\\n",
    "    .setPrefixRegexPatterns([\"\\\\b(no|without|denies|never|none|free of|not include)\\\\b\"]) \\\n",
    "    .setSuffixRegexPatterns([\"\\\\b(free of|negative for|absence of|not|rule out)\\\\b\"]) \\\n",
    "    .setExceptionKeywords([\"without\"]) \\\n",
    "    .setExceptionRegexPatterns([\"\\\\b(not clearly)\\\\b\"]) \\\n",
    "    .addPrefixKeywords([\"negative for\",\"negative\"]) \\\n",
    "    .addSuffixKeywords([\"absent\",\"neither\"]) \\\n",
    "    .setCaseSensitive(False) \\\n",
    "    .setPrefixAndSuffixMatch(False) \\\n",
    "    .setAssertion(\"absent\") \\\n",
    "    .setScopeWindow([2, 2])\\\n",
    "    .setIncludeChunkToScope(True)\\\n",
    "\n",
    "flattener = Flattener() \\\n",
    "    .setInputCols(\"assertion\") \\\n",
    "\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    stages=[\n",
    "        document_assembler,\n",
    "        sentence_detector,\n",
    "        tokenizer,\n",
    "        word_embeddings,\n",
    "        clinical_ner,\n",
    "        ner_converter,\n",
    "        contextual_assertion,\n",
    "        flattener\n",
    "        ])\n",
    "\n",
    "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "model = pipeline.fit(empty_data)\n",
    "\n",
    "result = model.transform(data)\n",
    "result.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wTMq-U0-bAck"
   },
   "source": [
    "### NEGEX( DEFAULT )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qfjUSqUcdbor"
   },
   "outputs": [],
   "source": [
    "text = \"\"\"Patient resting in bed. Patient given azithromycin without any difficulty. Patient has audible wheezing, states chest tightness.\n",
    "     No evidence of hypertension. Patient denies nausea at this time. zofran declined. Patient is also having intermittent sweating\n",
    "     associated with pneumonia. Patient refused pain but tylenol still given. Neither substance abuse nor alcohol use however cocaine\n",
    "     once used in the last year. Alcoholism unlikely. Patient has headache and fever. Patient is not diabetic. Not clearly of diarrhea.\n",
    "     Lab reports confirm lymphocytopenia. Cardaic rhythm is Sinus bradycardia. Patient also has a history of cardiac injury.\n",
    "     No kidney injury reported. No abnormal rashes or ulcers. Patient might not have liver disease. Confirmed absence of hemoptysis.\n",
    "     Although patient has severe pneumonia and fever, test reports are negative for COVID-19 infection. COVID-19 viral infection absent.\n",
    "    \"\"\"\n",
    "data = spark.createDataFrame([[text]]).toDF(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eoiP07S2hv1Z"
   },
   "outputs": [],
   "source": [
    "contextual_assertion = ContextualAssertion()\\\n",
    "            .setInputCols(\"sentence\", \"token\", \"ner_chunk\") \\\n",
    "            .setOutputCol(\"assertion\") \\\n",
    "\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    stages=[\n",
    "          document_assembler,\n",
    "          sentence_detector,\n",
    "          tokenizer,\n",
    "          word_embeddings,\n",
    "          clinical_ner,\n",
    "          ner_converter,\n",
    "          contextual_assertion,\n",
    "      ])\n",
    "\n",
    "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "model = pipeline.fit(empty_data)\n",
    "\n",
    "result = model.transform(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 694
    },
    "executionInfo": {
     "elapsed": 2858,
     "status": "ok",
     "timestamp": 1733912378450,
     "user": {
      "displayName": "G√∂khan T√úRER",
      "userId": "17886843627290606834"
     },
     "user_tz": -180
    },
    "id": "EuYdcdORc_y8",
    "outputId": "8ea7db8b-c6f5-4d57-93b1-5a1df0c72c40"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    @import url('https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700&display=swap');\n",
       "    @import url('https://fonts.googleapis.com/css2?family=Vistol Regular:wght@300;400;500;600;700&display=swap');\n",
       "    \n",
       "    .spark-nlp-display-scroll-entities {\n",
       "        border: 1px solid #E7EDF0;\n",
       "        border-radius: 3px;\n",
       "        text-align: justify;\n",
       "        \n",
       "    }\n",
       "    .spark-nlp-display-scroll-entities span {  \n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        color: #536B76;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "    }\n",
       "    \n",
       "    .spark-nlp-display-entity-wrapper{\n",
       "    \n",
       "        display: inline-grid;\n",
       "        text-align: center;\n",
       "        border-radius: 4px;\n",
       "        margin: 0 2px 5px 2px;\n",
       "        padding: 1px\n",
       "    }\n",
       "    .spark-nlp-display-entity-name{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "        \n",
       "        background: #f1f2f3;\n",
       "        border-width: medium;\n",
       "        text-align: center;\n",
       "        \n",
       "        font-weight: 400;\n",
       "        \n",
       "        border-radius: 5px;\n",
       "        padding: 2px 5px;\n",
       "        display: block;\n",
       "        margin: 3px 2px;\n",
       "    \n",
       "    }\n",
       "    .spark-nlp-display-entity-type{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        color: #ffffff;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "        \n",
       "        text-transform: uppercase;\n",
       "        \n",
       "        font-weight: 500;\n",
       "\n",
       "        display: block;\n",
       "        padding: 3px 5px;\n",
       "    }\n",
       "    \n",
       "    .spark-nlp-display-entity-resolution{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        color: #ffffff;\n",
       "        font-family: 'Vistol Regular', sans-serif !important;\n",
       "        \n",
       "        text-transform: uppercase;\n",
       "        \n",
       "        font-weight: 500;\n",
       "\n",
       "        display: block;\n",
       "        padding: 3px 5px;\n",
       "    }\n",
       "    \n",
       "    .spark-nlp-display-others{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "        \n",
       "        font-weight: 400;\n",
       "    }\n",
       "\n",
       "</style>\n",
       " <span class=\"spark-nlp-display-others\" style=\"background-color: white\">Patient resting in bed. Patient given </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #8b6673B3\"><span class=\"spark-nlp-display-entity-name\">azithromycin </span><span class=\"spark-nlp-display-entity-type\">TREATMENT</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> without </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #800080B3\"><span class=\"spark-nlp-display-entity-name\">any difficulty </span><span class=\"spark-nlp-display-entity-type\">PROBLEM</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #800080FF\">absent </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">. Patient has </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #800080B3\"><span class=\"spark-nlp-display-entity-name\">audible wheezing </span><span class=\"spark-nlp-display-entity-type\">PROBLEM</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, states </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #800080B3\"><span class=\"spark-nlp-display-entity-name\">chest tightness </span><span class=\"spark-nlp-display-entity-type\">PROBLEM</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">.<br>     No evidence of </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #800080B3\"><span class=\"spark-nlp-display-entity-name\">hypertension </span><span class=\"spark-nlp-display-entity-type\">PROBLEM</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #800080FF\">absent </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">. Patient denies </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #800080B3\"><span class=\"spark-nlp-display-entity-name\">nausea </span><span class=\"spark-nlp-display-entity-type\">PROBLEM</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #800080FF\">absent </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> at this time. </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #8b6673B3\"><span class=\"spark-nlp-display-entity-name\">zofran </span><span class=\"spark-nlp-display-entity-type\">TREATMENT</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #8b6673FF\">absent </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> declined. Patient is also having </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #800080B3\"><span class=\"spark-nlp-display-entity-name\">intermittent sweating </span><span class=\"spark-nlp-display-entity-type\">PROBLEM</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"><br>     associated with </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #800080B3\"><span class=\"spark-nlp-display-entity-name\">pneumonia </span><span class=\"spark-nlp-display-entity-type\">PROBLEM</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">. Patient refused </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #800080B3\"><span class=\"spark-nlp-display-entity-name\">pain </span><span class=\"spark-nlp-display-entity-type\">PROBLEM</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #800080FF\">absent </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> but </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #8b6673B3\"><span class=\"spark-nlp-display-entity-name\">tylenol </span><span class=\"spark-nlp-display-entity-type\">TREATMENT</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #8b6673FF\">absent </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> still given. Neither substance abuse nor alcohol use however cocaine<br>     once used in the last year. </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #800080B3\"><span class=\"spark-nlp-display-entity-name\">Alcoholism </span><span class=\"spark-nlp-display-entity-type\">PROBLEM</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #800080FF\">absent </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> unlikely. Patient has </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #800080B3\"><span class=\"spark-nlp-display-entity-name\">headache </span><span class=\"spark-nlp-display-entity-type\">PROBLEM</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> and </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #800080B3\"><span class=\"spark-nlp-display-entity-name\">fever </span><span class=\"spark-nlp-display-entity-type\">PROBLEM</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">. Patient is not </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #800080B3\"><span class=\"spark-nlp-display-entity-name\">diabetic </span><span class=\"spark-nlp-display-entity-type\">PROBLEM</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #800080FF\">absent </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">. Not clearly of </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #800080B3\"><span class=\"spark-nlp-display-entity-name\">diarrhea </span><span class=\"spark-nlp-display-entity-type\">PROBLEM</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">.<br>     Lab reports confirm </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #800080B3\"><span class=\"spark-nlp-display-entity-name\">lymphocytopenia </span><span class=\"spark-nlp-display-entity-type\">PROBLEM</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">. Cardaic rhythm is </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #800080B3\"><span class=\"spark-nlp-display-entity-name\">Sinus bradycardia </span><span class=\"spark-nlp-display-entity-type\">PROBLEM</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">. Patient also has a history of </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #800080B3\"><span class=\"spark-nlp-display-entity-name\">cardiac injury </span><span class=\"spark-nlp-display-entity-type\">PROBLEM</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">.<br>     No </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #800080B3\"><span class=\"spark-nlp-display-entity-name\">kidney injury </span><span class=\"spark-nlp-display-entity-type\">PROBLEM</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #800080FF\">absent </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> reported. No </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #800080B3\"><span class=\"spark-nlp-display-entity-name\">abnormal rashes </span><span class=\"spark-nlp-display-entity-type\">PROBLEM</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #800080FF\">absent </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> or </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #800080B3\"><span class=\"spark-nlp-display-entity-name\">ulcers </span><span class=\"spark-nlp-display-entity-type\">PROBLEM</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #800080FF\">absent </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">. Patient might not have </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #800080B3\"><span class=\"spark-nlp-display-entity-name\">liver disease </span><span class=\"spark-nlp-display-entity-type\">PROBLEM</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #800080FF\">absent </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">. Confirmed absence of </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #800080B3\"><span class=\"spark-nlp-display-entity-name\">hemoptysis </span><span class=\"spark-nlp-display-entity-type\">PROBLEM</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #800080FF\">absent </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">.<br>     Although patient has </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #800080B3\"><span class=\"spark-nlp-display-entity-name\">severe pneumonia </span><span class=\"spark-nlp-display-entity-type\">PROBLEM</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> and </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #800080B3\"><span class=\"spark-nlp-display-entity-name\">fever </span><span class=\"spark-nlp-display-entity-type\">PROBLEM</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, test reports are negative for </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #800080B3\"><span class=\"spark-nlp-display-entity-name\">COVID-19 infection </span><span class=\"spark-nlp-display-entity-type\">PROBLEM</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #800080FF\">absent </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">. COVID-19 </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #800080B3\"><span class=\"spark-nlp-display-entity-name\">viral infection </span><span class=\"spark-nlp-display-entity-type\">PROBLEM</span><span class=\"spark-nlp-display-entity-resolution\" style=\"background-color: #800080FF\">absent </span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> absent.<br>    </span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sparknlp_display import AssertionVisualizer\n",
    "\n",
    "vis = AssertionVisualizer()\n",
    "\n",
    "vis.display(result.collect()[0], 'ner_chunk', 'assertion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2868,
     "status": "ok",
     "timestamp": 1733912381315,
     "user": {
      "displayName": "G√∂khan T√úRER",
      "userId": "17886843627290606834"
     },
     "user_tz": -180
    },
    "id": "cr3gwYCZdCwP",
    "outputId": "95415ad2-d91b-4ff3-f6ff-b5561eb799cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+---+---------+----------------+\n",
      "|ner_chunk         |begin|end|ner_label|assertion_result|\n",
      "+------------------+-----+---+---------+----------------+\n",
      "|any difficulty    |59   |72 |PROBLEM  |absent          |\n",
      "|hypertension      |149  |160|PROBLEM  |absent          |\n",
      "|nausea            |178  |183|PROBLEM  |absent          |\n",
      "|zofran            |199  |204|TREATMENT|absent          |\n",
      "|pain              |309  |312|PROBLEM  |absent          |\n",
      "|tylenol           |318  |324|TREATMENT|absent          |\n",
      "|Alcoholism        |428  |437|PROBLEM  |absent          |\n",
      "|diabetic          |496  |503|PROBLEM  |absent          |\n",
      "|kidney injury     |664  |676|PROBLEM  |absent          |\n",
      "|abnormal rashes   |691  |705|PROBLEM  |absent          |\n",
      "|ulcers            |710  |715|PROBLEM  |absent          |\n",
      "|liver disease     |741  |753|PROBLEM  |absent          |\n",
      "|hemoptysis        |777  |786|PROBLEM  |absent          |\n",
      "|COVID-19 infection|873  |890|PROBLEM  |absent          |\n",
      "|viral infection   |902  |916|PROBLEM  |absent          |\n",
      "+------------------+-----+---+---------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flattener = Flattener() \\\n",
    "    .setInputCols(\"assertion\") \\\n",
    "    .setExplodeSelectedFields({\"assertion\":[\"metadata.ner_chunk as ner_chunk\",\n",
    "                                            \"begin as begin\",\n",
    "                                            \"end as end\",\n",
    "                                            \"metadata.ner_label as ner_label\",\n",
    "                                            \"result\"]})\n",
    "pipeline = Pipeline(\n",
    "    stages=[\n",
    "        document_assembler,\n",
    "        sentence_detector,\n",
    "        tokenizer,\n",
    "        word_embeddings,\n",
    "        clinical_ner,\n",
    "        ner_converter,\n",
    "        contextual_assertion,\n",
    "        flattener\n",
    "        ])\n",
    "\n",
    "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "model = pipeline.fit(empty_data)\n",
    "\n",
    "result = model.transform(data)\n",
    "result.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cRsfAR9OOFnp"
   },
   "source": [
    "### DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rCBa-PkmOEiu"
   },
   "outputs": [],
   "source": [
    "dateText = \"\"\"Patient resting in bed. Patient given azithromycin without any difficulty. Patient has audible wheezing, states chest tightness.\n",
    "      No evidence of hypertension. Patient denies nausea at this time. zofran declined. Patient is also having intermittent sweating\n",
    "      associated with pneumonia. Patient refused pain but tylenol still given. Neither substance abuse nor alcohol use however cocaine\n",
    "      once used in the last year. Alcoholism detected in 2022-01-15. Patient has headache and fever. Patient diabetic in the past. Not clearly of diarrhea.\n",
    "      Lab reports confirm lymphocytopenia. Cardaic rhythm is Sinus bradycardia. Patient also has a history of cardiac injury.\n",
    "      Kidney injury will be reported in 2024-01-15. No abnormal rashes or ulcers. Patient have liver disease before. Confirmed absence of hemoptysis.\n",
    "      Although patient has severe pneumonia and fever, test reports are negative for COVID-19 infection. COVID-19 viral infection can detect in the future.\n",
    "      \"\"\"\n",
    "pattern = '(?:yesterday|last\\s(?:night|week|month|year|Monday|Tuesday|Wednesday|Thursday|Friday|Saturday|Sunday)|(?:a|an|one|two|three|four|five|six|seven|eight|nine|ten|several|many|few)\\s(?:days?|weeks?|months?|years?)\\sago|in\\s(?:\\d{4}|\\d{1,2}\\s(?:January|February|March|April|May|June|July|August|September|October|November|December)))'\n",
    "\n",
    "data = spark.createDataFrame([[dateText]]).toDF(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3722,
     "status": "ok",
     "timestamp": 1733912385034,
     "user": {
      "displayName": "G√∂khan T√úRER",
      "userId": "17886843627290606834"
     },
     "user_tz": -180
    },
    "id": "OQxV3dMvOlII",
    "outputId": "784dd41e-2511-4ed2-a0ab-06186e382c84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+---+---------+----------------+\n",
      "|ner_chunk    |begin|end|ner_label|assertion_result|\n",
      "+-------------+-----+---+---------+----------------+\n",
      "|Alcoholism   |431  |440|PROBLEM  |past            |\n",
      "|diabetic     |506  |513|PROBLEM  |past            |\n",
      "|Kidney injury|685  |697|PROBLEM  |past            |\n",
      "|liver disease|774  |786|PROBLEM  |past            |\n",
      "+-------------+-----+---+---------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "contextual_assertion = ContextualAssertion() \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"ner_chunk\"]) \\\n",
    "    .setOutputCol(\"assertion\") \\\n",
    "    .setPrefixKeywords([\"before\", \"past\"]) \\\n",
    "    .setSuffixKeywords([\"before\",\"past\"]) \\\n",
    "    .setPrefixRegexPatterns([pattern]) \\\n",
    "    .setSuffixRegexPatterns([pattern]) \\\n",
    "    .setScopeWindow([5,5])\\\n",
    "    .setAssertion(\"past\")\n",
    "\n",
    "flattener = Flattener() \\\n",
    "    .setInputCols(\"assertion\") \\\n",
    "    .setExplodeSelectedFields({\"assertion\":[\"metadata.ner_chunk as ner_chunk\",\n",
    "                                            \"begin as begin\",\n",
    "                                            \"end as end\",\n",
    "                                            \"metadata.ner_label as ner_label\",\n",
    "                                            \"result\"]})\n",
    "pipeline = Pipeline(\n",
    "    stages=[\n",
    "          document_assembler,\n",
    "          sentence_detector,\n",
    "          tokenizer,\n",
    "          word_embeddings,\n",
    "          clinical_ner,\n",
    "          ner_converter,\n",
    "          contextual_assertion,\n",
    "          flattener\n",
    "      ])\n",
    "\n",
    "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "model = pipeline.fit(empty_data)\n",
    "\n",
    "result = model.transform(data)\n",
    "result.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ydiWwL1-O5q0"
   },
   "source": [
    "### FAMILY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j3peVi4sO5Fz"
   },
   "outputs": [],
   "source": [
    "familyText = \"\"\"Patient has a family history of diabetes. Mother's side has a history of hypertension.\n",
    "                Father diagnosed with heart disease last year. Sister and brother both have asthma.\n",
    "                Grandfather had cancer in his late 70s. No known family history of substance abuse.\n",
    "                Family history of autoimmune diseases is also noted.\"\"\"\n",
    "\n",
    "familyPatterns = [\"(mother|father|sister|brother|grandfather|grandmother|uncle|aunt|cousin|family)\"]\n",
    "familyKeywords = [\"family history\", \"family member\"]\n",
    "\n",
    "data = spark.createDataFrame([[familyText]]).toDF(\"text\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2663,
     "status": "ok",
     "timestamp": 1733912387689,
     "user": {
      "displayName": "G√∂khan T√úRER",
      "userId": "17886843627290606834"
     },
     "user_tz": -180
    },
    "id": "B6xJmaRNPBgi",
    "outputId": "25ef72aa-c85a-4e2c-fda3-0b1f8e01a0ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+---+---------+----------------------+\n",
      "|ner_chunk          |begin|end|ner_label|assertionFamily_result|\n",
      "+-------------------+-----+---+---------+----------------------+\n",
      "|diabetes           |32   |39 |PROBLEM  |family                |\n",
      "|hypertension       |73   |84 |PROBLEM  |family                |\n",
      "|heart disease      |125  |137|PROBLEM  |family                |\n",
      "|asthma             |179  |184|PROBLEM  |family                |\n",
      "|cancer             |219  |224|PROBLEM  |family                |\n",
      "|substance abuse    |270  |284|PROBLEM  |family                |\n",
      "|autoimmune diseases|321  |339|PROBLEM  |family                |\n",
      "+-------------------+-----+---+---------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "contextualAssertionFamily = ContextualAssertion()\\\n",
    "    .setInputCols([\"sentence\", \"token\", \"ner_chunk\"])\\\n",
    "    .setOutputCol(\"assertionFamily\")\\\n",
    "    .setPrefixRegexPatterns(familyPatterns)\\\n",
    "    .setSuffixRegexPatterns(familyPatterns)\\\n",
    "    .setPrefixKeywords(familyKeywords)\\\n",
    "    .setSuffixKeywords(familyKeywords)\\\n",
    "    .setCaseSensitive(False)\\\n",
    "    .setAssertion(\"family\")\\\n",
    "\n",
    "flattener =Flattener()\\\n",
    "    .setInputCols(\"assertionFamily\")\\\n",
    "    .setExplodeSelectedFields({\"assertionFamily\":[\"metadata.ner_chunk as ner_chunk\",\n",
    "                                            \"begin as begin\",\n",
    "                                            \"end as end\",\n",
    "                                            \"metadata.ner_label as ner_label\",\n",
    "                                            \"result\"]})\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    stages=[\n",
    "        document_assembler,\n",
    "        sentence_detector,\n",
    "        tokenizer,\n",
    "        word_embeddings,\n",
    "        clinical_ner,\n",
    "        ner_converter,\n",
    "        contextualAssertionFamily,\n",
    "        flattener\n",
    "\n",
    "    ])\n",
    "\n",
    "\n",
    "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "\n",
    "model = pipeline.fit(empty_data)\n",
    "result = model.transform(data)\n",
    "result.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eZGUQ3rOi5-6"
   },
   "source": [
    "## Pretrained Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MGJQMIxGjDKJ"
   },
   "source": [
    "| Model Name                                                            |      Description            |\n",
    "|-----------------------------------------------------------------------|-----------------------------|\n",
    "| [`contextual_assertion_someone_else`](https://nlp.johnsnowlabs.com/2024/06/26/contextual_assertion_someone_else_en.html) |  Identifies contextual cues within text data to detect `someone else` assertions |\n",
    "| [`contextual_assertion_absent`](https://nlp.johnsnowlabs.com/2024/07/03/contextual_assertion_absent_en.html) |  Identifies contextual cues within text data to detect `absent` assertions |\n",
    "| [`contextual_assertion_past`](https://nlp.johnsnowlabs.com/2024/07/04/contextual_assertion_past_en.html) |  Identifies contextual cues within text data to detect `past` assertions |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10978,
     "status": "ok",
     "timestamp": 1733912398661,
     "user": {
      "displayName": "G√∂khan T√úRER",
      "userId": "17886843627290606834"
     },
     "user_tz": -180
    },
    "id": "pdnkKtQ6i5u3",
    "outputId": "14f9d2d0-5d63-40fc-f86a-0c2b25016fde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[OK!]\n",
      "ner_clinical download started this may take some time.\n",
      "[OK!]\n",
      "contextual_assertion_someone_else download started this may take some time.\n",
      "[OK!]\n",
      "+----------------------------+-----+---+-------------------+---------+\n",
      "|result                      |begin|end|ner_chunk          |ner_label|\n",
      "+----------------------------+-----+---+-------------------+---------+\n",
      "|associated_with_someone_else|32   |39 |diabetes           |PROBLEM  |\n",
      "|associated_with_someone_else|64   |76 |heart failure      |PROBLEM  |\n",
      "|associated_with_someone_else|118  |123|asthma             |PROBLEM  |\n",
      "|associated_with_someone_else|152  |157|cancer             |PROBLEM  |\n",
      "|associated_with_someone_else|203  |217|substance abuse    |PROBLEM  |\n",
      "|associated_with_someone_else|238  |256|autoimmune diseases|PROBLEM  |\n",
      "+----------------------------+-----+---+-------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "sentence_detector = SentenceDetector() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols([\"sentence\"]) \\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "word_embeddings = WordEmbeddingsModel \\\n",
    "    .pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\", \"token\"]) \\\n",
    "    .setOutputCol(\"embeddings\")\n",
    "\n",
    "clinical_ner = MedicalNerModel \\\n",
    "    .pretrained(\"ner_clinical\", \"en\", \"clinical/models\") \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"ner\")\n",
    "\n",
    "ner_converter = NerConverter() \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"ner\"]) \\\n",
    "    .setOutputCol(\"ner_chunk\")\n",
    "\n",
    "contextual_assertion_someoneElse = ContextualAssertion\\\n",
    "     .pretrained(\"contextual_assertion_someone_else\" ,\"en\" ,\"clinical/models\")\\\n",
    "     .setInputCols(\"sentence\", \"token\", \"ner_chunk\")\\\n",
    "     .setOutputCol(\"assertionSomeoneElse\")\n",
    "\n",
    "flattener =Flattener()\\\n",
    "      .setInputCols(\"assertionSomeoneElse\")\\\n",
    "      .setExplodeSelectedFields({\"assertionSomeoneElse\": [\"result as result\",\n",
    "                                                          \"begin as begin \",\n",
    "                                                          \"end as end\",\n",
    "                                                          \"metadata.ner_chunk as ner_chunk\",\n",
    "                                                          \"metadata.ner_label as ner_label\"]\n",
    "                               })\n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "    document_assembler,\n",
    "    sentence_detector,\n",
    "    tokenizer,\n",
    "    word_embeddings,\n",
    "    clinical_ner,\n",
    "    ner_converter,\n",
    "    contextual_assertion_someoneElse,\n",
    "    flattener\n",
    "\n",
    "])\n",
    "\n",
    "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "model = pipeline.fit(empty_data)\n",
    "text = \"\"\"Patient has a family history of diabetes. Father diagnosed with heart failure last year. Sister and brother both have asthma.\n",
    "          Grandfather had cancer in his late 70s. No known family history of substance abuse. Family history of autoimmune diseases is also noted.\"\"\"\n",
    "\n",
    "data = spark.createDataFrame([[text]]).toDF('text')\n",
    "\n",
    "result = model.transform(data)\n",
    "result.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pValOiXRqQAp"
   },
   "source": [
    "##  Contextual Assertion Benchmarks for Enhanced Clinical Text Annotation\n",
    "\n",
    "The following benchmark demonstrates the benefits and efficiency of using Contextual Assertion, either alone or in combination with AssertionDL models, for annotating clinical texts. The benchmark evaluates the performance of these methods in various assertion-focused pipelines, offering valuable insights into their scalability and effectiveness.\n",
    "\n",
    "- `Dataset`: 253 Clinical Texts from in-house dataset\n",
    "  - train set count: 201\n",
    "  - test set count: 52\n",
    "\n",
    "**AssertionDL Pipeline:**\n",
    "\n",
    "```python\n",
    "clinical_assertion_pipeline = Pipeline(\n",
    "    stages=[\n",
    "        document_assembler,\n",
    "        sentence_detector,\n",
    "        tokenizer,\n",
    "        word_embeddings,\n",
    "        clinical_ner,\n",
    "        ner_converter,\n",
    "        assertionDL  # Pratrained AssertionDL Model\n",
    "    ])\n",
    "\n",
    "```\n",
    "\n",
    "*AssertionDL Results:*\n",
    "```bash\n",
    "       label  precision    recall  f1-score   support\n",
    "      Absent       0.80      0.76      0.78        21\n",
    "        Past       0.63      0.67      0.65        18\n",
    "     Present       0.54      0.54      0.54        13\n",
    "    accuracy        -         -        0.67        52\n",
    "   macro-avg       0.66      0.66      0.66        52\n",
    "weighted-avg       0.68      0.67      0.67        52\n",
    "\n",
    "```\n",
    "\n",
    "**Contextual Assertion Pipeline:**\n",
    "\n",
    "```python\n",
    "clinical_assertion_pipeline = Pipeline(\n",
    "    stages=[\n",
    "        document_assembler,\n",
    "        sentence_detector,\n",
    "        tokenizer,\n",
    "        word_embeddings,\n",
    "        clinical_ner,\n",
    "        ner_converter,\n",
    "        contextual_assertion_absent, # Rule based Contextual Assertion\n",
    "        contextual_assertion_past,   # Rule based Contextual Assertion\n",
    "        assertionMerger\n",
    "    ])\n",
    "\n",
    "```\n",
    "\n",
    "*Contextual Assertion Results:*\n",
    "```bash\n",
    "       label   precision    recall  f1-score   support\n",
    "      Absent       1.00      0.76      0.86        21\n",
    "        Past       0.86      1.00      0.92        18\n",
    "    accuracy        -         -        0.87        39\n",
    "   macro-avg       0.62      0.59      0.60        39\n",
    "weighted-avg       0.93      0.87      0.89        39\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "**Contextual Assertion and AssertionDL Pipeline:**\n",
    "\n",
    "```python\n",
    "clinical_assertion_pipeline = Pipeline(\n",
    "    stages=[\n",
    "        document_assembler,\n",
    "        sentence_detector,\n",
    "        tokenizer,\n",
    "        word_embeddings,\n",
    "        clinical_ner,\n",
    "        ner_converter,\n",
    "        contextual_assertion_absent, # Rule based Contextual Assertion\n",
    "        contextual_assertion_past,   # Rule based Contextual Assertion\n",
    "        assertionDL,                 # Pratrained AssertionDL Model\n",
    "        assertionMerger\n",
    "    ])\n",
    "\n",
    "```\n",
    "\n",
    "*Contextual Assertion and AssertionDL Results:*\n",
    "```bash\n",
    "       label  precision    recall  f1-score   support\n",
    "      Absent       0.90      0.86      0.88        21\n",
    "        Past       0.62      1.00      0.77        18\n",
    "     Present       1.00      0.23      0.38        13\n",
    "    accuracy        -         -        0.75        52\n",
    "   macro avg       0.84      0.70      0.67        52\n",
    "weighted avg       0.83      0.75      0.71        52\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "This benchmark highlights the significant improvements in precision, recall, and F1-score achieved by integrating Contextual Assertion with the AssertionDL model, making it a robust tool for accurate clinical text annotation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mB7lElfFvowH"
   },
   "source": [
    "\n",
    "- `Dataset`: Used in-house jsl_augmented dataset\n",
    "\n",
    "\n",
    "F1 scores:\n",
    "\n",
    "|Assertion Label|Contextual Assertion|AssertionDL|\n",
    "|-|-|-|\n",
    "|Absent       |0.82|0.90|\n",
    "|Family       |0.63|0.73|\n",
    "|Hypothetical |0.51|0.69|\n",
    "|Past         |0.73|0.77|\n",
    "|Planned      |0.57|0.62|\n",
    "|Possible     |0.49|0.74|\n",
    "|SomeoneElse  |0.79|0.84|"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
