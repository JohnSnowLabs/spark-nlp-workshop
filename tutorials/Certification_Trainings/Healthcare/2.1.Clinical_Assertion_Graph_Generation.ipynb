{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2.1.Clinical_Assertion_Graph_Generation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InUmp9hn1vX6",
        "colab_type": "text"
      },
      "source": [
        "# Spark NLP Clinical Assertion Model TF Graph Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-Kle9jF1mDx",
        "colab_type": "text"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/2.1.Clinical_Assertion_Graph_Generation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXxiaFIe1uoX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==1.15"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2pzWsg2yV2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "   BiLSTM on I2b2 Assertion Status Classification\n",
        "\"\"\"\n",
        "import tensorflow as tf\n",
        "from math import ceil\n",
        "\n",
        "class AssertionModel:\n",
        "\n",
        "    def __init__(self, seq_max_len, feat_size, n_classes, device='/cpu:0'):\n",
        "        tf.reset_default_graph()\n",
        "        self._device = device\n",
        "        with tf.device(device):\n",
        "            self.x = tf.placeholder(\"float\", [None, seq_max_len, feat_size], 'word_repr/word_embeddings')\n",
        "            self.y = tf.placeholder(\"float\", [None, n_classes], 'training/labels')\n",
        "\n",
        "            # A placeholder for indicating each sentence length\n",
        "            self.seqlen = tf.placeholder(tf.int32, [None], 'word_repr/sentence_lengths')\n",
        "            self.n_classes = n_classes\n",
        "\n",
        "            self.output_keep_prob = tf.placeholder_with_default(tf.constant(1.0, dtype=tf.float32), (), 'training/dropout')\n",
        "            self.rate = tf.placeholder_with_default(tf.constant(.02, dtype=tf.float32), (), 'training/lr')\n",
        "\n",
        "            # per_process_gpu_memory_fraction=0.99, \n",
        "            gpu_options = tf.GPUOptions(allow_growth=True)\n",
        "            config_proto = tf.ConfigProto(log_device_placement=True, allow_soft_placement=True, gpu_options=gpu_options)\n",
        "            self.sess = tf.Session(config=config_proto)\n",
        "\n",
        "    def fully_connected_layer(self, input_data, output_dim, activation_func=None):\n",
        "        with tf.device(self._device):\n",
        "            input_dim = int(input_data.get_shape()[1])\n",
        "            W = tf.Variable(tf.random_normal([input_dim, output_dim]))\n",
        "            b = tf.Variable(tf.random_normal([output_dim]))\n",
        "            if activation_func:\n",
        "                return activation_func(tf.matmul(input_data, W) + b)\n",
        "            else:\n",
        "                return tf.add(tf.matmul(input_data, W), b, name='output')\n",
        "\n",
        "    def add_bidirectional_lstm(self, n_hidden=30, num_layers=3):\n",
        "        with tf.device(self._device):\n",
        "            seq_max_len = self.x.get_shape()[1]\n",
        "\n",
        "            fw_cells = []\n",
        "            bw_cells = []\n",
        "\n",
        "            for layer_num in range(1, num_layers + 1):\n",
        "                # Define a lstm cell with tensorflow  -  Forward direction cell\n",
        "                lstm_fw_cell = tf.nn.rnn_cell.BasicLSTMCell(n_hidden, forget_bias=1.0, name='fw' + str(layer_num))\n",
        "                lstm_fw_cell = tf.nn.rnn_cell.DropoutWrapper(lstm_fw_cell, output_keep_prob=self.output_keep_prob)\n",
        "                fw_cells.append(lstm_fw_cell)\n",
        "\n",
        "                # Backward direction cell\n",
        "                lstm_bw_cell = tf.nn.rnn_cell.BasicLSTMCell(n_hidden, forget_bias=1.0, name='bw' + str(layer_num))\n",
        "                lstm_bw_cell = tf.nn.rnn_cell.DropoutWrapper(lstm_bw_cell, output_keep_prob=self.output_keep_prob)\n",
        "                bw_cells.append(lstm_bw_cell)\n",
        "\n",
        "            # Get lstm cell output, providing 'sequence_length' will perform dynamic\n",
        "            # calculation.\n",
        "            outputs, _, _ = \\\n",
        "                tf.contrib.rnn.stack_bidirectional_dynamic_rnn(fw_cells, bw_cells,\n",
        "                                                self.x, dtype=tf.float32,\n",
        "                                                sequence_length=self.seqlen)\n",
        "\n",
        "            # Hack to build the indexing and retrieve the right output.\n",
        "            batchSize = tf.shape(outputs)[0]\n",
        "\n",
        "            # Start indices for each sample\n",
        "            index = tf.range(0, batchSize) * seq_max_len + (self.seqlen - 1)\n",
        "\n",
        "            # Index of the last output for the variable length sequence\n",
        "            outputs = tf.gather(tf.reshape(outputs, [-1, n_hidden * 2]), index)\n",
        "\n",
        "            # Linear activation, using outputs computed above\n",
        "            self.bi_lstm = self.fully_connected_layer(outputs, self.n_classes)\n",
        "\n",
        "            self.output_label = tf.argmax(self.bi_lstm, 1, name=\"output_label\")\n",
        "\n",
        "            # match_count reflects the number of matches in a batch\n",
        "            correct_pred = tf.equal(tf.argmax(self.bi_lstm, 1), tf.argmax(self.y, 1))\n",
        "            self.match_count = tf.reduce_sum(tf.cast(correct_pred, tf.float32), name='training/match_count')\n",
        "\n",
        "    def add_optimizer(self):\n",
        "        with tf.device(self._device):\n",
        "            with tf.variable_scope(\"training\") as scope:\n",
        "                pred = self.bi_lstm\n",
        "\n",
        "                # Define loss and optimizer\n",
        "                cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=pred, labels=self.y), name=\"loss\")\n",
        "                self.optimizer = tf.train.AdamOptimizer(learning_rate=self.rate).minimize(cost)\n",
        "\n",
        "            # Initialize the variables (i.e. assign their default value)\n",
        "            self.init = tf.global_variables_initializer()\n",
        "\n",
        "    def train(self, trainset, testset, epochs, batch_size=64, learning_rate=0.01, dropout=0.15,  epoch_acc=7):\n",
        "        # Run the initializer\n",
        "        with tf.device(self._device):\n",
        "            self.sess.run(self.init)\n",
        "\n",
        "            num_batches = ceil(trainset.size()[0] / batch_size)\n",
        "            rate = learning_rate\n",
        "            for epoch in range(1, epochs + 1):\n",
        "                for batch in range(1, num_batches + 1):\n",
        "                    batch_x, batch_y, batch_seqlen = trainset.next(batch_size)\n",
        "                    # Run optimization op (backprop)\n",
        "                    self.sess.run(self.optimizer, feed_dict={self.x: batch_x, self.y: batch_y,\n",
        "                                                   self.seqlen: batch_seqlen, self.output_keep_prob: 1 - dropout,\n",
        "                                                   self.rate: rate})\n",
        "                if epoch > epoch_acc:\n",
        "                    print('epoch # %d' % epoch, 'accuracy: %f' % self.calc_accuracy(testset, batch_size))\n",
        "                    rate *= .99\n",
        "                    #print(self.confusion_matrix(testset, sess, batch_size))\n",
        "                else:\n",
        "                    print('epoch # %d' % epoch)\n",
        "\n",
        "            print(\"Optimization Finished!\")\n",
        "\n",
        "    def calc_accuracy(self, dataset, batch_size):\n",
        "\n",
        "        ''' Calculate accuracy on dataset '''\n",
        "        \n",
        "        with tf.device(self._device):\n",
        "\n",
        "            assert (dataset.batch_id == 0)\n",
        "            n_test_batches = ceil(dataset.size()[0] / batch_size)\n",
        "            global_matches = 0\n",
        "\n",
        "            for batch in range(1, n_test_batches + 1):\n",
        "                batch_x, batch_y, batch_seqlen = dataset.next(batch_size)\n",
        "                global_matches += self.sess.run(self.match_count, feed_dict={self.x: batch_x, self.y:batch_y, self.seqlen: batch_seqlen})\n",
        "\n",
        "            return global_matches / float(dataset.size()[0])\n",
        "\n",
        "    def confusion_matrix(self, dataset, sess, batch_size):\n",
        "        with tf.device(self._device):\n",
        "            assert(dataset.batch_id == 0)\n",
        "\n",
        "            n_test_batches = ceil(dataset.size()[0] / batch_size)\n",
        "            predicted = list()\n",
        "\n",
        "            # obtain index of largest\n",
        "            correct = [one_hot_label.index(max(one_hot_label)) for one_hot_label in dataset.labels]\n",
        "\n",
        "            for batch in range(1, n_test_batches + 1):\n",
        "                batch_x, batch_y, batch_seqlen = dataset.next(batch_size)\n",
        "                batch_predictions = sess.run(self.bi_lstm, feed_dict={self.x: batch_x, self.seqlen: batch_seqlen})\n",
        "                predicted += [pred.argmax() for pred in batch_predictions]\n",
        "\n",
        "            # lengths should match\n",
        "            assert(len(predicted) == len(correct))\n",
        "\n",
        "            # infer all possible class labels\n",
        "            labels = set(correct)\n",
        "            from collections import defaultdict\n",
        "            matrix = {k: defaultdict(int) for k in labels}\n",
        "\n",
        "            for g, p in zip(correct, predicted):\n",
        "                matrix[g][p] += 1\n",
        "\n",
        "            # sanity check, confusion matrix contains as many elements as they were used during prediction\n",
        "            matrix_size = sum([element for idx in matrix for element in matrix[idx].values()])\n",
        "            assert(len(predicted) == matrix_size)\n",
        "\n",
        "            # Check to make sure score computation is correct\n",
        "            # from sklearn.metrics import f1_score\n",
        "            # print(f1_score(correct, predicted, average='micro'))\n",
        "\n",
        "            return matrix\n",
        "\n",
        "    def persist_graph(self, filename):\n",
        "        # Add ops to save and restore all the variables (not used here but we need it in the graph).\n",
        "        with tf.device(self._device):\n",
        "            tf.train.Saver()\n",
        "            tf.train.write_graph(self.sess.graph, './', filename, False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-JWcRSWykbS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 552
        },
        "outputId": "cbc6fd73-c6d5-4afc-a1d4-8966f1161430"
      },
      "source": [
        "def create_graph(n_classes, filename):\n",
        "\n",
        "    # instantiate model\n",
        "    model = AssertionModel(max_seq_len, feat_size=feat_size + 10, n_classes=n_classes, device='/cpu:0')\n",
        "\n",
        "    # Network Parameters\n",
        "    model.add_bidirectional_lstm(n_hidden=34)\n",
        "    model.add_optimizer()\n",
        "\n",
        "    # Persist graph\n",
        "    model.persist_graph(filename)\n",
        "\n",
        "\n",
        "# i2b2\n",
        "max_seq_len = 250\n",
        "feat_size = 200\n",
        "n_classes = 7\n",
        "create_graph(max_seq_len, feat_size, n_classes, 'blstm_34_32_30_200_7.pb')\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-3-3f657bceb931>:47: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/rnn/python/ops/rnn.py:239: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:735: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:739: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py:244: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLhHOz8Uy6nj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}