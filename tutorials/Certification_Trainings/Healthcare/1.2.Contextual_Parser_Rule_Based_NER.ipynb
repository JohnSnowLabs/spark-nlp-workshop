{"cells":[{"cell_type":"markdown","metadata":{"id":"i8W51t04BN6B"},"source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"]},{"cell_type":"markdown","metadata":{"id":"21lTnEqRBd0s"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.2.Contextual_Parser_Rule_Based_NER.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"3-vwpSj3BSbj"},"source":["# 1.2 ContextualParser (Rule Based NER)"]},{"cell_type":"markdown","metadata":{"id":"5SBh1CNgOg54"},"source":["## Colab Setup"]},{"cell_type":"code","source":["import json, os\n","from google.colab import files\n","\n","if 'spark_jsl.json' not in os.listdir():\n","  license_keys = files.upload()\n","  os.rename(list(license_keys.keys())[0], 'spark_jsl.json')\n","\n","with open('spark_jsl.json') as f:\n","    license_keys = json.load(f)\n","\n","# Defining license key-value pairs as local variables\n","locals().update(license_keys)\n","os.environ.update(license_keys)"],"metadata":{"id":"NsjRecTSvQA9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Installing pyspark and spark-nlp\n","! pip install --upgrade -q pyspark==3.3.0 spark-nlp==$PUBLIC_VERSION\n","\n","# Installing Spark NLP Healthcare\n","! pip install --upgrade -q spark-nlp-jsl==$JSL_VERSION  --extra-index-url https://pypi.johnsnowlabs.com/$SECRET\n","\n","# Installing Spark NLP Display Library for visualization\n","! pip install -q spark-nlp-display"],"metadata":{"id":"mPVM43jNvYA1"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"id":"53Qom33h4nvu","colab":{"base_uri":"https://localhost:8080/","height":254},"executionInfo":{"status":"ok","timestamp":1689494012419,"user_tz":-120,"elapsed":38138,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"}},"outputId":"01b70715-7481-476b-cfce-255d3a7ec437"},"outputs":[{"output_type":"stream","name":"stdout","text":["Spark NLP Version : 5.0.0\n","Spark NLP_JSL Version : 5.0.0\n"]},{"output_type":"execute_result","data":{"text/plain":["<pyspark.sql.session.SparkSession at 0x7b2e0afd84c0>"],"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://7c7ec253a58e:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.3.0</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>Spark NLP Licensed</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "]},"metadata":{},"execution_count":3}],"source":["from pyspark.ml import Pipeline,PipelineModel\n","from pyspark.sql import SparkSession\n","\n","import sparknlp_jsl\n","import sparknlp\n","\n","from sparknlp.annotator import *\n","from sparknlp_jsl.annotator import *\n","from sparknlp.base import *\n","\n","params = {\"spark.driver.memory\":\"16G\",\n","\"spark.kryoserializer.buffer.max\":\"2000M\",\n","\"spark.driver.maxResultSize\":\"2000M\"}\n","\n","spark = sparknlp_jsl.start(license_keys['SECRET'],params=params)\n","\n","print (\"Spark NLP Version :\", sparknlp.version())\n","print (\"Spark NLP_JSL Version :\", sparknlp_jsl.version())\n","\n","spark"]},{"cell_type":"markdown","source":["# How the ContextualParser Works"],"metadata":{"id":"xZzN6yNBvb2b"}},{"cell_type":"markdown","source":["Spark NLP's `ContextualParser` is a licensed annotator that allows users to extract entities from a document based on pattern matching. It provides more functionality than its open-source counterpart `EntityRuler` by allowing users to customize specific characteristics for pattern matching. You're able to find entities using regex rules for full and partial matches, a dictionary with normalizing options and context parameters to take into account things such as token distances.\n","\n","There are 3 components necessary to understand when using the `ContextualParser` annotator:\n","\n","1. `ContextualParser` annotator's parameters\n","2. JSON configuration file\n","3. Dictionary"],"metadata":{"id":"nSO62FEY0iof"}},{"cell_type":"markdown","source":["## 1. ContextualParser Annotator Parameters"],"metadata":{"id":"T0_3bAzaPbip"}},{"cell_type":"markdown","source":["Here are all the parameters available to use with the `ContextualParserApproach`:"],"metadata":{"id":"PTSYc7RUQgKh"}},{"cell_type":"markdown","source":["```\n","contextualParser = ContextualParserApproach() \\\n","    .setInputCols([\"sentence\", \"token\"]) \\\n","    .setOutputCol(\"entity\") \\\n","    .setCaseSensitive(True) \\\n","    .setJsonPath(\"context_config.json\") \\\n","    .setPrefixAndSuffixMatch(True) \\\n","    .setCompleteContextMatch(True) \\\n","    .setDictionary(\"dictionary.tsv\", options={\"orientation\":\"vertical\"})\n","```\n"],"metadata":{"id":"vF4_Dm7qVTty"}},{"cell_type":"markdown","source":["We will dive deeper into the details of each parameter, but here's a quick overview:\n","\n","- `setCaseSensitive`: do you want the matching to be case sensitive (applies to all JSON properties apart from the regex property)\n","- `setJsonPath`: the path to your JSON configuration file\n","- `setPrefixAndSuffixMatch`: do you want to match using both the prefix AND suffix properties from the JSON configuration file\n","- `setCompleteContextMatch`: do you want an exact match of prefix and suffix.\n","- `setDictionary`: the path to your dictionary, used for normalizing entities\n","\n","Let's start by looking at the JSON configuration file."],"metadata":{"id":"uVmRKjoBZ7HQ"}},{"cell_type":"markdown","source":["## 2. JSON Configuration File"],"metadata":{"id":"GVO5m215TjXf"}},{"cell_type":"markdown","source":["Here is a fully utilized JSON configuration file."],"metadata":{"id":"HNJr5ISlaJsl"}},{"cell_type":"markdown","source":["```\n","{\n","  \"entity\": \"Gender\",\n","  \"ruleScope\": \"sentence\",\n","  \"regex\": \"girl|boy\",\n","  \"completeMatchRegex\": \"true\",\n","  \"matchScope\": \"token\",\n","  \"prefix\": [\"birth\", \"growing\", \"assessment\"],\n","  \"suffix\": [\"faster\", \"velocities\"],\n","  \"contextLength\": 100,\n","  \"contextException\": [\"slightly\"],\n","  \"exceptionDistance\": 40\n"," }\n"," ```"],"metadata":{"id":"4q1UuczZVhD_"}},{"cell_type":"markdown","source":["### 2.1. Basic Properties"],"metadata":{"id":"GChnk1cXaUIZ"}},{"cell_type":"markdown","source":["There are 5 basic properties you can set in your JSON configuration file:\n","\n","- `entity`\n","- `ruleScope`\n","- `regex`\n","- `completeMatchRegex`\n","- `matchScope`\n","\n","Let's first look at the 3 most essential properties to set:"],"metadata":{"id":"p-kJhmUe0f13"}},{"cell_type":"markdown","source":["```\n","{\n","  \"entity\": \"Digit\",\n","  \"ruleScope\": \"sentence\",\n","  \"regex\": \"\\\\d+\" # Note here: backslashes are escape characters in JSON, so for regex pattern \"\\d+\" we need to write it out as \"\\\\d+\"\n","}\n","```"],"metadata":{"id":"7RP8mwtgVkcj"}},{"cell_type":"markdown","source":["Here, we're looking for tokens in our text that match the regex: \"`\\d+`\" and assign the \"`Digit`\" entity to those tokens. When `ruleScope` is set to \"`sentence`\", we're looking for a match on each *token* of a **sentence**. You can change it to \"`document`\" to look for a match on each *sentence* of a **document**. The latter is particularly useful when working with multi-word matches, but we'll explore this at a later stage.\n","\n","The next properties to look at are `completeMatchRegex` and `matchScope`. To understand their use case, let's take a look at an example where we're trying to match all digits in our text.\n","\n","Let's say we come across the following string: ***XYZ987***\n","\n","Depending on how we set the `completeMatchRegex` and `matchScope` properties, we'll get the following results:"],"metadata":{"id":"pHSsBgoNcJiw"}},{"cell_type":"markdown","source":["```\n","{\n","  \"entity\": \"Digit\",\n","  \"ruleScope\": \"sentence\",\n","  \"regex\": \"\\\\d+\",\n","  \"completeMatchRegex\": \"false\",\n","  \"matchScope\": \"token\"\n","}\n","```"],"metadata":{"id":"tOxfFn8_VngD"}},{"cell_type":"markdown","source":["`OUTPUT: [XYZ987]`"],"metadata":{"id":"dZzkfdtDyavl"}},{"cell_type":"markdown","source":["```\n","{\n","  \"entity\": \"Digit\",\n","  \"ruleScope\": \"sentence\",\n","  \"regex\": \"\\\\d+\",  \n","  \"completeMatchRegex\": \"false\",\n","  \"matchScope\": \"sub-token\"\n","}\n","```"],"metadata":{"id":"K37Ucw75Vrog"}},{"cell_type":"markdown","source":["`OUTPUT: [987]`\n"],"metadata":{"id":"CkOfYVHGyb20"}},{"cell_type":"markdown","source":["```\n","{\n","  \"entity\": \"Digit\",\n","  \"ruleScope\": \"sentence\",\n","  \"regex\": \"\\\\d+\",\n","  \"completeMatchRegex\": \"true\"\n","  # matchScope is ignored here\n","}\n","```"],"metadata":{"id":"9Jpr2IkFVwKw"}},{"cell_type":"markdown","source":["`OUTPUT: []`"],"metadata":{"id":"ZiYD0oF7gJtw"}},{"cell_type":"markdown","source":["`\"completeMatchRegex\": \"true\"` will only return an output if our string was modified in the following way (to get a complete, exact match): **XYZ 987**"],"metadata":{"id":"bFE9Ri2N4xxT"}},{"cell_type":"markdown","source":["```\n","{\n","  \"entity\": \"Digit\",\n","  \"ruleScope\": \"sentence\",\n","  \"regex\": \"\\\\d+\",  \n","  \"completeMatchRegex\": \"true\",\n","  \"matchScope\": \"token\" # Note here: sub-token would return the same output\n","}\n","```"],"metadata":{"id":"L-_sXg5l5NBg"}},{"cell_type":"markdown","source":["`OUTPUT: [987]`"],"metadata":{"id":"zUeuct_05p3f"}},{"cell_type":"markdown","source":["### 2.2. Context Awareness Properties"],"metadata":{"id":"ZlIUAPKazpT9"}},{"cell_type":"markdown","source":["There are 5 properties related to context awareness:\n","\n","- `contextLength`\n","- `prefix`\n","- `suffix`\n","- `contextException`\n","- `exceptionDistance`\n","\n"],"metadata":{"id":"9D2UfFFBz7fX"}},{"cell_type":"markdown","source":["Let's look at a similar example. Say we have the following text: ***At birth, the typical boy is growing slightly faster than the typical girl, but growth rates become equal at about seven months.***\n","\n","If we want to match the gender that grows faster at birth, we can start by defining our regex: \"`girl|boy`\"\n","\n","Next, we add a prefix (\"`birth`\") and suffix (\"`faster`\") to ask the parser to match the regex only if the word \"`birth`\" comes before and only if the word \"`faster`\" comes after. Finally, we will need to set the `contextLength` - this is the maximum number of tokens after the prefix and before the suffix that will be searched to find a regex match.\n","\n","Here's what the JSON configuration file would look like:"],"metadata":{"id":"IcUlaqmgDL9R"}},{"cell_type":"markdown","source":["```\n","{\n","  \"entity\": \"Gender\",\n","  \"ruleScope\": \"sentence\",\n","  \"regex\": \"girl|boy\",\n","  \"contextLength\": 50,\n","  \"prefix\": [\"birth\"],\n","  \"suffix\": [\"faster\"]\n","}\n","```"],"metadata":{"id":"J5Tq5OJBVzCL"}},{"cell_type":"markdown","source":["`OUTPUT: [boy]`"],"metadata":{"id":"G5Y5r9pO92B0"}},{"cell_type":"markdown","source":["If you remember, the annotator has a `setPrefixAndSuffixMatch()` parameter. If you set it to `True`, the previous output would remain as is. However, if you had set it to `False` and used the following JSON configuration:"],"metadata":{"id":"IXchjZZC_Gm0"}},{"cell_type":"markdown","source":["```\n","{\n","  \"entity\": \"Gender\",\n","  \"ruleScope\": \"sentence\",\n","  \"regex\": \"girl|boy\",\n","  \"contextLength\": 50,\n","  \"prefix\": [\"birth\"],\n","  \"suffix\": [\"faster\", \"rates\"]\n","}\n","```"],"metadata":{"id":"xO64udOnV1GJ"}},{"cell_type":"markdown","source":["`OUTPUT: [boy, girl]`"],"metadata":{"id":"Xm-y_c_RAJpF"}},{"cell_type":"markdown","source":["The parser now takes into account either the prefix OR suffix, only one of the condition has to be fulfilled for a match to count."],"metadata":{"id":"Yk0nox1sAdw_"}},{"cell_type":"markdown","source":["If you remember, the annotator has a `setCompleteContextMatch()` parameter. If you set it to `True`, and used the following JSON configuration :"],"metadata":{"id":"MyTdPDlgLmxL"}},{"cell_type":"markdown","source":["```\n","{\n","  \"entity\": \"Gender\",\n","  \"ruleScope\": \"sentence\",\n","  \"regex\": \"girl|boy\",\n","  \"contextLength\": 50,\n","  \"prefix\": [\"birth\"],\n","  \"suffix\": [\"fast\"]\n","}\n","```"],"metadata":{"id":"1ycrvCMpMJ_J"}},{"cell_type":"markdown","source":["`OUTPUT: []`"],"metadata":{"id":"r5A67yBZMj2N"}},{"cell_type":"markdown","source":["However if we set `setCompleteContextMatch()` as `False`, and use the same JSON configuration as above, we get the following output :"],"metadata":{"id":"N1duAqATM-ir"}},{"cell_type":"markdown","source":["`OUTPUT: [boy]`"],"metadata":{"id":"s0vd_jfsNi7y"}},{"cell_type":"markdown","source":["Here's the sentence again: ***At birth, the typical boy is growing slightly faster than the typical girl, but growth rates become equal at about seven months.***\n","\n","The last 2 properties related to context awareness are `contextException` and `exceptionDistance`. This rules out matches based on a given exception:"],"metadata":{"id":"vdEFJZM1DGQ1"}},{"cell_type":"markdown","source":["```\n","{\n","  \"entity\": \"Gender\",\n","  \"ruleScope\": \"sentence\",\n","  \"regex\": \"girl|boy\",\n","  \"contextLength\": 50,\n","  \"prefix\": [\"birth\"],\n","  \"suffix\": [\"faster\", \"rates\"],\n","  \"contextException\": [\"At\"],\n","  \"exceptionDistance\": 5\n","}\n","```"],"metadata":{"id":"0JluGupMV5SR"}},{"cell_type":"markdown","source":["`OUTPUT: [girl]`"],"metadata":{"id":"EnFzqpHlC3Qz"}},{"cell_type":"markdown","source":["Here we've asked the parser to ignore a match if the token \"`At`\" is within 5 tokens of the matched regex. This caused the token \"`boy`\" to be ignored."],"metadata":{"id":"JT09xrE-DCiO"}},{"cell_type":"markdown","source":["If the annotator's `setOptionalContextRules` parameter is set `True`, it allows us to output regex matches regardless of context match (prefix, suffix configuration). For usage of the `setOptionalContextRules` parameter go to the [Example2 output](#scrollTo=1tdgMbaWDhNC&line=1&uniqifier=1)."],"metadata":{"id":"nQ9-Fkr94qAH"}},{"cell_type":"markdown","source":["When `shortestContextMatch` parameter is set to `True`, it will stop finding for matches when one of prefix and suffix data is found in the text.\",\n","                                "],"metadata":{"id":"NBZ1D92g5aEB"}},{"cell_type":"markdown","source":["Confidence Value Scenarios:\n","* When there is regex match only, the confidence value will be 0.5.\n","* When there are regex and prefix matches together, the confidence value will be > 0.5 depending on the distance between target token and the prefix.\n","* When there are regex and suffix matches together, the confidence value will be > 0.5 depending on the distance between target token and the suffix.\n","* When there are regex, prefix, and suffix matches all together, the confidence value will be > than the other scenarios."],"metadata":{"id":"41wdqkIX5WAy"}},{"cell_type":"markdown","source":["## 3. Dictionary"],"metadata":{"id":"VzFSjw7aVO2b"}},{"cell_type":"markdown","source":["Another key feature of the `ContextualParser` annotator is the use of dictionaries. You can specify a path to a dictionary in `tsv` or `csv` format using the `setDictionary()` parameter. Using a dictionary is a useful when you have a list of exact words that you want the parser to pick up when processing some text."],"metadata":{"id":"5NPiJZx-Va8b"}},{"cell_type":"markdown","source":["### 3.1. Orientation\n","\n","The first feature to be aware of when it comes to feeding dictionaries is the format of the dictionaries. The `ContextualParser` annotator will accept dictionaries in the horizontal format and in a vertical format. This is how they would look in practice:"],"metadata":{"id":"hmB9hadyXYeM"}},{"cell_type":"markdown","source":["Horizontal:\n","\n","| normalize | word1 | word2 | word3     |\n","|-----------|-------|-------|-----------|\n","| female    | woman | girl  | lady      |\n","| male      | man   | boy   | gentleman |\n"],"metadata":{"id":"eyDmIqLmWGRy"}},{"cell_type":"markdown","source":["\n","Vertical:\n","\n","| female    | normalize |\n","|-----------|-----------|\n","| woman     | word1     |\n","| girl      | word2     |\n","| lady      | word3     |"],"metadata":{"id":"ToFbLxsDYInk"}},{"cell_type":"markdown","source":["As you can see, your dictionary needs to have a `normalize` field that lets the annotator know which entity labels to use, and another field that lets the annotator know a list of words it should be looking to match. Here's how to set the format that your dictionary uses:"],"metadata":{"id":"dCrIw4CRYeBC"}},{"cell_type":"markdown","source":["```\n","contextualParser = ContextualParserApproach() \\\n","    .setDictionary(\"dictionary.tsv\", options={\"orientation\":\"vertical\"}) # default is horizontal\n","```"],"metadata":{"id":"Z_epZRQiV85Y"}},{"cell_type":"markdown","source":["### 3.2. Dictionary-related JSON Properties\n","\n","When working with dictionaries, there are 2 properties in the JSON configuration file to be aware of:\n","\n","- `ruleScope`\n","- `matchScope`\n","\n","This is especially true when you have multi-word entities in your dictionary.\n","\n","Let's take an example of a dictionary that contains a list of cities, sometimes made up of multiple words:\n","\n","| normalize | word1 | word2 | word3     |\n","|-----------|-------|-------|-----------|\n","| City      | New York | Salt Lake City  | Washington      |\n","\n","\n"],"metadata":{"id":"_CvM-FgLZgKk"}},{"cell_type":"markdown","source":["Let's say we're working with the following text: ***I love New York. Salt Lake City is nice too.***"],"metadata":{"id":"v5weyyiIMzNr"}},{"cell_type":"markdown","source":["With the following JSON properties, here's what you would get:"],"metadata":{"id":"xg8eJwuTJcB6"}},{"cell_type":"markdown","source":["```\n","{\n","  \"entity\": \"City\",\n","  \"ruleScope\": \"sentence\",\n","  \"matchScope\": \"sub-token\",\n","}\n","```"],"metadata":{"id":"R1TNWtywoGWb"}},{"cell_type":"markdown","source":["`OUTPUT: []`"],"metadata":{"id":"Wweg5_C9JuWm"}},{"cell_type":"markdown","source":["When `ruleScope` is set to `\"sentence\"`, the annotator attempts to find matches at the token level, parsing through each token in the sentence one by one, looking for a match with the dictionary items. Since `\"New York\"` and `\"Salt Lake City\"` are made up of multiple tokens, the annotator would never find a match from the dictionary. Let's change `ruleScope` to `\"document\"`:"],"metadata":{"id":"pNYWPr2eLJ5d"}},{"cell_type":"markdown","source":["```\n","{\n","  \"entity\": \"City\",\n","  \"ruleScope\": \"document\",\n","  \"matchScope\": \"sub-token\",\n","}\n","```"],"metadata":{"id":"Xib9zHN7oBvV"}},{"cell_type":"markdown","source":["`OUTPUT: [New York, Salt Lake City]`"],"metadata":{"id":"MYmkGdtALXzK"}},{"cell_type":"markdown","source":["When `ruleScope` is set to `\"document\"`, the annotator attempts to find matches by parsing through each sentence in the document one by one, looking for a match with the dictionary items. Beware of how you set `matchScope`. Taking the previous example, if we were to set `matchScope` to `\"token\"` instead of `\"sub-token\"`, here's what would happen:"],"metadata":{"id":"Nmc7rvfsdFK9"}},{"cell_type":"markdown","source":["```\n","{\n","  \"entity\": \"City\",\n","  \"ruleScope\": \"document\",\n","  \"matchScope\": \"token\"\n","}\n","```"],"metadata":{"id":"vkzDTcgen9aS"}},{"cell_type":"markdown","source":["`OUTPUT: [I love New York., Salt Lake City is nice too.]`"],"metadata":{"id":"np7rBSQmetA9"}},{"cell_type":"markdown","source":["As you can see, when `ruleScope` is at the document level, if you set your `matchScope` to the token level, the annotator will output each sentence containing the matched entities as individual chunks."],"metadata":{"id":"w5nNtvLaeOv9"}},{"cell_type":"markdown","source":["### 3.3. Working with Multi-Word Matches\n","\n","Although not directly related to dictionaries, if we build on top of what we've just seen, there is a use-case that is particularly in demand when working with the `ContextualParser` annotator: finding regex matches for chunks of words that span across multiple tokens.\n","\n","Let's re-iterate how the `ruleScope` property works: when `ruleScope` is set to `\"sentence\"`, we're looking for a match on each token of a sentence. When `ruleScope` is set to `\"document\"`, we're looking for a match on each sentence of a document.\n","\n","So now let's imagine you're parsing through medical documents trying to tag the *Family History* headers in those documents."],"metadata":{"id":"7zTtAFwqQdNy"}},{"cell_type":"markdown","source":["```\n","{\n","  \"entity\": \"Family History Header\",\n","  \"regex\": \"[f|F]amily\\s+[h|H]istory\",  \n","  \"ruleScope\": \"document\",\n","  \"matchScope\": \"sub-token\"\n","}\n","```\n"],"metadata":{"id":"eJWXRrg0Qu0q"}},{"cell_type":"markdown","source":["`OUTPUT: [Family History, family history, Family history]`"],"metadata":{"id":"OP4H1t3CQyg5"}},{"cell_type":"markdown","source":["If you had set `ruleScope` to  `\"sentence\"`, here's what would have happened:"],"metadata":{"id":"X8PgD_N9RFTP"}},{"cell_type":"markdown","source":["```\n","{\n","  \"entity\": \"Family History Header\",\n","  \"regex\": \"[f|F]amily\\s+[h|H]istory\",  \n","  \"ruleScope\": \"sentence\",\n","  \"matchScope\": \"sub-token\"\n","}\n","```"],"metadata":{"id":"ljqiVjWaRJPe"}},{"cell_type":"markdown","source":["`OUTPUT: []`"],"metadata":{"id":"GfcGKW81RMKN"}},{"cell_type":"markdown","source":["Since Family History is divided into two different tokens, the annotator will never find a match since it's now looking for a match on each token of a sentence."],"metadata":{"id":"yMMgQdK5RPYb"}},{"cell_type":"markdown","source":["# Running a Pipeline"],"metadata":{"id":"ehWiHjziPfGV"}},{"cell_type":"markdown","source":["## Example 1: Detecting Cities"],"metadata":{"id":"VGz-nXwCDLgb"}},{"cell_type":"markdown","source":["Let's try running through some examples to build on top of what you've learned so far."],"metadata":{"id":"thaF2bObwDXd"}},{"cell_type":"code","source":["# Here's some sample text\n","sample_text = \"\"\"Peter Parker is a nice guy and lives in New York . Bruce Wayne is also a nice guy and lives in San Antonio and Gotham City . \"\"\""],"metadata":{"id":"mcWKcPZO-upM","executionInfo":{"status":"ok","timestamp":1689494012420,"user_tz":-120,"elapsed":12,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Create a dictionary to detect cities\n","cities = \"\"\"City\\nNew York\\nGotham City\\nSan Antonio\\nSalt Lake City\"\"\"\n","\n","with open('cities.tsv', 'w') as f:\n","    f.write(cities)\n","\n","# Check what dictionary looks like\n","!cat cities.tsv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y4Ipms-4PwoN","outputId":"92e316a4-99a0-496a-b01f-fcdca382e027","executionInfo":{"status":"ok","timestamp":1689494012420,"user_tz":-120,"elapsed":11,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"}}},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["City\n","New York\n","Gotham City\n","San Antonio\n","Salt Lake City"]}]},{"cell_type":"code","source":["# Create JSON file\n","cities = {\n","  \"entity\": \"City\",\n","  \"ruleScope\": \"document\",\n","  \"matchScope\":\"sub-token\",\n","  \"completeMatchRegex\": \"false\"\n","}\n","\n","import json\n","with open('cities.json', 'w') as f:\n","    json.dump(cities, f)"],"metadata":{"id":"Jvi1mbqY_LeA","executionInfo":{"status":"ok","timestamp":1689494012421,"user_tz":-120,"elapsed":7,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Build pipeline\n","document_assembler = DocumentAssembler() \\\n","    .setInputCol(\"text\") \\\n","    .setOutputCol(\"document\")\n","\n","sentence_detector = SentenceDetector() \\\n","    .setInputCols([\"document\"]) \\\n","    .setOutputCol(\"sentence\")\n","\n","tokenizer = Tokenizer() \\\n","    .setInputCols([\"sentence\"]) \\\n","    .setOutputCol(\"token\")\n","\n","contextual_parser = ContextualParserApproach() \\\n","    .setInputCols([\"sentence\", \"token\"])\\\n","    .setOutputCol(\"entity\")\\\n","    .setJsonPath(\"cities.json\")\\\n","    .setCaseSensitive(True)\\\n","    .setDictionary('cities.tsv', options={\"orientation\":\"vertical\"})\n","\n","chunk_converter = ChunkConverter() \\\n","    .setInputCols([\"entity\"]) \\\n","    .setOutputCol(\"ner_chunk\")\n","\n","parserPipeline = Pipeline(stages=[\n","        document_assembler,\n","        sentence_detector,\n","        tokenizer,\n","        contextual_parser,\n","        chunk_converter,\n","        ])"],"metadata":{"id":"yjQmEjWNQHvx","executionInfo":{"status":"ok","timestamp":1689494012789,"user_tz":-120,"elapsed":375,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Create a lightpipeline model\n","empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n","\n","parserModel = parserPipeline.fit(empty_data)\n","\n","light_model = LightPipeline(parserModel)"],"metadata":{"id":"HxPVaa4fYCb5","executionInfo":{"status":"ok","timestamp":1689494017783,"user_tz":-120,"elapsed":4999,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Annotate the sample text\n","annotations = light_model.fullAnnotate(sample_text)[0]"],"metadata":{"id":"3T1xnn0vYOMA","executionInfo":{"status":"ok","timestamp":1689494018858,"user_tz":-120,"elapsed":1081,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Check outputs\n","annotations.get('ner_chunk')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NY5zFoeSb8fg","outputId":"b386bb55-ebbd-44ab-bf55-1647f1435978","executionInfo":{"status":"ok","timestamp":1689494018859,"user_tz":-120,"elapsed":13,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"}}},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Annotation(chunk, 40, 47, New York, {'field': 'City', 'tokenIndex': '9', 'ner_source': 'ner_chunk', 'normalized': 'City', 'confidenceValue': '0.50', 'entity': 'City', 'sentence': '0'}, []),\n"," Annotation(chunk, 95, 105, San Antonio, {'field': 'City', 'tokenIndex': '10', 'ner_source': 'ner_chunk', 'normalized': 'City', 'confidenceValue': '0.50', 'entity': 'City', 'sentence': '1'}, []),\n"," Annotation(chunk, 111, 121, Gotham City, {'field': 'City', 'tokenIndex': '13', 'ner_source': 'ner_chunk', 'normalized': 'City', 'confidenceValue': '0.50', 'entity': 'City', 'sentence': '1'}, [])]"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# Visualize outputs\n","from sparknlp_display import NerVisualizer\n","\n","visualiser = NerVisualizer()\n","\n","visualiser.display(annotations, label_col='ner_chunk', document_col='document', save_path=\"display_result.html\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":88},"id":"BBRie-vWXzK6","outputId":"50471f72-0667-4ae4-8696-ea1285d8a2a1","executionInfo":{"status":"ok","timestamp":1689494019531,"user_tz":-120,"elapsed":679,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"}}},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","<style>\n","    @import url('https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700&display=swap');\n","    @import url('https://fonts.googleapis.com/css2?family=Vistol Regular:wght@300;400;500;600;700&display=swap');\n","    \n","    .spark-nlp-display-scroll-entities {\n","        border: 1px solid #E7EDF0;\n","        border-radius: 3px;\n","        text-align: justify;\n","        \n","    }\n","    .spark-nlp-display-scroll-entities span {  \n","        font-size: 14px;\n","        line-height: 24px;\n","        color: #536B76;\n","        font-family: 'Montserrat', sans-serif !important;\n","    }\n","    \n","    .spark-nlp-display-entity-wrapper{\n","    \n","        display: inline-grid;\n","        text-align: center;\n","        border-radius: 4px;\n","        margin: 0 2px 5px 2px;\n","        padding: 1px\n","    }\n","    .spark-nlp-display-entity-name{\n","        font-size: 14px;\n","        line-height: 24px;\n","        font-family: 'Montserrat', sans-serif !important;\n","        \n","        background: #f1f2f3;\n","        border-width: medium;\n","        text-align: center;\n","        \n","        font-weight: 400;\n","        \n","        border-radius: 5px;\n","        padding: 2px 5px;\n","        display: block;\n","        margin: 3px 2px;\n","    \n","    }\n","    .spark-nlp-display-entity-type{\n","        font-size: 14px;\n","        line-height: 24px;\n","        color: #ffffff;\n","        font-family: 'Montserrat', sans-serif !important;\n","        \n","        text-transform: uppercase;\n","        \n","        font-weight: 500;\n","\n","        display: block;\n","        padding: 3px 5px;\n","    }\n","    \n","    .spark-nlp-display-entity-resolution{\n","        font-size: 14px;\n","        line-height: 24px;\n","        color: #ffffff;\n","        font-family: 'Vistol Regular', sans-serif !important;\n","        \n","        text-transform: uppercase;\n","        \n","        font-weight: 500;\n","\n","        display: block;\n","        padding: 3px 5px;\n","    }\n","    \n","    .spark-nlp-display-others{\n","        font-size: 14px;\n","        line-height: 24px;\n","        font-family: 'Montserrat', sans-serif !important;\n","        \n","        font-weight: 400;\n","    }\n","\n","</style>\n"," <span class=\"spark-nlp-display-others\" style=\"background-color: white\">Peter Parker is a nice guy and lives in </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #107386\"><span class=\"spark-nlp-display-entity-name\">New York </span><span class=\"spark-nlp-display-entity-type\">City</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> . Bruce Wayne is also a nice guy and lives in </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #107386\"><span class=\"spark-nlp-display-entity-name\">San Antonio </span><span class=\"spark-nlp-display-entity-type\">City</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> and </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #107386\"><span class=\"spark-nlp-display-entity-name\">Gotham City </span><span class=\"spark-nlp-display-entity-type\">City</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> . </span></div>"]},"metadata":{}}]},{"cell_type":"markdown","source":["Feel free to experiment with the annotator parameters and JSON properties to see how the output might change."],"metadata":{"id":"gtD1HJ7SABU7"}},{"cell_type":"markdown","source":["## Example 2: Detect Gender and Age"],"metadata":{"id":"lR6FnTsyBAjn"}},{"cell_type":"code","source":["# Here's some sample text\n","sample_text = \"\"\"A 28 year old female with a history of gestational diabetes mellitus diagnosed 8 years ago.\n","                 3 years ago, he reported an episode of HTG-induced pancreatitis .\n","                 5 months old boy with repeated concussions.\"\"\""],"metadata":{"id":"tXK5CLYfDhNB","executionInfo":{"status":"ok","timestamp":1689494019532,"user_tz":-120,"elapsed":18,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Create a dictionary to detect gender\n","gender = '''male,man,male,boy,gentleman,he,him\n","female,woman,female,girl,lady,old-lady,she,her\n","neutral,they,neutral,it'''\n","\n","with open('gender.csv', 'w') as f:\n","    f.write(gender)\n","\n","# Check what dictionary looks like\n","!cat gender.csv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0307e26b-3e6c-4e90-ce2b-16d140a3eca1","id":"0OZqYhDFDhNB","executionInfo":{"status":"ok","timestamp":1689494019757,"user_tz":-120,"elapsed":242,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"}}},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["male,man,male,boy,gentleman,he,him\n","female,woman,female,girl,lady,old-lady,she,her\n","neutral,they,neutral,it"]}]},{"cell_type":"code","source":["# Create JSON file for gender\n","gender = {\n","  \"entity\": \"Gender\",\n","  \"ruleScope\": \"sentence\",\n","  \"completeMatchRegex\": \"true\",\n","  \"matchScope\":\"token\"\n","}\n","\n","import json\n","with open('gender.json', 'w') as f:\n","    json.dump(gender, f)"],"metadata":{"id":"U5-tYW1iDhNB","executionInfo":{"status":"ok","timestamp":1689494019758,"user_tz":-120,"elapsed":6,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# Create JSON file for age\n","age = {\n","  \"entity\": \"Age\",\n","  \"ruleScope\": \"sentence\",\n","  \"matchScope\":\"token\",\n","  \"regex\":\"\\\\d{1,3}\",\n","  \"prefix\":[\"age of\", \"age\"],\n","  \"suffix\": [\"-years-old\", \"years-old\", \"-year-old\",\n","             \"-months-old\", \"-month-old\", \"-months-old\",\n","             \"-day-old\", \"-days-old\", \"month old\",\n","             \"days old\", \"year old\", \"years old\",\n","             \"years\", \"year\", \"months\", \"old\"],\n","  \"contextLength\": 25,\n","  \"contextException\": [\"ago\"],\n","  \"exceptionDistance\": 12\n","}\n","\n","with open('age.json', 'w') as f:\n","    json.dump(age, f)"],"metadata":{"id":"bynTPmlQHEPv","executionInfo":{"status":"ok","timestamp":1689494019758,"user_tz":-120,"elapsed":5,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# Build pipeline\n","document_assembler = DocumentAssembler() \\\n","    .setInputCol(\"text\") \\\n","    .setOutputCol(\"document\")\n","\n","sentence_detector = SentenceDetector() \\\n","    .setInputCols([\"document\"]) \\\n","    .setOutputCol(\"sentence\")\n","\n","tokenizer = Tokenizer() \\\n","    .setInputCols([\"sentence\"]) \\\n","    .setOutputCol(\"token\")\n","\n","gender_contextual_parser = ContextualParserApproach() \\\n","        .setInputCols([\"sentence\", \"token\"]) \\\n","        .setOutputCol(\"chunk_gender\") \\\n","        .setJsonPath(\"gender.json\") \\\n","        .setCaseSensitive(False) \\\n","        .setDictionary('gender.csv', options={\"delimiter\":\",\"}) \\\n","        .setPrefixAndSuffixMatch(False)\n","\n","age_contextual_parser = ContextualParserApproach() \\\n","        .setInputCols([\"sentence\", \"token\"]) \\\n","        .setOutputCol(\"chunk_age\") \\\n","        .setJsonPath(\"age.json\") \\\n","        .setCaseSensitive(False) \\\n","        .setPrefixAndSuffixMatch(False)\\\n","        .setShortestContextMatch(True)\\\n","        .setOptionalContextRules(False)\n","\n","chunk_merger = ChunkMergeApproach() \\\n","    .setInputCols([\"chunk_gender\", \"chunk_age\"]) \\\n","    .setOutputCol(\"ner_chunk\")\n","\n","parserPipeline = Pipeline(stages=[\n","        document_assembler,\n","        sentence_detector,\n","        tokenizer,\n","        gender_contextual_parser,\n","        age_contextual_parser,\n","        chunk_merger\n","        ])"],"metadata":{"id":"pBQVujx1DhNC","executionInfo":{"status":"ok","timestamp":1689494019759,"user_tz":-120,"elapsed":6,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# Create a lightpipeline model\n","empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n","\n","parserModel = parserPipeline.fit(empty_data)\n","\n","light_model = LightPipeline(parserModel)"],"metadata":{"id":"36ZxeslFDhNC","executionInfo":{"status":"ok","timestamp":1689494021005,"user_tz":-120,"elapsed":1251,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# Annotate the sample text\n","annotations = light_model.fullAnnotate(sample_text)[0]"],"metadata":{"id":"OIhdQ4IjDhNC","executionInfo":{"status":"ok","timestamp":1689494021363,"user_tz":-120,"elapsed":365,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# Check outputs\n","annotations.get('ner_chunk')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b27c0cbd-3c18-4777-aee7-58633c21c81a","id":"1tdgMbaWDhNC","executionInfo":{"status":"ok","timestamp":1689494021364,"user_tz":-120,"elapsed":22,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"}}},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Annotation(chunk, 2, 3, 28, {'tokenIndex': '1', 'entity': 'Age', 'field': 'Age', 'chunk': '0', 'normalized': '', 'sentence': '0', 'confidenceValue': '0.74'}, []),\n"," Annotation(chunk, 14, 19, female, {'tokenIndex': '4', 'entity': 'Gender', 'field': 'Gender', 'chunk': '1', 'normalized': 'female', 'sentence': '0', 'confidenceValue': '0.50'}, []),\n"," Annotation(chunk, 122, 123, he, {'tokenIndex': '4', 'entity': 'Gender', 'field': 'Gender', 'chunk': '2', 'normalized': 'male', 'sentence': '1', 'confidenceValue': '0.50'}, []),\n"," Annotation(chunk, 192, 192, 5, {'tokenIndex': '0', 'entity': 'Age', 'field': 'Age', 'chunk': '3', 'normalized': '', 'sentence': '2', 'confidenceValue': '0.74'}, []),\n"," Annotation(chunk, 205, 207, boy, {'tokenIndex': '3', 'entity': 'Gender', 'field': 'Gender', 'chunk': '4', 'normalized': 'male', 'sentence': '2', 'confidenceValue': '0.50'}, [])]"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["# Visualize outputs\n","from sparknlp_display import NerVisualizer\n","\n","visualiser = NerVisualizer()\n","\n","visualiser.display(annotations, label_col='ner_chunk', document_col='document', save_path=\"display_result_2.html\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":230},"outputId":"30441480-4a01-4438-d1eb-ebca6e7ad411","id":"xw0mQKMxDhND","executionInfo":{"status":"ok","timestamp":1689494021364,"user_tz":-120,"elapsed":19,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"}}},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","<style>\n","    @import url('https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700&display=swap');\n","    @import url('https://fonts.googleapis.com/css2?family=Vistol Regular:wght@300;400;500;600;700&display=swap');\n","    \n","    .spark-nlp-display-scroll-entities {\n","        border: 1px solid #E7EDF0;\n","        border-radius: 3px;\n","        text-align: justify;\n","        \n","    }\n","    .spark-nlp-display-scroll-entities span {  \n","        font-size: 14px;\n","        line-height: 24px;\n","        color: #536B76;\n","        font-family: 'Montserrat', sans-serif !important;\n","    }\n","    \n","    .spark-nlp-display-entity-wrapper{\n","    \n","        display: inline-grid;\n","        text-align: center;\n","        border-radius: 4px;\n","        margin: 0 2px 5px 2px;\n","        padding: 1px\n","    }\n","    .spark-nlp-display-entity-name{\n","        font-size: 14px;\n","        line-height: 24px;\n","        font-family: 'Montserrat', sans-serif !important;\n","        \n","        background: #f1f2f3;\n","        border-width: medium;\n","        text-align: center;\n","        \n","        font-weight: 400;\n","        \n","        border-radius: 5px;\n","        padding: 2px 5px;\n","        display: block;\n","        margin: 3px 2px;\n","    \n","    }\n","    .spark-nlp-display-entity-type{\n","        font-size: 14px;\n","        line-height: 24px;\n","        color: #ffffff;\n","        font-family: 'Montserrat', sans-serif !important;\n","        \n","        text-transform: uppercase;\n","        \n","        font-weight: 500;\n","\n","        display: block;\n","        padding: 3px 5px;\n","    }\n","    \n","    .spark-nlp-display-entity-resolution{\n","        font-size: 14px;\n","        line-height: 24px;\n","        color: #ffffff;\n","        font-family: 'Vistol Regular', sans-serif !important;\n","        \n","        text-transform: uppercase;\n","        \n","        font-weight: 500;\n","\n","        display: block;\n","        padding: 3px 5px;\n","    }\n","    \n","    .spark-nlp-display-others{\n","        font-size: 14px;\n","        line-height: 24px;\n","        font-family: 'Montserrat', sans-serif !important;\n","        \n","        font-weight: 400;\n","    }\n","\n","</style>\n"," <span class=\"spark-nlp-display-others\" style=\"background-color: white\">A </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #ffe0ac\"><span class=\"spark-nlp-display-entity-name\">28 </span><span class=\"spark-nlp-display-entity-type\">Age</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> year old </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #ffacb7\"><span class=\"spark-nlp-display-entity-name\">female </span><span class=\"spark-nlp-display-entity-type\">Gender</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> with a history of gestational diabetes mellitus diagnosed 8 years ago.<br>                 3 years ago, </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #ffacb7\"><span class=\"spark-nlp-display-entity-name\">he </span><span class=\"spark-nlp-display-entity-type\">Gender</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> reported an episode of HTG-induced pancreatitis .<br>                 </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #ffe0ac\"><span class=\"spark-nlp-display-entity-name\">5 </span><span class=\"spark-nlp-display-entity-type\">Age</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> months old </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #ffacb7\"><span class=\"spark-nlp-display-entity-name\">boy </span><span class=\"spark-nlp-display-entity-type\">Gender</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> with repeated concussions.</span></div>"]},"metadata":{}}]},{"cell_type":"markdown","source":["Feel free to experiment with the annotator parameters and JSON properties to see how the output might change. If you're looking to work on running the pipeline on a full dataset, just make sure to use the `fit()` and `transform()` methods directly on your dataset instead of using the lightpipeline."],"metadata":{"id":"iOtVACnl_t3n"}},{"cell_type":"code","source":["# Create example dataframe with sample text\n","data = spark.createDataFrame([[sample_text]]).toDF(\"text\")\n","\n","# Fit and show\n","results = parserPipeline.fit(data).transform(data)\n","results.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L6nRUUrRRfoB","outputId":"93d359e8-5fca-4f9f-e955-c5befa011870","executionInfo":{"status":"ok","timestamp":1689494028046,"user_tz":-120,"elapsed":6698,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"}}},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n","|                text|            document|            sentence|               token|        chunk_gender|           chunk_age|           ner_chunk|\n","+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n","|A 28 year old fem...|[{document, 0, 23...|[{document, 0, 90...|[{token, 0, 0, A,...|[{chunk, 14, 19, ...|[{chunk, 2, 3, 28...|[{chunk, 2, 3, 28...|\n","+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n","\n"]}]},{"cell_type":"code","source":["results.select(\"chunk_age.result\").show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"orB8zsF9G6H4","outputId":"fae955b0-e22d-4fb8-eb12-7ec2f5add53a","executionInfo":{"status":"ok","timestamp":1689494028997,"user_tz":-120,"elapsed":956,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"}}},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------+\n","| result|\n","+-------+\n","|[28, 5]|\n","+-------+\n","\n"]}]},{"cell_type":"code","source":["results.select(\"chunk_gender.result\").show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qzn7Qv3_HERi","outputId":"18d6c2ad-2584-46e0-ce5f-906a8fed1fb6","executionInfo":{"status":"ok","timestamp":1689494030231,"user_tz":-120,"elapsed":1239,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"}}},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------------+\n","|           result|\n","+-----------------+\n","|[female, he, boy]|\n","+-----------------+\n","\n"]}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":0}