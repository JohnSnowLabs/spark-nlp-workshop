{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61757ab7-0d33-442e-9ce8-f01031ec163b",
   "metadata": {},
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1280fe1d-cd97-43e4-82ef-1e523ae56c6f",
   "metadata": {},
   "source": [
    "<!-- ========================================================= -->\n",
    "<!--        John Snow Labs - Package Installation Guide         -->\n",
    "<!--        JupyterLab Single Markdown Cell (HTML Content)      -->\n",
    "<!-- ========================================================= -->\n",
    "\n",
    "<h1>Package Installation</h1>\n",
    "\n",
    "<!-- Link to official GitHub repository -->\n",
    "<p>\n",
    "  Official Repository:\n",
    "  <a href=\"https://github.com/JohnSnowLabs/johnsnowlabs\" target=\"_blank\">\n",
    "    https://github.com/JohnSnowLabs/johnsnowlabs\n",
    "  </a>\n",
    "</p>\n",
    "\n",
    "<!-- License setup instructions -->\n",
    "<p>\n",
    "  Keep your <strong>license keys</strong> in a JSON file and point to it using the\n",
    "  <code>json_license_path</code> argument when starting the Spark session.\n",
    "</p>\n",
    "\n",
    "<!-- Visual NLP configuration note -->\n",
    "<p>\n",
    "  Set <code>visual=True</code> while starting the Spark session to install and make\n",
    "  <strong>Visual NLP libraries</strong> available.\n",
    "</p>\n",
    "\n",
    "<!-- Restart note -->\n",
    "<p>\n",
    "  ‚ö†Ô∏è <strong>Important:</strong> After installing the library, make sure to\n",
    "  <strong>RESTART your session</strong> before running Spark again.\n",
    "</p>\n",
    "\n",
    "<!-- End of notebook cell -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf509c5-ed34-4552-93e9-dd6a5f93832b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q johnsnowlabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6318bd6e-1848-4ab1-88da-ac48e4beb748",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from johnsnowlabs import nlp, visual, medical\n",
    "\n",
    "nlp.install(refresh_install=True, visual=True, json_license_path=\"./spark_nlp_for_healthcare_spark_ocr_10538.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c665871-f9de-42e7-9d88-ff859bb56f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "### RESTART SESSION !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "127d6747-475f-43da-a111-4dab969b924a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üëå License info detected in file ./spark_nlp_for_healthcare_spark_ocr_10538.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/21 09:36:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üëå Launched \u001b[92mgpu optimized\u001b[39m session with with: üöÄSpark-NLP==6.1.3, üíäSpark-Healthcare==6.1.1, üï∂Spark-OCR==6.1.0, running on ‚ö° PySpark==3.4.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://071af2228ca5:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>John-Snow-Labs-Spark-Session üöÄ with Jars for: üöÄSpark-NLP==6.1.3, üíäSpark-Healthcare==6.1.1, üï∂Spark-OCR==6.1.0, running on ‚ö° PySpark==3.4.0</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7d37955e3860>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from johnsnowlabs import visual, nlp\n",
    "\n",
    "spark = nlp.start(visual=True, hardware_target=\"gpu\", json_license_path=\"./spark_nlp_for_healthcare_spark_ocr_10538.json\")\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bb5116-315b-450c-a30b-d7721ae29cc4",
   "metadata": {},
   "source": [
    "<h1>Spark Streaming Overview</h1>\n",
    "\n",
    "<!-- Notebook purpose -->\n",
    "<p>\n",
    "  This notebook introduces <strong>Spark Streaming</strong> ‚Äî the real-time and continuous data processing framework in\n",
    "  <strong>Apache Spark</strong>. It demonstrates how <strong>Visual NLP</strong> and <strong>Healthcare NLP</strong> pipelines\n",
    "  can be integrated with streaming data sources to perform large-scale, real-time document and image processing tasks\n",
    "  such as OCR, De-identification, and Visual Question Answering.\n",
    "</p>\n",
    "\n",
    "<!-- Aggregation note -->\n",
    "<p>\n",
    "  In streaming mode, <strong>aggregations should be performed inside</strong>\n",
    "  <code>foreach_batch_function()</code>.\n",
    "  This is because stages such as <strong>DicomDrawRegions</strong> perform internal aggregations\n",
    "  (e.g., collecting coordinates, exceptions, or pixel regions) that are not compatible with the default append mode\n",
    "  of Structured Streaming. Executing them inside the <code>foreach_batch_function()</code> ensures that\n",
    "  all per-batch computations are properly handled and results are written deterministically.\n",
    "</p>\n",
    "\n",
    "<!-- Stages list -->\n",
    "<h2>Concepts and Components Covered in this Notebook</h2>\n",
    "<ul>\n",
    "  <li>clinical_deidentification_docwise_benchmark_large Pretrained Pipeline</li>\n",
    "  <li>Spark Streaming</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbf20fc9-1b4d-4f87-9f07-381ee708d665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ Spark OCR Imports\n",
    "from sparkocr.transformers import *\n",
    "from sparkocr.enums import *\n",
    "from sparkocr.utils import *\n",
    "from sparkocr.schemas import BinarySchema\n",
    "\n",
    "# ‚ö° Spark NLP Core\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "\n",
    "# üîó Spark ML\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# üß© Spark NLP for Healthcare (JSL)\n",
    "import sparknlp_jsl\n",
    "from sparknlp_jsl.annotator import *\n",
    "from sparkocr.base import LightPipeline\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from urllib.parse import urlparse\n",
    "from IPython.display import display, Markdown\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import pkg_resources\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532f4f72-09ca-48ff-81d7-e08c6ac09bb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "deid_pipeline = PretrainedPipeline(\"clinical_deidentification_docwise_benchmark_large\", \"en\", \"clinical/models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e728e1a5-46d1-415e-8bb1-3c191419d765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_text_detector_mem_opt download started this may take some time.\n",
      "Approximate size to download 77.5 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/21 09:38:45 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n",
      "25/10/21 09:38:45 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_text_detector_mem_opt download started this may take some time.\n",
      "Approximate size to download 77.5 MB\n",
      "Download done! Loading the resource.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/21 09:38:47 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n",
      "25/10/21 09:38:47 WARN S3AbortableInputStream: Not all bytes were read from the S3ObjectInputStream, aborting HTTP connection. This is likely an error and may result in sub-optimal behavior. Request only the bytes you need via a ranged GET or drain the input stream after use.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ocr_large_printed_v2_opt download started this may take some time.\n",
      "Approximate size to download 931 MB\n",
      "Download done! Loading the resource.\n"
     ]
    }
   ],
   "source": [
    "dicom_to_metadata = DicomToMetadata() \\\n",
    "    .setInputCol(\"content\") \\\n",
    "    .setOutputCol(\"metadata\") \\\n",
    "    .setKeepInput(True)\n",
    "\n",
    "dicom_to_image = DicomToImageV3() \\\n",
    "    .setInputCols([\"content\"]) \\\n",
    "    .setOutputCol(\"image_raw\") \\\n",
    "    .setKeepInput(False)\n",
    "\n",
    "text_detector = ImageTextDetector.pretrained(\"image_text_detector_mem_opt\", \"en\", \"clinical/ocr\") \\\n",
    "    .setInputCol(\"image_raw\") \\\n",
    "    .setOutputCol(\"text_regions\") \\\n",
    "    .setScoreThreshold(0.7) \\\n",
    "    .setWithRefiner(True) \\\n",
    "    .setUseGPU(True) \\\n",
    "    .setWidth(0)\n",
    "\n",
    "ocr = ImageToTextV2.pretrained(\"ocr_large_printed_v2_opt\", \"en\", \"clinical/ocr\") \\\n",
    "    .setRegionsColumn(\"text_regions\") \\\n",
    "    .setInputCols([\"image_raw\"]) \\\n",
    "    .setOutputCol(\"text\") \\\n",
    "    .setOutputFormat(\"text_with_positions\") \\\n",
    "    .setGroupImages(False) \\\n",
    "    .setKeepInput(False) \\\n",
    "    .setUseGPU(True) \\\n",
    "    .setUseCaching(True) \\\n",
    "    .setBatchSize(4)\n",
    "\n",
    "regex_matcher = RegexMatcher()\\\n",
    "    .setInputCols(\"document\")\\\n",
    "    .setOutputCol(\"regex\")\\\n",
    "    .setRules([\n",
    "        r\"(?:\\s[MFU]|\\b[MFU])(?:\\s|\\b|$);GENDER\",\n",
    "        r\"\\b(?:JT|SWU|JKR|MWF|ICG|NKF|YH|TJN|LEITO|ACO|CEF|CMS|JGR|MSS|MHS|ROC|LM|RCN|FTA|MGO|LACI|VV|HA|TR|CJA)\\b;CODE\"]) \\\n",
    "    .setDelimiter(\";\")\n",
    "\n",
    "chunkConverter = ChunkConverter()\\\n",
    "    .setInputCols(\"regex\")\\\n",
    "    .setOutputCol(\"regex_chunks\")\n",
    "\n",
    "chunk_merger = ChunkMergeApproach()\\\n",
    "    .setInputCols('regex_chunks', \"ner_chunk\")\\\n",
    "    .setOutputCol('merged_ner_chunk')\\\n",
    "    .setMergeOverlapping(True)\n",
    "\n",
    "position_finder = PositionFinder() \\\n",
    "    .setInputCols(\"merged_ner_chunk\") \\\n",
    "    .setOutputCol(\"coordinates\") \\\n",
    "    .setPageMatrixCol(\"positions\") \\\n",
    "    .setSmoothCoordinates(True)\n",
    "\n",
    "draw_regions = DicomDrawRegions() \\\n",
    "    .setInputCol(\"path\") \\\n",
    "    .setInputRegionsCol(\"coordinates\") \\\n",
    "    .setOutputCol(\"dicom\") \\\n",
    "    .setAggCols([\"path\"]) \\\n",
    "    .setKeepInput(True)\n",
    "\n",
    "dicom_deidentifier = DicomMetadataDeidentifier() \\\n",
    "    .setInputCols([\"dicom\"]) \\\n",
    "    .setOutputCol(\"dicom_cleaned\")\n",
    "\n",
    "stages = deid_pipeline.model.stages[:-2].copy()\n",
    "\n",
    "stages.insert(0, dicom_to_metadata)\n",
    "stages.insert(1, dicom_to_image)\n",
    "stages.insert(2, text_detector)\n",
    "stages.insert(3, ocr)\n",
    "stages.append(regex_matcher)\n",
    "stages.append(chunkConverter)\n",
    "stages.append(chunk_merger)\n",
    "stages.append(position_finder)\n",
    "\n",
    "dicom_phi_deid_pipeline = Pipeline(stages=stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f73372ba-5da3-4cf3-a09e-4654bc8c319d",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxFilesPerTrigger = 2\n",
    "dicom_path = \"./data/visual/dicom/midib/\"\n",
    "outputPath = \"./deid_stream_output/\"\n",
    "\n",
    "os.makedirs(outputPath, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bbbb88-4b3f-4406-aad6-35d3963e941d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dicom_stream_df = spark.readStream \\\n",
    "    .format(\"binaryFile\") \\\n",
    "    .schema(BinarySchema) \\\n",
    "    .option(\"maxFilesPerTrigger\", maxFilesPerTrigger) \\\n",
    "    .option(\"recursiveFileLookup\", True) \\\n",
    "    .load(dicom_path) \\\n",
    "    .withColumn(\"timestamp\", current_timestamp())\n",
    "\n",
    "result = dicom_phi_deid_pipeline.fit(dicom_stream_df).transform(dicom_stream_df)\n",
    "\n",
    "get_base_name = F.udf(lambda path: os.path.basename(path).replace(\".dcm\", \"\"), StringType())\n",
    "\n",
    "def foreach_batch_function(df, epoch_id):\n",
    "    \n",
    "    df1 = draw_regions.transform(df).withColumn(\"fileName\", get_base_name(col(\"path\"))).repartition(\"fileName\")\n",
    "\n",
    "    dicom_deidentifier.transform(df1).write.format(\"binaryFormat\") \\\n",
    "      .option(\"type\", \"dicom\") \\\n",
    "      .option(\"field\", \"dicom_cleaned\") \\\n",
    "      .option(\"nameField\", \"fileName\") \\\n",
    "      .option(\"extension\", \"dcm\") \\\n",
    "      .option(\"prefix\", \"de-id-\") \\\n",
    "      .mode(\"append\") \\\n",
    "      .save(outputPath)\n",
    "\n",
    "query = result.writeStream.foreachBatch(foreach_batch_function) \\\n",
    "   .queryName('dicom_result') \\\n",
    "   .start()\n",
    "\n",
    "query.lastProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "167ef9d8-a419-47cb-adb6-e834f705179a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'ceb50421-613a-4bba-9157-a2c1d4e5ef53',\n",
       " 'runId': '0c1323fa-16e6-49e4-abb2-c93cb2e791e9',\n",
       " 'name': 'dicom_result',\n",
       " 'timestamp': '2025-10-21T09:48:11.630Z',\n",
       " 'batchId': 13,\n",
       " 'numInputRows': 0,\n",
       " 'inputRowsPerSecond': 0.0,\n",
       " 'processedRowsPerSecond': 0.0,\n",
       " 'durationMs': {'latestOffset': 137, 'triggerExecution': 137},\n",
       " 'stateOperators': [],\n",
       " 'sources': [{'description': 'FileStreamSource[file:/workspace/data/visual/dicom]',\n",
       "   'startOffset': {'logOffset': 12},\n",
       "   'endOffset': {'logOffset': 12},\n",
       "   'latestOffset': None,\n",
       "   'numInputRows': 0,\n",
       "   'inputRowsPerSecond': 0.0,\n",
       "   'processedRowsPerSecond': 0.0}],\n",
       " 'sink': {'description': 'ForeachBatchSink', 'numOutputRows': -1}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.lastProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb1680b4-baa0-4437-849b-4f2a4618e323",
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
