{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0447335",
   "metadata": {},
   "source": [
    "# GenAI Lab ‚Äî LLM Comparison & De-identification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26efb811",
   "metadata": {},
   "source": [
    "## Setup & Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c89d16d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install requests langchain_openai tqdm python-dotenv --break-system-packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af63f322",
   "metadata": {},
   "source": [
    "Load Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d9640476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2217a30f",
   "metadata": {},
   "source": [
    "### Authentication helper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7129259e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, requests, time, json\n",
    "\n",
    "API_URL = os.getenv(\"API_URL\")\n",
    "HEADERS = {\n",
    "    # \"Host\": API_URL.replace(\"http://\", \"\").replace(\"https://\", \"\"),\n",
    "    \"Origin\": API_URL,\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "\n",
    "\n",
    "class AuthManager:\n",
    "    def __init__(self, username, password, client_id, client_secret):\n",
    "        self.api_url = API_URL\n",
    "        self.username = username\n",
    "        self.password = password\n",
    "        self.client_id = client_id\n",
    "        self.client_secret = client_secret\n",
    "        self.token_last_timestamp = 0\n",
    "        self.access_token = None\n",
    "        self.refresh_token = None\n",
    "        self._cookies = None\n",
    "        self.get_token()\n",
    "\n",
    "    def is_token_expired(self):\n",
    "        # Token expires in 15 minutes, refresh 1 min before\n",
    "        if not self.token_last_timestamp or not self.access_token:\n",
    "            return True\n",
    "        return (int(time.time()) - self.token_last_timestamp) > (14 * 60)\n",
    "\n",
    "    def get_token(self):\n",
    "        url = f\"{self.api_url}/openid-connect/token\"\n",
    "        data = {\n",
    "            \"username\": self.username,\n",
    "            \"password\": self.password,\n",
    "            \"client_id\": self.client_id,\n",
    "            \"client_secret\": self.client_secret,\n",
    "        }\n",
    "        response = requests.post(url, data=json.dumps(data))\n",
    "        if not response.ok:\n",
    "            print(f\"‚ùå Failed getting token: {response.json()}\")\n",
    "            return None\n",
    "        auth_info = response.json()\n",
    "        self.access_token = auth_info[\"access_token\"]\n",
    "        self.refresh_token = auth_info[\"refresh_token\"]\n",
    "        self.token_last_timestamp = int(time.time())\n",
    "        self._cookies = {\n",
    "            \"access_token\": f\"Bearer {self.access_token}\",\n",
    "            \"refresh_token\": self.refresh_token,\n",
    "        }\n",
    "        return self.access_token\n",
    "\n",
    "    @property\n",
    "    def cookies(self):\n",
    "        if self.is_token_expired():\n",
    "            self.get_token()\n",
    "        return self._cookies\n",
    "\n",
    "    def get_auth_header(self):\n",
    "        if self.is_token_expired():\n",
    "            self.get_token()\n",
    "        return {\"Authorization\": f\"Bearer {self.access_token}\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674b5435",
   "metadata": {},
   "source": [
    "### LOGIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eb6855ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üü¢ Authentication Successful\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "USERNAME = os.getenv(\"USERNAME\")\n",
    "PASSWORD = os.getenv(\"PASSWORD\")\n",
    "CLIENT_ID = \"annotationlab\"\n",
    "CLIENT_SECRET = os.getenv(\"CLIENT_SECRET\")\n",
    "\n",
    "auth = AuthManager(USERNAME, PASSWORD, CLIENT_ID, CLIENT_SECRET)\n",
    "print(\"üü¢ Authentication Successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4a2a2c",
   "metadata": {},
   "source": [
    "### Project Helpers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7ee41f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from math import ceil\n",
    "import uuid\n",
    "\n",
    "\n",
    "def create_project(project_name: str):\n",
    "    try:\n",
    "        payload = {\"project_name\": project_name}\n",
    "        response = requests.post(\n",
    "            f\"{API_URL}/api/projects/create\",\n",
    "            headers=HEADERS,\n",
    "            cookies=auth.cookies,\n",
    "            json=payload,\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        print(f\"‚úÖ Project '{project_name}' created successfully\")\n",
    "        return response.json()\n",
    "    except requests.HTTPError as http_error:\n",
    "        print(f\"‚ùå Project Creation Failed. Error={http_error.response.text}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def get_config_templates():\n",
    "    try:\n",
    "        response = requests.get(\n",
    "            f\"{API_URL}/api/projects/config_templates\",\n",
    "            headers=HEADERS,\n",
    "            cookies=auth.cookies,\n",
    "        )\n",
    "        return response.json()[\"templates\"]\n",
    "    except requests.HTTPError as http_error:\n",
    "        print(f\"‚ùå Couldn't get config templates. Error={http_error.response.text}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def update_project_config(project_name: str, label_config: str, deploy=False, custom_llm_service_provider=None):\n",
    "    try:\n",
    "        payload = {\"label_config\": label_config, \"deploy\": str(deploy).lower()}\n",
    "        if custom_llm_service_provider:\n",
    "            payload.update({\"custom_llm_service_provider\": json.dumps(custom_llm_service_provider)})\n",
    "        response = requests.post(\n",
    "            f\"{API_URL}/api/projects/{project_name}/save-config\",\n",
    "            headers={**HEADERS, \"Content-Type\": \"application/x-www-form-urlencoded\"},\n",
    "            cookies=auth.cookies,\n",
    "            data=payload,\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        print(f\"‚úÖ Updated project config for '{project_name}' project\")\n",
    "        return response.json()\n",
    "    except requests.HTTPError as http_error:\n",
    "        print(f\"‚ùå Couldn't update project config. Error={http_error.response.text}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def import_tasks_to_project(project_name: str, file_path: str):\n",
    "    try:\n",
    "        file_name = os.path.basename(file_path)\n",
    "        total_size = os.stat(file_path).st_size\n",
    "        chunk_size = 5000000\n",
    "        total_chunks = ceil(total_size / chunk_size)\n",
    "        upload_url = f\"{API_URL}/api/projects/{project_name}/import\"\n",
    "        data = {\n",
    "            \"dzuuid\": str(uuid.uuid4()),\n",
    "            \"dzchunkindex\": \"0\",\n",
    "            \"dztotalfilesize\": str(total_size),\n",
    "            \"dzchunksize\": str(chunk_size),\n",
    "            \"dztotalchunkcount\": str(total_chunks),\n",
    "            \"dzchunkbyteoffset\": \"\",\n",
    "            \"overwrite\": False,\n",
    "            \"ocr_enable\": False,\n",
    "            \"file_name\": file_name,\n",
    "        }\n",
    "        with open(file_path, \"rb\") as file:\n",
    "            files = {\"file\": (file_name, file, \"application/octet-stream\")}\n",
    "            for current_chunk in range(1, total_chunks + 1):\n",
    "                data.update(\n",
    "                    {\n",
    "                        \"dzchunkindex\": str(current_chunk - 1),\n",
    "                        \"dzchunkbyteoffset\": str(chunk_size * (current_chunk - 1)),\n",
    "                    }\n",
    "                )\n",
    "                r = requests.post(\n",
    "                    upload_url,\n",
    "                    files=files,\n",
    "                    data=data,\n",
    "                    cookies=auth.cookies,\n",
    "                )\n",
    "                r.raise_for_status()\n",
    "        print(\"‚úÖ Tasks Imported Successfully.\")\n",
    "    except requests.HTTPError as http_error:\n",
    "        print(f\"‚ùå Import Task Failed. Error={http_error.response.text}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def export_deidentified_tasks(project_name: str):\n",
    "    try:\n",
    "        payload = {\n",
    "            \"tags\": [],\n",
    "            \"groundTruth\": True,\n",
    "            \"excludeTasksWithoutCompletions\": True,\n",
    "            \"excludeTasksWithoutPredictions\": False,\n",
    "            \"annotation_task\": \"all\",\n",
    "            \"annotation_task_value\": [],\n",
    "            \"annotators\": [],\n",
    "            \"deidentificationTask\": True,\n",
    "            \"type\": \"local\",\n",
    "        }\n",
    "        params = {\"format\": \"JSON\"}\n",
    "        response = requests.post(\n",
    "            f\"{API_URL}/api/projects/{project_name}/export\",\n",
    "            headers=HEADERS,\n",
    "            cookies=auth.cookies,\n",
    "            params=params,\n",
    "            json=payload,\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        download_link = response.json().get(\"download_link\")\n",
    "        if not download_link:\n",
    "            raise Exception(\"No download_link in export response\")\n",
    "\n",
    "        with requests.get(download_link, cookies=auth.cookies, stream=True) as download_res:\n",
    "            download_res.raise_for_status()\n",
    "            filename = f\"{datetime.now().strftime('%Y-%m-%d-%H-%M-%S')}_{project_name}.zip\"\n",
    "            chunk_size = 8192\n",
    "            with open(filename, 'wb') as f:\n",
    "                for chunk in download_res.iter_content(chunk_size=chunk_size):\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "        print(f\"‚úÖ Tasks Exported successfully: {filename}\")\n",
    "    except requests.HTTPError as http_error:\n",
    "        print(f\"‚ùå Tasks Export Failed. Error={http_error.response.text}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def get_project_tasks(project_name: str):\n",
    "    try:\n",
    "        response = requests.get(\n",
    "            f\"{API_URL}/api/projects/{project_name}/tasks\",\n",
    "            headers=HEADERS,\n",
    "            cookies=auth.cookies,\n",
    "        )\n",
    "        tasks = response.json()[\"items\"]\n",
    "        return tasks\n",
    "    except requests.HTTPError as http_error:\n",
    "        print(f\"‚ùå Error while getting project tasks. Error={http_error.response.text}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2592006a",
   "metadata": {},
   "source": [
    "## Gen AI Lab - LLM Comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c618379",
   "metadata": {},
   "source": [
    "### 1 - Create Blind LLM Comparison Type Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5672bbe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Project 'NotebookLLMComparisonProject' created successfully\n",
      "‚úÖ Updated project config for 'NotebookLLMComparisonProject' project\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [{'message': 'Project config saved.', 'success': True}]}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LLM_COMPARISON_PROJECT_NAME = \"NotebookLLMComparisonProject\"\n",
    "\n",
    "create_project(LLM_COMPARISON_PROJECT_NAME)\n",
    "\n",
    "config_templates = get_config_templates()\n",
    "blind_eval_proj_config = next(\n",
    "    (config for config in config_templates.get(\"text\", []) if config.get(\"title\") == \"Blind LLM Response Comparison\"),\n",
    "    None,\n",
    ")\n",
    "if not blind_eval_proj_config:\n",
    "    raise RuntimeError(f\"'Blind LLM Response Comparison' type project config not found\")\n",
    "\n",
    "update_project_config(\n",
    "    LLM_COMPARISON_PROJECT_NAME,\n",
    "    label_config=blind_eval_proj_config['label_config'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92555844",
   "metadata": {},
   "source": [
    "### 2 - Add 3 Different LLMs to Project Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8bf1aa50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Updated project config for 'NotebookLLMComparisonProject' project\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [{'message': 'Project config saved.', 'success': True}]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "THREE_LLMS_BLIND_EVAL_LABEL_CONFIG = \"\"\"<View orientation=\"horizontal\" pretty=\"true\" is_llm_comparison=\"true\">\n",
    "  <View pretty=\"true\" className=\"summary\">\n",
    "    <Text name=\"Result Summary\" value=\"$prompt\"/>\n",
    "  </View>\n",
    "  <Header value=\"What response do you prefer  \" size=\"5\" style=\"margin: 10px 20px 10px 0;\"/>\n",
    "  <Choices name=\"choices\" toName=\"Result Summary\" choice=\"single\" showInline=\"true\">\n",
    "    <Choice value=\"response1\"/>\n",
    "    <Choice value=\"response2\"/>\n",
    "    <Choice value=\"response3\"/>\n",
    "  </Choices>\n",
    "  <View orientation=\"horizontal\" pretty=\"true\" evaluation_block=\"true\" style=\"max-height: 70vh;\">\n",
    "    <View style=\"position: sticky; top: 0; z-index: 1000; margin-bottom: 16px;\" pretty=\"true\">\n",
    "      <Labels name=\"label\" toName=\"response1,response2,response3\">\n",
    "        <Label background=\"#cc00d0\" value=\"Hallucination\"/>\n",
    "        <Label background=\"#ffb800\" value=\"CitationError\"/>\n",
    "        <Label background=\"#8e66ff\" value=\"HallucinatedReference\"/>\n",
    "        <Label background=\"#e06681\" value=\"FromMemoryFact\"/>\n",
    "        <Label background=\"#9cbdf7\" value=\"FactMissingCitation\"/>\n",
    "      </Labels>\n",
    "    </View>\n",
    "    <View pretty=\"true\" orientation=\"none\" style=\"display: grid; grid-template-columns: repeat(2, 1fr); row-gap: 16px;\">\n",
    "      <View duplication_block=\"true\" names=\"response1,response2,response3\" collapsible=\"true\" style=\"gap: 16px\">\n",
    "        <View>\n",
    "          <Header value=\"Rate the quality of References\" size=\"5\"/>\n",
    "          <View style=\"gap: 20px;\" orientation=\"vertical\" pretty=\"true\">\n",
    "            <Rating name=\"CitedReferencesQuality\" toName=\"response1,response2,response3\" maxRating=\"5\" meta=\"Rate the quality of References\"/>\n",
    "          </View>\n",
    "        </View>\n",
    "        <View style=\"height: 300px; overflow-y: auto;\" orientation=\"vertical\" pretty=\"true\">\n",
    "          <Text name=\"response1\" value=\"$response1\"/>\n",
    "          <Text name=\"response2\" value=\"$response2\"/>\n",
    "          <Text name=\"response3\" value=\"$response3\"/>\n",
    "        </View>\n",
    "        <Choices name=\"Organization and Coherence\" toName=\"response1,response2,response3\" choice=\"single\" meta=\"Organization and Coherence\" collapsible=\"true\">\n",
    "          <Choice value=\"Score 1 - Poor Organization\"/>\n",
    "          <Choice value=\"Score 2 - Basic Organization\"/>\n",
    "          <Choice value=\"Score 3 - Moderate Organization\"/>\n",
    "          <Choice value=\"Score 4 - Strong Organization\"/>\n",
    "          <Choice value=\"Score 5 - Exceptional Organization\"/>\n",
    "        </Choices>\n",
    "        <Choices name=\"Coverage and Amount of information\" toName=\"response1,response2,response3\" choice=\"single\" meta=\"Coverage and Amount of information\" collapsible=\"true\">\n",
    "          <Choice value=\"Score 1 - Severely Lacking Coverage\"/>\n",
    "          <Choice value=\"Score 2- Partial Coverage\"/>\n",
    "          <Choice value=\"Score 3 - Acceptable Coverage / Overview\"/>\n",
    "          <Choice value=\"Score 4 - Good Coverage\"/>\n",
    "          <Choice value=\"Score 5 - Comprehensive Coverage\"/>\n",
    "        </Choices>\n",
    "        <Choices name=\"Relevance\" toName=\"response1,response2,response3\" choice=\"single\" meta=\"Relevance\" collapsible=\"true\">\n",
    "          <Choice value=\"Score 1 - Off-Topic\"/>\n",
    "          <Choice value=\"Score 2 - Frequently Off-Topic with Limited Focus\"/>\n",
    "          <Choice value=\"Score 3 - Somewhat On-Topic but with Several Digressions or Irrelevant Information\"/>\n",
    "          <Choice value=\"Score 4 - Mostly On-Topic with Minor Deviations\"/>\n",
    "          <Choice value=\"Score 5 - Focused and Entirely On-Topic\"/>\n",
    "        </Choices>\n",
    "        <Choices name=\"Overall Helpfulness\" toName=\"response1,response2,response3\" choice=\"single\" meta=\"Overall Helpfulness\" collapsible=\"true\">\n",
    "          <Choice value=\"Score 1 - Unhelpful\"/>\n",
    "          <Choice value=\"Score 2 - Better than Searching from Scratch, but Limited Utility\"/>\n",
    "          <Choice value=\"Score 3 - Provides Useful Discussions and Papers, Though Individual Review is Needed\"/>\n",
    "          <Choice value=\"Score 4 - Useful\"/>\n",
    "          <Choice value=\"Score 5 - Super Useful\"/>\n",
    "        </Choices>\n",
    "        <Header value=\"Comments\" size=\"5\"/>\n",
    "        <TextArea name=\"OverallComments\" toName=\"response1,response2,response3\" rows=\"3\" maxSubmissions=\"1\" editable=\"true\"/>\n",
    "      </View>\n",
    "    </View>\n",
    "  </View>\n",
    "</View>\"\"\"\n",
    "\n",
    "\n",
    "MODEL_NAME_RESPONSE_LABEL_MAP = {\n",
    "    \"gpt-4o-mini\": \"response1\",\n",
    "    \"gpt-4.1-mini\": \"response2\",\n",
    "    \"gpt-5-mini\": \"response3\",\n",
    "}\n",
    "\n",
    "custom_llm_service_provider = {v:k for k,v in MODEL_NAME_RESPONSE_LABEL_MAP.items()}\n",
    "update_project_config(\n",
    "    LLM_COMPARISON_PROJECT_NAME,\n",
    "    label_config=THREE_LLMS_BLIND_EVAL_LABEL_CONFIG,\n",
    "    custom_llm_service_provider=custom_llm_service_provider,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e366ec",
   "metadata": {},
   "source": [
    "### Generate Responses for the Prompts with 3 different LLMs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a42400cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "# Azure Open AI Creds:\n",
    "AZURE_ENDPOINT = os.getenv(\"AZURE_ENDPOINT\")\n",
    "AZURE_API_VERSION = os.getenv(\"AZURE_API_VERSION\")\n",
    "AZURE_API_KEY = os.getenv(\"AZURE_API_KEY\")\n",
    "\n",
    "\n",
    "def generate_llm_response(prompt: str, model_name: str, temperature=1):\n",
    "    llm = AzureChatOpenAI(\n",
    "        azure_deployment=model_name,\n",
    "        api_key=AZURE_API_KEY,\n",
    "        azure_endpoint=AZURE_ENDPOINT,\n",
    "        api_version=AZURE_API_VERSION,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    response = llm.invoke(prompt)\n",
    "    return response.content\n",
    "\n",
    "\n",
    "def get_multi_llm_response(prompt: str, llm_models: List[str], temperature=1):\n",
    "    responses = []\n",
    "    for llm_model in llm_models:\n",
    "        response = generate_llm_response(prompt, llm_model, temperature)\n",
    "        responses.append({\"model\": llm_model, \"response\": response})\n",
    "    return prompt, responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e3e61434",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîÑ Generating Responses: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:41<00:00,  4.14s/it]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from concurrent.futures import as_completed, ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "\n",
    "PROMPTS_FILE_PATH = \"prompts.json\"\n",
    "PROMPTS_RESPONSES_FILE_PATH = \"prompts-responses.json\"\n",
    "LLM_MODELS = MODEL_NAME_RESPONSE_LABEL_MAP.keys()\n",
    "\n",
    "# Get Prompts\n",
    "with open(PROMPTS_FILE_PATH) as f:\n",
    "    prompts = json.load(f)\n",
    "\n",
    "# Generate Responses with different LLMs for each Prompts\n",
    "prompts_responses = []\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    futures = [executor.submit(get_multi_llm_response, prompt, LLM_MODELS) for prompt in prompts]\n",
    "    for future in tqdm(as_completed(futures), desc=\"üîÑ Generating Responses\", total=len(futures)):\n",
    "        prompt, responses = future.result()\n",
    "        prompts_responses.append({\"prompt\": prompt, \"responses\": responses})\n",
    "\n",
    "# Save Prompts Responses\n",
    "with open(PROMPTS_RESPONSES_FILE_PATH, \"w\") as f:\n",
    "    json.dump(prompts_responses, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbddfcf8",
   "metadata": {},
   "source": [
    "Format the responses to the tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "22e84778",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_COMPARISON_TASKS_FILE_PATH = \"llm-comparison-tasks.json\"\n",
    "\n",
    "\n",
    "def format_prompt_responses_as_task(prompt_responses):\n",
    "    task = {\"data\": {\"prompt\": prompt_responses[\"prompt\"]}}\n",
    "    for response in prompt_responses['responses']:\n",
    "        model = response[\"model\"]\n",
    "        response_label = MODEL_NAME_RESPONSE_LABEL_MAP[model]\n",
    "        task[\"data\"].update({response_label: response[\"response\"]})\n",
    "    return task\n",
    "\n",
    "\n",
    "with open(PROMPTS_RESPONSES_FILE_PATH) as f:\n",
    "    prompts_responses = json.load(f)\n",
    "\n",
    "tasks = []\n",
    "for prompt_responses in prompts_responses:\n",
    "    tasks.append(format_prompt_responses_as_task(prompt_responses))\n",
    "\n",
    "with open(LLM_COMPARISON_TASKS_FILE_PATH, \"w\") as f:\n",
    "    json.dump(tasks, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064519bb",
   "metadata": {},
   "source": [
    "### 2 - Import the tasks to the Project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "308aaccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tasks Imported Successfully.\n"
     ]
    }
   ],
   "source": [
    "import_tasks_to_project(\n",
    "    project_name=LLM_COMPARISON_PROJECT_NAME, file_path=LLM_COMPARISON_TASKS_FILE_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c1fbb1",
   "metadata": {},
   "source": [
    "## Gen AI Lab - DeIdentification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225ae1e0",
   "metadata": {},
   "source": [
    "### DeIdentification Helpers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cbf6da97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_servers():\n",
    "    try:\n",
    "        response = requests.get(\n",
    "            f\"{API_URL}/api/mt/get_model_servers\", headers=HEADERS, cookies=auth.cookies\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        model_servers = response.json()\n",
    "        return model_servers\n",
    "    except requests.HTTPError as http_error:\n",
    "        print(f\"‚ùå Error while getting model servers. Error={http_error.response.text}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def run_deidentification(project_name: str, server_project_id=None):\n",
    "    if not server_project_id:\n",
    "        deployed_model_servers = get_model_servers()\n",
    "        available_model_servers = [\n",
    "            model_server\n",
    "            for model_server in deployed_model_servers\n",
    "            if model_server[\"state\"] == \"idle\"\n",
    "        ]\n",
    "\n",
    "        if not available_model_servers:\n",
    "            print(\"‚ùå Model server not available.\")\n",
    "            raise Exception(\"Model server not available\")\n",
    "        server_project_id = available_model_servers[0][\"id\"]\n",
    "\n",
    "    tasks = get_project_tasks(project_name)\n",
    "    task_ids = [task[\"id\"] for task in tasks]\n",
    "    params = {\"server_project_id\": server_project_id}\n",
    "    payload = {\"task_ids\": task_ids, \"status\": \"\", \"only_deidentificate\": True}\n",
    "    print(\n",
    "        f\"üöÄ Starting DeIdentification; server_id={server_project_id} project_name={project_name} task_ids={task_ids}\"\n",
    "    )\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            f\"{API_URL}/api/projects/{project_name}/preannotate\",\n",
    "            headers=HEADERS,\n",
    "            cookies=auth.cookies,\n",
    "            params=params,\n",
    "            json=payload,\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        print(f\"‚úÖ {response.json()['message']}\")\n",
    "        return {\n",
    "            \"project_name\": project_name,\n",
    "            \"server_project_id\": server_project_id,\n",
    "            \"task_ids\": task_ids,\n",
    "        }\n",
    "    except requests.HTTPError as http_error:\n",
    "        print(f\"‚ùå Error starting DeIdentification. Error={http_error.response.text}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def get_deidentification_status(project_name, task_ids):\n",
    "    try:\n",
    "        response = requests.get(\n",
    "            f\"{API_URL}/api/projects/{project_name}/preannotation_status\",\n",
    "            headers=HEADERS,\n",
    "            cookies=auth.cookies,\n",
    "            params={\"task_id\": \",\".join(map(str, task_ids))},\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.HTTPError as http_error:\n",
    "        print(f\"‚ùå Error while getting DeIdentification Status. Error={http_error.response.text}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01588d18",
   "metadata": {},
   "source": [
    "### 1 - Create DeIdentification Type Project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6d647a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Project 'NotebookDeIdentificationProject' created successfully\n",
      "‚úÖ Updated project config for 'NotebookDeIdentificationProject' project\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [{'message': 'Project config saved.', 'success': True}]}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEIDENTIFICATION_PROJECT_NAME = \"NotebookDeIdentificationProject\"\n",
    "\n",
    "create_project(DEIDENTIFICATION_PROJECT_NAME)\n",
    "\n",
    "config_templates = get_config_templates()\n",
    "deid_proj_config = next(\n",
    "    config\n",
    "    for config in config_templates[\"text\"]\n",
    "    if config[\"title\"] == \"De-identification\"\n",
    ")\n",
    "\n",
    "update_project_config(\n",
    "    DEIDENTIFICATION_PROJECT_NAME, label_config=deid_proj_config[\"label_config\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d797c9e2",
   "metadata": {},
   "source": [
    "### 2 - Import PreAnnotated Tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2426b6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tasks Imported Successfully.\n"
     ]
    }
   ],
   "source": [
    "PREANNOTATED_TASKS_FILE = \"Pre-Annotated-Tasks-ForDeid.zip\"\n",
    "import_tasks_to_project(DEIDENTIFICATION_PROJECT_NAME, PREANNOTATED_TASKS_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57512c9",
   "metadata": {},
   "source": [
    "### 3 - Run DeIdentification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eac497fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting DeIdentification; server_id=144 project_name=NotebookDeIdentificationProject task_ids=[10, 9, 8, 7, 6, 5, 4, 3, 2, 1]\n",
      "‚ùå Error starting DeIdentification. Error={\"error\":\"Server not deployed\"}\n",
      "\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "400 Client Error: Bad Request for url: https://genailab.demo.johnsnowlabs.dev/api/projects/NotebookDeIdentificationProject/preannotate?server_project_id=144",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m SERVER_PROJECT_ID = \u001b[32m144\u001b[39m  \u001b[38;5;66;03m# Already deployed Server Project id\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m run_info = \u001b[43mrun_deidentification\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEIDENTIFICATION_PROJECT_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSERVER_PROJECT_ID\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 43\u001b[39m, in \u001b[36mrun_deidentification\u001b[39m\u001b[34m(project_name, server_project_id)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     36\u001b[39m     response = requests.post(\n\u001b[32m     37\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mAPI_URL\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/api/projects/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproject_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/preannotate\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     38\u001b[39m         headers=HEADERS,\n\u001b[32m   (...)\u001b[39m\u001b[32m     41\u001b[39m         json=payload,\n\u001b[32m     42\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚úÖ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.json()[\u001b[33m'\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     45\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m     46\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mproject_name\u001b[39m\u001b[33m\"\u001b[39m: project_name,\n\u001b[32m     47\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mserver_project_id\u001b[39m\u001b[33m\"\u001b[39m: server_project_id,\n\u001b[32m     48\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtask_ids\u001b[39m\u001b[33m\"\u001b[39m: task_ids,\n\u001b[32m     49\u001b[39m     }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3/dist-packages/requests/models.py:1021\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1016\u001b[39m     http_error_msg = (\n\u001b[32m   1017\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m     )\n\u001b[32m   1020\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1021\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 400 Client Error: Bad Request for url: https://genailab.demo.johnsnowlabs.dev/api/projects/NotebookDeIdentificationProject/preannotate?server_project_id=144"
     ]
    }
   ],
   "source": [
    "SERVER_PROJECT_ID = 144  # Already deployed Server Project id\n",
    "run_info = run_deidentification(DEIDENTIFICATION_PROJECT_NAME, SERVER_PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde5a792",
   "metadata": {},
   "source": [
    "### 4 - Get DeIdentification Progress\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8904724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "p_bar = tqdm(desc=\"üîÑ DeIdentification Progress\", total=len(run_info[\"task_ids\"]))\n",
    "while True:\n",
    "    deidentification_status = get_deidentification_status(\n",
    "        run_info[\"project_name\"], run_info[\"task_ids\"]\n",
    "    )\n",
    "    total = len(run_info[\"task_ids\"])\n",
    "    running = deidentification_status[\"running\"]\n",
    "\n",
    "    p_bar.n = total - running\n",
    "    p_bar.refresh()\n",
    "\n",
    "    if deidentification_status[\"running\"] == 0:\n",
    "        print(\"üéâ DeIdentification Completed!\")\n",
    "        p_bar.close()\n",
    "        break\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60edc67a-1f26-4168-9e2b-44b97c0ce75d",
   "metadata": {},
   "source": [
    "### 5 - Export De-Identified Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a579a0cb-5f5d-4034-9278-3ffc6b59d92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_deidentified_tasks(DEIDENTIFICATION_PROJECT_NAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
