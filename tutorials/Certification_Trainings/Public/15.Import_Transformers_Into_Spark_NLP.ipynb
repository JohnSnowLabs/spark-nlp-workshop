{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"],"metadata":{"id":"Jjblr56uRTJf"}},{"cell_type":"markdown","metadata":{"id":"2vXYNX2lQROB"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/15.Import_Transformers_Into_Spark_NLP.ipynb)"]},{"cell_type":"markdown","source":["## Import Transformers from HuggingFace ðŸ¤—  into Spark NLP ðŸš€\n","Let's keep in mind that this feature is only in Spark NLP 3.2.x and after. So please make sure you have upgraded to the latest Spark NLP release\n"],"metadata":{"id":"nkays-Ij-wI9"}},{"cell_type":"markdown","metadata":{"id":"MzxB-Nq6cxOA"},"source":["## Export and Save HuggingFace model"]},{"cell_type":"markdown","metadata":{"id":"yNQkhyMHMgkE"},"source":["- Let's install `HuggingFace` and `TensorFlow`. You don't need `TensorFlow` to be installed for Spark NLP, however, we need it to load and save models from HuggingFace.\n","- We lock TensorFlow on `2.11.0` version and Transformers on `4.25.1`. This doesn't mean it won't work with the future releases, but we wanted you to know which versions have been tested successfully."]},{"cell_type":"code","metadata":{"id":"hHXgqiWpMfCY"},"source":["!pip install -q transformers==4.25.1 tensorflow==2.11.0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y3AM6bj4P3NS"},"source":["- HuggingFace comes with a native `saved_model` feature inside `save_pretrained` function for TensorFlow based models. We will use that to save it as TF `SavedModel`.\n","- We'll use [dslim/bert-base-NER](https://huggingface.co/dslim/bert-base-NER) model from HuggingFace as an example\n","- In addition to `TFBertForTokenClassification` we also need to save the `BertTokenizer`. This is the same for every model, these are assets needed for tokenization inside Spark NLP."]},{"cell_type":"code","metadata":{"id":"ZaiirlSKNhVD"},"source":["from transformers import TFBertForTokenClassification, BertTokenizer\n","import tensorflow as tf\n","\n","MODEL_NAME = 'dslim/bert-base-NER'\n","\n","tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n","tokenizer.save_pretrained('./{}_tokenizer/'.format(MODEL_NAME))\n","\n","# just in case if there is no TF/Keras file provided in the model\n","# we can just use `from_pt` and convert PyTorch to TensorFlow\n","try:\n","  print('try downloading TF weights')\n","  model = TFBertForTokenClassification.from_pretrained(MODEL_NAME)\n","except:\n","  print('try downloading PyTorch weights')\n","  model = TFBertForTokenClassification.from_pretrained(MODEL_NAME, from_pt=True)\n","\n","# Define TF Signature\n","@tf.function(\n","  input_signature=[\n","      {\n","          \"input_ids\": tf.TensorSpec((None, None), tf.int32, name=\"input_ids\"),\n","          \"attention_mask\": tf.TensorSpec((None, None), tf.int32, name=\"attention_mask\"),\n","          \"token_type_ids\": tf.TensorSpec((None, None), tf.int32, name=\"token_type_ids\"),\n","      }\n","  ]\n",")\n","def serving_fn(input):\n","    return model(input)\n","\n","model.save_pretrained(\"./{}\".format(MODEL_NAME), saved_model=True, signatures={\"serving_default\": serving_fn})\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nlgyZuJfS5IB"},"source":["Let's have a look inside these two directories and see what we are dealing with:"]},{"cell_type":"code","metadata":{"id":"p2XCole7TTef","executionInfo":{"status":"ok","timestamp":1689020831858,"user_tz":-120,"elapsed":26,"user":{"displayName":"Damla","userId":"03285166568766987047"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e6e3aeca-5699-48b0-9a7c-c20b134df204"},"source":["!ls -l {MODEL_NAME}"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["total 421088\n","-rw-r--r-- 1 root root       999 Jul 10 20:27 config.json\n","drwxr-xr-x 3 root root      4096 Jul 10 20:27 saved_model\n","-rw-r--r-- 1 root root 431179756 Jul 10 20:27 tf_model.h5\n"]}]},{"cell_type":"code","metadata":{"id":"r0DOGz8VUR-r","executionInfo":{"status":"ok","timestamp":1689020831858,"user_tz":-120,"elapsed":16,"user":{"displayName":"Damla","userId":"03285166568766987047"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bb41895c-0bc2-41cd-d464-1ea7eb70edc3"},"source":["!ls -l {MODEL_NAME}/saved_model/1"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["total 9152\n","drwxr-xr-x 2 root root    4096 Jul 10 20:27 assets\n","-rw-r--r-- 1 root root      53 Jul 10 20:27 fingerprint.pb\n","-rw-r--r-- 1 root root  165837 Jul 10 20:27 keras_metadata.pb\n","-rw-r--r-- 1 root root 9190201 Jul 10 20:27 saved_model.pb\n","drwxr-xr-x 2 root root    4096 Jul 10 20:27 variables\n"]}]},{"cell_type":"code","metadata":{"id":"Mcm2UpNxUUQN","executionInfo":{"status":"ok","timestamp":1689020832314,"user_tz":-120,"elapsed":467,"user":{"displayName":"Damla","userId":"03285166568766987047"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9c62631e-2a8c-4859-da28-a9d674402edb"},"source":["!ls -l {MODEL_NAME}_tokenizer"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["total 220\n","-rw-r--r-- 1 root root    125 Jul 10 20:26 special_tokens_map.json\n","-rw-r--r-- 1 root root    551 Jul 10 20:26 tokenizer_config.json\n","-rw-r--r-- 1 root root 213450 Jul 10 20:26 vocab.txt\n"]}]},{"cell_type":"markdown","metadata":{"id":"gZegMvuGTmHt"},"source":["- As you can see, we need the SavedModel from `saved_model/1/` path\n","- We also be needing `vocab.txt` from the tokenizer\n","- All we need is to just copy the `vocab.txt` to `saved_model/1/assets` which Spark NLP will look for\n","- In addition to vocabs, we also need `labels` and their `ids` which is saved inside the model's config. We will save this inside `labels.txt`"]},{"cell_type":"code","metadata":{"id":"ez6MT-RTT7ss","executionInfo":{"status":"ok","timestamp":1689020832315,"user_tz":-120,"elapsed":464,"user":{"displayName":"Damla","userId":"03285166568766987047"}}},"source":["asset_path = '{}/saved_model/1/assets'.format(MODEL_NAME)\n","\n","!cp {MODEL_NAME}_tokenizer/vocab.txt {asset_path}"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"vcg_5YP1-vfC","executionInfo":{"status":"ok","timestamp":1689020832315,"user_tz":-120,"elapsed":14,"user":{"displayName":"Damla","userId":"03285166568766987047"}}},"source":["# get label2id dictionary\n","labels = model.config.label2id\n","# sort the dictionary based on the id\n","labels = sorted(labels, key=labels.get)\n","\n","with open(asset_path+'/labels.txt', 'w') as f:\n","    f.write('\\n'.join(labels))"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mBq7ztzlACYO"},"source":["Voila! We have our `vocab.txt` and `labels.txt` inside assets directory"]},{"cell_type":"code","metadata":{"id":"OYnT5U8N9dxT","executionInfo":{"status":"ok","timestamp":1689020832316,"user_tz":-120,"elapsed":14,"user":{"displayName":"Damla","userId":"03285166568766987047"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e3ce7731-902b-4015-d4f9-6c015238f89e"},"source":["! ls -l {MODEL_NAME}/saved_model/1/assets"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["total 216\n","-rw-r--r-- 1 root root     51 Jul 10 20:27 labels.txt\n","-rw-r--r-- 1 root root 213450 Jul 10 20:27 vocab.txt\n"]}]},{"cell_type":"markdown","metadata":{"id":"NlJKd2tIU0PD"},"source":["## Import and Save BertForTokenClassification in Spark NLP\n"]},{"cell_type":"markdown","metadata":{"id":"A0FXoxHJc5CU"},"source":["- Let's install and setup Spark NLP in Google Colab"]},{"cell_type":"code","source":["! pip install -q pyspark==3.3.0 spark-nlp==5.0.0"],"metadata":{"id":"ZEaBzzZ5jQ4u"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m_NAgx4hdCGP"},"source":["Let's start Spark with Spark NLP included via our simple `start()` function"]},{"cell_type":"code","metadata":{"id":"cbNneAVCLU1y","executionInfo":{"status":"ok","timestamp":1689020916342,"user_tz":-120,"elapsed":43020,"user":{"displayName":"Damla","userId":"03285166568766987047"}}},"source":["import sparknlp\n","\n","spark = sparknlp.start()"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ABTu9MrdVafM"},"source":["- Let's use `loadSavedModel` functon in `BertForTokenClassification` which allows us to load TensorFlow model in SavedModel format\n","- Most params can be set later when you are loading this model in `BertForTokenClassification` in runtime like `setMaxSentenceLength`, so don't worry what you are setting them now\n","- `loadSavedModel` accepts two params, first is the path to the TF SavedModel. The second is the SparkSession that is `spark` variable we previously started via `sparknlp.start()`\n","- NOTE: `loadSavedModel` only accepts local paths and not distributed file systems such as `HDFS`, `S3`, `DBFS`, etc. That is why we use `write.save` so we can use `.load()` from any file systems\n","\n"]},{"cell_type":"code","metadata":{"id":"8W_almibVRTj","executionInfo":{"status":"ok","timestamp":1689020933377,"user_tz":-120,"elapsed":17042,"user":{"displayName":"Damla","userId":"03285166568766987047"}}},"source":["from sparknlp.annotator import *\n","from sparknlp.base import *\n","\n","tokenClassifier = BertForTokenClassification.loadSavedModel(\n","     '{}/saved_model/1'.format(MODEL_NAME),\n","     spark\n"," )\\\n"," .setInputCols([\"document\",'token'])\\\n"," .setOutputCol(\"ner\")\\\n"," .setCaseSensitive(True)\\\n"," .setMaxSentenceLength(128)"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PjGiq4KnXWuy"},"source":["- Let's save it on disk so it is easier to be moved around and also be used later via `.load` function"]},{"cell_type":"code","metadata":{"id":"iWu5HfbnXAlM","executionInfo":{"status":"ok","timestamp":1689020947037,"user_tz":-120,"elapsed":13662,"user":{"displayName":"Damla","userId":"03285166568766987047"}}},"source":["tokenClassifier.write().overwrite().save(\"./{}_spark_nlp\".format(MODEL_NAME))"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QCrjxPhzDplN"},"source":["Let's clean up stuff we don't need anymore"]},{"cell_type":"code","metadata":{"id":"ZgkVIJshDtLx","executionInfo":{"status":"ok","timestamp":1689020947038,"user_tz":-120,"elapsed":4,"user":{"displayName":"Damla","userId":"03285166568766987047"}}},"source":["! rm -rf {MODEL_NAME}_tokenizer {MODEL_NAME}"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["Awesome!\n","\n","This is your BertForTokenClassification model from HuggingFace ðŸ¤—  loaded and saved by Spark NLP ðŸš€"],"metadata":{"id":"zeQt3UFv3vVb"}},{"cell_type":"code","metadata":{"id":"ogpxSWxOXj3W","executionInfo":{"status":"ok","timestamp":1689020947674,"user_tz":-120,"elapsed":638,"user":{"displayName":"Damla","userId":"03285166568766987047"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ca314447-fb96-4323-fe65-510219a5320f"},"source":["! ls -l {MODEL_NAME}_spark_nlp"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["total 429708\n","-rw-r--r-- 1 root root 440007186 Jul 10 20:29 bert_classification_tensorflow\n","drwxr-xr-x 5 root root      4096 Jul 10 20:28 fields\n","drwxr-xr-x 2 root root      4096 Jul 10 20:28 metadata\n"]}]},{"cell_type":"markdown","metadata":{"id":"Fbehje7fYTDj"},"source":["Now let's see how we can use it on other machines, clusters, or any place you wish to use your new and shiny BertForTokenClassification model"]},{"cell_type":"code","metadata":{"id":"1mm3CvkwYRgs","executionInfo":{"status":"ok","timestamp":1689020959299,"user_tz":-120,"elapsed":11627,"user":{"displayName":"Damla","userId":"03285166568766987047"}}},"source":["tokenClassifier_loaded = BertForTokenClassification.load(\"./{}_spark_nlp\".format(MODEL_NAME))\\\n","  .setInputCols([\"document\",'token'])\\\n","  .setOutputCol(\"ner\")"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_he2LDtBYo1h"},"source":["That's it! You can now go wild and use hundreds of `BertForTokenClassification` models from HuggingFace ðŸ¤— in Spark NLP ðŸš€\n"]},{"cell_type":"markdown","metadata":{"id":"BDWNWdBlBpHi"},"source":["You can see what labels were used to train this model via `getClasses` function:"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"pGRTNISyYlnO","executionInfo":{"status":"ok","timestamp":1689020959300,"user_tz":-120,"elapsed":5,"user":{"displayName":"Damla","userId":"03285166568766987047"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0c62b02b-313f-4837-ff45-7c535bdd5ff9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['B-LOC', 'I-ORG', 'I-MISC', 'I-LOC', 'I-PER', 'B-MISC', 'B-ORG', 'O', 'B-PER']"]},"metadata":{},"execution_count":16}],"source":["tokenClassifier_loaded.getClasses()"]},{"cell_type":"markdown","metadata":{"id":"UvRBsP2SBpHi"},"source":["This is how you can use your loaded classifier model in Spark NLP ðŸš€ pipeline:"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"MysnSyi8BpHi","executionInfo":{"status":"ok","timestamp":1689020973863,"user_tz":-120,"elapsed":14566,"user":{"displayName":"Damla","userId":"03285166568766987047"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d5dcff20-1ecb-43fa-f3a6-3b55d61a73c4"},"outputs":[{"output_type":"stream","name":"stdout","text":["+----------------------------------------------------+------------------------------------------------+\n","|text                                                |result                                          |\n","+----------------------------------------------------+------------------------------------------------+\n","|My name is Sarah and I live in London               |[O, O, O, B-PER, O, O, O, O, B-LOC]             |\n","|My name is Clara and I live in Berkeley, California.|[O, O, O, B-PER, O, O, O, O, B-LOC, O, B-LOC, O]|\n","+----------------------------------------------------+------------------------------------------------+\n","\n"]}],"source":["document_assembler = DocumentAssembler() \\\n","    .setInputCol('text') \\\n","    .setOutputCol('document')\n","\n","tokenizer = Tokenizer() \\\n","    .setInputCols(['document']) \\\n","    .setOutputCol('token')\n","\n","pipeline = Pipeline(stages=[\n","    document_assembler,\n","    tokenizer,\n","    tokenClassifier_loaded\n","])\n","\n","# couple of simple examples\n","example = spark.createDataFrame([[\"My name is Sarah and I live in London\"],\n","                                 [\"My name is Clara and I live in Berkeley, California.\"]]).toDF(\"text\")\n","\n","result = pipeline.fit(example).transform(example)\n","\n","# result is a DataFrame\n","result.select(\"text\", \"ner.result\").show(truncate=False)"]}]}