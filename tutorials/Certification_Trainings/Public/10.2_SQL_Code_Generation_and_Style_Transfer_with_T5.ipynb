{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10.2_SQL_Code_Generation_and_Style_Transfer_with_T5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
      ],
      "metadata": {
        "id": "hhMACKisq3rt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/10.2_SQL_Code_Generation_and_Style_Transfer_with_T5.ipynb)"
      ],
      "metadata": {
        "id": "ImQpLSDRqyG8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SQL Code Generation and Style Transfer with T5"
      ],
      "metadata": {
        "id": "uG1Ho98ompoP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Google's T5 is a Sequence to Sequence model that was trained on over 15 different NLP datasets with various problem types, raning from Text Summarization, Question Answering, Translation to various semantical deduction tasks, which enriches T5's ability to map token sequences to semantic vectors which contain more meaning, which T5 leverages to generalize across various tasks and even to never before trained tasks.\n",
        "\n",
        "On top of this, T5 is trained on the standard Word prediction task, which most transformer based models like BERT, GPT, ELMO have been trained on. This gives T5 general knowledge of real world concepts to additionally enhance its understanding."
      ],
      "metadata": {
        "id": "vXVKZGgOqvOD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Colab Setup"
      ],
      "metadata": {
        "id": "GRHZ1bL7nEC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q pyspark==3.2.0 spark-nlp"
      ],
      "metadata": {
        "id": "gCZYK-3FnEY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sparknlp\n",
        "spark = sparknlp.start(spark32=True)\n",
        "\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "from pyspark.ml import Pipeline\n",
        "import pandas as pd\n",
        "\n",
        "print(\"Spark NLP version\", sparknlp.version())\n",
        "print(\"Apache Spark version:\", spark.version)\n",
        "\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "BbrKqGQWnGlv",
        "outputId": "348eceb6-6fa6-4194-ea4d-f87324175d38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP version 3.4.0\n",
            "Apache Spark version: 3.2.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://c8b437f0da14:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark NLP</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f5637f39290>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# T5-small fine-tuned on WikiSQL\n",
        "\n",
        "Google’s T5 small fine-tuned on WikiSQL for English to SQL translation. Will generate SQL code from natural language input when task is set it to “translate English to SQL:”."
      ],
      "metadata": {
        "id": "L9ABwLmCnVNF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documentAssembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"text\") \\\n",
        "    .setOutputCol(\"documents\")\n",
        "\n",
        "t5 = T5Transformer.pretrained(\"t5_small_wikiSQL\") \\\n",
        "    .setTask(\"translate English to SQL:\") \\\n",
        "    .setInputCols([\"documents\"]) \\\n",
        "    .setMaxOutputLength(200) \\\n",
        "    .setOutputCol(\"sql\")\n",
        "\n",
        "pipeline = Pipeline().setStages([documentAssembler, t5])\n",
        "\n",
        "data = spark.createDataFrame([[\"How many customers have ordered more than 2 items?\"]]).toDF(\"text\")\n",
        "\n",
        "result = pipeline.fit(data).transform(data)\n",
        "\n",
        "result.select(\"sql.result\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Z3rAgd6nHue",
        "outputId": "96ecae20-d342-4243-f1fb-344276766d53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t5_small_wikiSQL download started this may take some time.\n",
            "Approximate size to download 249.9 MB\n",
            "[OK!]\n",
            "+----------------------------------------------------+\n",
            "|result                                              |\n",
            "+----------------------------------------------------+\n",
            "|[SELECT COUNT Customers FROM table WHERE Orders > 2]|\n",
            "+----------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Warning** \n",
        "The next models are quite large and they will not all fit into the same Spark/Colab session. You will have to **restart your Colab session** in between running the models or you will encounter errors."
      ],
      "metadata": {
        "id": "Nn20JI9gmWPo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# T5 for Active to Passive Style Transfer\n",
        "\n",
        "This is a text-to-text model based on T5 fine-tuned to generate actively written text from a passively written text input, for the task “transfer Active to Passive:”. It is based on Prithiviraj Damodaran’s Styleformer."
      ],
      "metadata": {
        "id": "rlcgoyAdoFqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documentAssembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"text\") \\\n",
        "    .setOutputCol(\"documents\")\n",
        "\n",
        "t5 = T5Transformer.pretrained(\"t5_active_to_passive_styletransfer\") \\\n",
        "    .setTask(\"transfer Active to Passive:\") \\\n",
        "    .setInputCols([\"documents\"]) \\\n",
        "    .setMaxOutputLength(200) \\\n",
        "    .setOutputCol(\"transfers\")\n",
        "\n",
        "pipeline = Pipeline().setStages([documentAssembler, t5])\n",
        "\n",
        "data = spark.createDataFrame([[\"I am writing you a letter.\"]]).toDF(\"text\")\n",
        "\n",
        "result = pipeline.fit(data).transform(data)\n",
        "\n",
        "result.select(\"transfers.result\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aUBO_48nHpn",
        "outputId": "98d2d6d1-9c41-4f18-ffba-551ce8dd56c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t5_active_to_passive_styletransfer download started this may take some time.\n",
            "Approximate size to download 252.3 MB\n",
            "[OK!]\n",
            "+---------------------------+\n",
            "|result                     |\n",
            "+---------------------------+\n",
            "|[a letter is written by me]|\n",
            "+---------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# T5 for Passive to Active Style Transfer\n",
        "\n",
        "This is a text-to-text model based on T5 fine-tuned to generate passively written text from a actively written text input, for the task “transfer Passive to Active:”. It is based on Prithiviraj Damodaran’s Styleformer."
      ],
      "metadata": {
        "id": "B5C0Bn17o3Kz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documentAssembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"text\") \\\n",
        "    .setOutputCol(\"documents\")\n",
        "\n",
        "t5 = T5Transformer.pretrained(\"t5_passive_to_active_styletransfer\") \\\n",
        "    .setTask(\"transfer Passive to Active:\") \\\n",
        "    .setInputCols([\"documents\"]) \\\n",
        "    .setMaxOutputLength(200) \\\n",
        "    .setOutputCol(\"transfers\")\n",
        "\n",
        "pipeline = Pipeline().setStages([documentAssembler, t5])\n",
        "\n",
        "data = spark.createDataFrame([[\"A letter was sent to you.\"]]).toDF(\"text\")\n",
        "\n",
        "result = pipeline.fit(data).transform(data)\n",
        "\n",
        "result.select(\"transfers.result\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEroTgL6o6Jj",
        "outputId": "8ba4942a-c8f0-4a4e-df7a-adcc8ca34cb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t5_passive_to_active_styletransfer download started this may take some time.\n",
            "Approximate size to download 252.8 MB\n",
            "[OK!]\n",
            "+-------------------+\n",
            "|result             |\n",
            "+-------------------+\n",
            "|[you sent a letter]|\n",
            "+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# T5 for Formal to Informal Style Transfer\n",
        "\n",
        "This is a text-to-text model based on T5 fine-tuned to generate informal text from a formal text input, for the task “transfer Formal to Casual:”. It is based on Prithiviraj Damodaran’s Styleformer."
      ],
      "metadata": {
        "id": "7A6W6L_oodRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documentAssembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"text\") \\\n",
        "    .setOutputCol(\"documents\")\n",
        "\n",
        "t5 = T5Transformer.pretrained(\"t5_formal_to_informal_styletransfer\") \\\n",
        "    .setTask(\"transfer Formal to Casual:\") \\\n",
        "    .setInputCols([\"documents\"]) \\\n",
        "    .setMaxOutputLength(200) \\\n",
        "    .setOutputCol(\"transfers\")\n",
        "\n",
        "pipeline = Pipeline().setStages([documentAssembler, t5])\n",
        "\n",
        "data = spark.createDataFrame([[\"Please leave the room now.\"]]).toDF(\"text\")\n",
        "\n",
        "result = pipeline.fit(data).transform(data)\n",
        "\n",
        "result.select(\"transfers.result\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjsyOC2SnHlM",
        "outputId": "fcc667a7-7cb1-4b2b-8451-9c12301330ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t5_formal_to_informal_styletransfer download started this may take some time.\n",
            "Approximate size to download 881.1 MB\n",
            "[OK!]\n",
            "+---------------------+\n",
            "|result               |\n",
            "+---------------------+\n",
            "|[leave the room now.]|\n",
            "+---------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# T5 for Informal to Formal Style Transfer\n",
        "\n",
        "This is a text-to-text model based on T5 fine-tuned to generate informal text from a formal text input, for the task “transfer Casual to Formal:”. It is based on Prithiviraj Damodaran’s Styleformer."
      ],
      "metadata": {
        "id": "EluF-OV7or9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documentAssembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"text\") \\\n",
        "    .setOutputCol(\"documents\")\n",
        "\n",
        "t5 = T5Transformer.pretrained(\"t5_informal_to_formal_styletransfer\") \\\n",
        "    .setTask(\"transfer Casual to Formal:\") \\\n",
        "    .setInputCols([\"documents\"]) \\\n",
        "    .setMaxOutputLength(200) \\\n",
        "    .setOutputCol(\"transfers\")\n",
        "\n",
        "pipeline = Pipeline().setStages([documentAssembler, t5])\n",
        "\n",
        "data = spark.createDataFrame([[\"Who gives a crap?\"]]).toDF(\"text\")\n",
        "\n",
        "result = pipeline.fit(data).transform(data)\n",
        "\n",
        "result.select(\"transfers.result\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rUPy23TnHcW",
        "outputId": "a1646ff7-79f7-41b6-9ec1-8f650d556ce9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t5_informal_to_formal_styletransfer download started this may take some time.\n",
            "Approximate size to download 881.2 MB\n",
            "[OK!]\n",
            "+------------+\n",
            "|result      |\n",
            "+------------+\n",
            "|[Who cares?]|\n",
            "+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Overview of every task available with T5\n",
        "[The T5 model](https://arxiv.org/pdf/1910.10683.pdf) is trained on various datasets for 17 different tasks which fall into 8 categories.\n",
        "\n",
        "\n",
        "\n",
        "1. Text summarization\n",
        "2. Question answering\n",
        "3. Translation\n",
        "4. Sentiment analysis\n",
        "5. Natural Language inference\n",
        "6. Coreference resolution\n",
        "7. Sentence Completion\n",
        "8. Word sense disambiguation\n",
        "\n",
        "### Every T5 Task with explanation:\n",
        "|Task Name | Explanation | \n",
        "|----------|--------------|\n",
        "|[1.CoLA](https://nyu-mll.github.io/CoLA/)                   | Classify if a sentence is gramaticaly correct|\n",
        "|[2.RTE](https://dl.acm.org/doi/10.1007/11736790_9)                    | Classify whether if a statement can be deducted from a sentence|\n",
        "|[3.MNLI](https://arxiv.org/abs/1704.05426)                   | Classify for a hypothesis and premise whether they contradict or contradict each other or neither of both (3 class).|\n",
        "|[4.MRPC](https://www.aclweb.org/anthology/I05-5002.pdf)                   | Classify whether a pair of sentences is a re-phrasing of each other (semantically equivalent)|\n",
        "|[5.QNLI](https://arxiv.org/pdf/1804.07461.pdf)                   | Classify whether the answer to a question can be deducted from an answer candidate.|\n",
        "|[6.QQP](https://www.quora.com/q/quoradata/First-Quora-Dataset-Release-Question-Pairs)                    | Classify whether a pair of questions is a re-phrasing of each other (semantically equivalent)|\n",
        "|[7.SST2](https://www.aclweb.org/anthology/D13-1170.pdf)                   | Classify the sentiment of a sentence as positive or negative|\n",
        "|[8.STSB](https://www.aclweb.org/anthology/S17-2001/)                   | Classify the sentiment of a sentence on a scale from 1 to 5 (21 Sentiment classes)|\n",
        "|[9.CB](https://ojs.ub.uni-konstanz.de/sub/index.php/sub/article/view/601)                     | Classify for a premise and a hypothesis whether they contradict each other or not (binary).|\n",
        "|[10.COPA](https://www.aaai.org/ocs/index.php/SSS/SSS11/paper/view/2418/0)                   | Classify for a question, premise, and 2 choices which choice the correct choice is (binary).|\n",
        "|[11.MultiRc](https://www.aclweb.org/anthology/N18-1023.pdf)                | Classify for a question, a paragraph of text, and an answer candidate, if the answer is correct (binary),|\n",
        "|[12.WiC](https://arxiv.org/abs/1808.09121)                    | Classify for a pair of sentences and a disambigous word if the word has the same meaning in both sentences.|\n",
        "|[13.WSC/DPR](https://www.aaai.org/ocs/index.php/KR/KR12/paper/view/4492/0)       | Predict for an ambiguous pronoun in a sentence what it is referring to.  |\n",
        "|[14.Summarization](https://arxiv.org/abs/1506.03340)          | Summarize text into a shorter representation.|\n",
        "|[15.SQuAD](https://arxiv.org/abs/1606.05250)                  | Answer a question for a given context.|\n",
        "|[16.WMT1.](https://arxiv.org/abs/1706.03762)                  | Translate English to German|\n",
        "|[17.WMT2.](https://arxiv.org/abs/1706.03762)                   | Translate English to French|\n",
        "|[18.WMT3.](https://arxiv.org/abs/1706.03762)                   | Translate English to Romanian|\n",
        "\n"
      ],
      "metadata": {
        "id": "yK47Q_berZcQ"
      }
    }
  ]
}