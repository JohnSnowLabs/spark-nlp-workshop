{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6.Playground_DataFrames.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXatvRX899i0"
      },
      "source": [
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lt-CiWRewNWD"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop//blob/master/tutorials/Certification_Trainings/Public/6.Playground_DataFrames.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Alh8i-_fJ59"
      },
      "source": [
        "# Spark DataFrames Playground"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJ0MnF3bfWbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cee116a4-e767-4059-8d2c-16406a9423b8"
      },
      "source": [
        "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash\n",
        "# !bash colab.sh\n",
        "# by default they are set to the latest\n",
        "# -p is for pyspark\n",
        "# -s is for spark-nlp\n",
        "# setup colab with a specific version:\n",
        "# !bash colab.sh -p 3.0.2 -s 3.0.1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-14 03:54:39--  http://setup.johnsnowlabs.com/colab.sh\n",
            "Resolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 51.158.130.26\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.26|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh [following]\n",
            "--2021-04-14 03:54:40--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1594 (1.6K) [text/plain]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                   100%[===================>]   1.56K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-04-14 03:54:40 (42.2 MB/s) - written to stdout [1594/1594]\n",
            "\n",
            "setup Colab for PySpark 3.0.2 and Spark NLP 3.0.1\n",
            "\u001b[K     |████████████████████████████████| 204.8MB 70kB/s \n",
            "\u001b[K     |████████████████████████████████| 153kB 54.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 25.4MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZucC6lQ2pYQ"
      },
      "source": [
        "\n",
        "<b>  if you want to work with Spark 2.3 </b>\n",
        "```\n",
        "import os\n",
        "\n",
        "# Install java\n",
        "! apt-get update -qq\n",
        "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-2.3.0/spark-2.3.0-bin-hadoop2.7.tgz\n",
        "\n",
        "!tar xf spark-2.3.0-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.3.0-bin-hadoop2.7\"\n",
        "! java -version\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "! pip install --ignore-installed -q spark-nlp==2.7.5\n",
        "\n",
        "import sparknlp\n",
        "\n",
        "spark = sparknlp.start(spark23=True)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4wDHHvKfHyO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "outputId": "25c38008-d96d-4be1-e8fd-cef05ceefffc"
      },
      "source": [
        "import sparknlp\n",
        "\n",
        "spark = sparknlp.start()\n",
        "\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "print(\"Spark NLP version\", sparknlp.version())\n",
        "\n",
        "print(\"Apache Spark version:\", spark.version)\n",
        "\n",
        "spark"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spark NLP version 3.0.1\n",
            "Apache Spark version: 3.0.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://b089e5b37d78:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.0.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark NLP</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f22a555b310>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xi7g0dR4fDhD"
      },
      "source": [
        "spark = sparknlp.start()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLulYEvRfDhG"
      },
      "source": [
        "document = DocumentAssembler().setInputCol('text').setOutputCol('document')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLfu1NU_fDhJ"
      },
      "source": [
        "tokenizer = Tokenizer().setInputCols('document').setOutputCol('token')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxZ9s3YCfDhM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08ba60b1-16af-4bc5-b99c-40d022784ff9"
      },
      "source": [
        "pos = PerceptronModel.pretrained().setInputCols('document', 'token').setOutputCol('pos')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pos_anc download started this may take some time.\n",
            "Approximate size to download 3.9 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cI-uo9ZbfDhR"
      },
      "source": [
        "pipeline = Pipeline().setStages([document, tokenizer, pos])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJoifWwRfjrG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ca7041a-fe10-40ff-e8c4-8233eb6ffc4c"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/jupyter/annotation/english/spark-nlp-basics/sample-sentences-en.txt"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-14 04:01:13--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/jupyter/annotation/english/spark-nlp-basics/sample-sentences-en.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 284 [text/plain]\n",
            "Saving to: ‘sample-sentences-en.txt’\n",
            "\n",
            "sample-sentences-en 100%[===================>]     284  --.-KB/s    in 0s      \n",
            "\n",
            "2021-04-14 04:01:14 (17.1 MB/s) - ‘sample-sentences-en.txt’ saved [284/284]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGksf1hCfDhU"
      },
      "source": [
        "data = spark.read.text('./sample-sentences-en.txt').toDF('text')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgTNu0_KfDhX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07f72a98-5884-484b-82ad-c237761ed73d"
      },
      "source": [
        "data.show(5)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+\n",
            "|                text|\n",
            "+--------------------+\n",
            "|Peter is a very g...|\n",
            "|My life in Russia...|\n",
            "|John and Peter ar...|\n",
            "|Lucas Nogal Dunbe...|\n",
            "|Europe is very cu...|\n",
            "+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAnijYcYfDhb"
      },
      "source": [
        "model = pipeline.fit(data)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_fTTzUPfDhd"
      },
      "source": [
        "result = model.transform(data)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ll7rPvWefDhg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04a8333b-d991-4eff-d3fa-1e143efec957"
      },
      "source": [
        "result.show(5)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "|                text|            document|               token|                 pos|\n",
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "|Peter is a very g...|[[document, 0, 27...|[[token, 0, 4, Pe...|[[pos, 0, 4, NNP,...|\n",
            "|My life in Russia...|[[document, 0, 37...|[[token, 0, 1, My...|[[pos, 0, 1, PRP$...|\n",
            "|John and Peter ar...|[[document, 0, 76...|[[token, 0, 3, Jo...|[[pos, 0, 3, NNP,...|\n",
            "|Lucas Nogal Dunbe...|[[document, 0, 67...|[[token, 0, 4, Lu...|[[pos, 0, 4, NNP,...|\n",
            "|Europe is very cu...|[[document, 0, 68...|[[token, 0, 5, Eu...|[[pos, 0, 5, NNP,...|\n",
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i06WW8wzfDhk"
      },
      "source": [
        "stored = result\\\n",
        "  .select('text', 'pos.begin', 'pos.end', 'pos.result', 'pos.metadata')\\\n",
        "  .toDF('text', 'pos_begin', 'pos_end', 'pos_result', 'pos_meta')\\\n",
        "  .cache()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBQWLPjzfDhp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cd5e209-3a46-4f3b-eaa8-ab25c10528b4"
      },
      "source": [
        "stored.printSchema()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- text: string (nullable = true)\n",
            " |-- pos_begin: array (nullable = true)\n",
            " |    |-- element: integer (containsNull = true)\n",
            " |-- pos_end: array (nullable = true)\n",
            " |    |-- element: integer (containsNull = true)\n",
            " |-- pos_result: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- pos_meta: array (nullable = true)\n",
            " |    |-- element: map (containsNull = true)\n",
            " |    |    |-- key: string\n",
            " |    |    |-- value: string (valueContainsNull = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X93ASKmGfDhw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "790e9a03-480d-4b5f-cb62-0a14481b112a"
      },
      "source": [
        "stored.show(5)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                text|           pos_begin|             pos_end|          pos_result|            pos_meta|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|Peter is a very g...|[0, 6, 9, 11, 16,...|[4, 7, 9, 14, 19,...|[NNP, VBZ, DT, RB...|[[word -> Peter],...|\n",
            "|My life in Russia...|[0, 3, 8, 11, 18,...|[1, 6, 9, 16, 19,...|[PRP$, NN, IN, NN...|[[word -> My], [w...|\n",
            "|John and Peter ar...|[0, 5, 9, 15, 19,...|[3, 7, 13, 17, 26...|[NNP, CC, NNP, VB...|[[word -> John], ...|\n",
            "|Lucas Nogal Dunbe...|[0, 6, 12, 23, 26...|[4, 10, 21, 24, 2...|[NNP, NNP, NNP, V...|[[word -> Lucas],...|\n",
            "|Europe is very cu...|[0, 7, 10, 15, 23...|[5, 8, 13, 21, 26...|[NNP, VBZ, RB, RB...|[[word -> Europe]...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rI8rO1GjfDhz"
      },
      "source": [
        "---------\n",
        "## Spark SQL Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5c5OVnNafDh0"
      },
      "source": [
        "from pyspark.sql.functions import *"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_nWknqlfDh3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "765152dc-5308-43e5-964d-884248312fac"
      },
      "source": [
        "stored.filter(array_contains('pos_result', 'VBD')).show(5)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----+---------+-------+----------+--------+\n",
            "|text|pos_begin|pos_end|pos_result|pos_meta|\n",
            "+----+---------+-------+----------+--------+\n",
            "+----+---------+-------+----------+--------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwBH_f-1fDh7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44de1887-b20a-4747-b5cf-11952b2b0f7d"
      },
      "source": [
        "stored.withColumn('token_count', size('pos_result')).select('pos_result', 'token_count').show(5)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+-----------+\n",
            "|          pos_result|token_count|\n",
            "+--------------------+-----------+\n",
            "|[NNP, VBZ, DT, RB...|          7|\n",
            "|[PRP$, NN, IN, NN...|          8|\n",
            "|[NNP, CC, NNP, VB...|         15|\n",
            "|[NNP, NNP, NNP, V...|         15|\n",
            "|[NNP, VBZ, RB, RB...|         15|\n",
            "+--------------------+-----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZn-kEFifDh_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb4a07c1-1783-42a0-966d-7c83538b5e65"
      },
      "source": [
        "stored.select('text', array_max('pos_end')).show(5)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+------------------+\n",
            "|                text|array_max(pos_end)|\n",
            "+--------------------+------------------+\n",
            "|Peter is a very g...|                27|\n",
            "|My life in Russia...|                37|\n",
            "|John and Peter ar...|                76|\n",
            "|Lucas Nogal Dunbe...|                67|\n",
            "|Europe is very cu...|                68|\n",
            "+--------------------+------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfzcYDcFfDiC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9408f02-c5a6-4f83-d201-949c9546bfd9"
      },
      "source": [
        "stored.withColumn('unique_pos', array_distinct('pos_result')).select('pos_result', 'unique_pos').show(5)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+\n",
            "|          pos_result|          unique_pos|\n",
            "+--------------------+--------------------+\n",
            "|[NNP, VBZ, DT, RB...|[NNP, VBZ, DT, RB...|\n",
            "|[PRP$, NN, IN, NN...|[PRP$, NN, IN, NN...|\n",
            "|[NNP, CC, NNP, VB...|[NNP, CC, VBP, NN...|\n",
            "|[NNP, NNP, NNP, V...|[NNP, VBZ, DT, RB...|\n",
            "|[NNP, VBZ, RB, RB...|[NNP, VBZ, RB, JJ...|\n",
            "+--------------------+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9k5hwUSfDiE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b52e3ac-0dbe-4619-d174-e02c9dc9af58"
      },
      "source": [
        "stored.groupBy(array_distinct('pos_result')).count().show(10)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------------+-----+\n",
            "|array_distinct(pos_result)|count|\n",
            "+--------------------------+-----+\n",
            "|      [NNP, CC, VBP, NN...|    1|\n",
            "|      [NNP, VBZ, DT, RB...|    1|\n",
            "|      [NNP, VBZ, RB, JJ...|    1|\n",
            "|      [PRP$, NN, IN, NN...|    1|\n",
            "|      [NNP, VBZ, DT, RB...|    1|\n",
            "+--------------------------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5O_ERu47fDiI"
      },
      "source": [
        "----------------\n",
        "### SQL Functions with `col`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BP2dz_BqfDiJ"
      },
      "source": [
        "from pyspark.sql.functions import col"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9a1KaVEfDiM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99ca2dde-ebf5-4cb4-c952-88b665bba14d"
      },
      "source": [
        "stored.select(col('pos_meta').getItem(0).getItem('word')).show(5)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------+\n",
            "|pos_meta[0][word]|\n",
            "+-----------------+\n",
            "|            Peter|\n",
            "|               My|\n",
            "|             John|\n",
            "|            Lucas|\n",
            "|           Europe|\n",
            "+-----------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0TtaUgUfDiP"
      },
      "source": [
        "-------------\n",
        "### Spark NLP Annotation UDFs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Psqxd7eWfDiQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75d81a25-a090-4f19-88a6-bc492b90d72d"
      },
      "source": [
        "result.select('pos').show(1, truncate=False)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|pos                                                                                                                                                                                                                                                                    |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|[[pos, 0, 4, NNP, [word -> Peter], []], [pos, 6, 7, VBZ, [word -> is], []], [pos, 9, 9, DT, [word -> a], []], [pos, 11, 14, RB, [word -> very], []], [pos, 16, 19, JJ, [word -> good], []], [pos, 21, 26, NN, [word -> person], []], [pos, 27, 27, ., [word -> .], []]]|\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 1 row\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miYDmJiSfDiU"
      },
      "source": [
        "def nn_tokens(annotations):\n",
        "    nn_annotations = list(\n",
        "        filter(lambda annotation: annotation.result == 'NN', annotations)\n",
        "    )\n",
        "    return list(\n",
        "        map(lambda nn_annotation: nn_annotation.metadata['word'], nn_annotations)\n",
        "    )"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsJDj_bjfDiX"
      },
      "source": [
        "from sparknlp.functions import *"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeYfUAbXfDid"
      },
      "source": [
        "from pyspark.sql.types import ArrayType, StringType"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMdSUHW-fDig",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e7413bf-263c-43e2-a530-8f043992ecf7"
      },
      "source": [
        "result.select(map_annotations(nn_tokens, ArrayType(StringType()))('pos').alias('nn_tokens')).show(truncate=False)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+\n",
            "|nn_tokens|\n",
            "+---------+\n",
            "|[person] |\n",
            "|[life]   |\n",
            "|[]       |\n",
            "|[car]    |\n",
            "|[]       |\n",
            "+---------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
