{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"16.GPT2_Transformer_In_Spark_NLP.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"],"metadata":{"id":"6sBtVqUvZTQB"}},{"cell_type":"markdown","source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/16.GPT2_Transformer_In_Spark_NLP.ipynb)"],"metadata":{"id":"67YDMg3GZTCQ"}},{"cell_type":"markdown","source":["# GPT2Transformer: OpenAI Text-To-Text Transformer"],"metadata":{"id":"l9cW8XItZlyD"}},{"cell_type":"markdown","source":["GPT-2 displays a broad set of capabilities, including the ability to generate conditional synthetic text samples of unprecedented quality, where the model is primed with an input and it generates a lengthy continuation.\n","\n","Pretrained models can be loaded with `pretrained()` of the companion object:"],"metadata":{"id":"YaXRil_iZu41"}},{"cell_type":"markdown","source":["## Colab Setup"],"metadata":{"id":"JiF9XgzIcJaA"}},{"cell_type":"code","source":["! pip install -q pyspark==3.3.0 spark-nlp==4.0.1"],"metadata":{"id":"nQdPMraEcJ1K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import sparknlp\n","\n","from sparknlp.base import *\n","from sparknlp.annotator import *\n","\n","from pyspark.sql import SparkSession\n","from pyspark.sql import functions as F\n","from pyspark.ml import Pipeline,PipelineModel\n","\n","spark = sparknlp.start()\n","\n","print(\"Spark NLP version\", sparknlp.version())\n","print(\"Apache Spark version:\", spark.version)\n","\n","spark"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":258},"id":"4dun3ggxcLzd","outputId":"ee62179b-6cea-4668-a58f-0cc64fd2cf67","executionInfo":{"status":"ok","timestamp":1657020797199,"user_tz":-180,"elapsed":54134,"user":{"displayName":"Monster C","userId":"08787989274818793476"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Spark NLP version 4.0.1\n","Apache Spark version: 3.3.0\n"]},{"output_type":"execute_result","data":{"text/plain":["<pyspark.sql.session.SparkSession at 0x7feca10e1510>"],"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://ec46047fbe02:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.3.0</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>Spark NLP</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["**GPT2 Models In Spark NLP**\n","\n","*   `gpt2`\n","*   `gpt2_medium`\n","*   `gpt2_distilled`\n","*   `gpt2_large`\n","\n","The default model is `\"gpt2\"`, if no name is provided. For available pretrained models please see the [Spark NLP Models Hub](https://nlp.johnsnowlabs.com/models?q=gpt2)\n","\n"],"metadata":{"id":"_FKVL06rdMpV"}},{"cell_type":"markdown","source":["## GPT2 Pipeline "],"metadata":{"id":"7-Un073ccDYi"}},{"cell_type":"markdown","source":["Now, let's create a Spark NLP Pipeline with `gpt2_medium` model and check the results."],"metadata":{"id":"MR8j4syuq-Nr"}},{"cell_type":"code","source":["documentAssembler = DocumentAssembler() \\\n","    .setInputCol(\"text\") \\\n","    .setOutputCol(\"documents\")\n","    \n","gpt2 = GPT2Transformer.pretrained(\"gpt2_medium\") \\\n","    .setInputCols([\"documents\"]) \\\n","    .setMaxOutputLength(50) \\\n","    .setMinOutputLength(25) \\\n","    .setOutputCol(\"generation\")\n","    \n","pipeline = Pipeline().setStages([documentAssembler,\n","                                 gpt2])\n","\n","data = spark.createDataFrame([[\"My name is Leonardo.\"]]).toDF(\"text\")\n","result = pipeline.fit(data).transform(data)\n","result.select(\"generation.result\").show(truncate=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IfRKHG-AumPo","outputId":"d957fd76-bd44-4324-ad70-dce8eb44dc89","executionInfo":{"status":"ok","timestamp":1657021244329,"user_tz":-180,"elapsed":188454,"user":{"displayName":"Monster C","userId":"08787989274818793476"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["gpt2_medium download started this may take some time.\n","Approximate size to download 1.2 GB\n","[OK!]\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|result                                                                                                                                                                                                                                           |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|[ My name is Leonardo. I'm a student at the University of California, Berkeley. I've been studying computer science for the past two years. I have a PhD in computer science from the University, and I'm currently working on a PhD at the same]|\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","\n"]}]},{"cell_type":"markdown","source":["We can display the documentation of all params with their optionally default values and user-supplied values by `explainParams()` function"],"metadata":{"id":"kreh6RHjs-lE"}},{"cell_type":"code","source":["gpt2.explainParams()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":127},"id":"DpBQuEwEsy3U","outputId":"e15fdbed-1360-49f8-b77a-b442eedf33cc","executionInfo":{"status":"ok","timestamp":1657021523345,"user_tz":-180,"elapsed":610,"user":{"displayName":"Monster C","userId":"08787989274818793476"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"batchSize: Size of every batch (default: 4)\\nconfigProtoBytes: ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString() (undefined)\\ndoSample: Whether or not to use sampling; use greedy decoding otherwise (default: False, current: False)\\nignoreTokenIds: A list of token ids which are ignored in the decoder's output (default: [])\\ninputCols: previous annotations columns, if renamed (current: ['documents'])\\nlazyAnnotator: Whether this AnnotatorModel acts as lazy in RecursivePipelines (default: False)\\nmaxOutputLength: Maximum length of output text (default: 20, current: 50)\\nminOutputLength: Minimum length of the sequence to be generated (default: 0, current: 25)\\nnoRepeatNgramSize: If set to int > 0, all ngrams of that size can only occur once (default: 0, current: 3)\\noutputCol: output annotation column. can be left default. (current: generation)\\nrepetitionPenalty: The parameter for repetition penalty. 1.0 means no penalty. See `this paper <https://arxiv.org/pdf/1909.05858.pdf>`__ for more details (default: 1.0)\\ntask: Transformer's task, e.g. 'is it true that'> (default: )\\ntemperature: The value used to module the next token probabilities (default: 1.0)\\ntopK: The number of highest probability vocabulary tokens to keep for top-k-filtering (default: 50, current: 50)\\ntopP: If set to float < 1, only the most probable tokens with probabilities that add up to ``top_p`` or higher are kept for generation (default: 1.0)\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["Let's use model with more sentences and set `.setDoSample()` parameter as True, this parameter is used for whether or not to use sampling; use greedy decoding otherwise, by default False. <br/>\n","Also, we use `.setTopK()` parameter for the number of highest probability vocabulary tokens to keep for top-k-filtering, by default 50."],"metadata":{"id":"sVXRNJFPEcgq"}},{"cell_type":"code","source":["sample_texts= [[1, \"Mey name is Leonardo\"], \n","               [2, \"My name is Leonardo and I come from Rome.\"],\n","               [3, \"My name is\"], \n","               [4, \"What is the difference between diesel and petrol?\"]]\n","\n","sample_df= spark.createDataFrame(sample_texts).toDF(\"id\", \"text\")"],"metadata":{"id":"aMAsyNfPh3Fs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["documentAssembler = DocumentAssembler() \\\n","    .setInputCol(\"text\") \\\n","    .setOutputCol(\"documents\")\n","    \n","gpt2 = GPT2Transformer.pretrained(\"gpt2_medium\") \\\n","        .setInputCols([\"documents\"]) \\\n","        .setMaxOutputLength(50) \\\n","        .setMinOutputLength(25) \\\n","        .setDoSample(True)\\\n","        .setTopK(20)\\\n","        .setOutputCol(\"generation\")\n","\n","pipeline = Pipeline().setStages([documentAssembler,\n","                                 gpt2])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z5guR3Bx_khw","outputId":"112a5f79-2a34-4547-8e69-bd89a4a9cc39","executionInfo":{"status":"ok","timestamp":1657021534010,"user_tz":-180,"elapsed":4574,"user":{"displayName":"Monster C","userId":"08787989274818793476"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["gpt2_medium download started this may take some time.\n","Approximate size to download 1.2 GB\n","[OK!]\n"]}]},{"cell_type":"code","source":["result = pipeline.fit(sample_df).transform(sample_df)"],"metadata":{"id":"s42EODmku4TZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result.show()"],"metadata":{"id":"fNi7lUxYvPWF","executionInfo":{"status":"ok","timestamp":1657021652112,"user_tz":-180,"elapsed":112228,"user":{"displayName":"Monster C","userId":"08787989274818793476"}},"outputId":"3e451766-5fe5-4a80-cc4e-4458c5d345e9","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+--------------------+--------------------+--------------------+\n","| id|                text|           documents|          generation|\n","+---+--------------------+--------------------+--------------------+\n","|  1|Mey name is Leonardo|[{document, 0, 19...|[{document, 0, 21...|\n","|  2|My name is Leonar...|[{document, 0, 40...|[{document, 0, 21...|\n","|  3|          My name is|[{document, 0, 9,...|[{document, 0, 16...|\n","|  4|What is the diffe...|[{document, 0, 48...|[{document, 0, 25...|\n","+---+--------------------+--------------------+--------------------+\n","\n"]}]},{"cell_type":"code","source":["result = pipeline.fit(sample_df).transform(sample_df)\n","result.select(\"id\", \"generation.result\").show(truncate=False)"],"metadata":{"id":"DBxs5-os_zak","executionInfo":{"status":"ok","timestamp":1657021759089,"user_tz":-180,"elapsed":106981,"user":{"displayName":"Monster C","userId":"08787989274818793476"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0e9de17f-8d5a-4509-fed9-a08370cf72ab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|id |result                                                                                                                                                                                                                                                         |\n","+---+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|1  |[ Mey name is Leonardo Mey (1901-1994), a well-known designer of the \"Borgia\" and other Italian cars. He was born in Milan and went to the Imperial Academy of Art (Milan) in 1894.]                                                                           |\n","|2  |[ My name is Leonardo and I come from Rome. If someone says that I'm gay, my reply is always, \"No, I'm not!\"\\nThere was a time when I felt like I'd had my heart broken. I'd heard that men]                                                                   |\n","|3  |[ My name is Chris Hahn. This is the first article I've written where I'm not in the office and doing an interview. It's pretty cool, but not exactly what I'm looking for. I'm still working on an interview with my girlfriend]                              |\n","|4  |[ What is the difference between diesel and petrol? What are those different fuels?\\n\\nThis section presents the most widely held and popular explanations of each.\\n\\nDiesel: What's the Difference\\n\\nThe term diesel was introduced in the United States in]|\n","+---+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","\n"]}]},{"cell_type":"markdown","source":["### Changing the Transformer's task"],"metadata":{"id":"JbOQyj-DAHi7"}},{"cell_type":"markdown","source":["Now, we change the task of Transformer. We can verify some informations to GPT-2 by setting `.setTask()` parameter as **\"Is it true that\"**. <br/>\n","We give a text to the model by setting `setTask(\"Is it true that\")` and model adds the \"Is it true that\" expression at the beginning of the sentence and generates sentences."],"metadata":{"id":"010b5pPvFAEU"}},{"cell_type":"code","source":[" gpt2 = GPT2Transformer.pretrained(\"gpt2_medium\")\\\n","          .setTask(\"Is it true that\")\\\n","          .setInputCols([\"documents\"])\\\n","          .setMaxOutputLength(50)\\\n","          .setOutputCol(\"generation\")\n","\n","pipeline = Pipeline().setStages([documentAssembler,\n","                                 gpt2])"],"metadata":{"id":"sTjeFAh5UIMV","executionInfo":{"status":"ok","timestamp":1657021870597,"user_tz":-180,"elapsed":4875,"user":{"displayName":"Monster C","userId":"08787989274818793476"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"11cc6271-9b8a-4425-bc21-53290a118b82"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["gpt2_medium download started this may take some time.\n","Approximate size to download 1.2 GB\n","[OK!]\n"]}]},{"cell_type":"code","source":["sample_text= [[1, \"Donald Trump is rich?\"],\n","              [2, \"Pink Floyd is rock band?\"]]\n","\n","sample_df= spark.createDataFrame(sample_text).toDF(\"id\", \"text\")\n","\n","result = pipeline.fit(sample_df).transform(sample_df)\n","result.select(\"id\", \"generation.result\").show(truncate=False)"],"metadata":{"id":"Hf1WIe6_bUTN","executionInfo":{"status":"ok","timestamp":1657021922024,"user_tz":-180,"elapsed":51430,"user":{"displayName":"Monster C","userId":"08787989274818793476"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1ef2f0cf-7094-40a9-d71d-e88dec62871b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+---+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|id |result                                                                                                                                                                                                                          |\n","+---+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|1  |[ Is it true that Donald Trump is rich?\\n\\nTrump has been described by Forbes' own data as having a net worth of $4 billion. He also recently gave up his share of the Miss Universe Miss USA pageant, and reportedly has $200,]|\n","|2  |[ Is it true that Pink Floyd is rock band?\\n\\nThere are many, many other rock bands. When I was growing up, I had no idea what a \"rock band\" even was. I don't know what a country/rock/j]                                      |\n","+---+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","\n"]}]}]}