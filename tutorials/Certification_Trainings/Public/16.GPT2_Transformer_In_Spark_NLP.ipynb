{"cells":[{"cell_type":"markdown","metadata":{"id":"6sBtVqUvZTQB"},"source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"]},{"cell_type":"markdown","metadata":{"id":"67YDMg3GZTCQ"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/16.GPT2_Transformer_In_Spark_NLP.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"l9cW8XItZlyD"},"source":["# GPT2Transformer: OpenAI Text-To-Text Transformer"]},{"cell_type":"markdown","metadata":{"id":"YaXRil_iZu41"},"source":["GPT-2 displays a broad set of capabilities, including the ability to generate conditional synthetic text samples of unprecedented quality, where the model is primed with an input and it generates a lengthy continuation.\n","\n","Pretrained models can be loaded with `pretrained()` of the companion object:"]},{"cell_type":"markdown","metadata":{"id":"JiF9XgzIcJaA"},"source":["## Colab Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nQdPMraEcJ1K"},"outputs":[],"source":["! pip install -q  pyspark==3.2.0 spark-nlp==3.4.2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":253},"id":"4dun3ggxcLzd","outputId":"5762c168-3d87-4137-c30b-a1332dc84d96"},"outputs":[{"name":"stdout","output_type":"stream","text":["Spark NLP version 3.4.2\n","Apache Spark version: 3.2.0\n"]},{"data":{"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://bfd1217d89a3:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.2.0</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>Spark NLP</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "],"text/plain":["<pyspark.sql.session.SparkSession at 0x7fd492650390>"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["import sparknlp\n","\n","spark = sparknlp.start(spark32=True)\n","\n","from sparknlp.base import *\n","from sparknlp.annotator import *\n","from pyspark.ml import Pipeline,PipelineModel\n","from pyspark.sql import SparkSession\n","from pyspark.sql import functions as F\n","\n","print(\"Spark NLP version\", sparknlp.version())\n","print(\"Apache Spark version:\", spark.version)\n","\n","spark"]},{"cell_type":"markdown","metadata":{"id":"_FKVL06rdMpV"},"source":["**GPT2 Models In Spark NLP**\n","\n","*   `gpt2`\n","*   `gpt2_medium`\n","*   `gpt2_distilled`\n","*   `gpt2_large`\n","\n","The default model is `\"gpt2\"`, if no name is provided. For available pretrained models please see the [Spark NLP Models Hub](https://nlp.johnsnowlabs.com/models?q=gpt2)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"7-Un073ccDYi"},"source":["## GPT2 Pipeline "]},{"cell_type":"markdown","metadata":{"id":"MR8j4syuq-Nr"},"source":["Now, let's create a Spark NLP Pipeline with `gpt2_medium` model and check the results."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IfRKHG-AumPo","outputId":"4f5c48dd-a71c-4e98-f886-43890b7725c4"},"outputs":[{"name":"stdout","output_type":"stream","text":["gpt2_medium download started this may take some time.\n","Approximate size to download 1.2 GB\n","[OK!]\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|result                                                                                                                                                                                                                                           |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|[ My name is Leonardo. I'm a student at the University of California, Berkeley. I've been studying computer science for the past two years. I have a PhD in computer science from the University, and I'm currently working on a PhD at the same]|\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","\n"]}],"source":["documentAssembler = DocumentAssembler() \\\n","    .setInputCol(\"text\") \\\n","    .setOutputCol(\"documents\")\n","    \n","gpt2 = GPT2Transformer.pretrained(\"gpt2_medium\") \\\n","    .setInputCols([\"documents\"]) \\\n","    .setMaxOutputLength(50) \\\n","    .setMinOutputLength(25) \\\n","    .setOutputCol(\"generation\")\n","    \n","pipeline = Pipeline().setStages([documentAssembler,\n","                                 gpt2])\n","\n","data = spark.createDataFrame([[\"My name is Leonardo.\"]]).toDF(\"text\")\n","result = pipeline.fit(data).transform(data)\n","result.select(\"generation.result\").show(truncate=False)"]},{"cell_type":"markdown","metadata":{"id":"kreh6RHjs-lE"},"source":["We can display the documentation of all params with their optionally default values and user-supplied values by `explainParams()` function"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104},"id":"DpBQuEwEsy3U","outputId":"cb6f9127-efb0-465c-a3f3-5b58e6595921"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"batchSize: Size of every batch (default: 4)\\nconfigProtoBytes: ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString() (undefined)\\ndoSample: Whether or not to use sampling; use greedy decoding otherwise (default: False, current: False)\\nignoreTokenIds: A list of token ids which are ignored in the decoder's output (default: [])\\ninputCols: previous annotations columns, if renamed (current: ['documents'])\\nlazyAnnotator: Whether this AnnotatorModel acts as lazy in RecursivePipelines (default: False)\\nmaxOutputLength: Maximum length of output text (default: 20, current: 50)\\nminOutputLength: Minimum length of the sequence to be generated (default: 0, current: 25)\\nnoRepeatNgramSize: If set to int > 0, all ngrams of that size can only occur once (default: 0, current: 3)\\noutputCol: output annotation column. can be left default. (current: generation)\\nrepetitionPenalty: The parameter for repetition penalty. 1.0 means no penalty. See `this paper <https://arxiv.org/pdf/1909.05858.pdf>`__ for more details (default: 1.0)\\ntask: Transformer's task, e.g. 'is it true that'> (default: )\\ntemperature: The value used to module the next token probabilities (default: 1.0)\\ntopK: The number of highest probability vocabulary tokens to keep for top-k-filtering (default: 50, current: 50)\\ntopP: If set to float < 1, only the most probable tokens with probabilities that add up to ``top_p`` or higher are kept for generation (default: 1.0)\""]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["gpt2.explainParams()"]},{"cell_type":"markdown","metadata":{"id":"sVXRNJFPEcgq"},"source":["Let's use model with more sentences and set `.setDoSample()` parameter as True, this parameter is used for whether or not to use sampling; use greedy decoding otherwise, by default False. <br/>\n","Also, we use `.setTopK()` parameter for the number of highest probability vocabulary tokens to keep for top-k-filtering, by default 50."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aMAsyNfPh3Fs"},"outputs":[],"source":["sample_texts= [[1, \"Mey name is Leonardo\"], [2, \"My name is Leonardo and I come from Rome.\"],\n","               [3, \"My name is\"], [4, \"What is the difference between diesel and petrol?\"]]\n","\n","sample_df= spark.createDataFrame(sample_texts).toDF(\"id\", \"text\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z5guR3Bx_khw","outputId":"6790ac83-4ed6-41e2-b674-2894711c42a0"},"outputs":[{"name":"stdout","output_type":"stream","text":["gpt2_medium download started this may take some time.\n","Approximate size to download 1.2 GB\n","[OK!]\n"]}],"source":["gpt2 = GPT2Transformer.pretrained(\"gpt2_medium\") \\\n","        .setInputCols([\"documents\"]) \\\n","        .setMaxOutputLength(50) \\\n","        .setMinOutputLength(25) \\\n","        .setDoSample(True)\\\n","        .setTopK(20)\\\n","        .setOutputCol(\"generation\")\n","\n","pipeline = Pipeline().setStages([documentAssembler,\n","                                 gpt2])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DBxs5-os_zak","outputId":"c716c81b-3f91-425d-bdd1-06597f4f762f"},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|id |result                                                                                                                                                                                                                                       |\n","+---+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|1  |[ Mey name is Leonardo Dessau. He was the first and only player to be chosen as a captain on a World Cup squad. His nickname in the United States has become \"Pete in the back pocket\", after his favorite player from the USA]              |\n","|2  |[ My name is Leonardo and I come from Rome. I was in college there. It is so beautiful. It was not as bad there, it is better today. But we had a horrible earthquake there. I can remember it vividly with my mind, how]                    |\n","|3  |[ My name is Michael Dolan,\" says Dolan.\\n\\nAs a young man, his favorite TV character was the detective, Dr. Phil — whose character, The Dr., has an affinity for the crime-scene scene. So he knew something]                               |\n","|4  |[ What is the difference between diesel and petrol? In short, you can't just mix two fuels together, even though both types are equally dangerous — and it's important to note that they are both made from the same type of oil.\\n\\nWhy you]|\n","+---+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","\n"]}],"source":["result = pipeline.fit(sample_df).transform(sample_df)\n","result.select(\"id\", \"generation.result\").show(truncate=False)"]},{"cell_type":"markdown","metadata":{"id":"JbOQyj-DAHi7"},"source":["### Changing the Transformer's task"]},{"cell_type":"markdown","metadata":{"id":"010b5pPvFAEU"},"source":["Now, we change the task of Transformer. We can verify some informations to GPT-2 by setting `.setTask()` parameter as **\"Is it true that\"**. <br/>\n","We give a text to the model by setting `setTask(\"Is it true that\")` and model adds the \"Is it true that\" expression at the beginning of the sentence and generates sentences."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sTjeFAh5UIMV","outputId":"d2c07a5c-acb1-49ba-81bb-17894d2ca7dd"},"outputs":[{"name":"stdout","output_type":"stream","text":["gpt2_medium download started this may take some time.\n","Approximate size to download 1.2 GB\n","[OK!]\n"]}],"source":[" gpt2 = GPT2Transformer.pretrained(\"gpt2_medium\")\\\n","          .setTask(\"Is it true that\")\\\n","          .setInputCols([\"documents\"])\\\n","          .setMaxOutputLength(50)\\\n","          .setOutputCol(\"generation\")\n","\n","pipeline = Pipeline().setStages([documentAssembler,\n","                                 gpt2])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hf1WIe6_bUTN","outputId":"9ee4568d-d5b4-43d1-a12f-bbb0772feb0f"},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|id |result                                                                                                                                                                                                          |\n","+---+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|1  |[ Is it true that Donald Trump is rich?\\n\\nHe is rich, of course, but the truth is that he's not actually rich. He's the wealthiest member of the U.S. Senate.\\n\\nAnd that's because Trump owns his]            |\n","|2  |[ Is it true that Pink Floyd is rock band? I'm looking at you – David Gilmour (bassist and lyricist) who did it. I'm gonna take this question out right there.\\n\\nYou know Pink Floyd was originally called The]|\n","+---+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","\n"]}],"source":["sample_text= [[1, \"Donald Trump is rich?\"],\n","              [2, \"Pink Floyd is rock band?\"]]\n","\n","sample_df= spark.createDataFrame(sample_text).toDF(\"id\", \"text\")\n","\n","result = pipeline.fit(sample_df).transform(sample_df)\n","result.select(\"id\", \"generation.result\").show(truncate=False)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"16.GPT2_Transformer_In_Spark_NLP.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
