{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uZhJcUl06r8w"
   },
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/training/english/dl-ner/ner_elmo.ipynb)\n",
    "\n",
    "## 0. Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 66366,
     "status": "ok",
     "timestamp": 1589304465223,
     "user": {
      "displayName": "Christian Kasim Loan",
      "photoUrl": "",
      "userId": "14469489166467359317"
     },
     "user_tz": -120
    },
    "id": "22mElNLo6rUI",
    "outputId": "f2a8d6a9-6c1f-40de-9080-2a4b5729ba96"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Install java\n",
    "! apt-get update -qq\n",
    "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
    "\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
    "! java -version\n",
    "\n",
    "# Install pyspark\n",
    "! pip install --ignore-installed pyspark==2.4.4\n",
    "\n",
    "# Install Spark NLP\n",
    "! pip install --ignore-installed spark-nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A_QE6hqA4WHh"
   },
   "source": [
    "# How to train a NER classifier with ELMO embeddings based on Char CNNs - BiLSTM - CRF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wybDus1P4WHk"
   },
   "source": [
    "## Download the file into the local File System \n",
    "### It is a standard conll2003 format training file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 68447,
     "status": "ok",
     "timestamp": 1589304467315,
     "user": {
      "displayName": "Christian Kasim Loan",
      "photoUrl": "",
      "userId": "14469489166467359317"
     },
     "user_tz": -120
    },
    "id": "EA0QHrLF4WHl",
    "outputId": "13905c90-81f7-4bfc-ecee-2033dbf0d617"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Not found will downloading it!\n"
     ]
    }
   ],
   "source": [
    "# Download CoNLL 2003 Dataset\n",
    "import os\n",
    "from pathlib import Path\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "download_path = \"./eng.train\"\n",
    "\n",
    "\n",
    "if not Path(download_path).is_file():\n",
    "    print(\"File Not found will downloading it!\")\n",
    "    url = \"https://github.com/patverga/torch-ner-nlp-from-scratch/raw/master/data/conll2003/eng.train\"\n",
    "    urllib.request.urlretrieve(url, download_path)\n",
    "else:\n",
    "    print(\"File already present.\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uYZhNUVH4WHs"
   },
   "source": [
    "# Read CoNLL Dataset into Spark dataframe and automagically generate features for futures tasks\n",
    "The readDataset method of the CoNLL class handily adds all the features required in the next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 149621,
     "status": "ok",
     "timestamp": 1589304548496,
     "user": {
      "displayName": "Christian Kasim Loan",
      "photoUrl": "",
      "userId": "14469489166467359317"
     },
     "user_tz": -120
    },
    "id": "lQExmc684WHu",
    "outputId": "b64d01d1-95ab-43d9-c8ec-e29bbcdb7a30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|            document|            sentence|               token|                 pos|               label|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|EU rejects German...|[[document, 0, 47...|[[document, 0, 47...|[[token, 0, 1, EU...|[[pos, 0, 1, NNP,...|[[named_entity, 0...|\n",
      "|     Peter Blackburn|[[document, 0, 14...|[[document, 0, 14...|[[token, 0, 4, Pe...|[[pos, 0, 4, NNP,...|[[named_entity, 0...|\n",
      "| BRUSSELS 1996-08-22|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 7, BR...|[[pos, 0, 7, NNP,...|[[named_entity, 0...|\n",
      "|The European Comm...|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 2, Th...|[[pos, 0, 2, DT, ...|[[named_entity, 0...|\n",
      "|Germany 's repres...|[[document, 0, 21...|[[document, 0, 21...|[[token, 0, 6, Ge...|[[pos, 0, 6, NNP,...|[[named_entity, 0...|\n",
      "|\" We do n't suppo...|[[document, 0, 16...|[[document, 0, 16...|[[token, 0, 0, \",...|[[pos, 0, 0, \", [...|[[named_entity, 0...|\n",
      "|He said further s...|[[document, 0, 13...|[[document, 0, 13...|[[token, 0, 1, He...|[[pos, 0, 1, PRP,...|[[named_entity, 0...|\n",
      "|He said a proposa...|[[document, 0, 22...|[[document, 0, 22...|[[token, 0, 1, He...|[[pos, 0, 1, PRP,...|[[named_entity, 0...|\n",
      "|Fischler proposed...|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 7, Fi...|[[pos, 0, 7, JJR,...|[[named_entity, 0...|\n",
      "|But Fischler agre...|[[document, 0, 21...|[[document, 0, 21...|[[token, 0, 2, Bu...|[[pos, 0, 2, CC, ...|[[named_entity, 0...|\n",
      "|Spanish Farm Mini...|[[document, 0, 16...|[[document, 0, 16...|[[token, 0, 6, Sp...|[[pos, 0, 6, NNP,...|[[named_entity, 0...|\n",
      "|                   .|[[document, 0, 0,...|[[document, 0, 0,...|[[token, 0, 0, .,...|[[pos, 0, 0, ., [...|[[named_entity, 0...|\n",
      "|Only France and B...|[[document, 0, 52...|[[document, 0, 52...|[[token, 0, 3, On...|[[pos, 0, 3, RB, ...|[[named_entity, 0...|\n",
      "|The EU 's scienti...|[[document, 0, 17...|[[document, 0, 17...|[[token, 0, 2, Th...|[[pos, 0, 2, DT, ...|[[named_entity, 0...|\n",
      "|Sheep have long b...|[[document, 0, 17...|[[document, 0, 17...|[[token, 0, 4, Sh...|[[pos, 0, 4, NNP,...|[[named_entity, 0...|\n",
      "|British farmers d...|[[document, 0, 21...|[[document, 0, 21...|[[token, 0, 6, Br...|[[pos, 0, 6, JJ, ...|[[named_entity, 0...|\n",
      "|\" What we have to...|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 0, \",...|[[pos, 0, 0, \", [...|[[named_entity, 0...|\n",
      "|Bonn has led effo...|[[document, 0, 21...|[[document, 0, 21...|[[token, 0, 3, Bo...|[[pos, 0, 3, NNP,...|[[named_entity, 0...|\n",
      "|Germany imported ...|[[document, 0, 84...|[[document, 0, 84...|[[token, 0, 6, Ge...|[[pos, 0, 6, NNP,...|[[named_entity, 0...|\n",
      "|It brought in 4,2...|[[document, 0, 82...|[[document, 0, 82...|[[token, 0, 1, It...|[[pos, 0, 1, PRP,...|[[named_entity, 0...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sparknlp\n",
    "from sparknlp.training import CoNLL\n",
    "\n",
    "spark = sparknlp.start()\n",
    "training_data = CoNLL().readDataset(spark, './eng.train')\n",
    "training_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JF9dJWoW4WH6"
   },
   "source": [
    "# Define the NER Pipeline \n",
    "\n",
    "### This pipeline defines a pretrained elmo component and a trainable NerDLApproach which is based on the Char CNN - BiLSTM - CRF\n",
    "\n",
    "Usually you have to add additional pipeline components before the elmo for the document, sentence and token columns. But CoNLL took already care of this for us, awesome!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 189970,
     "status": "ok",
     "timestamp": 1589304588853,
     "user": {
      "displayName": "Christian Kasim Loan",
      "photoUrl": "",
      "userId": "14469489166467359317"
     },
     "user_tz": -120
    },
    "id": "Z0xFttkH4WH7",
    "outputId": "3bccaed8-504d-4a4c-aaaf-f315617b413e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elmo download started this may take some time.\n",
      "Approximate size to download 334.1 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.common import *\n",
    "from sparknlp.base import *\n",
    "\n",
    "# Define the pretrained Elmo model. \n",
    "# We need to set lstm_outputs2 pooling layer, because the elmo layer is not yet compatible with NerDL\n",
    "elmo = ElmoEmbeddings.pretrained().setPoolingLayer(\"lstm_outputs2\") \\\n",
    " .setInputCols(\"sentence\", \"token\")\\\n",
    " .setOutputCol(\"elmo\")\\\n",
    "\n",
    "\n",
    "# Defien the Char CNN - BiLSTM - CRF model. We will feed it the Elmo tokens \n",
    "nerTagger = NerDLApproach()\\\n",
    "  .setInputCols([\"sentence\", \"token\", \"elmo\"])\\\n",
    "  .setLabelColumn(\"label\")\\\n",
    "  .setOutputCol(\"ner\")\\\n",
    "  .setMaxEpochs(1)\\\n",
    "  .setRandomSeed(0)\\\n",
    "  .setVerbose(0)\n",
    "\n",
    "# put everything into the pipe\n",
    "pipeline = Pipeline(\n",
    "    stages = [\n",
    "      elmo ,\n",
    "       nerTagger\n",
    "  ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YpcIr8b_4WIB"
   },
   "source": [
    "# Fit the Pipeline and get results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 219721,
     "status": "ok",
     "timestamp": 1589304618611,
     "user": {
      "displayName": "Christian Kasim Loan",
      "photoUrl": "",
      "userId": "14469489166467359317"
     },
     "user_tz": -120
    },
    "id": "hDKsFDRy4WIC",
    "outputId": "d8630394-85f2-4719-8b78-a28615b961d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|            document|            sentence|               token|                 pos|               label|                elmo|                 ner|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|EU rejects German...|[[document, 0, 47...|[[document, 0, 47...|[[token, 0, 1, EU...|[[pos, 0, 1, NNP,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|\n",
      "|     Peter Blackburn|[[document, 0, 14...|[[document, 0, 14...|[[token, 0, 4, Pe...|[[pos, 0, 4, NNP,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|\n",
      "| BRUSSELS 1996-08-22|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 7, BR...|[[pos, 0, 7, NNP,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|\n",
      "|The European Comm...|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 2, Th...|[[pos, 0, 2, DT, ...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|\n",
      "|Germany 's repres...|[[document, 0, 21...|[[document, 0, 21...|[[token, 0, 6, Ge...|[[pos, 0, 6, NNP,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|\n",
      "|\" We do n't suppo...|[[document, 0, 16...|[[document, 0, 16...|[[token, 0, 0, \",...|[[pos, 0, 0, \", [...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|\n",
      "|He said further s...|[[document, 0, 13...|[[document, 0, 13...|[[token, 0, 1, He...|[[pos, 0, 1, PRP,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|\n",
      "|He said a proposa...|[[document, 0, 22...|[[document, 0, 22...|[[token, 0, 1, He...|[[pos, 0, 1, PRP,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|\n",
      "|Fischler proposed...|[[document, 0, 18...|[[document, 0, 18...|[[token, 0, 7, Fi...|[[pos, 0, 7, JJR,...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|\n",
      "|But Fischler agre...|[[document, 0, 21...|[[document, 0, 21...|[[token, 0, 2, Bu...|[[pos, 0, 2, CC, ...|[[named_entity, 0...|[[word_embeddings...|[[named_entity, 0...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ner_df = pipeline.fit(training_data.limit(10)).transform(training_data.limit(10))\n",
    "#elmo_embeds = pipeline.fit(training_data).transform(training_data)\n",
    "\n",
    "ner_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HFSKuv-x4WIH"
   },
   "source": [
    "### Checkout only result columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 220933,
     "status": "ok",
     "timestamp": 1589304619831,
     "user": {
      "displayName": "Christian Kasim Loan",
      "photoUrl": "",
      "userId": "14469489166467359317"
     },
     "user_tz": -120
    },
    "id": "ObW2xBPn4WII",
    "outputId": "92ef3c98-42ae-4d1b-d4dd-546e9a74b3ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|text                                            |ner                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n",
      "+------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|EU rejects German call to boycott British lamb .|[[named_entity, 0, 1, O, [word -> EU], []], [named_entity, 3, 9, O, [word -> rejects], []], [named_entity, 11, 16, O, [word -> German], []], [named_entity, 18, 21, O, [word -> call], []], [named_entity, 23, 24, O, [word -> to], []], [named_entity, 26, 32, O, [word -> boycott], []], [named_entity, 34, 40, O, [word -> British], []], [named_entity, 42, 45, O, [word -> lamb], []], [named_entity, 47, 47, O, [word -> .], []]]|\n",
      "+------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ner_df.select(*['text', 'ner']).limit(1).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CAGIS-vS4WIO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "ner_elmo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "name": "NER-Tutorial",
  "notebookId": 3359671281044291
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
