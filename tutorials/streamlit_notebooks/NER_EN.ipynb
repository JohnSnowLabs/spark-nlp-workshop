{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER_EN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TA21Jo5d9SVq"
      },
      "source": [
        "\n",
        "\n",
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_EN.ipynb)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzIdjHkAW8TB"
      },
      "source": [
        "# **Detect entities in English text**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIeCOiJNW-88"
      },
      "source": [
        "## 1. Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGJktFHdHL1n",
        "outputId": "5755529b-8d0a-44bf-ae58-4fc6dc597b59"
      },
      "source": [
        "# Install java\n",
        "!apt-get update -qq\n",
        "!apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "!java -version\n",
        "\n",
        "# This is only to setup PySpark and Spark NLP on Colab\n",
        "# -p is for pyspark\n",
        "# -s is for spark-nlp\n",
        "# !bash colab_setup.sh -p 3.1.1 -s 3.0.0  \n",
        "# by default they are set to the latest\n",
        "\n",
        "!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/colab_setup.sh\n",
        "!bash colab_setup.sh -p 3.1.1 -s 3.0.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"11.0.10\" 2021-01-19\n",
            "OpenJDK Runtime Environment (build 11.0.10+9-Ubuntu-0ubuntu1.18.04)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.10+9-Ubuntu-0ubuntu1.18.04, mixed mode, sharing)\n",
            "setup Colab for PySpark 3.1.1 and Spark NLP 3.0.0\n",
            "\u001b[K     |████████████████████████████████| 212.3MB 73kB/s \n",
            "\u001b[K     |████████████████████████████████| 143kB 28.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 38.6MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCIT5VLxS3I1"
      },
      "source": [
        "## 2. Start the Spark session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khjM-z9ORFU3"
      },
      "source": [
        "Import dependencies and start Spark session."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sw-t1zxlHTB7"
      },
      "source": [
        "import os\n",
        "import json\n",
        "os.environ['JAVA_HOME'] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "import sparknlp\n",
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "\n",
        "spark = sparknlp.start()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RgiqfX5XDqb"
      },
      "source": [
        "## 3. Select the DL model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLuDz_t40be4"
      },
      "source": [
        "# If you change the model, re-run all the cells below\n",
        "# Other applicable models: ner_dl, ner_dl_bert\n",
        "MODEL_NAME = \"onto_100\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Y9GpdJhXIpD"
      },
      "source": [
        "## 4. Some sample examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBOKkB2THdGI"
      },
      "source": [
        "text_list = [\n",
        "    \"\"\"William Henry Gates III (born October 28, 1955) is an American business magnate, software developer, investor, and philanthropist. He is best known as the co-founder of Microsoft Corporation. During his career at Microsoft, Gates held the positions of chairman, chief executive officer (CEO), president and chief software architect, while also being the largest individual shareholder until May 2014. He is one of the best-known entrepreneurs and pioneers of the microcomputer revolution of the 1970s and 1980s. Born and raised in Seattle, Washington, Gates co-founded Microsoft with childhood friend Paul Allen in 1975, in Albuquerque, New Mexico; it went on to become the world's largest personal computer software company. Gates led the company as chairman and CEO until stepping down as CEO in January 2000, but he remained chairman and became chief software architect. During the late 1990s, Gates had been criticized for his business tactics, which have been considered anti-competitive. This opinion has been upheld by numerous court rulings. In June 2006, Gates announced that he would be transitioning to a part-time role at Microsoft and full-time work at the Bill & Melinda Gates Foundation, the private charitable foundation that he and his wife, Melinda Gates, established in 2000.[9] He gradually transferred his duties to Ray Ozzie and Craig Mundie. He stepped down as chairman of Microsoft in February 2014 and assumed a new post as technology adviser to support the newly appointed CEO Satya Nadella.\"\"\",\n",
        "    \"\"\"The Mona Lisa is a 16th century oil painting created by Leonardo. It's held at the Louvre in Paris.\"\"\"\n",
        "]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XftYgju4XOw_"
      },
      "source": [
        "## 5. Define Spark NLP pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBggF5P8J1gc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33fac780-fec0-485f-92d9-928ca4d5ba3c"
      },
      "source": [
        "documentAssembler = DocumentAssembler() \\\n",
        "    .setInputCol('text') \\\n",
        "    .setOutputCol('document')\n",
        "\n",
        "tokenizer = Tokenizer() \\\n",
        "    .setInputCols(['document']) \\\n",
        "    .setOutputCol('token')\n",
        "\n",
        "# ner_dl and onto_100 model are trained with glove_100d, so the embeddings in\n",
        "# the pipeline should match\n",
        "if (MODEL_NAME == \"ner_dl\") or (MODEL_NAME == \"onto_100\"):\n",
        "    embeddings = WordEmbeddingsModel.pretrained('glove_100d') \\\n",
        "        .setInputCols([\"document\", 'token']) \\\n",
        "        .setOutputCol(\"embeddings\")\n",
        "\n",
        "# Bert model uses Bert embeddings\n",
        "elif MODEL_NAME == \"ner_dl_bert\":\n",
        "    embeddings = BertEmbeddings.pretrained(name='bert_base_cased', lang='en') \\\n",
        "        .setInputCols(['document', 'token']) \\\n",
        "        .setOutputCol('embeddings')\n",
        "\n",
        "ner_model = NerDLModel.pretrained(MODEL_NAME, 'en') \\\n",
        "    .setInputCols(['document', 'token', 'embeddings']) \\\n",
        "    .setOutputCol('ner')\n",
        "\n",
        "ner_converter = NerConverter() \\\n",
        "    .setInputCols(['document', 'token', 'ner']) \\\n",
        "    .setOutputCol('ner_chunk')\n",
        "\n",
        "nlp_pipeline = Pipeline(stages=[\n",
        "    documentAssembler, \n",
        "    tokenizer,\n",
        "    embeddings,\n",
        "    ner_model,\n",
        "    ner_converter\n",
        "])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "glove_100d download started this may take some time.\n",
            "Approximate size to download 145.3 MB\n",
            "[OK!]\n",
            "onto_100 download started this may take some time.\n",
            "Approximate size to download 13.5 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv0abcwhXWC-"
      },
      "source": [
        "## 6. Run the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYf_9sXDXR4t"
      },
      "source": [
        "empty_df = spark.createDataFrame([['']]).toDF('text')\n",
        "pipeline_model = nlp_pipeline.fit(empty_df)\n",
        "df = spark.createDataFrame(pd.DataFrame({'text': text_list}))\n",
        "result = pipeline_model.transform(df)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQY8tAP6XZJL"
      },
      "source": [
        "## 7. Visualize results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ar32BZu7J79X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d920d431-1005-4bbc-b45a-970090d11345"
      },
      "source": [
        "result.select(\n",
        "    F.explode(\n",
        "        F.arrays_zip('ner_chunk.result', 'ner_chunk.metadata')\n",
        "    ).alias(\"cols\")\n",
        ").select(\n",
        "    F.expr(\"cols['0']\").alias('chunk'),\n",
        "    F.expr(\"cols['1']['entity']\").alias('ner_label')\n",
        ").show(truncate=False)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------------+---------+\n",
            "|chunk                  |ner_label|\n",
            "+-----------------------+---------+\n",
            "|William Henry Gates III|PERSON   |\n",
            "|October 28, 1955       |DATE     |\n",
            "|American               |NORP     |\n",
            "|Microsoft Corporation  |ORG      |\n",
            "|Microsoft              |ORG      |\n",
            "|Gates                  |PERSON   |\n",
            "|May 2014               |DATE     |\n",
            "|one                    |CARDINAL |\n",
            "|the 1970s and 1980s    |DATE     |\n",
            "|Born                   |PERSON   |\n",
            "|Seattle                |GPE      |\n",
            "|Washington             |GPE      |\n",
            "|Gates                  |PERSON   |\n",
            "|Microsoft              |ORG      |\n",
            "|Paul Allen             |PERSON   |\n",
            "|1975                   |DATE     |\n",
            "|Albuquerque            |GPE      |\n",
            "|New Mexico             |GPE      |\n",
            "|Gates                  |PERSON   |\n",
            "|January 2000           |DATE     |\n",
            "+-----------------------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}