{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Translation Models & Pipelines - Spark NLP Python.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3inuQHTI-G-P"
      },
      "source": [
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Cd4gz6vxHiQ"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/TRANSLATION_PIPELINES_MODELS.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXqTJvvh-MCU"
      },
      "source": [
        "# Spark NLP Translation Models & Pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqF9bPKCooXx"
      },
      "source": [
        "## 0. Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wes9qAN7oekN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a4fc2ae-825f-48a8-c63a-5a384409d1af"
      },
      "source": [
        "# This is only to setup PySpark and Spark NLP on Colab\n",
        "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-08 12:09:03--  http://setup.johnsnowlabs.com/colab.sh\n",
            "Resolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 51.158.130.125\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh [following]\n",
            "--2021-07-08 12:09:03--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1608 (1.6K) [text/plain]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                     0%[                    ]       0  --.-KB/s               setup Colab for PySpark 3.0.3 and Spark NLP 3.1.2\n",
            "-                   100%[===================>]   1.57K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2021-07-08 12:09:03 (1.77 MB/s) - written to stdout [1608/1608]\n",
            "\n",
            "Hit:1 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Get:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:5 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:7 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:8 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:9 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "Hit:13 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:14 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:15 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,780 kB]\n",
            "Get:16 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [910 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,658 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,188 kB]\n",
            "Get:19 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [40.8 kB]\n",
            "Ign:21 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:21 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [637 kB]\n",
            "Get:22 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,221 kB]\n",
            "Get:23 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,418 kB]\n",
            "Fetched 12.1 MB in 4s (3,466 kB/s)\n",
            "Reading package lists... Done\n",
            "\u001b[K     |████████████████████████████████| 209.1MB 60kB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 7.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 51.1MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODtmoBwfoX3T"
      },
      "source": [
        "## 1. Start Spark Session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2iPSc6PKSiG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "outputId": "c7121003-031f-4c8d-93f5-605ae97e0556"
      },
      "source": [
        "import sparknlp\n",
        "\n",
        "spark = sparknlp.start()\n",
        "\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "\n",
        "print(\"Spark NLP version\", sparknlp.version())\n",
        "print(\"Apache Spark version:\", spark.version)\n",
        "\n",
        "spark"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spark NLP version 3.1.2\n",
            "Apache Spark version: 3.0.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://4dae8b2fa6d3:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.0.3</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark NLP</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f66491af7d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5_ceVORzFCi"
      },
      "source": [
        "## **Pipelines**: Open-Source Marian Translation Pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fFyndLq0oYh"
      },
      "source": [
        "### Translate English to Hausa Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2iVrC0y0nCn",
        "outputId": "8db9cb6e-d2bf-4845-d461-d8e50d817535"
      },
      "source": [
        "from sparknlp.pretrained import PretrainedPipeline \n",
        "pipeline = PretrainedPipeline(\"translate_en_ha\", lang = \"xx\") \n",
        "pipeline.annotate(\"Your sentence to translate!\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "translate_en_ha download started this may take some time.\n",
            "Approx size to download 267.8 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'document': ['Your sentence to translate!'],\n",
              " 'sentence': ['Your sentence to translate!'],\n",
              " 'translation': ['Hukuncinka na fassara!']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBcOdlhw_OI8"
      },
      "source": [
        "### Translate English to Azerbaijani Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hA0vIXxJ0dBt",
        "outputId": "6dc026ff-4928-4be7-d03a-7abb7afa075f"
      },
      "source": [
        "from sparknlp.pretrained import PretrainedPipeline \n",
        "\n",
        "pipeline = PretrainedPipeline(\"translate_en_az\", lang = \"xx\") \n",
        "pipeline.annotate(\"Your sentence to translate!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "translate_en_az download started this may take some time.\n",
            "Approx size to download 244.9 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'document': ['Your sentence to translate!'],\n",
              " 'sentence': ['Your sentence to translate!'],\n",
              " 'translation': ['Sənin tərcüməni tərcümə etmək üçün bu qədər böyük bir şərəfdir!']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BlbNIAi_gGN"
      },
      "source": [
        "### Translate English to Baltic languages Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlswhXCv_rig"
      },
      "source": [
        "from sparknlp.pretrained import PretrainedPipeline \n",
        "\n",
        "pipeline = PretrainedPipeline(\"translate_en_bat\", lang = \"xx\") \n",
        "pipeline.annotate(\"Your sentence to translate!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trAZs_L7_onQ"
      },
      "source": [
        "### Translate English to Arabic Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bFYHb2X_sPK"
      },
      "source": [
        "from sparknlp.pretrained import PretrainedPipeline \n",
        "\n",
        "pipeline = PretrainedPipeline(\"translate_en_ar\", lang = \"xx\") \n",
        "pipeline.annotate(\"Your sentence to translate!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nk1by0vcEyxx"
      },
      "source": [
        "## **Models**: Open-Source Marian Fast Neural Machine Translation Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zc3KaDcS1uG6"
      },
      "source": [
        "### Translation Model from Spanish to Waray"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyPXllUQ1rMU",
        "outputId": "3d657aeb-9459-45c1-824d-63fcdd4548c6"
      },
      "source": [
        "input_dict = {\n",
        "1: \"Además de ser el rey del norte, John Snow es un médico inglés y líder en el desarrollo de la anestesia y la higiene médica. Se le considera el primero en utilizar datos para curar el brote de cólera en 1854.\",\n",
        "2: \"Titanic es una película épica estadounidense de 1997 sobre desastres y romance dirigida, escrita, coproducida y coeditada por James Cameron. Incorpora aspectos históricos y ficticios, y se basa en relatos del hundimiento del RMS Titanic. Está protagonizada por Leonardo DiCaprio y Kate Winslet como miembros de diferentes clases sociales que se enamoran a bordo del barco durante su desafortunado viaje inaugural.\",\n",
        "3: \"William Henry Gates III (nacido el 28 de octubre de 1955) es un magnate empresarial, desarrollador de software, inversor y filántropo estadounidense. Es mejor conocido como cofundador de Microsoft Corporation. Durante su carrera en Microsoft, Gates ocupó los puestos de presidente, director ejecutivo (CEO), presidente y arquitecto jefe de software. También fue el mayor accionista individual hasta mayo de 2014. Es uno de los empresarios más reconocidos y pioneros de la revolución de las microcomputadoras de los años setenta y ochenta.\",\n",
        "4: \"La Mona Lisa es una obra de Leonardo.. Se celebra en el Louvre en París\",\n",
        "5: \"Facebook es un servicio de red social lanzado como TheFacebook el 4 de febrero de 2004. Fue fundado por Mark Zuckerberg con sus compañeros de cuarto y compañeros de la Universidad de Harvard Eduardo Saverin, Andrew McCollum, Dustin Moskovitz y Chris Hughes. La membresía del sitio web estaba inicialmente limitada por los fundadores a los estudiantes de Harvard, pero se expandió a otras universidades en el área de Boston, la Ivy League y gradualmente a la mayoría de las universidades de los Estados Unidos y Canadá.\",\n",
        "6: \"Geoffrey Everest Hinton es un psicólogo cognitivo e informático canadiense inglés, más conocido por su trabajo en redes neuronales artificiales. Desde 2013 divide su tiempo trabajando para Google y la Universidad de Toronto. En 2017, fue cofundador y se convirtió en el Asesor Científico Jefe del Vector Institute en Toronto.\",\n",
        "7: \"Cuando le dije a John que quería mudarme a Alaska, me advirtió que tendría problemas para encontrar un Starbucks allí.\"\n",
        "}\n",
        "\n",
        "documentAssembler = DocumentAssembler()\\\n",
        "  .setInputCol(\"text\")\\\n",
        "  .setOutputCol(\"document\")\n",
        "\n",
        "sentencerDL = SentenceDetectorDLModel.pretrained(\"sentence_detector_dl\", \"xx\")\\\n",
        "  .setInputCols([\"document\"])\\\n",
        "  .setOutputCol(\"sentence\")\n",
        "\n",
        "marian = MarianTransformer.pretrained(\"opus_mt_es_war\", \"xx\")\\\n",
        "  .setInputCols([\"sentence\"])\\\n",
        "  .setOutputCol(\"translation\")\n",
        "\n",
        "marian_pipeline = Pipeline(stages=[documentAssembler, sentencerDL, marian])\n",
        "light_pipeline = LightPipeline(marian_pipeline.fit(spark.createDataFrame([[\"\"]]).toDF(\"text\")))\n",
        "for sample in input_dict.values():\n",
        "  result = light_pipeline.fullAnnotate(sample)\n",
        "  print ('Translated:\\n')\n",
        "  for sentence in result[0]['translation']:\n",
        "    print (sentence.result)\n",
        "  print(\"-\"*100)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentence_detector_dl download started this may take some time.\n",
            "Approximate size to download 514.9 KB\n",
            "[OK!]\n",
            "opus_mt_es_war download started this may take some time.\n",
            "Approximate size to download 379.9 MB\n",
            "[OK!]\n",
            "Translated:\n",
            "\n",
            "Gawas pa han pagin hadi ha norte, hi John Syy usa nga Ingles nga doktor ngan lider ha pag - uswag han  ngan kalimpyo ha mediko.\n",
            "An siyahan nga paggamit hin impormasyon basi matambal an samad han kasina han 117.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Translated:\n",
            "\n",
            "Hi usa nga pelikula ha E.U. ha Estados Unidos han 1997 mahitungod han mga kalamidad ngan mga video, mga surat, ngan mga kapppppp - ay nga mga\n",
            "An makasaysayan ngan an komplikado nga mga bahin iginbasar ha mga istorya han Mga Ebanghelyo han Mga Ebanghelyo mahitungod han Mga Ebanghelyo.\n",
            "Hi Leonardo Diits ngan hi Kasssssss mga membro han magkalainlain nga mga klase han sosiedad nga nahigugma ha barko durante han ira siyahan nga pagbiyahe\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Translated:\n",
            "\n",
            "Hi William Gat III (An edad 28, 1955) usa nga kilala nga negosyante ha gobyerno han Estados Unidos, ngan an iya asawa nga hi Henrybe, usa nga negosyante ha gobyerno han Estados Unidos\n",
            "Mas kilala hiya sugad nga an Haggs de Murbe han Hee Core Core han daan nga mga nasud.\n",
            "Durante han iya karera ha Mitbtt, an Gat amo an responsable nga opisyal han presidente, direktor, presidente, ngan lider han.\n",
            "Nagin an pinakabantogan nga paradara han mga tawo ngadto ha Mayo 2014.\n",
            "Usa hiya han pinakakilala nga mga negosyante ngan nanguna ha pagpoo han mga paranano nga mga grupo han mga sundalo tikang han dekada 70 tubtob 80.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Translated:\n",
            "\n",
            "An Tanna usa nga obra maestra ni Leonardo.\n",
            ".\n",
            "Pagsulod ha Paris\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Translated:\n",
            "\n",
            "An U.S.A. usa nga serbisyo ha komunidad nga nakasentro ha sosiedad sugad han The han Pebrero 4, 2004.\n",
            "Hi Mark Zlatn ngan an iya mga kaupod ha University of Eduardoka, Andrew, ngan Chris\n",
            "An siyahan nga bahin han website amo an mga estudyante han mga unibersidad ha, kondi an iba nga mga unibersidad ha sentro han, an Ibvvvvy\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Translated:\n",
            "\n",
            "Hi Geoffrey Erl usa nga eksperto ha Ingles ngan ha Canada, nga kilala gud ha iya trabaho sugad nga mga parahimo hin mga produkto han kompyuter.\n",
            "Tikang han 2013, gin - aayad ni Bugto Grjn an iya panahon ha pagtrabaho para ha Go ngan ha University of Toronto.\n",
            "Han 2017, hi Aspppp nagin an Aalrr nga Apppcccr ha Toronto.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Translated:\n",
            "\n",
            "Han ginsumatan ko hi John nga karuyag niya bumalhin ha Aalka, nagpahamangno hiya nga magkakaada hiya mga problema basi makabiling hin usa nga nga libro.\n",
            "----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JI5dSe10BrEL"
      },
      "source": [
        "### Translation Model from Thai to English"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XD4GvDMTEyyT",
        "outputId": "97fee924-7421-4abb-f4f4-fbbc2fb63d3a"
      },
      "source": [
        "data = \"ประโยคของคุณที่จะแปล!\"\n",
        "\n",
        "documentAssembler = DocumentAssembler()\\\n",
        "  .setInputCol(\"text\")\\\n",
        "  .setOutputCol(\"document\")\n",
        "\n",
        "sentencerDL = SentenceDetectorDLModel.pretrained(\"sentence_detector_dl\", \"xx\")\\\n",
        "  .setInputCols([\"document\"])\\\n",
        "  .setOutputCol(\"sentence\")\n",
        "\n",
        "marian = MarianTransformer.pretrained(\"opus_mt_th_en\", \"xx\")\\\n",
        "  .setInputCols([\"sentence\"])\\\n",
        "  .setOutputCol(\"translation\")\n",
        "\n",
        "marian_pipeline = Pipeline(stages=[documentAssembler, sentencerDL, marian])\n",
        "light_pipeline = LightPipeline(marian_pipeline.fit(spark.createDataFrame([[\"\"]]).toDF(\"text\")))\n",
        "result = light_pipeline.fullAnnotate(data)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentence_detector_dl download started this may take some time.\n",
            "Approximate size to download 514.9 KB\n",
            "[OK!]\n",
            "opus_mt_th_en download started this may take some time.\n",
            "Approximate size to download 388.5 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoNDDloxHeuW"
      },
      "source": [
        "### Translation Model from Turkish to English"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qwlHyckHeua",
        "outputId": "a9f66c0f-555e-4533-a669-9f0266b4d3ab"
      },
      "source": [
        "data = \"Çevrilecek cümleniz!\"\n",
        "\n",
        "documentAssembler = DocumentAssembler()\\\n",
        "  .setInputCol(\"text\")\\\n",
        "  .setOutputCol(\"document\")\n",
        "\n",
        "sentencerDL = SentenceDetectorDLModel.pretrained(\"sentence_detector_dl\", \"xx\")\\\n",
        "  .setInputCols([\"document\"])\\\n",
        "  .setOutputCol(\"sentence\")\n",
        "\n",
        "marian = MarianTransformer.pretrained(\"opus_mt_tr_en\", \"xx\")\\\n",
        "  .setInputCols([\"sentence\"])\\\n",
        "  .setOutputCol(\"translation\")\n",
        "\n",
        "marian_pipeline = Pipeline(stages=[documentAssembler, sentencerDL, marian])\n",
        "light_pipeline = LightPipeline(marian_pipeline.fit(spark.createDataFrame([[\"\"]]).toDF(\"text\")))\n",
        "result = light_pipeline.fullAnnotate(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentence_detector_dl download started this may take some time.\n",
            "Approximate size to download 514.9 KB\n",
            "[OK!]\n",
            "opus_mt_tr_en download started this may take some time.\n",
            "Approximate size to download 386.5 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBQWrkVhHgRw"
      },
      "source": [
        "### Translation Model from Hungarian to English"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlt-TIl7HgRy",
        "outputId": "c59bf6fa-533e-4339-bfc1-f755da98afd5"
      },
      "source": [
        "data = \"Fordítandó mondatod!\"\n",
        "\n",
        "documentAssembler = DocumentAssembler()\\\n",
        "  .setInputCol(\"text\")\\\n",
        "  .setOutputCol(\"document\")\n",
        "\n",
        "sentencerDL = SentenceDetectorDLModel.pretrained(\"sentence_detector_dl\", \"xx\")\\\n",
        "  .setInputCols([\"document\"])\\\n",
        "  .setOutputCol(\"sentence\")\n",
        "\n",
        "marian = MarianTransformer.pretrained(\"opus_mt_hu_en\", \"xx\")\\\n",
        "  .setInputCols([\"sentence\"])\\\n",
        "  .setOutputCol(\"translation\")\n",
        "\n",
        "marian_pipeline = Pipeline(stages=[documentAssembler, sentencerDL, marian])\n",
        "light_pipeline = LightPipeline(marian_pipeline.fit(spark.createDataFrame([[\"\"]]).toDF(\"text\")))\n",
        "result = light_pipeline.fullAnnotate(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentence_detector_dl download started this may take some time.\n",
            "Approximate size to download 514.9 KB\n",
            "[OK!]\n",
            "opus_mt_hu_en download started this may take some time.\n",
            "Approximate size to download 387.1 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}