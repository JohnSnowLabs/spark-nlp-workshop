{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CLASSIFICATION_Fr_SENTIMENT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vas1PNJwZp2U"
      },
      "source": [
        "\n",
        "\n",
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/CLASSIFICATION_Fr_Sentiment.ipynb)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2lonApkZwJP"
      },
      "source": [
        "# **Sentiment Analysis of French texts**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMURhBz4ZwM6"
      },
      "source": [
        "## 1. Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyYMEtv59sox",
        "outputId": "fcee5a07-3938-4adf-e843-26b35cc688ad"
      },
      "source": [
        "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-05 10:35:09--  http://setup.johnsnowlabs.com/colab.sh\n",
            "Resolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 51.158.130.125\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://setup.johnsnowlabs.com/colab.sh [following]\n",
            "--2021-10-05 10:35:09--  https://setup.johnsnowlabs.com/colab.sh\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh [following]\n",
            "--2021-10-05 10:35:09--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1608 (1.6K) [text/plain]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                   100%[===================>]   1.57K  --.-KB/s    in 0s      \n",
            "\n",
            "setup Colab for PySpark 3.0.3 and Spark NLP 3.3.0\n",
            "2021-10-05 10:35:09 (17.3 MB/s) - written to stdout [1608/1608]\n",
            "\n",
            "Get:1 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:5 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:6 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Hit:7 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:8 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:9 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Ign:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:13 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,800 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,208 kB]\n",
            "Get:16 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,802 kB]\n",
            "Get:17 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [922 kB]\n",
            "Get:18 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [40.8 kB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,430 kB]\n",
            "Fetched 9,492 kB in 3s (2,724 kB/s)\n",
            "Reading package lists... Done\n",
            "\u001b[K     |████████████████████████████████| 209.1 MB 55 kB/s \n",
            "\u001b[K     |████████████████████████████████| 120 kB 51.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 198 kB 44.4 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_zcj8Y89zxI"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "import sparknlp\n",
        "from sparknlp.pretrained import PretrainedPipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKf4YBDBZ9x7"
      },
      "source": [
        "## 2. Start Spark Session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGBQWrkf-Tlv"
      },
      "source": [
        "spark = sparknlp.start()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRXP3pl4cVOt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_-O5I9BaF08"
      },
      "source": [
        "## 3. Some sample examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0-Axxuz-V95"
      },
      "source": [
        "text_list = [\n",
        "\"\"\"Jeu et championnat pas assez excitants ? Devez-vous vérifier l'arbitre vidéo maintenant? Je suis horrifié, pensa-t-il, il ne devrait répondre que s'il a fait des erreurs flagrantes. Le football n'est plus amusant.\"\"\",             \n",
        "\"\"\"J'ai raté le podcast werder hier mercredi. À quelle vitesse vous vous habituez à quelque chose et vous l'attendez avec impatience. Merci à Plainsman pour les bonnes interviews et la perspicacité dans les coulisses du werderbremen. Passez de bonnes vacances d'hiver !\"\"\",\n",
        "\"\"\"Les scènes s'enchaînent de manière saccadée, les dialogues sont théâtraux, le jeu des acteurs ne transcende pas franchement le film. Seule la musique de Vivaldi sauve le tout. Belle déception.\"\"\",\n",
        "\"\"\"Je n'aime pas l'arbitre parce qu'il est empoisonné !\"\"\",\n",
        "\"\"\"ManCity Guardiola et sa bande, vous êtes des connards. Je viens de perdre une fortune à cause de ta dette envers tes Bavarois là-bas.\"\"\",\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULKvemZpaNal"
      },
      "source": [
        "## 4. Define Spark NLP pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Y7GcAse-2Ie",
        "outputId": "3e84ee42-c06b-411e-aa66-5036a2615742"
      },
      "source": [
        "document = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "embeddings = BertSentenceEmbeddings\\\n",
        "    .pretrained('labse', 'xx') \\\n",
        "    .setInputCols([\"document\"])\\\n",
        "    .setOutputCol(\"sentence_embeddings\")\n",
        "\n",
        "sentimentClassifier = ClassifierDLModel.pretrained(\"classifierdl_bert_sentiment\", \"fr\") \\\n",
        "  .setInputCols([\"document\", \"sentence_embeddings\"]) \\\n",
        "  .setOutputCol(\"class\")    \n",
        "     \n",
        "nlpPipeline = Pipeline(stages=[\n",
        " document, \n",
        " embeddings,\n",
        " sentimentClassifier\n",
        " ])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labse download started this may take some time.\n",
            "Approximate size to download 1.7 GB\n",
            "[OK!]\n",
            "classifierdl_bert_sentiment download started this may take some time.\n",
            "Approximate size to download 22.2 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZtgPiQPafLR"
      },
      "source": [
        "## 5. Run the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZIJCK75_AeC"
      },
      "source": [
        "empty_df = spark.createDataFrame([['']]).toDF(\"text\")\n",
        "\n",
        "pipelineModel = nlpPipeline.fit(empty_df)\n",
        "df = spark.createDataFrame(pd.DataFrame({\"text\":text_list}))\n",
        "result = pipelineModel.transform(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GM8GfPB5aSCu"
      },
      "source": [
        "## 6. Visualize results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeDbR4Gd_uo0",
        "outputId": "851013ba-a8c0-4d95-8c0a-9792328555d3"
      },
      "source": [
        "\n",
        "result.select(F.explode(F.arrays_zip('document.result', 'class.result')).alias(\"cols\")) \\\n",
        ".select(F.expr(\"cols['0']\").alias(\"document\"),\n",
        "        F.expr(\"cols['1']\").alias(\"class\")).show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+\n",
            "|document                                                                                                                                                                                                                                                                  |class   |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+\n",
            "|Jeu et championnat pas assez excitants ? Devez-vous vérifier l'arbitre vidéo maintenant? Je suis horrifié, pensa-t-il, il ne devrait répondre que s'il a fait des erreurs flagrantes. Le football n'est plus amusant.                                                     |NEGATIVE|\n",
            "|J'ai raté le podcast werder hier mercredi. À quelle vitesse vous vous habituez à quelque chose et vous l'attendez avec impatience. Merci à Plainsman pour les bonnes interviews et la perspicacité dans les coulisses du werderbremen. Passez de bonnes vacances d'hiver !|POSITIVE|\n",
            "|Les scènes s'enchaînent de manière saccadée, les dialogues sont théâtraux, le jeu des acteurs ne transcende pas franchement le film. Seule la musique de Vivaldi sauve le tout. Belle déception.                                                                          |NEGATIVE|\n",
            "|Je n'aime pas l'arbitre parce qu'il est empoisonné !                                                                                                                                                                                                                      |NEGATIVE|\n",
            "|ManCity Guardiola et sa bande, vous êtes des connards. Je viens de perdre une fortune à cause de ta dette envers tes Bavarois là-bas.                                                                                                                                     |NEGATIVE|\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ualVYC2U_xp0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}