{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TEXT_PREPROCESSING.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ee_Kcf21AeFS"
      },
      "source": [
        "\n",
        "\n",
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/TEXT_PREPROCESSING.ipynb)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OG6pbilzA7GE"
      },
      "source": [
        "# **Pre-Process text:**\n",
        "## **Convert text to tokens, remove punctuation, stop words, perform stemming and lemmatization using Spark NLP's annotators**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMBsXh3WIYTb"
      },
      "source": [
        "**Demo of the following annotators:**\n",
        "\n",
        "\n",
        "* SentenceDetector\n",
        "* Tokenizer\n",
        "* Normalizer\n",
        "* Stemmer\n",
        "* Lemmatizer\n",
        "* StopWordsCleaner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5YPbgjj_wJV"
      },
      "source": [
        "## 1. Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6o8-g0tEqNz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dae639e4-798d-487c-b83e-b1b46463f113"
      },
      "source": [
        "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash\n",
        "# !bash colab.sh\n",
        "# -p is for pyspark\n",
        "# -s is for spark-nlp\n",
        "# !bash colab.sh -p 3.1.1 -s 3.0.1\n",
        "# by default they are set to the latest"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"11.0.10\" 2021-01-19\n",
            "OpenJDK Runtime Environment (build 11.0.10+9-Ubuntu-0ubuntu1.18.04)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.10+9-Ubuntu-0ubuntu1.18.04, mixed mode, sharing)\n",
            "setup Colab for PySpark 3.1.1 and Spark NLP 3.0.0\n",
            "\u001b[K     |████████████████████████████████| 212.3MB 60kB/s \n",
            "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /simple/spark-nlp/\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 143kB 42.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 40.4MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMmT9S6mE0ad"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "import sparknlp\n",
        "from sparknlp.pretrained import PretrainedPipeline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E41Jp1vD_4Zy"
      },
      "source": [
        "## 2. Start Spark Session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zBXbY_vE2ss"
      },
      "source": [
        "spark = sparknlp.start()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoDybOvfAHjC"
      },
      "source": [
        "## 3. Setting sample text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJ7GCD0pFDvP"
      },
      "source": [
        "## Generating Example Files ##\n",
        "\n",
        "text_list = [\"\"\"The Geneva Motor Show, the first major car show of the year, opens tomorrow with U.S. Car makers hoping to make new inroads into European markets due to the cheap dollar, automobile executives said. Ford Motor Co and General Motors Corp sell cars in Europe, where about 10.5 mln new cars a year are bought. GM also makes a few thousand in North American plants for European export.\"\"\",\n",
        "             ]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hm2G1yAsHTGH"
      },
      "source": [
        "## 4. Download lemma reference file. (you may also use a pre-trained lemmatization model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezbuthMzeYDf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82deb84b-18a3-49e2-e684-f61b27c9373a"
      },
      "source": [
        "#getting lemma files\n",
        "!wget https://raw.githubusercontent.com/mahavivo/vocabulary/master/lemmas/AntBNC_lemmas_ver_001.txt"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-04 11:27:25--  https://raw.githubusercontent.com/mahavivo/vocabulary/master/lemmas/AntBNC_lemmas_ver_001.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1348552 (1.3M) [text/plain]\n",
            "Saving to: ‘AntBNC_lemmas_ver_001.txt’\n",
            "\n",
            "\r          AntBNC_le   0%[                    ]       0  --.-KB/s               \rAntBNC_lemmas_ver_0 100%[===================>]   1.29M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2021-04-04 11:27:25 (82.3 MB/s) - ‘AntBNC_lemmas_ver_001.txt’ saved [1348552/1348552]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2eJbLJE_-VW"
      },
      "source": [
        "## 5. Define Spark NLP pipleline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiYxv0mOFIcX"
      },
      "source": [
        "documentAssembler = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "sentenceDetector = SentenceDetector()\\\n",
        "    .setInputCols(['document'])\\\n",
        "    .setOutputCol('sentences')\n",
        "\n",
        "tokenizer = Tokenizer() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "normalizer = Normalizer() \\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"normalized\")\\\n",
        "    .setLowercase(True)\\\n",
        "    .setCleanupPatterns([\"[^\\w\\d\\s]\"])\n",
        "\n",
        "stopwords_cleaner = StopWordsCleaner()\\\n",
        "    .setInputCols(\"token\")\\\n",
        "    .setOutputCol(\"removed_stopwords\")\\\n",
        "    .setCaseSensitive(False)\\\n",
        "\n",
        "stemmer = Stemmer() \\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"stem\")\n",
        "\n",
        "\n",
        "lemmatizer = Lemmatizer() \\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"lemma\") \\\n",
        "    .setDictionary(\"./AntBNC_lemmas_ver_001.txt\", value_delimiter =\"\\t\", key_delimiter = \"->\")\n",
        "\n",
        "nlpPipeline = Pipeline(stages=[documentAssembler,\n",
        "                               sentenceDetector,\n",
        "                               tokenizer,\n",
        "                               normalizer,\n",
        "                               stopwords_cleaner,\n",
        "                               stemmer,\n",
        "                               lemmatizer,\n",
        "                               ])\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akv_NYv7MDDw"
      },
      "source": [
        "## 6. Run pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQm-b5dMMARa"
      },
      "source": [
        "empty_df = spark.createDataFrame([['']]).toDF(\"text\")\n",
        "\n",
        "pipelineModel = nlpPipeline.fit(empty_df)\n",
        "\n",
        "df = spark.createDataFrame(pd.DataFrame({'text':text_list}))\n",
        "result = pipelineModel.transform(df)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgZ9hnwmMHyO"
      },
      "source": [
        "## 7. Visualize Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBDmM5aRH1zR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06ac1050-41d5-4b27-9ac1-543e17878354"
      },
      "source": [
        "# sentences in the text\n",
        "result.select(F.explode(F.arrays_zip('sentences.result')).alias(\"cols\")) \\\n",
        ".select(F.expr(\"cols['0']\").alias(\"sentences\")).show(truncate=False)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------------------------------------------------------------------------------------------------------+\n",
            "|sentences                                                                                                       |\n",
            "+----------------------------------------------------------------------------------------------------------------+\n",
            "|The Geneva Motor Show, the first major car show of the year, opens tomorrow with U.S.                           |\n",
            "|Car makers hoping to make new inroads into European markets due to the cheap dollar, automobile executives said.|\n",
            "|Ford Motor Co and General Motors Corp sell cars in Europe, where about 10.5 mln new cars a year are bought.     |\n",
            "|GM also makes a few thousand in North American plants for European export.                                      |\n",
            "+----------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4ACcIXqGkfl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ddd361b-ac04-42b4-dd8f-982b285b901b"
      },
      "source": [
        "# tokens in the text\n",
        "result.select(F.explode(F.arrays_zip('token.result')).alias(\"cols\")) \\\n",
        ".select(F.expr(\"cols['0']\").alias(\"tokens\")).show(truncate=False)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+\n",
            "|tokens  |\n",
            "+--------+\n",
            "|The     |\n",
            "|Geneva  |\n",
            "|Motor   |\n",
            "|Show    |\n",
            "|,       |\n",
            "|the     |\n",
            "|first   |\n",
            "|major   |\n",
            "|car     |\n",
            "|show    |\n",
            "|of      |\n",
            "|the     |\n",
            "|year    |\n",
            "|,       |\n",
            "|opens   |\n",
            "|tomorrow|\n",
            "|with    |\n",
            "|U.S     |\n",
            "|.       |\n",
            "|Car     |\n",
            "+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgB5ZEDxdKah",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55aa000e-4e01-4727-ce4a-7b6a05753d28"
      },
      "source": [
        "# eliminated punctuation\n",
        "result.select(F.explode(F.arrays_zip('normalized.result')).alias(\"cols\")) \\\n",
        ".select(F.expr(\"cols['0']\").alias(\"normalized_tokens\")).show(truncate=False)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------+\n",
            "|normalized_tokens|\n",
            "+-----------------+\n",
            "|the              |\n",
            "|geneva           |\n",
            "|motor            |\n",
            "|show             |\n",
            "|the              |\n",
            "|first            |\n",
            "|major            |\n",
            "|car              |\n",
            "|show             |\n",
            "|of               |\n",
            "|the              |\n",
            "|year             |\n",
            "|opens            |\n",
            "|tomorrow         |\n",
            "|with             |\n",
            "|us               |\n",
            "|car              |\n",
            "|makers           |\n",
            "|hoping           |\n",
            "|to               |\n",
            "+-----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOGUACIJeeUj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "543102bb-54e2-4a2b-9d14-dab4347ad0c3"
      },
      "source": [
        "# stemmed tokens\n",
        "result.select(F.explode(F.arrays_zip('stem.result')).alias(\"cols\")) \\\n",
        ".select(F.expr(\"cols['0']\").alias(\"token_stems\")).show(truncate=False)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------+\n",
            "|token_stems|\n",
            "+-----------+\n",
            "|the        |\n",
            "|geneva     |\n",
            "|motor      |\n",
            "|show       |\n",
            "|,          |\n",
            "|the        |\n",
            "|first      |\n",
            "|major      |\n",
            "|car        |\n",
            "|show       |\n",
            "|of         |\n",
            "|the        |\n",
            "|year       |\n",
            "|,          |\n",
            "|open       |\n",
            "|tomorrow   |\n",
            "|with       |\n",
            "|u.         |\n",
            "|.          |\n",
            "|car        |\n",
            "+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApCB3G-6gGar",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc62ff29-1c15-45f3-be94-9f64bc380ab0"
      },
      "source": [
        "# removed_stopwords\n",
        "result.select(F.explode(F.arrays_zip('removed_stopwords.result')).alias(\"cols\")) \\\n",
        ".select(F.expr(\"cols['0']\").alias(\"removed_stopwords\")).show(truncate=False)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------+\n",
            "|removed_stopwords|\n",
            "+-----------------+\n",
            "|Geneva           |\n",
            "|Motor            |\n",
            "|Show             |\n",
            "|,                |\n",
            "|first            |\n",
            "|major            |\n",
            "|car              |\n",
            "|show             |\n",
            "|year             |\n",
            "|,                |\n",
            "|opens            |\n",
            "|tomorrow         |\n",
            "|U.S              |\n",
            "|.                |\n",
            "|Car              |\n",
            "|makers           |\n",
            "|hoping           |\n",
            "|make             |\n",
            "|new              |\n",
            "|inroads          |\n",
            "+-----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQ86qhQmgMbh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "451c16f7-ec90-42d9-f325-39a1fe9da384"
      },
      "source": [
        "# lemmatization\n",
        "result.select(F.explode(F.arrays_zip('lemma.result')).alias(\"cols\")) \\\n",
        ".select(F.expr(\"cols['0']\").alias(\"lemma\")).show(truncate=False)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+\n",
            "|lemma   |\n",
            "+--------+\n",
            "|The     |\n",
            "|Geneva  |\n",
            "|Motor   |\n",
            "|Show    |\n",
            "|,       |\n",
            "|the     |\n",
            "|first   |\n",
            "|major   |\n",
            "|car     |\n",
            "|show    |\n",
            "|of      |\n",
            "|the     |\n",
            "|year    |\n",
            "|,       |\n",
            "|open    |\n",
            "|tomorrow|\n",
            "|with    |\n",
            "|U.S     |\n",
            "|.       |\n",
            "|Car     |\n",
            "+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}