{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TEXT_PREPROCESSING.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ee_Kcf21AeFS",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/TEXT_PREPROCESSING.ipynb)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OG6pbilzA7GE",
        "colab_type": "text"
      },
      "source": [
        "# **Pre-Process text:**\n",
        "## **Convert text to tokens, remove punctuation, stop words, perform stemming and lemmatization using Spark NLP's annotators**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMBsXh3WIYTb",
        "colab_type": "text"
      },
      "source": [
        "**Demo of the following annotators:**\n",
        "\n",
        "\n",
        "* SentenceDetector\n",
        "* Tokenizer\n",
        "* Normalizer\n",
        "* Stemmer\n",
        "* Lemmatizer\n",
        "* StopWordsCleaner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5YPbgjj_wJV",
        "colab_type": "text"
      },
      "source": [
        "## 0. Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6o8-g0tEqNz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sudo apt-get install openjdk-8-jdk\n",
        "!java -version\n",
        "!pip install --ignore-installed -q pyspark==2.4.4\n",
        "!pip install spark-nlp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMmT9S6mE0ad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "import json\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "import sparknlp\n",
        "from sparknlp.pretrained import PretrainedPipeline"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E41Jp1vD_4Zy",
        "colab_type": "text"
      },
      "source": [
        "## 1. Start Spark Session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zBXbY_vE2ss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spark = sparknlp.start()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoDybOvfAHjC",
        "colab_type": "text"
      },
      "source": [
        "## 2. Setting sample text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJ7GCD0pFDvP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Generating Example Files ##\n",
        "\n",
        "text_list = [\"\"\"The Geneva Motor Show, the first major car show of the year, opens tomorrow with U.S. Car makers hoping to make new inroads into European markets due to the cheap dollar, automobile executives said. Ford Motor Co and General Motors Corp sell cars in Europe, where about 10.5 mln new cars a year are bought. GM also makes a few thousand in North American plants for European export.\"\"\",\n",
        "             ]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hm2G1yAsHTGH",
        "colab_type": "text"
      },
      "source": [
        "## 3. Download lemma reference file. (you may also use a pre-trained lemmatization model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezbuthMzeYDf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#getting lemma files\n",
        "!wget https://raw.githubusercontent.com/mahavivo/vocabulary/master/lemmas/AntBNC_lemmas_ver_001.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2eJbLJE_-VW",
        "colab_type": "text"
      },
      "source": [
        "## 4. Define Spark NLP pipleline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiYxv0mOFIcX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "documentAssembler = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "sentenceDetector = SentenceDetector()\\\n",
        "    .setInputCols(['document'])\\\n",
        "    .setOutputCol('sentences')\n",
        "\n",
        "tokenizer = Tokenizer() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "normalizer = Normalizer() \\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"normalized\")\\\n",
        "    .setLowercase(True)\\\n",
        "    .setCleanupPatterns([\"[^\\w\\d\\s]\"])\n",
        "\n",
        "stopwords_cleaner = StopWordsCleaner()\\\n",
        "    .setInputCols(\"token\")\\\n",
        "    .setOutputCol(\"removed_stopwords\")\\\n",
        "    .setCaseSensitive(False)\\\n",
        "\n",
        "stemmer = Stemmer() \\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"stem\")\n",
        "\n",
        "\n",
        "lemmatizer = Lemmatizer() \\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"lemma\") \\\n",
        "    .setDictionary(\"./AntBNC_lemmas_ver_001.txt\", value_delimiter =\"\\t\", key_delimiter = \"->\")\n",
        "\n",
        "nlpPipeline = Pipeline(stages=[documentAssembler,\n",
        "                               sentenceDetector,\n",
        "                               tokenizer,\n",
        "                               normalizer,\n",
        "                               stopwords_cleaner,\n",
        "                               stemmer,\n",
        "                               lemmatizer,\n",
        "                               ])\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akv_NYv7MDDw",
        "colab_type": "text"
      },
      "source": [
        "## 5. Run pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQm-b5dMMARa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "empty_df = spark.createDataFrame([['']]).toDF(\"text\")\n",
        "\n",
        "pipelineModel = nlpPipeline.fit(empty_df)\n",
        "\n",
        "df = spark.createDataFrame(pd.DataFrame({'text':text_list}))\n",
        "result = pipelineModel.transform(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgZ9hnwmMHyO",
        "colab_type": "text"
      },
      "source": [
        "## 6. Visualize Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBDmM5aRH1zR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sentences in the text\n",
        "result.select(F.explode(F.arrays_zip('sentences.result')).alias(\"cols\")) \\\n",
        ".select(F.expr(\"cols['0']\").alias(\"sentences\")).show(truncate=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4ACcIXqGkfl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tokens in the text\n",
        "result.select(F.explode(F.arrays_zip('token.result')).alias(\"cols\")) \\\n",
        ".select(F.expr(\"cols['0']\").alias(\"tokens\")).show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgB5ZEDxdKah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# eliminated punctuation\n",
        "result.select(F.explode(F.arrays_zip('normalized.result')).alias(\"cols\")) \\\n",
        ".select(F.expr(\"cols['0']\").alias(\"normalized_tokens\")).show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOGUACIJeeUj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# stemmed tokens\n",
        "result.select(F.explode(F.arrays_zip('stem.result')).alias(\"cols\")) \\\n",
        ".select(F.expr(\"cols['0']\").alias(\"token_stems\")).show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApCB3G-6gGar",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# removed_stopwords\n",
        "result.select(F.explode(F.arrays_zip('removed_stopwords.result')).alias(\"cols\")) \\\n",
        ".select(F.expr(\"cols['0']\").alias(\"removed_stopwords\")).show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQ86qhQmgMbh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lemmatization\n",
        "result.select(F.explode(F.arrays_zip('lemma.result')).alias(\"cols\")) \\\n",
        ".select(F.expr(\"cols['0']\").alias(\"lemma\")).show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}