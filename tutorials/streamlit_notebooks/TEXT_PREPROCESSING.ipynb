{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ee_Kcf21AeFS"
      },
      "source": [
        "\n",
        "\n",
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/TEXT_PREPROCESSING.ipynb)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OG6pbilzA7GE"
      },
      "source": [
        "# **Pre-Process text:**\n",
        "## **Convert text to tokens, remove punctuation, stop words, perform stemming and lemmatization using Spark NLP's annotators**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMBsXh3WIYTb"
      },
      "source": [
        "**Demo of the following annotators:**\n",
        "\n",
        "\n",
        "* SentenceDetector\n",
        "* Tokenizer\n",
        "* Normalizer\n",
        "* Stemmer\n",
        "* Lemmatizer\n",
        "* StopWordsCleaner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5YPbgjj_wJV"
      },
      "source": [
        "## 1. Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6o8-g0tEqNz",
        "outputId": "dae639e4-798d-487c-b83e-b1b46463f113"
      },
      "outputs": [],
      "source": [
        "# Install PySpark and Spark NLP\n",
        "! pip install -q pyspark==3.1.2 spark-nlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yMmT9S6mE0ad"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "import sparknlp\n",
        "from sparknlp.pretrained import PretrainedPipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E41Jp1vD_4Zy"
      },
      "source": [
        "## 2. Start Spark Session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4zBXbY_vE2ss"
      },
      "outputs": [],
      "source": [
        "spark = sparknlp.start()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoDybOvfAHjC"
      },
      "source": [
        "## 3. Setting sample text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GJ7GCD0pFDvP"
      },
      "outputs": [],
      "source": [
        "## Generating Example Files ##\n",
        "\n",
        "text_list = [\"\"\"The Geneva Motor Show, the first major car show of the year, opens tomorrow with U.S. Car makers hoping to make new inroads into European markets due to the cheap dollar, automobile executives said. Ford Motor Co and General Motors Corp sell cars in Europe, where about 10.5 mln new cars a year are bought. GM also makes a few thousand in North American plants for European export.\"\"\",\n",
        "             ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hm2G1yAsHTGH"
      },
      "source": [
        "## 4. Download lemma reference file. (you may also use a pre-trained lemmatization model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezbuthMzeYDf",
        "outputId": "82deb84b-18a3-49e2-e684-f61b27c9373a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-01-08 19:20:10--  https://raw.githubusercontent.com/mahavivo/vocabulary/master/lemmas/AntBNC_lemmas_ver_001.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1348552 (1.3M) [text/plain]\n",
            "Saving to: ‘AntBNC_lemmas_ver_001.txt’\n",
            "\n",
            "AntBNC_lemmas_ver_0 100%[===================>]   1.29M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2022-01-08 19:20:10 (19.2 MB/s) - ‘AntBNC_lemmas_ver_001.txt’ saved [1348552/1348552]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#getting lemma files\n",
        "!wget https://raw.githubusercontent.com/mahavivo/vocabulary/master/lemmas/AntBNC_lemmas_ver_001.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2eJbLJE_-VW"
      },
      "source": [
        "## 5. Define Spark NLP pipleline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IiYxv0mOFIcX"
      },
      "outputs": [],
      "source": [
        "documentAssembler = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "sentenceDetector = SentenceDetector()\\\n",
        "    .setInputCols(['document'])\\\n",
        "    .setOutputCol('sentences')\n",
        "\n",
        "tokenizer = Tokenizer() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "normalizer = Normalizer() \\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"normalized\")\\\n",
        "    .setLowercase(True)\\\n",
        "    .setCleanupPatterns([\"[^\\w\\d\\s]\"])\n",
        "\n",
        "stopwords_cleaner = StopWordsCleaner()\\\n",
        "    .setInputCols(\"token\")\\\n",
        "    .setOutputCol(\"removed_stopwords\")\\\n",
        "    .setCaseSensitive(False)\\\n",
        "\n",
        "stemmer = Stemmer() \\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"stem\")\n",
        "\n",
        "\n",
        "lemmatizer = Lemmatizer() \\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"lemma\") \\\n",
        "    .setDictionary(\"./AntBNC_lemmas_ver_001.txt\", value_delimiter =\"\\t\", key_delimiter = \"->\")\n",
        "\n",
        "nlpPipeline = Pipeline(stages=[documentAssembler,\n",
        "                               sentenceDetector,\n",
        "                               tokenizer,\n",
        "                               normalizer,\n",
        "                               stopwords_cleaner,\n",
        "                               stemmer,\n",
        "                               lemmatizer,\n",
        "                               ])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akv_NYv7MDDw"
      },
      "source": [
        "## 6. Run pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IQm-b5dMMARa"
      },
      "outputs": [],
      "source": [
        "empty_df = spark.createDataFrame([['']]).toDF(\"text\")\n",
        "\n",
        "pipelineModel = nlpPipeline.fit(empty_df)\n",
        "\n",
        "df = spark.createDataFrame(pd.DataFrame({'text':text_list}))\n",
        "result = pipelineModel.transform(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgZ9hnwmMHyO"
      },
      "source": [
        "## 7. Visualize Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBDmM5aRH1zR",
        "outputId": "06ac1050-41d5-4b27-9ac1-543e17878354"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------------------------------------------------------------------------------------------------------------+\n",
            "|sentences                                                                                                       |\n",
            "+----------------------------------------------------------------------------------------------------------------+\n",
            "|The Geneva Motor Show, the first major car show of the year, opens tomorrow with U.S.                           |\n",
            "|Car makers hoping to make new inroads into European markets due to the cheap dollar, automobile executives said.|\n",
            "|Ford Motor Co and General Motors Corp sell cars in Europe, where about 10.5 mln new cars a year are bought.     |\n",
            "|GM also makes a few thousand in North American plants for European export.                                      |\n",
            "+----------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# sentences in the text\n",
        "result.select(F.explode(F.arrays_zip('sentences.result')).alias(\"cols\")) \\\n",
        ".select(F.expr(\"cols['0']\").alias(\"sentences\")).show(truncate=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4ACcIXqGkfl",
        "outputId": "6ddd361b-ac04-42b4-dd8f-982b285b901b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+\n",
            "|tokens  |\n",
            "+--------+\n",
            "|The     |\n",
            "|Geneva  |\n",
            "|Motor   |\n",
            "|Show    |\n",
            "|,       |\n",
            "|the     |\n",
            "|first   |\n",
            "|major   |\n",
            "|car     |\n",
            "|show    |\n",
            "|of      |\n",
            "|the     |\n",
            "|year    |\n",
            "|,       |\n",
            "|opens   |\n",
            "|tomorrow|\n",
            "|with    |\n",
            "|U.S     |\n",
            "|.       |\n",
            "|Car     |\n",
            "+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# tokens in the text\n",
        "result.select(F.explode(F.arrays_zip('token.result')).alias(\"cols\")) \\\n",
        ".select(F.expr(\"cols['0']\").alias(\"tokens\")).show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgB5ZEDxdKah",
        "outputId": "55aa000e-4e01-4727-ce4a-7b6a05753d28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------------+\n",
            "|normalized_tokens|\n",
            "+-----------------+\n",
            "|the              |\n",
            "|geneva           |\n",
            "|motor            |\n",
            "|show             |\n",
            "|the              |\n",
            "|first            |\n",
            "|major            |\n",
            "|car              |\n",
            "|show             |\n",
            "|of               |\n",
            "|the              |\n",
            "|year             |\n",
            "|opens            |\n",
            "|tomorrow         |\n",
            "|with             |\n",
            "|us               |\n",
            "|car              |\n",
            "|makers           |\n",
            "|hoping           |\n",
            "|to               |\n",
            "+-----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# eliminated punctuation\n",
        "result.select(F.explode(F.arrays_zip('normalized.result')).alias(\"cols\")) \\\n",
        ".select(F.expr(\"cols['0']\").alias(\"normalized_tokens\")).show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOGUACIJeeUj",
        "outputId": "543102bb-54e2-4a2b-9d14-dab4347ad0c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------+\n",
            "|token_stems|\n",
            "+-----------+\n",
            "|the        |\n",
            "|geneva     |\n",
            "|motor      |\n",
            "|show       |\n",
            "|,          |\n",
            "|the        |\n",
            "|first      |\n",
            "|major      |\n",
            "|car        |\n",
            "|show       |\n",
            "|of         |\n",
            "|the        |\n",
            "|year       |\n",
            "|,          |\n",
            "|open       |\n",
            "|tomorrow   |\n",
            "|with       |\n",
            "|u.         |\n",
            "|.          |\n",
            "|car        |\n",
            "+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# stemmed tokens\n",
        "result.select(F.explode(F.arrays_zip('stem.result')).alias(\"cols\")) \\\n",
        ".select(F.expr(\"cols['0']\").alias(\"token_stems\")).show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApCB3G-6gGar",
        "outputId": "fc62ff29-1c15-45f3-be94-9f64bc380ab0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------------+\n",
            "|removed_stopwords|\n",
            "+-----------------+\n",
            "|Geneva           |\n",
            "|Motor            |\n",
            "|Show             |\n",
            "|,                |\n",
            "|first            |\n",
            "|major            |\n",
            "|car              |\n",
            "|show             |\n",
            "|year             |\n",
            "|,                |\n",
            "|opens            |\n",
            "|tomorrow         |\n",
            "|U.S              |\n",
            "|.                |\n",
            "|Car              |\n",
            "|makers           |\n",
            "|hoping           |\n",
            "|make             |\n",
            "|new              |\n",
            "|inroads          |\n",
            "+-----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# removed_stopwords\n",
        "result.select(F.explode(F.arrays_zip('removed_stopwords.result')).alias(\"cols\")) \\\n",
        ".select(F.expr(\"cols['0']\").alias(\"removed_stopwords\")).show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQ86qhQmgMbh",
        "outputId": "451c16f7-ec90-42d9-f325-39a1fe9da384"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+\n",
            "|lemma   |\n",
            "+--------+\n",
            "|The     |\n",
            "|Geneva  |\n",
            "|Motor   |\n",
            "|Show    |\n",
            "|,       |\n",
            "|the     |\n",
            "|first   |\n",
            "|major   |\n",
            "|car     |\n",
            "|show    |\n",
            "|of      |\n",
            "|the     |\n",
            "|year    |\n",
            "|,       |\n",
            "|open    |\n",
            "|tomorrow|\n",
            "|with    |\n",
            "|U.S     |\n",
            "|.       |\n",
            "|Car     |\n",
            "+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# lemmatization\n",
        "result.select(F.explode(F.arrays_zip('lemma.result')).alias(\"cols\")) \\\n",
        ".select(F.expr(\"cols['0']\").alias(\"lemma\")).show(truncate=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "TEXT_PREPROCESSING.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "45150093197569bb3a58481dcd32cd1adb45462fa3448719e8ac38ada6166aca"
    },
    "kernelspec": {
      "display_name": "Python 3.6.10 64-bit ('tensorflow2_p36': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
