{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5-final"
    },
    "colab": {
      "name": "SENTENCE_GRAMMAR.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYh5IIU9HiGW"
      },
      "source": [
        "\n",
        "\n",
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/SENTENCE_GRAMMAR.ipynb)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ix3SFqH3HiGf"
      },
      "source": [
        "# **Evaluate Sentence Grammar**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxtLDESgHiGh"
      },
      "source": [
        "## 1. Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKbWBRSQHiGi",
        "outputId": "ee90d15b-b2c7-4bf1-eeb8-2e1fa44a837e"
      },
      "source": [
        "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash\n",
        "# !bash colab.sh\n",
        "# -p is for pyspark\n",
        "# -s is for spark-nlp\n",
        "# !bash colab.sh -p 3.1.1 -s 3.0.1\n",
        "# by default they are set to the latest"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"11.0.10\" 2021-01-19\n",
            "OpenJDK Runtime Environment (build 11.0.10+9-Ubuntu-0ubuntu1.18.04)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.10+9-Ubuntu-0ubuntu1.18.04, mixed mode, sharing)\n",
            "setup Colab for PySpark 3.1.1 and Spark NLP 3.0.0\n",
            "\u001b[K     |████████████████████████████████| 212.3MB 72kB/s \n",
            "\u001b[K     |████████████████████████████████| 143kB 33.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 52.1MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnxLyqnSHiGm"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "import sparknlp\n",
        "from sparknlp.pretrained import PretrainedPipeline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQiESM5JHiGq"
      },
      "source": [
        "## 2. Start Spark Session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FWtHC6nHiGr"
      },
      "source": [
        "spark = sparknlp.start()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYrCKtZnHiGt"
      },
      "source": [
        "## 3. Select the model to use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsB2E2EgHiGu"
      },
      "source": [
        "#MODEL_NAME = 't5_small'\n",
        "MODEL_NAME = 't5_base'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuAeevR0HiGw"
      },
      "source": [
        "## 4 Examples to try on the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O09gwivoHiGx"
      },
      "source": [
        "text_list = ['Anna and Mike is going skiing and they is liked is', 'Anna and Mike like to dance']"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1KfPRGgHiGz"
      },
      "source": [
        "## 5. Define the Spark NLP pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hW8XwHkQHiG3"
      },
      "source": [
        "The `T5 Transformer` model is able to perform 18 different tasks (ref.: [this paper](https://arxiv.org/abs/1910.10683)). To check the grammar in a sentence, we use the prefix `cola sentence:` in the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbPr97XdHiG4"
      },
      "source": [
        "# Prefix to be used on the T5Transformer().setTask(<<prefix>>)\n",
        "task_prefix = 'cola sentence:'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvfrQB4KHiG5",
        "outputId": "c9b62a40-70e3-4294-b71b-7c09ac5fb2d9"
      },
      "source": [
        "document_assembler = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"documents\")\n",
        "\n",
        "t5 = T5Transformer() \\\n",
        "    .pretrained(MODEL_NAME) \\\n",
        "    .setTask(task_prefix)\\\n",
        "    .setMaxOutputLength(200)\\\n",
        "    .setInputCols([\"documents\"]) \\\n",
        "    .setOutputCol(\"T5\")\n",
        "\n",
        "pipeline = Pipeline(stages=[document_assembler, t5])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "t5_base download started this may take some time.\n",
            "Approximate size to download 446 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6ybagtcHiG6"
      },
      "source": [
        "## 6. Run the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJUb7cqTHiG7"
      },
      "source": [
        "# Fit on empty data frame (model is pretrained)\n",
        "empty_df = spark.createDataFrame([['']]).toDF('text')\n",
        "pipeline_model = pipeline.fit(empty_df)\n",
        "\n",
        "# Create Light Pipeline\n",
        "lmodel = LightPipeline(pipeline_model)\n",
        "\n",
        "# Use the model to make predictions\n",
        "res = lmodel.fullAnnotate(text_list)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNOEgryOHiG7"
      },
      "source": [
        "## 7. Visualize the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pioyl037HiG7"
      },
      "source": [
        "Using Light Pipeline:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Yx5Ax21HiG8",
        "outputId": "c6e26766-6377-4b9d-c304-b0f9b8adba85"
      },
      "source": [
        "for r in res:\n",
        "    print(f\"{r['documents'][0].result} => Grammar: {r['T5'][0].result}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Anna and Mike is going skiing and they is liked is => Grammar: unacceptable\n",
            "Anna and Mike like to dance => Grammar: acceptable\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0HjUk75HiG8"
      },
      "source": [
        "Using pipeline model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuagdW8VHiG9"
      },
      "source": [
        "# Send example texts to spark data frame\n",
        "text_df = spark.createDataFrame(pd.DataFrame({'text': text_list}))\n",
        "\n",
        "# Predict with the model\n",
        "result = pipeline_model.transform(text_df)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMTvm6K_HiG-",
        "outputId": "56bd1f73-c3dc-4d77-8e25-76caaecf0749"
      },
      "source": [
        "result.select('text', 'T5.result').show(truncate=False)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------+--------------+\n",
            "|text                                              |result        |\n",
            "+--------------------------------------------------+--------------+\n",
            "|Anna and Mike is going skiing and they is liked is|[unacceptable]|\n",
            "|Anna and Mike like to dance                       |[acceptable]  |\n",
            "+--------------------------------------------------+--------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}