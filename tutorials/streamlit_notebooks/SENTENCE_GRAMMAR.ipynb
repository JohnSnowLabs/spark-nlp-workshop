{
 "cells": [
  {
   "source": [
    "\n",
    "\n",
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/SENTENCE_GRAMMAR.ipynb)\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# **Evaluate Sentence Grammar**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 1. Colab Setup"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install java\n",
    "!apt-get update -qq\n",
    "!apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
    "!java -version\n",
    "\n",
    "# This is only to setup PySpark and Spark NLP on Colab\n",
    "# -p is for pyspark\n",
    "# -s is for spark-nlp\n",
    "# !bash colab_setup.sh -p 3.1.1 -s 3.0.0  \n",
    "# by default they are set to the latest\n",
    "\n",
    "!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/colab_setup.sh\n",
    "!bash colab_setup.sh\n",
    "\n",
    "# Update environmental variables\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import *\n",
    "import sparknlp\n",
    "from sparknlp.pretrained import PretrainedPipeline"
   ]
  },
  {
   "source": [
    "## 2. Start Spark Session"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = sparknlp.start()"
   ]
  },
  {
   "source": [
    "## 3. Select the model to use"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL_NAME = 't5_small'\n",
    "MODEL_NAME = 't5_base'"
   ]
  },
  {
   "source": [
    "## 4 Examples to try on the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = ['Anna and Mike is going skiing and they is liked is', 'Anna and Mike like to dance']"
   ]
  },
  {
   "source": [
    "## 5. Define the Spark NLP pipeline"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The `T5 Transformer` model is able to perform 18 different tasks (ref.: [this paper](https://arxiv.org/abs/1910.10683)). To check the grammar in a sentence, we use the prefix `cola sentence:` in the model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prefix to be used on the T5Transformer().setTask(<<prefix>>)\n",
    "task_prefix = 'cola sentence:'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "t5_base download started this may take some time.\n",
      "Approximate size to download 446 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "document_assembler = DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"documents\")\n",
    "\n",
    "t5 = T5Transformer() \\\n",
    "    .pretrained(MODEL_NAME) \\\n",
    "    .setTask(task_prefix)\\\n",
    "    .setMaxOutputLength(200)\\\n",
    "    .setInputCols([\"documents\"]) \\\n",
    "    .setOutputCol(\"T5\")\n",
    "\n",
    "pipeline = Pipeline(stages=[document_assembler, t5])"
   ]
  },
  {
   "source": [
    "## 6. Run the pipeline"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit on empty data frame (model is pretrained)\n",
    "empty_df = spark.createDataFrame([['']]).toDF('text')\n",
    "pipeline_model = pipeline.fit(empty_df)\n",
    "\n",
    "# Create Light Pipeline\n",
    "lmodel = LightPipeline(pipeline_model)\n",
    "\n",
    "# Use the model to make predictions\n",
    "res = lmodel.fullAnnotate(text_list)"
   ]
  },
  {
   "source": [
    "## 7. Visualize the results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Using Light Pipeline:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Anna and Mike is going skiing and they is liked is => Grammar: unacceptable\nAnna and Mike like to dance => Grammar: acceptable\n"
     ]
    }
   ],
   "source": [
    "for r in res:\n",
    "    print(f\"{r['documents'][0].result} => Grammar: {r['T5'][0].result}\")"
   ]
  },
  {
   "source": [
    "Using pipeline model:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send example texts to spark data frame\n",
    "text_df = spark.createDataFrame(pd.DataFrame({'text': text_list}))\n",
    "\n",
    "# Predict with the model\n",
    "result = pipeline_model.transform(text_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------------------------------------+--------------+\n|text                                              |result        |\n+--------------------------------------------------+--------------+\n|Anna and Mike is going skiing and they is liked is|[unacceptable]|\n|Anna and Mike like to dance                       |[acceptable]  |\n+--------------------------------------------------+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "result.select('text', 'T5.result').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}