{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vXYNX2lQROB"
      },
      "source": [
        "\n",
        "\n",
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_HINDI_ENGLISH.ipynb)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRsj9Vs4S5dM"
      },
      "source": [
        "# **Detect Entities in hindi and english language texts**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0mz2_alr3An"
      },
      "source": [
        "## 1. Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tpW5nkMc53m",
        "outputId": "02e870b7-7ab0-444a-87db-abe6ac0e7772"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-13 15:48:41--  http://setup.johnsnowlabs.com/colab.sh\n",
            "Resolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 51.158.130.125\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://setup.johnsnowlabs.com/colab.sh [following]\n",
            "--2021-12-13 15:48:43--  https://setup.johnsnowlabs.com/colab.sh\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh [following]\n",
            "--2021-12-13 15:48:44--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1275 (1.2K) [text/plain]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                   100%[===================>]   1.25K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-12-13 15:48:44 (48.8 MB/s) - written to stdout [1275/1275]\n",
            "\n",
            "setup Colab for PySpark 3.0.3 and Spark NLP 3.3.4\n",
            "Installing PySpark 3.0.3 and Spark NLP 3.3.4\n",
            "\u001b[K     |████████████████████████████████| 209.1 MB 58 kB/s \n",
            "\u001b[K     |████████████████████████████████| 133 kB 49.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 198 kB 57.4 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "! wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Start Spark Session"
      ],
      "metadata": {
        "id": "6UD239FZuKUG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbNneAVCLU1y"
      },
      "outputs": [],
      "source": [
        "import sparknlp\n",
        "# let's start Spark with Spark NLP\n",
        "spark = sparknlp.start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIGUfEtSDbEi"
      },
      "outputs": [],
      "source": [
        "import sparknlp\n",
        "import pandas as pd\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "from tabulate import tabulate\n",
        "import sparknlp\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Define Spark NLP pipeline"
      ],
      "metadata": {
        "id": "Fh2em__AuPiA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gvn2hTw6DbIH"
      },
      "outputs": [],
      "source": [
        "document_assembler = DocumentAssembler()\\\n",
        "    .setInputCol('text')\\\n",
        "    .setOutputCol('document')\n",
        "\n",
        "sentence_detector = SentenceDetector() \\\n",
        "    .setInputCols(['document'])\\\n",
        "    .setOutputCol('sentence')\n",
        "\n",
        "tokenizer = Tokenizer()\\\n",
        "    .setInputCols(['sentence']) \\\n",
        "    .setOutputCol('token')\n",
        "\n",
        "tokenClassifier_loaded = BertForTokenClassification.pretrained(\"bert_token_classifier_hi_en_ner\",\"hi\")\\\n",
        "  .setInputCols([\"sentence\",'token'])\\\n",
        "  .setOutputCol(\"ner\")\n",
        "\n",
        "ner_converter = NerConverter()\\\n",
        "        .setInputCols([\"sentence\",\"token\",\"ner\"])\\\n",
        "        .setOutputCol(\"ner_chunk\")\n",
        "        \n",
        "nlp_pipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, tokenClassifier_loaded, ner_converter])\n",
        "pipeline_model = nlp_pipeline.fit(spark.createDataFrame([[\"\"]]).toDF(\"text\"))\n",
        "result = pipeline_model.transform(spark.createDataFrame([[\"\"\"वॉरेन एडवर्ड बफेट (Warren Buffet) (अगस्त 30 (August 30), 1930 को ओमाहा (Omaha), नेब्रास्का (Nebraska) में पैदा हुए) एक अमेरिकी निवेशक (investor), व्यवसायी और परोपकारी (philanthropist) व्यक्तित्व हैं।\"\"\"]], [\"text\"]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Visualize results"
      ],
      "metadata": {
        "id": "zOwCDY-RuTDU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOjcmo25Ds-J",
        "outputId": "79e233c5-6a4a-49a7-9fb1-d34bd5dfb2e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+---------+\n",
            "|chunk            |ner_label|\n",
            "+-----------------+---------+\n",
            "|वॉरेन एडवर्ड बफेट|PERSON   |\n",
            "|Warren Buffet    |PERSON   |\n",
            "|ओमाहा            |PLACE    |\n",
            "|Omaha            |PLACE    |\n",
            "|नेब्रास्का       |PLACE    |\n",
            "|Nebraska         |PLACE    |\n",
            "+-----------------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result.select(F.explode(F.arrays_zip('ner_chunk.result', 'ner_chunk.metadata')).alias(\"cols\")) \\\n",
        "      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
        "              F.expr(\"cols['1']['entity']\").alias(\"ner_label\"))\\\n",
        "      .show(truncate=False)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "NER_HINDI_ENGLISH.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}