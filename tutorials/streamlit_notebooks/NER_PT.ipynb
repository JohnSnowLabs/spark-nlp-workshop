{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER_PT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TA21Jo5d9SVq"
      },
      "source": [
        "\n",
        "\n",
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_PT.ipynb)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzIdjHkAW8TB"
      },
      "source": [
        "# **Detect entities in Portuguese text**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIeCOiJNW-88"
      },
      "source": [
        "## 1. Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGJktFHdHL1n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56ea355d-ca0b-4894-ce76-fe9b73723f15"
      },
      "source": [
        "# Install java\n",
        "!apt-get update -qq\n",
        "!apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "!java -version\n",
        "\n",
        "# This is only to setup PySpark and Spark NLP on Colab\n",
        "# -p is for pyspark\n",
        "# -s is for spark-nlp\n",
        "# !bash colab_setup.sh -p 3.1.1 -s 3.0.0  \n",
        "# by default they are set to the latest\n",
        "\n",
        "!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/colab_setup.sh\n",
        "!bash colab_setup.sh -p 3.1.1 -s 3.0.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"11.0.10\" 2021-01-19\n",
            "OpenJDK Runtime Environment (build 11.0.10+9-Ubuntu-0ubuntu1.18.04)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.10+9-Ubuntu-0ubuntu1.18.04, mixed mode, sharing)\n",
            "setup Colab for PySpark 3.1.1 and Spark NLP 3.0.0\n",
            "\u001b[K     |████████████████████████████████| 212.3MB 61kB/s \n",
            "\u001b[K     |████████████████████████████████| 143kB 53.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 53.8MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCIT5VLxS3I1"
      },
      "source": [
        "## 2. Start the Spark session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sw-t1zxlHTB7"
      },
      "source": [
        "import os\n",
        "import json\n",
        "os.environ['JAVA_HOME'] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "import sparknlp\n",
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "\n",
        "spark = sparknlp.start()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RgiqfX5XDqb"
      },
      "source": [
        "## 3. Select the DL model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLuDz_t40be4"
      },
      "source": [
        "# If you change the model, re-run all the cells below.\n",
        "# Applicable models: wikiner_840B_300, wikiner_6B_300, wikiner_6B_100\n",
        "MODEL_NAME = \"wikiner_840B_300\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Y9GpdJhXIpD"
      },
      "source": [
        "## 4. Some sample examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBOKkB2THdGI"
      },
      "source": [
        "# Enter examples to be transformed as strings in this list\n",
        "text_list = [\n",
        "    \"\"\"William Henry Gates III (nascido em 28 de outubro de 1955) é um magnata americano de negócios, desenvolvedor de software, investidor e filantropo. Ele é mais conhecido como co-fundador da Microsoft Corporation. Durante sua carreira na Microsoft, Gates ocupou os cargos de presidente, diretor executivo (CEO), presidente e diretor de arquitetura de software, além de ser o maior acionista individual até maio de 2014. Ele é um dos empreendedores e pioneiros mais conhecidos da revolução dos microcomputadores nas décadas de 1970 e 1980. Nascido e criado em Seattle, Washington, Gates co-fundou a Microsoft com o amigo de infância Paul Allen em 1975, em Albuquerque, Novo México; tornou-se a maior empresa de software de computador pessoal do mundo. Gates liderou a empresa como presidente e CEO até deixar o cargo em janeiro de 2000, mas ele permaneceu como presidente e tornou-se arquiteto-chefe de software. No final dos anos 90, Gates foi criticado por suas táticas de negócios, que foram consideradas anticompetitivas. Esta opinião foi confirmada por várias decisões judiciais. Em junho de 2006, Gates anunciou que iria passar para um cargo de meio período na Microsoft e trabalhar em período integral na Fundação Bill & Melinda Gates, a fundação de caridade privada que ele e sua esposa, Melinda Gates, estabeleceram em 2000. [ 9] Ele gradualmente transferiu seus deveres para Ray Ozzie e Craig Mundie. Ele deixou o cargo de presidente da Microsoft em fevereiro de 2014 e assumiu um novo cargo como consultor de tecnologia para apoiar a recém-nomeada CEO Satya Nadella.\"\"\",\n",
        "    \"\"\"A Mona Lisa é uma pintura a óleo do século XVI, criada por Leonardo. É realizada no Louvre, em Paris.\"\"\"\n",
        "]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XftYgju4XOw_"
      },
      "source": [
        "## 5. Define Spark NLP pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBggF5P8J1gc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4627510-cd6d-4f8b-a1d3-db7c41ac910a"
      },
      "source": [
        "document_assembler = DocumentAssembler() \\\n",
        "    .setInputCol('text') \\\n",
        "    .setOutputCol('document')\n",
        "\n",
        "tokenizer = Tokenizer() \\\n",
        "    .setInputCols(['document']) \\\n",
        "    .setOutputCol('token')\n",
        "\n",
        "# The wikiner_840B_300 is trained with glove_840B_300, so the embeddings in the\n",
        "# pipeline should match. Same applies for the other available models.\n",
        "if MODEL_NAME == \"wikiner_840B_300\":\n",
        "    embeddings = WordEmbeddingsModel.pretrained('glove_840B_300', lang='xx') \\\n",
        "        .setInputCols(['document', 'token']) \\\n",
        "        .setOutputCol('embeddings')\n",
        "elif MODEL_NAME == \"wikiner_6B_300\":\n",
        "    embeddings = WordEmbeddingsModel.pretrained('glove_6B_300', lang='xx') \\\n",
        "        .setInputCols(['document', 'token']) \\\n",
        "        .setOutputCol('embeddings')\n",
        "elif MODEL_NAME == \"wikiner_6B_100\":\n",
        "    embeddings = WordEmbeddingsModel.pretrained('glove_100d') \\\n",
        "        .setInputCols(['document', 'token']) \\\n",
        "        .setOutputCol('embeddings')\n",
        "\n",
        "ner_model = NerDLModel.pretrained(MODEL_NAME, 'pt') \\\n",
        "    .setInputCols(['document', 'token', 'embeddings']) \\\n",
        "    .setOutputCol('ner')\n",
        "\n",
        "ner_converter = NerConverter() \\\n",
        "    .setInputCols(['document', 'token', 'ner']) \\\n",
        "    .setOutputCol('ner_chunk')\n",
        "\n",
        "nlp_pipeline = Pipeline(stages=[\n",
        "    document_assembler, \n",
        "    tokenizer,\n",
        "    embeddings,\n",
        "    ner_model,\n",
        "    ner_converter\n",
        "])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "glove_840B_300 download started this may take some time.\n",
            "Approximate size to download 2.3 GB\n",
            "[OK!]\n",
            "wikiner_840B_300 download started this may take some time.\n",
            "Approximate size to download 14.5 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv0abcwhXWC-"
      },
      "source": [
        "## 6. Run the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYf_9sXDXR4t"
      },
      "source": [
        "empty_df = spark.createDataFrame([['']]).toDF('text')\n",
        "pipeline_model = nlp_pipeline.fit(empty_df)\n",
        "df = spark.createDataFrame(pd.DataFrame({'text': text_list}))\n",
        "result = pipeline_model.transform(df)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQY8tAP6XZJL"
      },
      "source": [
        "## 7. Visualize results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ar32BZu7J79X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66830739-c711-43d4-b1f1-c4ec3a4431a9"
      },
      "source": [
        "result.select(\n",
        "    F.explode(\n",
        "        F.arrays_zip('ner_chunk.result', 'ner_chunk.metadata')\n",
        "    ).alias(\"cols\")\n",
        ").select(\n",
        "    F.expr(\"cols['0']\").alias('chunk'),\n",
        "    F.expr(\"cols['1']['entity']\").alias('ner_label')\n",
        ").show(truncate=False)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------------+---------+\n",
            "|chunk                  |ner_label|\n",
            "+-----------------------+---------+\n",
            "|William Henry Gates III|PER      |\n",
            "|Ele                    |PER      |\n",
            "|Microsoft Corporation  |ORG      |\n",
            "|Durante                |PER      |\n",
            "|Microsoft              |ORG      |\n",
            "|Gates                  |PER      |\n",
            "|CEO                    |ORG      |\n",
            "|Nascido                |PER      |\n",
            "|Seattle                |LOC      |\n",
            "|Washington             |LOC      |\n",
            "|Gates                  |PER      |\n",
            "|Microsoft              |ORG      |\n",
            "|Paul Allen             |PER      |\n",
            "|Albuquerque            |LOC      |\n",
            "|Novo México            |LOC      |\n",
            "|Gates                  |PER      |\n",
            "|CEO                    |ORG      |\n",
            "|Gates                  |PER      |\n",
            "|Esta opinião           |MISC     |\n",
            "|Gates                  |PER      |\n",
            "+-----------------------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}