{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Detect entities in Turkish text**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Colab Setup, loading necassary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install java\n",
    "!apt-get update -qq\n",
    "!apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
    "!java -version\n",
    "\n",
    "# This is only to setup PySpark and Spark NLP on Colab\n",
    "# -p is for pyspark\n",
    "# -s is for spark-nlp\n",
    "# !bash colab_setup.sh -p 3.1.1 -s 3.0.0  \n",
    "# by default they are set to the latest\n",
    "\n",
    "!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/colab_setup.sh\n",
    "!bash colab_setup.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "import json\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import *\n",
    "import sparknlp\n",
    "from sparknlp.pretrained import PretrainedPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Start the Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.4'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Select the DL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you change the model, re-run all the cells below.\n",
    "# Applicable models: \"glove_840B_300\" and \"bert_multi_cased\"\n",
    "\n",
    "#MODEL_NAME = 'turkish_ner_840B_300'\n",
    "MODEL_NAME = \"turkish_ner_bert\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Some sample examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter examples to be transformed as strings in this list\n",
    "\n",
    "text_list = [\"\"\"William Henry Gates III (28 Ekim 1955 doğumlu), Amerikalı bir iş adamı, \\\n",
    "yazılım geliştirici, yatırımcı ve hayırseverdir. En çok Microsoft şirketinin kurucu \\\n",
    "ortağı olarak bilinir. William Gates , Microsoft şirketindeki kariyeri boyunca başkan, \\\n",
    "icra kurulu başkanı, başkan ve yazılım mimarisi başkanı pozisyonlarında bulunmuş, \\\n",
    "aynı zamanda Mayıs 2014'e kadar en büyük bireysel hissedar olmuştur. O, 1970'lerin \\\n",
    "ve 1980'lerin mikrobilgisayar devriminin en tanınmış girişimcilerinden ve öncülerinden biridir. \\\n",
    "Seattle Washington'da doğup büyüyen William Gates, 1975'te New Mexico Albuquerque'de \\\n",
    "çocukluk arkadaşı Paul Allen ile Microsoft şirketini kurdu; dünyanın en büyük kişisel \\\n",
    "bilgisayar yazılım şirketi haline geldi. William Gates, Ocak 2000'de icra kurulu başkanı \\\n",
    "olarak istifa edene kadar şirketi başkan ve icra kurulu başkanı olarak yönetti ve \\\n",
    "daha sonra yazılım mimarisi başkanı oldu. 1990'ların sonlarında, William Gates rekabete \\\n",
    "aykırı olduğu düşünülen iş taktikleri nedeniyle eleştirilmişti. Bu görüş, çok sayıda \\\n",
    "mahkeme kararıyla onaylanmıştır. Haziran 2006'da William Gates, Microsoft şirketinde \\\n",
    "yarı zamanlı bir göreve ve 2000 yılında eşi Melinda Gates ile birlikte kurdukları özel \\\n",
    "hayır kurumu olan B&Melinda G. Vakfı'nda tam zamanlı çalışmaya geçeceğini duyurdu. \\\n",
    "Görevlerini kademeli olarak Ray Ozzie ve Craig Mundie'ye devretti. Şubat 2014'te \\\n",
    "Microsoft başkanlığından ayrıldı ve yeni atanan icra kurulu başkanı, Satya Nadella'yı \\\n",
    "desteklemek için teknoloji danışmanı olarak yeni bir göreve başladı.\"\"\",\n",
    "    \n",
    "\"Mona Lisa, Leonardo tarafından yaratılan 16. yüzyıldan kalma bir yağlı boya tablodur. \\\n",
    "Tablo, Paris'teki Louvre Müzesi'nde sergileniyor.\",\n",
    "             \n",
    "\"\"\"Facebook, 4 Şubat 2004 tarihinde TheFacebook adıyla başlatılan bir sosyal ağ hizmetidir. \\\n",
    "Mark Zuckerberg tarafından üniversite oda arkadaşları ve Harvard Üniversitesi öğrencileri \\\n",
    "Eduardo Saverin, Andrew McCollum, Dustin Moskovitz ve Chris Hughes ile birlikte kurulmuştur. \\\n",
    "Web sitesinin üyeliği başlangıçta kurucular tarafından Harvard öğrencileriyle sınırlıydı, ancak \\\n",
    "Boston bölgesindeki diğer kolejlere, Ivy-Ligine ve kademeli olarak ABD ve Kanada'daki çoğu üniversiteye genişletildi.\"\"\",\n",
    "            \n",
    "\"\"\"Geoffrey Everest Hinton, çoğu yapay sinir ağları üzerine yaptığı çalışmalarla tanınan \\\n",
    "İngiliz Kanadalı bir bilişsel psikolog ve bilgisayar bilimcisidir. 2013'ten beri zamanını \\\n",
    "Google ve Toronto Üniversitesi için ikiye ayırıyor. 2017 yılında, Toronto'da bulunan \\\n",
    "V. Enstitüsü'nün kurucu ortağı ve Bilimsel Konular Başdanışmanı oldu.\"\"\",\n",
    "             \n",
    "\"\"\"John Snow'a, Alaska'ya taşınmak istediğimi söylediğimde, orada bir Starbucks \\\n",
    "Cafe firması bulmakta zorlanacağım konusunda beni uyardı.\"\"\"\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Define Spark NLP pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_multi_cased download started this may take some time.\n",
      "Approximate size to download 638.6 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "documentAssembler = DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "sentenceDetector = SentenceDetector()\\\n",
    "  .setInputCols([\"document\"])\\\n",
    "  .setOutputCol(\"sentence\")\n",
    "\n",
    "tokenizer = Tokenizer()\\\n",
    "  .setInputCols([\"sentence\"])\\\n",
    "  .setOutputCol(\"token\")\n",
    "\n",
    "embeddings = None\n",
    "public_ner = None\n",
    "\n",
    "if MODEL_NAME == 'turkish_ner_840B_300' :\n",
    "    embeddings = WordEmbeddingsModel.pretrained(model_dict[MODEL_NAME], \"xx\").\\\n",
    "                    setInputCols([\"sentence\", 'token']).\\\n",
    "                    setOutputCol(\"embeddings\").\\\n",
    "                    setCaseSensitive(True)\n",
    "\n",
    "    public_ner = NerDLModel.pretrained(MODEL_NAME, 'tr') \\\n",
    "              .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "              .setOutputCol(\"ner\")\n",
    "    \n",
    "elif MODEL_NAME == 'turkish_ner_bert' :\n",
    "    embeddings = BertEmbeddings.pretrained(model_dict[MODEL_NAME], 'xx') \\\n",
    "        .setInputCols([\"sentence\", \"token\"])\\\n",
    "        .setOutputCol(\"embeddings\")\n",
    "\n",
    "    public_ner = NerDLModel.pretrained(MODEL_NAME, 'tr') \\\n",
    "              .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "              .setOutputCol(\"ner\")\n",
    "\n",
    "ner_converter = NerConverter() \\\n",
    "                .setInputCols([\"sentence\", \"token\", \"ner\"]) \\\n",
    "                  .setOutputCol(\"ner_chunk\")\n",
    "\n",
    "nlp_pipeline = Pipeline(stages=[ documentAssembler, sentenceDetector,\n",
    "                                 tokenizer,\n",
    "                                 embeddings,\n",
    "                                 public_ner,\n",
    "                                 ner_converter\n",
    "                                 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Run the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_df = spark.createDataFrame([['']]).toDF('text')\n",
    "pipeline_model = nlp_pipeline.fit(empty_df)\n",
    "df = spark.createDataFrame(pd.DataFrame({'text': text_list}))\n",
    "result = pipeline_model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+---------+\n",
      "|chunk                 |ner_label|\n",
      "+----------------------+---------+\n",
      "|William Henry Gates   |PER      |\n",
      "|Microsoft             |ORG      |\n",
      "|William Gates         |PER      |\n",
      "|Microsoft             |ORG      |\n",
      "|William Gates         |PER      |\n",
      "|New Mexico            |ORG      |\n",
      "|Albuquerque'de        |LOC      |\n",
      "|Paul Allen            |PER      |\n",
      "|Microsoft             |ORG      |\n",
      "|William Gates         |PER      |\n",
      "|William Gates         |PER      |\n",
      "|William Gates         |PER      |\n",
      "|Microsoft             |ORG      |\n",
      "|Melinda Gates         |PER      |\n",
      "|B&Melinda G. Vakfı'nda|ORG      |\n",
      "|Ray Ozzie             |PER      |\n",
      "|Craig Mundie'ye       |PER      |\n",
      "|Microsoft             |ORG      |\n",
      "|Satya Nadella'yı      |PER      |\n",
      "|John Snow             |PER      |\n",
      "+----------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.select(F.explode(F.arrays_zip('ner_chunk.result', 'ner_chunk.metadata')).alias(\"cols\")) \\\n",
    ".select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
    "        F.expr(\"cols['1']['entity']\").alias(\"ner_label\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}