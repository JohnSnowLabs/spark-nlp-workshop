{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SENTIMENT_SW.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kmy22Of4SZSh"
      },
      "source": [
        "\n",
        "\n",
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/SENTIMENT_SW.ipynb)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRsj9Vs4S5dM"
      },
      "source": [
        "# **Sentiment Analysis of Swahili texts**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9DQgBorTKx0"
      },
      "source": [
        "## 1. Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzEcEZrbSbnf",
        "outputId": "dc282644-d445-4db1-990c-370717203a92"
      },
      "source": [
        "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-12 10:39:48--  http://setup.johnsnowlabs.com/colab.sh\n",
            "Resolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 51.158.130.125\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://setup.johnsnowlabs.com/colab.sh [following]\n",
            "--2022-01-12 10:39:48--  https://setup.johnsnowlabs.com/colab.sh\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh [following]\n",
            "--2022-01-12 10:39:49--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1453 (1.4K) [text/plain]\n",
            "Saving to: â€˜STDOUTâ€™\n",
            "\n",
            "-                   100%[===================>]   1.42K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-01-12 10:39:49 (21.1 MB/s) - written to stdout [1453/1453]\n",
            "\n",
            "setup Colab for PySpark 3.0.3 and Spark NLP 3.4.0\n",
            "Installing PySpark 3.0.3 and Spark NLP 3.4.0\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 209.1 MB 64 kB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 140 kB 45.3 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 198 kB 36.9 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ChQNQEfuWsrR",
        "outputId": "ca566dbc-b054-4ebe-cd6f-c6607c0e5941"
      },
      "source": [
        "!pip install --ignore-installed spark-nlp-display"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting spark-nlp-display\n",
            "  Downloading spark_nlp_display-1.8-py3-none-any.whl (95 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 95 kB 2.1 MB/s \n",
            "\u001b[?25hCollecting svgwrite==1.4\n",
            "  Downloading svgwrite-1.4-py3-none-any.whl (66 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66 kB 3.6 MB/s \n",
            "\u001b[?25hCollecting numpy\n",
            "  Downloading numpy-1.21.5-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15.7 MB 42.4 MB/s \n",
            "\u001b[?25hCollecting ipython\n",
            "  Downloading ipython-7.31.0-py3-none-any.whl (792 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 792 kB 45.8 MB/s \n",
            "\u001b[?25hCollecting pandas\n",
            "  Downloading pandas-1.3.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11.3 MB 31.8 MB/s \n",
            "\u001b[?25hCollecting spark-nlp\n",
            "  Using cached spark_nlp-3.4.0-py2.py3-none-any.whl (140 kB)\n",
            "Collecting pygments\n",
            "  Downloading Pygments-2.11.2-py3-none-any.whl (1.1 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1 MB 41.3 MB/s \n",
            "\u001b[?25hCollecting matplotlib-inline\n",
            "  Downloading matplotlib_inline-0.1.3-py3-none-any.whl (8.2 kB)\n",
            "Collecting backcall\n",
            "  Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n",
            "  Downloading prompt_toolkit-3.0.24-py3-none-any.whl (374 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 374 kB 46.1 MB/s \n",
            "\u001b[?25hCollecting traitlets>=4.2\n",
            "  Downloading traitlets-5.1.1-py3-none-any.whl (102 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102 kB 8.6 MB/s \n",
            "\u001b[?25hCollecting pexpect>4.3\n",
            "  Downloading pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 59 kB 5.0 MB/s \n",
            "\u001b[?25hCollecting pickleshare\n",
            "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
            "Collecting jedi>=0.16\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.6 MB 37.9 MB/s \n",
            "\u001b[?25hCollecting decorator\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting setuptools>=18.5\n",
            "  Downloading setuptools-60.5.0-py3-none-any.whl (958 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 958 kB 42.8 MB/s \n",
            "\u001b[?25hCollecting parso<0.9.0,>=0.8.0\n",
            "  Downloading parso-0.8.3-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100 kB 9.4 MB/s \n",
            "\u001b[?25hCollecting ptyprocess>=0.5\n",
            "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
            "Collecting wcwidth\n",
            "  Downloading wcwidth-0.2.5-py2.py3-none-any.whl (30 kB)\n",
            "Collecting python-dateutil>=2.7.3\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 247 kB 31.8 MB/s \n",
            "\u001b[?25hCollecting pytz>=2017.3\n",
            "  Downloading pytz-2021.3-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 503 kB 43.0 MB/s \n",
            "\u001b[?25hCollecting six>=1.5\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Installing collected packages: wcwidth, traitlets, six, ptyprocess, parso, setuptools, pytz, python-dateutil, pygments, prompt-toolkit, pickleshare, pexpect, numpy, matplotlib-inline, jedi, decorator, backcall, svgwrite, spark-nlp, pandas, ipython, spark-nlp-display\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.3.post1 requires numpy<1.20,>=1.16.0, but you have numpy 1.21.5 which is incompatible.\n",
            "nbclient 0.5.9 requires jupyter-client>=6.1.5, but you have jupyter-client 5.3.5 which is incompatible.\n",
            "moviepy 0.2.3.5 requires decorator<5.0,>=4.0.2, but you have decorator 5.1.1 which is incompatible.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.24 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.31.0 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas~=1.1.0; python_version >= \"3.0\", but you have pandas 1.3.5 which is incompatible.\n",
            "google-colab 1.0.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed backcall-0.2.0 decorator-5.1.1 ipython-7.31.0 jedi-0.18.1 matplotlib-inline-0.1.3 numpy-1.21.5 pandas-1.3.5 parso-0.8.3 pexpect-4.8.0 pickleshare-0.7.5 prompt-toolkit-3.0.24 ptyprocess-0.7.0 pygments-2.11.2 python-dateutil-2.8.2 pytz-2021.3 setuptools-60.5.0 six-1.16.0 spark-nlp-3.4.0 spark-nlp-display-1.8 svgwrite-1.4 traitlets-5.1.1 wcwidth-0.2.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "IPython",
                  "dateutil",
                  "decorator",
                  "numpy",
                  "pandas",
                  "pexpect",
                  "pickleshare",
                  "pkg_resources",
                  "prompt_toolkit",
                  "pygments",
                  "pytz",
                  "six",
                  "traitlets",
                  "wcwidth"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o78aqL2VTOFU"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "import sparknlp\n",
        "from sparknlp.pretrained import PretrainedPipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUtHfXX6TT5T"
      },
      "source": [
        "## 2. Start Spark Session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjMiR2b6TOM9"
      },
      "source": [
        "spark = sparknlp.start()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-me64q5WTex8"
      },
      "source": [
        "## 3. Some sample examples"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_list=[\"\"\"Tukio bora katika sinema ilikuwa wakati Gerardo anajaribu kupata wimbo ambao unaendelea kupitia kichwa chake.\"\"\",\"\"\"ni dharau kwa akili ya mtu na upotezaji mkubwa wa pesa\"\"\",\"\"\"Kris Kristoffersen ni mzuri kwenye sinema hii na kweli hufanya tofauti.\"\"\",\"\"\"Hadithi yenyewe ni ya kutabirika tu na ya uvivu.\"\"\",\"\"\"ninapendekeza hizi kwa kuwa zinaonekana nzuri sana, kifahari na nzuri\"\"\",\"\"\"Safaricom si muache kucheza na mkopo wa nambari yangu tafadhali. mnanifilisishaðŸ˜“ðŸ˜“ðŸ˜¯\"\"\",\"\"\"Bidhaa ilikuwa bora na inafanya kazi vizuri kuliko ya verizon na bei ilikuwa rahisi \"\"\",\"\"\"Siwezi kuona jinsi sinema hii inavyoweza kuwa msukumo kwa mtu yeyote kushinda woga na kukataliwa.\"\"\",\"\"\"Sinema hii inasawazishwa vizuri na vichekesho na mchezo wa kuigiza na nilijifurahisha sana.\"\"\"]"
      ],
      "metadata": {
        "id": "moNYRtej_8AD"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lwQIiLPTzat"
      },
      "source": [
        "## 4. Define Spark NLP pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GImc405eTOSK",
        "outputId": "3553075c-b43f-47e7-ede0-7fbc1e9dc955"
      },
      "source": [
        "document_assembler = DocumentAssembler() \\\n",
        "      .setInputCol(\"text\") \\\n",
        "      .setOutputCol(\"document\")\n",
        "\n",
        "tokenizer = Tokenizer() \\\n",
        "      .setInputCols([\"document\"]) \\\n",
        "      .setOutputCol(\"token\")\n",
        "    \n",
        "normalizer = Normalizer() \\\n",
        "      .setInputCols([\"token\"]) \\\n",
        "      .setOutputCol(\"normalized\")\n",
        "\n",
        "stopwords_cleaner = StopWordsCleaner.pretrained(\"stopwords_sw\", \"sw\") \\\n",
        "        .setInputCols([\"normalized\"]) \\\n",
        "        .setOutputCol(\"cleanTokens\")\\\n",
        "        .setCaseSensitive(False)\n",
        "\n",
        "embeddings = XlmRoBertaEmbeddings.pretrained(\"xlm_roberta_base_finetuned_swahili\", \"sw\")\\\n",
        "    .setInputCols([\"document\", \"cleanTokens\"])\\\n",
        "    .setOutputCol(\"embeddings\")\n",
        "\n",
        "embeddingsSentence = SentenceEmbeddings() \\\n",
        "      .setInputCols([\"document\", \"embeddings\"]) \\\n",
        "      .setOutputCol(\"sentence_embeddings\") \\\n",
        "      .setPoolingStrategy(\"AVERAGE\")\n",
        "\n",
        "sentimentClassifier = ClassifierDLModel.pretrained(\"classifierdl_xlm_roberta_sentiment\", \"sw\") \\\n",
        "  .setInputCols([\"document\", \"sentence_embeddings\"]) \\\n",
        "  .setOutputCol(\"class\")\n",
        "\n",
        "sw_pipeline = Pipeline(stages=[document_assembler, tokenizer, normalizer, stopwords_cleaner, embeddings, embeddingsSentence, sentimentClassifier])"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stopwords_sw download started this may take some time.\n",
            "Approximate size to download 1.5 KB\n",
            "[OK!]\n",
            "xlm_roberta_base_finetuned_swahili download started this may take some time.\n",
            "Approximate size to download 994.1 MB\n",
            "[OK!]\n",
            "classifierdl_xlm_roberta_sentiment download started this may take some time.\n",
            "Approximate size to download 21.9 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZsG9a2ST70t"
      },
      "source": [
        "## 5. Run the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8k_omsF6T8S0"
      },
      "source": [
        "model = sw_pipeline.fit(spark.createDataFrame(pd.DataFrame({'text': ['']})))\n",
        "\n",
        "result = model.transform(spark.createDataFrame(pd.DataFrame({'text': text_list})))\n"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKVc3bTmVQj3"
      },
      "source": [
        "## 6. Visualize results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kElw6v7iVRea",
        "outputId": "24696ddf-80f5-4848-89dd-3bb64736ab81"
      },
      "source": [
        "\n",
        "result.select(F.explode(F.arrays_zip('document.result', 'class.result')).alias(\"cols\")) \\\n",
        ".select(\n",
        "        F.expr(\"cols['0']\").alias(\"chunk\"),\n",
        "        F.expr(\"cols['1']\").alias('result')).show(truncate=False)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------------------------------------------------------------------------+--------+\n",
            "|chunk                                                                                                        |result  |\n",
            "+-------------------------------------------------------------------------------------------------------------+--------+\n",
            "|Tukio bora katika sinema ilikuwa wakati Gerardo anajaribu kupata wimbo ambao unaendelea kupitia kichwa chake.|Positive|\n",
            "|ni dharau kwa akili ya mtu na upotezaji mkubwa wa pesa                                                       |Negative|\n",
            "|Kris Kristoffersen ni mzuri kwenye sinema hii na kweli hufanya tofauti.                                      |Positive|\n",
            "|Hadithi yenyewe ni ya kutabirika tu na ya uvivu.                                                             |Negative|\n",
            "|ninapendekeza hizi kwa kuwa zinaonekana nzuri sana, kifahari na nzuri                                        |Positive|\n",
            "|Safaricom si muache kucheza na mkopo wa nambari yangu tafadhali. mnanifilisishaðŸ˜“ðŸ˜“ðŸ˜¯                        |Negative|\n",
            "|Bidhaa ilikuwa bora na inafanya kazi vizuri kuliko ya verizon na bei ilikuwa rahisi                          |Positive|\n",
            "|Siwezi kuona jinsi sinema hii inavyoweza kuwa msukumo kwa mtu yeyote kushinda woga na kukataliwa.            |Negative|\n",
            "|Sinema hii inasawazishwa vizuri na vichekesho na mchezo wa kuigiza na nilijifurahisha sana.                  |Positive|\n",
            "+-------------------------------------------------------------------------------------------------------------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "D0ABdhdCDQpY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}