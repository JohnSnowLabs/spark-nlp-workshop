{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDmXsEGhauan"
      },
      "source": [
        "\n",
        "\n",
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/CLASSIFICATION_EN_SPAM.ipynb)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UChknajcavFm"
      },
      "source": [
        "# **Detect Spam messages**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_Zz-kwQa7Ez"
      },
      "source": [
        "## 1. Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIJfXkK54WFk",
        "outputId": "c49f7a46-ec12-4adf-8e5b-d8431ac33d2d"
      },
      "outputs": [],
      "source": [
        "# Install PySpark and Spark NLP\n",
        "! pip install -q pyspark==3.1.2 spark-nlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "v29AZ9XO5AhU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "import sparknlp\n",
        "from sparknlp.pretrained import PretrainedPipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqorlWy9a9pF"
      },
      "source": [
        "## 2. Start Spark Session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sI-CZ9PO5GW9"
      },
      "outputs": [],
      "source": [
        "spark = sparknlp.start()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JaFJmC_bD04"
      },
      "source": [
        "## 3. Select the DL model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Y6s6ljDsH9ZK"
      },
      "outputs": [],
      "source": [
        "### Select Model\n",
        "model_name = 'classifierdl_use_spam'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGttu2LqbAIn"
      },
      "source": [
        "## 4. Some sample examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WGFzBK1EX8wm"
      },
      "outputs": [],
      "source": [
        "text_list=[\n",
        "\"\"\"Hiya do u like the hlday pics looked horrible in them so took mo out! Hows the camp Amrca thing? Speak soon Serena:)\"\"\",\n",
        "\"\"\"U have a secret admirer who is looking 2 make contact with U-find out who they R*reveal who thinks UR so special-call on 09058094594\"\"\",]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcE65Pc0bGPO"
      },
      "source": [
        "## 5. Define Spark NLP pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2CS_jdi5Phc",
        "outputId": "572cb597-56f2-46be-bac2-2c3a6af89bb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tfhub_use download started this may take some time.\n",
            "Approximate size to download 923.7 MB\n",
            "[OK!]\n",
            "classifierdl_use_spam download started this may take some time.\n",
            "Approximate size to download 21.3 MB\n",
            "[OK!]\n"
          ]
        }
      ],
      "source": [
        "documentAssembler = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "use = UniversalSentenceEncoder.pretrained(lang=\"en\") \\\n",
        " .setInputCols([\"document\"])\\\n",
        " .setOutputCol(\"sentence_embeddings\")\n",
        "\n",
        "document_classifier = ClassifierDLModel.pretrained(model_name)\\\n",
        "  .setInputCols(['document', 'sentence_embeddings']).setOutputCol(\"class\")\n",
        "\n",
        "nlpPipeline = Pipeline(stages=[\n",
        " documentAssembler, \n",
        " use,\n",
        " document_classifier\n",
        " ])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1wPffwfbKNb"
      },
      "source": [
        "## 6. Run the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RZxkeqNpbR02"
      },
      "outputs": [],
      "source": [
        "empty_df = spark.createDataFrame([['']]).toDF(\"text\")\n",
        "pipelineModel = nlpPipeline.fit(empty_df)\n",
        "df = spark.createDataFrame(pd.DataFrame({\"text\":text_list}))\n",
        "result = pipelineModel.transform(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nvJc6dwbX9X"
      },
      "source": [
        "## 7. Visualize results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P84W1Z4uPI_b",
        "outputId": "a69457ad-7d09-40c7-e844-70310b496235"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
            "|document                                                                                                                            |class|\n",
            "+------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
            "|Hiya do u like the hlday pics looked horrible in them so took mo out! Hows the camp Amrca thing? Speak soon Serena:)                |ham  |\n",
            "|U have a secret admirer who is looking 2 make contact with U-find out who they R*reveal who thinks UR so special-call on 09058094594|ham  |\n",
            "+------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result.select(F.explode(F.arrays_zip('document.result', 'class.result')).alias(\"cols\")) \\\n",
        ".select(F.expr(\"cols['0']\").alias(\"document\"),\n",
        "        F.expr(\"cols['1']\").alias(\"class\")).show(truncate=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "CLASSIFICATION_EN_SPAM.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
