{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CLASSIFICATION_EN_SPAM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDmXsEGhauan",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/CLASSIFICATION_EN_SPAM.ipynb)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UChknajcavFm",
        "colab_type": "text"
      },
      "source": [
        "# **Detect Spam messages**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_Zz-kwQa7Ez",
        "colab_type": "text"
      },
      "source": [
        "## 0. Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIJfXkK54WFk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sudo apt-get install openjdk-8-jdk\n",
        "!java -version\n",
        "!pip install --ignore-installed -q pyspark==2.4.4\n",
        "!pip install spark-nlp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v29AZ9XO5AhU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "import json\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "import sparknlp\n",
        "from sparknlp.pretrained import PretrainedPipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqorlWy9a9pF",
        "colab_type": "text"
      },
      "source": [
        "## 1. Start Spark Session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sI-CZ9PO5GW9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spark = sparknlp.start()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JaFJmC_bD04",
        "colab_type": "text"
      },
      "source": [
        "## 2. Select the DL model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6s6ljDsH9ZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Select Model\n",
        "model_name = 'classifierdl_use_spam'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGttu2LqbAIn",
        "colab_type": "text"
      },
      "source": [
        "## 3. Some sample examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGFzBK1EX8wm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_list=[\n",
        "\"\"\"Hiya do u like the hlday pics looked horrible in them so took mo out! Hows the camp Amrca thing? Speak soon Serena:)\"\"\",\n",
        "\"\"\"U have a secret admirer who is looking 2 make contact with U-find out who they R*reveal who thinks UR so special-call on 09058094594\"\"\",]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcE65Pc0bGPO",
        "colab_type": "text"
      },
      "source": [
        "## 4. Define Spark NLP pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2CS_jdi5Phc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "documentAssembler = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "use = UniversalSentenceEncoder.pretrained(lang=\"en\") \\\n",
        " .setInputCols([\"document\"])\\\n",
        " .setOutputCol(\"sentence_embeddings\")\n",
        "\n",
        "document_classifier = ClassifierDLModel.pretrained(model_name)\\\n",
        "  .setInputCols(['document', 'sentence_embeddings']).setOutputCol(\"class\")\n",
        "\n",
        "nlpPipeline = Pipeline(stages=[\n",
        " documentAssembler, \n",
        " use,\n",
        " document_classifier\n",
        " ])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1wPffwfbKNb",
        "colab_type": "text"
      },
      "source": [
        "## 5. Run the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZxkeqNpbR02",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "empty_df = spark.createDataFrame([['']]).toDF(\"text\")\n",
        "pipelineModel = nlpPipeline.fit(empty_df)\n",
        "df = spark.createDataFrame(pd.DataFrame({\"text\":text_list}))\n",
        "result = pipelineModel.transform(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nvJc6dwbX9X",
        "colab_type": "text"
      },
      "source": [
        "## 6. Visualize results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P84W1Z4uPI_b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result.select(F.explode(F.arrays_zip('document.result', 'class.result')).alias(\"cols\")) \\\n",
        ".select(F.expr(\"cols['0']\").alias(\"document\"),\n",
        "        F.expr(\"cols['1']\").alias(\"class\")).show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}