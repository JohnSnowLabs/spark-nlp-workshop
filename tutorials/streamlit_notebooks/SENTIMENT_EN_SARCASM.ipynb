{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3efkhhm4OmTE"
      },
      "source": [
        "\n",
        "\n",
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/SENTIMENT_EN_SARCASM.ipynb)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mf8sEImLOeuK"
      },
      "source": [
        "# **Detect Sarcasm in text**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnAbjj-XOkU0"
      },
      "source": [
        "## 1. Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6o8-g0tEqNz",
        "outputId": "3e9384a9-8b17-4117-c077-4f1482149ab3"
      },
      "outputs": [],
      "source": [
        "# Install PySpark and Spark NLP\n",
        "! pip install -q pyspark==3.1.2 spark-nlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yMmT9S6mE0ad"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "import sparknlp\n",
        "from sparknlp.pretrained import PretrainedPipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbcg5L8HOzOT"
      },
      "source": [
        "## 2. Start Spark Session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4zBXbY_vE2ss"
      },
      "outputs": [],
      "source": [
        "spark = sparknlp.start()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toi6M1CCO3EI"
      },
      "source": [
        "## 3. Select the DL model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1XxHWemdE5hX"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME='classifierdl_use_sarcasm'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Z-GzJzRO8_b"
      },
      "source": [
        "## 4. Some sample examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GJ7GCD0pFDvP"
      },
      "outputs": [],
      "source": [
        "## Generating Example Files ##\n",
        "text_list = [\n",
        "             #sarcasm\n",
        "             \"\"\"Love getting home from work knowing that in less than 8hours you're getting up to go back there again.\"\"\",\n",
        "             #neutral\n",
        "             \"\"\"Oh my gosh! Can you imagine @JessieJ playing piano on her tour while singing a song. I would die and go to heaven. #sheisanangel\"\"\",\n",
        "             #sarcasm\n",
        "            \"\"\"Dear Teva, thank you for waking me up every few hours by howling. Your just trying to be mother natures alarm clock.\"\"\",\n",
        "             #neutral\n",
        "             \"\"\"The United States is a signatory to this international convention\"\"\",\n",
        "             #sarcasm\n",
        "             \"\"\"If I could put into words how much I love waking up at am on Tuesdays I would\"\"\",\n",
        "             #neutral\n",
        "             \"\"\"@pdomo Don't forget that Nick Foles is also the new Tom Brady. What a preseason! #toomanystudQBs #thankgodwedonthavetebow\"\"\",\n",
        "             #sarcasm\n",
        "             \"\"\"I cant even describe how excited I am to go cook noodles for hours\"\"\",\n",
        "             #neutral\n",
        "             \"\"\"@Will_Piper should move back up fella. I'm already here... On my own... Having loads of fun\"\"\",\n",
        "             #sarcasm\n",
        "             \"\"\"Tweeting at work... Having sooooo much fun and honestly not bored at all #countdowntillfinish\"\"\",\n",
        "             #neutral\n",
        "             \"\"\"I can do what I want to. I play by my own rules\"\"\",\n",
        "             ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPUC8L81PKsG"
      },
      "source": [
        "## 5. Define Spark NLP pipleline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiYxv0mOFIcX",
        "outputId": "9d8c9474-c0c7-450b-a867-cc5e650312dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tfhub_use download started this may take some time.\n",
            "Approximate size to download 923.7 MB\n",
            "[OK!]\n",
            "classifierdl_use_sarcasm download started this may take some time.\n",
            "Approximate size to download 21.3 MB\n",
            "[OK!]\n"
          ]
        }
      ],
      "source": [
        "documentAssembler = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "    \n",
        "use = UniversalSentenceEncoder.pretrained(name=\"tfhub_use\", lang=\"en\")\\\n",
        " .setInputCols([\"document\"])\\\n",
        " .setOutputCol(\"sentence_embeddings\")\n",
        "\n",
        "\n",
        "sentimentdl = ClassifierDLModel.pretrained(name=MODEL_NAME)\\\n",
        "    .setInputCols([\"sentence_embeddings\"])\\\n",
        "    .setOutputCol(\"sentiment\")\n",
        "\n",
        "nlpPipeline = Pipeline(\n",
        "      stages = [\n",
        "          documentAssembler,\n",
        "          use,\n",
        "          sentimentdl\n",
        "      ])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bezf_8HCPNWS"
      },
      "source": [
        "## 6. Run the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ajXsD_5FPOaD"
      },
      "outputs": [],
      "source": [
        "empty_df = spark.createDataFrame([['']]).toDF(\"text\")\n",
        "\n",
        "pipelineModel = nlpPipeline.fit(empty_df)\n",
        "\n",
        "df = spark.createDataFrame(pd.DataFrame({\"text\":text_list}))\n",
        "result = pipelineModel.transform(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwALixBdPTXh"
      },
      "source": [
        "## 7. Visualize results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzJSQhTnFix5",
        "outputId": "cd07102f-98dc-4db0-d8a5-04c37dd90295"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------------------------------------------------------------------------------------+---------+\n",
            "|document                                                                                                                        |sentiment|\n",
            "+--------------------------------------------------------------------------------------------------------------------------------+---------+\n",
            "|Love getting home from work knowing that in less than 8hours you're getting up to go back there again.                          |sarcasm  |\n",
            "|Oh my gosh! Can you imagine @JessieJ playing piano on her tour while singing a song. I would die and go to heaven. #sheisanangel|normal   |\n",
            "|Dear Teva, thank you for waking me up every few hours by howling. Your just trying to be mother natures alarm clock.            |sarcasm  |\n",
            "|The United States is a signatory to this international convention                                                               |normal   |\n",
            "|If I could put into words how much I love waking up at am on Tuesdays I would                                                   |sarcasm  |\n",
            "|@pdomo Don't forget that Nick Foles is also the new Tom Brady. What a preseason! #toomanystudQBs #thankgodwedonthavetebow       |normal   |\n",
            "|I cant even describe how excited I am to go cook noodles for hours                                                              |sarcasm  |\n",
            "|@Will_Piper should move back up fella. I'm already here... On my own... Having loads of fun                                     |normal   |\n",
            "|Tweeting at work... Having sooooo much fun and honestly not bored at all #countdowntillfinish                                   |sarcasm  |\n",
            "|I can do what I want to. I play by my own rules                                                                                 |normal   |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "result.select(F.explode(F.arrays_zip('document.result', 'sentiment.result')).alias(\"cols\")) \\\n",
        ".select(F.expr(\"cols['0']\").alias(\"document\"),\n",
        "        F.expr(\"cols['1']\").alias(\"sentiment\")).show(truncate=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "SENTIMENT_EN_SARCASM.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "45150093197569bb3a58481dcd32cd1adb45462fa3448719e8ac38ada6166aca"
    },
    "kernelspec": {
      "display_name": "Python 3.6.10 64-bit ('tensorflow2_p36': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
