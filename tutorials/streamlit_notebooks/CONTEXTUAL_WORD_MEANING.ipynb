{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5-final"
    },
    "colab": {
      "name": "CONTEXTUAL_WORD_MEANING.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpObGT1MFHSx"
      },
      "source": [
        "\n",
        "\n",
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/CONTEXTUAL_WORD_MEANING.ipynb)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXYEPp-PFHTF"
      },
      "source": [
        "# **Infer word meaning from context**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxdOMVpLFHTJ"
      },
      "source": [
        "Compare the meaning of words in two different sentences and evaluate ambiguous pronouns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JX8ZOfrJFHTL"
      },
      "source": [
        "## 1. Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVIbU985FHTM",
        "outputId": "1671e237-b8a5-46d5-d76b-083fd3f4fd45"
      },
      "source": [
        "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash\n",
        "# !bash colab.sh\n",
        "# -p is for pyspark\n",
        "# -s is for spark-nlp\n",
        "# !bash colab.sh -p 3.1.1 -s 3.0.1\n",
        "# by default they are set to the latest"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"11.0.10\" 2021-01-19\n",
            "OpenJDK Runtime Environment (build 11.0.10+9-Ubuntu-0ubuntu1.18.04)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.10+9-Ubuntu-0ubuntu1.18.04, mixed mode, sharing)\n",
            "setup Colab for PySpark 3.1.1 and Spark NLP 3.0.0\n",
            "\u001b[K     |████████████████████████████████| 212.3MB 63kB/s \n",
            "\u001b[K     |████████████████████████████████| 143kB 45.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 47.7MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yv-4SMMjFHTO"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "import sparknlp\n",
        "from sparknlp.pretrained import PretrainedPipeline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFUQxUGoFHTQ"
      },
      "source": [
        "## 2. Start Spark Session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LB0xN1KJFHTQ"
      },
      "source": [
        "spark = sparknlp.start()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-9ZS6oKFHTR"
      },
      "source": [
        "## 3. Select the model to use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuh-a8hJFHTS"
      },
      "source": [
        "#MODEL_NAME = 't5_small'\n",
        "MODEL_NAME = 't5_base'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sH7kAnBFHTT"
      },
      "source": [
        "### 3.1 Select the task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17IyRaX5FHTV"
      },
      "source": [
        "The `T5 Transformer` model is able to perform 18 different tasks (ref.: [this paper](https://arxiv.org/abs/1910.10683)). To infer word meaning from context, we can use the following tasks:\n",
        "\n",
        "- `wic`: Classify for a pair of sentences and a disambigous word if the word has the same meaning in both sentences.\n",
        "- `wsc-dpr`: Predict for an ambiguous pronoun in a sentence what it is referring to."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXazlzpeFHTV"
      },
      "source": [
        "#TASK = 'wic'\n",
        "TASK = 'wsc-dpr'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93M1MQp0FHTZ"
      },
      "source": [
        "# Prefix to be used on the T5Transformer().setTask(<<prefix>>)\n",
        "task_prefix = {\n",
        "                'wic': 'wic pos::', \n",
        "                'wsc-dpr': 'wsc:',\n",
        "            }"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovEzxhROFHTb"
      },
      "source": [
        "## 4 Examples to try on the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgVVLGUYFHTc"
      },
      "source": [
        "text_lists = {\n",
        "            'wic':      [\"\"\"\n",
        "                        pos:\n",
        "                        sentence1: The expanded window will give us time to catch the thieves.\n",
        "                        sentence2: You have a two-hour window of turning in your homework.\n",
        "                        word: window\n",
        "                        \"\"\"],\n",
        "            'wsc-dpr':  [\"\"\"The stable was very roomy, with four good stalls; a large swinging window opened into the yard , which made *it* pleasant and airy.\"\"\"]\n",
        "            }"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ceVj-r3FHTd"
      },
      "source": [
        "## 5. Define the Spark NLP pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ze1G_lwZFHTd",
        "outputId": "d759b2da-3bb1-40fa-c2f9-d0eaabef48d4"
      },
      "source": [
        "document_assembler = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"documents\")\n",
        "\n",
        "t5 = T5Transformer() \\\n",
        "    .pretrained(MODEL_NAME) \\\n",
        "    .setTask(task_prefix[TASK])\\\n",
        "    .setMaxOutputLength(200)\\\n",
        "    .setInputCols([\"documents\"]) \\\n",
        "    .setOutputCol(\"T5\")\n",
        "\n",
        "pipeline = Pipeline(stages=[document_assembler, t5])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "t5_base download started this may take some time.\n",
            "Approximate size to download 446 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nvlw5EOpFHTg"
      },
      "source": [
        "## 6. Run the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaCo5bt6FHTh"
      },
      "source": [
        "# Fit on empty data frame (model is pretrained)\n",
        "empty_df = spark.createDataFrame([['']]).toDF('text')\n",
        "pipeline_model = pipeline.fit(empty_df)\n",
        "\n",
        "# Send example texts to spark data frame\n",
        "text_df = spark.createDataFrame(pd.DataFrame({'text': text_lists[TASK]}))\n",
        "\n",
        "# Predict with the Pipeline model\n",
        "result = pipeline_model.transform(text_df)\n",
        "\n",
        "# Create Light Pipeline\n",
        "lmodel = LightPipeline(pipeline_model)\n",
        "\n",
        "# Predict with then Ligh Pipeline model\n",
        "res = lmodel.fullAnnotate(text_lists[TASK])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xl9yWCWoFHTh"
      },
      "source": [
        "## 7. Visualize the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLA7JY8IFHTi"
      },
      "source": [
        "Using Light Pipeline:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7mRHihPFHTj",
        "outputId": "e5d03b53-b55f-45c8-fcd5-0e42d1b80793"
      },
      "source": [
        "for r in res:\n",
        "    print(f\"{r['documents'][0].result} => {r['T5'][0].result}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The stable was very roomy, with four good stalls; a large swinging window opened into the yard , which made *it* pleasant and airy. => True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnrdsA1kFHTk"
      },
      "source": [
        "Using pipeline model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lb26-2xtFHTk",
        "outputId": "0dc5e0f8-19a8-404a-c936-80c8e5550d87"
      },
      "source": [
        "result.select('text', 'T5.result').show(truncate=150)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------------------------------------------------------------------------------------------------------------------------+------+\n",
            "|                                                                                                                               text|result|\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------+------+\n",
            "|The stable was very roomy, with four good stalls; a large swinging window opened into the yard , which made *it* pleasant and airy.|[True]|\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}