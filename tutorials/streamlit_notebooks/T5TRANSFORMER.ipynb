{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "T5TRANSFORMER.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TA21Jo5d9SVq"
      },
      "source": [
        "\n",
        "\n",
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/T5TRANSFORMER.ipynb)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzIdjHkAW8TB"
      },
      "source": [
        "# **Text Summarization & Question Answering using google's T5 Transformer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1sZkQkt3sXX"
      },
      "source": [
        "### Spark NLP documentation and instructions:\n",
        "https://nlp.johnsnowlabs.com/docs/en/quickstart\n",
        "\n",
        "### Spark NLP Google T5 Article \t\n",
        "https://towardsdatascience.com/hands-on-googles-text-to-text-transfer-transformer-t5-with-spark-nlp-6f7db75cecff\n",
        "\n",
        "### You can find details about Spark NLP annotators here:\n",
        "https://nlp.johnsnowlabs.com/docs/en/annotators\n",
        "\n",
        "### You can find details about Spark NLP models here:\n",
        "https://nlp.johnsnowlabs.com/models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIeCOiJNW-88"
      },
      "source": [
        "## 1. Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGJktFHdHL1n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54e0591a-9727-4638-c9f4-bd98a6ed97e5"
      },
      "source": [
        "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash\n",
        "# !bash colab.sh\n",
        "# -p is for pyspark\n",
        "# -s is for spark-nlp\n",
        "# !bash colab.sh -p 3.1.1 -s 3.0.1\n",
        "# by default they are set to the latest"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"11.0.10\" 2021-01-19\n",
            "OpenJDK Runtime Environment (build 11.0.10+9-Ubuntu-0ubuntu1.18.04)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.10+9-Ubuntu-0ubuntu1.18.04, mixed mode, sharing)\n",
            "setup Colab for PySpark 3.1.1 and Spark NLP 3.0.0\n",
            "\u001b[K     |████████████████████████████████| 212.3MB 52kB/s \n",
            "\u001b[K     |████████████████████████████████| 143kB 28.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 35.9MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 102kB 4.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 7.0MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCIT5VLxS3I1"
      },
      "source": [
        "## 2. Start the Spark session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khjM-z9ORFU3"
      },
      "source": [
        "Import dependencies and start Spark session."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sw-t1zxlHTB7"
      },
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "import sparknlp\n",
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "\n",
        "spark = sparknlp.start()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RgiqfX5XDqb"
      },
      "source": [
        "## 3. Select the DL model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPqBOgDhnvjB"
      },
      "source": [
        "For complete model list: \n",
        "https://nlp.johnsnowlabs.com/models\n",
        "\n",
        "For `T5` models:\n",
        "https://nlp.johnsnowlabs.com/models?tag=t5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQACwlw5dJT6"
      },
      "source": [
        "##4. Text Summaization using T5 Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XftYgju4XOw_"
      },
      "source": [
        " Define Spark NLP pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBggF5P8J1gc",
        "outputId": "a4cc407f-6cc1-49a2-da2f-c2c5fd684249"
      },
      "source": [
        "document_assembler = DocumentAssembler()\\\n",
        ".setInputCol(\"text\")\\\n",
        ".setOutputCol(\"documents\")\n",
        "\n",
        "t5 = T5Transformer() \\\n",
        "  .pretrained(\"t5_small\", 'en') \\\n",
        "  .setTask(\"summarize:\")\\\n",
        "  .setMaxOutputLength(200)\\\n",
        "  .setInputCols([\"documents\"]) \\\n",
        "  .setOutputCol(\"summaries\")\n",
        "\n",
        "summarizer_pp = Pipeline(stages=[\n",
        "    document_assembler, t5\n",
        "])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "t5_small download started this may take some time.\n",
            "Approximate size to download 139 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv0abcwhXWC-"
      },
      "source": [
        "Run the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYf_9sXDXR4t",
        "outputId": "80ba6a86-f693-47f3-c38a-d0e4a8da0642"
      },
      "source": [
        "empty_df = spark.createDataFrame([['']]).toDF('text')\n",
        "pipeline_model = summarizer_pp.fit(empty_df)\n",
        "sum_lmodel = LightPipeline(pipeline_model)\n",
        "\n",
        "example_txt = \"\"\"\n",
        "\n",
        "Mona Lisa is a 16th century oil painting created by Leonardo. It is held at the Louvre in Paris.\n",
        "\"\"\"\n",
        "\n",
        "res = sum_lmodel.fullAnnotate(example_txt)[0]\n",
        "\n",
        "\n",
        "print ('Summary:', res['summaries'][0].result)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Summary: mona Lisa is a 16th century oil painting created by Leonardo .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QPs_I1JeaFV"
      },
      "source": [
        "##5. Question Answering using T5 Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oup7_-KNefgz"
      },
      "source": [
        " Define Spark NLP pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmIBAkUWeiAO",
        "outputId": "9d372f52-b7c5-428f-c8bd-15879885e240"
      },
      "source": [
        "document_assembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"text\") \\\n",
        "    .setOutputCol(\"documents\")\n",
        "\n",
        "sentence_detector = SentenceDetectorDLModel\\\n",
        "    .pretrained(\"sentence_detector_dl\", \"en\")\\\n",
        "    .setInputCols([\"documents\"])\\\n",
        "    .setOutputCol(\"questions\")\n",
        "\n",
        "t5 = T5Transformer()\\\n",
        "    .pretrained(\"google_t5_small_ssm_nq\", 'en')\\\n",
        "    .setInputCols([\"questions\"])\\\n",
        "    .setOutputCol(\"answers\")\\\n",
        "\n",
        "qa_pp = Pipeline(stages=[\n",
        "    document_assembler, sentence_detector, t5\n",
        "])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentence_detector_dl download started this may take some time.\n",
            "Approximate size to download 354.6 KB\n",
            "[OK!]\n",
            "google_t5_small_ssm_nq download started this may take some time.\n",
            "Approximate size to download 139 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBRwmr-lfB6T"
      },
      "source": [
        "Run the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJmiFMHKfCX0",
        "outputId": "d7979304-fa3d-41f9-cb92-26c359663a1c"
      },
      "source": [
        "empty_df = spark.createDataFrame([['']]).toDF('text')\n",
        "pipeline_model = qa_pp.fit(empty_df)\n",
        "qa_lmodel = LightPipeline(pipeline_model)\n",
        "\n",
        "questions = [\"What is the capital of America?\",\n",
        "             \"who is the most famous singer?\",\n",
        "             \"when do we have winters?\",\n",
        "             \"Who is the president of the USA?\",\n",
        "             \"Who is the founder of Microsoft?\"\n",
        "]\n",
        "\n",
        "res = qa_lmodel.fullAnnotate(questions)\n",
        "\n",
        "\n",
        "for i, r in enumerate(res):\n",
        "  print (\"Question:\", questions[i])\n",
        "  for sent in r['answers']:\n",
        "    print ('Answer:\\t', sent.result)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Question: What is the capital of America?\n",
            "Answer:\t Washington, D.C.\n",
            "Question: who is the most famous singer?\n",
            "Answer:\t Selena Gomez\n",
            "Question: when do we have winters?\n",
            "Answer:\t February 3\n",
            "Question: Who is the president of the USA?\n",
            "Answer:\t Donald Trump\n",
            "Question: Who is the founder of Microsoft?\n",
            "Answer:\t Microsoft founder Bill Gates\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}