{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4b_2KemgDWf"
      },
      "source": [
        "\n",
        "\n",
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/SPELL_CHECKER_EN.ipynb)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnZG0I4ogNLI"
      },
      "source": [
        "# **Spell check your text documents**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apjCmRyjgQll"
      },
      "source": [
        "## 1. Colab Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2phEj9SygX4n"
      },
      "source": [
        "Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAiXj3DOfyZ-",
        "outputId": "856f844e-a44f-4d94-863c-2d70c6d08de5"
      },
      "outputs": [],
      "source": [
        "# Install PySpark and Spark NLP\n",
        "! pip install -q pyspark==3.1.2 spark-nlp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DE2XyDI7NHtg"
      },
      "source": [
        "Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "g9hfxX3df3n3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "import sparknlp\n",
        "from sparknlp.pretrained import PretrainedPipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3Ur62RrgaxX"
      },
      "source": [
        "Start Spark Session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "763GC_wVNN6F"
      },
      "outputs": [],
      "source": [
        "spark = sparknlp.start()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUP6-XeQgeQW"
      },
      "source": [
        "## 2. Select the NER model and construct the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taOqLG1Ogc3D",
        "outputId": "0b0defd2-18bd-4d45-c1bd-a89e2dc151d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "spellcheck_dl download started this may take some time.\n",
            "Approximate size to download 111.4 MB\n",
            "[OK!]\n"
          ]
        }
      ],
      "source": [
        "document_assembler = DocumentAssembler()\\\n",
        "  .setInputCol(\"text\")\\\n",
        "  .setOutputCol(\"document\")\n",
        "\n",
        "tokenizer = RecursiveTokenizer()\\\n",
        "  .setInputCols([\"document\"])\\\n",
        "  .setOutputCol(\"token\")\\\n",
        "  .setPrefixes([\"\\\"\", \"(\", \"[\", \"\\n\"])\\\n",
        "  .setSuffixes([\".\", \",\", \"?\", \")\",\"!\", \"â€˜s\"])\n",
        "\n",
        "spell_model = ContextSpellCheckerModel\\\n",
        "    .pretrained('spellcheck_dl')\\\n",
        "    .setInputCols(\"token\")\\\n",
        "    .setOutputCol(\"corrected\")\n",
        "\n",
        "finisher = Finisher().setInputCols(\"corrected\")\n",
        "\n",
        "light_pipeline = Pipeline(stages = [\n",
        "                                    document_assembler,\n",
        "                                    tokenizer,\n",
        "                                    spell_model,\n",
        "                                    finisher\n",
        "                                    ])\n",
        "## For comparison\n",
        "full_pipeline = Pipeline(\n",
        "    stages = [\n",
        "              document_assembler,\n",
        "              tokenizer,\n",
        "              spell_model\n",
        "  ])\n",
        "\n",
        "empty_ds = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
        "pipeline_model = full_pipeline.fit(empty_ds)\n",
        "l_pipeline_model = LightPipeline(light_pipeline.fit(empty_ds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_DzGuMPibKr"
      },
      "source": [
        "## 3. Create example inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "c7yPd884i_XQ"
      },
      "outputs": [],
      "source": [
        "# Enter examples as strings in this array\n",
        "input_list = [\"Plaese alliow me tao introdduce myhelf, I am a man of waelth und tiaste\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvyOmrgHjO5J"
      },
      "source": [
        "## 4. Use the pipeline to create outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICREynF-jzn8"
      },
      "source": [
        "Full Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RLbrPvC3jOSw"
      },
      "outputs": [],
      "source": [
        "df = spark.createDataFrame(pd.DataFrame({\"text\": input_list}))\n",
        "result = pipeline_model.transform(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhlbvs1Dj1ck"
      },
      "source": [
        "Light Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YulVrYgAj2ex"
      },
      "outputs": [],
      "source": [
        "# Light pipelines expect a single example.\n",
        "light_result = l_pipeline_model.annotate(input_list[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uk72hQGqjX3f"
      },
      "source": [
        "## 5. Visualize results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9JDK9_EjaF_"
      },
      "source": [
        "Visualize comparison as dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FY_7D9RFjlQS",
        "outputId": "9027ea28-b48a-4e80-8690-b31e614b35dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+---------+\n",
            "|original  |corrected|\n",
            "+----------+---------+\n",
            "|Plaese    |Please   |\n",
            "|alliow    |allow    |\n",
            "|me        |me       |\n",
            "|tao       |to       |\n",
            "|introdduce|introduce|\n",
            "|myhelf    |myself   |\n",
            "|,         |,        |\n",
            "|I         |I        |\n",
            "|am        |am       |\n",
            "|a         |a        |\n",
            "|man       |man      |\n",
            "|of        |of       |\n",
            "|waelth    |wealth   |\n",
            "|und       |und      |\n",
            "|tiaste    |taste    |\n",
            "+----------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "exploded = F.explode(F.arrays_zip('token.result', 'corrected.result'))\n",
        "select_expression_0 = F.expr(\"cols['0']\").alias(\"original\")\n",
        "select_expression_1 = F.expr(\"cols['1']\").alias(\"corrected\")\n",
        "result.select(exploded.alias(\"cols\")) \\\n",
        "    .select(select_expression_0, select_expression_1).show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yItQfZmhcji"
      },
      "source": [
        "Vizualise light pipeline and finished result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zHSiB0skP83",
        "outputId": "9a5f32d1-b72d-4d8a-bebe-07f431caf2e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Please',\n",
              " 'allow',\n",
              " 'me',\n",
              " 'to',\n",
              " 'introduce',\n",
              " 'myself',\n",
              " ',',\n",
              " 'I',\n",
              " 'am',\n",
              " 'a',\n",
              " 'man',\n",
              " 'of',\n",
              " 'wealth',\n",
              " 'und',\n",
              " 'taste']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# this finished result does not need parsing and can directly be used an any other task.\n",
        "light_result['corrected']"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "SPELL_CHECKER_EN.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "45150093197569bb3a58481dcd32cd1adb45462fa3448719e8ac38ada6166aca"
    },
    "kernelspec": {
      "display_name": "Python 3.6.10 64-bit ('tensorflow2_p36': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
