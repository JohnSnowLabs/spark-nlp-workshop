{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SPELL_CHECKER_EN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4b_2KemgDWf"
      },
      "source": [
        "\n",
        "\n",
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/SPELL_CHECKER_EN.ipynb)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnZG0I4ogNLI"
      },
      "source": [
        "# **Spell check your text documents**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apjCmRyjgQll"
      },
      "source": [
        "## 1. Colab Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2phEj9SygX4n"
      },
      "source": [
        "Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAiXj3DOfyZ-",
        "outputId": "856f844e-a44f-4d94-863c-2d70c6d08de5"
      },
      "source": [
        "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash\n",
        "# !bash colab.sh\n",
        "# -p is for pyspark\n",
        "# -s is for spark-nlp\n",
        "# !bash colab.sh -p 3.1.1 -s 3.0.1\n",
        "# by default they are set to the latest"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"11.0.10\" 2021-01-19\n",
            "OpenJDK Runtime Environment (build 11.0.10+9-Ubuntu-0ubuntu1.18.04)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.10+9-Ubuntu-0ubuntu1.18.04, mixed mode, sharing)\n",
            "setup Colab for PySpark 3.1.1 and Spark NLP 3.0.0\n",
            "\u001b[K     |████████████████████████████████| 212.3MB 72kB/s \n",
            "\u001b[K     |████████████████████████████████| 143kB 46.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 47.5MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DE2XyDI7NHtg"
      },
      "source": [
        "Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9hfxX3df3n3"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "import sparknlp\n",
        "from sparknlp.pretrained import PretrainedPipeline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3Ur62RrgaxX"
      },
      "source": [
        "Start Spark Session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "763GC_wVNN6F"
      },
      "source": [
        "spark = sparknlp.start()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUP6-XeQgeQW"
      },
      "source": [
        "## 2. Select the NER model and construct the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taOqLG1Ogc3D",
        "outputId": "0b0defd2-18bd-4d45-c1bd-a89e2dc151d4"
      },
      "source": [
        "document_assembler = DocumentAssembler()\\\n",
        "  .setInputCol(\"text\")\\\n",
        "  .setOutputCol(\"document\")\n",
        "\n",
        "tokenizer = RecursiveTokenizer()\\\n",
        "  .setInputCols([\"document\"])\\\n",
        "  .setOutputCol(\"token\")\\\n",
        "  .setPrefixes([\"\\\"\", \"(\", \"[\", \"\\n\"])\\\n",
        "  .setSuffixes([\".\", \",\", \"?\", \")\",\"!\", \"‘s\"])\n",
        "\n",
        "spell_model = ContextSpellCheckerModel\\\n",
        "    .pretrained('spellcheck_dl')\\\n",
        "    .setInputCols(\"token\")\\\n",
        "    .setOutputCol(\"corrected\")\n",
        "\n",
        "finisher = Finisher().setInputCols(\"corrected\")\n",
        "\n",
        "light_pipeline = Pipeline(stages = [\n",
        "                                    document_assembler,\n",
        "                                    tokenizer,\n",
        "                                    spell_model,\n",
        "                                    finisher\n",
        "                                    ])\n",
        "## For comparison\n",
        "full_pipeline = Pipeline(\n",
        "    stages = [\n",
        "              document_assembler,\n",
        "              tokenizer,\n",
        "              spell_model\n",
        "  ])\n",
        "\n",
        "empty_ds = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
        "pipeline_model = full_pipeline.fit(empty_ds)\n",
        "l_pipeline_model = LightPipeline(light_pipeline.fit(empty_ds))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "spellcheck_dl download started this may take some time.\n",
            "Approximate size to download 111.4 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_DzGuMPibKr"
      },
      "source": [
        "## 3. Create example inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7yPd884i_XQ"
      },
      "source": [
        "# Enter examples as strings in this array\n",
        "input_list = [\"Plaese alliow me tao introdduce myhelf, I am a man of waelth und tiaste\"]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvyOmrgHjO5J"
      },
      "source": [
        "## 4. Use the pipeline to create outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICREynF-jzn8"
      },
      "source": [
        "Full Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLbrPvC3jOSw"
      },
      "source": [
        "df = spark.createDataFrame(pd.DataFrame({\"text\": input_list}))\n",
        "result = pipeline_model.transform(df)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhlbvs1Dj1ck"
      },
      "source": [
        "Light Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YulVrYgAj2ex"
      },
      "source": [
        "# Light pipelines expect a single example.\n",
        "light_result = l_pipeline_model.annotate(input_list[0])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uk72hQGqjX3f"
      },
      "source": [
        "## 5. Visualize results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9JDK9_EjaF_"
      },
      "source": [
        "Visualize comparison as dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FY_7D9RFjlQS",
        "outputId": "9027ea28-b48a-4e80-8690-b31e614b35dd"
      },
      "source": [
        "exploded = F.explode(F.arrays_zip('token.result', 'corrected.result'))\n",
        "select_expression_0 = F.expr(\"cols['0']\").alias(\"original\")\n",
        "select_expression_1 = F.expr(\"cols['1']\").alias(\"corrected\")\n",
        "result.select(exploded.alias(\"cols\")) \\\n",
        "    .select(select_expression_0, select_expression_1).show(truncate=False)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+---------+\n",
            "|original  |corrected|\n",
            "+----------+---------+\n",
            "|Plaese    |Please   |\n",
            "|alliow    |allow    |\n",
            "|me        |me       |\n",
            "|tao       |to       |\n",
            "|introdduce|introduce|\n",
            "|myhelf    |myself   |\n",
            "|,         |,        |\n",
            "|I         |I        |\n",
            "|am        |am       |\n",
            "|a         |a        |\n",
            "|man       |man      |\n",
            "|of        |of       |\n",
            "|waelth    |wealth   |\n",
            "|und       |und      |\n",
            "|tiaste    |taste    |\n",
            "+----------+---------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yItQfZmhcji"
      },
      "source": [
        "Vizualise light pipeline and finished result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zHSiB0skP83",
        "outputId": "9a5f32d1-b72d-4d8a-bebe-07f431caf2e9"
      },
      "source": [
        "# this finished result does not need parsing and can directly be used an any other task.\n",
        "light_result['corrected']"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Please',\n",
              " 'allow',\n",
              " 'me',\n",
              " 'to',\n",
              " 'introduce',\n",
              " 'myself',\n",
              " ',',\n",
              " 'I',\n",
              " 'am',\n",
              " 'a',\n",
              " 'man',\n",
              " 'of',\n",
              " 'wealth',\n",
              " 'und',\n",
              " 'taste']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    }
  ]
}