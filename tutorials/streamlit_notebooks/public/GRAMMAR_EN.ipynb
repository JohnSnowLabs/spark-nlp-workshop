{"cells":[{"cell_type":"markdown","metadata":{"id":"hb-VyZjNYsNu"},"source":["\n","\n","![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n","\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/GRAMMAR_EN.ipynb)\n"]},{"cell_type":"markdown","metadata":{"id":"syePZ-1gYyj3"},"source":["# **Extract Part of speech tags and perform dependency parsing on a text**"]},{"cell_type":"markdown","metadata":{"id":"wDJCr8UTZAqg"},"source":["## 1. Colab Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w6o8-g0tEqNz"},"outputs":[],"source":["# Install PySpark and Spark NLP\n","! pip install -q pyspark==3.3.0 spark-nlp==4.2.1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yMmT9S6mE0ad"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import json\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, accuracy_score\n","from pyspark.ml import Pipeline\n","from pyspark.sql.types import StringType, IntegerType\n","from pyspark.sql import SparkSession\n","import pyspark.sql.functions as F\n","from sparknlp.annotator import *\n","from sparknlp.base import *\n","import sparknlp\n","from sparknlp.pretrained import PretrainedPipeline"]},{"cell_type":"markdown","metadata":{"id":"f0fyw4cTZDMp"},"source":["## 2. Start Spark Session"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4zBXbY_vE2ss"},"outputs":[],"source":["spark = sparknlp.start()"]},{"cell_type":"markdown","metadata":{"id":"ODFvrTAgZGGw"},"source":["## 3. Select the DL model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1XxHWemdE5hX"},"outputs":[],"source":["MODEL_NAME='dependency_typed_conllu'"]},{"cell_type":"markdown","metadata":{"id":"s-HM1On1ZJ4L"},"source":["## 4. Some sample examples"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GJ7GCD0pFDvP"},"outputs":[],"source":["## Generating Example Files ##\n","text_list = [\"\"\"John Snow is a good man. He knows a lot about science.\"\"\",\n","             \"\"\"In what country is the WTO headquartered?\"\"\",\n","             \"\"\"I was wearing my dark blue shirt and tie.\"\"\",\n","             \"\"\"The Geneva Motor Show is the most popular car show of the year.\"\"\",\n","             \"\"\"Bill Gates and Steve Jobs had periods of civility.\"\"\",]\n"]},{"cell_type":"markdown","metadata":{"id":"b_FMM_GLZMjX"},"source":["## 5. Define Spark NLP pipeline"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IiYxv0mOFIcX","outputId":"6502dce3-5534-4a22-b89b-21327604df0a","executionInfo":{"status":"ok","timestamp":1666182653322,"user_tz":-120,"elapsed":12040,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["pos_anc download started this may take some time.\n","Approximate size to download 3.9 MB\n","[OK!]\n","dependency_conllu download started this may take some time.\n","Approximate size to download 16.7 MB\n","[OK!]\n","dependency_typed_conllu download started this may take some time.\n","Approximate size to download 2.4 MB\n","[OK!]\n"]}],"source":["documentAssembler = DocumentAssembler()\\\n","        .setInputCol(\"text\")\\\n","        .setOutputCol(\"document\")\n","\n","tokenizer = Tokenizer() \\\n","        .setInputCols([\"document\"]) \\\n","        .setOutputCol(\"token\")\n","\n","pos = PerceptronModel.pretrained(\"pos_anc\", 'en')\\\n","        .setInputCols(\"document\", \"token\")\\\n","        .setOutputCol(\"pos\")\n","\n","dep_parser = DependencyParserModel.pretrained('dependency_conllu')\\\n","        .setInputCols([\"document\", \"pos\", \"token\"])\\\n","        .setOutputCol(\"dependency\")\n","\n","\n","typed_dep_parser = TypedDependencyParserModel.pretrained('dependency_typed_conllu')\\\n","        .setInputCols([\"token\", \"pos\", \"dependency\"])\\\n","        .setOutputCol(\"dependency_type\")\n","\n","\n","nlpPipeline = Pipeline(\n","      stages = [documentAssembler,\n","                tokenizer,\n","                pos,\n","                dep_parser,\n","                typed_dep_parser])\n","\n"]},{"cell_type":"markdown","metadata":{"id":"2zMXh_skZPvR"},"source":["## 6. Select the example to test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gQmz-XHWZX1N"},"outputs":[],"source":["index=0"]},{"cell_type":"markdown","metadata":{"id":"9ipT3X2sZeBq"},"source":["## 7. Run the pipeline on selected example"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7O34pc7d27-j"},"outputs":[],"source":["df = spark.createDataFrame(text_list, StringType()).toDF(\"text\")\n","result = nlpPipeline.fit(df).transform(df)\n"]},{"cell_type":"markdown","metadata":{"id":"tBr9mBDXZUTX"},"source":["## 8. Visualize results"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TzJSQhTnFix5","outputId":"a8c92c01-51dc-4d1e-9d21-8a1b9298cb24","executionInfo":{"status":"ok","timestamp":1666182658112,"user_tz":-120,"elapsed":2819,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["+-------+-----+---+---+-------------+-------------------------------------------------------------+---------------+\n","|chunk  |begin|end|pos|dependency   |dependency_start                                             |dependency_type|\n","+-------+-----+---+---+-------------+-------------------------------------------------------------+---------------+\n","|John   |0    |3  |NNP|knows        |{head -> 9, head.begin -> 28, head.end -> 32, sentence -> 0} |nsubj          |\n","|Snow   |5    |8  |NNP|man          |{head -> 6, head.begin -> 20, head.end -> 22, sentence -> 0} |flat           |\n","|is     |10   |11 |VBZ|man          |{head -> 6, head.begin -> 20, head.end -> 22, sentence -> 0} |nsubj          |\n","|a      |13   |13 |DT |man          |{head -> 6, head.begin -> 20, head.end -> 22, sentence -> 0} |nsubj          |\n","|good   |15   |18 |JJ |man          |{head -> 6, head.begin -> 20, head.end -> 22, sentence -> 0} |amod           |\n","|man    |20   |22 |NN |John         |{head -> 1, head.begin -> 0, head.end -> 3, sentence -> 0}   |flat           |\n","|.      |23   |23 |.  |knows        |{head -> 9, head.begin -> 28, head.end -> 32, sentence -> 0} |punct          |\n","|He     |25   |26 |PRP|knows        |{head -> 9, head.begin -> 28, head.end -> 32, sentence -> 0} |nsubj          |\n","|knows  |28   |32 |VBZ|ROOT         |{head -> 0, head.begin -> -1, head.end -> -1, sentence -> 0} |root           |\n","|a      |34   |34 |DT |lot          |{head -> 11, head.begin -> 36, head.end -> 38, sentence -> 0}|nsubj          |\n","|lot    |36   |38 |NN |knows        |{head -> 9, head.begin -> 28, head.end -> 32, sentence -> 0} |nsubj          |\n","|about  |40   |44 |IN |science      |{head -> 13, head.begin -> 46, head.end -> 52, sentence -> 0}|det            |\n","|science|46   |52 |NN |lot          |{head -> 11, head.begin -> 36, head.end -> 38, sentence -> 0}|flat           |\n","|.      |53   |53 |.  |knows        |{head -> 9, head.begin -> 28, head.end -> 32, sentence -> 0} |punct          |\n","|In     |0    |1  |IN |country      |{head -> 3, head.begin -> 8, head.end -> 14, sentence -> 0}  |det            |\n","|what   |3    |6  |WP |country      |{head -> 3, head.begin -> 8, head.end -> 14, sentence -> 0}  |nsubj          |\n","|country|8    |14 |NN |headquartered|{head -> 7, head.begin -> 27, head.end -> 39, sentence -> 0} |nsubj          |\n","|is     |16   |17 |VBZ|headquartered|{head -> 7, head.begin -> 27, head.end -> 39, sentence -> 0} |parataxis      |\n","|the    |19   |21 |DT |headquartered|{head -> 7, head.begin -> 27, head.end -> 39, sentence -> 0} |nsubj          |\n","|WTO    |23   |25 |NNP|headquartered|{head -> 7, head.begin -> 27, head.end -> 39, sentence -> 0} |nsubj          |\n","+-------+-----+---+---+-------------+-------------------------------------------------------------+---------------+\n","only showing top 20 rows\n","\n"]}],"source":["result.select(F.explode(F.arrays_zip(result.token.result,\n","                                     result.token.begin,\n","                                     result.token.end, \n","                                     result.pos.result, \n","                                     result.dependency.result, \n","                                     result.dependency.metadata,\n","                                     result.dependency_type.result)).alias(\"cols\"))\\\n","      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n","              F.expr(\"cols['1']\").alias(\"begin\"),\n","              F.expr(\"cols['2']\").alias(\"end\"),\n","              F.expr(\"cols['3']\").alias(\"pos\"),\n","              F.expr(\"cols['4']\").alias(\"dependency\"),\n","              F.expr(\"cols['5']\").alias(\"dependency_start\"),\n","              F.expr(\"cols['6']\").alias(\"dependency_type\")).show(truncate=False)\n"]},{"cell_type":"code","source":[],"metadata":{"id":"9Vb3zCq1OWw4"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[],"toc_visible":true},"interpreter":{"hash":"60af5c81ffa00bed911704ff054405489da13f9503e86373e95cf9267d593cbf"},"kernelspec":{"display_name":"Python 3.6.10 64-bit ('tensorflow_p36': conda)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"}},"nbformat":4,"nbformat_minor":0}