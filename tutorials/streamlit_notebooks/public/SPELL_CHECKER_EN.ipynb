{"cells":[{"cell_type":"markdown","metadata":{"id":"I4b_2KemgDWf"},"source":["\n","\n","![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n","\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/SPELL_CHECKER_EN.ipynb)\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"TnZG0I4ogNLI"},"source":["# **Spell check your text documents**"]},{"cell_type":"markdown","metadata":{"id":"apjCmRyjgQll"},"source":["## 1. Colab Setup"]},{"cell_type":"markdown","metadata":{"id":"2phEj9SygX4n"},"source":["Install dependencies"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uAiXj3DOfyZ-"},"outputs":[],"source":["# Install PySpark and Spark NLP\n","! pip install -q pyspark==3.3.0 spark-nlp==4.2.1"]},{"cell_type":"markdown","metadata":{"id":"DE2XyDI7NHtg"},"source":["Import dependencies"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g9hfxX3df3n3"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import json\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, accuracy_score\n","from pyspark.ml import Pipeline\n","from pyspark.sql.types import StringType, IntegerType\n","from pyspark.sql import SparkSession\n","import pyspark.sql.functions as F\n","from sparknlp.annotator import *\n","from sparknlp.base import *\n","import sparknlp\n","from sparknlp.pretrained import PretrainedPipeline"]},{"cell_type":"markdown","metadata":{"id":"T3Ur62RrgaxX"},"source":["Start Spark Session"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"763GC_wVNN6F"},"outputs":[],"source":["spark = sparknlp.start()"]},{"cell_type":"markdown","metadata":{"id":"AUP6-XeQgeQW"},"source":["## 2. Select the NER model and construct the pipeline"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"taOqLG1Ogc3D","outputId":"e2aa8b97-b1e0-4901-df6a-7ec5864e3caa","executionInfo":{"status":"ok","timestamp":1666170315510,"user_tz":-120,"elapsed":45664,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["spellcheck_dl download started this may take some time.\n","Approximate size to download 95.1 MB\n","[OK!]\n"]}],"source":["document_assembler = DocumentAssembler()\\\n","  .setInputCol(\"text\")\\\n","  .setOutputCol(\"document\")\n","\n","tokenizer = RecursiveTokenizer()\\\n","  .setInputCols([\"document\"])\\\n","  .setOutputCol(\"token\")\\\n","  .setPrefixes([\"\\\"\", \"(\", \"[\", \"\\n\"])\\\n","  .setSuffixes([\".\", \",\", \"?\", \")\",\"!\", \"â€˜s\"])\n","\n","spell_model = ContextSpellCheckerModel\\\n","    .pretrained('spellcheck_dl')\\\n","    .setInputCols(\"token\")\\\n","    .setOutputCol(\"corrected\")\n","\n","finisher = Finisher().setInputCols(\"corrected\")\n","\n","light_pipeline = Pipeline(stages = [document_assembler,\n","                                    tokenizer,\n","                                    spell_model,\n","                                    finisher])\n","## For comparison\n","full_pipeline = Pipeline(stages = [document_assembler,\n","                                   tokenizer,\n","                                   spell_model])\n","\n","empty_ds = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n","pipeline_model = full_pipeline.fit(empty_ds)\n","l_pipeline_model = LightPipeline(light_pipeline.fit(empty_ds))"]},{"cell_type":"markdown","metadata":{"id":"C_DzGuMPibKr"},"source":["## 3. Create example inputs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c7yPd884i_XQ"},"outputs":[],"source":["# Enter examples as strings in this array\n","input_list = [\"Plaese alliow me tao introdduce myhelf, I am a man of waelth und tiaste\"]"]},{"cell_type":"markdown","metadata":{"id":"OvyOmrgHjO5J"},"source":["## 4. Use the pipeline to create outputs"]},{"cell_type":"markdown","metadata":{"id":"ICREynF-jzn8"},"source":["Full Pipeline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RLbrPvC3jOSw"},"outputs":[],"source":["df = spark.createDataFrame(pd.DataFrame({\"text\": input_list}))\n","result = pipeline_model.transform(df)"]},{"cell_type":"markdown","metadata":{"id":"mhlbvs1Dj1ck"},"source":["Light Pipeline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YulVrYgAj2ex"},"outputs":[],"source":["# Light pipelines expect a single example.\n","light_result = l_pipeline_model.annotate(input_list[0])"]},{"cell_type":"markdown","metadata":{"id":"Uk72hQGqjX3f"},"source":["## 5. Visualize results"]},{"cell_type":"markdown","metadata":{"id":"J9JDK9_EjaF_"},"source":["Visualize comparison as dataframe"]},{"cell_type":"code","source":["result.select(F.explode(F.arrays_zip(result.token.result, \n","                                     result.corrected.result)).alias(\"cols\")) \\\n","      .select(F.expr(\"cols['0']\").alias(\"original\"),\n","              F.expr(\"cols['1']\").alias('corrected')).show(truncate=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uekWfx_tFL3x","executionInfo":{"status":"ok","timestamp":1666170320226,"user_tz":-120,"elapsed":2635,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"}},"outputId":"750b7a39-8297-4ec3-f4e3-fb7b5c7e4afa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------+---------+\n","|original  |corrected|\n","+----------+---------+\n","|Plaese    |Please   |\n","|alliow    |allow    |\n","|me        |me       |\n","|tao       |to       |\n","|introdduce|introduce|\n","|myhelf    |myself   |\n","|,         |,        |\n","|I         |I        |\n","|am        |am       |\n","|a         |a        |\n","|man       |man      |\n","|of        |of       |\n","|waelth    |wealth   |\n","|und       |and      |\n","|tiaste    |taste    |\n","+----------+---------+\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"5yItQfZmhcji"},"source":["Vizualise light pipeline and finished result"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9zHSiB0skP83","outputId":"92060244-b719-427d-a4c3-77908a88e840","executionInfo":{"status":"ok","timestamp":1666170320226,"user_tz":-120,"elapsed":36,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Please',\n"," 'allow',\n"," 'me',\n"," 'to',\n"," 'introduce',\n"," 'myself',\n"," ',',\n"," 'I',\n"," 'am',\n"," 'a',\n"," 'man',\n"," 'of',\n"," 'wealth',\n"," 'and',\n"," 'taste']"]},"metadata":{},"execution_count":9}],"source":["# this finished result does not need parsing and can directly be used an any other task.\n","light_result['corrected']"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"interpreter":{"hash":"45150093197569bb3a58481dcd32cd1adb45462fa3448719e8ac38ada6166aca"},"kernelspec":{"display_name":"Python 3.6.10 64-bit ('tensorflow2_p36': conda)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"}},"nbformat":4,"nbformat_minor":0}