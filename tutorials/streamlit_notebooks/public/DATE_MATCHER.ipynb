{"cells":[{"cell_type":"markdown","metadata":{"id":"TA21Jo5d9SVq"},"source":["\n","\n","![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n","\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/DATE_MATCHER.ipynb)\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"CzIdjHkAW8TB"},"source":["# **Spark NLP Date Matcher**"]},{"cell_type":"markdown","metadata":{"id":"IPkP_ghy4Wj_"},"source":["### Spark NLP documentation and instructions:\n","https://nlp.johnsnowlabs.com/docs/en/quickstart\n","\n","### You can find details about Spark NLP annotators here:\n","https://nlp.johnsnowlabs.com/docs/en/annotators\n","\n","### You can find details about Spark NLP models here:\n","https://nlp.johnsnowlabs.com/models\n"]},{"cell_type":"markdown","metadata":{"id":"wIeCOiJNW-88"},"source":["## 1. Colab Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CGJktFHdHL1n"},"outputs":[],"source":["# Install PySpark and Spark NLP\n","! pip install -q pyspark==3.1.2 spark-nlp==4.2.8"]},{"cell_type":"markdown","metadata":{"id":"eCIT5VLxS3I1"},"source":["## 2. Start the Spark session"]},{"cell_type":"markdown","metadata":{"id":"khjM-z9ORFU3"},"source":["Import dependencies and start Spark session."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"sw-t1zxlHTB7","executionInfo":{"status":"ok","timestamp":1675545894678,"user_tz":-60,"elapsed":632,"user":{"displayName":"Damla","userId":"03285166568766987047"}}},"outputs":[],"source":["import json\n","import pandas as pd\n","import numpy as np\n","\n","import sparknlp\n","import pyspark.sql.functions as F\n","\n","from pyspark.ml import Pipeline\n","from pyspark.sql import SparkSession\n","from sparknlp.annotator import *\n","from sparknlp.base import *\n","from sparknlp.pretrained import PretrainedPipeline\n","from pyspark.sql.types import StringType, IntegerType"]},{"cell_type":"code","source":["spark = sparknlp.start()\n","print (\"Spark NLP Version :\", sparknlp.version())\n","spark"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":228},"id":"Bw8baOwAUKNX","executionInfo":{"status":"ok","timestamp":1675545939388,"user_tz":-60,"elapsed":44714,"user":{"displayName":"Damla","userId":"03285166568766987047"}},"outputId":"3552e5b8-fb99-4e91-ad57-0912b748de2a"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Spark NLP Version : 4.2.8\n"]},{"output_type":"execute_result","data":{"text/plain":["<pyspark.sql.session.SparkSession at 0x7f960c191eb0>"],"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://ea2c7f7c140d:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.1.2</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>Spark NLP</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"D8E-vYDd1jT0"},"source":["##3. Build Pipeline"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"gz_naMHK1ik2","executionInfo":{"status":"ok","timestamp":1675545942306,"user_tz":-60,"elapsed":2929,"user":{"displayName":"Damla","userId":"03285166568766987047"}}},"outputs":[],"source":["document_assembler = DocumentAssembler()\\\n","    .setInputCol(\"text\")\\\n","    .setOutputCol(\"document\")\n","\n","sentence_detector = SentenceDetector()\\\n","    .setInputCols(\"document\")\\\n","    .setOutputCol(\"sentence\")\n","\n","date_matcher = DateMatcher() \\\n","    .setInputCols('sentence')\\\n","    .setOutputCol(\"date\")\n","\n","pipeline1= Pipeline(\n","    stages=[ \n","        document_assembler, \n","        sentence_detector,\n","        date_matcher,\n","        ])\n","\n","empty_df = spark.createDataFrame([['']]).toDF(\"text\")\n","\n","date_pp = pipeline1.fit(empty_df)\n","date_model = LightPipeline(date_pp)"]},{"cell_type":"markdown","metadata":{"id":"3wwbB08A1ocE"},"source":["##4. Run & Visualize"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"3ID8yd871xaZ","executionInfo":{"status":"ok","timestamp":1675545942306,"user_tz":-60,"elapsed":3,"user":{"displayName":"Damla","userId":"03285166568766987047"}}},"outputs":[],"source":["input_list = [\n","    \"\"\"David visited the restaurant yesterday with his family. \n","He also visited and the day before, but at that time he was alone.\n","David again visited today with his colleagues.\n","He and his friends really liked the food and hoped to visit again tomorrow.\"\"\",]"]},{"cell_type":"code","source":["tres = date_model.fullAnnotate(input_list)[0]\n","for dte in tres['date']:\n","    sent = tres['sentence'][int(dte.metadata['sentence'])]\n","    print (f'text/chunk {sent.result[dte.begin:dte.end+1]} | mapped_date: {dte.result}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kO9U-Rg19Hx7","executionInfo":{"status":"ok","timestamp":1675545942675,"user_tz":-60,"elapsed":371,"user":{"displayName":"Damla","userId":"03285166568766987047"}},"outputId":"07c154fc-7d83-4935-8130-45248e9e4a2c"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Before _validateStagesInputCols\n","text/chunk yesterday | mapped_date: 2023/02/03\n","text/chunk  day before | mapped_date: 2023/02/03\n","text/chunk today | mapped_date: 2023/02/04\n","text/chunk tomorrow | mapped_date: 2023/02/05\n"]}]}],"metadata":{"colab":{"provenance":[]},"interpreter":{"hash":"60af5c81ffa00bed911704ff054405489da13f9503e86373e95cf9267d593cbf"},"kernelspec":{"display_name":"Python 3.6.10 64-bit ('tensorflow_p36': conda)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"}},"nbformat":4,"nbformat_minor":0}