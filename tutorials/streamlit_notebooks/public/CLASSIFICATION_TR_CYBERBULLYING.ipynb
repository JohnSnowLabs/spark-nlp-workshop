{"cells":[{"cell_type":"markdown","metadata":{"id":"Wcq6iO7eQXB9"},"source":["\n","\n","![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n","\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/SENTIMENT_EN_CYBERBULLYING.ipynb)\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"69nlbFfSQbtI"},"source":["# **Detect bullying in tweets**"]},{"cell_type":"markdown","metadata":{"id":"At_1tTpNQ4xa"},"source":["## 1. Colab Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w6o8-g0tEqNz"},"outputs":[],"source":["# Install PySpark and Spark NLP\n","! pip install -q pyspark==3.3.0 spark-nlp==4.2.1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yMmT9S6mE0ad"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import json\n","from pyspark.ml import Pipeline\n","from pyspark.sql.types import StringType, IntegerType\n","from pyspark.sql import SparkSession\n","import pyspark.sql.functions as F\n","from sparknlp.annotator import *\n","from sparknlp.base import *\n","import sparknlp\n","from sparknlp.pretrained import PretrainedPipeline"]},{"cell_type":"markdown","metadata":{"id":"ohBO_O8IQ7Ib"},"source":["## 2. Start Spark Session"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4zBXbY_vE2ss"},"outputs":[],"source":["spark = sparknlp.start()"]},{"cell_type":"markdown","metadata":{"id":"XdltrQa6Q98p"},"source":["## 3. Select the DL model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1XxHWemdE5hX"},"outputs":[],"source":["MODEL_NAME='classifierdl_berturk_cyberbullying'"]},{"cell_type":"markdown","metadata":{"id":"lNL-WnVoRCOr"},"source":["## 4. Some sample examples"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GJ7GCD0pFDvP"},"outputs":[],"source":["text_list = [\"\"\"Gidişin olsun, dönüşün olmasın inşallah senin..\"\"\",\n","         \"\"\"Gidişin ile dönüşün çok sürmez inşallah senin.\"\"\",\n","         \"\"\"Geberesice sırtlan soyu seni.\"\"\",\n","         \"\"\"Sırtlanların çölde geberdiğini görünce üzülen bir insandım.\"\"\",\n","         \"\"\"Bu ne aptal bir adam böyle.\"\"\"]"]},{"cell_type":"markdown","metadata":{"id":"wKvXxQhsRFSh"},"source":["## 5. Define Spark NLP pipeline"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IiYxv0mOFIcX","outputId":"b51604a9-9c27-4c5f-ee8a-5227a135bb87","executionInfo":{"status":"ok","timestamp":1666189318577,"user_tz":-120,"elapsed":73523,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["lemma_antbnc download started this may take some time.\n","Approximate size to download 907.6 KB\n","[OK!]\n","bert_base_turkish_uncased download started this may take some time.\n","Approximate size to download 395.8 MB\n","[OK!]\n","classifierdl_berturk_cyberbullying download started this may take some time.\n","Approximate size to download 22.5 MB\n","[OK!]\n"]}],"source":["documentAssembler = DocumentAssembler()\\\n","    .setInputCol(\"text\")\\\n","    .setOutputCol(\"document\")\n","\n","tokenizer = Tokenizer() \\\n","    .setInputCols([\"document\"]) \\\n","    .setOutputCol(\"token\")\n","      \n","normalizer = Normalizer() \\\n","    .setInputCols([\"token\"]) \\\n","    .setOutputCol(\"normalized\")\n","\n","stopwords_cleaner = StopWordsCleaner()\\\n","    .setInputCols(\"normalized\")\\\n","    .setOutputCol(\"cleanTokens\")\\\n","    .setCaseSensitive(False)\n","\n","lemma = LemmatizerModel.pretrained('lemma_antbnc') \\\n","    .setInputCols([\"cleanTokens\"]) \\\n","    .setOutputCol(\"lemma\")\n","    \n","berturk_embeddings = BertEmbeddings.pretrained(\"bert_base_turkish_uncased\", \"tr\") \\\n","      .setInputCols(\"document\", \"lemma\") \\\n","      .setOutputCol(\"embeddings\")\n","\n","embeddingsSentence = SentenceEmbeddings() \\\n","      .setInputCols([\"document\", \"embeddings\"]) \\\n","      .setOutputCol(\"sentence_embeddings\") \\\n","      .setPoolingStrategy(\"AVERAGE\")\n","\n","document_classifier = ClassifierDLModel.pretrained(MODEL_NAME, 'tr') \\\n","  .setInputCols([\"document\", \"sentence_embeddings\"]) \\\n","  .setOutputCol(\"class_\")\n","\n","nlpPipeline = Pipeline(\n","      stages = [\n","          documentAssembler, \n","          tokenizer, normalizer, \n","          stopwords_cleaner, \n","          lemma, \n","          berturk_embeddings, \n","          embeddingsSentence, \n","          document_classifier])\n"]},{"cell_type":"markdown","metadata":{"id":"xHX_4kmDRIYG"},"source":["## 6. Run the pipeline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mu8-zrx8RP6h"},"outputs":[],"source":["df = spark.createDataFrame(text_list, StringType()).toDF(\"text\")\n","result = nlpPipeline.fit(df).transform(df)"]},{"cell_type":"markdown","metadata":{"id":"huwbT786RKuY"},"source":["## 7. Visualize results"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_ZhzQGwjCySL","outputId":"14df37af-db6c-4a3e-c931-dd4d688d0805","executionInfo":{"status":"ok","timestamp":1666189334164,"user_tz":-120,"elapsed":10977,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------------------------------------------------------+-------+\n","|document                                                   |class  |\n","+-----------------------------------------------------------+-------+\n","|Gidişin olsun, dönüşün olmasın inşallah senin..            |Pozitif|\n","|Gidişin ile dönüşün çok sürmez inşallah senin.             |Pozitif|\n","|Geberesice sırtlan soyu seni.                              |Negatif|\n","|Sırtlanların çölde geberdiğini görünce üzülen bir insandım.|Pozitif|\n","|Bu ne aptal bir adam böyle.                                |Negatif|\n","+-----------------------------------------------------------+-------+\n","\n"]}],"source":["result.select(F.explode(F.arrays_zip(result.document.result, \n","                                     result.class_.result)).alias(\"cols\")) \\\n","      .select(F.expr(\"cols['0']\").alias(\"document\"),\n","              F.expr(\"cols['1']\").alias(\"class\")).show(truncate=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o24k2CpLVwxE"},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"interpreter":{"hash":"60af5c81ffa00bed911704ff054405489da13f9503e86373e95cf9267d593cbf"},"kernelspec":{"display_name":"Python 3.6.10 64-bit ('tensorflow_p36': conda)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"}},"nbformat":4,"nbformat_minor":0}