{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SENTIMENT_UR.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/public/SENTIMENT_UR.ipynb)"
      ],
      "metadata": {
        "id": "eZU4hmc4IK9G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Analyze sentiment in Urdu movie reviews and tweets**"
      ],
      "metadata": {
        "id": "iu-P9dPHJ6iX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Colab Setup**"
      ],
      "metadata": {
        "id": "8e0HUE_QH3_I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcPe-BmbvijG"
      },
      "outputs": [],
      "source": [
        "# Install PySpark and Spark NLP\n",
        "! pip install -q pyspark==3.1.2 spark-nlp==3.4.4\n",
        "\n",
        "# Install Spark NLP Display lib\n",
        "! pip install --upgrade -q spark-nlp-display"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Start the Spark session**"
      ],
      "metadata": {
        "id": "Oyszm0lfKLgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sparknlp\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "pd.set_option('display.max_columns', None)  \n",
        "pd.set_option('display.expand_frame_repr', False)\n",
        "pd.set_option('max_colwidth', None)\n",
        "\n",
        "import string\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "spark = sparknlp.start()\n",
        "\n",
        "print(\"Spark NLP version\", sparknlp.version())\n",
        "print(\"Apache Spark version:\", spark.version)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkIDVLZlwJZH",
        "outputId": "63d6f02d-7591-4276-d4d9-0ea4a0b80f73"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP version 3.4.4\n",
            "Apache Spark version: 3.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ğŸ” For about model**"
      ],
      "metadata": {
        "id": "zdkipZ63LY9-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "ğŸ“Œ **\"sentimentdl_urduvec_imdb\"**--> *Analyse sentiment in reviews by classifying them as positive or negative. This model is trained using urduvec_140M_300d word embeddings. The word embeddings are then converted to sentence embeddings before feeding to the sentiment classifier which uses a DL architecture to classify sentences.*\n",
        "\n",
        "*  positive , negative\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Hm8RnxGNJptO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ğŸ”Define Spark NLP pipeline**"
      ],
      "metadata": {
        "id": "STkeDskc4RCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document_assembler = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "sentence_detector = SentenceDetector() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"sentence\")\n",
        "\n",
        "tokenizer = Tokenizer() \\\n",
        "    .setInputCols([\"sentence\"]) \\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "word_embeddings = WordEmbeddingsModel()\\\n",
        "    .pretrained('urduvec_140M_300d', 'ur')\\\n",
        "    .setInputCols([\"sentence\",'token'])\\\n",
        "    .setOutputCol(\"word_embeddings\")\n",
        "\n",
        "sentence_embeddings = SentenceEmbeddings() \\\n",
        "    .setInputCols([\"sentence\", \"word_embeddings\"]) \\\n",
        "    .setOutputCol(\"sentence_embeddings\") \\\n",
        "    .setPoolingStrategy(\"AVERAGE\")\n",
        "\n",
        "classifier = SentimentDLModel.pretrained('sentimentdl_urduvec_imdb', 'ur' )\\\n",
        "    .setInputCols(['sentence_embeddings'])\\\n",
        "    .setOutputCol('sentiment')\n",
        "\n",
        "nlpPipeline = Pipeline(stages=[ document_assembler,\n",
        "                                sentence_detector, \n",
        "                                tokenizer,\n",
        "                                word_embeddings,\n",
        "                                sentence_embeddings,\n",
        "                                classifier\n",
        "                                 ])\n",
        "\n",
        "empty_df = spark.createDataFrame([['']]).toDF(\"text\")\n",
        "pipelineModel = nlpPipeline.fit(empty_df)\n",
        "light_model = LightPipeline(pipelineModel)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuUVv0eOGjnQ",
        "outputId": "cb98eab7-844e-4675-a16c-7a8acaa5adbe"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "urduvec_140M_300d download started this may take some time.\n",
            "Approximate size to download 110.2 MB\n",
            "[OK!]\n",
            "sentimentdl_urduvec_imdb download started this may take some time.\n",
            "Approximate size to download 9 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ğŸ”Sample text**"
      ],
      "metadata": {
        "id": "LUH8FUAZhzoC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "    ÛŒÛ Ú©Ø±Ø¯Ø§Ø± Ø²Ù†Ø¯Û Ø¯Ù„ Ø§ÙˆØ± Ø¯Ù„Ú†Ø³Ù¾ ØªÚ¾Û’ ØŒ Ù¾Ù„Ø§Ù¹ Ø¨ÛØªØ±ÛŒÙ† Ø·ÙˆØ± Ù¾Ø± Ú†Ù„ Ø±ÛØ§ ØªÚ¾Ø§ ØŒ Ù¾Ø§Ø¦Ø±Ùˆ Ø§Ø«Ø±Ø§Øª Ú©Ùˆ Ù…ÛØ§Ø±Øª Ú©Û’ Ø³Ø§ØªÚ¾ Ø§Ù†Ø¬Ø§Ù… Ø¯ÛŒØ§ Ú¯ÛŒØ§ ØªÚ¾Ø§ ØŒ Ø§ÙˆØ± Ø§Ø³ Ù…ÛŒÚº Ø§ÛŒÚ© Ø¨Ù†ÛŒØ§Ø¯ÛŒ Ù…Ø­Ø¨Øª Ú©ÛŒ Ù…Ø«Ù„Ø« Ú©ÛŒ Ú©ÛØ§Ù†ÛŒ Ù„ÛŒ Ú¯Ø¦ÛŒ ÛÛ’ Ø§ÙˆØ± Ø§Ø³ Ù…ÛŒÚº Ø³Ø§Ø¦Ù†Ø³ ÙÚ©Ø´Ù† Ø¹Ù†ØµØ± Ú©Ùˆ Ù¾Ú¾ÛŒÙ†Ú© Ø¯ÛŒØ§ Ú¯ÛŒØ§ ÛÛ’Û” Ù…ÛŒÚº Ø¨ÛØª Ø³Ø§Ø±Û’ Ú©Ø±Ø¯Ø§Ø±ÙˆÚº Ú©Û’ Ø³Ø§ØªÚ¾ Ø§Ù† Ú©ÛŒ Ù†Ø´Ø§Ù†Ø¯ÛÛŒ Ú©Ø±Ø³Ú©ØªØ§ ØªÚ¾Ø§ Ø§ÙˆØ± Ø§Ù† Ú©Û’ Ù…Ø­Ø±Ú©Ø§Øª Ù†Û’ Ú©ÛØ§Ù†ÛŒ Ú©Û’ ÙØ±ÛŒÙ… ÙˆØ±Ú© Ù…ÛŒÚº Ù…Ù†Ø·Ù‚ÛŒ Ø¹Ù‚Ù„ÛŒ Ø§Ø­Ø³Ø§Ø³ Ù¾ÛŒØ¯Ø§ Ú©ÛŒØ§ ØªÚ¾Ø§Û” Ú©ÛŒÙ…Ø±Ø§ Ú©Ø§Ù… Ø¨ÛØª Ø§Ú†Ú¾Ø§ ØªÚ¾Ø§ ØŒ Ø¢ÚˆÛŒÙˆ ÙˆØ§Ø¶Ø­ Ø§ÙˆØ± Ø¯Ø±Ø³Øª ØªÚ¾Ø§ ØŒ Ø¨ÛŒÚ© Ú¯Ø±Ø§Ø¤Ù†Úˆ Ù…ÛŒÙˆØ²Ú© Ú©Ùˆ Ø§Ø«Ø± Ø§Ù†Ø¯Ø§Ø² Ú©Û’ Ù„Ø¦Û’ Ù…Ù†ØªØ®Ø¨ Ú©ÛŒØ§ Ú¯ÛŒØ§ ØªÚ¾Ø§ ØŒ Ú¯Ø§Ù†Û’ ÙˆØ§Ù„Û’ ÙØ§Ø¦Ø± Ù…ÛŒÙ† Ø§ÛŒÚ© Ø§Ú†Ú¾Û’ Ø¨Ø§ØµÙ„Ø§Ø­ÛŒØª ÛŒØ§Ø¯Ú¯Ø§Ø± ØªÚ¾Û’Û” Ø¹Ø¬ÛŒØ¨ Ú©ÛŒÙÛŒØª ØŒ Ø³ÛŒÙ¹ÙˆÚº Ù†Û’ Ø¨ÛØª Ø¹Ù…Ø¯Û ØªÛŒØ§Ø± Ú©ÛŒØ§ ØŒ Ø§ÙˆØ± ÛÙ†Ø± Ù…Ù†Ø¯ ÛÙ†Ø± Ú©Û’ Ø³Ø§ØªÚ¾ Ø§Ù†Ø¬Ø§Ù… Ø¯ÛŒØ¦Û’ Ú¯Ø¦Û’ Ø®Ø§Øµ Ø§Ø«Ø±Ø§ØªÛ” Ù…ÛŒÚº Ø­ÛŒØ±Øª Ø²Ø¯Û ÛÙˆÚº Ú©Û Ú©Ø³ Ø·Ø±Ø­ Ú†ÛŒÙ† Ø§Ø³Ù¹ÙˆØ± Ú©ÛŒ Ù¾Ø§Ø±Ú©Ù†Ú¯ Ù…ÛŒÚº Ù¾ÙˆØ±ÛŒ Ù…Ù†ÛŒ Ú©Ø§Ø±Ù†ÛŒÙˆØ§Ù„ Ú©Ùˆ Ø§ÛŒÚ© ÛÛŒ Ù„ÛŒÙ…Ù¾Ù¾ÙˆØ³Ù¹ Ø¢Ø¤Ù¹ Ù„ÛŒÙ¹ Ú©Û’ Ø°Ø±ÛŒØ¹Û ØªÙ‚ÙˆÛŒØª Ù…Ù„ Ø³Ú©ØªÛŒ ÛÛ’Û” Ú©Ù… Ø³Û’ Ú©Ù… Ú©ÛÙ†Ø§ Ù†Ø§Ù…Ù…Ú©Ù† Ù„Ú¯ØªØ§ ÛÛ’Û” ÙÙ„Ù… Ú©Û’ Ø§Ø®ØªØªØ§Ù… Ú©Û’ Ù‚Ø±ÛŒØ¨ Ø¨Ú¾Ø§Ø¦ÛŒÙˆÚº Ú©Û’ Ù…Ø§Ø¨ÛŒÙ† Ù„Ú‘Ø§Ø¦ÛŒ Ø´Ø§Ù†Ø¯Ø§Ø± ØªÚ¾ÛŒÛ” Ø¬Ù… ÙˆØ±Ù†ÛŒ Ú©Ùˆ ØºÛŒØ± Ø¬ÙˆÚ©Ø± ÙˆØ§Ù„Û’ Ú©Ø±Ø¯Ø§Ø± Ù…ÛŒÚº Ø±Ú©Ú¾Ù†Ø§ Ø¨Ú¾ÛŒ Ø§ÛŒÚ© Ø­ÛŒØ±Øª Ø§Ù†Ú¯ÛŒØ² Ù¹Ú† ØªÚ¾Ø§ Ú©ÛŒÙˆÙ†Ú©Û Ø§Ø³ Ù†Û’ Ø§ÛŒÚ© Ú©Ø§Ø±Ù†ÛŒ Ú©Ø§ Ù†ÛŒÙ… Ø³Ù†Ø¬ÛŒØ¯Û Ú©Ø±Ø¯Ø§Ø± Ø¨ÛØª Ø¹Ù…Ø¯Û Ø§Ø¯Ø§ Ú©ÛŒØ§ ØªÚ¾Ø§Û”\"\"\""
      ],
      "metadata": {
        "id": "OoX5nXgJp4Py"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.createDataFrame([[text]]).toDF('text')\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEjum6jgpRSh",
        "outputId": "6a9970c9-4679-4f6c-fe1a-c0d664caeac6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|                text|\n",
            "+--------------------+\n",
            "|\n",
            "    ÛŒÛ Ú©Ø±Ø¯Ø§Ø± Ø²Ù†Ø¯...|\n",
            "+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ğŸ”Run the pipeline**"
      ],
      "metadata": {
        "id": "OD9FO4pahgSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = pipelineModel.transform(df)"
      ],
      "metadata": {
        "id": "Z8Dhyq1YpNDu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.select('sentiment.result', 'sentence.result').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cyWEx5tqTEv",
        "outputId": "df3ef9c9-8029-4500-e635-975c37d5579f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------------+\n",
            "|    result|              result|\n",
            "+----------+--------------------+\n",
            "|[positive]|[ÛŒÛ Ú©Ø±Ø¯Ø§Ø± Ø²Ù†Ø¯Û Ø¯Ù„...|\n",
            "+----------+--------------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}