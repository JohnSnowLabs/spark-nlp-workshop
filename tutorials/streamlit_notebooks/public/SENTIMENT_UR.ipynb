{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SENTIMENT_UR.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/public/SENTIMENT_UR.ipynb)"
      ],
      "metadata": {
        "id": "eZU4hmc4IK9G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Analyze sentiment in Urdu movie reviews and tweets**"
      ],
      "metadata": {
        "id": "iu-P9dPHJ6iX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Colab Setup**"
      ],
      "metadata": {
        "id": "8e0HUE_QH3_I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcPe-BmbvijG"
      },
      "outputs": [],
      "source": [
        "# Install PySpark and Spark NLP\n",
        "! pip install -q pyspark==3.1.2 spark-nlp==3.4.4\n",
        "\n",
        "# Install Spark NLP Display lib\n",
        "! pip install --upgrade -q spark-nlp-display"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Start the Spark session**"
      ],
      "metadata": {
        "id": "Oyszm0lfKLgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sparknlp\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "pd.set_option('display.max_columns', None)  \n",
        "pd.set_option('display.expand_frame_repr', False)\n",
        "pd.set_option('max_colwidth', None)\n",
        "\n",
        "import string\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "spark = sparknlp.start()\n",
        "\n",
        "print(\"Spark NLP version\", sparknlp.version())\n",
        "print(\"Apache Spark version:\", spark.version)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkIDVLZlwJZH",
        "outputId": "63d6f02d-7591-4276-d4d9-0ea4a0b80f73"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP version 3.4.4\n",
            "Apache Spark version: 3.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **🔎 For about model**"
      ],
      "metadata": {
        "id": "zdkipZ63LY9-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "📌 **\"sentimentdl_urduvec_imdb\"**--> *Analyse sentiment in reviews by classifying them as positive or negative. This model is trained using urduvec_140M_300d word embeddings. The word embeddings are then converted to sentence embeddings before feeding to the sentiment classifier which uses a DL architecture to classify sentences.*\n",
        "\n",
        "*  positive , negative\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Hm8RnxGNJptO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **🔎Define Spark NLP pipeline**"
      ],
      "metadata": {
        "id": "STkeDskc4RCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document_assembler = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "sentence_detector = SentenceDetector() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"sentence\")\n",
        "\n",
        "tokenizer = Tokenizer() \\\n",
        "    .setInputCols([\"sentence\"]) \\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "word_embeddings = WordEmbeddingsModel()\\\n",
        "    .pretrained('urduvec_140M_300d', 'ur')\\\n",
        "    .setInputCols([\"sentence\",'token'])\\\n",
        "    .setOutputCol(\"word_embeddings\")\n",
        "\n",
        "sentence_embeddings = SentenceEmbeddings() \\\n",
        "    .setInputCols([\"sentence\", \"word_embeddings\"]) \\\n",
        "    .setOutputCol(\"sentence_embeddings\") \\\n",
        "    .setPoolingStrategy(\"AVERAGE\")\n",
        "\n",
        "classifier = SentimentDLModel.pretrained('sentimentdl_urduvec_imdb', 'ur' )\\\n",
        "    .setInputCols(['sentence_embeddings'])\\\n",
        "    .setOutputCol('sentiment')\n",
        "\n",
        "nlpPipeline = Pipeline(stages=[ document_assembler,\n",
        "                                sentence_detector, \n",
        "                                tokenizer,\n",
        "                                word_embeddings,\n",
        "                                sentence_embeddings,\n",
        "                                classifier\n",
        "                                 ])\n",
        "\n",
        "empty_df = spark.createDataFrame([['']]).toDF(\"text\")\n",
        "pipelineModel = nlpPipeline.fit(empty_df)\n",
        "light_model = LightPipeline(pipelineModel)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuUVv0eOGjnQ",
        "outputId": "cb98eab7-844e-4675-a16c-7a8acaa5adbe"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "urduvec_140M_300d download started this may take some time.\n",
            "Approximate size to download 110.2 MB\n",
            "[OK!]\n",
            "sentimentdl_urduvec_imdb download started this may take some time.\n",
            "Approximate size to download 9 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **🔎Sample text**"
      ],
      "metadata": {
        "id": "LUH8FUAZhzoC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "    یہ کردار زندہ دل اور دلچسپ تھے ، پلاٹ بہترین طور پر چل رہا تھا ، پائرو اثرات کو مہارت کے ساتھ انجام دیا گیا تھا ، اور اس میں ایک بنیادی محبت کی مثلث کی کہانی لی گئی ہے اور اس میں سائنس فکشن عنصر کو پھینک دیا گیا ہے۔ میں بہت سارے کرداروں کے ساتھ ان کی نشاندہی کرسکتا تھا اور ان کے محرکات نے کہانی کے فریم ورک میں منطقی عقلی احساس پیدا کیا تھا۔ کیمرا کام بہت اچھا تھا ، آڈیو واضح اور درست تھا ، بیک گراؤنڈ میوزک کو اثر انداز کے لئے منتخب کیا گیا تھا ، گانے والے فائر مین ایک اچھے باصلاحیت یادگار تھے۔ عجیب کیفیت ، سیٹوں نے بہت عمدہ تیار کیا ، اور ہنر مند ہنر کے ساتھ انجام دیئے گئے خاص اثرات۔ میں حیرت زدہ ہوں کہ کس طرح چین اسٹور کی پارکنگ میں پوری منی کارنیوال کو ایک ہی لیمپپوسٹ آؤٹ لیٹ کے ذریعہ تقویت مل سکتی ہے۔ کم سے کم کہنا ناممکن لگتا ہے۔ فلم کے اختتام کے قریب بھائیوں کے مابین لڑائی شاندار تھی۔ جم ورنی کو غیر جوکر والے کردار میں رکھنا بھی ایک حیرت انگیز ٹچ تھا کیونکہ اس نے ایک کارنی کا نیم سنجیدہ کردار بہت عمدہ ادا کیا تھا۔\"\"\""
      ],
      "metadata": {
        "id": "OoX5nXgJp4Py"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.createDataFrame([[text]]).toDF('text')\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEjum6jgpRSh",
        "outputId": "6a9970c9-4679-4f6c-fe1a-c0d664caeac6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|                text|\n",
            "+--------------------+\n",
            "|\n",
            "    یہ کردار زند...|\n",
            "+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **🔎Run the pipeline**"
      ],
      "metadata": {
        "id": "OD9FO4pahgSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = pipelineModel.transform(df)"
      ],
      "metadata": {
        "id": "Z8Dhyq1YpNDu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.select('sentiment.result', 'sentence.result').show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cyWEx5tqTEv",
        "outputId": "df3ef9c9-8029-4500-e635-975c37d5579f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------------+\n",
            "|    result|              result|\n",
            "+----------+--------------------+\n",
            "|[positive]|[یہ کردار زندہ دل...|\n",
            "+----------+--------------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}