{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CLASSIFICATION_MULTILABEL_TOXIC.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EotGy802StAn",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/CLASSIFICATION_MULTILABEL_TOXIC.ipynb)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZGjocpuSwmn",
        "colab_type": "text"
      },
      "source": [
        "# **Detect toxic content in comments**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tYdYPhkSmMTE"
      },
      "source": [
        "## 1. Colab setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "izRnq4e08XKs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "c40de2e8-5357-4e8f-b1fa-58289409e612"
      },
      "source": [
        "# Install java\n",
        "!apt-get update -qq\n",
        "!apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "!java -version\n",
        "\n",
        "# This is only to setup PySpark and Spark NLP on Colab\n",
        "# -p is for pyspark\n",
        "# -s is for spark-nlp\n",
        "# !bash colab_setup.sh -p 3.1.1 -s 3.0.0  \n",
        "# by default they are set to the latest\n",
        "\n",
        "!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/colab_setup.sh\n",
        "!bash colab_setup.sh\n",
        "\n",
        "!wget -q https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/scripts/colab/pyspark.sh\n",
        "!bash pyspark.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 215.7MB 69kB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 39.5MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 133kB 4.6MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sxs7u_Xo7-i9",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import json\n",
        "os.environ['JAVA_HOME'] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ['PATH'] = os.environ['JAVA_HOME'] + \"/bin:\" + os.environ['PATH']\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "import sparknlp\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "\n",
        "# Start Spark session\n",
        "spark = sparknlp.start(gpu=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "F-53R49pmSBN"
      },
      "source": [
        "## 2. Pipeline creation and training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "07Cw1BGrmGTo"
      },
      "source": [
        "Create pipeline to be trained on example inputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DYVAXYXW7-jf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "7a78d7c0-d679-47b8-ec6a-5dab9cf7f8a5"
      },
      "source": [
        "document_assembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"text\") \\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "sentence_detector = SentenceDetector() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"sentence\")\n",
        "\n",
        "tokenizer = Tokenizer() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "embeddingsSentence = UniversalSentenceEncoder.pretrained(lang='en') \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"sentence_embeddings\")\n",
        "\n",
        "classsifierdl = MultiClassifierDLApproach() \\\n",
        "    .setInputCols([\"sentence_embeddings\"]) \\\n",
        "    .setOutputCol(\"class\") \\\n",
        "    .setLabelColumn(\"labels\") \\\n",
        "    .setMaxEpochs(10) \\\n",
        "    .setLr(1e-3) \\\n",
        "    .setThreshold(0.7) \\\n",
        "    .setValidationSplit(0.2) \\\n",
        "    .setOutputLogsPath('./') \\\n",
        "    .setEnableOutputLogs(True)\n",
        "\n",
        "pipeline = Pipeline(stages=[\n",
        "    document_assembler,\n",
        "    tokenizer,\n",
        "    embeddingsSentence,\n",
        "    classsifierdl\n",
        "])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tfhub_use download started this may take some time.\n",
            "Approximate size to download 923.7 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WRQRt36fmA9_"
      },
      "source": [
        "Download training and testing datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dsBntyOYS3T9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "19e2da9d-7fc1-43dc-c21d-853ae5839bf9"
      },
      "source": [
        "! curl -O 'https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/classifier-dl/toxic_comments/toxic_train.snappy.parquet'\n",
        "! curl -O 'https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/classifier-dl/toxic_comments/toxic_test.snappy.parquet'\n",
        "trainDataset = spark.read.parquet(\"toxic_train.snappy.parquet\")\n",
        "testDataset = spark.read.parquet(\"toxic_test.snappy.parquet\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 2702k  100 2702k    0     0  9099k      0 --:--:-- --:--:-- --:--:-- 9099k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  289k  100  289k    0     0  1288k      0 --:--:-- --:--:-- --:--:-- 1288k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFiOVvswSqcC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res = trainDataset.toPandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Hh1h5WJMSqcE",
        "colab_type": "code",
        "colab": {},
        "outputId": "00750c89-0efd-43eb-ed8b-1bbec14bc6f8"
      },
      "source": [
        "res"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00024b59235015f3</td>\n",
              "      <td>Virgin\\nMy only warning? You'll block me? Well...</td>\n",
              "      <td>[toxic, obscene, insult]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0002bcb3da6cb337</td>\n",
              "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
              "      <td>[toxic, severe_toxic, obscene, insult]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000521f420b7ac15</td>\n",
              "      <td>Words can't describe how annoying I find you W...</td>\n",
              "      <td>[toxic]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0005c987bdfc9d4b</td>\n",
              "      <td>Hey... what is it..\\n@ | talk .\\nWhat is it......</td>\n",
              "      <td>[toxic]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>000e5ac5aa216bac</td>\n",
              "      <td>\"\\n\\n Cut the Shit \\n\\nWill you please cut the...</td>\n",
              "      <td>[toxic, obscene, insult]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14615</th>\n",
              "      <td>fff631d42c6abb63</td>\n",
              "      <td>you marked my edit as vandilisim when i was st...</td>\n",
              "      <td>[toxic, obscene, insult]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14616</th>\n",
              "      <td>fffb8bea1d5e4d3b</td>\n",
              "      <td>yes, yes, thank you. good to know, but who dec...</td>\n",
              "      <td>[toxic, obscene, insult]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14617</th>\n",
              "      <td>fffd0ce82f58251e</td>\n",
              "      <td>[to any of those fucking admins]</td>\n",
              "      <td>[toxic, obscene]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14618</th>\n",
              "      <td>fffdc608b84c9b27</td>\n",
              "      <td>That last link you gave me does not make sense...</td>\n",
              "      <td>[toxic]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14619</th>\n",
              "      <td>fffedeecd0364534</td>\n",
              "      <td>to be driven away and die</td>\n",
              "      <td>[toxic]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14620 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     id                                               text  \\\n",
              "0      00024b59235015f3  Virgin\\nMy only warning? You'll block me? Well...   \n",
              "1      0002bcb3da6cb337       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK   \n",
              "2      000521f420b7ac15  Words can't describe how annoying I find you W...   \n",
              "3      0005c987bdfc9d4b  Hey... what is it..\\n@ | talk .\\nWhat is it......   \n",
              "4      000e5ac5aa216bac  \"\\n\\n Cut the Shit \\n\\nWill you please cut the...   \n",
              "...                 ...                                                ...   \n",
              "14615  fff631d42c6abb63  you marked my edit as vandilisim when i was st...   \n",
              "14616  fffb8bea1d5e4d3b  yes, yes, thank you. good to know, but who dec...   \n",
              "14617  fffd0ce82f58251e                   [to any of those fucking admins]   \n",
              "14618  fffdc608b84c9b27  That last link you gave me does not make sense...   \n",
              "14619  fffedeecd0364534                          to be driven away and die   \n",
              "\n",
              "                                       labels  \n",
              "0                    [toxic, obscene, insult]  \n",
              "1      [toxic, severe_toxic, obscene, insult]  \n",
              "2                                     [toxic]  \n",
              "3                                     [toxic]  \n",
              "4                    [toxic, obscene, insult]  \n",
              "...                                       ...  \n",
              "14615                [toxic, obscene, insult]  \n",
              "14616                [toxic, obscene, insult]  \n",
              "14617                        [toxic, obscene]  \n",
              "14618                                 [toxic]  \n",
              "14619                                 [toxic]  \n",
              "\n",
              "[14620 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxoKXXmPSqcH",
        "colab_type": "code",
        "colab": {},
        "outputId": "796a7a42-0cd1-43ed-8e78-30e0cee070f1"
      },
      "source": [
        "all_labs = []\n",
        "for r in res['labels'].values:\n",
        "    all_labs.extend(r)\n",
        "set(all_labs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'identity_hate', 'insult', 'obscene', 'severe_toxic', 'threat', 'toxic'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qIIF2e1Kl4fF"
      },
      "source": [
        "Train the pipeline model on the training dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WlGbDPbjRQ_E",
        "colab": {}
      },
      "source": [
        "pipelineModel = pipeline.fit(trainDataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fm-0aY6Gmppl"
      },
      "source": [
        "Example training log:\n",
        "\n",
        "\n",
        "```\n",
        "Training started - epochs: 10 - learning_rate: 0.001 - batch_size: 64 - training_examples: 127657 - classes: 7\n",
        "Epoch 0/10 - 46.00s - loss: 0.079907365 - acc: 0.9723665 - val_loss: 0.07093345 - val_acc: 0.97352755 - val_f1: 0.91585624 - val_tpr: 0.9008827 - batches: 1995\n",
        "Epoch 1/10 - 28.26s - loss: 0.06964213 - acc: 0.9747156 - val_loss: 0.069492534 - val_acc: 0.9739863 - val_f1: 0.91734964 - val_tpr: 0.9029063 - batches: 1995\n",
        "Epoch 2/10 - 27.99s - loss: 0.06808146 - acc: 0.9752242 - val_loss: 0.06841504 - val_acc: 0.97444665 - val_f1: 0.9187962 - val_tpr: 0.9039833 - batches: 1995\n",
        "Epoch 3/10 - 27.94s - loss: 0.066884466 - acc: 0.9757066 - val_loss: 0.06769186 - val_acc: 0.9746787 - val_f1: 0.9195223 - val_tpr: 0.90438014 - batches: 1995\n",
        "Epoch 4/10 - 28.04s - loss: 0.06587076 - acc: 0.9761073 - val_loss: 0.067252316 - val_acc: 0.9749198 - val_f1: 0.92028916 - val_tpr: 0.9049118 - batches: 1995\n",
        "Epoch 5/10 - 28.05s - loss: 0.06501821 - acc: 0.97637606 - val_loss: 0.06700255 - val_acc: 0.9750182 - val_f1: 0.9205762 - val_tpr: 0.90496385 - batches: 1995\n",
        "Epoch 6/10 - 27.92s - loss: 0.064287946 - acc: 0.9765889 - val_loss: 0.06686394 - val_acc: 0.9750045 - val_f1: 0.9205367 - val_tpr: 0.904986 - batches: 1995\n",
        "Epoch 7/10 - 28.19s - loss: 0.063645855 - acc: 0.97682655 - val_loss: 0.0667824 - val_acc: 0.97498673 - val_f1: 0.92048156 - val_tpr: 0.90499973 - batches: 1995\n",
        "Epoch 8/10 - 28.53s - loss: 0.06306508 - acc: 0.97704613 - val_loss: 0.06673989 - val_acc: 0.974991 - val_f1: 0.9205486 - val_tpr: 0.9056079 - batches: 1995\n",
        "Epoch 9/10 - 28.61s - loss: 0.0625258 - acc: 0.97720623 - val_loss: 0.06672904 - val_acc: 0.9750411 - val_f1: 0.9207759 - val_tpr: 0.90621996 - batches: 1995\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pD1oGGgwmVUe"
      },
      "source": [
        "## 3. Testing and examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lzia33pWl0Lc"
      },
      "source": [
        "Run the model on the test dataset to evaluate performance and generate examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VUo4_e2s7-js",
        "colab": {}
      },
      "source": [
        "test_res = pipelineModel.transform(testDataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VFCxC-YwlobE"
      },
      "source": [
        "Visualizing the raw test dataset after classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F9cTSIObV0_C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        },
        "outputId": "316893d7-9e97-48c7-e9ab-c2cb8f33bee6"
      },
      "source": [
        "test_res.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|              id|                text|              labels|            document|               token| sentence_embeddings|               class|\n",
            "+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|0007e25b2121310b|Bye! \n",
            "\n",
            "Don't look...|             [toxic]|[[document, 0, 56...|[[token, 0, 2, By...|[[sentence_embedd...|[[category, 0, 56...|\n",
            "|001956c382006abd|I'm Sorry \n",
            "\n",
            "I'm s...|             [toxic]|[[document, 0, 31...|[[token, 0, 2, I'...|[[sentence_embedd...|[[category, 0, 31...|\n",
            "|00c1b6962307c80e|Well you are ridi...|             [toxic]|[[document, 0, 95...|[[token, 0, 3, We...|[[sentence_embedd...|[[category, 0, 95...|\n",
            "|0109d5a4788850f7|Thank you for you...|[toxic, obscene, ...|[[document, 0, 71...|[[token, 0, 4, Th...|[[sentence_embedd...|[[category, 0, 71...|\n",
            "|011e2c96cfa8a055|Fucked with the w...|    [toxic, obscene]|[[document, 0, 58...|[[token, 0, 5, Fu...|[[sentence_embedd...|[[category, 0, 58...|\n",
            "|0120c81c20837d0a|Fat Niggers? \n",
            "Sho...|[toxic, obscene, ...|[[document, 0, 78...|[[token, 0, 2, Fa...|[[sentence_embedd...|[[category, 0, 78...|\n",
            "|01465fd903558524|Lots of that othe...|    [toxic, obscene]|[[document, 0, 76...|[[token, 0, 3, Lo...|[[sentence_embedd...|[[category, 0, 76...|\n",
            "|018d92501fc50d09|Did you go to Aus...|             [toxic]|[[document, 0, 11...|[[token, 0, 2, Di...|[[sentence_embedd...|[[category, 0, 11...|\n",
            "|018e6f1e1b18723a|\"\n",
            "\n",
            " Another crap ...|             [toxic]|[[document, 0, 55...|[[token, 0, 0, \",...|[[sentence_embedd...|[[category, 0, 55...|\n",
            "|0199d6af27b715f3|I'm also a sock p...|     [toxic, threat]|[[document, 0, 13...|[[token, 0, 2, I'...|[[sentence_embedd...|[[category, 0, 13...|\n",
            "|01f304185a18cb7b|Don't peddle your...|             [toxic]|[[document, 0, 98...|[[token, 0, 4, Do...|[[sentence_embedd...|[[category, 0, 98...|\n",
            "|0251ad80bf585093|P.S. Are you a /b...|             [toxic]|[[document, 0, 22...|[[token, 0, 2, P....|[[sentence_embedd...|[[category, 0, 22...|\n",
            "|02526d2f0b73abe4|Have the balls to...|[toxic, obscene, ...|[[document, 0, 16...|[[token, 0, 3, Ha...|[[sentence_embedd...|[[category, 0, 16...|\n",
            "|026561cbdbc6ff5a|[Maria], you damn...|             [toxic]|[[document, 0, 15...|[[token, 0, 6, [M...|[[sentence_embedd...|[[category, 0, 15...|\n",
            "|029e65e9e69f6662|Fuuck you you bud...|[toxic, severe_to...|[[document, 0, 34...|[[token, 0, 4, Fu...|[[sentence_embedd...|[[category, 0, 34...|\n",
            "|02a1ac2c706d3306|FisherQueen, woul...|             [toxic]|[[document, 0, 16...|[[token, 0, 10, F...|[[sentence_embedd...|[[category, 0, 16...|\n",
            "|02fe38c6d10c97a5|Get off your high...|             [toxic]|[[document, 0, 36...|[[token, 0, 2, Ge...|[[sentence_embedd...|[[category, 0, 36...|\n",
            "|030ed098f411f8c7|Cavorting with He...|[toxic, severe_to...|[[document, 0, 41...|[[token, 0, 8, Ca...|[[sentence_embedd...|[[category, 0, 41...|\n",
            "|0349653f81b942ba|What a joker you ...|             [toxic]|[[document, 0, 46...|[[token, 0, 3, Wh...|[[sentence_embedd...|[[category, 0, 46...|\n",
            "|039281cfaf5a7462|\"\n",
            "\n",
            "Lol dumb arabs...|[toxic, obscene, ...|[[document, 0, 11...|[[token, 0, 0, \",...|[[sentence_embedd...|[[category, 0, 11...|\n",
            "+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JlyXUWWulijW"
      },
      "source": [
        "Write some sample inputs and outputs from the test dataset to file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i_rcLmhnWfYS",
        "colab": {}
      },
      "source": [
        "! mkdir -p inputs\n",
        "! mkdir -p outputs\n",
        "\n",
        "result = test_res.toPandas()\n",
        "for i in range(1, 11):\n",
        "    text = result[['document']].iloc[i][0][0].result\n",
        "    with open(f'inputs/{i}.txt', 'w') as f:\n",
        "        f.write(text[:96].replace('\\n', '') + \" ...\\n\" + text)\n",
        "    result[['class']].iloc[i].to_json(f'outputs/{i}.json')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}