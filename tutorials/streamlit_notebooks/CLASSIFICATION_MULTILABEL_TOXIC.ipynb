{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CLASSIFICATION_MULTILABEL_TOXIC.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EotGy802StAn"
      },
      "source": [
        "\n",
        "\n",
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/CLASSIFICATION_MULTILABEL_TOXIC.ipynb)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZGjocpuSwmn"
      },
      "source": [
        "# **Detect toxic content in comments**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYdYPhkSmMTE"
      },
      "source": [
        "## 1. Colab setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izRnq4e08XKs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "113c2510-9a83-459a-e4b0-b9e29ba4313e"
      },
      "source": [
        "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash\n",
        "# !bash colab.sh\n",
        "# -p is for pyspark\n",
        "# -s is for spark-nlp\n",
        "# !bash colab.sh -p 3.1.1 -s 3.0.1\n",
        "# by default they are set to the latest"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"11.0.10\" 2021-01-19\n",
            "OpenJDK Runtime Environment (build 11.0.10+9-Ubuntu-0ubuntu1.18.04)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.10+9-Ubuntu-0ubuntu1.18.04, mixed mode, sharing)\n",
            "setup Colab for PySpark 3.1.1 and Spark NLP 3.0.0\n",
            "\u001b[K     |████████████████████████████████| 212.3MB 68kB/s \n",
            "\u001b[K     |████████████████████████████████| 143kB 44.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 48.0MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxs7u_Xo7-i9"
      },
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "import sparknlp\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "\n",
        "# Start Spark session\n",
        "spark = sparknlp.start()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-53R49pmSBN"
      },
      "source": [
        "## 2. Pipeline creation and training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07Cw1BGrmGTo"
      },
      "source": [
        "Create pipeline to be trained on example inputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYVAXYXW7-jf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d2ed695-80b7-4f61-fbb4-6ebceb11b777"
      },
      "source": [
        "document_assembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"text\") \\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "sentence_detector = SentenceDetector() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"sentence\")\n",
        "\n",
        "tokenizer = Tokenizer() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "embeddingsSentence = UniversalSentenceEncoder.pretrained(lang='en') \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"sentence_embeddings\")\n",
        "\n",
        "classsifierdl = MultiClassifierDLApproach() \\\n",
        "    .setInputCols([\"sentence_embeddings\"]) \\\n",
        "    .setOutputCol(\"class\") \\\n",
        "    .setLabelColumn(\"labels\") \\\n",
        "    .setMaxEpochs(10) \\\n",
        "    .setLr(1e-3) \\\n",
        "    .setThreshold(0.7) \\\n",
        "    .setValidationSplit(0.2) \\\n",
        "    .setOutputLogsPath('./') \\\n",
        "    .setEnableOutputLogs(True)\n",
        "\n",
        "pipeline = Pipeline(stages=[\n",
        "    document_assembler,\n",
        "    tokenizer,\n",
        "    embeddingsSentence,\n",
        "    classsifierdl\n",
        "])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tfhub_use download started this may take some time.\n",
            "Approximate size to download 923.7 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRQRt36fmA9_"
      },
      "source": [
        "Download training and testing datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsBntyOYS3T9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "282c9cb8-1dff-497c-9cfb-c3c91c211927"
      },
      "source": [
        "! curl -O 'https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/classifier-dl/toxic_comments/toxic_train.snappy.parquet'\n",
        "! curl -O 'https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/classifier-dl/toxic_comments/toxic_test.snappy.parquet'\n",
        "trainDataset = spark.read.parquet(\"toxic_train.snappy.parquet\")\n",
        "testDataset = spark.read.parquet(\"toxic_test.snappy.parquet\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 2702k  100 2702k    0     0  3138k      0 --:--:-- --:--:-- --:--:-- 3135k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  289k  100  289k    0     0   472k      0 --:--:-- --:--:-- --:--:--  472k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFiOVvswSqcC"
      },
      "source": [
        "res = trainDataset.toPandas()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Hh1h5WJMSqcE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "b8f23a0b-8622-4328-8b89-0698304456e6"
      },
      "source": [
        "res"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00024b59235015f3</td>\n",
              "      <td>Virgin\\nMy only warning? You'll block me? Well...</td>\n",
              "      <td>[toxic, obscene, insult]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0002bcb3da6cb337</td>\n",
              "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
              "      <td>[toxic, severe_toxic, obscene, insult]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000521f420b7ac15</td>\n",
              "      <td>Words can't describe how annoying I find you W...</td>\n",
              "      <td>[toxic]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0005c987bdfc9d4b</td>\n",
              "      <td>Hey... what is it..\\n@ | talk .\\nWhat is it......</td>\n",
              "      <td>[toxic]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>000e5ac5aa216bac</td>\n",
              "      <td>\"\\n\\n Cut the Shit \\n\\nWill you please cut the...</td>\n",
              "      <td>[toxic, obscene, insult]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14615</th>\n",
              "      <td>fff631d42c6abb63</td>\n",
              "      <td>you marked my edit as vandilisim when i was st...</td>\n",
              "      <td>[toxic, obscene, insult]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14616</th>\n",
              "      <td>fffb8bea1d5e4d3b</td>\n",
              "      <td>yes, yes, thank you. good to know, but who dec...</td>\n",
              "      <td>[toxic, obscene, insult]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14617</th>\n",
              "      <td>fffd0ce82f58251e</td>\n",
              "      <td>[to any of those fucking admins]</td>\n",
              "      <td>[toxic, obscene]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14618</th>\n",
              "      <td>fffdc608b84c9b27</td>\n",
              "      <td>That last link you gave me does not make sense...</td>\n",
              "      <td>[toxic]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14619</th>\n",
              "      <td>fffedeecd0364534</td>\n",
              "      <td>to be driven away and die</td>\n",
              "      <td>[toxic]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14620 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     id  ...                                  labels\n",
              "0      00024b59235015f3  ...                [toxic, obscene, insult]\n",
              "1      0002bcb3da6cb337  ...  [toxic, severe_toxic, obscene, insult]\n",
              "2      000521f420b7ac15  ...                                 [toxic]\n",
              "3      0005c987bdfc9d4b  ...                                 [toxic]\n",
              "4      000e5ac5aa216bac  ...                [toxic, obscene, insult]\n",
              "...                 ...  ...                                     ...\n",
              "14615  fff631d42c6abb63  ...                [toxic, obscene, insult]\n",
              "14616  fffb8bea1d5e4d3b  ...                [toxic, obscene, insult]\n",
              "14617  fffd0ce82f58251e  ...                        [toxic, obscene]\n",
              "14618  fffdc608b84c9b27  ...                                 [toxic]\n",
              "14619  fffedeecd0364534  ...                                 [toxic]\n",
              "\n",
              "[14620 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxoKXXmPSqcH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e00bda59-f442-4614-8938-66f6f739c9cb"
      },
      "source": [
        "all_labs = []\n",
        "for r in res['labels'].values:\n",
        "    all_labs.extend(r)\n",
        "set(all_labs)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'identity_hate', 'insult', 'obscene', 'severe_toxic', 'threat', 'toxic'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIIF2e1Kl4fF"
      },
      "source": [
        "Train the pipeline model on the training dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlGbDPbjRQ_E"
      },
      "source": [
        "pipelineModel = pipeline.fit(trainDataset)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fm-0aY6Gmppl"
      },
      "source": [
        "Example training log:\n",
        "\n",
        "\n",
        "```\n",
        "Training started - epochs: 10 - learning_rate: 0.001 - batch_size: 64 - training_examples: 127657 - classes: 7\n",
        "Epoch 0/10 - 46.00s - loss: 0.079907365 - acc: 0.9723665 - val_loss: 0.07093345 - val_acc: 0.97352755 - val_f1: 0.91585624 - val_tpr: 0.9008827 - batches: 1995\n",
        "Epoch 1/10 - 28.26s - loss: 0.06964213 - acc: 0.9747156 - val_loss: 0.069492534 - val_acc: 0.9739863 - val_f1: 0.91734964 - val_tpr: 0.9029063 - batches: 1995\n",
        "Epoch 2/10 - 27.99s - loss: 0.06808146 - acc: 0.9752242 - val_loss: 0.06841504 - val_acc: 0.97444665 - val_f1: 0.9187962 - val_tpr: 0.9039833 - batches: 1995\n",
        "Epoch 3/10 - 27.94s - loss: 0.066884466 - acc: 0.9757066 - val_loss: 0.06769186 - val_acc: 0.9746787 - val_f1: 0.9195223 - val_tpr: 0.90438014 - batches: 1995\n",
        "Epoch 4/10 - 28.04s - loss: 0.06587076 - acc: 0.9761073 - val_loss: 0.067252316 - val_acc: 0.9749198 - val_f1: 0.92028916 - val_tpr: 0.9049118 - batches: 1995\n",
        "Epoch 5/10 - 28.05s - loss: 0.06501821 - acc: 0.97637606 - val_loss: 0.06700255 - val_acc: 0.9750182 - val_f1: 0.9205762 - val_tpr: 0.90496385 - batches: 1995\n",
        "Epoch 6/10 - 27.92s - loss: 0.064287946 - acc: 0.9765889 - val_loss: 0.06686394 - val_acc: 0.9750045 - val_f1: 0.9205367 - val_tpr: 0.904986 - batches: 1995\n",
        "Epoch 7/10 - 28.19s - loss: 0.063645855 - acc: 0.97682655 - val_loss: 0.0667824 - val_acc: 0.97498673 - val_f1: 0.92048156 - val_tpr: 0.90499973 - batches: 1995\n",
        "Epoch 8/10 - 28.53s - loss: 0.06306508 - acc: 0.97704613 - val_loss: 0.06673989 - val_acc: 0.974991 - val_f1: 0.9205486 - val_tpr: 0.9056079 - batches: 1995\n",
        "Epoch 9/10 - 28.61s - loss: 0.0625258 - acc: 0.97720623 - val_loss: 0.06672904 - val_acc: 0.9750411 - val_f1: 0.9207759 - val_tpr: 0.90621996 - batches: 1995\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pD1oGGgwmVUe"
      },
      "source": [
        "## 3. Testing and examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzia33pWl0Lc"
      },
      "source": [
        "Run the model on the test dataset to evaluate performance and generate examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUo4_e2s7-js"
      },
      "source": [
        "test_res = pipelineModel.transform(testDataset)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFCxC-YwlobE"
      },
      "source": [
        "Visualizing the raw test dataset after classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9cTSIObV0_C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26bcaf6c-0b19-4a06-d1b6-0a6b6d1def29"
      },
      "source": [
        "test_res.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|              id|                text|              labels|            document|               token| sentence_embeddings|               class|\n",
            "+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|0007e25b2121310b|Bye! \n",
            "\n",
            "Don't look...|             [toxic]|[{document, 0, 56...|[{token, 0, 2, By...|[{sentence_embedd...|[{category, 0, 56...|\n",
            "|001956c382006abd|I'm Sorry \n",
            "\n",
            "I'm s...|             [toxic]|[{document, 0, 31...|[{token, 0, 2, I'...|[{sentence_embedd...|[{category, 0, 31...|\n",
            "|00c1b6962307c80e|Well you are ridi...|             [toxic]|[{document, 0, 95...|[{token, 0, 3, We...|[{sentence_embedd...|[{category, 0, 95...|\n",
            "|0109d5a4788850f7|Thank you for you...|[toxic, obscene, ...|[{document, 0, 71...|[{token, 0, 4, Th...|[{sentence_embedd...|[{category, 0, 71...|\n",
            "|011e2c96cfa8a055|Fucked with the w...|    [toxic, obscene]|[{document, 0, 58...|[{token, 0, 5, Fu...|[{sentence_embedd...|[{category, 0, 58...|\n",
            "|0120c81c20837d0a|Fat Niggers? \n",
            "Sho...|[toxic, obscene, ...|[{document, 0, 78...|[{token, 0, 2, Fa...|[{sentence_embedd...|[{category, 0, 78...|\n",
            "|01465fd903558524|Lots of that othe...|    [toxic, obscene]|[{document, 0, 76...|[{token, 0, 3, Lo...|[{sentence_embedd...|[{category, 0, 76...|\n",
            "|018d92501fc50d09|Did you go to Aus...|             [toxic]|[{document, 0, 11...|[{token, 0, 2, Di...|[{sentence_embedd...|[{category, 0, 11...|\n",
            "|018e6f1e1b18723a|\"\n",
            "\n",
            " Another crap ...|             [toxic]|[{document, 0, 55...|[{token, 0, 0, \",...|[{sentence_embedd...|[{category, 0, 55...|\n",
            "|0199d6af27b715f3|I'm also a sock p...|     [toxic, threat]|[{document, 0, 13...|[{token, 0, 2, I'...|[{sentence_embedd...|[{category, 0, 13...|\n",
            "|01f304185a18cb7b|Don't peddle your...|             [toxic]|[{document, 0, 98...|[{token, 0, 4, Do...|[{sentence_embedd...|[{category, 0, 98...|\n",
            "|0251ad80bf585093|P.S. Are you a /b...|             [toxic]|[{document, 0, 22...|[{token, 0, 2, P....|[{sentence_embedd...|[{category, 0, 22...|\n",
            "|02526d2f0b73abe4|Have the balls to...|[toxic, obscene, ...|[{document, 0, 16...|[{token, 0, 3, Ha...|[{sentence_embedd...|[{category, 0, 16...|\n",
            "|026561cbdbc6ff5a|[Maria], you damn...|             [toxic]|[{document, 0, 15...|[{token, 0, 6, [M...|[{sentence_embedd...|[{category, 0, 15...|\n",
            "|029e65e9e69f6662|Fuuck you you bud...|[toxic, severe_to...|[{document, 0, 34...|[{token, 0, 4, Fu...|[{sentence_embedd...|[{category, 0, 34...|\n",
            "|02a1ac2c706d3306|FisherQueen, woul...|             [toxic]|[{document, 0, 16...|[{token, 0, 10, F...|[{sentence_embedd...|[{category, 0, 16...|\n",
            "|02fe38c6d10c97a5|Get off your high...|             [toxic]|[{document, 0, 36...|[{token, 0, 2, Ge...|[{sentence_embedd...|[{category, 0, 36...|\n",
            "|030ed098f411f8c7|Cavorting with He...|[toxic, severe_to...|[{document, 0, 41...|[{token, 0, 8, Ca...|[{sentence_embedd...|[{category, 0, 41...|\n",
            "|0349653f81b942ba|What a joker you ...|             [toxic]|[{document, 0, 46...|[{token, 0, 3, Wh...|[{sentence_embedd...|[{category, 0, 46...|\n",
            "|039281cfaf5a7462|\"\n",
            "\n",
            "Lol dumb arabs...|[toxic, obscene, ...|[{document, 0, 11...|[{token, 0, 0, \",...|[{sentence_embedd...|[{category, 0, 11...|\n",
            "+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlyXUWWulijW"
      },
      "source": [
        "Write some sample inputs and outputs from the test dataset to file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_rcLmhnWfYS"
      },
      "source": [
        "! mkdir -p inputs\n",
        "! mkdir -p outputs\n",
        "\n",
        "result = test_res.toPandas()\n",
        "for i in range(1, 11):\n",
        "    text = result[['document']].iloc[i][0][0].result\n",
        "    with open(f'inputs/{i}.txt', 'w') as f:\n",
        "        f.write(text[:96].replace('\\n', '') + \" ...\\n\" + text)\n",
        "    result[['class']].iloc[i].to_json(f'outputs/{i}.json')"
      ],
      "execution_count": 11,
      "outputs": []
    }
  ]
}