{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eaKUNmLKIAjr"
   },
   "source": [
    "\n",
    "\n",
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/ABSA_Inference.ipynb)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KkeqSGefIJW-"
   },
   "source": [
    "# **Aspect Based Sentiment Analysis in Spark NLP**\n",
    "\n",
    "#### Model Details: https://nlp.johnsnowlabs.com/2020/12/29/ner_aspect_based_sentiment_en.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhA_CmHaIRQz"
   },
   "source": [
    "### Spark NLP documentation and instructions:\n",
    "https://nlp.johnsnowlabs.com/docs/en/quickstart\n",
    "\n",
    "### You can find details about Spark NLP annotators here:\n",
    "https://nlp.johnsnowlabs.com/docs/en/annotators\n",
    "\n",
    "### You can find details about Spark NLP models here:\n",
    "https://nlp.johnsnowlabs.com/models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PbO7pJJqIV_T"
   },
   "source": [
    "## 1. Colab Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pgtx3Ji1JK2W"
   },
   "source": [
    "Install Dependencies and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LWoA7SChHu41"
   },
   "outputs": [],
   "source": [
    "# Install Java\n",
    "! apt-get update -qq\n",
    "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
    "! java -version\n",
    "\n",
    "# Install pyspark\n",
    "! pip install --ignore-installed -q pyspark==2.4.4\n",
    "\n",
    "# Install Spark NLP\n",
    "! pip install --ignore-installed spark-nlp\n",
    "# Install Spark NLP Display lib\n",
    "! pip install --ignore-installed spark-nlp-display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vt4GalFKIasv"
   },
   "source": [
    "Import and start the Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "id": "gdmZSvJNIeQP",
    "outputId": "3e8fb7ef-7808-46c2-ae0a-1e588d240096"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"\\nspark = SparkSession.builder     .appName('Spark NLP Licensed')     .master('local[*]')     .config('spark.driver.memory', '16G')     .config('spark.serializer', 'org.apache.spark.serializer.KryoSerializer')     .config('spark.kryoserializer.buffer.max', '2000M')     .config('spark.jars.packages', 'com.johnsnowlabs.nlp:spark-nlp_2.11:' +sparknlp.version()).getOrCreate()\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['JAVA_HOME'] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ['PATH'] = os.environ['JAVA_HOME'] + \"/bin:\" + os.environ['PATH']\n",
    "\n",
    "import pandas as pd\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "import sparknlp\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import *\n",
    "\n",
    "spark = sparknlp.start()\n",
    "\n",
    "# manually start session\n",
    "'''\n",
    "spark = SparkSession.builder \\\n",
    "    .appName('Spark NLP Licensed') \\\n",
    "    .master('local[*]') \\\n",
    "    .config('spark.driver.memory', '16G') \\\n",
    "    .config('spark.serializer', 'org.apache.spark.serializer.KryoSerializer') \\\n",
    "    .config('spark.kryoserializer.buffer.max', '2000M') \\\n",
    "    .config('spark.jars.packages', 'com.johnsnowlabs.nlp:spark-nlp_2.11:' +sparknlp.version()).getOrCreate()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EBW8SeRnIf1-"
   },
   "source": [
    "##2. Build Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5FzKvkdBHu44",
    "outputId": "632c970d-0065-444a-d512-127da2d87356"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove_6B_300 download started this may take some time.\n",
      "Approximate size to download 426.2 MB\n",
      "[OK!]\n",
      "ner_aspect_based_sentiment download started this may take some time.\n",
      "Approximate size to download 21.3 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol('text')\\\n",
    "    .setOutputCol('document')\n",
    "\n",
    "sentence_detector = SentenceDetector() \\\n",
    "    .setInputCols(['document'])\\\n",
    "    .setOutputCol('sentence')\n",
    "\n",
    "tokenizer = Tokenizer()\\\n",
    "    .setInputCols(['sentence']) \\\n",
    "    .setOutputCol('token')\n",
    "\n",
    "word_embeddings = WordEmbeddingsModel.pretrained(\"glove_6B_300\", \"xx\")\\\n",
    "    .setInputCols([\"document\", \"token\"])\\\n",
    "    .setOutputCol(\"embeddings\")\n",
    "    \n",
    "ner_model = NerDLModel.pretrained(\"ner_aspect_based_sentiment\")\\\n",
    "    .setInputCols([\"document\", \"token\", \"embeddings\"])\\\n",
    "    .setOutputCol(\"ner\")\n",
    "\n",
    "ner_converter = NerConverter()\\\n",
    "    .setInputCols(['sentence', 'token', 'ner']) \\\n",
    "    .setOutputCol('ner_chunk')\n",
    "\n",
    "nlp_pipeline = Pipeline(stages=[\n",
    "    document_assembler, \n",
    "    sentence_detector,\n",
    "    tokenizer,\n",
    "    word_embeddings,\n",
    "    ner_model,\n",
    "    ner_converter])\n",
    "\n",
    "empty_df = spark.createDataFrame([['']]).toDF('text')\n",
    "pipeline_model = nlp_pipeline.fit(empty_df)\n",
    "light_pipeline = LightPipeline(pipeline_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nzf1KWDzJhk2"
   },
   "source": [
    "## 3. Create example inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "TOGmXRQ0Jw6X"
   },
   "outputs": [],
   "source": [
    "# Enter examples as strings in this array\n",
    "input_list = [\n",
    "    \"\"\"From the beginning, we were met by friendly staff members, and the convienent parking at Chelsea Piers made it easy for us to get to the boat.\"\"\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-W10hpftJ0D5"
   },
   "source": [
    "## 4. Run the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9BMNDC8MSeS"
   },
   "source": [
    "Full Pipeline (Expects a spark Data Frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "bAdIbN4rJzXh"
   },
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(pd.DataFrame({\"text\": input_list}))\n",
    "result = pipeline_model.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mHYdK2aKMXaC"
   },
   "source": [
    "Light Pipeline (Expects a list of string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "OrEfJogLMaZP"
   },
   "outputs": [],
   "source": [
    "lresult = light_pipeline.fullAnnotate(input_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TnPhWxstJ53j"
   },
   "source": [
    "## 5. Visualize results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S1tfkrE1MmfN"
   },
   "source": [
    "Full Pipeline Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "xXjYtpVuURln",
    "outputId": "a9a46ae9-e4cd-4066-bd3f-a0a37d01d677"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    @import url('https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700&display=swap');\n",
       "    @import url('https://fonts.googleapis.com/css2?family=Vistol Regular:wght@300;400;500;600;700&display=swap');\n",
       "    \n",
       "    .spark-nlp-display-scroll-entities {\n",
       "        border: 1px solid #E7EDF0;\n",
       "        border-radius: 3px;\n",
       "        text-align: justify;\n",
       "        \n",
       "    }\n",
       "    .spark-nlp-display-scroll-entities span {  \n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        color: #536B76;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "    }\n",
       "    \n",
       "    .spark-nlp-display-entity-wrapper{\n",
       "    \n",
       "        display: inline-grid;\n",
       "        text-align: center;\n",
       "        border-radius: 4px;\n",
       "        margin: 0 2px 5px 2px;\n",
       "        padding: 1px\n",
       "    }\n",
       "    .spark-nlp-display-entity-name{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "        \n",
       "        background: #f1f2f3;\n",
       "        border-width: medium;\n",
       "        text-align: center;\n",
       "        \n",
       "        font-weight: 400;\n",
       "        \n",
       "        border-radius: 5px;\n",
       "        padding: 2px 5px;\n",
       "        display: block;\n",
       "        margin: 3px 2px;\n",
       "    \n",
       "    }\n",
       "    .spark-nlp-display-entity-type{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        color: #ffffff;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "        \n",
       "        text-transform: uppercase;\n",
       "        \n",
       "        font-weight: 500;\n",
       "\n",
       "        display: block;\n",
       "        padding: 3px 5px;\n",
       "    }\n",
       "    \n",
       "    .spark-nlp-display-entity-resolution{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        color: #ffffff;\n",
       "        font-family: 'Vistol Regular', sans-serif !important;\n",
       "        \n",
       "        text-transform: uppercase;\n",
       "        \n",
       "        font-weight: 500;\n",
       "\n",
       "        display: block;\n",
       "        padding: 3px 5px;\n",
       "    }\n",
       "    \n",
       "    .spark-nlp-display-others{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "        \n",
       "        font-weight: 400;\n",
       "    }\n",
       "\n",
       "</style>\n",
       " <span class=\"spark-nlp-display-others\" style=\"background-color: white\">From the beginning, we were met by friendly </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #B1E087\"><span class=\"spark-nlp-display-entity-name\">staff members </span><span class=\"spark-nlp-display-entity-type\">POS</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, and the convienent parking at Chelsea Piers made it easy for us to get to the boat.</span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using display lib\n",
    "from sparknlp_display import NerVisualizer\n",
    "\n",
    "NerVisualizer().display(result.collect()[0], 'ner_chunk', 'document')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Rv-Li9DJ6S7",
    "outputId": "c806d2e0-441d-49ef-a04f-07cb22746289"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+\n",
      "|chunk        |ner_label|\n",
      "+-------------+---------+\n",
      "|staff members|POS      |\n",
      "+-------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Process manually\n",
    "exploded = F.explode(F.arrays_zip('ner_chunk.result', 'ner_chunk.metadata'))\n",
    "select_expression_0 = F.expr(\"cols['0']\").alias(\"chunk\")\n",
    "select_expression_1 = F.expr(\"cols['1']['entity']\").alias(\"ner_label\")\n",
    "result.select(exploded.alias(\"cols\")) \\\n",
    "    .select(select_expression_0, select_expression_1).show(truncate=False)\n",
    "result = result.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zd1qdsbdMoUF"
   },
   "source": [
    "Light Pipeline Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "MAkhpH_TVMhK",
    "outputId": "efcd99a2-7706-4332-c9e7-80686931918b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    @import url('https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700&display=swap');\n",
       "    @import url('https://fonts.googleapis.com/css2?family=Vistol Regular:wght@300;400;500;600;700&display=swap');\n",
       "    \n",
       "    .spark-nlp-display-scroll-entities {\n",
       "        border: 1px solid #E7EDF0;\n",
       "        border-radius: 3px;\n",
       "        text-align: justify;\n",
       "        \n",
       "    }\n",
       "    .spark-nlp-display-scroll-entities span {  \n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        color: #536B76;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "    }\n",
       "    \n",
       "    .spark-nlp-display-entity-wrapper{\n",
       "    \n",
       "        display: inline-grid;\n",
       "        text-align: center;\n",
       "        border-radius: 4px;\n",
       "        margin: 0 2px 5px 2px;\n",
       "        padding: 1px\n",
       "    }\n",
       "    .spark-nlp-display-entity-name{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "        \n",
       "        background: #f1f2f3;\n",
       "        border-width: medium;\n",
       "        text-align: center;\n",
       "        \n",
       "        font-weight: 400;\n",
       "        \n",
       "        border-radius: 5px;\n",
       "        padding: 2px 5px;\n",
       "        display: block;\n",
       "        margin: 3px 2px;\n",
       "    \n",
       "    }\n",
       "    .spark-nlp-display-entity-type{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        color: #ffffff;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "        \n",
       "        text-transform: uppercase;\n",
       "        \n",
       "        font-weight: 500;\n",
       "\n",
       "        display: block;\n",
       "        padding: 3px 5px;\n",
       "    }\n",
       "    \n",
       "    .spark-nlp-display-entity-resolution{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        color: #ffffff;\n",
       "        font-family: 'Vistol Regular', sans-serif !important;\n",
       "        \n",
       "        text-transform: uppercase;\n",
       "        \n",
       "        font-weight: 500;\n",
       "\n",
       "        display: block;\n",
       "        padding: 3px 5px;\n",
       "    }\n",
       "    \n",
       "    .spark-nlp-display-others{\n",
       "        font-size: 14px;\n",
       "        line-height: 24px;\n",
       "        font-family: 'Montserrat', sans-serif !important;\n",
       "        \n",
       "        font-weight: 400;\n",
       "    }\n",
       "\n",
       "</style>\n",
       " <span class=\"spark-nlp-display-others\" style=\"background-color: white\">From the beginning, we were met by friendly </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #70F69B\"><span class=\"spark-nlp-display-entity-name\">staff members </span><span class=\"spark-nlp-display-entity-type\">POS</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, and the convienent parking at Chelsea Piers made it easy for us to get to the boat.</span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using display lib\n",
    "from sparknlp_display import NerVisualizer\n",
    "\n",
    "NerVisualizer().display(lresult[0], 'ner_chunk', 'document')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UJGdtmLSMrao",
    "outputId": "e0f068c0-835c-46ab-bcec-a776b7ab0068"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token/Phrase: staff members Sentiment:  POS\n"
     ]
    }
   ],
   "source": [
    "# Process manually\n",
    "for example in lresult:\n",
    "  for res in example['ner_chunk']:\n",
    "    print ('Token/Phrase:', res.result, 'Sentiment: ', res.metadata['entity'])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ABSA_Inference.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
