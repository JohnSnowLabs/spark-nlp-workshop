{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaKUNmLKIAjr"
      },
      "source": [
        "\n",
        "\n",
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/ABSA_Inference.ipynb)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkeqSGefIJW-"
      },
      "source": [
        "# **Aspect Based Sentiment Analysis in Spark NLP**\n",
        "\n",
        "#### Model Details: https://nlp.johnsnowlabs.com/2020/12/29/ner_aspect_based_sentiment_en.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhA_CmHaIRQz"
      },
      "source": [
        "### Spark NLP documentation and instructions:\n",
        "https://nlp.johnsnowlabs.com/docs/en/quickstart\n",
        "\n",
        "### You can find details about Spark NLP annotators here:\n",
        "https://nlp.johnsnowlabs.com/docs/en/annotators\n",
        "\n",
        "### You can find details about Spark NLP models here:\n",
        "https://nlp.johnsnowlabs.com/models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbO7pJJqIV_T"
      },
      "source": [
        "## 1. Colab Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pgtx3Ji1JK2W"
      },
      "source": [
        "Install Dependencies and Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWoA7SChHu41",
        "outputId": "19ce3688-f604-452f-cde0-46e580af7f75"
      },
      "outputs": [],
      "source": [
        "# Install PySpark and Spark NLP\n",
        "! pip install -q pyspark==3.1.2 spark-nlp\n",
        "\n",
        "# Install Spark NLP Display lib\n",
        "! pip install --upgrade -q spark-nlp-display"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vt4GalFKIasv"
      },
      "source": [
        "Import and start the Spark session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "gdmZSvJNIeQP",
        "outputId": "1a6e6bfa-b440-4cb9-8a40-34e48287eabb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\nspark = SparkSession.builder     .appName('Spark NLP Licensed')     .master('local[*]')     .config('spark.driver.memory', '16G')     .config('spark.serializer', 'org.apache.spark.serializer.KryoSerializer')     .config('spark.kryoserializer.buffer.max', '2000M')     .config('spark.jars.packages', 'com.johnsnowlabs.nlp:spark-nlp_2.11:' +sparknlp.version()).getOrCreate()\\n\""
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "import sparknlp\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "\n",
        "spark = sparknlp.start()\n",
        "\n",
        "# manually start session\n",
        "'''\n",
        "spark = SparkSession.builder \\\n",
        "    .appName('Spark NLP Licensed') \\\n",
        "    .master('local[*]') \\\n",
        "    .config('spark.driver.memory', '16G') \\\n",
        "    .config('spark.serializer', 'org.apache.spark.serializer.KryoSerializer') \\\n",
        "    .config('spark.kryoserializer.buffer.max', '2000M') \\\n",
        "    .config('spark.jars.packages', 'com.johnsnowlabs.nlp:spark-nlp_2.11:' +sparknlp.version()).getOrCreate()\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBW8SeRnIf1-"
      },
      "source": [
        "##2. Build Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FzKvkdBHu44",
        "outputId": "0b67f446-0a88-407b-fb17-04196883cc1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "glove_6B_300 download started this may take some time.\n",
            "Approximate size to download 426.2 MB\n",
            "[OK!]\n",
            "ner_aspect_based_sentiment download started this may take some time.\n",
            "Approximate size to download 21.3 MB\n",
            "[OK!]\n"
          ]
        }
      ],
      "source": [
        "document_assembler = DocumentAssembler() \\\n",
        "    .setInputCol('text')\\\n",
        "    .setOutputCol('document')\n",
        "\n",
        "sentence_detector = SentenceDetector() \\\n",
        "    .setInputCols(['document'])\\\n",
        "    .setOutputCol('sentence')\n",
        "\n",
        "tokenizer = Tokenizer()\\\n",
        "    .setInputCols(['sentence']) \\\n",
        "    .setOutputCol('token')\n",
        "\n",
        "word_embeddings = WordEmbeddingsModel.pretrained(\"glove_6B_300\", \"xx\")\\\n",
        "    .setInputCols([\"document\", \"token\"])\\\n",
        "    .setOutputCol(\"embeddings\")\n",
        "    \n",
        "ner_model = NerDLModel.pretrained(\"ner_aspect_based_sentiment\")\\\n",
        "    .setInputCols([\"document\", \"token\", \"embeddings\"])\\\n",
        "    .setOutputCol(\"ner\")\n",
        "\n",
        "ner_converter = NerConverter()\\\n",
        "    .setInputCols(['sentence', 'token', 'ner']) \\\n",
        "    .setOutputCol('ner_chunk')\n",
        "\n",
        "nlp_pipeline = Pipeline(stages=[\n",
        "    document_assembler, \n",
        "    sentence_detector,\n",
        "    tokenizer,\n",
        "    word_embeddings,\n",
        "    ner_model,\n",
        "    ner_converter])\n",
        "\n",
        "empty_df = spark.createDataFrame([['']]).toDF('text')\n",
        "pipeline_model = nlp_pipeline.fit(empty_df)\n",
        "light_pipeline = LightPipeline(pipeline_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzf1KWDzJhk2"
      },
      "source": [
        "## 3. Create example inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TOGmXRQ0Jw6X"
      },
      "outputs": [],
      "source": [
        "# Enter examples as strings in this array\n",
        "input_list = [\n",
        "    \"\"\"From the beginning, we were met by friendly staff members, and the convienent parking at Chelsea Piers made it easy for us to get to the boat.\"\"\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-W10hpftJ0D5"
      },
      "source": [
        "## 4. Run the pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9BMNDC8MSeS"
      },
      "source": [
        "Full Pipeline (Expects a spark Data Frame)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bAdIbN4rJzXh"
      },
      "outputs": [],
      "source": [
        "df = spark.createDataFrame(pd.DataFrame({\"text\": input_list}))\n",
        "result = pipeline_model.transform(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHYdK2aKMXaC"
      },
      "source": [
        "Light Pipeline (Expects a list of string)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OrEfJogLMaZP"
      },
      "outputs": [],
      "source": [
        "lresult = light_pipeline.fullAnnotate(input_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnPhWxstJ53j"
      },
      "source": [
        "## 5. Visualize results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1tfkrE1MmfN"
      },
      "source": [
        "Full Pipeline Result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "xXjYtpVuURln",
        "outputId": "65446fff-0986-48b2-e318-90037bd1997a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    @import url('https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700&display=swap');\n",
              "    @import url('https://fonts.googleapis.com/css2?family=Vistol Regular:wght@300;400;500;600;700&display=swap');\n",
              "    \n",
              "    .spark-nlp-display-scroll-entities {\n",
              "        border: 1px solid #E7EDF0;\n",
              "        border-radius: 3px;\n",
              "        text-align: justify;\n",
              "        \n",
              "    }\n",
              "    .spark-nlp-display-scroll-entities span {  \n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        color: #536B76;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "    }\n",
              "    \n",
              "    .spark-nlp-display-entity-wrapper{\n",
              "    \n",
              "        display: inline-grid;\n",
              "        text-align: center;\n",
              "        border-radius: 4px;\n",
              "        margin: 0 2px 5px 2px;\n",
              "        padding: 1px\n",
              "    }\n",
              "    .spark-nlp-display-entity-name{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "        \n",
              "        background: #f1f2f3;\n",
              "        border-width: medium;\n",
              "        text-align: center;\n",
              "        \n",
              "        font-weight: 400;\n",
              "        \n",
              "        border-radius: 5px;\n",
              "        padding: 2px 5px;\n",
              "        display: block;\n",
              "        margin: 3px 2px;\n",
              "    \n",
              "    }\n",
              "    .spark-nlp-display-entity-type{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        color: #ffffff;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "        \n",
              "        text-transform: uppercase;\n",
              "        \n",
              "        font-weight: 500;\n",
              "\n",
              "        display: block;\n",
              "        padding: 3px 5px;\n",
              "    }\n",
              "    \n",
              "    .spark-nlp-display-entity-resolution{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        color: #ffffff;\n",
              "        font-family: 'Vistol Regular', sans-serif !important;\n",
              "        \n",
              "        text-transform: uppercase;\n",
              "        \n",
              "        font-weight: 500;\n",
              "\n",
              "        display: block;\n",
              "        padding: 3px 5px;\n",
              "    }\n",
              "    \n",
              "    .spark-nlp-display-others{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "        \n",
              "        font-weight: 400;\n",
              "    }\n",
              "\n",
              "</style>\n",
              " <span class=\"spark-nlp-display-others\" style=\"background-color: white\">From the beginning, we were met by friendly </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #673133\"><span class=\"spark-nlp-display-entity-name\">staff members </span><span class=\"spark-nlp-display-entity-type\">POS</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, and the convienent parking at Chelsea Piers made it easy for us to get to the boat.</span></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Using display lib\n",
        "from sparknlp_display import NerVisualizer\n",
        "\n",
        "NerVisualizer().display(result.collect()[0], 'ner_chunk', 'document')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Rv-Li9DJ6S7",
        "outputId": "95271c85-c9d9-44de-8772-906e8f5ec353"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+---------+\n",
            "|chunk        |ner_label|\n",
            "+-------------+---------+\n",
            "|staff members|POS      |\n",
            "+-------------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Process manually\n",
        "exploded = F.explode(F.arrays_zip('ner_chunk.result', 'ner_chunk.metadata'))\n",
        "select_expression_0 = F.expr(\"cols['0']\").alias(\"chunk\")\n",
        "select_expression_1 = F.expr(\"cols['1']['entity']\").alias(\"ner_label\")\n",
        "result.select(exploded.alias(\"cols\")) \\\n",
        "    .select(select_expression_0, select_expression_1).show(truncate=False)\n",
        "result = result.toPandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zd1qdsbdMoUF"
      },
      "source": [
        "Light Pipeline Result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "MAkhpH_TVMhK",
        "outputId": "97288ee9-85a0-4575-ff0f-ba62473f6ded"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    @import url('https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700&display=swap');\n",
              "    @import url('https://fonts.googleapis.com/css2?family=Vistol Regular:wght@300;400;500;600;700&display=swap');\n",
              "    \n",
              "    .spark-nlp-display-scroll-entities {\n",
              "        border: 1px solid #E7EDF0;\n",
              "        border-radius: 3px;\n",
              "        text-align: justify;\n",
              "        \n",
              "    }\n",
              "    .spark-nlp-display-scroll-entities span {  \n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        color: #536B76;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "    }\n",
              "    \n",
              "    .spark-nlp-display-entity-wrapper{\n",
              "    \n",
              "        display: inline-grid;\n",
              "        text-align: center;\n",
              "        border-radius: 4px;\n",
              "        margin: 0 2px 5px 2px;\n",
              "        padding: 1px\n",
              "    }\n",
              "    .spark-nlp-display-entity-name{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "        \n",
              "        background: #f1f2f3;\n",
              "        border-width: medium;\n",
              "        text-align: center;\n",
              "        \n",
              "        font-weight: 400;\n",
              "        \n",
              "        border-radius: 5px;\n",
              "        padding: 2px 5px;\n",
              "        display: block;\n",
              "        margin: 3px 2px;\n",
              "    \n",
              "    }\n",
              "    .spark-nlp-display-entity-type{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        color: #ffffff;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "        \n",
              "        text-transform: uppercase;\n",
              "        \n",
              "        font-weight: 500;\n",
              "\n",
              "        display: block;\n",
              "        padding: 3px 5px;\n",
              "    }\n",
              "    \n",
              "    .spark-nlp-display-entity-resolution{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        color: #ffffff;\n",
              "        font-family: 'Vistol Regular', sans-serif !important;\n",
              "        \n",
              "        text-transform: uppercase;\n",
              "        \n",
              "        font-weight: 500;\n",
              "\n",
              "        display: block;\n",
              "        padding: 3px 5px;\n",
              "    }\n",
              "    \n",
              "    .spark-nlp-display-others{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "        \n",
              "        font-weight: 400;\n",
              "    }\n",
              "\n",
              "</style>\n",
              " <span class=\"spark-nlp-display-others\" style=\"background-color: white\">From the beginning, we were met by friendly </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #3C5226\"><span class=\"spark-nlp-display-entity-name\">staff members </span><span class=\"spark-nlp-display-entity-type\">POS</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, and the convienent parking at Chelsea Piers made it easy for us to get to the boat.</span></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Using display lib\n",
        "from sparknlp_display import NerVisualizer\n",
        "\n",
        "NerVisualizer().display(lresult[0], 'ner_chunk', 'document')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJGdtmLSMrao",
        "outputId": "2e0f580b-bf2f-4b14-bb19-6a6a4dc01a93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token/Phrase: staff members Sentiment:  POS\n"
          ]
        }
      ],
      "source": [
        "# Process manually\n",
        "for example in lresult:\n",
        "  for res in example['ner_chunk']:\n",
        "    print ('Token/Phrase:', res.result, 'Sentiment: ', res.metadata['entity'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ABSA_Inference.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
