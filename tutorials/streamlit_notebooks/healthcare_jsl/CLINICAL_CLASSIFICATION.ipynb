{"cells":[{"cell_type":"markdown","metadata":{"id":"TA21Jo5d9SVq"},"source":["\n","\n","![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n","\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/healthcare_jsl/CLINICAL_CLASSIFICATION.ipynb)\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"CzIdjHkAW8TB"},"source":["# **How to use Licensed Classification models in Spark NLP**"]},{"cell_type":"markdown","metadata":{"id":"RuZr5fPZ4Jwa"},"source":["### Spark NLP documentation and instructions:\n","https://nlp.johnsnowlabs.com/docs/en/quickstart\n","\n","### You can find details about Spark NLP annotators here:\n","https://nlp.johnsnowlabs.com/docs/en/annotators\n","\n","### You can find details about Spark NLP models here:\n","https://nlp.johnsnowlabs.com/models\n"]},{"cell_type":"markdown","metadata":{"id":"6uDmeHEFW7_h"},"source":["To run this yourself, you will need to upload your license keys to the notebook. Just Run The Cell Below in order to do that. Also You can open the file explorer on the left side of the screen and upload `license_keys.json` to the folder that opens.\n","Otherwise, you can look at the example outputs at the bottom of the notebook.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"wIeCOiJNW-88"},"source":["## 1. Colab Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dnJ9X-mbEOMr"},"outputs":[],"source":["# Install the johnsnowlabs library to access Spark-OCR and Spark-NLP for Healthcare, Finance, and Legal.\n","! pip install -q johnsnowlabs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qeg3QosiFf5u"},"outputs":[],"source":["from google.colab import files\n","print(\"Please Upload your John Snow Labs License using the button below\")\n","license_keys = files.upload()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JK4D8yjTPlgJ"},"outputs":[],"source":["from johnsnowlabs import *\n","\n","# After uploading your license run this to install all licensed Python Wheels and pre-download Jars the Spark Session JVM\n","# Make sure to restart your notebook afterwards for changes to take effect\n","\n","jsl.install()"]},{"cell_type":"markdown","metadata":{"id":"WcrI5WVvGDvP"},"source":["## 2. Start Session"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uh5IkMSuFwH0"},"outputs":[],"source":["from johnsnowlabs import *\n","# Automatically load license data and start a session with all jars user has access to\n","spark = jsl.start()"]},{"cell_type":"markdown","metadata":{"id":"9RgiqfX5XDqb"},"source":["## 2. Usage Guidelines"]},{"cell_type":"markdown","metadata":{"id":"AVKr8C2SrkZQ"},"source":["1. **Selecting the correct Classification Model**\n","\n","> a. To select from all the Classification models available in Spark NLP please go to https://nlp.johnsnowlabs.com/models\n","\n","> b. Read through the model descriptions to select desired model\n","\n","> c. Some of the available models:\n",">> classifierdl_pico_biobert\n","\n",">> classifierdl_ade_biobert\n","---\n","2. **Selecting correct embeddings for the chosen model**\n","\n","> a. Models are trained on specific embeddings and same embeddings should be used at inference to get best results\n","\n","> b. If the name of the model contains \"**biobert**\" (e.g: *ner_anatomy_biobert*) then the model is trained using \"**biobert_pubmed_base_cased**\" embeddings. Otherwise, \"**embeddings_clinical**\" was used to train that model.\n","\n","> c. Using correct embeddings\n","\n",">> To use *embeddings_clinical* :\n","\n",">>> word_embeddings = WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\n","    .setInputCols([\"sentence\", \"token\"]) \\\n","    .setOutputCol(\"embeddings\")\n","\n",">> To use *Bert* Embeddings:\n","\n",">>> embeddings = BertEmbeddings.pretrained('biobert_pubmed_base_cased')\\\n","    .setInputCols([\"document\", 'token'])\\\n","    .setOutputCol(\"word_embeddings\")\n","> d. You can find list of all embeddings at https://nlp.johnsnowlabs.com/models?tag=embeddings\n"]},{"cell_type":"markdown","metadata":{"id":"zweiG2ilZqoR"},"source":["Create the pipeline"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15965,"status":"ok","timestamp":1665308182046,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"},"user_tz":-120},"id":"LLuDz_t40be4","outputId":"71bea1b3-914f-46d9-8d64-3ddb676e6f9e"},"outputs":[{"name":"stdout","output_type":"stream","text":["biobert_pubmed_base_cased download started this may take some time.\n","Approximate size to download 386.4 MB\n","[OK!]\n","classifierdl_pico_biobert download started this may take some time.\n","Approximate size to download 22 MB\n","[OK!]\n"]}],"source":["document_assembler = nlp.DocumentAssembler()\\\n","  .setInputCol(\"text\")\\\n","  .setOutputCol(\"document\")\n","\n","tokenizer = nlp.Tokenizer() \\\n","  .setInputCols([\"document\"]) \\\n","  .setOutputCol(\"token\")\n","\n","embeddings = nlp.BertEmbeddings.pretrained('biobert_pubmed_base_cased')\\\n","    .setInputCols([\"document\", 'token'])\\\n","    .setOutputCol(\"word_embeddings\")\n","\n","sentence_embeddings = nlp.SentenceEmbeddings() \\\n","      .setInputCols([\"document\", \"word_embeddings\"]) \\\n","      .setOutputCol(\"sentence_embeddings\") \\\n","      .setPoolingStrategy(\"AVERAGE\")\n","      # .setStorageRef('SentenceEmbeddings_5d018a59d7c3')\n","\n","classifier = nlp.ClassifierDLModel.pretrained('classifierdl_pico_biobert', 'en', 'clinical/models')\\\n","    .setInputCols(['document', 'token', 'sentence_embeddings']).setOutputCol('class')\n","\n","nlp_pipeline = Pipeline(\n","    stages=[\n","        document_assembler, \n","        tokenizer,\n","        embeddings,\n","        sentence_embeddings, \n","        classifier\n","        ])"]},{"cell_type":"markdown","metadata":{"id":"2Y9GpdJhXIpD"},"source":["## 3. Create example inputs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vBOKkB2THdGI"},"outputs":[],"source":["# Enter examples as strings in this array\n","input_list = [\n","    \"\"\"A total of 10 adult daily smokers who reported at least one stressful event and coping episode and provided post-quit data.\"\"\",\n","]"]},{"cell_type":"markdown","metadata":{"id":"mv0abcwhXWC-"},"source":["## 4. Use the pipeline to create outputs"]},{"cell_type":"markdown","metadata":{"id":"27rHwCk4ODFr"},"source":["Full Pipeline (Expects a Spark Data Frame)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TK1DB9JZaPs3"},"outputs":[],"source":["import pandas as pd\n","\n","empty_df = spark.createDataFrame([['']]).toDF('text')\n","pipeline_model = nlp_pipeline.fit(empty_df)\n","df = spark.createDataFrame(pd.DataFrame({'text': input_list}))\n","result = pipeline_model.transform(df)\n","lmodel = LightPipeline(pipeline_model)"]},{"cell_type":"markdown","metadata":{"id":"FFq4QRXjOEeG"},"source":["Light Pipeline (Expects a list of string)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NzFUrSmkOFfs"},"outputs":[],"source":["lresult = lmodel.annotate(input_list)"]},{"cell_type":"markdown","metadata":{"id":"UQY8tAP6XZJL"},"source":["## 5. Visualize results"]},{"cell_type":"markdown","metadata":{"id":"0vhxZgvibTi3"},"source":["Full Pipeline Results"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7467,"status":"ok","timestamp":1665308287992,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"},"user_tz":-120},"id":"3CFdzZ1IK86u","outputId":"2e778683-468d-4f14-e411-fe2a3a956e96"},"outputs":[{"name":"stdout","output_type":"stream","text":["+------------+---------------------------------------------------------------------------------------------------------------------------+\n","|class       |document                                                                                                                   |\n","+------------+---------------------------------------------------------------------------------------------------------------------------+\n","|PARTICIPANTS|A total of 10 adult daily smokers who reported at least one stressful event and coping episode and provided post-quit data.|\n","+------------+---------------------------------------------------------------------------------------------------------------------------+\n","\n"]}],"source":["result.select(F.explode(F.arrays_zip('class.result', \n","                                     'document.result')).alias(\"cols\")) \\\n","      .select(F.expr(\"cols['0']\").alias(\"class\"),\n","              F.expr(\"cols['1']\").alias(\"document\")).show(truncate=False)"]},{"cell_type":"markdown","metadata":{"id":"hnsMLq9gctSq"},"source":["Light Pipeline Results"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":202,"status":"ok","timestamp":1665308353743,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"},"user_tz":-120},"id":"r_5EjZkpHKhZ","outputId":"19e6c942-e094-485d-c355-c314286c3b94"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'PARTICIPANTS'"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["lresult[0]['class'][0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aDE-1YI-HIcV"},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"interpreter":{"hash":"45150093197569bb3a58481dcd32cd1adb45462fa3448719e8ac38ada6166aca"},"kernelspec":{"display_name":"Python 3.6.10 64-bit ('tensorflow2_p36': conda)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.10"}},"nbformat":4,"nbformat_minor":0}
