{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GRAMMAR_EN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6o8-g0tEqNz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sudo apt-get install openjdk-8-jdk\n",
        "!java -version\n",
        "!pip install --ignore-installed -q pyspark==2.4.4\n",
        "!pip install spark-nlp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMmT9S6mE0ad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "import sparknlp\n",
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "#import svgwrite"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zBXbY_vE2ss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spark = sparknlp.start()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XxHWemdE5hX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "MODEL_NAME='dependency_typed_conllu'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJ7GCD0pFDvP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Generating Example Files ##\n",
        "text_list = [\n",
        "             \"\"\"John Snow is a good man. He knows a lot about science.\"\"\",\n",
        "             \"\"\"In what country is the WTO headquartered?\"\"\",\n",
        "             \"\"\"I was wearing my dark blue shirt and tie.\"\"\",\n",
        "             \"\"\"The Geneva Motor Show is the most popular car show of the year.\"\"\",\n",
        "             \"\"\"Bill Gates and Steve Jobs had periods of civility.\"\"\",\n",
        "]\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiYxv0mOFIcX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "documentAssembler = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "tokenizer = Tokenizer() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "pos = PerceptronModel.pretrained(\"pos_anc\", 'en')\\\n",
        "        .setInputCols(\"document\", \"token\")\\\n",
        "        .setOutputCol(\"pos\")\n",
        "\n",
        "dep_parser = DependencyParserModel.pretrained('dependency_conllu')\\\n",
        "        .setInputCols([\"document\", \"pos\", \"token\"])\\\n",
        "        .setOutputCol(\"dependency\")\n",
        "\n",
        "\n",
        "typed_dep_parser = TypedDependencyParserModel.pretrained('dependency_typed_conllu')\\\n",
        "        .setInputCols([\"token\", \"pos\", \"dependency\"])\\\n",
        "        .setOutputCol(\"dependency_type\")\n",
        "\n",
        "\n",
        "nlpPipeline = Pipeline(\n",
        "      stages = [\n",
        "          documentAssembler,\n",
        "          tokenizer,\n",
        "          pos,\n",
        "          chunker,\n",
        "          dep_parser,\n",
        "          typed_dep_parser\n",
        "      ])\n",
        "\n",
        "empty_df = spark.createDataFrame([['']]).toDF(\"text\")\n",
        "\n",
        "pipelineModel = nlpPipeline.fit(empty_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7O34pc7d27-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index=0\n",
        "df = spark.createDataFrame(pd.DataFrame({\"text\":[text_list[index]]}))\n",
        "result = pipelineModel.transform(df)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzJSQhTnFix5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "result.select(F.explode(F.arrays_zip('token.result',\n",
        "                                     'token.begin',\n",
        "                                     'token.end', \n",
        "                                     'pos.result', \n",
        "                                     'dependency.result', \n",
        "                                                  'dependency.metadata',\n",
        "                                                  'dependency_type.result')).alias(\"cols\"))\\\n",
        "                                                  .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
        "                                                          F.expr(\"cols['1']\").alias(\"begin\"),\n",
        "                                                          F.expr(\"cols['2']\").alias(\"end\"),\n",
        "                                                          F.expr(\"cols['3']\").alias(\"pos\"),\n",
        "                                                          F.expr(\"cols['4']\").alias(\"dependency\"),\n",
        "                                                          F.expr(\"cols['5']\").alias(\"dependency_start\"),\n",
        "                                                          F.expr(\"cols['6']\").alias(\"dependency_type\")).toPandas()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}