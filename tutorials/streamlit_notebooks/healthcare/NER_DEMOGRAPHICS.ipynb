{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NER_DEMOGRAPHICS.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"TA21Jo5d9SVq","colab_type":"text"},"source":["\n","\n","![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n","\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/healthcare/NER_DEMOGRAPHICS.ipynb)\n"]},{"cell_type":"markdown","metadata":{"id":"CzIdjHkAW8TB","colab_type":"text"},"source":["# **Detect demographic information**"]},{"cell_type":"markdown","metadata":{"id":"6uDmeHEFW7_h","colab_type":"text"},"source":["To run this yourself, you will need to upload your license keys to the notebook. Otherwise, you can look at the example outputs at the bottom of the notebook. To upload license keys, open the file explorer on the left side of the screen and upload `workshop_license_keys.json` to the folder that opens."]},{"cell_type":"markdown","metadata":{"id":"wIeCOiJNW-88","colab_type":"text"},"source":["## 1. Colab Setup"]},{"cell_type":"markdown","metadata":{"id":"HMIDv74CYN0d","colab_type":"text"},"source":["Import license keys"]},{"cell_type":"code","metadata":{"id":"ttHPIV2JXbIM","colab_type":"code","colab":{}},"source":["import os\n","import json\n","\n","with open('/content/workshop_license_keys.json', 'r') as f:\n","    license_keys = json.load(f)\n","\n","license_keys.keys()\n","\n","secret = license_keys['JSL_SECRET']\n","os.environ['SPARK_NLP_LICENSE'] = license_keys['SPARK_NLP_LICENSE']\n","os.environ['JSL_OCR_LICENSE'] = license_keys['JSL_OCR_LICENSE']\n","os.environ['AWS_ACCESS_KEY_ID'] = license_keys['AWS_ACCESS_KEY_ID']\n","os.environ['AWS_SECRET_ACCESS_KEY'] = license_keys['AWS_SECRET_ACCESS_KEY']\n","\n","jsl_version = secret.split('-')[0]\n","jsl_version"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rQtc1CHaYQjU","colab_type":"text"},"source":["Install dependencies"]},{"cell_type":"code","metadata":{"id":"CGJktFHdHL1n","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":326},"outputId":"1882c7b5-4484-43c8-c1e2-84578876d53f"},"source":["# Install Java\n","! apt-get update -qq\n","! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n","! java -version\n","\n","# Install pyspark\n","! pip install --ignore-installed -q pyspark==2.4.4\n","\n","# Install Spark NLP\n","! pip install --ignore-installed spark-nlp\n","! python -m pip install --upgrade spark-nlp-jsl==$jsl_version --extra-index-url https://pypi.johnsnowlabs.com/$secret"],"execution_count":null,"outputs":[{"output_type":"stream","text":["openjdk version \"11.0.8\" 2020-07-14\n","OpenJDK Runtime Environment (build 11.0.8+10-post-Ubuntu-0ubuntu118.04.1)\n","OpenJDK 64-Bit Server VM (build 11.0.8+10-post-Ubuntu-0ubuntu118.04.1, mixed mode, sharing)\n","\u001b[K     |████████████████████████████████| 215.7MB 58kB/s \n","\u001b[K     |████████████████████████████████| 204kB 34.1MB/s \n","\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting spark-nlp\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b5/a2/5c2e18a65784442ded6f6c58af175ca4d99649337de569fac55b04d7ed8e/spark_nlp-2.5.5-py2.py3-none-any.whl (124kB)\n","\u001b[K     |████████████████████████████████| 133kB 2.8MB/s \n","\u001b[?25hInstalling collected packages: spark-nlp\n","Successfully installed spark-nlp-2.5.5\n","Looking in indexes: https://pypi.org/simple, https://pypi.johnsnowlabs.com/2.5.5-4f4b7f600f8ba3cdc5973a6baa47b901b0c8d8a3\n","Collecting spark-nlp-jsl==2.5.5\n","  Downloading https://pypi.johnsnowlabs.com/2.5.5-4f4b7f600f8ba3cdc5973a6baa47b901b0c8d8a3/spark-nlp-jsl/spark_nlp_jsl-2.5.5-py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: spark-nlp==2.5.5 in /usr/local/lib/python3.6/dist-packages (from spark-nlp-jsl==2.5.5) (2.5.5)\n","Installing collected packages: spark-nlp-jsl\n","Successfully installed spark-nlp-jsl-2.5.5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Hj5FRDV4YSXN","colab_type":"text"},"source":["Import dependencies into Python and start the Spark session"]},{"cell_type":"code","metadata":{"id":"sw-t1zxlHTB7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":392},"outputId":"272eddd7-e21f-4504-af31-8fe8b8c8ca0a"},"source":["os.environ['JAVA_HOME'] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ['PATH'] = os.environ['JAVA_HOME'] + \"/bin:\" + os.environ['PATH']\n","\n","import pandas as pd\n","from pyspark.ml import Pipeline\n","from pyspark.sql import SparkSession\n","import pyspark.sql.functions as F\n","\n","import sparknlp\n","from sparknlp.annotator import *\n","from sparknlp_jsl.annotator import *\n","from sparknlp.base import *\n","import sparknlp_jsl\n","\n","builder = SparkSession.builder \\\n","    .appName('Spark NLP Licensed') \\\n","    .master('local[*]') \\\n","    .config('spark.driver.memory', '16G') \\\n","    .config('spark.serializer', 'org.apache.spark.serializer.KryoSerializer') \\\n","    .config('spark.kryoserializer.buffer.max', '2000M') \\\n","    .config('spark.jars.packages', 'com.johnsnowlabs.nlp:spark-nlp_2.11:' +sparknlp.version()) \\\n","    .config('spark.jars', f'https://pypi.johnsnowlabs.com/{secret}/spark-nlp-jsl-{jsl_version}.jar')\n","    \n","spark = builder.getOrCreate()"],"execution_count":null,"outputs":[{"output_type":"error","ename":"Exception","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-974a8a8055fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mbuilder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mappName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Spark NLP Licensed'\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mmaster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'local[*]'\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'spark.driver.memory'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'16G'\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'spark.serializer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'org.apache.spark.serializer.KryoSerializer'\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'spark.kryoserializer.buffer.max'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2000M'\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'spark.jars.packages'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'com.johnsnowlabs.nlp:spark-nlp_2.11:2.5.2'\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'spark.jars'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'https://pypi.johnsnowlabs.com/{secret}/spark-nlp-jsl-2.5.2.jar'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mspark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    171\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                         \u001b[0msparkConf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                     \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparkConf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m                     \u001b[0;31m# This SparkContext may be an existing one.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[0;34m(cls, conf)\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    131\u001b[0m                     \" note this option will be removed in Spark 3.0\")\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgateway\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlaunch_gateway\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjvm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/java_gateway.py\u001b[0m in \u001b[0;36mlaunch_gateway\u001b[0;34m(conf)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mJVM\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \"\"\"\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_launch_gateway\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyspark/java_gateway.py\u001b[0m in \u001b[0;36m_launch_gateway\u001b[0;34m(conf, insecure)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Java gateway process exited before sending its port number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mException\u001b[0m: Java gateway process exited before sending its port number"]}]},{"cell_type":"markdown","metadata":{"id":"9RgiqfX5XDqb","colab_type":"text"},"source":["## 2. Select the NER model and construct the pipeline"]},{"cell_type":"markdown","metadata":{"id":"MbWioxCasOXH","colab_type":"text"},"source":["Select the NER model - Demographics models: **ner_deid_enriched, ner_deid_large, ner_jsl**\n","\n","For more details: https://github.com/JohnSnowLabs/spark-nlp-models#pretrained-models---spark-nlp-for-healthcare"]},{"cell_type":"code","metadata":{"id":"jeSfy_oGsTL6","colab_type":"code","colab":{}},"source":["# You can change this to the model you want to use and re-run cells below.\n","# Demographics models: ner_deid_enriched, ner_deid_large, ner_jsl\n","MODEL_NAME = \"ner_deid_enriched\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zweiG2ilZqoR","colab_type":"text"},"source":["Create the pipeline"]},{"cell_type":"code","metadata":{"id":"LLuDz_t40be4","colab_type":"code","colab":{}},"source":["document_assembler = DocumentAssembler() \\\n","    .setInputCol('text')\\\n","    .setOutputCol('document')\n","\n","sentence_detector = SentenceDetector() \\\n","    .setInputCols(['document'])\\\n","    .setOutputCol('sentence')\n","\n","tokenizer = Tokenizer()\\\n","    .setInputCols(['sentence']) \\\n","    .setOutputCol('token')\n","\n","word_embeddings = WordEmbeddingsModel.pretrained('embeddings_clinical', 'en', 'clinical/models') \\\n","    .setInputCols(['sentence', 'token']) \\\n","    .setOutputCol('embeddings')\n","\n","clinical_ner = NerDLModel.pretrained(MODEL_NAME, 'en', 'clinical/models') \\\n","    .setInputCols(['sentence', 'token', 'embeddings']) \\\n","    .setOutputCol('ner')\n","\n","ner_converter = NerConverter()\\\n","    .setInputCols(['sentence', 'token', 'ner']) \\\n","    .setOutputCol('ner_chunk')\n","\n","nlp_pipeline = Pipeline(stages=[\n","    document_assembler, \n","    sentence_detector,\n","    tokenizer,\n","    word_embeddings,\n","    clinical_ner,\n","    ner_converter])\n","\n","empty_df = spark.createDataFrame([['']]).toDF(\"text\")\n","pipeline_model = nlp_pipeline.fit(empty_df)\n","light_pipeline = LightPipeline(pipeline_model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2Y9GpdJhXIpD","colab_type":"text"},"source":["## 3. Create example inputs"]},{"cell_type":"code","metadata":{"id":"vBOKkB2THdGI","colab_type":"code","colab":{}},"source":["# Enter examples as strings in this array\n","input_list = [\n","    \"\"\"HISTORY OF PRESENT ILLNESS: Mr. Smith is a 60-year-old white male veteran with multiple comorbidities, who has a history of bladder cancer diagnosed approximately two years ago by the VA Hospital. He underwent a resection there. He was to be admitted to the Day Hospital for cystectomy. He was seen in Urology Clinic and Radiology Clinic on 02/04/2003.\n","\n","HOSPITAL COURSE: Mr. Smith presented to the Day Hospital in anticipation for Urology surgery. On evaluation, EKG, echocardiogram was abnormal, a Cardiology consult was obtained. A cardiac adenosine stress MRI was then proceeded, same was positive for inducible ischemia, mild-to-moderate inferolateral subendocardial infarction with peri-infarct ischemia. In addition, inducible ischemia seen in the inferior lateral septum. Mr. Smith underwent a left heart catheterization, which revealed two vessel coronary artery disease. The RCA, proximal was 95% stenosed and the distal 80% stenosed. The mid LAD was 85% stenosed and the distal LAD was 85% stenosed. There was four Multi-Link Vision bare metal stents placed to decrease all four lesions to 0%. Following intervention, Mr. Smith was admitted to 7 Ardmore Tower under Cardiology Service under the direction of Dr. Hart. Mr. Smith had a noncomplicated post-intervention hospital course. He was stable for discharge home on 02/07/2003 with instructions to take Plavix daily for one month and Urology is aware of the same.\"\"\"\n","]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mv0abcwhXWC-","colab_type":"text"},"source":["## 4. Use the pipeline to create outputs"]},{"cell_type":"code","metadata":{"id":"TK1DB9JZaPs3","colab_type":"code","colab":{}},"source":["df = spark.createDataFrame(pd.DataFrame({\"text\": input_list}))\n","result = pipeline_model.transform(df)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UQY8tAP6XZJL","colab_type":"text"},"source":["## 5. Visualize results"]},{"cell_type":"markdown","metadata":{"id":"hnsMLq9gctSq","colab_type":"text"},"source":["Visualize outputs as data frame"]},{"cell_type":"code","metadata":{"id":"Ar32BZu7J79X","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":330},"outputId":"6870a43f-a772-4825-e6b5-f30270bbcae6"},"source":["exploded = F.explode(F.arrays_zip('ner_chunk.result', 'ner_chunk.metadata'))\n","select_expression_0 = F.expr(\"cols['0']\").alias(\"chunk\")\n","select_expression_1 = F.expr(\"cols['1']['entity']\").alias(\"ner_label\")\n","result.select(exploded.alias(\"cols\")) \\\n","    .select(select_expression_0, select_expression_1).show(truncate=False)\n","result = result.toPandas()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["+---------------+---------+\n","|chunk          |ner_label|\n","+---------------+---------+\n","|Smith          |PATIENT  |\n","|Smith          |PATIENT  |\n","|VA Hospital    |HOSPITAL |\n","|Day Hospital   |HOSPITAL |\n","|02/04/2003     |DATE     |\n","|Smith          |PATIENT  |\n","|Day Hospital   |HOSPITAL |\n","|Smith          |PATIENT  |\n","|Smith          |PATIENT  |\n","|7 Ardmore Tower|STREET   |\n","|Hart           |DOCTOR   |\n","|Smith          |PATIENT  |\n","|02/07/2003     |DATE     |\n","+---------------+---------+\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1wdVmoUcdnAk","colab_type":"text"},"source":["Functions to display outputs as HTML"]},{"cell_type":"code","metadata":{"id":"tFeu7loodcQQ","colab_type":"code","colab":{}},"source":["from IPython.display import HTML, display\n","import random\n","\n","def get_color():\n","    r = lambda: random.randint(128,255)\n","    return \"#%02x%02x%02x\" % (r(), r(), r())\n","\n","def annotation_to_html(full_annotation):\n","    ner_chunks = full_annotation[0]['ner_chunk']\n","    text = full_annotation[0]['document'][0].result\n","    label_color = {}\n","    for chunk in ner_chunks:\n","        label_color[chunk.metadata['entity']] = get_color()\n","\n","    html_output = \"<div>\"\n","    pos = 0\n","\n","    for n in ner_chunks:\n","        if pos < n.begin and pos < len(text):\n","            html_output += f\"<span class=\\\"others\\\">{text[pos:n.begin]}</span>\"\n","        pos = n.end + 1\n","        html_output += f\"<span class=\\\"entity-wrapper\\\" style=\\\"color: black; background-color: {label_color[n.metadata['entity']]}\\\"> <span class=\\\"entity-name\\\">{n.result}</span> <span class=\\\"entity-type\\\">[{n.metadata['entity']}]</span></span>\"\n","\n","    if pos < len(text):\n","        html_output += f\"<span class=\\\"others\\\">{text[pos:]}</span>\"\n","\n","    html_output += \"</div>\"\n","    display(HTML(html_output))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-piHygJ6dpEa","colab_type":"text"},"source":["Display example outputs as HTML"]},{"cell_type":"code","metadata":{"id":"AtbhE24VeG_C","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":191},"outputId":"05d8fae4-bf84-45c3-e047-39c7448e58ee"},"source":["for example in input_list:\n","    annotation_to_html(light_pipeline.fullAnnotate(example))"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<div><span class=\"others\">HISTORY OF PRESENT ILLNESS: Mr. </span><span class=\"entity-wrapper\" style=\"color: black; background-color: #f9f7fb\"> <span class=\"entity-name\">Smith</span> <span class=\"entity-type\">[PATIENT]</span></span><span class=\"others\"> is a 60-year-old white male veteran with multiple comorbidities, who has a history of bladder cancer diagnosed approximately two years ago by the </span><span class=\"entity-wrapper\" style=\"color: black; background-color: #a9e3a5\"> <span class=\"entity-name\">VA Hospital</span> <span class=\"entity-type\">[HOSPITAL]</span></span><span class=\"others\">. He underwent a resection there. He was to be admitted to the </span><span class=\"entity-wrapper\" style=\"color: black; background-color: #a9e3a5\"> <span class=\"entity-name\">Day Hospital</span> <span class=\"entity-type\">[HOSPITAL]</span></span><span class=\"others\"> for cystectomy. He was seen in Urology Clinic and Radiology Clinic on </span><span class=\"entity-wrapper\" style=\"color: black; background-color: #ebc4a2\"> <span class=\"entity-name\">02/04/2003</span> <span class=\"entity-type\">[DATE]</span></span><span class=\"others\">.\n","\n","HOSPITAL COURSE: Mr. </span><span class=\"entity-wrapper\" style=\"color: black; background-color: #f9f7fb\"> <span class=\"entity-name\">Smith</span> <span class=\"entity-type\">[PATIENT]</span></span><span class=\"others\"> presented to the </span><span class=\"entity-wrapper\" style=\"color: black; background-color: #a9e3a5\"> <span class=\"entity-name\">Day Hospital</span> <span class=\"entity-type\">[HOSPITAL]</span></span><span class=\"others\"> in anticipation for Urology surgery. On evaluation, EKG, echocardiogram was abnormal, a Cardiology consult was obtained. A cardiac adenosine stress MRI was then proceeded, same was positive for inducible ischemia, mild-to-moderate inferolateral subendocardial infarction with peri-infarct ischemia. In addition, inducible ischemia seen in the inferior lateral septum. Mr. </span><span class=\"entity-wrapper\" style=\"color: black; background-color: #f9f7fb\"> <span class=\"entity-name\">Smith</span> <span class=\"entity-type\">[PATIENT]</span></span><span class=\"others\"> underwent a left heart catheterization, which revealed two vessel coronary artery disease. The RCA, proximal was 95% stenosed and the distal 80% stenosed. The mid LAD was 85% stenosed and the distal LAD was 85% stenosed. There was four Multi-Link Vision bare metal stents placed to decrease all four lesions to 0%. Following intervention, Mr. </span><span class=\"entity-wrapper\" style=\"color: black; background-color: #f9f7fb\"> <span class=\"entity-name\">Smith</span> <span class=\"entity-type\">[PATIENT]</span></span><span class=\"others\"> was admitted to </span><span class=\"entity-wrapper\" style=\"color: black; background-color: #a6ccb3\"> <span class=\"entity-name\">7 Ardmore Tower</span> <span class=\"entity-type\">[STREET]</span></span><span class=\"others\"> under Cardiology Service under the direction of Dr. </span><span class=\"entity-wrapper\" style=\"color: black; background-color: #def982\"> <span class=\"entity-name\">Hart</span> <span class=\"entity-type\">[DOCTOR]</span></span><span class=\"others\">. Mr. </span><span class=\"entity-wrapper\" style=\"color: black; background-color: #f9f7fb\"> <span class=\"entity-name\">Smith</span> <span class=\"entity-type\">[PATIENT]</span></span><span class=\"others\"> had a noncomplicated post-intervention hospital course. He was stable for discharge home on </span><span class=\"entity-wrapper\" style=\"color: black; background-color: #ebc4a2\"> <span class=\"entity-name\">02/07/2003</span> <span class=\"entity-type\">[DATE]</span></span><span class=\"others\"> with instructions to take Plavix daily for one month and Urology is aware of the same.</span></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]}]}