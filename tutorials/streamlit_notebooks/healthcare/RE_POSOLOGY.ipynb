{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RE_POSOLOGY.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"TA21Jo5d9SVq","colab_type":"text"},"source":["\n","\n","![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n","\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/healthcare/RE_POSOLOGY.ipynb)\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"CzIdjHkAW8TB","colab_type":"text"},"source":["# **Detect posology relations**"]},{"cell_type":"markdown","metadata":{"id":"6uDmeHEFW7_h","colab_type":"text"},"source":["To run this yourself, you will need to upload your license keys to the notebook. Otherwise, you can look at the example outputs at the bottom of the notebook. To upload license keys, open the file explorer on the left side of the screen and upload `workshop_license_keys.json` to the folder that opens."]},{"cell_type":"markdown","metadata":{"id":"wIeCOiJNW-88","colab_type":"text"},"source":["## 1. Colab Setup"]},{"cell_type":"markdown","metadata":{"id":"HMIDv74CYN0d","colab_type":"text"},"source":["Import license keys"]},{"cell_type":"code","metadata":{"id":"ttHPIV2JXbIM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1599820758535,"user_tz":-300,"elapsed":1563,"user":{"displayName":"Hasham Ul Haq","photoUrl":"","userId":"10508284328555930330"}},"outputId":"0e3aa0b3-85cb-4f2f-e34a-1d9437e92d2d"},"source":["import os\n","import json\n","\n","with open('/content/spark_nlp_for_healthcare.json', 'r') as f:\n","    license_keys = json.load(f)\n","\n","license_keys.keys()\n","\n","secret = license_keys['SECRET']\n","os.environ['SPARK_NLP_LICENSE'] = license_keys['SPARK_NLP_LICENSE']\n","os.environ['AWS_ACCESS_KEY_ID'] = license_keys['AWS_ACCESS_KEY_ID']\n","os.environ['AWS_SECRET_ACCESS_KEY'] = license_keys['AWS_SECRET_ACCESS_KEY']\n","sparknlp_version = license_keys[\"PUBLIC_VERSION\"]\n","jsl_version = license_keys[\"JSL_VERSION\"]\n","\n","print ('SparkNLP Version:', sparknlp_version)\n","print ('SparkNLP-JSL Version:', jsl_version)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["SparkNLP Version: 2.6.0\n","SparkNLP-JSL Version: 2.6.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rQtc1CHaYQjU","colab_type":"text"},"source":["Install dependencies"]},{"cell_type":"code","metadata":{"id":"CGJktFHdHL1n","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":326},"executionInfo":{"status":"ok","timestamp":1599820756966,"user_tz":-300,"elapsed":57073,"user":{"displayName":"Hasham Ul Haq","photoUrl":"","userId":"10508284328555930330"}},"outputId":"7cfa7dfc-3ffc-4c38-c726-c903e2bcb858"},"source":["# Install Java\n","! apt-get update -qq\n","! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n","! java -version\n","\n","# Install pyspark\n","! pip install --ignore-installed -q pyspark==2.4.4\n","\n","# Install Spark NLP\n","! pip install --ignore-installed spark-nlp==$sparknlp_version\n","! python -m pip install --upgrade spark-nlp-jsl==$jsl_version --extra-index-url https://pypi.johnsnowlabs.com/$secret"],"execution_count":2,"outputs":[{"output_type":"stream","text":["openjdk version \"11.0.8\" 2020-07-14\n","OpenJDK Runtime Environment (build 11.0.8+10-post-Ubuntu-0ubuntu118.04.1)\n","OpenJDK 64-Bit Server VM (build 11.0.8+10-post-Ubuntu-0ubuntu118.04.1, mixed mode, sharing)\n","\u001b[K     |████████████████████████████████| 215.7MB 57kB/s \n","\u001b[K     |████████████████████████████████| 204kB 47.0MB/s \n","\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting spark-nlp==2.6.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e4/30/1bd0abcc97caed518efe527b9146897255dffcf71c4708586a82ea9eb29a/spark_nlp-2.6.0-py2.py3-none-any.whl (125kB)\n","\u001b[K     |████████████████████████████████| 133kB 3.4MB/s \n","\u001b[?25hInstalling collected packages: spark-nlp\n","Successfully installed spark-nlp-2.6.0\n","Looking in indexes: https://pypi.org/simple, https://pypi.johnsnowlabs.com/2.6.0-8388813d58b67fa25bf9cf603393363af96dba16\n","Collecting spark-nlp-jsl==2.6.0\n","  Downloading https://pypi.johnsnowlabs.com/2.6.0-8388813d58b67fa25bf9cf603393363af96dba16/spark-nlp-jsl/spark_nlp_jsl-2.6.0-py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: spark-nlp==2.6.0 in /usr/local/lib/python3.6/dist-packages (from spark-nlp-jsl==2.6.0) (2.6.0)\n","Installing collected packages: spark-nlp-jsl\n","Successfully installed spark-nlp-jsl-2.6.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Hj5FRDV4YSXN","colab_type":"text"},"source":["Import dependencies into Python"]},{"cell_type":"code","metadata":{"id":"qUWyj8c6JSPP","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599820844412,"user_tz":-300,"elapsed":1090,"user":{"displayName":"Hasham Ul Haq","photoUrl":"","userId":"10508284328555930330"}}},"source":["os.environ['JAVA_HOME'] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ['PATH'] = os.environ['JAVA_HOME'] + \"/bin:\" + os.environ['PATH']\n","\n","import pandas as pd\n","from pyspark.ml import Pipeline\n","from pyspark.sql import SparkSession\n","import pyspark.sql.functions as F\n","\n","import sparknlp\n","from sparknlp.annotator import *\n","from sparknlp_jsl.annotator import *\n","from sparknlp.base import *\n","import sparknlp_jsl\n"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ed6Htm7qDQB3","colab_type":"text"},"source":["Start the Spark session"]},{"cell_type":"code","metadata":{"id":"eaSM8-xhDRa4","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599820864325,"user_tz":-300,"elapsed":19605,"user":{"displayName":"Hasham Ul Haq","photoUrl":"","userId":"10508284328555930330"}}},"source":["spark = sparknlp_jsl.start(secret)"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9RgiqfX5XDqb","colab_type":"text"},"source":["## 2. Select the Relation Extraction model and construct the pipeline"]},{"cell_type":"markdown","metadata":{"id":"AVKr8C2SrkZQ","colab_type":"text"},"source":["Select the models:\n","\n","\n","* Posology Relation Extraction models: **posology_re**\n","\n","\n","\n","\n","For more details: https://github.com/JohnSnowLabs/spark-nlp-models#pretrained-models---spark-nlp-for-healthcare"]},{"cell_type":"code","metadata":{"id":"cK9xxkkfrsLc","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599820864326,"user_tz":-300,"elapsed":18681,"user":{"displayName":"Hasham Ul Haq","photoUrl":"","userId":"10508284328555930330"}}},"source":["# Change this to the model you want to use and re-run the cells below.\n","RE_MODEL_NAME = \"posology_re\"\n","NER_MODEL_NAME = \"ner_posology_large\""],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zweiG2ilZqoR","colab_type":"text"},"source":["Create the pipeline"]},{"cell_type":"code","metadata":{"id":"LLuDz_t40be4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":221},"executionInfo":{"status":"ok","timestamp":1599821013592,"user_tz":-300,"elapsed":167101,"user":{"displayName":"Hasham Ul Haq","photoUrl":"","userId":"10508284328555930330"}},"outputId":"b4ea2fee-8bb5-4a7f-c4ad-3a46444179e3"},"source":["document_assembler = DocumentAssembler() \\\n","    .setInputCol('text')\\\n","    .setOutputCol('document')\n","\n","sentence_detector = SentenceDetector() \\\n","    .setInputCols(['document'])\\\n","    .setOutputCol('sentences')\n","\n","tokenizer = Tokenizer()\\\n","    .setInputCols(['sentences']) \\\n","    .setOutputCol('tokens')\n","\n","pos_tagger = PerceptronModel()\\\n","    .pretrained(\"pos_clinical\", \"en\", \"clinical/models\") \\\n","    .setInputCols([\"sentences\", \"tokens\"])\\\n","    .setOutputCol(\"pos_tags\")\n","\n","dependency_parser = DependencyParserModel()\\\n","    .pretrained(\"dependency_conllu\", \"en\")\\\n","    .setInputCols([\"sentences\", \"pos_tags\", \"tokens\"])\\\n","    .setOutputCol(\"dependencies\")\n","\n","embeddings = WordEmbeddingsModel.pretrained('embeddings_clinical', 'en', 'clinical/models')\\\n","    .setInputCols([\"sentences\", \"tokens\"])\\\n","    .setOutputCol(\"embeddings\")\n","\n","clinical_ner_model = NerDLModel().pretrained(NER_MODEL_NAME, 'en', 'clinical/models').setInputCols(\"sentences\", \"tokens\", \"embeddings\")\\\n","    .setOutputCol(\"clinical_ner_tags\")   \n","\n","clinical_ner_chunker = NerConverter()\\\n","    .setInputCols([\"sentences\", \"tokens\", \"clinical_ner_tags\"])\\\n","    .setOutputCol(\"clinical_ner_chunks\")\n","\n","clinical_re_Model = RelationExtractionModel()\\\n","    .pretrained(RE_MODEL_NAME, 'en', 'clinical/models')\\\n","    .setInputCols([\"embeddings\", \"pos_tags\", \"clinical_ner_chunks\", \"dependencies\"])\\\n","    .setOutputCol(\"clinical_relations\")\\\n","    .setMaxSyntacticDistance(4)\n","    #.setRelationPairs()#[\"problem-test\", \"problem-treatment\"]) # we can set the possible relation pairs (if not set, all the relations will be calculated)\n","\n","pipeline = Pipeline(stages=[\n","    document_assembler, \n","    sentence_detector,\n","    tokenizer,\n","    pos_tagger,\n","    dependency_parser,\n","    embeddings,\n","    clinical_ner_model,\n","    clinical_ner_chunker,\n","    clinical_re_Model])\n","\n","empty_df = spark.createDataFrame([['']]).toDF(\"text\")\n","pipeline_model = pipeline.fit(empty_df)\n","light_pipeline = LightPipeline(pipeline_model)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["pos_clinical download started this may take some time.\n","Approximate size to download 1.7 MB\n","[OK!]\n","dependency_conllu download started this may take some time.\n","Approximate size to download 16.6 MB\n","[OK!]\n","embeddings_clinical download started this may take some time.\n","Approximate size to download 1.6 GB\n","[OK!]\n","ner_posology_large download started this may take some time.\n","Approximate size to download 13.8 MB\n","[OK!]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2Y9GpdJhXIpD","colab_type":"text"},"source":["## 3. Create example inputs"]},{"cell_type":"code","metadata":{"id":"vBOKkB2THdGI","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599821013594,"user_tz":-300,"elapsed":165372,"user":{"displayName":"Hasham Ul Haq","photoUrl":"","userId":"10508284328555930330"}}},"source":["# Enter examples as strings in this array\n","input_list = [\n","\"\"\"The patient is a 40-year-old white male who presents with a chief complaint of \"chest pain\". The patient is diabetic and has a prior history of coronary artery disease. The patient presents today stating that his chest pain started yesterday evening and has been somewhat intermittent. He has been advised Aspirin 81 milligrams QDay. Humulin N. insulin 50 units in a.m. HCTZ 50 mg QDay. Nitroglycerin 1/150 sublingually PRN chest pain.\"\"\",\n","]"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1gmrjqHSGcJx","colab_type":"text"},"source":["# 4. Run the pipeline"]},{"cell_type":"code","metadata":{"id":"xdhgKutMHUoC","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599821018607,"user_tz":-300,"elapsed":169059,"user":{"displayName":"Hasham Ul Haq","photoUrl":"","userId":"10508284328555930330"}}},"source":["df = spark.createDataFrame(pd.DataFrame({\"text\": input_list}))\n","result = pipeline_model.transform(df)\n","light_result = light_pipeline.fullAnnotate(input_list[0])"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UIVShVLhI68M","colab_type":"text"},"source":["# 5. Visualize"]},{"cell_type":"markdown","metadata":{"id":"472iBPpK-FvF","colab_type":"text"},"source":["helper function for visualization"]},{"cell_type":"code","metadata":{"id":"PQrKey9B-FF_","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599821018608,"user_tz":-300,"elapsed":168048,"user":{"displayName":"Hasham Ul Haq","photoUrl":"","userId":"10508284328555930330"}}},"source":["def get_relations_df (results, rel='clinical_relations'):\n","    rel_pairs=[]\n","    for rel in results[rel]:\n","        rel_pairs.append((\n","          rel.result, \n","          rel.metadata['entity1'], \n","          rel.metadata['entity1_begin'],\n","          rel.metadata['entity1_end'],\n","          rel.metadata['chunk1'], \n","          rel.metadata['entity2'],\n","          rel.metadata['entity2_begin'],\n","          rel.metadata['entity2_end'],\n","          rel.metadata['chunk2'], \n","          rel.metadata['confidence']\n","        ))\n","\n","    rel_df = pd.DataFrame(rel_pairs, columns=['relation','entity1','entity1_begin','entity1_end','chunk1','entity2','entity2_begin','entity2_end','chunk2', 'confidence'])\n","\n","    return rel_df[rel_df.relation!='O']"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qdh2BQaLI7tU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":501},"executionInfo":{"status":"ok","timestamp":1599066000165,"user_tz":-300,"elapsed":2847,"user":{"displayName":"Hasham Ul Haq","photoUrl":"","userId":"10508284328555930330"}},"outputId":"db04a7f4-0838-4f5a-ec05-f3844e412553"},"source":["get_relations_df(light_result[0])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>relation</th>\n","      <th>entity1</th>\n","      <th>entity1_begin</th>\n","      <th>entity1_end</th>\n","      <th>chunk1</th>\n","      <th>entity2</th>\n","      <th>entity2_begin</th>\n","      <th>entity2_end</th>\n","      <th>chunk2</th>\n","      <th>confidence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>DRUG-STRENGTH</td>\n","      <td>DRUG</td>\n","      <td>306</td>\n","      <td>312</td>\n","      <td>Aspirin</td>\n","      <td>STRENGTH</td>\n","      <td>314</td>\n","      <td>326</td>\n","      <td>81 milligrams</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>DRUG-FREQUENCY</td>\n","      <td>DRUG</td>\n","      <td>306</td>\n","      <td>312</td>\n","      <td>Aspirin</td>\n","      <td>FREQUENCY</td>\n","      <td>328</td>\n","      <td>331</td>\n","      <td>QDay</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>DRUG-DOSAGE</td>\n","      <td>DRUG</td>\n","      <td>334</td>\n","      <td>340</td>\n","      <td>Humulin</td>\n","      <td>DOSAGE</td>\n","      <td>353</td>\n","      <td>360</td>\n","      <td>50 units</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>DRUG-DOSAGE</td>\n","      <td>DRUG</td>\n","      <td>345</td>\n","      <td>351</td>\n","      <td>insulin</td>\n","      <td>DOSAGE</td>\n","      <td>353</td>\n","      <td>360</td>\n","      <td>50 units</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>DRUG-STRENGTH</td>\n","      <td>DRUG</td>\n","      <td>370</td>\n","      <td>373</td>\n","      <td>HCTZ</td>\n","      <td>STRENGTH</td>\n","      <td>375</td>\n","      <td>379</td>\n","      <td>50 mg</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>DRUG-FREQUENCY</td>\n","      <td>DRUG</td>\n","      <td>370</td>\n","      <td>373</td>\n","      <td>HCTZ</td>\n","      <td>FREQUENCY</td>\n","      <td>381</td>\n","      <td>384</td>\n","      <td>QDay</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>DRUG-STRENGTH</td>\n","      <td>DRUG</td>\n","      <td>387</td>\n","      <td>399</td>\n","      <td>Nitroglycerin</td>\n","      <td>STRENGTH</td>\n","      <td>401</td>\n","      <td>405</td>\n","      <td>1/150</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>DRUG-ROUTE</td>\n","      <td>DRUG</td>\n","      <td>387</td>\n","      <td>399</td>\n","      <td>Nitroglycerin</td>\n","      <td>ROUTE</td>\n","      <td>407</td>\n","      <td>418</td>\n","      <td>sublingually</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>DRUG-FREQUENCY</td>\n","      <td>DRUG</td>\n","      <td>387</td>\n","      <td>399</td>\n","      <td>Nitroglycerin</td>\n","      <td>FREQUENCY</td>\n","      <td>420</td>\n","      <td>422</td>\n","      <td>PRN</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         relation entity1 entity1_begin  ... entity2_end         chunk2 confidence\n","0   DRUG-STRENGTH    DRUG           306  ...         326  81 milligrams        1.0\n","1  DRUG-FREQUENCY    DRUG           306  ...         331           QDay        1.0\n","2     DRUG-DOSAGE    DRUG           334  ...         360       50 units        1.0\n","3     DRUG-DOSAGE    DRUG           345  ...         360       50 units        1.0\n","4   DRUG-STRENGTH    DRUG           370  ...         379          50 mg        1.0\n","5  DRUG-FREQUENCY    DRUG           370  ...         384           QDay        1.0\n","6   DRUG-STRENGTH    DRUG           387  ...         405          1/150        1.0\n","7      DRUG-ROUTE    DRUG           387  ...         418   sublingually        1.0\n","8  DRUG-FREQUENCY    DRUG           387  ...         422            PRN        1.0\n","\n","[9 rows x 10 columns]"]},"metadata":{"tags":[]},"execution_count":12}]}]}