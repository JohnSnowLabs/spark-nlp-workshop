{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NORMALIZED_SECTION_HEADER_MAPPER.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/healthcare/NORMALIZED_SECTION_HEADER_MAPPER.ipynb)"
      ],
      "metadata": {
        "id": "N4bAsOG64nZL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **`normalized_section_header_mapper` model**"
      ],
      "metadata": {
        "id": "04rkpbqyBXuA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Colab Setup**"
      ],
      "metadata": {
        "id": "ISNyGR4K4Y_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "if 'spark_jsl.json' not in os.listdir():\n",
        "  license_keys = files.upload()\n",
        "  os.rename(list(license_keys.keys())[0], 'spark_jsl.json')\n",
        "\n",
        "with open('spark_jsl.json') as f:\n",
        "    license_keys = json.load(f)\n",
        "\n",
        "# Defining license key-value pairs as local variables\n",
        "locals().update(license_keys)\n",
        "os.environ.update(license_keys)"
      ],
      "metadata": {
        "id": "et-o7PQP0Sjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXF9kBOB0Caz"
      },
      "outputs": [],
      "source": [
        "# Installing pyspark and spark-nlp\n",
        "! pip install --upgrade -q pyspark==3.1.2 spark-nlp==$PUBLIC_VERSION\n",
        "\n",
        "# Installing Spark NLP Healthcare\n",
        "! pip install --upgrade -q spark-nlp-jsl==$JSL_VERSION  --extra-index-url https://pypi.johnsnowlabs.com/$SECRET\n",
        "\n",
        "# Installing Spark NLP Display Library for visualization\n",
        "! pip install -q spark-nlp-display"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Start the Spark session**"
      ],
      "metadata": {
        "id": "Y6YKz2y64ugj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "import sparknlp\n",
        "import sparknlp_jsl\n",
        "\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp_jsl.annotator import *\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.ml import Pipeline,PipelineModel\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "params = {\"spark.driver.memory\":\"16G\", \n",
        "          \"spark.kryoserializer.buffer.max\":\"2000M\", \n",
        "          \"spark.driver.maxResultSize\":\"2000M\"} \n",
        "\n",
        "print(\"Spark NLP Version :\", sparknlp.version())\n",
        "print(\"Spark NLP_JSL Version :\", sparknlp_jsl.version())\n",
        "\n",
        "spark = sparknlp_jsl.start(license_keys['SECRET'],params=params)\n",
        "\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "Rc2_m9JX0VZR",
        "outputId": "c631b132-714d-4dfe-b6ad-f621fa511eac"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP Version : 3.4.4\n",
            "Spark NLP_JSL Version : 3.5.2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f498e886150>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://da26c1206bc3:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark NLP Licensed</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ðŸ”Ž For about models**"
      ],
      "metadata": {
        "id": "mitty7tK1Lux"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ“Œ **normalized_section_header_mapper**\n",
        "\n",
        "This pretrained pipeline normalizes the section headers in clinical notes. It returns two levels of normalization called level_1 and level_2."
      ],
      "metadata": {
        "id": "h48IlU5V1QJl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ðŸ”ŽDefine Spark NLP pipeline**"
      ],
      "metadata": {
        "id": "Ay08hTB11pLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document_assembler = DocumentAssembler()\\\n",
        "      .setInputCol('text')\\\n",
        "      .setOutputCol('document')\n",
        "\n",
        "sentence_detector = SentenceDetector()\\\n",
        "      .setInputCols([\"document\"])\\\n",
        "      .setOutputCol(\"sentence\")\n",
        "\n",
        "tokenizer = Tokenizer()\\\n",
        "      .setInputCols(\"sentence\")\\\n",
        "      .setOutputCol(\"token\")\n",
        "\n",
        "embeddings = WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\",\"clinical/models\")\\\n",
        "      .setInputCols([\"sentence\", \"token\"])\\\n",
        "      .setOutputCol(\"word_embeddings\")\n",
        "\n",
        "clinical_ner = MedicalNerModel.pretrained(\"ner_jsl_slim\", \"en\", \"clinical/models\")\\\n",
        "      .setInputCols([\"sentence\",\"token\", \"word_embeddings\"])\\\n",
        "      .setOutputCol(\"ner\")\n",
        "\n",
        "ner_converter = NerConverter()\\\n",
        "      .setInputCols([\"sentence\", \"token\", \"ner\"])\\\n",
        "      .setOutputCol(\"ner_chunk\")\\\n",
        "      .setWhiteList([\"Header\"])\n",
        "\n",
        "chunkerMapper = ChunkMapperModel.pretrained(\"normalized_section_header_mapper\", \"en\", \"clinical/models\") \\\n",
        "      .setInputCols(\"ner_chunk\")\\\n",
        "      .setOutputCol(\"mappings\")\\\n",
        "      .setRel(\"level_1\") #or level_2\n",
        "\n",
        "pipeline = Pipeline().setStages([document_assembler,\n",
        "                                 sentence_detector,\n",
        "                                 tokenizer, \n",
        "                                 embeddings,\n",
        "                                 clinical_ner, \n",
        "                                 ner_converter, \n",
        "                                 chunkerMapper])\n",
        "\n",
        "pipeline_model = pipeline.fit(spark.createDataFrame([[\"\"]]).toDF('text'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJxBdHQa0iey",
        "outputId": "9dd757ba-cc4d-4137-fb0e-94a382b9e6a5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embeddings_clinical download started this may take some time.\n",
            "Approximate size to download 1.6 GB\n",
            "[OK!]\n",
            "ner_jsl_slim download started this may take some time.\n",
            "[OK!]\n",
            "normalized_section_header_mapper download started this may take some time.\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ðŸ”ŽSample Text**"
      ],
      "metadata": {
        "id": "8G-YK3gs2PpT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = \"\"\"ADMISSION DIAGNOSIS Upper respiratory illness with apnea, possible pertussis.\n",
        "DISCHARGE DIAGNOSIS Upper respiratory illness with apnea, possible pertussis.\n",
        "PATIENT HISTORY This is a one plus-month-old female with respiratory symptoms for approximately a week prior to admission.  This involved cough, post-tussive emesis, questionable fever, but only 99.7.  Their usual doctor prescribed amoxicillin over the phone.  The coughing persisted and worsened.  She went to the ER, where sats were normal at baseline, but dropped into the 80s with coughing spells.  They did witness some apnea.  They gave some Rocephin, did some labs, and the patient was transferred to hospital.\n",
        "GENERAL HISTORY AND PHYSICAL On admission. there was some nasal discharge. Remainder of the HEENT was normal.Had few rhonchi,  No retractions,  No significant coughing or apnea during the admission physical. abdomen  benign.  \n",
        "RADIOGRAPHIC STUDIES She had a CBC done Garberville, which showed a white count of 12.4, with a differential of 10 segs, 82 lymphs, 8 monos, hemoglobin of 15, hematocrit 42, platelets 296,000, and a normal BMP.  An x-ray was done and I do not have an official interpretation, but to the admitting physician, Dr. X it showed no significant infiltrate.  Well at hospital, she had a rapid influenza swab done, which was negative.  She had a rapid RSV done, which is still not in the chart, but I believe I was told that it was negative.  She also had a pertussis PCR swab done and a pertussis culture done, neither of which has result in the chart.  I do know that the pertussis culture proved to be negative.\n",
        "HOSPITAL COURSE The baby was afebrile.  Required no oxygen in the hospital.  Actually fed reasonably well.  Did have one episode of coughing with slight emesis.  Appeared basically quite well between episodes.  Had no apnea witnessed and after overnight observation, the parents were anxious to go home.  The patient was started on Zithromax in the hospital.\n",
        "DISCHARGE CONDITION The patient was in stable condition and good condition on exam at the time and was discharged home on Zithromax to be followed up in the office within a week.\n",
        "DISCHARGE INSTRUCTIONS Include usual diet and to follow up within a week, but certainly sooner if the coughing is worse and there is cyanosis or apnea again.\"\"\"\n",
        "\n",
        "\n",
        "data = spark.createDataFrame([[sample_text]]).toDF('text')"
      ],
      "metadata": {
        "id": "MvxK0aIH25qk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ðŸ”ŽRun the pipeline**"
      ],
      "metadata": {
        "id": "cHRkkFpV3cGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = pipeline_model.transform(data)"
      ],
      "metadata": {
        "id": "1LtasCE0P0_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.select(F.explode(F.arrays_zip(\"ner_chunk.result\", \"mappings.result\")).alias(\"col\"))\\\n",
        "                            .select(F.expr(\"col['0']\").alias(\"ner_chunk\"),\n",
        "                                    F.expr(\"col['1']\").alias(\"normalized_headers\")).show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6ejXY0o3chf",
        "outputId": "14e4128c-f7c4-4519-d9e6-8a5d98dbb815"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------+-----------------------------+\n",
            "|ner_chunk                   |normalized_headers           |\n",
            "+----------------------------+-----------------------------+\n",
            "|ADMISSION DIAGNOSIS         |DIAGNOSIS                    |\n",
            "|DISCHARGE DIAGNOSIS         |DIAGNOSIS                    |\n",
            "|PATIENT HISTORY             |HISTORY                      |\n",
            "|GENERAL HISTORY AND PHYSICAL|EXAM TYPE                    |\n",
            "|RADIOGRAPHIC STUDIES        |LABORATORY AND RADIOLOGY DATA|\n",
            "|HOSPITAL COURSE             |COURSE TYPE                  |\n",
            "|DISCHARGE CONDITION         |DISCHARGE RELATED            |\n",
            "|DISCHARGE INSTRUCTIONS      |DISCHARGE RELATED            |\n",
            "+----------------------------+-----------------------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}