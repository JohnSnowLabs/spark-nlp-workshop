{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4b_2KemgDWf"
      },
      "source": [
        "\n",
        "\n",
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/healthcare/CONTEXTUAL_SPELL_CHECKER.ipynb)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnZG0I4ogNLI"
      },
      "source": [
        "# **Spell checking for clinical documents**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yjs3mqUJgNQM"
      },
      "source": [
        "To run this yourself, you will need to upload your license keys to the notebook. Just Run The Cell Below in order to do that. Also You can open the file explorer on the left side of the screen and upload `license_keys.json` to the folder that opens.\n",
        "Otherwise, you can look at the example outputs at the bottom of the notebook.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apjCmRyjgQll"
      },
      "source": [
        "## 1. Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": "OK"
            }
          }
        },
        "id": "uAiXj3DOfyZ-",
        "outputId": "eaba2e02-14a9-43d3-9cd2-0734d6de38e8"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "license_keys = files.upload()\n",
        "\n",
        "with open(list(license_keys.keys())[0]) as f:\n",
        "    license_keys = json.load(f)\n",
        "\n",
        "# Defining license key-value pairs as local variables\n",
        "locals().update(license_keys)\n",
        "\n",
        "# Adding license key-value pairs to environment variables\n",
        "os.environ.update(license_keys)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2phEj9SygX4n"
      },
      "source": [
        "Install Pyspark & SparkNLP and Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bGQnBVvvbHH_"
      },
      "outputs": [],
      "source": [
        "# Installing pyspark and spark-nlp\n",
        "! pip install --upgrade -q pyspark==3.1.2 spark-nlp==$PUBLIC_VERSION\n",
        "\n",
        "# Installing Spark NLP Healthcare\n",
        "! pip install --upgrade -q spark-nlp-jsl==$JSL_VERSION  --extra-index-url https://pypi.johnsnowlabs.com/$SECRET\n",
        "\n",
        "# Installing Spark NLP Display Library for visualization\n",
        "! pip install -q spark-nlp-display"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3Ur62RrgaxX"
      },
      "source": [
        "Import dependencies into Python and start the Spark session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "br9cSI8_gbWw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Spark NLP Version : 3.3.4\n",
            "Spark NLP_JSL Version : 3.3.4\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://ip-172-31-38-169.us-east-2.compute.internal:4048\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark NLP Licensed</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fc56fcd1080>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "from pyspark.ml import Pipeline,PipelineModel\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp_jsl.annotator import *\n",
        "from sparknlp.base import *\n",
        "import sparknlp_jsl\n",
        "import sparknlp\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "params = {\"spark.driver.memory\":\"16G\", \n",
        "          \"spark.kryoserializer.buffer.max\":\"2000M\", \n",
        "          \"spark.driver.maxResultSize\":\"2000M\"} \n",
        "\n",
        "print (\"Spark NLP Version :\", sparknlp.version())\n",
        "print (\"Spark NLP_JSL Version :\", sparknlp_jsl.version())\n",
        "\n",
        "spark = sparknlp_jsl.start(license_keys['SECRET'],params=params)\n",
        "\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# if you want to start the session with custom params as in start function above\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "def start(SECRET):\n",
        "    builder = SparkSession.builder \\\n",
        "        .appName(\"Spark NLP Licensed\") \\\n",
        "        .master(\"local[*]\") \\\n",
        "        .config(\"spark.driver.memory\", \"16G\") \\\n",
        "        .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
        "        .config(\"spark.kryoserializer.buffer.max\", \"2000M\") \\\n",
        "        .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:\"+PUBLIC_VERSION) \\\n",
        "        .config(\"spark.jars\", \"https://pypi.johnsnowlabs.com/\"+SECRET+\"/spark-nlp-jsl-\"+JSL_VERSION+\".jar\")\n",
        "      \n",
        "    return builder.getOrCreate()\n",
        "\n",
        "#spark = start(SECRET)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUP6-XeQgeQW"
      },
      "source": [
        "## 2. Select the NER model and construct the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taOqLG1Ogc3D",
        "outputId": "1e6e6e85-f06e-4136-9acc-3fd107a4b8fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "spellcheck_clinical download started this may take some time.\n",
            "Approximate size to download 142.2 MB\n",
            "[OK!]\n"
          ]
        }
      ],
      "source": [
        "document_assembler = DocumentAssembler() \\\n",
        "    .setInputCol('text') \\\n",
        "    .setOutputCol('document')\n",
        "\n",
        "tokenizer = RecursiveTokenizer() \\\n",
        "    .setInputCols(['document']) \\\n",
        "    .setOutputCol('token') \\\n",
        "    .setPrefixes([\"\\\"\", \"(\", \"[\", \"\\n\"]) \\\n",
        "    .setSuffixes([\".\", \",\", \"?\", \")\",\"!\", \"â€˜s\"])\n",
        "\n",
        "spell_model = ContextSpellCheckerModel.pretrained('spellcheck_clinical', 'en', 'clinical/models') \\\n",
        "    .setInputCols('token') \\\n",
        "    .setOutputCol('corrected')\n",
        "\n",
        "finisher = Finisher().setInputCols('corrected')\n",
        "\n",
        "light_pipeline = Pipeline(stages=[\n",
        "    document_assembler,\n",
        "    tokenizer,\n",
        "    spell_model,\n",
        "    finisher\n",
        "])\n",
        "\n",
        "full_pipeline = Pipeline(stages=[\n",
        "    document_assembler,\n",
        "    tokenizer,\n",
        "    spell_model\n",
        "])\n",
        "\n",
        "empty_df = spark.createDataFrame([[\"\"]]).toDF('text')\n",
        "pipeline_model = full_pipeline.fit(empty_df)\n",
        "light_pipeline_model = LightPipeline(light_pipeline.fit(empty_df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_DzGuMPibKr"
      },
      "source": [
        "## 3. Create example inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "c7yPd884i_XQ"
      },
      "outputs": [],
      "source": [
        "# Enter examples as strings in this array\n",
        "input_list = [\n",
        "    \"The pateint is a 5-mont-old infnt who presented initially on Monday with a cold, cugh, and runny nse for 2 days. Mom states she had no fevr. Her appetite was good but she was spitting up a lot. She had no difficulty breathin and her cough was described as dry and hacky. At that time, pysicl exam showed a right TM, which was red. Left TM was okay. She was fairly congsted but looked happy and playful. She was started on Amxil and Aldx and we told to recheck in 2 weaks to recheck her ear. Mom returned to clinic again today because she got much worse ovrnght. She was having dificlty breathing. She was much more congested and her apetit had decrsed significantly today. She also spked a tempratre yesterday of 102.6 and always hvng trouble sleping scondry to congestion.\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvyOmrgHjO5J"
      },
      "source": [
        "## 4. Use the pipeline to create outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICREynF-jzn8"
      },
      "source": [
        "Full Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RLbrPvC3jOSw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = spark.createDataFrame(pd.DataFrame({'text': input_list}))\n",
        "result = pipeline_model.transform(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhlbvs1Dj1ck"
      },
      "source": [
        "Light Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "YulVrYgAj2ex"
      },
      "outputs": [],
      "source": [
        "# Light pipelines use plain string inputs instead of data frame inputs\n",
        "light_result = light_pipeline_model.annotate(input_list[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uk72hQGqjX3f"
      },
      "source": [
        "## 5. Visualize results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9JDK9_EjaF_"
      },
      "source": [
        "Visualize comparison as dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FY_7D9RFjlQS",
        "outputId": "27156b58-b291-4284-d04f-93e6554dcd23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+-----------+\n",
            "|original  |corrected  |\n",
            "+----------+-----------+\n",
            "|The       |The        |\n",
            "|pateint   |patient    |\n",
            "|is        |is         |\n",
            "|a         |a          |\n",
            "|5-mont-old|5-month-old|\n",
            "|infnt     |infant     |\n",
            "|who       |who        |\n",
            "|presented |presented  |\n",
            "|initially |initially  |\n",
            "|on        |on         |\n",
            "|Monday    |Monday     |\n",
            "|with      |with       |\n",
            "|a         |a          |\n",
            "|cold      |cold       |\n",
            "|,         |,          |\n",
            "|cugh      |cough      |\n",
            "|,         |,          |\n",
            "|and       |and        |\n",
            "|runny     |runny      |\n",
            "|nse       |nose       |\n",
            "+----------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "exploded = F.explode(F.arrays_zip('token.result', 'corrected.result'))\n",
        "select_expression_0 = F.expr(\"cols['0']\").alias(\"original\")\n",
        "select_expression_1 = F.expr(\"cols['1']\").alias(\"corrected\")\n",
        "result.select(exploded.alias(\"cols\")) \\\n",
        "    .select(select_expression_0, select_expression_1).show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yItQfZmhcji"
      },
      "source": [
        "Vizualise light pipeline and finished result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zHSiB0skP83",
        "outputId": "8e0a445c-91ef-440e-b256-50a09cbac76c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['The',\n",
              " 'patient',\n",
              " 'is',\n",
              " 'a',\n",
              " '5-month-old',\n",
              " 'infant',\n",
              " 'who',\n",
              " 'presented',\n",
              " 'initially',\n",
              " 'on',\n",
              " 'Monday',\n",
              " 'with',\n",
              " 'a',\n",
              " 'cold',\n",
              " ',',\n",
              " 'cough',\n",
              " ',',\n",
              " 'and',\n",
              " 'runny',\n",
              " 'nose',\n",
              " 'for',\n",
              " '2',\n",
              " 'days',\n",
              " '.',\n",
              " 'Mom',\n",
              " 'states',\n",
              " 'she',\n",
              " 'had',\n",
              " 'no',\n",
              " 'fer',\n",
              " '.',\n",
              " 'Her',\n",
              " 'appetite',\n",
              " 'was',\n",
              " 'good',\n",
              " 'but',\n",
              " 'she',\n",
              " 'was',\n",
              " 'spitting',\n",
              " 'up',\n",
              " 'a',\n",
              " 'lot',\n",
              " '.',\n",
              " 'She',\n",
              " 'had',\n",
              " 'no',\n",
              " 'difficulty',\n",
              " 'breathing',\n",
              " 'and',\n",
              " 'her',\n",
              " 'cough',\n",
              " 'was',\n",
              " 'described',\n",
              " 'as',\n",
              " 'dry',\n",
              " 'and',\n",
              " 'back',\n",
              " '.',\n",
              " 'At',\n",
              " 'that',\n",
              " 'time',\n",
              " ',',\n",
              " 'physical',\n",
              " 'exam',\n",
              " 'showed',\n",
              " 'a',\n",
              " 'right',\n",
              " 'TM',\n",
              " ',',\n",
              " 'which',\n",
              " 'was',\n",
              " 'red',\n",
              " '.',\n",
              " 'Left',\n",
              " 'TM',\n",
              " 'was',\n",
              " 'okay',\n",
              " '.',\n",
              " 'She',\n",
              " 'was',\n",
              " 'fairly',\n",
              " 'congested',\n",
              " 'but',\n",
              " 'looked',\n",
              " 'happy',\n",
              " 'and',\n",
              " 'play',\n",
              " '.',\n",
              " 'She',\n",
              " 'was',\n",
              " 'started',\n",
              " 'on',\n",
              " 'Amoxil',\n",
              " 'and',\n",
              " 'Aldex',\n",
              " 'and',\n",
              " 'we',\n",
              " 'told',\n",
              " 'to',\n",
              " 'recheck',\n",
              " 'in',\n",
              " '2',\n",
              " 'weeks',\n",
              " 'to',\n",
              " 'recheck',\n",
              " 'her',\n",
              " 'ear',\n",
              " '.',\n",
              " 'Mom',\n",
              " 'returned',\n",
              " 'to',\n",
              " 'clinic',\n",
              " 'again',\n",
              " 'today',\n",
              " 'because',\n",
              " 'she',\n",
              " 'got',\n",
              " 'much',\n",
              " 'worse',\n",
              " 'overnight',\n",
              " '.',\n",
              " 'She',\n",
              " 'was',\n",
              " 'having',\n",
              " 'difficulty',\n",
              " 'breathing',\n",
              " '.',\n",
              " 'She',\n",
              " 'was',\n",
              " 'much',\n",
              " 'more',\n",
              " 'congested',\n",
              " 'and',\n",
              " 'her',\n",
              " 'acetic',\n",
              " 'had',\n",
              " 'decreased',\n",
              " 'significantly',\n",
              " 'today',\n",
              " '.',\n",
              " 'She',\n",
              " 'also',\n",
              " 'speed',\n",
              " 'a',\n",
              " 'temperature',\n",
              " 'yesterday',\n",
              " 'of',\n",
              " '102.6',\n",
              " 'and',\n",
              " 'always',\n",
              " 'hang',\n",
              " 'trouble',\n",
              " 'sleeping',\n",
              " 'secondary',\n",
              " 'to',\n",
              " 'congestion',\n",
              " '.']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# This finished result does not need parsing and can directly be used in any\n",
        "# other task\n",
        "light_result['corrected']"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "CONTEXTUAL_SPELL_CHECKER.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "45150093197569bb3a58481dcd32cd1adb45462fa3448719e8ac38ada6166aca"
    },
    "kernelspec": {
      "display_name": "Python 3.6.10 64-bit ('tensorflow2_p36': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
