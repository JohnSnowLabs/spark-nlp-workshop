{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RE_CLINICAL.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"TA21Jo5d9SVq","colab_type":"text"},"source":["\n","\n","![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n","\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/healthcare/RE_CLINICAL.ipynb)\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"CzIdjHkAW8TB","colab_type":"text"},"source":["# **Detect causality between symptoms and treatment**"]},{"cell_type":"markdown","metadata":{"id":"6uDmeHEFW7_h","colab_type":"text"},"source":["To run this yourself, you will need to upload your license keys to the notebook. Otherwise, you can look at the example outputs at the bottom of the notebook. To upload license keys, open the file explorer on the left side of the screen and upload `workshop_license_keys.json` to the folder that opens."]},{"cell_type":"markdown","metadata":{"id":"wIeCOiJNW-88","colab_type":"text"},"source":["## 1. Colab Setup"]},{"cell_type":"markdown","metadata":{"id":"HMIDv74CYN0d","colab_type":"text"},"source":["Import license keys"]},{"cell_type":"code","metadata":{"id":"ttHPIV2JXbIM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1599820641285,"user_tz":-300,"elapsed":1204,"user":{"displayName":"Hasham Ul Haq","photoUrl":"","userId":"10508284328555930330"}},"outputId":"d242b047-fac8-4607-c52e-43b5998e05e9"},"source":["import os\n","import json\n","\n","with open('/content/spark_nlp_for_healthcare.json', 'r') as f:\n","    license_keys = json.load(f)\n","\n","license_keys.keys()\n","\n","secret = license_keys['SECRET']\n","os.environ['SPARK_NLP_LICENSE'] = license_keys['SPARK_NLP_LICENSE']\n","os.environ['AWS_ACCESS_KEY_ID'] = license_keys['AWS_ACCESS_KEY_ID']\n","os.environ['AWS_SECRET_ACCESS_KEY'] = license_keys['AWS_SECRET_ACCESS_KEY']\n","sparknlp_version = license_keys[\"PUBLIC_VERSION\"]\n","jsl_version = license_keys[\"JSL_VERSION\"]\n","\n","print ('SparkNLP Version:', sparknlp_version)\n","print ('SparkNLP-JSL Version:', jsl_version)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["SparkNLP Version: 2.6.0\n","SparkNLP-JSL Version: 2.6.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rQtc1CHaYQjU","colab_type":"text"},"source":["Install dependencies"]},{"cell_type":"code","metadata":{"id":"CGJktFHdHL1n","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":326},"executionInfo":{"status":"ok","timestamp":1599820716930,"user_tz":-300,"elapsed":75630,"user":{"displayName":"Hasham Ul Haq","photoUrl":"","userId":"10508284328555930330"}},"outputId":"bcd7ff49-02af-4b56-99f0-8f4977a3ef28"},"source":["# Install Java\n","! apt-get update -qq\n","! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n","! java -version\n","\n","# Install pyspark\n","! pip install --ignore-installed -q pyspark==2.4.4\n","\n","# Install Spark NLP\n","! pip install --ignore-installed spark-nlp==$sparknlp_version\n","! python -m pip install --upgrade spark-nlp-jsl==$jsl_version --extra-index-url https://pypi.johnsnowlabs.com/$secret"],"execution_count":2,"outputs":[{"output_type":"stream","text":["openjdk version \"11.0.8\" 2020-07-14\n","OpenJDK Runtime Environment (build 11.0.8+10-post-Ubuntu-0ubuntu118.04.1)\n","OpenJDK 64-Bit Server VM (build 11.0.8+10-post-Ubuntu-0ubuntu118.04.1, mixed mode, sharing)\n","\u001b[K     |████████████████████████████████| 215.7MB 66kB/s \n","\u001b[K     |████████████████████████████████| 204kB 19.7MB/s \n","\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting spark-nlp==2.6.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e4/30/1bd0abcc97caed518efe527b9146897255dffcf71c4708586a82ea9eb29a/spark_nlp-2.6.0-py2.py3-none-any.whl (125kB)\n","\u001b[K     |████████████████████████████████| 133kB 3.2MB/s \n","\u001b[?25hInstalling collected packages: spark-nlp\n","Successfully installed spark-nlp-2.6.0\n","Looking in indexes: https://pypi.org/simple, https://pypi.johnsnowlabs.com/2.6.0-8388813d58b67fa25bf9cf603393363af96dba16\n","Collecting spark-nlp-jsl==2.6.0\n","Requirement already satisfied, skipping upgrade: spark-nlp==2.6.0 in /usr/local/lib/python3.6/dist-packages (from spark-nlp-jsl==2.6.0) (2.6.0)\n","Installing collected packages: spark-nlp-jsl\n","Successfully installed spark-nlp-jsl-2.6.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Hj5FRDV4YSXN","colab_type":"text"},"source":["Import dependencies into Python"]},{"cell_type":"code","metadata":{"id":"qUWyj8c6JSPP","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599820716932,"user_tz":-300,"elapsed":74259,"user":{"displayName":"Hasham Ul Haq","photoUrl":"","userId":"10508284328555930330"}}},"source":["os.environ['JAVA_HOME'] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ['PATH'] = os.environ['JAVA_HOME'] + \"/bin:\" + os.environ['PATH']\n","\n","import pandas as pd\n","from pyspark.ml import Pipeline\n","from pyspark.sql import SparkSession\n","import pyspark.sql.functions as F\n","\n","import sparknlp\n","from sparknlp.annotator import *\n","from sparknlp_jsl.annotator import *\n","from sparknlp.base import *\n","import sparknlp_jsl\n"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ed6Htm7qDQB3","colab_type":"text"},"source":["Start the Spark session"]},{"cell_type":"code","metadata":{"id":"eaSM8-xhDRa4","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599820736938,"user_tz":-300,"elapsed":92537,"user":{"displayName":"Hasham Ul Haq","photoUrl":"","userId":"10508284328555930330"}}},"source":["spark = sparknlp_jsl.start(secret)"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9RgiqfX5XDqb","colab_type":"text"},"source":["## 2. Select the Relation Extraction model and construct the pipeline"]},{"cell_type":"markdown","metadata":{"id":"AVKr8C2SrkZQ","colab_type":"text"},"source":["Select the models:\n","\n","\n","* Clinical Relation Extraction models: **re_clinical**\n","\n","\n","\n","\n","For more details: https://github.com/JohnSnowLabs/spark-nlp-models#pretrained-models---spark-nlp-for-healthcare"]},{"cell_type":"code","metadata":{"id":"cK9xxkkfrsLc","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599820736941,"user_tz":-300,"elapsed":91839,"user":{"displayName":"Hasham Ul Haq","photoUrl":"","userId":"10508284328555930330"}}},"source":["# Change this to the model you want to use and re-run the cells below.\n","RE_MODEL_NAME = \"re_clinical\"\n","NER_MODEL_NAME = \"ner_clinical\""],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zweiG2ilZqoR","colab_type":"text"},"source":["Create the pipeline"]},{"cell_type":"code","metadata":{"id":"LLuDz_t40be4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":272},"executionInfo":{"status":"ok","timestamp":1599820887111,"user_tz":-300,"elapsed":240535,"user":{"displayName":"Hasham Ul Haq","photoUrl":"","userId":"10508284328555930330"}},"outputId":"d59d7fb6-1cec-47b6-8380-af3fab71ebc1"},"source":["document_assembler = DocumentAssembler() \\\n","    .setInputCol('text')\\\n","    .setOutputCol('document')\n","\n","sentence_detector = SentenceDetector() \\\n","    .setInputCols(['document'])\\\n","    .setOutputCol('sentences')\n","\n","tokenizer = Tokenizer()\\\n","    .setInputCols(['sentences']) \\\n","    .setOutputCol('tokens')\n","\n","pos_tagger = PerceptronModel()\\\n","    .pretrained(\"pos_clinical\", \"en\", \"clinical/models\") \\\n","    .setInputCols([\"sentences\", \"tokens\"])\\\n","    .setOutputCol(\"pos_tags\")\n","\n","dependency_parser = DependencyParserModel()\\\n","    .pretrained(\"dependency_conllu\", \"en\")\\\n","    .setInputCols([\"sentences\", \"pos_tags\", \"tokens\"])\\\n","    .setOutputCol(\"dependencies\")\n","\n","embeddings = WordEmbeddingsModel.pretrained('embeddings_clinical', 'en', 'clinical/models')\\\n","    .setInputCols([\"sentences\", \"tokens\"])\\\n","    .setOutputCol(\"embeddings\")\n","\n","clinical_ner_model = NerDLModel().pretrained(NER_MODEL_NAME, 'en', 'clinical/models').setInputCols(\"sentences\", \"tokens\", \"embeddings\")\\\n","    .setOutputCol(\"clinical_ner_tags\")   \n","\n","clinical_ner_chunker = NerConverter()\\\n","    .setInputCols([\"sentences\", \"tokens\", \"clinical_ner_tags\"])\\\n","    .setOutputCol(\"clinical_ner_chunks\")\n","\n","clinical_re_Model = RelationExtractionModel()\\\n","    .pretrained(RE_MODEL_NAME, 'en', 'clinical/models')\\\n","    .setInputCols([\"embeddings\", \"pos_tags\", \"clinical_ner_chunks\", \"dependencies\"])\\\n","    .setOutputCol(\"clinical_relations\")\\\n","    .setMaxSyntacticDistance(4)\n","    #.setRelationPairs()#[\"problem-test\", \"problem-treatment\"]) # we can set the possible relation pairs (if not set, all the relations will be calculated)\n","\n","pipeline = Pipeline(stages=[\n","    document_assembler, \n","    sentence_detector,\n","    tokenizer,\n","    pos_tagger,\n","    dependency_parser,\n","    embeddings,\n","    clinical_ner_model,\n","    clinical_ner_chunker,\n","    clinical_re_Model])\n","\n","empty_df = spark.createDataFrame([['']]).toDF(\"text\")\n","pipeline_model = pipeline.fit(empty_df)\n","light_pipeline = LightPipeline(pipeline_model)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["pos_clinical download started this may take some time.\n","Approximate size to download 1.7 MB\n","[OK!]\n","dependency_conllu download started this may take some time.\n","Approximate size to download 16.6 MB\n","[OK!]\n","embeddings_clinical download started this may take some time.\n","Approximate size to download 1.6 GB\n","[OK!]\n","ner_clinical download started this may take some time.\n","Approximate size to download 13.8 MB\n","[OK!]\n","re_clinical download started this may take some time.\n","Approximate size to download 6 MB\n","[OK!]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2Y9GpdJhXIpD","colab_type":"text"},"source":["## 3. Create example inputs"]},{"cell_type":"code","metadata":{"id":"vBOKkB2THdGI","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599820887112,"user_tz":-300,"elapsed":238384,"user":{"displayName":"Hasham Ul Haq","photoUrl":"","userId":"10508284328555930330"}}},"source":["# Enter examples as strings in this array\n","input_list = [\n","\"\"\"She is followed by Dr. X in our office and has a history of severe tricuspid regurgitation with mild elevation and PA pressure. On 05/12/08, preserved left and right ventricular systolic function, aortic sclerosis with apparent mild aortic stenosis, and bi-atrial enlargement. She has previously had a Persantine Myoview nuclear rest-stress test scan completed at ABCD Medical Center in 07/06 that was negative. She has had significant mitral valve regurgitation in the past being moderate, but on the most recent echocardiogram on 05/12/08, that was not felt to be significant. She has a history of hypertension and EKGs in our office show normal sinus rhythm with frequent APCs versus wandering atrial pacemaker. She does have a history of significant hypertension in the past. She has had dizzy spells and denies clearly any true syncope. She has had bradycardia in the past from beta-blocker therapy.\"\"\"\n","]"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1gmrjqHSGcJx","colab_type":"text"},"source":["# 4. Run the pipeline"]},{"cell_type":"code","metadata":{"id":"xdhgKutMHUoC","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599820893377,"user_tz":-300,"elapsed":243922,"user":{"displayName":"Hasham Ul Haq","photoUrl":"","userId":"10508284328555930330"}}},"source":["df = spark.createDataFrame(pd.DataFrame({\"text\": input_list}))\n","result = pipeline_model.transform(df)\n","light_result = light_pipeline.fullAnnotate(input_list[0])"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UIVShVLhI68M","colab_type":"text"},"source":["# 5. Visualize"]},{"cell_type":"markdown","metadata":{"id":"472iBPpK-FvF","colab_type":"text"},"source":["helper function for visualization"]},{"cell_type":"code","metadata":{"id":"PQrKey9B-FF_","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599820893379,"user_tz":-300,"elapsed":242752,"user":{"displayName":"Hasham Ul Haq","photoUrl":"","userId":"10508284328555930330"}}},"source":["def get_relations_df (results, rel='clinical_relations'):\n","    rel_pairs=[]\n","    for rel in results[rel]:\n","        rel_pairs.append((\n","          rel.result, \n","          rel.metadata['entity1'], \n","          rel.metadata['entity1_begin'],\n","          rel.metadata['entity1_end'],\n","          rel.metadata['chunk1'], \n","          rel.metadata['entity2'],\n","          rel.metadata['entity2_begin'],\n","          rel.metadata['entity2_end'],\n","          rel.metadata['chunk2'], \n","          rel.metadata['confidence']\n","        ))\n","\n","    rel_df = pd.DataFrame(rel_pairs, columns=['relation','entity1','entity1_begin','entity1_end','chunk1','entity2','entity2_begin','entity2_end','chunk2', 'confidence'])\n","\n","    return rel_df[rel_df.relation!='O']"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qdh2BQaLI7tU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":741},"executionInfo":{"status":"ok","timestamp":1599065816463,"user_tz":-300,"elapsed":151286,"user":{"displayName":"Hasham Ul Haq","photoUrl":"","userId":"10508284328555930330"}},"outputId":"c4bfe035-53a2-4b0b-fdb9-28fe0e87b0d2"},"source":["get_relations_df(light_result[0])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>relation</th>\n","      <th>entity1</th>\n","      <th>entity1_begin</th>\n","      <th>entity1_end</th>\n","      <th>chunk1</th>\n","      <th>entity2</th>\n","      <th>entity2_begin</th>\n","      <th>entity2_end</th>\n","      <th>chunk2</th>\n","      <th>confidence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>PIP</td>\n","      <td>PROBLEM</td>\n","      <td>60</td>\n","      <td>89</td>\n","      <td>severe tricuspid regurgitation</td>\n","      <td>PROBLEM</td>\n","      <td>96</td>\n","      <td>109</td>\n","      <td>mild elevation</td>\n","      <td>0.72941315</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>TeRP</td>\n","      <td>PROBLEM</td>\n","      <td>60</td>\n","      <td>89</td>\n","      <td>severe tricuspid regurgitation</td>\n","      <td>PROBLEM</td>\n","      <td>115</td>\n","      <td>125</td>\n","      <td>PA pressure</td>\n","      <td>0.9968425</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>PIP</td>\n","      <td>PROBLEM</td>\n","      <td>96</td>\n","      <td>109</td>\n","      <td>mild elevation</td>\n","      <td>PROBLEM</td>\n","      <td>115</td>\n","      <td>125</td>\n","      <td>PA pressure</td>\n","      <td>0.9999994</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>TeRP</td>\n","      <td>PROBLEM</td>\n","      <td>197</td>\n","      <td>212</td>\n","      <td>aortic sclerosis</td>\n","      <td>PROBLEM</td>\n","      <td>219</td>\n","      <td>247</td>\n","      <td>apparent mild aortic stenosis</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>TeRP</td>\n","      <td>PROBLEM</td>\n","      <td>197</td>\n","      <td>212</td>\n","      <td>aortic sclerosis</td>\n","      <td>PROBLEM</td>\n","      <td>254</td>\n","      <td>274</td>\n","      <td>bi-atrial enlargement</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>TeRP</td>\n","      <td>PROBLEM</td>\n","      <td>219</td>\n","      <td>247</td>\n","      <td>apparent mild aortic stenosis</td>\n","      <td>PROBLEM</td>\n","      <td>254</td>\n","      <td>274</td>\n","      <td>bi-atrial enlargement</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>TeRP</td>\n","      <td>PROBLEM</td>\n","      <td>424</td>\n","      <td>461</td>\n","      <td>significant mitral valve regurgitation</td>\n","      <td>TEST</td>\n","      <td>507</td>\n","      <td>527</td>\n","      <td>recent echocardiogram</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>PIP</td>\n","      <td>PROBLEM</td>\n","      <td>600</td>\n","      <td>611</td>\n","      <td>hypertension</td>\n","      <td>TEST</td>\n","      <td>617</td>\n","      <td>620</td>\n","      <td>EKGs</td>\n","      <td>0.9999987</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>TeRP</td>\n","      <td>PROBLEM</td>\n","      <td>600</td>\n","      <td>611</td>\n","      <td>hypertension</td>\n","      <td>PROBLEM</td>\n","      <td>666</td>\n","      <td>678</td>\n","      <td>frequent APCs</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>TeRP</td>\n","      <td>PROBLEM</td>\n","      <td>600</td>\n","      <td>611</td>\n","      <td>hypertension</td>\n","      <td>PROBLEM</td>\n","      <td>687</td>\n","      <td>712</td>\n","      <td>wandering atrial pacemaker</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>TeRP</td>\n","      <td>TEST</td>\n","      <td>617</td>\n","      <td>620</td>\n","      <td>EKGs</td>\n","      <td>PROBLEM</td>\n","      <td>666</td>\n","      <td>678</td>\n","      <td>frequent APCs</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>TeRP</td>\n","      <td>TEST</td>\n","      <td>617</td>\n","      <td>620</td>\n","      <td>EKGs</td>\n","      <td>PROBLEM</td>\n","      <td>687</td>\n","      <td>712</td>\n","      <td>wandering atrial pacemaker</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>TeRP</td>\n","      <td>PROBLEM</td>\n","      <td>666</td>\n","      <td>678</td>\n","      <td>frequent APCs</td>\n","      <td>PROBLEM</td>\n","      <td>687</td>\n","      <td>712</td>\n","      <td>wandering atrial pacemaker</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>TeRP</td>\n","      <td>PROBLEM</td>\n","      <td>792</td>\n","      <td>803</td>\n","      <td>dizzy spells</td>\n","      <td>PROBLEM</td>\n","      <td>828</td>\n","      <td>839</td>\n","      <td>true syncope</td>\n","      <td>0.9999292</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   relation  entity1  ...                         chunk2  confidence\n","0       PIP  PROBLEM  ...                 mild elevation  0.72941315\n","1      TeRP  PROBLEM  ...                    PA pressure   0.9968425\n","2       PIP  PROBLEM  ...                    PA pressure   0.9999994\n","3      TeRP  PROBLEM  ...  apparent mild aortic stenosis         1.0\n","4      TeRP  PROBLEM  ...          bi-atrial enlargement         1.0\n","5      TeRP  PROBLEM  ...          bi-atrial enlargement         1.0\n","6      TeRP  PROBLEM  ...          recent echocardiogram         1.0\n","7       PIP  PROBLEM  ...                           EKGs   0.9999987\n","8      TeRP  PROBLEM  ...                  frequent APCs         1.0\n","9      TeRP  PROBLEM  ...     wandering atrial pacemaker         1.0\n","10     TeRP     TEST  ...                  frequent APCs         1.0\n","11     TeRP     TEST  ...     wandering atrial pacemaker         1.0\n","12     TeRP  PROBLEM  ...     wandering atrial pacemaker         1.0\n","13     TeRP  PROBLEM  ...                   true syncope   0.9999292\n","\n","[14 rows x 10 columns]"]},"metadata":{"tags":[]},"execution_count":10}]}]}