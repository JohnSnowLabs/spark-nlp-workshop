{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKQ4bH7qMGrA"
      },
      "source": [
        "\n",
        "\n",
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/healthcare/SMOKING_STATUS.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Colab Setup**"
      ],
      "metadata": {
        "id": "sgH-87OuO_8o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "if 'spark_jsl.json' not in os.listdir():\n",
        "  license_keys = files.upload()\n",
        "  os.rename(list(license_keys.keys())[0], 'spark_jsl.json')\n",
        "\n",
        "with open('spark_jsl.json') as f:\n",
        "    license_keys = json.load(f)\n",
        "\n",
        "# Defining license key-value pairs as local variables\n",
        "locals().update(license_keys)\n",
        "os.environ.update(license_keys)"
      ],
      "metadata": {
        "id": "1i0hJbRV5_sj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing pyspark and spark-nlp\n",
        "! pip install --upgrade -q pyspark==3.1.2 spark-nlp==$PUBLIC_VERSION\n",
        "\n",
        "# Installing Spark NLP Healthcare\n",
        "! pip install --upgrade -q spark-nlp-jsl==$JSL_VERSION  --extra-index-url https://pypi.johnsnowlabs.com/$SECRET"
      ],
      "metadata": {
        "id": "BLW9TWPL5_y6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "from pyspark.ml import Pipeline, PipelineModel\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "import sparknlp\n",
        "import sparknlp_jsl\n",
        "\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp_jsl.annotator import *\n",
        "from sparknlp.base import *\n",
        "from sparknlp.util import *\n",
        "from sparknlp.pretrained import ResourceDownloader\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "pd.set_option('display.max_columns', None)  \n",
        "pd.set_option('display.expand_frame_repr', False)\n",
        "pd.set_option('max_colwidth', None)\n",
        "\n",
        "import string\n",
        "import numpy as np\n",
        "\n",
        "params = {\"spark.driver.memory\":\"16G\",\n",
        "          \"spark.kryoserializer.buffer.max\":\"2000M\",\n",
        "          \"spark.driver.maxResultSize\":\"2000M\"}\n",
        "\n",
        "spark = sparknlp_jsl.start(secret = SECRET, params=params)\n",
        "\n",
        "print (\"Spark NLP Version :\", sparknlp.version())\n",
        "print (\"Spark NLP_JSL Version :\", sparknlp_jsl.version())\n",
        "\n",
        "spark"
      ],
      "metadata": {
        "id": "_2936n_06Jf9",
        "outputId": "0a583148-1e87-4dd9-bfc9-fab0e794b720",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP Version : 4.2.4\n",
            "Spark NLP_JSL Version : 4.2.3\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f1b2d5099a0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://6d5352376531:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark NLP Licensed</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Pipeline**"
      ],
      "metadata": {
        "id": "XMh76P5y6jP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_pipeline(ner_model_name):\n",
        "\n",
        "  documentAssembler = DocumentAssembler()\\\n",
        "      .setInputCol(\"text\")\\\n",
        "      .setOutputCol(\"document\")\n",
        "\n",
        "  sentenceDetector = SentenceDetectorDLModel.pretrained(\"sentence_detector_dl_healthcare\",\"en\",\"clinical/models\")\\\n",
        "      .setInputCols([\"document\"])\\\n",
        "      .setOutputCol(\"sentence\")\n",
        "\n",
        "  tokenizer = Tokenizer() \\\n",
        "      .setInputCols([\"sentence\"]) \\\n",
        "      .setOutputCol(\"token\")\n",
        "\n",
        "  embeddings = WordEmbeddingsModel().pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n",
        "      .setInputCols([\"sentence\", \"token\"]) \\\n",
        "      .setOutputCol(\"embeddings\")      \n",
        "\n",
        "  if ner_model_name == \"ner_jsl_enriched\":\n",
        "    ner = MedicalNerModel.pretrained(ner_model_name, \"en\", \"clinical/models\") \\\n",
        "      .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
        "      .setOutputCol(\"jsl_ner\")\n",
        "\n",
        "    ner_converter = NerConverter() \\\n",
        "        .setInputCols([\"sentence\", \"token\", \"jsl_ner\"]) \\\n",
        "        .setOutputCol(\"ner_chunk\").setWhiteList([\"Smoking_Status\", \"Smoking\"])\n",
        "      \n",
        "    assertion = AssertionDLModel.pretrained(\"assertion_oncology_smoking_status_wip\", \"en\", \"clinical/models\") \\\n",
        "        .setInputCols([\"sentence\", \"ner_chunk\", \"embeddings\"]) \\\n",
        "        .setOutputCol(\"assertion\")\n",
        "\n",
        "    \n",
        "  elif ner_model_name == \"ner_oncology\":         \n",
        "\n",
        "    ner = MedicalNerModel.pretrained(ner_model_name, \"en\", \"clinical/models\") \\\n",
        "        .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
        "        .setOutputCol(\"ner\")\n",
        "\n",
        "    ner_converter = NerConverter() \\\n",
        "        .setInputCols([\"sentence\", \"token\", \"ner\"]) \\\n",
        "        .setOutputCol(\"ner_chunk\").setWhiteList([\"Smoking_Status\", \"Smoking\"])\n",
        "        \n",
        "    assertion = AssertionDLModel.pretrained(\"assertion_oncology_smoking_status_wip\", \"en\", \"clinical/models\") \\\n",
        "        .setInputCols([\"sentence\", \"ner_chunk\", \"embeddings\"]) \\\n",
        "        .setOutputCol(\"assertion\")\n",
        "            \n",
        "\n",
        "  elif ner_model_name == \"ner_oncology_demographics\":\n",
        "\n",
        "    ner = MedicalNerModel.pretrained(ner_model_name, \"en\", \"clinical/models\") \\\n",
        "      .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
        "      .setOutputCol(\"ner\")\n",
        "\n",
        "    ner_converter = NerConverter() \\\n",
        "        .setInputCols([\"sentence\", \"token\", \"ner\"]) \\\n",
        "        .setOutputCol(\"ner_chunk\").setWhiteList([\"Smoking_Status\", \"Smoking\"])\n",
        "        \n",
        "    assertion = AssertionDLModel.pretrained(\"assertion_oncology_smoking_status_wip\", \"en\", \"clinical/models\") \\\n",
        "        .setInputCols([\"sentence\", \"ner_chunk\", \"embeddings\"]) \\\n",
        "        .setOutputCol(\"assertion\")\n",
        "\n",
        "\n",
        "\n",
        "  elif ner_model_name == \"jsl_ner_wip_clinical\":\n",
        "\n",
        "    ner = MedicalNerModel.pretrained(ner_model_name, \"en\", \"clinical/models\") \\\n",
        "        .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
        "        .setOutputCol(\"ner\")\n",
        "\n",
        "    ner_converter = NerConverter() \\\n",
        "        .setInputCols([\"sentence\", \"token\", \"ner\"]) \\\n",
        "        .setOutputCol(\"ner_chunk\").setWhiteList([\"Smoking_Status\", \"Smoking\"])\n",
        "\n",
        "    assertion = AssertionDLModel.pretrained(\"assertion_jsl_large\", \"en\", \"clinical/models\") \\\n",
        "        .setInputCols([\"sentence\", \"ner_chunk\", \"embeddings\"]) \\\n",
        "        .setOutputCol(\"assertion\")\n",
        "\n",
        "\n",
        "  elif ner_model_name == \"ner_jsl\":\n",
        "\n",
        "    ner = MedicalNerModel.pretrained(ner_model_name, \"en\", \"clinical/models\") \\\n",
        "      .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
        "      .setOutputCol(\"jsl_ner\")\n",
        "\n",
        "    ner_converter = NerConverter() \\\n",
        "        .setInputCols([\"sentence\", \"token\", \"jsl_ner\"]) \\\n",
        "        .setOutputCol(\"ner_chunk\").setWhiteList([\"Smoking_Status\", \"Smoking\"])\n",
        "      \n",
        "    assertion = AssertionDLModel.pretrained(\"assertion_oncology_smoking_status_wip\", \"en\", \"clinical/models\") \\\n",
        "        .setInputCols([\"sentence\", \"ner_chunk\", \"embeddings\"]) \\\n",
        "        .setOutputCol(\"assertion\")\n",
        "\n",
        "\n",
        "    \n",
        "  elif ner_model_name == \"jsl_ner_wip_modifier_clinical\":\n",
        "\n",
        "    ner = MedicalNerModel.pretrained(ner_model_name, \"en\", \"clinical/models\") \\\n",
        "      .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
        "      .setOutputCol(\"jsl_ner\")\n",
        "\n",
        "    ner_converter = NerConverter() \\\n",
        "        .setInputCols([\"sentence\", \"token\", \"jsl_ner\"]) \\\n",
        "        .setOutputCol(\"ner_chunk\").setWhiteList([\"Smoking_Status\", \"Smoking\"])\n",
        "\n",
        "    assertion = AssertionDLModel.pretrained(\"assertion_jsl_large\", \"en\", \"clinical/models\") \\\n",
        "        .setInputCols([\"sentence\", \"ner_chunk\", \"embeddings\"]) \\\n",
        "        .setOutputCol(\"assertion\")\n",
        "        \n",
        "\n",
        "    \n",
        "  elif ner_model_name == \"jsl_rd_ner_wip_greedy_clinical\":\n",
        "\n",
        "    ner = MedicalNerModel.pretrained(ner_model_name, \"en\", \"clinical/models\") \\\n",
        "        .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
        "        .setOutputCol(\"ner\")\n",
        "\n",
        "    ner_converter = NerConverter() \\\n",
        "        .setInputCols([\"sentence\", \"token\", \"ner\"]) \\\n",
        "        .setOutputCol(\"ner_chunk\").setWhiteList([\"Smoking_Status\", \"Smoking\"])\n",
        "\n",
        "    assertion = AssertionDLModel.pretrained(\"assertion_jsl_large\", \"en\", \"clinical/models\") \\\n",
        "        .setInputCols([\"sentence\", \"ner_chunk\", \"embeddings\"]) \\\n",
        "        .setOutputCol(\"assertion\")\n",
        "        \n",
        "  nlpPipeline = Pipeline(stages=[documentAssembler, \n",
        "                                  sentenceDetector, \n",
        "                                  tokenizer, \n",
        "                                  embeddings, \n",
        "                                  ner, \n",
        "                                  ner_converter,\n",
        "                                  assertion])\n",
        "  return nlpPipeline"
      ],
      "metadata": {
        "id": "__YUHvF06kwp"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sample Text**"
      ],
      "metadata": {
        "id": "y3askn2SPHZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Generating Example Files ##\n",
        "text_list = [\"The patient is a 40-years-old black woman with Breast Cancer. She started smoking when she was 20 years old, but she quit. Her mother died of breast cancer at age 55.\",\n",
        "\"The patient is a 60-years-old native american woman, diagnosed with liver cancer at age 58. She is a nonsmoker and has no other medical history.\",\n",
        "\"The patient is a 69 y.o. man with prostatic cancer. He was diagnosed at age 65, and he quit smoking at that time.\",\n",
        "\"She has no family history of cancer, and none in her family is a smoker.\"]"
      ],
      "metadata": {
        "id": "7QtL_SvA_Zct"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model Names**"
      ],
      "metadata": {
        "id": "GMVALjdgGo-V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `\"ner_oncology`"
      ],
      "metadata": {
        "id": "W6Jg8UteJP04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = model_pipeline(\"ner_oncology\")"
      ],
      "metadata": {
        "id": "iJZbaNb-IfbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StringType\n",
        "\n",
        "data = spark.createDataFrame(text_list, StringType()).toDF('text')\n",
        "\n",
        "result = pipeline.fit(data).transform(data)\n",
        "\n",
        "result.select(F.explode(F.arrays_zip(result.ner_chunk.result,  \n",
        "                                     result.ner_chunk.begin, \n",
        "                                     result.ner_chunk.end, \n",
        "                                     result.ner_chunk.metadata, \n",
        "                                     result.assertion.result,\n",
        "                                     result.assertion.metadata)).alias(\"cols\")) \\\n",
        "      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
        "              F.expr(\"cols['1']\").alias(\"begin\"),\n",
        "              F.expr(\"cols['2']\").alias(\"end\"),\n",
        "              F.expr(\"cols['3']['entity']\").alias(\"ner_label\"),\n",
        "              F.expr(\"cols['3']['sentence']\").alias(\"sent_id\"),\n",
        "              F.expr(\"cols['4']\").alias(\"assertion\"),\n",
        "              F.expr(\"cols['5']['confidence']\").alias(\"confidence\") ).show(truncate=False)"
      ],
      "metadata": {
        "id": "475oSaP1JxPh",
        "outputId": "1075664a-aa77-4903-d386-2faded9dc4aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----+---+--------------+-------+---------+----------+\n",
            "|chunk    |begin|end|ner_label     |sent_id|assertion|confidence|\n",
            "+---------+-----+---+--------------+-------+---------+----------+\n",
            "|smoking  |74   |80 |Smoking_Status|1      |Past     |0.9865    |\n",
            "|nonsmoker|101  |109|Smoking_Status|1      |Absent   |0.6854    |\n",
            "|smoking  |92   |98 |Smoking_Status|1      |Past     |0.9355    |\n",
            "|smoker   |65   |70 |Smoking_Status|0      |Absent   |0.9015    |\n",
            "+---------+-----+---+--------------+-------+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `ner_oncology_demographics`"
      ],
      "metadata": {
        "id": "V-WNFd_LH6jr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = model_pipeline(\"ner_oncology_demographics\")"
      ],
      "metadata": {
        "id": "KiwQfF0uH8Tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StringType\n",
        "\n",
        "data = spark.createDataFrame(text_list, StringType()).toDF('text')\n",
        "\n",
        "result = pipeline.fit(data).transform(data)\n",
        "\n",
        "result.select(F.explode(F.arrays_zip(result.ner_chunk.result,  \n",
        "                                     result.ner_chunk.begin, \n",
        "                                     result.ner_chunk.end, \n",
        "                                     result.ner_chunk.metadata, \n",
        "                                     result.assertion.result,\n",
        "                                     result.assertion.metadata)).alias(\"cols\")) \\\n",
        "      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
        "              F.expr(\"cols['1']\").alias(\"begin\"),\n",
        "              F.expr(\"cols['2']\").alias(\"end\"),\n",
        "              F.expr(\"cols['3']['entity']\").alias(\"ner_label\"),\n",
        "              F.expr(\"cols['3']['sentence']\").alias(\"sent_id\"),\n",
        "              F.expr(\"cols['4']\").alias(\"assertion\"),\n",
        "              F.expr(\"cols['5']['confidence']\").alias(\"confidence\") ).show(truncate=False)"
      ],
      "metadata": {
        "id": "FD90SXeTIAib",
        "outputId": "60fffe90-8f74-426d-8fd1-6385200eb1d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----+---+--------------+-------+---------+----------+\n",
            "|chunk    |begin|end|ner_label     |sent_id|assertion|confidence|\n",
            "+---------+-----+---+--------------+-------+---------+----------+\n",
            "|smoking  |74   |80 |Smoking_Status|1      |Past     |0.9865    |\n",
            "|nonsmoker|101  |109|Smoking_Status|1      |Absent   |0.6854    |\n",
            "|smoking  |92   |98 |Smoking_Status|1      |Past     |0.9355    |\n",
            "|smoker   |65   |70 |Smoking_Status|0      |Absent   |0.9015    |\n",
            "+---------+-----+---+--------------+-------+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `ner_jsl`"
      ],
      "metadata": {
        "id": "WiDBgbx8HHTw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = model_pipeline(\"ner_jsl\")"
      ],
      "metadata": {
        "id": "1Udajtp6G9wa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StringType\n",
        "\n",
        "data = spark.createDataFrame(text_list, StringType()).toDF('text')\n",
        "\n",
        "result = pipeline.fit(data).transform(data)\n",
        "\n",
        "result.select(F.explode(F.arrays_zip(result.ner_chunk.result,  \n",
        "                                     result.ner_chunk.begin, \n",
        "                                     result.ner_chunk.end, \n",
        "                                     result.ner_chunk.metadata, \n",
        "                                     result.assertion.result,\n",
        "                                     result.assertion.metadata)).alias(\"cols\")) \\\n",
        "      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
        "              F.expr(\"cols['1']\").alias(\"begin\"),\n",
        "              F.expr(\"cols['2']\").alias(\"end\"),\n",
        "              F.expr(\"cols['3']['entity']\").alias(\"ner_label\"),\n",
        "              F.expr(\"cols['3']['sentence']\").alias(\"sent_id\"),\n",
        "              F.expr(\"cols['4']\").alias(\"assertion\"),\n",
        "              F.expr(\"cols['5']['confidence']\").alias(\"confidence\") ).show(truncate=False)"
      ],
      "metadata": {
        "id": "inpwFIBjHMIu",
        "outputId": "549ba70d-446f-4498-dd62-b14427f696e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----+---+---------+-------+---------+----------+\n",
            "|chunk    |begin|end|ner_label|sent_id|assertion|confidence|\n",
            "+---------+-----+---+---------+-------+---------+----------+\n",
            "|smoking  |74   |80 |Smoking  |1      |Past     |0.9865    |\n",
            "|nonsmoker|101  |109|Smoking  |1      |Absent   |0.6854    |\n",
            "|smoking  |92   |98 |Smoking  |1      |Past     |0.9355    |\n",
            "|smoker   |65   |70 |Smoking  |0      |Absent   |0.9015    |\n",
            "+---------+-----+---+---------+-------+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `ner_jsl_enriched`"
      ],
      "metadata": {
        "id": "kgLbCvBMJJ_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = model_pipeline(\"ner_jsl_enriched\")"
      ],
      "metadata": {
        "id": "s2HkP6GaJTUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StringType\n",
        "\n",
        "data = spark.createDataFrame(text_list, StringType()).toDF('text')\n",
        "\n",
        "result = pipeline.fit(data).transform(data)\n",
        "\n",
        "result.select(F.explode(F.arrays_zip(result.ner_chunk.result,  \n",
        "                                     result.ner_chunk.begin, \n",
        "                                     result.ner_chunk.end, \n",
        "                                     result.ner_chunk.metadata, \n",
        "                                     result.assertion.result,\n",
        "                                     result.assertion.metadata)).alias(\"cols\")) \\\n",
        "      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
        "              F.expr(\"cols['1']\").alias(\"begin\"),\n",
        "              F.expr(\"cols['2']\").alias(\"end\"),\n",
        "              F.expr(\"cols['3']['entity']\").alias(\"ner_label\"),\n",
        "              F.expr(\"cols['3']['sentence']\").alias(\"sent_id\"),\n",
        "              F.expr(\"cols['4']\").alias(\"assertion\"),\n",
        "              F.expr(\"cols['5']['confidence']\").alias(\"confidence\") ).show(truncate=False)"
      ],
      "metadata": {
        "id": "Stkl67-vJTak",
        "outputId": "e1182a71-e621-462f-b664-056c2ef0a60f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----+---+---------+-------+---------+----------+\n",
            "|chunk    |begin|end|ner_label|sent_id|assertion|confidence|\n",
            "+---------+-----+---+---------+-------+---------+----------+\n",
            "|smoking  |74   |80 |Smoking  |1      |Past     |0.9865    |\n",
            "|nonsmoker|101  |109|Smoking  |1      |Absent   |0.6854    |\n",
            "|smoking  |92   |98 |Smoking  |1      |Past     |0.9355    |\n",
            "|smoker   |65   |70 |Smoking  |0      |Absent   |0.9015    |\n",
            "+---------+-----+---+---------+-------+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `jsl_ner_wip_clinical`"
      ],
      "metadata": {
        "id": "p_cpVvolHs-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = model_pipeline(\"jsl_ner_wip_clinical\")"
      ],
      "metadata": {
        "id": "YvygCo5IHl59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StringType\n",
        "\n",
        "data = spark.createDataFrame(text_list, StringType()).toDF('text')\n",
        "\n",
        "result = pipeline.fit(data).transform(data)\n",
        "\n",
        "result.select(F.explode(F.arrays_zip(result.ner_chunk.result,  \n",
        "                                     result.ner_chunk.begin, \n",
        "                                     result.ner_chunk.end, \n",
        "                                     result.ner_chunk.metadata, \n",
        "                                     result.assertion.result,\n",
        "                                     result.assertion.metadata)).alias(\"cols\")) \\\n",
        "      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
        "              F.expr(\"cols['1']\").alias(\"begin\"),\n",
        "              F.expr(\"cols['2']\").alias(\"end\"),\n",
        "              F.expr(\"cols['3']['entity']\").alias(\"ner_label\"),\n",
        "              F.expr(\"cols['3']['sentence']\").alias(\"sent_id\"),\n",
        "              F.expr(\"cols['4']\").alias(\"assertion\") ).show(truncate=False)"
      ],
      "metadata": {
        "id": "cyQ0493mHq2p",
        "outputId": "e895a26c-8f89-45c0-f30a-78930f09b39b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----+---+---------+-------+---------+\n",
            "|chunk    |begin|end|ner_label|sent_id|assertion|\n",
            "+---------+-----+---+---------+-------+---------+\n",
            "|smoking  |74   |80 |Smoking  |1      |past     |\n",
            "|nonsmoker|101  |109|Smoking  |1      |absent   |\n",
            "|smoking  |92   |98 |Smoking  |1      |past     |\n",
            "|smoker   |65   |70 |Smoking  |0      |absent   |\n",
            "+---------+-----+---+---------+-------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `jsl_ner_wip_modifier_clinical`"
      ],
      "metadata": {
        "id": "shIL5KUbG1Gs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = model_pipeline(\"jsl_ner_wip_modifier_clinical\")"
      ],
      "metadata": {
        "id": "bqJeZJL0GR1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StringType\n",
        "\n",
        "data = spark.createDataFrame(text_list, StringType()).toDF('text')\n",
        "\n",
        "result = pipeline.fit(data).transform(data)\n",
        "\n",
        "result.select(F.explode(F.arrays_zip(result.ner_chunk.result,  \n",
        "                                     result.ner_chunk.begin, \n",
        "                                     result.ner_chunk.end, \n",
        "                                     result.ner_chunk.metadata, \n",
        "                                     result.assertion.result,\n",
        "                                     result.assertion.metadata)).alias(\"cols\")) \\\n",
        "      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
        "              F.expr(\"cols['1']\").alias(\"begin\"),\n",
        "              F.expr(\"cols['2']\").alias(\"end\"),\n",
        "              F.expr(\"cols['3']['entity']\").alias(\"ner_label\"),\n",
        "              F.expr(\"cols['3']['sentence']\").alias(\"sent_id\"),\n",
        "              F.expr(\"cols['4']\").alias(\"assertion\") ).show(truncate=False)"
      ],
      "metadata": {
        "id": "ShX8vfwJG5Mi",
        "outputId": "bf82aa5c-13b1-4023-d627-1d132c36a53b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----+---+---------+-------+---------+\n",
            "|chunk    |begin|end|ner_label|sent_id|assertion|\n",
            "+---------+-----+---+---------+-------+---------+\n",
            "|smoking  |74   |80 |Smoking  |1      |past     |\n",
            "|nonsmoker|101  |109|Smoking  |1      |absent   |\n",
            "|smoking  |92   |98 |Smoking  |1      |past     |\n",
            "|smoker   |65   |70 |Smoking  |0      |absent   |\n",
            "+---------+-----+---+---------+-------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `jsl_rd_ner_wip_greedy_clinical`"
      ],
      "metadata": {
        "id": "nZ6e9MGbGi9p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = model_pipeline(\"jsl_rd_ner_wip_greedy_clinical\")"
      ],
      "metadata": {
        "id": "XgP0y5Dw-5ER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StringType\n",
        "\n",
        "data = spark.createDataFrame(text_list, StringType()).toDF('text')\n",
        "\n",
        "result = pipeline.fit(data).transform(data)\n",
        "\n",
        "result.select(F.explode(F.arrays_zip(result.ner_chunk.result,  \n",
        "                                     result.ner_chunk.begin, \n",
        "                                     result.ner_chunk.end, \n",
        "                                     result.ner_chunk.metadata, \n",
        "                                     result.assertion.result,\n",
        "                                     result.assertion.metadata)).alias(\"cols\")) \\\n",
        "      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
        "              F.expr(\"cols['1']\").alias(\"begin\"),\n",
        "              F.expr(\"cols['2']\").alias(\"end\"),\n",
        "              F.expr(\"cols['3']['entity']\").alias(\"ner_label\"),\n",
        "              F.expr(\"cols['3']['sentence']\").alias(\"sent_id\"),\n",
        "              F.expr(\"cols['4']\").alias(\"assertion\") ).show(truncate=False)"
      ],
      "metadata": {
        "id": "C2X_BHHL_dzd",
        "outputId": "d935ae6b-8877-49bf-ebfd-169a5668a9d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----+---+---------+-------+---------+\n",
            "|chunk    |begin|end|ner_label|sent_id|assertion|\n",
            "+---------+-----+---+---------+-------+---------+\n",
            "|smoking  |74   |80 |Smoking  |1      |past     |\n",
            "|nonsmoker|101  |109|Smoking  |1      |absent   |\n",
            "|smoking  |92   |98 |Smoking  |1      |past     |\n",
            "|smoker   |65   |70 |Smoking  |0      |absent   |\n",
            "+---------+-----+---+---------+-------+---------+\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}