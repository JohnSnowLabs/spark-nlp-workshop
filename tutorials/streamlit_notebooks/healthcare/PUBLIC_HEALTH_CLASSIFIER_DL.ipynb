{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/healthcare/PUBLIC_HEALTH_CLASSIFIER_DL.ipynb)"
      ],
      "metadata": {
        "id": "owDE4m_FyfJV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Colab Setup**"
      ],
      "metadata": {
        "id": "LJRtUrApybYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "license_keys = files.upload()\n",
        "\n",
        "with open(list(license_keys.keys())[0]) as f:\n",
        "    license_keys = json.load(f)\n",
        "\n",
        "# Defining license key-value pairs as local variables\n",
        "locals().update(license_keys)\n",
        "\n",
        "# Adding license key-value pairs to environment variables\n",
        "os.environ.update(license_keys)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "JDrQQLJHycAH",
        "outputId": "50a6ffba-3bde-4361-85d2-7f10c1127143"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e2780bed-f297-4c79-867a-c5f2f6e0d478\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e2780bed-f297-4c79-867a-c5f2f6e0d478\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 4.0.2.spark_nlp_for_healthcare.json to 4.0.2.spark_nlp_for_healthcare.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Install dependencies**"
      ],
      "metadata": {
        "id": "yhppYdqEyjcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing pyspark and spark-nlp\n",
        "! pip install --upgrade -q pyspark==3.1.2 spark-nlp==$PUBLIC_VERSION\n",
        "\n",
        "# Installing Spark NLP Healthcare\n",
        "! pip install --upgrade -q spark-nlp-jsl==$JSL_VERSION  --extra-index-url https://pypi.johnsnowlabs.com/$SECRET\n",
        "\n",
        "# Installing Spark NLP Display Library for visualization\n",
        "! pip install -q spark-nlp-display"
      ],
      "metadata": {
        "id": "vhLNO5TByj4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import dependencies into Python and start the Spark session**"
      ],
      "metadata": {
        "id": "xrydYR6j0cWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "import sparknlp\n",
        "import sparknlp_jsl\n",
        "\n",
        "from sparknlp.base import *\n",
        "from sparknlp.util import *\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp_jsl.annotator import *\n",
        "from sparknlp.pretrained import ResourceDownloader\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.types import StringType, IntegerType\n",
        "from pyspark.ml import Pipeline, PipelineModel\n",
        "\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', None)  \n",
        "pd.set_option('display.expand_frame_repr', False)\n",
        "pd.set_option('max_colwidth', None)\n",
        "\n",
        "import string\n",
        "import numpy as np\n",
        "\n",
        "params = {\"spark.driver.memory\":\"16G\",\n",
        "          \"spark.kryoserializer.buffer.max\":\"2000M\",\n",
        "          \"spark.driver.maxResultSize\":\"2000M\"}\n",
        "\n",
        "spark = sparknlp_jsl.start(secret = SECRET, params=params)\n",
        "\n",
        "print (\"Spark NLP Version :\", sparknlp.version())\n",
        "print (\"Spark NLP_JSL Version :\", sparknlp_jsl.version())\n",
        "\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "V4nSTI3N0aed",
        "outputId": "1ac37c77-dd43-45e0-9d7f-c1f3924f6ad2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP Version : 4.0.2\n",
            "Spark NLP_JSL Version : 4.0.2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f55ad22cb90>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://5b34a986149b:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark NLP Licensed</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MODELS**"
      ],
      "metadata": {
        "id": "Xx9px1JN0uwp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **classifierdl_vaccine_sentiment**"
      ],
      "metadata": {
        "id": "qJIdjEh30zmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_pipeline(model, text, lang = 'en'):  \n",
        "  document_assembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"text\") \\\n",
        "    .setOutputCol(\"sentence\")\n",
        "\n",
        "  tokenizer = Tokenizer() \\\n",
        "    .setInputCols([\"sentence\"]) \\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "  bert_embeddings = BertEmbeddings.pretrained(\"bert_embeddings_phs_bert\", \"en\", \"public/models\")\\\n",
        "    .setInputCols([\"sentence\", \"token\"])\\\n",
        "    .setOutputCol(\"embeddings\")\\\n",
        "\n",
        "  embeddingsSentence = SentenceEmbeddings() \\\n",
        "    .setInputCols([\"sentence\", \"embeddings\"]) \\\n",
        "    .setOutputCol(\"sentence_embeddings\") \\\n",
        "    .setPoolingStrategy(\"AVERAGE\")\n",
        "\n",
        "  classifierdl = ClassifierDLModel.pretrained(model, \"en\", \"clinical/models\")\\\n",
        "    .setInputCols(['sentence', 'token', 'sentence_embeddings'])\\\n",
        "    .setOutputCol('class')\n",
        "\n",
        "  pipeline = Pipeline(\n",
        "    stages = [\n",
        "        document_assembler,\n",
        "        tokenizer,\n",
        "        bert_embeddings,\n",
        "        embeddingsSentence,\n",
        "        classifierdl\n",
        "    ])\n",
        "\n",
        "  df = spark.createDataFrame(text, StringType()).toDF(\"text\")\n",
        "  results = pipeline.fit(df).transform(df)\n",
        "   \n",
        "  print(\"\\n\")\n",
        "  print(\"<----------------- MODEL NAME:\",\"\\033[1m\" + model + \"\\033[0m\",\" ----------------- >\")\n",
        "  \n",
        "  res = results.select( F.explode(F.arrays_zip(\"sentence.result\", \n",
        "                                               \"class.result\",\n",
        "                                               \"class.metadata\")).alias(\"col\"))\\\n",
        "               .select( F.expr(\"col['1']\").alias(\"prediction\"),\n",
        "                        F.expr(\"col['2']\").alias(\"confidence\"),\n",
        "                        F.expr(\"col['0']\").alias(\"sentence\"))\n",
        "  if res.count()>1:\n",
        "    udf_func = F.udf(lambda x,y:  x[str(y)])\n",
        "    print(\"\\n\",model,\"\\n\") \n",
        "    res.withColumn('confidence', udf_func(res.confidence, res.prediction)).show(truncate=False)\n"
      ],
      "metadata": {
        "id": "DvmL5nr10vXA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = \"classifierdl_vaccine_sentiment\""
      ],
      "metadata": {
        "id": "7OseGP4H03xH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_texts = [\"\"\" Perhaps when there s a  COVID 19 vaccine in the coming months  or years , it can help countries like   Pakistan increase national immunization stats if routine immunization is coupled with the virus jab drops.   Should the state, however, make vaccination a mandatory citizenship duty. \"\"\",\n",
        "\"\"\" Today  I received my second dose of the  COVID 19 vaccine. When it becomes available to you, don t wait   get vaccinated.  It s safe, easy, and it saves lives. \"\"\",\n",
        "\"\"\" I got my mom scheduled for the   Covid 19 vaccine.  A great relief to me, to be honest. \"\"\",\n",
        "\"\"\" It feels really exciting to have a personal connection to the province s vaccine numbers.   My step dad s 92 year old mother got her first dose yesterday.\"\"\",\n",
        "\"\"\" The current oxford vaccine is based off the work they did on the non mild coronavirus forms of  SARS and  MERS.   But since they were contained, the urgency to continue the work was reduced until  COVID 19. \"\"\",\n",
        "\"\"\" Got the covid vaccine tonight.... so far side effects for me. Super weak  exhausted. Injection site and arm hurts  AF Feel like  I smoked a fat. Other than that... feeling like a million bucks for doing my part. \"\"\"]"
      ],
      "metadata": {
        "id": "MeUBY0NU03z-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_pipeline(model, sample_texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXRS6RxO06jK",
        "outputId": "ca728606-3f97-420e-c3d8-c4c26f5e3de8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_embeddings_phs_bert download started this may take some time.\n",
            "Approximate size to download 1.2 GB\n",
            "[OK!]\n",
            "classifierdl_vaccine_sentiment download started this may take some time.\n",
            "Approximate size to download 23.1 MB\n",
            "[OK!]\n",
            "\n",
            "\n",
            "<----------------- MODEL NAME: \u001b[1mclassifierdl_vaccine_sentiment\u001b[0m  ----------------- >\n",
            "\n",
            " classifierdl_vaccine_sentiment \n",
            "\n",
            "+----------+----------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|prediction|confidence|sentence                                                                                                                                                                                                                                                                                       |\n",
            "+----------+----------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|positive  |0.8198555 | Perhaps when there s a  COVID 19 vaccine in the coming months  or years , it can help countries like   Pakistan increase national immunization stats if routine immunization is coupled with the virus jab drops.   Should the state, however, make vaccination a mandatory citizenship duty. |\n",
            "|positive  |0.9995857 | Today  I received my second dose of the  COVID 19 vaccine. When it becomes available to you, don t wait   get vaccinated.  It s safe, easy, and it saves lives.                                                                                                                               |\n",
            "|positive  |0.9999976 | I got my mom scheduled for the   Covid 19 vaccine.  A great relief to me, to be honest.                                                                                                                                                                                                       |\n",
            "|positive  |0.9999896 | It feels really exciting to have a personal connection to the province s vaccine numbers.   My step dad s 92 year old mother got her first dose yesterday.                                                                                                                                    |\n",
            "|neutral   |0.46951422| The current oxford vaccine is based off the work they did on the non mild coronavirus forms of  SARS and  MERS.   But since they were contained, the urgency to continue the work was reduced until  COVID 19.                                                                                |\n",
            "|negative  |0.99580634| Got the covid vaccine tonight.... so far side effects for me. Super weak  exhausted. Injection site and arm hurts  AF Feel like  I smoked a fat. Other than that... feeling like a million bucks for doing my part.                                                                           |\n",
            "+----------+----------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **classifierdl_health_mentions**"
      ],
      "metadata": {
        "id": "wl_LKWin1JXt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = \"classifierdl_health_mentions\""
      ],
      "metadata": {
        "id": "nEqWZVFP1J7P"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_texts = [\n",
        "\"\"\"Got sumatriptan for this week long migraine  I thought these were over as a kid  but I guess not  Thought I could just baby it a couple days with water and pedialyte and excedrin  Nope    Why am I so stubborn about continuing to  DO THINGA when I m obviously not well\"\"\",\n",
        "\"\"\"That Thunder trade alert just now from  almost gave me a heart attack  Was bracing myself to see THUNDER SENDS RUSS TO Wow That was the briefest emotional roller coaster ever\"\"\",\n",
        "\"\"\"The sickle cell clinic of  still goes on  It is even more for the next 2 months  Ever heard of childhood stroke  One of the leading causes of childhood stroke is sickle cell  Amidst cancer and other\"\"\",\n",
        "\"\"\"In 2015 I suffered a stroke  This prevented me from playing Rugby League again  It was difficult physically and mentally to recover from  bit four years later  here I am  about to embark on this   Read my story and please donate if you can\"\"\",\n",
        "\"\"\"i respect the fuck out of the lesbian who was in the bar bathroom  one holer  directly before me and dropped a gnarly rank dookie like make a raccoon cough type shit\"\"\",  \n",
        "\"\"\"Many of us have witnessed the sad  steady march of Alzheimer s disease as it destroys memory and thinking ability  But what about the physical effects of Alzheimer s which also are significant  but which we tend not to think about as much\"\"\"\n",
        "]"
      ],
      "metadata": {
        "id": "W6T52qw-2EVP"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_pipeline(model, sample_texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmIqsTBv1Wd0",
        "outputId": "37b99ad8-26b2-415c-e334-a9c2566e46a0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_embeddings_phs_bert download started this may take some time.\n",
            "Approximate size to download 1.2 GB\n",
            "[OK!]\n",
            "classifierdl_health_mentions download started this may take some time.\n",
            "Approximate size to download 22.9 MB\n",
            "[OK!]\n",
            "\n",
            "\n",
            "<----------------- MODEL NAME: \u001b[1mclassifierdl_health_mentions\u001b[0m  ----------------- >\n",
            "\n",
            " classifierdl_health_mentions \n",
            "\n",
            "+------------------+----------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|prediction        |confidence|sentence                                                                                                                                                                                                                                                                   |\n",
            "+------------------+----------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|health_mention    |0.999987  |Got sumatriptan for this week long migraine  I thought these were over as a kid  but I guess not  Thought I could just baby it a couple days with water and pedialyte and excedrin  Nope    Why am I so stubborn about continuing to  DO THINGA when I m obviously not well|\n",
            "|figurative_mention|0.9999999 |That Thunder trade alert just now from  almost gave me a heart attack  Was bracing myself to see THUNDER SENDS RUSS TO Wow That was the briefest emotional roller coaster ever                                                                                             |\n",
            "|other_mention     |0.9992162 |The sickle cell clinic of  still goes on  It is even more for the next 2 months  Ever heard of childhood stroke  One of the leading causes of childhood stroke is sickle cell  Amidst cancer and other                                                                     |\n",
            "|health_mention    |0.9999814 |In 2015 I suffered a stroke  This prevented me from playing Rugby League again  It was difficult physically and mentally to recover from  bit four years later  here I am  about to embark on this   Read my story and please donate if you can                            |\n",
            "|figurative_mention|0.60502684|i respect the fuck out of the lesbian who was in the bar bathroom  one holer  directly before me and dropped a gnarly rank dookie like make a raccoon cough type shit                                                                                                      |\n",
            "|other_mention     |0.99998915|Many of us have witnessed the sad  steady march of Alzheimer s disease as it destroys memory and thinking ability  But what about the physical effects of Alzheimer s which also are significant  but which we tend not to think about as much                             |\n",
            "+------------------+----------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P4g0HTN61aWa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}