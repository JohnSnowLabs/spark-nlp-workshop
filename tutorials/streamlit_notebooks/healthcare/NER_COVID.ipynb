{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TA21Jo5d9SVq"
      },
      "source": [
        "\n",
        "\n",
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/healthcare/NER_COVID.ipynb)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzIdjHkAW8TB"
      },
      "source": [
        "# **Extract entities in covid trials**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uDmeHEFW7_h"
      },
      "source": [
        "To run this yourself, you will need to upload your license keys to the notebook. Just Run The Cell Below in order to do that. Also You can open the file explorer on the left side of the screen and upload `license_keys.json` to the folder that opens.\n",
        "Otherwise, you can look at the example outputs at the bottom of the notebook.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIeCOiJNW-88"
      },
      "source": [
        "## 1. Colab Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMIDv74CYN0d"
      },
      "source": [
        "**Import license keys**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttHPIV2JXbIM"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "license_keys = files.upload()\n",
        "\n",
        "with open(list(license_keys.keys())[0]) as f:\n",
        "    license_keys = json.load(f)\n",
        "\n",
        "# Defining license key-value pairs as local variables\n",
        "locals().update(license_keys)\n",
        "\n",
        "# Adding license key-value pairs to environment variables\n",
        "os.environ.update(license_keys)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQtc1CHaYQjU"
      },
      "source": [
        "## 2. Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGJktFHdHL1n"
      },
      "outputs": [],
      "source": [
        "# Installing pyspark and spark-nlp\n",
        "! pip install --upgrade -q pyspark==3.1.2 spark-nlp==$PUBLIC_VERSION\n",
        "\n",
        "# Installing Spark NLP Healthcare\n",
        "! pip install --upgrade -q spark-nlp-jsl==$JSL_VERSION  --extra-index-url https://pypi.johnsnowlabs.com/$SECRET\n",
        "\n",
        "# Installing Spark NLP Display Library for visualization\n",
        "! pip install -q spark-nlp-display"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hj5FRDV4YSXN"
      },
      "source": [
        "**Import dependencies into Python and start the Spark session**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "sw-t1zxlHTB7",
        "outputId": "c25067e5-96cd-40be-9a60-886637b9bd6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Spark NLP Version : 3.4.4\n",
            "Spark NLP_JSL Version : 3.5.2\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://7f9b0a272be1:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark NLP Licensed</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f817197ce10>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Import sparknlp & sparknlp_jsl packages\n",
        "import sparknlp\n",
        "import sparknlp_jsl\n",
        "\n",
        "from sparknlp.base import *\n",
        "from sparknlp.common import *\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp_jsl.annotator import *\n",
        "\n",
        "# Import Pyspark packages\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F \n",
        "from pyspark.ml import Pipeline, PipelineModel\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "\n",
        "spark = sparknlp_jsl.start(license_keys['SECRET'])\n",
        "\n",
        "print (\"Spark NLP Version :\", sparknlp.version())\n",
        "print (\"Spark NLP_JSL Version :\", sparknlp_jsl.version())\n",
        "\n",
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RgiqfX5XDqb"
      },
      "source": [
        "## 3. Select the NER model and construct the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y48aZkoSAZTY"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = \"ner_covid_trials\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zweiG2ilZqoR"
      },
      "source": [
        "**Create the pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLuDz_t40be4",
        "outputId": "1677c3ab-123d-41b2-cdcc-6e8bfd370989"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "embeddings_clinical download started this may take some time.\n",
            "Approximate size to download 1.6 GB\n",
            "[OK!]\n",
            "ner_covid_trials download started this may take some time.\n",
            "[OK!]\n"
          ]
        }
      ],
      "source": [
        "document_assembler = DocumentAssembler() \\\n",
        "    .setInputCol('text')\\\n",
        "    .setOutputCol('document')\n",
        "\n",
        "sentence_detector = SentenceDetector() \\\n",
        "    .setInputCols(['document'])\\\n",
        "    .setOutputCol('sentence')\n",
        "\n",
        "tokenizer = Tokenizer()\\\n",
        "    .setInputCols(['sentence']) \\\n",
        "    .setOutputCol('token')\n",
        "\n",
        "word_embeddings = WordEmbeddingsModel.pretrained('embeddings_clinical', 'en', 'clinical/models') \\\n",
        "    .setInputCols(['sentence', 'token']) \\\n",
        "    .setOutputCol('embeddings')\n",
        "\n",
        "clinical_ner = MedicalNerModel.pretrained(MODEL_NAME, \"en\", \"clinical/models\") \\\n",
        "    .setInputCols([\"sentence\", \"token\", \"embeddings\"])\\\n",
        "    .setOutputCol(\"ner\")\n",
        "\n",
        "ner_converter = NerConverter()\\\n",
        "    .setInputCols(['sentence', 'token', 'ner']) \\\n",
        "    .setOutputCol('ner_chunk')\n",
        "\n",
        "nlp_pipeline = Pipeline(stages=[\n",
        "    document_assembler, \n",
        "    sentence_detector,\n",
        "    tokenizer,\n",
        "    word_embeddings,\n",
        "    clinical_ner,\n",
        "    ner_converter\n",
        "    ])\n",
        "\n",
        "empty_df = spark.createDataFrame([['']]).toDF('text')\n",
        "pipeline_model = nlp_pipeline.fit(empty_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Y9GpdJhXIpD"
      },
      "source": [
        "## 4. Create example inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBOKkB2THdGI"
      },
      "outputs": [],
      "source": [
        "sample_text = [\"\"\"In December 2019 , a group of patients with the acute respiratory disease was detected in Wuhan , Hubei Province of China . A month later , a new beta-coronavirus was identified as the cause of the 2019 coronavirus infection . SARS-CoV-2 is a coronavirus that belongs to the group of Î²-coronaviruses of the subgenus Coronaviridae . The SARS-CoV-2 is the third known zoonotic coronavirus disease after severe acute respiratory syndrome ( SARS ) and Middle Eastern respiratory syndrome ( MERS ). The diagnosis of SARS-CoV-2 recommended by the WHO , CDC is the collection of a sample from the upper respiratory tract ( nasal and oropharyngeal exudate ) or from the lower respiratory tract such as expectoration of endotracheal aspirate and bronchioloalveolar lavage and its analysis using the test of real-time polymerase chain reaction ( qRT-PCR ).\"\"\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv0abcwhXWC-"
      },
      "source": [
        "## 5. Use the pipeline to create outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TK1DB9JZaPs3",
        "outputId": "c887b84d-d7f9-4301-c883-8ef50a756d24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------------------------------+-------------------------+\n",
            "|chunk                              |ner_label                |\n",
            "+-----------------------------------+-------------------------+\n",
            "|December 2019                      |Date                     |\n",
            "|acute respiratory disease          |Disease_Syndrome_Disorder|\n",
            "|beta-coronavirus                   |Virus                    |\n",
            "|2019 coronavirus infection         |Disease_Syndrome_Disorder|\n",
            "|SARS-CoV-2                         |Virus                    |\n",
            "|coronavirus                        |Virus                    |\n",
            "|Î²-coronaviruses                    |Virus                    |\n",
            "|subgenus Coronaviridae             |Virus                    |\n",
            "|SARS-CoV-2                         |Virus                    |\n",
            "|zoonotic coronavirus disease       |Disease_Syndrome_Disorder|\n",
            "|severe acute respiratory syndrome  |Disease_Syndrome_Disorder|\n",
            "|SARS                               |Disease_Syndrome_Disorder|\n",
            "|Middle Eastern respiratory syndrome|Disease_Syndrome_Disorder|\n",
            "|MERS                               |Disease_Syndrome_Disorder|\n",
            "|SARS-CoV-2                         |Virus                    |\n",
            "|WHO                                |Institution              |\n",
            "|CDC                                |Institution              |\n",
            "+-----------------------------------+-------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = spark.createDataFrame(pd.DataFrame({'text': sample_text}))\n",
        "\n",
        "result = pipeline_model.transform(df)\n",
        "\n",
        "result.select(F.explode(F.arrays_zip(result.ner_chunk.result, \n",
        "                                     result.ner_chunk.metadata)).alias(\"cols\"))\\\n",
        "      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
        "              F.expr(\"cols['1']['entity']\").alias(\"ner_label\")).show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQY8tAP6XZJL"
      },
      "source": [
        "## 6. Visualize results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "Ar32BZu7J79X",
        "outputId": "5f7c8923-7522-4e95-8bda-0f60a3abb96b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    @import url('https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700&display=swap');\n",
              "    @import url('https://fonts.googleapis.com/css2?family=Vistol Regular:wght@300;400;500;600;700&display=swap');\n",
              "    \n",
              "    .spark-nlp-display-scroll-entities {\n",
              "        border: 1px solid #E7EDF0;\n",
              "        border-radius: 3px;\n",
              "        text-align: justify;\n",
              "        \n",
              "    }\n",
              "    .spark-nlp-display-scroll-entities span {  \n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        color: #536B76;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "    }\n",
              "    \n",
              "    .spark-nlp-display-entity-wrapper{\n",
              "    \n",
              "        display: inline-grid;\n",
              "        text-align: center;\n",
              "        border-radius: 4px;\n",
              "        margin: 0 2px 5px 2px;\n",
              "        padding: 1px\n",
              "    }\n",
              "    .spark-nlp-display-entity-name{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "        \n",
              "        background: #f1f2f3;\n",
              "        border-width: medium;\n",
              "        text-align: center;\n",
              "        \n",
              "        font-weight: 400;\n",
              "        \n",
              "        border-radius: 5px;\n",
              "        padding: 2px 5px;\n",
              "        display: block;\n",
              "        margin: 3px 2px;\n",
              "    \n",
              "    }\n",
              "    .spark-nlp-display-entity-type{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        color: #ffffff;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "        \n",
              "        text-transform: uppercase;\n",
              "        \n",
              "        font-weight: 500;\n",
              "\n",
              "        display: block;\n",
              "        padding: 3px 5px;\n",
              "    }\n",
              "    \n",
              "    .spark-nlp-display-entity-resolution{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        color: #ffffff;\n",
              "        font-family: 'Vistol Regular', sans-serif !important;\n",
              "        \n",
              "        text-transform: uppercase;\n",
              "        \n",
              "        font-weight: 500;\n",
              "\n",
              "        display: block;\n",
              "        padding: 3px 5px;\n",
              "    }\n",
              "    \n",
              "    .spark-nlp-display-others{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "        \n",
              "        font-weight: 400;\n",
              "    }\n",
              "\n",
              "</style>\n",
              " <span class=\"spark-nlp-display-others\" style=\"background-color: white\">In </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #a6b1e1\"><span class=\"spark-nlp-display-entity-name\">December 2019 </span><span class=\"spark-nlp-display-entity-type\">Date</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> , a group of patients with the </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #469802\"><span class=\"spark-nlp-display-entity-name\">acute respiratory disease </span><span class=\"spark-nlp-display-entity-type\">Disease_Syndrome_Disorder</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> was detected in Wuhan , Hubei Province of China . A month later , a new </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #B55C68\"><span class=\"spark-nlp-display-entity-name\">beta-coronavirus </span><span class=\"spark-nlp-display-entity-type\">Virus</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> was identified as the cause of the </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #469802\"><span class=\"spark-nlp-display-entity-name\">2019 coronavirus infection </span><span class=\"spark-nlp-display-entity-type\">Disease_Syndrome_Disorder</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> . </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #B55C68\"><span class=\"spark-nlp-display-entity-name\">SARS-CoV-2 </span><span class=\"spark-nlp-display-entity-type\">Virus</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> is a </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #B55C68\"><span class=\"spark-nlp-display-entity-name\">coronavirus </span><span class=\"spark-nlp-display-entity-type\">Virus</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> that belongs to the group of </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #B55C68\"><span class=\"spark-nlp-display-entity-name\">Î²-coronaviruses </span><span class=\"spark-nlp-display-entity-type\">Virus</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> of the </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #B55C68\"><span class=\"spark-nlp-display-entity-name\">subgenus Coronaviridae </span><span class=\"spark-nlp-display-entity-type\">Virus</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> . The </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #B55C68\"><span class=\"spark-nlp-display-entity-name\">SARS-CoV-2 </span><span class=\"spark-nlp-display-entity-type\">Virus</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> is the third known </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #469802\"><span class=\"spark-nlp-display-entity-name\">zoonotic coronavirus disease </span><span class=\"spark-nlp-display-entity-type\">Disease_Syndrome_Disorder</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> after </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #469802\"><span class=\"spark-nlp-display-entity-name\">severe acute respiratory syndrome </span><span class=\"spark-nlp-display-entity-type\">Disease_Syndrome_Disorder</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> ( </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #469802\"><span class=\"spark-nlp-display-entity-name\">SARS </span><span class=\"spark-nlp-display-entity-type\">Disease_Syndrome_Disorder</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> ) and </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #469802\"><span class=\"spark-nlp-display-entity-name\">Middle Eastern respiratory syndrome </span><span class=\"spark-nlp-display-entity-type\">Disease_Syndrome_Disorder</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> ( </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #469802\"><span class=\"spark-nlp-display-entity-name\">MERS </span><span class=\"spark-nlp-display-entity-type\">Disease_Syndrome_Disorder</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> ). The diagnosis of </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #B55C68\"><span class=\"spark-nlp-display-entity-name\">SARS-CoV-2 </span><span class=\"spark-nlp-display-entity-type\">Virus</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> recommended by the </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #4B7D62\"><span class=\"spark-nlp-display-entity-name\">WHO </span><span class=\"spark-nlp-display-entity-type\">Institution</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> , </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #4B7D62\"><span class=\"spark-nlp-display-entity-name\">CDC </span><span class=\"spark-nlp-display-entity-type\">Institution</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> is the collection of a sample from the upper respiratory tract ( nasal and oropharyngeal exudate ) or from the lower respiratory tract such as expectoration of endotracheal aspirate and bronchioloalveolar lavage and its analysis using the test of real-time polymerase chain reaction ( qRT-PCR ).</span></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sparknlp_display import NerVisualizer\n",
        "\n",
        "NerVisualizer().display(\n",
        "    result = result.collect()[0],\n",
        "    label_col = 'ner_chunk',\n",
        "    document_col = 'document'\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "NER_COVID_TRIALS.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
