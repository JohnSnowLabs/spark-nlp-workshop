{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER_LEGAL_PT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.9 64-bit"
    },
    "interpreter": {
      "hash": "44bdf782dfb35bc944f62c89ae2fce17412c01fe36b97164db622aba68bb836b"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TA21Jo5d9SVq"
      },
      "source": [
        "\n",
        "\n",
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_PT.ipynb)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzIdjHkAW8TB"
      },
      "source": [
        "# **Detect legal entities in Portuguese text**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIeCOiJNW-88"
      },
      "source": [
        "## 1. Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2JGGTdMdovR"
      },
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "license_keys = files.upload()\n",
        "\n",
        "with open(list(license_keys.keys())[0]) as f:\n",
        "    license_keys = json.load(f)\n",
        "\n",
        "sparknlp_version = license_keys[\"PUBLIC_VERSION\"]\n",
        "jsl_version = license_keys[\"JSL_VERSION\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMaVR-rnldBM",
        "outputId": "3fa03fea-d6b7-45f6-b460-ac6fb3eec364"
      },
      "source": [
        "print ('SparkNLP Version:', sparknlp_version)\n",
        "print ('SparkNLP-JSL Version:', jsl_version)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SparkNLP Version: 3.1.2\n",
            "SparkNLP-JSL Version: 3.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAowjxBjd9Dt"
      },
      "source": [
        "Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGJktFHdHL1n"
      },
      "source": [
        "%%capture\n",
        "for k,v in license_keys.items(): \n",
        "    %set_env $k=$v\n",
        "\n",
        "!wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/jsl_colab_setup.sh\n",
        "!bash jsl_colab_setup.sh\n",
        "\n",
        "# Install Spark NLP Display for visualization\n",
        "!pip install --ignore-installed spark-nlp-display"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCIT5VLxS3I1"
      },
      "source": [
        "## 2. Start the Spark session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sw-t1zxlHTB7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "2bcc653a-3b64-4ab9-8be9-62d2f764e437"
      },
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "import sparknlp\n",
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "\n",
        "import sparknlp_jsl\n",
        "from sparknlp_jsl.annotator import *\n",
        "\n",
        "spark = sparknlp_jsl.start(license_keys['SECRET'])\n",
        "\n",
        "spark"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://4daac011011c:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark NLP Licensed</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fb27dfaca10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RgiqfX5XDqb"
      },
      "source": [
        "## 3. Select the DL model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLuDz_t40be4"
      },
      "source": [
        "# If you change the model, re-run all the cells below.\n",
        "# Applicable models: lener_bert_base, lener_bert_large\n",
        "MODEL_NAME = \"lener_bert_base\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Y9GpdJhXIpD"
      },
      "source": [
        "## 4. Some sample examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBOKkB2THdGI"
      },
      "source": [
        "# Enter examples to be transformed as strings in this list\n",
        "text_list = [\n",
        "    \"\"\"a primeira câmara desta corte , em acórdão constante da relação 31/2000 , ata 27/2000 , ministro marcos vinicios vilaça , julgou regulares com ressalva as contas de carlos aureliano motta de souza , ex-diretor-geral do stm , no ano de 1999 ( peça 1 , p. 49-51 ) .\"\"\",\n",
        "    \"\"\"com isso , a corte , por meio da decisão 877/2000 – plenário , manifestou-se nos seguintes termos : 8.1 - determinar à secex/rj que , com base nos artigos 41 e 43 , inciso ii , da lei nº 8.443/92 : 8.1.1 - promova a audiência do responsável acima identificado , para que , no prazo regimental , apresente razões de justificativa quanto a ocorrência de antecipações de pagamentos para fornecimento de esquadrias de alumínio , ar-condicionado e elevadores da obra de construção do edifício da 1ª cjm/rj , em afronta aos artigos 62 e 63 da lei nº 4.320/64 ; 38 do decreto nº 93.872/86 ; e 65 , inciso ii , letra `` c '' , da lei nº 8.666/93 , bem como quanto às alterações contratuais .\"\"\"\n",
        "]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XftYgju4XOw_"
      },
      "source": [
        "## 5. Define Spark NLP pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBggF5P8J1gc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10cf5a7c-06e8-4b81-fc14-34a42c04ad27"
      },
      "source": [
        "document_assembler = DocumentAssembler() \\\n",
        "    .setInputCol('text') \\\n",
        "    .setOutputCol('document')\n",
        "\n",
        "tokenizer = Tokenizer() \\\n",
        "    .setInputCols(['document']) \\\n",
        "    .setOutputCol('token')\n",
        "\n",
        "# The model was trained with the Bert embeddings, we need to it.",
        "if MODEL_NAME == 'lener_bert_base':",
        "    bert_model = 'bert_portuguese_base_cased'",
        "else:",
        "    bert_model = 'bert_portuguese_large_cased'",
        "\n",
        "embeddings = BertEmbeddings.pretrained(bert_model, 'pt')\\\n",
        "    .setInputCols(\"document\", \"token\") \\\n",
        "    .setOutputCol(\"embeddings\")\n",
        "\n",
        "ner_model = MedicalNerModel.pretrained(MODEL_NAME, 'pt', 'clinical/models') \\\n",
        "    .setInputCols(['document', 'token', 'embeddings']) \\\n",
        "    .setOutputCol('ner')\n",
        "\n",
        "ner_converter = NerConverter() \\\n",
        "    .setInputCols(['document', 'token', 'ner']) \\\n",
        "    .setOutputCol('ner_chunk')\n",
        "\n",
        "nlp_pipeline = Pipeline(stages=[\n",
        "    document_assembler, \n",
        "    tokenizer,\n",
        "    embeddings,\n",
        "    ner_model,\n",
        "    ner_converter\n",
        "])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bert_portuguese_base_cased download started this may take some time.\n",
            "Approximate size to download 389.1 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv0abcwhXWC-"
      },
      "source": [
        "## 6. Run the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYf_9sXDXR4t"
      },
      "source": [
        "empty_df = spark.createDataFrame([['']]).toDF('text')\n",
        "pipeline_model = nlp_pipeline.fit(empty_df)\n",
        "df = spark.createDataFrame(pd.DataFrame({'text': text_list}))\n",
        "result = pipeline_model.transform(df)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQY8tAP6XZJL"
      },
      "source": [
        "## 7. Visualize results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ar32BZu7J79X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "bc5b9b05-22c5-4c19-f7d7-d9e3b4c3d921"
      },
      "source": [
        "from sparknlp_display import NerVisualizer\n",
        "\n",
        "NerVisualizer().display(\n",
        "    result = result.collect()[0],\n",
        "    label_col = 'ner_chunk',\n",
        "    document_col = 'document'\n",
        ")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    @import url('https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700&display=swap');\n",
              "    @import url('https://fonts.googleapis.com/css2?family=Vistol Regular:wght@300;400;500;600;700&display=swap');\n",
              "    \n",
              "    .spark-nlp-display-scroll-entities {\n",
              "        border: 1px solid #E7EDF0;\n",
              "        border-radius: 3px;\n",
              "        text-align: justify;\n",
              "        \n",
              "    }\n",
              "    .spark-nlp-display-scroll-entities span {  \n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        color: #536B76;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "    }\n",
              "    \n",
              "    .spark-nlp-display-entity-wrapper{\n",
              "    \n",
              "        display: inline-grid;\n",
              "        text-align: center;\n",
              "        border-radius: 4px;\n",
              "        margin: 0 2px 5px 2px;\n",
              "        padding: 1px\n",
              "    }\n",
              "    .spark-nlp-display-entity-name{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "        \n",
              "        background: #f1f2f3;\n",
              "        border-width: medium;\n",
              "        text-align: center;\n",
              "        \n",
              "        font-weight: 400;\n",
              "        \n",
              "        border-radius: 5px;\n",
              "        padding: 2px 5px;\n",
              "        display: block;\n",
              "        margin: 3px 2px;\n",
              "    \n",
              "    }\n",
              "    .spark-nlp-display-entity-type{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        color: #ffffff;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "        \n",
              "        text-transform: uppercase;\n",
              "        \n",
              "        font-weight: 500;\n",
              "\n",
              "        display: block;\n",
              "        padding: 3px 5px;\n",
              "    }\n",
              "    \n",
              "    .spark-nlp-display-entity-resolution{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        color: #ffffff;\n",
              "        font-family: 'Vistol Regular', sans-serif !important;\n",
              "        \n",
              "        text-transform: uppercase;\n",
              "        \n",
              "        font-weight: 500;\n",
              "\n",
              "        display: block;\n",
              "        padding: 3px 5px;\n",
              "    }\n",
              "    \n",
              "    .spark-nlp-display-others{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "        \n",
              "        font-weight: 400;\n",
              "    }\n",
              "\n",
              "</style>\n",
              " <span class=\"spark-nlp-display-others\" style=\"background-color: white\">a primeira câmara desta corte , em acórdão constante da </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #B3349E\"><span class=\"spark-nlp-display-entity-name\">relação 31/2000 </span><span class=\"spark-nlp-display-entity-type\">JURISPRUDENCIA</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> , </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #B3349E\"><span class=\"spark-nlp-display-entity-name\">ata 27/2000 </span><span class=\"spark-nlp-display-entity-type\">JURISPRUDENCIA</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> , ministro </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #138D93\"><span class=\"spark-nlp-display-entity-name\">marcos vinicios vilaça </span><span class=\"spark-nlp-display-entity-type\">PESSOA</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> , julgou regulares com ressalva as contas de </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #138D93\"><span class=\"spark-nlp-display-entity-name\">carlos aureliano motta de souza </span><span class=\"spark-nlp-display-entity-type\">PESSOA</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> , ex-diretor-geral do </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #7C5781\"><span class=\"spark-nlp-display-entity-name\">stm </span><span class=\"spark-nlp-display-entity-type\">ORGANIZACAO</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> , no ano de </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #1BB435\"><span class=\"spark-nlp-display-entity-name\">1999 </span><span class=\"spark-nlp-display-entity-type\">TEMPO</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> ( peça 1 , p. 49-51 ) .</span></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-61DDZx9nEY0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
