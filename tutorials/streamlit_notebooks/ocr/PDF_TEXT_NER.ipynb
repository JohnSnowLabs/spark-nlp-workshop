{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "PDF_TEXT_NER.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-pyfWT3a6S4"
      },
      "source": [
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/ocr/PDF_TEXT_NER.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWU8Tl9Fa3eT"
      },
      "source": [
        "# Recognize entities in scanned PDFs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DtUIwnIa3eU"
      },
      "source": [
        "To run this yourself, you will need to upload your **Spark OCR** license keys to the notebook. Otherwise, you can look at the example outputs at the bottom of the notebook. To upload license keys, open the file explorer on the left side of the screen and upload `workshop_license_keys.json` to the folder that opens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAbRkMvtz-Gl"
      },
      "source": [
        "For more in-depth tutorials: https://github.com/JohnSnowLabs/spark-ocr-workshop/tree/master/jupyter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdROQW5ScYKA"
      },
      "source": [
        "## 1. Colab Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeMJ4AoPkoMc"
      },
      "source": [
        "Read licence key"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUeMlVj1a3eV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          }
        },
        "outputId": "a20a4e7d-a410-49ec-fe20-7b57cacf6f56"
      },
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "license_keys = files.upload()\n",
        "os.rename(list(license_keys.keys())[0], 'spark_ocr.json')\n",
        "\n",
        "with open('spark_ocr.json') as f:\n",
        "    license_keys = json.load(f)\n",
        "\n",
        "# Defining license key-value pairs as local variables\n",
        "locals().update(license_keys)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-21bf17a7-9a11-46ca-add7-4cba38fc9376\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-21bf17a7-9a11-46ca-add7-4cba38fc9376\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving spark_nlp_for_healthcare_spark_ocr_3565.json to spark_nlp_for_healthcare_spark_ocr_3565.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74VqnE1reEFC"
      },
      "source": [
        "Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErndQ8oea3eY"
      },
      "source": [
        "# Installing pyspark and spark-nlp\n",
        "! pip install --upgrade -q pyspark==3.0.2 spark-nlp==$PUBLIC_VERSION\n",
        "\n",
        "# Installing Spark NLP Healthcare\n",
        "! pip -q install --upgrade spark-nlp-jsl==$JSL_VERSION  --extra-index-url https://pypi.johnsnowlabs.com/$SECRET\n",
        "\n",
        "# Installing Spark OCR\n",
        "! pip install spark-ocr==$OCR_VERSION\\+spark30 --extra-index-url=https://pypi.johnsnowlabs.com/$SPARK_OCR_SECRET --upgrade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b><h1><font color='darkred'>!!! ATTENTION !!! </font><h1><b>\n",
        "\n",
        "<b>After running previous cell, <font color='darkred'>RESTART the COLAB RUNTIME </font> and go ahead.<b>"
      ],
      "metadata": {
        "id": "3KMkY1T-A-aB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVt8BQaaeGp5"
      },
      "source": [
        "Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json, os\n",
        "\n",
        "with open(\"spark_ocr.json\", 'r') as f:\n",
        "  license_keys = json.load(f)\n",
        "\n",
        "# Adding license key-value pairs to environment variables\n",
        "os.environ.update(license_keys)\n",
        "\n",
        "# Defining license key-value pairs as local variables\n",
        "locals().update(license_keys)"
      ],
      "metadata": {
        "id": "yVwSM9kIA9II"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cn4in75Ha3eb"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "#Pyspark Imports\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml import PipelineModel\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Necessary imports from Spark OCR library\n",
        "import sparkocr\n",
        "from sparkocr import start\n",
        "from sparkocr.transformers import *\n",
        "from sparkocr.enums import *\n",
        "from sparkocr.utils import display_image, to_pil_image\n",
        "from sparkocr.metrics import score\n",
        "import pkg_resources\n",
        "\n",
        "# import sparknlp packages\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "import sparknlp_jsl\n",
        "from sparknlp_jsl.annotator import *\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmAnLt26eMHu"
      },
      "source": [
        "Start Spark Session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXtlGP0aa3ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "5d13c608-909e-468a-aa4e-fed6e11158e0"
      },
      "source": [
        "# Start spark\n",
        "spark = sparkocr.start(secret=SPARK_OCR_SECRET, \n",
        "                       nlp_version=PUBLIC_VERSION,\n",
        "                       nlp_secret=SECRET,\n",
        "                       nlp_internal=JSL_VERSION\n",
        "                       )\n",
        "spark"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark version: 3.0.2\n",
            "Spark NLP version: 3.3.4\n",
            "Spark OCR version: 3.9.1\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://e638f7472a42:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.0.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark OCR</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fd027b1a910>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6caZBlia3et"
      },
      "source": [
        "## 2. Download and read scanned pdf image. \n",
        "**To process PDF, download it and just use pdf_to_image annotator instead of binary_to_image in the pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6KK40-Q2NA0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30c8e82a-cefe-4293-b001-52d67d7c1c49"
      },
      "source": [
        "!wget https://www.reneelab.com/wp-content/uploads/sites/2/2015/11/target-500x600.png -O 1.jpg"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-10 17:25:24--  https://www.reneelab.com/wp-content/uploads/sites/2/2015/11/target-500x600.png\n",
            "Resolving www.reneelab.com (www.reneelab.com)... 172.66.43.113, 172.66.40.143, 2606:4700:3108::ac42:2b71, ...\n",
            "Connecting to www.reneelab.com (www.reneelab.com)|172.66.43.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [image/png]\n",
            "Saving to: ‘1.jpg’\n",
            "\n",
            "1.jpg                   [ <=>                ] 141.88K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2022-01-10 17:25:24 (5.35 MB/s) - ‘1.jpg’ saved [145284]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApsEfUpfa3eu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c848edbb-da15-4523-e2b5-ec3b6c2c606d"
      },
      "source": [
        "image_df = spark.read.format(\"binaryFile\").load('./1.jpg').cache()\n",
        "image_df.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+-------------------+------+--------------------+\n",
            "|               path|   modificationTime|length|             content|\n",
            "+-------------------+-------------------+------+--------------------+\n",
            "|file:/content/1.jpg|2016-12-19 13:28:45|145284|[89 50 4E 47 0D 0...|\n",
            "+-------------------+-------------------+------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxZlmX-ieyqE"
      },
      "source": [
        "## 3. Construct OCR & NLP pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9mQ1bwKrJM5"
      },
      "source": [
        "OCR Pipleline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9vo_4vua3er"
      },
      "source": [
        "# To load PDF instead of Image,\n",
        "#pdf_to_image = PdfToImage() \\\n",
        "#            .setInputCol(\"content\") \\\n",
        "#            .setOutputCol(\"image_raw\") \\\n",
        "#            .setKeepInput(True)\n",
        "\n",
        "# Read binary as image\n",
        "binary_to_image = BinaryToImage()\n",
        "binary_to_image.setInputCol('content')\n",
        "binary_to_image.setOutputCol('image')\n",
        "\n",
        "# Scale image\n",
        "scaler = ImageScaler()\n",
        "scaler.setInputCol('image')\n",
        "scaler.setOutputCol('scaled_image')\n",
        "scaler.setScaleFactor(2.0)\n",
        "\n",
        "# Binarize using adaptive tresholding\n",
        "binarizer = ImageAdaptiveThresholding()\n",
        "binarizer.setInputCol('scaled_image')\n",
        "binarizer.setOutputCol('binarized_image')\n",
        "binarizer.setBlockSize(91)\n",
        "binarizer.setOffset(70)\n",
        "\n",
        "# Remove extraneous objects from image\n",
        "remove_objects = ImageRemoveObjects()\n",
        "remove_objects.setInputCol('binarized_image')\n",
        "remove_objects.setOutputCol('cleared_image')\n",
        "remove_objects.setMinSizeObject(30)\n",
        "remove_objects.setMaxSizeObject(4000)\n",
        "\n",
        "# Apply morphology opening\n",
        "morpholy_operation = ImageMorphologyOperation()\n",
        "morpholy_operation.setKernelShape(KernelShape.DISK)\n",
        "morpholy_operation.setKernelSize(1)\n",
        "morpholy_operation.setOperation('closing')\n",
        "morpholy_operation.setInputCol('cleared_image')\n",
        "morpholy_operation.setOutputCol('corrected_image')\n",
        "\n",
        "# Extract text from corrected image with OCR\n",
        "ocr = ImageToText()\n",
        "ocr.setInputCol('binarized_image')\n",
        "ocr.setOutputCol('text')\n",
        "ocr.setConfidenceThreshold(50)\n",
        "ocr.setIgnoreResolution(False)\n",
        "\n",
        "# Create pipeline\n",
        "pipeline = PipelineModel(stages=[\n",
        "    binary_to_image,\n",
        "    scaler,\n",
        "    binarizer,\n",
        "    remove_objects,\n",
        "    morpholy_operation,\n",
        "    ocr])\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsNhQJ16rORr"
      },
      "source": [
        "NLP Pipeline containing **Spell Correction** and **NER**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4LIsvtMrQMi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14d4e292-d87b-4b0c-b139-d70b6fb751ba"
      },
      "source": [
        "documentAssembler = DocumentAssembler().setInputCol(\"text\").setOutputCol(\"document\")\n",
        "\n",
        "tokenizer = Tokenizer() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "spellModel = ContextSpellCheckerModel\\\n",
        "    .pretrained('spellcheck_dl')\\\n",
        "    .setInputCols(\"token\")\\\n",
        "    .setOutputCol(\"checked\")\n",
        "    \n",
        "embeddings = WordEmbeddingsModel.pretrained('glove_100d').\\\n",
        "                    setInputCols([\"document\", 'checked']).\\\n",
        "                    setOutputCol(\"embeddings\")\n",
        "\n",
        "public_ner = NerDLModel.pretrained('onto_100', 'en') \\\n",
        "          .setInputCols([\"document\", \"token\", \"embeddings\"]) \\\n",
        "          .setOutputCol(\"ner\")\n",
        "\n",
        "ner_converter = NerConverter() \\\n",
        "                .setInputCols([\"document\", \"token\", \"ner\"]) \\\n",
        "                  .setOutputCol(\"ner_chunk\")\n",
        "\n",
        "nlp_pipeline =  Pipeline(stages=[documentAssembler, \n",
        "                                tokenizer,\n",
        "                                spellModel,\n",
        "                                embeddings,\n",
        "                                public_ner,\n",
        "                                ner_converter])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spellcheck_dl download started this may take some time.\n",
            "Approximate size to download 111.4 MB\n",
            "[OK!]\n",
            "glove_100d download started this may take some time.\n",
            "Approximate size to download 145.3 MB\n",
            "[OK!]\n",
            "onto_100 download started this may take some time.\n",
            "Approximate size to download 13.5 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vd74DK4ha3ew"
      },
      "source": [
        "## 4. Run OCR pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5Wh9ysOa3ew"
      },
      "source": [
        "result = pipeline.transform(image_df).cache()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uC_egLWa3ez"
      },
      "source": [
        "## 5. Visualize Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyIew0rVgnPM"
      },
      "source": [
        "Display result dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCOLYbB5a3ez",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae4da7a0-9e42-4db1-9a6e-021eb39ae841"
      },
      "source": [
        "result.select(\"text\", \"confidence\").show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----------------+\n",
            "|                text|      confidence|\n",
            "+--------------------+----------------+\n",
            "|ADVERTISEMENT.\n",
            "\n",
            "T...|91.8821029663086|\n",
            "+--------------------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2C_VFRVIa3e6"
      },
      "source": [
        "Display text and images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJZGPMJna3e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9163749-f795-41dc-d601-289879c5a6f5"
      },
      "source": [
        "result_arr = []\n",
        "for r in result.distinct().collect():\n",
        "  print (r.text)\n",
        "  result_arr.append(r.text)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ADVERTISEMENT.\n",
            "\n",
            "Tuts publication of the Works of Jonn Kwox, it is\n",
            "supposed, will extend to Five Volumes. It was thought\n",
            "advisable to commence the series with his History of\n",
            "the Reformation in Scotland, as the work of greatest\n",
            "importance. The next volume will thus contain the\n",
            "Third and Fourth Books, which continue the History to\n",
            "the year 1564; at which period his historical labours\n",
            "may be considered to terminate. But the Fifth Book,\n",
            "forming a sequel to the History, and published under\n",
            "his name in 1644, will also be included. His Letters\n",
            "and Miscellancous Writings will be arranged in the\n",
            "subsequent volumes, as nearly as possible in chronolo-\n",
            "gical order; each portion being introduced by a separate\n",
            "avtice, respecting the manuscript or printed copies from\n",
            "which they have been taken.\n",
            "\n",
            "It may perhaps be expected that a Life of the Author\n",
            "thould have been prefixed to this volume. The Life of\n",
            "Knox, by Dr. M-Crig, is however a work so universally\n",
            "known, and of so much historical value, as to supersede\n",
            "any attenint that mieht he made for a detailed Dia-\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGRFKIITk94N"
      },
      "source": [
        "# 6. Run NLP pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vE5H1gBwjPmg"
      },
      "source": [
        "empty_df = spark.createDataFrame([['']]).toDF(\"text\")\n",
        "pipelineModel = nlp_pipeline.fit(empty_df)\n",
        "df = spark.createDataFrame(pd.DataFrame({\"text\":result_arr}))\n",
        "nlp_result = pipelineModel.transform(df)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsjBAh25lC3x"
      },
      "source": [
        "#7. Visualize NLP results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_S2Fr8Njtxt8"
      },
      "source": [
        "Contextual Spell Correction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OY1TerGzt1oA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6748006f-1aff-4a57-cac2-c0f6ebffe667"
      },
      "source": [
        "nlp_result.select(F.explode(F.arrays_zip('token.result', 'checked.result')).alias(\"cols\")) \\\n",
        ".select(F.expr(\"cols['0']\").alias(\"original\"),\n",
        "        F.expr(\"cols['1']\").alias(\"corrected\")).show(truncate=False)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+-------------+\n",
            "|original     |corrected    |\n",
            "+-------------+-------------+\n",
            "|ADVERTISEMENT|ADVERTISEMENT|\n",
            "|.            |.            |\n",
            "|Tuts         |puts         |\n",
            "|publication  |publication  |\n",
            "|of           |of           |\n",
            "|the          |the          |\n",
            "|Works        |Works        |\n",
            "|of           |of           |\n",
            "|Jonn         |John         |\n",
            "|Kwox         |Knox         |\n",
            "|,            |,            |\n",
            "|it           |it           |\n",
            "|is           |is           |\n",
            "|supposed     |supposed     |\n",
            "|,            |,            |\n",
            "|will         |will         |\n",
            "|extend       |extend       |\n",
            "|to           |to           |\n",
            "|Five         |Five         |\n",
            "|Volumes      |Volumes      |\n",
            "+-------------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5ZvzBfku-sg"
      },
      "source": [
        "NER "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iux_qfFBkq02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "500ef62e-a2f5-437d-dbe6-2baba4eae0b9"
      },
      "source": [
        "\n",
        "nlp_result.select(F.explode(F.arrays_zip('ner_chunk.result', 'ner_chunk.metadata')).alias(\"cols\")) \\\n",
        ".select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
        "        F.expr(\"cols['1']['entity']\").alias(\"ner_label\")).show(truncate=False)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------+-----------+\n",
            "|chunk                                 |ner_label  |\n",
            "+--------------------------------------+-----------+\n",
            "|the Works of Jonn Kwox                |WORK_OF_ART|\n",
            "|Five Volumes                          |WORK_OF_ART|\n",
            "|History of\n",
            "the Reformation            |WORK_OF_ART|\n",
            "|Scotland                              |GPE        |\n",
            "|Third                                 |ORDINAL    |\n",
            "|Fourth                                |ORDINAL    |\n",
            "|History to\n",
            "the year 1564              |DATE       |\n",
            "|labours                               |ORG        |\n",
            "|Fifth                                 |ORDINAL    |\n",
            "|History                               |WORK_OF_ART|\n",
            "|1644                                  |DATE       |\n",
            "|His Letters\n",
            "and Miscellancous Writings|WORK_OF_ART|\n",
            "|a Life of the Author                  |WORK_OF_ART|\n",
            "|The Life of\n",
            "Knox                      |WORK_OF_ART|\n",
            "|Dr                                    |PERSON     |\n",
            "|M-Crig                                |PERSON     |\n",
            "+--------------------------------------+-----------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}