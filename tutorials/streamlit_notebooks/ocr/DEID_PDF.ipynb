{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DEID_PDF.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyPOinPUrEs/mcnlMVnO0kdt"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"P8TTu4dvrqwi","colab_type":"text"},"source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n","\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/ocr/DEID_PDF.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"kBWM4Xi0r0sV","colab_type":"text"},"source":["# **De-identify PDF Documents**\n","Deidentify text and metada"]},{"cell_type":"markdown","metadata":{"id":"o1IAxyTRrx95","colab_type":"text"},"source":["To run this yourself, you will need to upload your **Spark OCR & Sprk NLP** license keys to the notebook. Otherwise, you can look at the example outputs at the bottom of the notebook. To upload license keys, open the file explorer on the left side of the screen and upload `workshop_license_keys.json` to the folder that opens."]},{"cell_type":"markdown","metadata":{"id":"_UwoxcjTsEWl","colab_type":"text"},"source":["# 1. Colab Setup"]},{"cell_type":"markdown","metadata":{"id":"J5t0AhtmsJqS","colab_type":"text"},"source":["Install correct version of Pillow and Restart runtime"]},{"cell_type":"code","metadata":{"id":"3VB-jAmXsDuc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598030781196,"user_tz":-300,"elapsed":1067,"user":{"displayName":"Hasham Ul Haq","photoUrl":"","userId":"10508284328555930330"}},"outputId":"795bd406-50fa-44de-f45a-5e6f792d95d7"},"source":["# Install correct Pillow version\n","import PIL\n","if PIL.__version__  != '6.2.1':\n","  print ('Installing correct version of Pillow. Kernel will restart automatically')\n","  !pip install --upgrade pillow==6.2.1\n","  # hard restart runtime\n","  import os\n","  os.kill(os.getpid(), 9)\n","else:\n","  print ('Correct Pillow detected')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Correct Pillow detected\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3lQrhKlYsMYq","colab_type":"text"},"source":["Read License Key"]},{"cell_type":"code","metadata":{"id":"JVMdFJhvrEWw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1598030804782,"user_tz":-300,"elapsed":1027,"user":{"displayName":"Hasham Ul Haq","photoUrl":"","userId":"10508284328555930330"}},"outputId":"11bedf3f-21f7-4d1e-d2ae-468662d3270b"},"source":["import os\n","import json\n","\n","with open('workshop_license_keys.json') as f:\n","    license_keys = json.load(f)\n","\n","secret = license_keys['JSL_OCR_SECRET']\n","jsl_secret = license_keys['JSL_SECRET']\n","os.environ['SPARK_OCR_LICENSE'] = license_keys['SPARK_OCR_LICENSE']\n","os.environ['JSL_OCR_LICENSE'] = license_keys['SPARK_OCR_LICENSE']\n","os.environ['AWS_ACCESS_KEY_ID']= license_keys['AWS_ACCESS_KEY_ID']\n","os.environ['AWS_SECRET_ACCESS_KEY'] = license_keys['AWS_SECRET_ACCESS_KEY']\n","version = secret.split(\"-\")[0]\n","jsl_version = jsl_secret.split('-')[0]\n","print ('Spark OCR Version:', version)\n","print ('OCR Version:', version,)\n","print ('JSL Version:', jsl_version)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Spark OCR Version: 1.5.0\n","OCR Version: 1.5.0\n","JSL Version: 2.5.5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jK01vNa0sOJf","colab_type":"text"},"source":["Install Dependencies"]},{"cell_type":"code","metadata":{"id":"r1CdYmvqrqCy","colab_type":"code","colab":{}},"source":["# Install Java\n","!apt-get update\n","!apt-get install -y openjdk-8-jdk\n","!java -version\n","\n","# Install pyspark\n","!pip install --ignore-installed -q pyspark==2.4.4\n","# Install Spark OCR from PYPI using secret\n","!python -m pip install --upgrade spark-ocr==$version  --extra-index-url https://pypi.johnsnowlabs.com/$secret\n","\n","# Install Spark NLP and Spark NLP JSL\n","! pip install --ignore-installed -q spark-nlp\n","!python -m pip install --upgrade spark-nlp-jsl==$jsl_version --extra-index-url https://pypi.johnsnowlabs.com/$jsl_secret\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UMzHQ_DrsfxD","colab_type":"text"},"source":["Importing Libraries"]},{"cell_type":"code","metadata":{"id":"sw1RJhxEtItB","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598030916349,"user_tz":-300,"elapsed":96832,"user":{"displayName":"Hasham Ul Haq","photoUrl":"","userId":"10508284328555930330"}}},"source":["import pandas as pd\n","import numpy as np\n","import os\n","\n","#Pyspark Imports\n","from pyspark.sql import SparkSession\n","from pyspark.ml import PipelineModel\n","from pyspark.sql import functions as F\n","\n","# Necessary imports from Spark OCR library\n","from sparkocr import start\n","from sparkocr.transformers import *\n","from sparkocr.enums import *\n","from sparkocr.utils import display_image, to_pil_image\n","from sparkocr.metrics import score\n","import pkg_resources\n","\n","# import sparknlp packages\n","from sparknlp.annotator import *\n","from sparknlp.base import *\n","import sparknlp_jsl\n","from sparknlp_jsl.annotator import *\n","\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WrFEVaeCtTB4","colab_type":"text"},"source":["Start Spark Session"]},{"cell_type":"code","metadata":{"id":"g6vXJJbctTNX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":216},"executionInfo":{"status":"ok","timestamp":1598030943293,"user_tz":-300,"elapsed":121743,"user":{"displayName":"Hasham Ul Haq","photoUrl":"","userId":"10508284328555930330"}},"outputId":"094fe4bb-63ee-420a-9fb2-948d324600c5"},"source":["spark = start(secret=secret,\n","              nlp_secret=jsl_secret,\n","              nlp_version=jsl_version,\n","              nlp_internal=True)\n","\n","spark"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://f363bef9484e:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v2.4.4</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>Spark OCR</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "],"text/plain":["<pyspark.sql.session.SparkSession at 0x7f6d0a00f0b8>"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"a6xXe2TftJNe","colab_type":"text"},"source":["# 2. Download and read PDF Document"]},{"cell_type":"code","metadata":{"id":"F0pmFfXbthlp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"executionInfo":{"status":"ok","timestamp":1598031018566,"user_tz":-300,"elapsed":17000,"user":{"displayName":"Hasham Ul Haq","photoUrl":"","userId":"10508284328555930330"}},"outputId":"e37d7f7c-16a8-47f1-9653-912f4b8566af"},"source":["pdf_example = pkg_resources.resource_filename('sparkocr', 'resources/ocr/pdfs/test_document.pdf')\n","pdf_example_df = spark.read.format(\"binaryFile\").load(pdf_example).cache()\n","pdf_example_df.show()"],"execution_count":6,"outputs":[{"output_type":"stream","text":["+--------------------+-------------------+------+--------------------+\n","|                path|   modificationTime|length|             content|\n","+--------------------+-------------------+------+--------------------+\n","|file:/usr/local/l...|2020-08-21 17:28:08|693743|[25 50 44 46 2D 3...|\n","+--------------------+-------------------+------+--------------------+\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"W1nZn-XXtmow","colab_type":"text"},"source":["Convert & View PDF as images"]},{"cell_type":"code","metadata":{"id":"OLbx1vmRto2Y","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1wOjmX9EyHgu6-PSD6vLVqSSkkwYybOhY"},"executionInfo":{"status":"ok","timestamp":1598031259087,"user_tz":-300,"elapsed":24770,"user":{"displayName":"Hasham Ul Haq","photoUrl":"","userId":"10508284328555930330"}},"outputId":"c811f7cf-e043-450e-d218-e7aa77bccd8c"},"source":["for image in PdfToImage().transform(pdf_example_df).collect():\n","  #print(image.exception)\n","  #print(image.metadata)\n","  display_image(image.image)"],"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"XsfuE4ottadW","colab_type":"text"},"source":["# 3. Construct OCR and DEID (NLP) Pipelines"]},{"cell_type":"markdown","metadata":{"id":"FtAikNkm-DbY","colab_type":"text"},"source":["De-identification Pipeline"]},{"cell_type":"code","metadata":{"id":"vC1qHGVxsd4d","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598031267781,"user_tz":-300,"elapsed":1498,"user":{"displayName":"Hasham Ul Haq","photoUrl":"","userId":"10508284328555930330"}}},"source":["def deidentification_nlp_pipeline(input_column, prefix = \"\"):\n","    document_assembler = DocumentAssembler() \\\n","        .setInputCol(input_column) \\\n","        .setOutputCol(prefix + \"document\")\n","\n","    # Sentence Detector annotator, processes various sentences per line\n","    sentence_detector = SentenceDetector() \\\n","        .setInputCols([prefix + \"document\"]) \\\n","        .setOutputCol(prefix + \"sentence\")\n","\n","    tokenizer = Tokenizer() \\\n","        .setInputCols([prefix + \"sentence\"]) \\\n","        .setOutputCol(prefix + \"token\")\n","\n","    # Clinical word embeddings\n","    word_embeddings = WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\") \\\n","        .setInputCols([prefix + \"sentence\", prefix + \"token\"]) \\\n","        .setOutputCol(prefix + \"embeddings\")\n","    # NER model trained on i2b2 (sampled from MIMIC) dataset\n","    clinical_ner = NerDLModel.pretrained(\"ner_deid_large\", \"en\", \"clinical/models\") \\\n","        .setInputCols([prefix + \"sentence\", prefix + \"token\", prefix + \"embeddings\"]) \\\n","        .setOutputCol(prefix + \"ner\")\n","\n","    custom_ner_converter = NerConverter() \\\n","        .setInputCols([prefix + \"sentence\", prefix + \"token\", prefix + \"ner\"]) \\\n","        .setOutputCol(prefix + \"ner_chunk\") \\\n","        .setWhiteList(['NAME', 'AGE', 'CONTACT',\n","                   'LOCATION', 'PROFESSION', 'PERSON'])\n","\n","    nlp_pipeline = Pipeline(stages=[\n","            document_assembler,\n","            sentence_detector,\n","            tokenizer,\n","            word_embeddings,\n","            clinical_ner,\n","            custom_ner_converter\n","        ])\n","    empty_data = spark.createDataFrame([[\"\"]]).toDF(input_column)\n","    nlp_model = nlp_pipeline.fit(empty_data)\n","    return nlp_model"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8oMgKuEh-G8P","colab_type":"text"},"source":["OCR and PDF to Image Conversion Pipeline."]},{"cell_type":"code","metadata":{"id":"37FLLrrc9aPp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"executionInfo":{"status":"ok","timestamp":1598031393621,"user_tz":-300,"elapsed":125272,"user":{"displayName":"Hasham Ul Haq","photoUrl":"","userId":"10508284328555930330"}},"outputId":"e6a6a583-422c-46ed-a743-726c0469b23c"},"source":["# Extract images from Dicom foram\n","# If text PDF extract text\n","pdf_to_text = PdfToText() \\\n","    .setInputCol(\"content\") \\\n","    .setOutputCol(\"text\") \\\n","    .setSplitPage(False)\n","\n","# If image pdf, extract image\n","pdf_to_image = PdfToImage() \\\n","    .setInputCol(\"content\") \\\n","    .setOutputCol(\"image_raw\") \\\n","    .setKeepInput(True)\n","\n","# Extract text from image\n","ocr = ImageToText() \\\n","    .setInputCol(\"image_raw\") \\\n","    .setOutputCol(\"text\") \\\n","    .setIgnoreResolution(False) \\\n","    .setOcrParams([\"preserve_interword_spaces=0\"])\n","\n","\n","# Find coordinates of sensitive data\n","position_finder = PositionFinder() \\\n","    .setInputCols(\"ner_chunk\") \\\n","    .setOutputCol(\"coordinates\") \\\n","    .setPageMatrixCol(\"positions\") \\\n","    .setMatchingWindow(10) \\\n","    .setPadding(0)\n","\n","# Draw filled rectangle to hide sensitive data\n","draw_regions = ImageDrawRegions()  \\\n","    .setInputCol(\"image_raw\")  \\\n","    .setInputRegionsCol(\"coordinates\")  \\\n","    .setOutputCol(\"image_with_regions\")  \\\n","    .setFilledRect(True)\n","\n","# Store image back to pdf\n","image_to_pdf = ImageToPdf() \\\n","        .setInputCol(\"image_with_regions\") \\\n","        .setOutputCol(\"pdf\")\n","\n","# OCR pipeline\n","pipeline = PipelineModel(stages=[\n","    pdf_to_text,\n","    pdf_to_image,\n","    ocr,\n","    deidentification_nlp_pipeline(input_column=\"text\"),\n","    position_finder,\n","    draw_regions,\n","    image_to_pdf\n","])"],"execution_count":12,"outputs":[{"output_type":"stream","text":["embeddings_clinical download started this may take some time.\n","Approximate size to download 1.6 GB\n","[OK!]\n","ner_deid_large download started this may take some time.\n","Approximate size to download 13.9 MB\n","[OK!]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"iHtbySQu-LCR","colab_type":"text"},"source":["# 4. Run the pipelines and save De-identified PDF Document"]},{"cell_type":"markdown","metadata":{"id":"pjSpEyhvJtre","colab_type":"text"},"source":["Run Pipeline"]},{"cell_type":"code","metadata":{"id":"BTatU7EHJo4j","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598032396999,"user_tz":-300,"elapsed":2586,"user":{"displayName":"Hasham Ul Haq","photoUrl":"","userId":"10508284328555930330"}}},"source":["result = pipeline.transform(pdf_example_df).cache()"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TPUYrQzxJvQA","colab_type":"text"},"source":["Save PDF"]},{"cell_type":"code","metadata":{"id":"3tWKnJRz9vHL","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598032448266,"user_tz":-300,"elapsed":51555,"user":{"displayName":"Hasham Ul Haq","photoUrl":"","userId":"10508284328555930330"}}},"source":["pdf = result.select(\"pdf\").head().pdf\n","pdfFile = open(\"Result.pdf\", \"wb\")\n","pdfFile.write(pdf)\n","pdfFile.close()"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UrwYnqwj-fC4","colab_type":"text"},"source":["# 5. Load De-identified PDF and Visualize Results"]},{"cell_type":"code","metadata":{"id":"_cb7bW64-eZ-","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598032648896,"user_tz":-300,"elapsed":86408,"user":{"displayName":"Hasham Ul Haq","photoUrl":"","userId":"10508284328555930330"}}},"source":["pdf_example_df = spark.read.format(\"binaryFile\").load(\"Result.pdf\")\n","for image in PdfToImage().transform(pdf_example_df).collect():\n","  #print(image.exception)\n","  #print(image.metadata)\n","  display_image(image.image)"],"execution_count":17,"outputs":[]}]}