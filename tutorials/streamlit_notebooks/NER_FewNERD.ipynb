{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER_FewNERD.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TA21Jo5d9SVq"
      },
      "source": [
        "\n",
        "\n",
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/NER_FewNERD.ipynb)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzIdjHkAW8TB"
      },
      "source": [
        "# **Detect entities using FewNERD NER Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIeCOiJNW-88"
      },
      "source": [
        "## 1. Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGJktFHdHL1n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9dd94c89-ba1d-4874-c833-66847beaf2b7"
      },
      "source": [
        "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash\n",
        "# !bash colab.sh\n",
        "# -p is for pyspark\n",
        "# -s is for spark-nlp\n",
        "# !bash colab.sh -p 3.1.1 -s 3.0.1\n",
        "# by default they are set to the latest\n",
        "\n",
        "# Install Spark NLP Display for visualization\n",
        "!pip install --ignore-installed spark-nlp-display"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-03 10:27:58--  http://setup.johnsnowlabs.com/colab.sh\n",
            "Resolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 51.158.130.125\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://setup.johnsnowlabs.com/colab.sh [following]\n",
            "--2021-12-03 10:27:59--  https://setup.johnsnowlabs.com/colab.sh\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh [following]\n",
            "--2021-12-03 10:27:59--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1275 (1.2K) [text/plain]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                     0%[                    ]       0  --.-KB/s               setup Colab for PySpark 3.0.3 and Spark NLP 3.3.4\n",
            "Installing PySpark 3.0.3 and Spark NLP 3.3.4\n",
            "-                   100%[===================>]   1.25K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-12-03 10:27:59 (38.6 MB/s) - written to stdout [1275/1275]\n",
            "\n",
            "\u001b[K     |████████████████████████████████| 209.1 MB 65 kB/s \n",
            "\u001b[K     |████████████████████████████████| 133 kB 48.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 198 kB 33.7 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting spark-nlp-display\n",
            "  Downloading spark_nlp_display-1.8-py3-none-any.whl (95 kB)\n",
            "\u001b[K     |████████████████████████████████| 95 kB 2.2 MB/s \n",
            "\u001b[?25hCollecting ipython\n",
            "  Downloading ipython-7.30.1-py3-none-any.whl (791 kB)\n",
            "\u001b[K     |████████████████████████████████| 791 kB 37.2 MB/s \n",
            "\u001b[?25hCollecting pandas\n",
            "  Downloading pandas-1.3.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.3 MB 29.6 MB/s \n",
            "\u001b[?25hCollecting svgwrite==1.4\n",
            "  Downloading svgwrite-1.4-py3-none-any.whl (66 kB)\n",
            "\u001b[K     |████████████████████████████████| 66 kB 4.1 MB/s \n",
            "\u001b[?25hCollecting spark-nlp\n",
            "  Using cached spark_nlp-3.3.4-py2.py3-none-any.whl (133 kB)\n",
            "Collecting numpy\n",
            "  Downloading numpy-1.21.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 147 kB/s \n",
            "\u001b[?25hCollecting traitlets>=4.2\n",
            "  Downloading traitlets-5.1.1-py3-none-any.whl (102 kB)\n",
            "\u001b[K     |████████████████████████████████| 102 kB 11.7 MB/s \n",
            "\u001b[?25hCollecting matplotlib-inline\n",
            "  Downloading matplotlib_inline-0.1.3-py3-none-any.whl (8.2 kB)\n",
            "Collecting backcall\n",
            "  Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting setuptools>=18.5\n",
            "  Downloading setuptools-59.4.0-py3-none-any.whl (952 kB)\n",
            "\u001b[K     |████████████████████████████████| 952 kB 41.3 MB/s \n",
            "\u001b[?25hCollecting pygments\n",
            "  Downloading Pygments-2.10.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 47.4 MB/s \n",
            "\u001b[?25hCollecting decorator\n",
            "  Downloading decorator-5.1.0-py3-none-any.whl (9.1 kB)\n",
            "Collecting pickleshare\n",
            "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
            "Collecting pexpect>4.3\n",
            "  Downloading pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 5.4 MB/s \n",
            "\u001b[?25hCollecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n",
            "  Downloading prompt_toolkit-3.0.23-py3-none-any.whl (374 kB)\n",
            "\u001b[K     |████████████████████████████████| 374 kB 51.0 MB/s \n",
            "\u001b[?25hCollecting jedi>=0.16\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 36.2 MB/s \n",
            "\u001b[?25hCollecting parso<0.9.0,>=0.8.0\n",
            "  Downloading parso-0.8.3-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[K     |████████████████████████████████| 100 kB 9.0 MB/s \n",
            "\u001b[?25hCollecting ptyprocess>=0.5\n",
            "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
            "Collecting wcwidth\n",
            "  Downloading wcwidth-0.2.5-py2.py3-none-any.whl (30 kB)\n",
            "Collecting python-dateutil>=2.7.3\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "\u001b[K     |████████████████████████████████| 247 kB 55.1 MB/s \n",
            "\u001b[?25hCollecting pytz>=2017.3\n",
            "  Downloading pytz-2021.3-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 31.2 MB/s \n",
            "\u001b[?25hCollecting six>=1.5\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Installing collected packages: wcwidth, traitlets, six, ptyprocess, parso, setuptools, pytz, python-dateutil, pygments, prompt-toolkit, pickleshare, pexpect, numpy, matplotlib-inline, jedi, decorator, backcall, svgwrite, spark-nlp, pandas, ipython, spark-nlp-display\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.3.post1 requires numpy<1.20,>=1.16.0, but you have numpy 1.21.4 which is incompatible.\n",
            "nbclient 0.5.9 requires jupyter-client>=6.1.5, but you have jupyter-client 5.3.5 which is incompatible.\n",
            "moviepy 0.2.3.5 requires decorator<5.0,>=4.0.2, but you have decorator 5.1.0 which is incompatible.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.23 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.30.1 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas~=1.1.0; python_version >= \"3.0\", but you have pandas 1.3.4 which is incompatible.\n",
            "google-colab 1.0.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed backcall-0.2.0 decorator-5.1.0 ipython-7.30.1 jedi-0.18.1 matplotlib-inline-0.1.3 numpy-1.21.4 pandas-1.3.4 parso-0.8.3 pexpect-4.8.0 pickleshare-0.7.5 prompt-toolkit-3.0.23 ptyprocess-0.7.0 pygments-2.10.0 python-dateutil-2.8.2 pytz-2021.3 setuptools-59.4.0 six-1.16.0 spark-nlp-3.3.4 spark-nlp-display-1.8 svgwrite-1.4 traitlets-5.1.1 wcwidth-0.2.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "IPython",
                  "dateutil",
                  "decorator",
                  "numpy",
                  "pandas",
                  "pexpect",
                  "pickleshare",
                  "pkg_resources",
                  "prompt_toolkit",
                  "pygments",
                  "pytz",
                  "six",
                  "traitlets",
                  "wcwidth"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCIT5VLxS3I1"
      },
      "source": [
        "## 2. Start the Spark session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khjM-z9ORFU3"
      },
      "source": [
        "Import dependencies and start Spark session."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sw-t1zxlHTB7"
      },
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sparknlp_display import NerVisualizer\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "import sparknlp\n",
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "\n",
        "spark = sparknlp.start()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Y9GpdJhXIpD"
      },
      "source": [
        "## 3. A sample text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBOKkB2THdGI"
      },
      "source": [
        "text_list = [\n",
        "    \"\"\"12 Corazones ('12 Hearts') is Spanish-language dating game show produced in the United States for the television network Telemundo since January 2005, based on its namesake Argentine TV show format. The show is filmed in Los Angeles and revolves around the twelve Zodiac signs that identify each contestant. In 2008, Ho filmed a cameo in the Steven Spielberg feature film The Cloverfield Paradox, as a news pundit.\"\"\"\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XftYgju4XOw_"
      },
      "source": [
        "## 4. Select the FewNERD NER Model, construct the pipeline and visualize the results.\n",
        "###Select the FewNERD NER Model - **\"nerdl_fewnerd_100d\",\"nerdl_fewnerd_subentity_100d\"**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxKtCUms33dR"
      },
      "source": [
        "model_list = [\"nerdl_fewnerd_100d\",\"nerdl_fewnerd_subentity_100d\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5-TNRBdUz50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "outputId": "2d89e81e-7dba-4026-8dc6-a2c9ac0cad7a"
      },
      "source": [
        "for MODEL_NAME in model_list:\n",
        "  documentAssembler = DocumentAssembler()\\\n",
        "        .setInputCol(\"text\")\\\n",
        "        .setOutputCol(\"document\")\n",
        "\n",
        "  sentenceDetector = SentenceDetector()\\\n",
        "        .setInputCols([\"document\"])\\\n",
        "        .setOutputCol(\"sentence\")\n",
        "\n",
        "  tokenizer = Tokenizer()\\\n",
        "        .setInputCols([\"sentence\"])\\\n",
        "        .setOutputCol(\"token\")\n",
        "\n",
        "  embeddings = WordEmbeddingsModel.pretrained(\"glove_100d\", \"en\")\\\n",
        "            .setInputCols(\"sentence\", \"token\") \\\n",
        "            .setOutputCol(\"embeddings\")\n",
        "\n",
        "  ner = NerDLModel.pretrained(MODEL_NAME)\\\n",
        "          .setInputCols([\"sentence\", \"token\", \"embeddings\"])\\\n",
        "          .setOutputCol(\"ner\")\n",
        "\n",
        "  ner_converter = NerConverter()\\\n",
        "      .setInputCols(['document', 'token', 'ner'])\\\n",
        "      .setOutputCol('ner_chunk')\n",
        "\n",
        "  nlpPipeline = Pipeline(stages=[documentAssembler, sentenceDetector,\n",
        "        tokenizer,\n",
        "        embeddings,\n",
        "        ner,\n",
        "        ner_converter])\n",
        "\n",
        "  empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
        "\n",
        "  ner_model = nlpPipeline.fit(empty_data)\n",
        "\n",
        "  df = spark.createDataFrame(pd.DataFrame({'text': text_list}))\n",
        "\n",
        "  result = ner_model.transform(df)\n",
        "  print(\"<----------------- MODEL NAME:\",\"\\033[1m\" + MODEL_NAME + \"\\033[0m\",\" ----------------- >\")\n",
        "  NerVisualizer().display(\n",
        "      result = result.collect()[0],\n",
        "      label_col = 'ner_chunk',\n",
        "      document_col = 'document'\n",
        "  )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "glove_100d download started this may take some time.\n",
            "Approximate size to download 145.3 MB\n",
            "[OK!]\n",
            "nerdl_fewnerd_100d download started this may take some time.\n",
            "Approximate size to download 14.2 MB\n",
            "[OK!]\n",
            "<----------------- MODEL NAME: \u001b[1mnerdl_fewnerd_100d\u001b[0m  ----------------- >\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    @import url('https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700&display=swap');\n",
              "    @import url('https://fonts.googleapis.com/css2?family=Vistol Regular:wght@300;400;500;600;700&display=swap');\n",
              "    \n",
              "    .spark-nlp-display-scroll-entities {\n",
              "        border: 1px solid #E7EDF0;\n",
              "        border-radius: 3px;\n",
              "        text-align: justify;\n",
              "        \n",
              "    }\n",
              "    .spark-nlp-display-scroll-entities span {  \n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        color: #536B76;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "    }\n",
              "    \n",
              "    .spark-nlp-display-entity-wrapper{\n",
              "    \n",
              "        display: inline-grid;\n",
              "        text-align: center;\n",
              "        border-radius: 4px;\n",
              "        margin: 0 2px 5px 2px;\n",
              "        padding: 1px\n",
              "    }\n",
              "    .spark-nlp-display-entity-name{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "        \n",
              "        background: #f1f2f3;\n",
              "        border-width: medium;\n",
              "        text-align: center;\n",
              "        \n",
              "        font-weight: 400;\n",
              "        \n",
              "        border-radius: 5px;\n",
              "        padding: 2px 5px;\n",
              "        display: block;\n",
              "        margin: 3px 2px;\n",
              "    \n",
              "    }\n",
              "    .spark-nlp-display-entity-type{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        color: #ffffff;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "        \n",
              "        text-transform: uppercase;\n",
              "        \n",
              "        font-weight: 500;\n",
              "\n",
              "        display: block;\n",
              "        padding: 3px 5px;\n",
              "    }\n",
              "    \n",
              "    .spark-nlp-display-entity-resolution{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        color: #ffffff;\n",
              "        font-family: 'Vistol Regular', sans-serif !important;\n",
              "        \n",
              "        text-transform: uppercase;\n",
              "        \n",
              "        font-weight: 500;\n",
              "\n",
              "        display: block;\n",
              "        padding: 3px 5px;\n",
              "    }\n",
              "    \n",
              "    .spark-nlp-display-others{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "        \n",
              "        font-weight: 400;\n",
              "    }\n",
              "\n",
              "</style>\n",
              " <span class=\"spark-nlp-display-others\" style=\"background-color: white\">12 Corazones ('12 Hearts') is Spanish-language dating game show produced in the </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #0B2840\"><span class=\"spark-nlp-display-entity-name\">United States </span><span class=\"spark-nlp-display-entity-type\">LOCATION</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> for the television network </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #B0533D\"><span class=\"spark-nlp-display-entity-name\">Telemundo </span><span class=\"spark-nlp-display-entity-type\">ORGANIZATION</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> since January 2005, based on its namesake </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #0B2840\"><span class=\"spark-nlp-display-entity-name\">Argentine </span><span class=\"spark-nlp-display-entity-type\">LOCATION</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> TV show format. The show is filmed in </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #0B2840\"><span class=\"spark-nlp-display-entity-name\">Los Angeles </span><span class=\"spark-nlp-display-entity-type\">LOCATION</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> and revolves around the twelve Zodiac signs that identify each contestant. In 2008, Ho filmed a cameo in the </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #9C922B\"><span class=\"spark-nlp-display-entity-name\">Steven Spielberg </span><span class=\"spark-nlp-display-entity-type\">PERSON</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> feature film </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #319A8D\"><span class=\"spark-nlp-display-entity-name\">The Cloverfield Paradox </span><span class=\"spark-nlp-display-entity-type\">ART</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, as a news pundit.</span></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "glove_100d download started this may take some time.\n",
            "Approximate size to download 145.3 MB\n",
            "[OK!]\n",
            "nerdl_fewnerd_subentity_100d download started this may take some time.\n",
            "Approximate size to download 14.7 MB\n",
            "[OK!]\n",
            "<----------------- MODEL NAME: \u001b[1mnerdl_fewnerd_subentity_100d\u001b[0m  ----------------- >\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    @import url('https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700&display=swap');\n",
              "    @import url('https://fonts.googleapis.com/css2?family=Vistol Regular:wght@300;400;500;600;700&display=swap');\n",
              "    \n",
              "    .spark-nlp-display-scroll-entities {\n",
              "        border: 1px solid #E7EDF0;\n",
              "        border-radius: 3px;\n",
              "        text-align: justify;\n",
              "        \n",
              "    }\n",
              "    .spark-nlp-display-scroll-entities span {  \n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        color: #536B76;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "    }\n",
              "    \n",
              "    .spark-nlp-display-entity-wrapper{\n",
              "    \n",
              "        display: inline-grid;\n",
              "        text-align: center;\n",
              "        border-radius: 4px;\n",
              "        margin: 0 2px 5px 2px;\n",
              "        padding: 1px\n",
              "    }\n",
              "    .spark-nlp-display-entity-name{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "        \n",
              "        background: #f1f2f3;\n",
              "        border-width: medium;\n",
              "        text-align: center;\n",
              "        \n",
              "        font-weight: 400;\n",
              "        \n",
              "        border-radius: 5px;\n",
              "        padding: 2px 5px;\n",
              "        display: block;\n",
              "        margin: 3px 2px;\n",
              "    \n",
              "    }\n",
              "    .spark-nlp-display-entity-type{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        color: #ffffff;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "        \n",
              "        text-transform: uppercase;\n",
              "        \n",
              "        font-weight: 500;\n",
              "\n",
              "        display: block;\n",
              "        padding: 3px 5px;\n",
              "    }\n",
              "    \n",
              "    .spark-nlp-display-entity-resolution{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        color: #ffffff;\n",
              "        font-family: 'Vistol Regular', sans-serif !important;\n",
              "        \n",
              "        text-transform: uppercase;\n",
              "        \n",
              "        font-weight: 500;\n",
              "\n",
              "        display: block;\n",
              "        padding: 3px 5px;\n",
              "    }\n",
              "    \n",
              "    .spark-nlp-display-others{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "        \n",
              "        font-weight: 400;\n",
              "    }\n",
              "\n",
              "</style>\n",
              " <span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #0440A7\"><span class=\"spark-nlp-display-entity-name\">12 Corazones ('12 Hearts') </span><span class=\"spark-nlp-display-entity-type\">art-broadcastprogram</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> is Spanish-language dating game show produced in the </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #9668C4\"><span class=\"spark-nlp-display-entity-name\">United States </span><span class=\"spark-nlp-display-entity-type\">location-GPE</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> for the television network </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #702E3D\"><span class=\"spark-nlp-display-entity-name\">Telemundo </span><span class=\"spark-nlp-display-entity-type\">organization-media/newspaper</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> since January 2005, based on its namesake </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #702E3D\"><span class=\"spark-nlp-display-entity-name\">Argentine TV </span><span class=\"spark-nlp-display-entity-type\">organization-media/newspaper</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> show format. The show is filmed in </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #9668C4\"><span class=\"spark-nlp-display-entity-name\">Los Angeles </span><span class=\"spark-nlp-display-entity-type\">location-GPE</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> and revolves around the twelve Zodiac signs that identify each contestant. In 2008, Ho filmed a cameo in the </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #A52418\"><span class=\"spark-nlp-display-entity-name\">Steven Spielberg </span><span class=\"spark-nlp-display-entity-type\">person-director</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> feature film </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #608A68\"><span class=\"spark-nlp-display-entity-name\">The Cloverfield Paradox </span><span class=\"spark-nlp-display-entity-type\">art-film</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, as a news pundit.</span></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}