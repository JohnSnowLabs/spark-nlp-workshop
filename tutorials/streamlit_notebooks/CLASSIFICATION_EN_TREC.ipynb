{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CLASSIFICATION_EN_TREC.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vas1PNJwZp2U"
      },
      "source": [
        "\n",
        "\n",
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/CLASSIFICATION_EN_TREC.ipynb)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2lonApkZwJP"
      },
      "source": [
        "# **Classify text according to TREC classes**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMURhBz4ZwM6"
      },
      "source": [
        "## 1. Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIJfXkK54WFk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd47c840-270b-4a27-9b5e-71af6bd0a829"
      },
      "source": [
        "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash\n",
        "# !bash colab.sh\n",
        "# -p is for pyspark\n",
        "# -s is for spark-nlp\n",
        "# !bash colab.sh -p 3.1.1 -s 3.0.1\n",
        "# by default they are set to the latest"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"11.0.10\" 2021-01-19\n",
            "OpenJDK Runtime Environment (build 11.0.10+9-Ubuntu-0ubuntu1.18.04)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.10+9-Ubuntu-0ubuntu1.18.04, mixed mode, sharing)\n",
            "setup Colab for PySpark 3.1.1 and Spark NLP 3.0.0\n",
            "\u001b[K     |████████████████████████████████| 212.3MB 61kB/s \n",
            "\u001b[K     |████████████████████████████████| 143kB 33.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 43.2MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v29AZ9XO5AhU"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "import sparknlp\n",
        "from sparknlp.pretrained import PretrainedPipeline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKf4YBDBZ9x7"
      },
      "source": [
        "## 2. Start Spark Session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sI-CZ9PO5GW9"
      },
      "source": [
        "spark = sparknlp.start()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXA24WIYaACJ"
      },
      "source": [
        "## 3. Select the DL model and re-run all the cells below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6s6ljDsH9ZK"
      },
      "source": [
        "### Select Model\n",
        "#model_name = 'classifierdl_use_trec6'\n",
        "model_name = 'classifierdl_use_trec50'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_-O5I9BaF08"
      },
      "source": [
        "## 4. Some sample examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGFzBK1EX8wm"
      },
      "source": [
        "\n",
        "text_list = [\n",
        "    \"What effect does pollution have on the Chesapeake Bay oysters?\",\n",
        "    \"What financial relationships exist between Google and its advertisers?\",\n",
        "    \"What financial relationships exist between the Chinese government and the Cuban government?\",\n",
        "    \"What was the number of member nations of the U.N. in 2000?\",\n",
        "    \"Who is the Secretary-General for political affairs?\",\n",
        "    \"When did the construction of stone circles begin in the UK?\",\n",
        "    \"In what country is the WTO headquartered?\",\n",
        "    \"What animal was the first mammal successfully cloned from adult cells?\",\n",
        "    \"What other prince showed his paintings in a two-prince exhibition with Prince Charles in London?\",\n",
        "    \"Is there evidence to support the involvement of Garry Kasparov in politics?\",\n",
        "  ]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULKvemZpaNal"
      },
      "source": [
        "## 5. Define Spark NLP pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2CS_jdi5Phc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c349cd6a-7637-4adc-88d9-99d296ea411d"
      },
      "source": [
        "documentAssembler = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "use = UniversalSentenceEncoder.pretrained(lang=\"en\") \\\n",
        " .setInputCols([\"document\"])\\\n",
        " .setOutputCol(\"sentence_embeddings\")\n",
        "\n",
        "\n",
        "document_classifier = ClassifierDLModel.pretrained(model_name, 'en') \\\n",
        "          .setInputCols([\"document\", \"sentence_embeddings\"]) \\\n",
        "          .setOutputCol(\"class\")\n",
        "\n",
        "nlpPipeline = Pipeline(stages=[\n",
        " documentAssembler, \n",
        " use,\n",
        " document_classifier\n",
        " ])\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tfhub_use download started this may take some time.\n",
            "Approximate size to download 923.7 MB\n",
            "[OK!]\n",
            "classifierdl_use_trec50 download started this may take some time.\n",
            "Approximate size to download 21.2 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZtgPiQPafLR"
      },
      "source": [
        "## 6. Run the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lr3DMHgd5Pk8"
      },
      "source": [
        "empty_df = spark.createDataFrame([['']]).toDF(\"text\")\n",
        "\n",
        "pipelineModel = nlpPipeline.fit(empty_df)\n",
        "df = spark.createDataFrame(pd.DataFrame({\"text\":text_list}))\n",
        "result = pipelineModel.transform(df)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GM8GfPB5aSCu"
      },
      "source": [
        "## 7. Visualize results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P84W1Z4uPI_b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db01e6ba-6ebe-4c06-e621-095ff2d05265"
      },
      "source": [
        "result.select(F.explode(F.arrays_zip('document.result', 'class.result')).alias(\"cols\")) \\\n",
        ".select(F.expr(\"cols['0']\").alias(\"document\"),\n",
        "        F.expr(\"cols['1']\").alias(\"class\")).show(truncate=False)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------------------------------------------------------------------------------------+------------+\n",
            "|document                                                                                        |class       |\n",
            "+------------------------------------------------------------------------------------------------+------------+\n",
            "|What effect does pollution have on the Chesapeake Bay oysters?                                  | DESC_desc  |\n",
            "|What financial relationships exist between Google and its advertisers?                          | DESC_desc  |\n",
            "|What financial relationships exist between the Chinese government and the Cuban government?     | DESC_desc  |\n",
            "|What was the number of member nations of the U.N. in 2000?                                      | NUM_count  |\n",
            "|Who is the Secretary-General for political affairs?                                             | HUM_ind    |\n",
            "|When did the construction of stone circles begin in the UK?                                     | LOC_other  |\n",
            "|In what country is the WTO headquartered?                                                       | LOC_other  |\n",
            "|What animal was the first mammal successfully cloned from adult cells?                          | HUM_ind    |\n",
            "|What other prince showed his paintings in a two-prince exhibition with Prince Charles in London?| HUM_ind    |\n",
            "|Is there evidence to support the involvement of Garry Kasparov in politics?                     | DESC_reason|\n",
            "+------------------------------------------------------------------------------------------------+------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}