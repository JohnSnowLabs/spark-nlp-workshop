{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER_PL.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXMyD8uSGrUy",
        "colab_type": "text"
      },
      "source": [
        "Set up virtual environment and import necessary modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGJktFHdHL1n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sudo apt-get install openjdk-8-jdk\n",
        "!java -version\n",
        "!pip install --ignore-installed -q pyspark==2.4.4\n",
        "!pip install spark-nlp\n",
        "!pip install streamlit\n",
        "!pip install googletrans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTDYhbeAGmdG",
        "colab_type": "text"
      },
      "source": [
        "Import necessary Python modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sw-t1zxlHTB7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "import googletrans\n",
        "from googletrans import Translator\n",
        "translator = Translator()\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "import sparknlp\n",
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "spark = sparknlp.start()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBOKkB2THdGI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_list = [\"\"\"William Henry Gates III (ur. 28 października 1955 r.) To amerykański magnat biznesowy, programista, inwestor i filantrop. Najbardziej znany jest jako współzałożyciel Microsoft Corporation. Podczas swojej kariery w Microsoft Gates zajmował stanowiska prezesa, dyrektora generalnego (CEO), prezesa i głównego architekta oprogramowania, będąc jednocześnie największym indywidualnym akcjonariuszem do maja 2014 r. Jest jednym z najbardziej znanych przedsiębiorców i pionierów rewolucja mikrokomputerowa lat 70. i 80. Urodzony i wychowany w Seattle w stanie Waszyngton, Gates był współzałożycielem Microsoftu z przyjacielem z dzieciństwa Paulem Allenem w 1975 roku w Albuquerque w Nowym Meksyku; stała się największą na świecie firmą produkującą oprogramowanie komputerowe. Gates prowadził firmę jako prezes i dyrektor generalny, aż do ustąpienia ze stanowiska dyrektora generalnego w styczniu 2000 r., Ale pozostał przewodniczącym i został głównym architektem oprogramowania. Pod koniec lat 90. Gates był krytykowany za taktykę biznesową, którą uważano za antykonkurencyjną. Opinię tę podtrzymują liczne orzeczenia sądowe. W czerwcu 2006 r. Gates ogłosił, że przejdzie do pracy w niepełnym wymiarze godzin w Microsoft i pracy w pełnym wymiarze godzin w Bill & Melinda Gates Foundation, prywatnej fundacji charytatywnej, którą on i jego żona Melinda Gates utworzyli w 2000 r. [ 9] Stopniowo przeniósł obowiązki na Raya Ozziego i Craiga Mundie. Zrezygnował z funkcji prezesa Microsoftu w lutym 2014 r. I objął nowe stanowisko jako doradca ds. Technologii, aby wesprzeć nowo mianowaną CEO Satyę Nadellę.\"\"\",\n",
        "             \"\"\"Mona Lisa to XVI-wieczny obraz olejny stworzony przez Leonarda. Odbywa się w Luwrze w Paryżu.\"\"\",\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7M0buHjTFhAb",
        "colab_type": "text"
      },
      "source": [
        "Change `MODEL_NAME` to use a different model. Change `LANG` to the language code of the language you want to use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLuDz_t40be4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_NAME = 'wikiner_6B_100'\n",
        "# MODEL_NAME = 'wikiner_6B_300'\n",
        "# MODEL_NAME = 'wikiner_840B_300'\n",
        "\n",
        "LANG = 'pl'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCusgrQEF_sa",
        "colab_type": "text"
      },
      "source": [
        "Create the pipeline to process the inputs. Selects a different `WordEmbeddingsModel` depending on the NER model chosen above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBggF5P8J1gc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "documentAssembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"text\") \\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "tokenizer = Tokenizer() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "# Select the appropriate WordEmbeddingsModel to match the NerDLModel.\n",
        "embeddings = None\n",
        "if MODEL_NAME == 'wikiner_6B_100':\n",
        "    embeddings = WordEmbeddingsModel.pretrained(name='glove_100d') \\\n",
        "        .setInputCols([\"document\", 'token']) \\\n",
        "        .setOutputCol(\"embeddings\")\n",
        "elif MODEL_NAME=='wikiner_6B_300':\n",
        "    embeddings = WordEmbeddingsModel.pretrained(name='glove_6B_300', lang='xx') \\\n",
        "        .setInputCols([\"document\", 'token']) \\\n",
        "        .setOutputCol(\"embeddings\")\n",
        "elif MODEL_NAME=='wikiner_840B_300':\n",
        "    embeddings = WordEmbeddingsModel.pretrained(name='glove_840B_300', lang='xx') \\\n",
        "        .setInputCols([\"document\", 'token']) \\\n",
        "        .setOutputCol(\"embeddings\")\n",
        "\n",
        "public_ner = NerDLModel.pretrained(MODEL_NAME, lang=LANG) \\\n",
        "    .setInputCols([\"document\", \"token\", \"embeddings\"]) \\\n",
        "    .setOutputCol(\"ner\")\n",
        "\n",
        "ner_converter = NerConverter() \\\n",
        "    .setInputCols([\"document\", \"token\", \"ner\"]) \\\n",
        "    .setOutputCol(\"ner_chunk\")\n",
        "\n",
        "nlpPipeline = Pipeline(stages=[documentAssembler, \n",
        "                               tokenizer,\n",
        "                               embeddings,\n",
        "                               public_ner,\n",
        "                               ner_converter])\n",
        "\n",
        "empty_df = spark.createDataFrame([['']]).toDF(\"text\")\n",
        "\n",
        "pipelineModel = nlpPipeline.fit(empty_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5GFZCutGZB1",
        "colab_type": "text"
      },
      "source": [
        "Use the pipeline to create outputs for the demo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ar32BZu7J79X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = spark.createDataFrame(pd.DataFrame({'text': text_list}))\n",
        "result = pipelineModel.transform(df)\n",
        "result.select(F.explode(\n",
        "    F.arrays_zip('ner_chunk.result', 'ner_chunk.metadata')) \\\n",
        "        .alias('cols')).select(F.expr(\"cols['0']\").alias('chunk'),\n",
        "    F.expr(\"cols['1']['entity']\").alias('ner_label')).show(truncate=False)\n",
        "result = result.toPandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcn5CYE8oGly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}