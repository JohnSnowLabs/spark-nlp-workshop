{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TA21Jo5d9SVq"
      },
      "source": [
        "\n",
        "\n",
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/T5TRANSFORMER_TRANSLATION.ipynb)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzIdjHkAW8TB"
      },
      "source": [
        "# **Text Translation using google's T5 Transformer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1sZkQkt3sXX"
      },
      "source": [
        "### Spark NLP documentation and instructions:\n",
        "https://nlp.johnsnowlabs.com/docs/en/quickstart\n",
        "\n",
        "### Spark NLP Google T5 Article \t\n",
        "https://towardsdatascience.com/hands-on-googles-text-to-text-transfer-transformer-t5-with-spark-nlp-6f7db75cecff\n",
        "\n",
        "### You can find details about Spark NLP annotators here:\n",
        "https://nlp.johnsnowlabs.com/docs/en/annotators\n",
        "\n",
        "### You can find details about Spark NLP models here:\n",
        "https://nlp.johnsnowlabs.com/models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIeCOiJNW-88"
      },
      "source": [
        "## 1. Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGJktFHdHL1n",
        "outputId": "b62d039c-9cd1-41b2-ac8f-2d494be0e955"
      },
      "outputs": [],
      "source": [
        "# Install PySpark and Spark NLP\n",
        "! pip install -q pyspark==3.1.2 spark-nlp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCIT5VLxS3I1"
      },
      "source": [
        "## 2. Start the Spark session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khjM-z9ORFU3"
      },
      "source": [
        "Import dependencies and start Spark session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sw-t1zxlHTB7"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "import sparknlp\n",
        "\n",
        "spark = sparknlp.start()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RgiqfX5XDqb"
      },
      "source": [
        "## 3. Select the DL model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPqBOgDhnvjB"
      },
      "source": [
        "For complete model list: \n",
        "https://nlp.johnsnowlabs.com/models\n",
        "\n",
        "For `T5` models:\n",
        "https://nlp.johnsnowlabs.com/models?tag=t5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQACwlw5dJT6"
      },
      "source": [
        "##4. Text Translation using T5 Transformer - English to German"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XftYgju4XOw_"
      },
      "source": [
        " Define Spark NLP pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBggF5P8J1gc",
        "outputId": "da7e2926-bd11-422a-e6dd-fb4cfbf55887"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sentence_detector_dl download started this may take some time.\n",
            "Approximate size to download 354.6 KB\n",
            "[OK!]\n",
            "t5_small download started this may take some time.\n",
            "Approximate size to download 139 MB\n",
            "[OK!]\n",
            "+---------------------------------------------------------+\n",
            "|result                                                   |\n",
            "+---------------------------------------------------------+\n",
            "|[Mein Name ist Spark NLP!, Es ist schön, Sie zu treffen.]|\n",
            "|[Mein Name ist Wolfgang und ich lebe in Berlin.]         |\n",
            "+---------------------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "document_assembler = DocumentAssembler()\\\n",
        ".setInputCol(\"text\")\\\n",
        ".setOutputCol(\"documents\")\n",
        "\n",
        "sentence_detector = SentenceDetectorDLModel().pretrained()\\\n",
        "  .setInputCols(\"documents\")\\\n",
        "  .setOutputCol(\"sentence\")\n",
        "  \n",
        "t5 = T5Transformer().pretrained(\"t5_small\", 'en') \\\n",
        "  .setInputCols([\"sentence\"]) \\\n",
        "  .setOutputCol(\"translation\")\\\n",
        "  .setTask(\"translate English to German:\")\\\n",
        "  .setMaxOutputLength(200)\n",
        "  \n",
        "pipeline = Pipeline(stages=[\n",
        "    document_assembler, \n",
        "    sentence_detector,\n",
        "    t5\n",
        "])\n",
        "\n",
        "data = spark.createDataFrame([\n",
        "  [1, \"My name is Spark NLP! It's nice to meet you.\"],\n",
        "  [2, \"My name is Wolfgang and I live in Berlin\"]\n",
        "]).toDF('id', 'text')\n",
        "\n",
        "results = pipeline.fit(data).transform(data)\n",
        "\n",
        "results.select(\"translation.result\").show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbTZ4OMDZWxe"
      },
      "source": [
        "##5. Text Translation using T5 Transformer - English to French"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FFPVzI2ZT02",
        "outputId": "2d9c6533-6062-4405-dba6-7d17dc5040b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sentence_detector_dl download started this may take some time.\n",
            "Approximate size to download 354.6 KB\n",
            "[OK!]\n",
            "t5_small download started this may take some time.\n",
            "Approximate size to download 139 MB\n",
            "[OK!]\n",
            "+------------------------------------------------------------+\n",
            "|result                                                      |\n",
            "+------------------------------------------------------------+\n",
            "|[Mon nom est Spark NLP!, C'est agréable de vous rencontrer.]|\n",
            "|[Mon nom est Wolfgang et je réside à Berlin.]               |\n",
            "+------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "document_assembler = DocumentAssembler()\\\n",
        ".setInputCol(\"text\")\\\n",
        ".setOutputCol(\"documents\")\n",
        "\n",
        "sentence_detector = SentenceDetectorDLModel().pretrained()\\\n",
        "  .setInputCols(\"documents\")\\\n",
        "  .setOutputCol(\"sentence\")\n",
        "  \n",
        "t5 = T5Transformer().pretrained(\"t5_small\", 'en') \\\n",
        "  .setInputCols([\"sentence\"]) \\\n",
        "  .setOutputCol(\"translation\")\\\n",
        "  .setTask(\"translate English to French:\")\\\n",
        "  .setMaxOutputLength(200)\n",
        "  \n",
        "pipeline = Pipeline(stages=[\n",
        "    document_assembler, \n",
        "    sentence_detector,\n",
        "    t5\n",
        "])\n",
        "\n",
        "data = spark.createDataFrame([\n",
        "  [1, \"My name is Spark NLP! It's nice to meet you.\"],\n",
        "  [2, \"My name is Wolfgang and I live in Berlin\"]\n",
        "]).toDF('id', 'text')\n",
        "\n",
        "results = pipeline.fit(data).transform(data)\n",
        "\n",
        "results.select(\"translation.result\").show(truncate=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "T5TRANSFORMER_TRANSLATION.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "45150093197569bb3a58481dcd32cd1adb45462fa3448719e8ac38ada6166aca"
    },
    "kernelspec": {
      "display_name": "Python 3.6.10 64-bit ('tensorflow2_p36': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
