{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "T5TRANSFORMER_TRANSLATION.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TA21Jo5d9SVq"
      },
      "source": [
        "\n",
        "\n",
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/T5TRANSFORMER_TRANSLATION.ipynb)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzIdjHkAW8TB"
      },
      "source": [
        "# **Text Translation using google's T5 Transformer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1sZkQkt3sXX"
      },
      "source": [
        "### Spark NLP documentation and instructions:\n",
        "https://nlp.johnsnowlabs.com/docs/en/quickstart\n",
        "\n",
        "### You can find details about Spark NLP annotators here:\n",
        "https://nlp.johnsnowlabs.com/docs/en/annotators\n",
        "\n",
        "### You can find details about Spark NLP models here:\n",
        "https://nlp.johnsnowlabs.com/models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIeCOiJNW-88"
      },
      "source": [
        "## 1. Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGJktFHdHL1n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf39d78d-81c6-4c89-ccb2-3f124e45afda"
      },
      "source": [
        "# Install java\n",
        "! apt-get update -qq\n",
        "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "! java -version\n",
        "\n",
        "# Install pyspark\n",
        "! pip install --ignore-installed -q pyspark==2.4.4\n",
        "\n",
        "# Install Spark NLP\n",
        "! pip install --ignore-installed spark-nlp==2.7.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"11.0.9.1\" 2020-11-04\n",
            "OpenJDK Runtime Environment (build 11.0.9.1+1-Ubuntu-0ubuntu1.18.04)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.9.1+1-Ubuntu-0ubuntu1.18.04, mixed mode, sharing)\n",
            "Collecting spark-nlp==2.7.0\n",
            "  Using cached https://files.pythonhosted.org/packages/cf/2c/0112881b86046b362592a7a9217d41894d857a1a0561dd4fd19a3d9c5791/spark_nlp-2.7.0-1-py2.py3-none-any.whl\n",
            "Installing collected packages: spark-nlp\n",
            "Successfully installed spark-nlp-2.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCIT5VLxS3I1"
      },
      "source": [
        "## 2. Start the Spark session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khjM-z9ORFU3"
      },
      "source": [
        "Import dependencies and start Spark session."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sw-t1zxlHTB7"
      },
      "source": [
        "import os\n",
        "import json\n",
        "os.environ['JAVA_HOME'] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "import sparknlp\n",
        "\n",
        "spark = sparknlp.start()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RgiqfX5XDqb"
      },
      "source": [
        "## 3. Select the DL model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPqBOgDhnvjB"
      },
      "source": [
        "For complete model list: \n",
        "https://nlp.johnsnowlabs.com/models\n",
        "\n",
        "For `T5` models:\n",
        "https://nlp.johnsnowlabs.com/models?tag=t5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQACwlw5dJT6"
      },
      "source": [
        "##4. Text Translation using T5 Transformer - English to German"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XftYgju4XOw_"
      },
      "source": [
        " Define Spark NLP pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBggF5P8J1gc",
        "outputId": "1db841b3-5663-46b5-eeb8-0f87bbc214e4"
      },
      "source": [
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "document_assembler = DocumentAssembler()\\\n",
        ".setInputCol(\"text\")\\\n",
        ".setOutputCol(\"documents\")\n",
        "\n",
        "sentence_detector = SentenceDetectorDLModel().pretrained()\\\n",
        "  .setInputCols(\"documents\")\\\n",
        "  .setOutputCol(\"sentence\")\n",
        "  \n",
        "t5 = T5Transformer().pretrained(\"t5_small\", 'en') \\\n",
        "  .setInputCols([\"sentence\"]) \\\n",
        "  .setOutputCol(\"translation\")\\\n",
        "  .setTask(\"translate English to German:\")\\\n",
        "  .setMaxOutputLength(200)\n",
        "  \n",
        "pipeline = Pipeline(stages=[\n",
        "    document_assembler, \n",
        "    sentence_detector,\n",
        "    t5\n",
        "])\n",
        "\n",
        "data = spark.createDataFrame([\n",
        "  [1, \"My name is Spark NLP! It's nice to meet you.\"],\n",
        "  [2, \"My name is Wolfgang and I live in Berlin\"]\n",
        "]).toDF('id', 'text')\n",
        "\n",
        "results = pipeline.fit(data).transform(data)\n",
        "\n",
        "results.select(\"translation.result\").show(truncate=False)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentence_detector_dl download started this may take some time.\n",
            "Approximate size to download 354.6 KB\n",
            "[OK!]\n",
            "t5_small download started this may take some time.\n",
            "Approximate size to download 168.7 MB\n",
            "[OK!]\n",
            "+---------------------------------------------------------+\n",
            "|result                                                   |\n",
            "+---------------------------------------------------------+\n",
            "|[Mein Name ist Spark NLP!, Es ist schön, Sie zu treffen.]|\n",
            "|[Mein Name ist Wolfgang und ich lebe in Berlin.]         |\n",
            "+---------------------------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbTZ4OMDZWxe"
      },
      "source": [
        "##5. Text Translation using T5 Transformer - English to French"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FFPVzI2ZT02",
        "outputId": "d869439f-ddd8-471c-bdab-70791a5c6ebc"
      },
      "source": [
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "document_assembler = DocumentAssembler()\\\n",
        ".setInputCol(\"text\")\\\n",
        ".setOutputCol(\"documents\")\n",
        "\n",
        "sentence_detector = SentenceDetectorDLModel().pretrained()\\\n",
        "  .setInputCols(\"documents\")\\\n",
        "  .setOutputCol(\"sentence\")\n",
        "  \n",
        "t5 = T5Transformer().pretrained(\"t5_small\", 'en') \\\n",
        "  .setInputCols([\"sentence\"]) \\\n",
        "  .setOutputCol(\"translation\")\\\n",
        "  .setTask(\"translate English to French:\")\\\n",
        "  .setMaxOutputLength(200)\n",
        "  \n",
        "pipeline = Pipeline(stages=[\n",
        "    document_assembler, \n",
        "    sentence_detector,\n",
        "    t5\n",
        "])\n",
        "\n",
        "data = spark.createDataFrame([\n",
        "  [1, \"My name is Spark NLP! It's nice to meet you.\"],\n",
        "  [2, \"My name is Wolfgang and I live in Berlin\"]\n",
        "]).toDF('id', 'text')\n",
        "\n",
        "results = pipeline.fit(data).transform(data)\n",
        "\n",
        "results.select(\"translation.result\").show(truncate=False)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentence_detector_dl download started this may take some time.\n",
            "Approximate size to download 354.6 KB\n",
            "[OK!]\n",
            "t5_small download started this may take some time.\n",
            "Approximate size to download 168.7 MB\n",
            "[OK!]\n",
            "+------------------------------------------------------------+\n",
            "|result                                                      |\n",
            "+------------------------------------------------------------+\n",
            "|[Mon nom est Spark NLP!, C'est agréable de vous rencontrer.]|\n",
            "|[Mon nom est Wolfgang et je vit à Berlin.]                  |\n",
            "+------------------------------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}