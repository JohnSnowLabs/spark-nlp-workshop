{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "T5TRANSFORMER_TRANSLATION.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TA21Jo5d9SVq"
      },
      "source": [
        "\n",
        "\n",
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/T5TRANSFORMER_TRANSLATION.ipynb)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzIdjHkAW8TB"
      },
      "source": [
        "# **Text Translation using google's T5 Transformer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1sZkQkt3sXX"
      },
      "source": [
        "### Spark NLP documentation and instructions:\n",
        "https://nlp.johnsnowlabs.com/docs/en/quickstart\n",
        "\n",
        "### Spark NLP Google T5 Article \t\n",
        "https://towardsdatascience.com/hands-on-googles-text-to-text-transfer-transformer-t5-with-spark-nlp-6f7db75cecff\n",
        "\n",
        "### You can find details about Spark NLP annotators here:\n",
        "https://nlp.johnsnowlabs.com/docs/en/annotators\n",
        "\n",
        "### You can find details about Spark NLP models here:\n",
        "https://nlp.johnsnowlabs.com/models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIeCOiJNW-88"
      },
      "source": [
        "## 1. Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGJktFHdHL1n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b62d039c-9cd1-41b2-ac8f-2d494be0e955"
      },
      "source": [
        "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash\n",
        "# !bash colab.sh\n",
        "# -p is for pyspark\n",
        "# -s is for spark-nlp\n",
        "# !bash colab.sh -p 3.1.1 -s 3.0.1\n",
        "# by default they are set to the latest"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"11.0.10\" 2021-01-19\n",
            "OpenJDK Runtime Environment (build 11.0.10+9-Ubuntu-0ubuntu1.18.04)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.10+9-Ubuntu-0ubuntu1.18.04, mixed mode, sharing)\n",
            "setup Colab for PySpark 3.1.1 and Spark NLP 3.0.0\n",
            "\u001b[K     |████████████████████████████████| 212.3MB 72kB/s \n",
            "\u001b[K     |████████████████████████████████| 143kB 47.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 41.8MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCIT5VLxS3I1"
      },
      "source": [
        "## 2. Start the Spark session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khjM-z9ORFU3"
      },
      "source": [
        "Import dependencies and start Spark session."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sw-t1zxlHTB7"
      },
      "source": [
        "import json\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "import sparknlp\n",
        "\n",
        "spark = sparknlp.start()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RgiqfX5XDqb"
      },
      "source": [
        "## 3. Select the DL model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPqBOgDhnvjB"
      },
      "source": [
        "For complete model list: \n",
        "https://nlp.johnsnowlabs.com/models\n",
        "\n",
        "For `T5` models:\n",
        "https://nlp.johnsnowlabs.com/models?tag=t5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQACwlw5dJT6"
      },
      "source": [
        "##4. Text Translation using T5 Transformer - English to German"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XftYgju4XOw_"
      },
      "source": [
        " Define Spark NLP pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBggF5P8J1gc",
        "outputId": "da7e2926-bd11-422a-e6dd-fb4cfbf55887"
      },
      "source": [
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "document_assembler = DocumentAssembler()\\\n",
        ".setInputCol(\"text\")\\\n",
        ".setOutputCol(\"documents\")\n",
        "\n",
        "sentence_detector = SentenceDetectorDLModel().pretrained()\\\n",
        "  .setInputCols(\"documents\")\\\n",
        "  .setOutputCol(\"sentence\")\n",
        "  \n",
        "t5 = T5Transformer().pretrained(\"t5_small\", 'en') \\\n",
        "  .setInputCols([\"sentence\"]) \\\n",
        "  .setOutputCol(\"translation\")\\\n",
        "  .setTask(\"translate English to German:\")\\\n",
        "  .setMaxOutputLength(200)\n",
        "  \n",
        "pipeline = Pipeline(stages=[\n",
        "    document_assembler, \n",
        "    sentence_detector,\n",
        "    t5\n",
        "])\n",
        "\n",
        "data = spark.createDataFrame([\n",
        "  [1, \"My name is Spark NLP! It's nice to meet you.\"],\n",
        "  [2, \"My name is Wolfgang and I live in Berlin\"]\n",
        "]).toDF('id', 'text')\n",
        "\n",
        "results = pipeline.fit(data).transform(data)\n",
        "\n",
        "results.select(\"translation.result\").show(truncate=False)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentence_detector_dl download started this may take some time.\n",
            "Approximate size to download 354.6 KB\n",
            "[OK!]\n",
            "t5_small download started this may take some time.\n",
            "Approximate size to download 139 MB\n",
            "[OK!]\n",
            "+---------------------------------------------------------+\n",
            "|result                                                   |\n",
            "+---------------------------------------------------------+\n",
            "|[Mein Name ist Spark NLP!, Es ist schön, Sie zu treffen.]|\n",
            "|[Mein Name ist Wolfgang und ich lebe in Berlin.]         |\n",
            "+---------------------------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbTZ4OMDZWxe"
      },
      "source": [
        "##5. Text Translation using T5 Transformer - English to French"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FFPVzI2ZT02",
        "outputId": "2d9c6533-6062-4405-dba6-7d17dc5040b4"
      },
      "source": [
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "document_assembler = DocumentAssembler()\\\n",
        ".setInputCol(\"text\")\\\n",
        ".setOutputCol(\"documents\")\n",
        "\n",
        "sentence_detector = SentenceDetectorDLModel().pretrained()\\\n",
        "  .setInputCols(\"documents\")\\\n",
        "  .setOutputCol(\"sentence\")\n",
        "  \n",
        "t5 = T5Transformer().pretrained(\"t5_small\", 'en') \\\n",
        "  .setInputCols([\"sentence\"]) \\\n",
        "  .setOutputCol(\"translation\")\\\n",
        "  .setTask(\"translate English to French:\")\\\n",
        "  .setMaxOutputLength(200)\n",
        "  \n",
        "pipeline = Pipeline(stages=[\n",
        "    document_assembler, \n",
        "    sentence_detector,\n",
        "    t5\n",
        "])\n",
        "\n",
        "data = spark.createDataFrame([\n",
        "  [1, \"My name is Spark NLP! It's nice to meet you.\"],\n",
        "  [2, \"My name is Wolfgang and I live in Berlin\"]\n",
        "]).toDF('id', 'text')\n",
        "\n",
        "results = pipeline.fit(data).transform(data)\n",
        "\n",
        "results.select(\"translation.result\").show(truncate=False)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentence_detector_dl download started this may take some time.\n",
            "Approximate size to download 354.6 KB\n",
            "[OK!]\n",
            "t5_small download started this may take some time.\n",
            "Approximate size to download 139 MB\n",
            "[OK!]\n",
            "+------------------------------------------------------------+\n",
            "|result                                                      |\n",
            "+------------------------------------------------------------+\n",
            "|[Mon nom est Spark NLP!, C'est agréable de vous rencontrer.]|\n",
            "|[Mon nom est Wolfgang et je réside à Berlin.]               |\n",
            "+------------------------------------------------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}