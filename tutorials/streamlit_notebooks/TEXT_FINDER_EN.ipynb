{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TEXT_FINDER_EN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISkb1pTfKDSp"
      },
      "source": [
        "\n",
        "\n",
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/streamlit_notebooks/TEXT_FINDER_EN.ipynb)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ylw8OtEPKpep"
      },
      "source": [
        "# **Find words/phrases in text using word and regex matching**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2gk3v2PK4Vw"
      },
      "source": [
        "**Demo of the following annotators:**\n",
        "\n",
        "\n",
        "* TextMatcher\n",
        "* RegexMatcher"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoUbB9IPKlba"
      },
      "source": [
        "## 1. Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6o8-g0tEqNz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "253d21e3-50b3-4457-e59e-ce907432ccf1"
      },
      "source": [
        "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash\n",
        "# !bash colab.sh\n",
        "# -p is for pyspark\n",
        "# -s is for spark-nlp\n",
        "# !bash colab.sh -p 3.1.1 -s 3.0.1\n",
        "# by default they are set to the latest"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"11.0.10\" 2021-01-19\n",
            "OpenJDK Runtime Environment (build 11.0.10+9-Ubuntu-0ubuntu1.18.04)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.10+9-Ubuntu-0ubuntu1.18.04, mixed mode, sharing)\n",
            "setup Colab for PySpark 3.1.1 and Spark NLP 3.0.0\n",
            "\u001b[K     |████████████████████████████████| 212.3MB 60kB/s \n",
            "\u001b[K     |████████████████████████████████| 143kB 34.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 49.8MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMmT9S6mE0ad"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "import sparknlp\n",
        "from sparknlp.pretrained import PretrainedPipeline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fXuHMb-LFdR"
      },
      "source": [
        "## 2. Start Spark Session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zBXbY_vE2ss"
      },
      "source": [
        "spark = sparknlp.start()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbyLBTOALJq_"
      },
      "source": [
        "## 3. Select annotator and re-run the cells below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XxHWemdE5hX"
      },
      "source": [
        "#MODEL_NAME='TextMatcher'\n",
        "MODEL_NAME='RegexMatcher'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLeaNmWILQLQ"
      },
      "source": [
        "## 4. Create some sample examples and desired regex/string matching queries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJ7GCD0pFDvP"
      },
      "source": [
        "## Generating Example Files ##\n",
        "text_list = [\"\"\"Quantum computing is the use of quantum-mechanical phenomena such as superposition and entanglement to perform computation. Computers that perform quantum computations are known as quantum computers. Quantum computers are believed to be able to solve certain computational problems, such as integer factorization (which underlies RSA encryption), substantially faster than classical computers. The study of quantum computing is a subfield of quantum information science. Quantum computing began in the early 1980s, when physicist Paul Benioff proposed a quantum mechanical model of the Turing machine. Richard Feynman and Yuri Manin later suggested that a quantum computer had the potential to simulate things that a classical computer could not. In 1994, Peter Shor developed a quantum algorithm for factoring integers that had the potential to decrypt RSA-encrypted communications. Despite ongoing experimental progress since the late 1990s, most researchers believe that \"fault-tolerant quantum computing is still a rather distant dream.\" In recent years, investment into quantum computing research has increased in both the public and private sector. On 23 October 2019, Google AI, in partnership with the U.S. National Aeronautics and Space Administration (NASA), published a paper in which they claimed to have achieved quantum supremacy. While some have disputed this claim, it is still a significant milestone in the history of quantum computing.\"\"\",\n",
        "             \"\"\"Instacart has raised a new round of financing that makes it one of the most valuable private companies in the U.S., leapfrogging DoorDash, Palantir and Robinhood. Amid surging demand for grocery delivery due to the coronavirus pandemic, Instacart has raised $225 million in a new funding round led by DST Global and General Catalyst. The round increases Instacart’s valuation to $13.7 billion, up from $8 billion when it last raised money in 2018.\"\"\",\n",
        "            ]\n",
        "\n",
        "exact_matches = ['Quantum', 'million', 'payments', 'index', 'market share', 'gap', 'market', 'measure', 'aspects', 'accounts', 'king' ]\n",
        "\n",
        "regex_rules = [\"\"\"Quantum\\s\\w+\"\"\", \"\"\"million\\s\\w+\"\"\", \"\"\"John\\s\\w+, followed by leader\"\"\", \"\"\"payment.*?\\s\"\"\", \"\"\"rall.*?\\s\"\"\", '\\d\\d\\d\\d', '\\d+ Years' ]\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9faZW7HLZfd"
      },
      "source": [
        "## 5. Save the queries in separate files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z83Hk7QHFFXD"
      },
      "source": [
        "if MODEL_NAME=='TextMatcher':\n",
        "  with open ('text_to_match.txt', 'w') as f:\n",
        "    for i in exact_matches:\n",
        "      f.write(i+'\\n')\n",
        "else:\n",
        "  with open ('regex_to_match.txt', 'w') as f:\n",
        "    for i in regex_rules:\n",
        "        f.write(i+'\\n')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWAPFBrgLj4l"
      },
      "source": [
        "## 6. Define Spark NLP pipleline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiYxv0mOFIcX"
      },
      "source": [
        "documentAssembler = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "    \n",
        "if MODEL_NAME=='TextMatcher':\n",
        "  tokenizer = Tokenizer() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"token\")\n",
        "  text_matcher = TextMatcher() \\\n",
        "      .setInputCols([\"document\",'token'])\\\n",
        "      .setOutputCol(\"matched_text\")\\\n",
        "      .setCaseSensitive(False)\\\n",
        "      .setEntities(path=\"text_to_match.txt\")\n",
        "\n",
        "  nlpPipeline = Pipeline(stages=[documentAssembler, \n",
        "                                 tokenizer,\n",
        "                                 text_matcher\n",
        "                                 ])\n",
        "else:\n",
        "  regex_matcher = RegexMatcher()\\\n",
        "    .setInputCols('document')\\\n",
        "    .setStrategy(\"MATCH_ALL\")\\\n",
        "    .setOutputCol(\"matched_text\")\\\n",
        "    .setExternalRules(path='regex_to_match.txt', delimiter=',')\n",
        "    \n",
        "\n",
        "  nlpPipeline = Pipeline(stages=[documentAssembler, \n",
        "                                 regex_matcher\n",
        "                                 ])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgj7Q29wL3Xf"
      },
      "source": [
        "## 7. Run the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-xUenm5L0Lk"
      },
      "source": [
        "empty_df = spark.createDataFrame([['']]).toDF(\"text\")\n",
        "\n",
        "pipelineModel = nlpPipeline.fit(empty_df)\n",
        "\n",
        "df = spark.createDataFrame(pd.DataFrame({'text':text_list}))\n",
        "result = pipelineModel.transform(df)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3Plj6OQL5qU"
      },
      "source": [
        "## 8. Visualize results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4ACcIXqGkfl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b0cae16-2017-4164-d99b-09cc18c5b71b"
      },
      "source": [
        "result.select(F.explode(F.arrays_zip('matched_text.result', 'matched_text.metadata')).alias(\"cols\")) \\\n",
        ".select(\n",
        "        F.expr(\"cols['0']\").alias(\"Matches Found\"),\n",
        "        F.expr(\"cols['1']['identifier']\").alias(\"matching_regex/string\"),\n",
        "        ).show(truncate=False)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------+---------------------+\n",
            "|Matches Found    |matching_regex/string|\n",
            "+-----------------+---------------------+\n",
            "|Quantum computing|Quantum\\s\\w+         |\n",
            "|Quantum computers|Quantum\\s\\w+         |\n",
            "|Quantum computing|Quantum\\s\\w+         |\n",
            "|1980             |\\d\\d\\d\\d             |\n",
            "|1994             |\\d\\d\\d\\d             |\n",
            "|1990             |\\d\\d\\d\\d             |\n",
            "|2019             |\\d\\d\\d\\d             |\n",
            "|million in       |million\\s\\w+         |\n",
            "|2018             |\\d\\d\\d\\d             |\n",
            "+-----------------+---------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}