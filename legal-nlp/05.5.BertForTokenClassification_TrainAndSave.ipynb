{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "RDayMKT-fgKA"
      },
      "source": [
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lB2EDmGdTUs2"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/legal-nlp/05.5.BertForTokenClassification_TrainAndSave.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PaR_Jxcek01"
      },
      "source": [
        "# Legal BertForTokenClassification\n",
        "Using Hugging Face and importing it to Legal NLP for scalability.\n",
        "\n",
        "This is a transformer-based approach, which usually returns much bigger models (10x) compared to NerModel, but it can improve the performance over NerModel. We don't carry out evaluation in this notebook, only training with full data and export into Spark NLP. To check evaluation, please check previous notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lPn3DiN72gO"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zoMfNqgRtLOg"
      },
      "outputs": [],
      "source": [
        "! pip -q install seqeval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwIqbitFoHtq"
      },
      "outputs": [],
      "source": [
        "! pip install transformers==4.8.1\n",
        "! pip install pyspark==3.1.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bp6w0FyRfIgX"
      },
      "source": [
        "# Setting name of the project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85VnDQRj5QuX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['PROJECT_NAME'] = 'legal_obligations'\n",
        "PROJECT_NAME = os.getenv('PROJECT_NAME')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "iCdSFJbE5tcw",
        "outputId": "052eefa6-807a-4c48-9e42-29551c870cde"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'legal_obligations'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "PROJECT_NAME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEvXZO_TuhkH"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9Yxer2wuizZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertTokenizer, BertConfig\n",
        "\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import files\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "import transformers\n",
        "from transformers import BertForTokenClassification, TFBertForTokenClassification, AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZVF2kvevCGZ"
      },
      "source": [
        "## Setting up Torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "48k2DViAvEMe",
        "outputId": "3457945f-a61f-4b17-ee24-64398c39c480"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.13.1+cu116'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "F3rwT34cw0Mv",
        "outputId": "386d4eed-08cd-46b3-efff-9fb19d629543"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla T4'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "\n",
        "torch.cuda.get_device_name(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXgdr64B79_d"
      },
      "source": [
        "# Check that files are available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZNIdLN6TUs9"
      },
      "outputs": [],
      "source": [
        "! wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/legal-nlp/data/conll_noO.conll"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fe7x0snlYCxY",
        "outputId": "9459c9f7-918b-4534-f523-d35d962a068a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "head: cannot open 'conll_noO.conll' for reading: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!head -n 20 conll_noO.conll"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8H1P-jwe8CF"
      },
      "source": [
        "# Creating folders for logs and checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Tbd2bI9hkUn"
      },
      "outputs": [],
      "source": [
        "! mkdir {PROJECT_NAME}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUc4B7NThUK3"
      },
      "outputs": [],
      "source": [
        "! mkdir {PROJECT_NAME}/logs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTUf3GUWuslz"
      },
      "source": [
        "# Starting a Spark Session for SparkNLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuCfCrbK6eWq"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "license_keys = files.upload()\n",
        "\n",
        "with open(list(license_keys.keys())[0]) as f:\n",
        "    license_keys = json.load(f)\n",
        "\n",
        "# Defining license key-value pairs as local variables\n",
        "locals().update(license_keys)\n",
        "\n",
        "# Adding license key-value pairs to environment variables\n",
        "os.environ.update(license_keys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frvjijxroKy9",
        "outputId": "7ecc12bd-e0b4-4bea-c48e-f9227a8b7c33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m448.4/448.4 KB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m358.9/358.9 KB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.6/95.6 KB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.9/66.9 KB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Installing pyspark and spark-nlp\n",
        "! pip install --upgrade -q pyspark==3.1.2 spark-nlp==$PUBLIC_VERSION\n",
        "\n",
        "# Installing Spark NLP Healthcare\n",
        "! pip install --upgrade -q spark-nlp-jsl==$JSL_VERSION  --extra-index-url https://pypi.johnsnowlabs.com/$SECRET\n",
        "\n",
        "# Installing Spark NLP Display Library for visualization\n",
        "! pip install -q spark-nlp-display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "IJ4Dg2ZesrEi",
        "outputId": "e8046a10-8587-4128-9612-28cebaf4355d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Spark NLP Version : 4.2.4\n",
            "Spark NLP_JSL Version : 4.2.4\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://b193d989552b:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark NLP Licensed</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f5faa7f5ee0>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "import sparknlp\n",
        "import sparknlp_jsl\n",
        "\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp_jsl.annotator import *\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.ml import Pipeline,PipelineModel\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "params = {\"spark.driver.memory\":\"16G\", \n",
        "          \"spark.kryoserializer.buffer.max\":\"2000M\", \n",
        "          \"spark.driver.maxResultSize\":\"2000M\"} \n",
        "\n",
        "print(\"Spark NLP Version :\", sparknlp.version())\n",
        "print(\"Spark NLP_JSL Version :\", sparknlp_jsl.version())\n",
        "\n",
        "spark = sparknlp_jsl.start(license_keys['SECRET'],params=params)\n",
        "\n",
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrwN2hCR8HH6"
      },
      "source": [
        "# Convert JSL conlls in dataframe format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBBV98gqo90p"
      },
      "outputs": [],
      "source": [
        "from sparknlp.training import CoNLL\n",
        "\n",
        "def get_conll_df(pth):\n",
        "  data = CoNLL().readDataset(spark, pth)\n",
        "  data = data.withColumn(\"sentence_idx\", F.monotonically_increasing_id())\n",
        "\n",
        "  df = data.select('sentence_idx', F.explode(F.arrays_zip('token.result','label.result','pos.result')).alias(\"cols\")) \\\n",
        "  .select('sentence_idx',\n",
        "          F.expr(\"cols['0']\").alias(\"word\"),\n",
        "          F.expr(\"cols['1']\").alias(\"tag\"),\n",
        "          F.expr(\"cols['2']\").alias(\"pos\")).toPandas()\n",
        "  return df\n",
        "\n",
        "train_data_df = get_conll_df('./conll_noO.conll')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pg3k2mCMqsaY",
        "outputId": "aedb6620-442f-4b76-de47-2a6f830b4c6d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "O            71670\n",
              "I-PARTY      12097\n",
              "B-PARTY       5804\n",
              "I-DOC         3203\n",
              "B-DOC         2007\n",
              "B-DATE        1796\n",
              "B-LAW          782\n",
              "B-ROLE         316\n",
              "B-LOC          259\n",
              "B-ORDINAL      151\n",
              "B-PERCENT      136\n",
              "B-PERSON        92\n",
              "I-EFFDATE       33\n",
              "B-EFFDATE       18\n",
              "Name: tag, dtype: int64"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data_df['tag'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lu_Kwnh28jMZ"
      },
      "source": [
        "# First, train / fine-tune a model on the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rmgghg5ZvQNE"
      },
      "source": [
        "## Iterating function to feed the model with sentences\n",
        "Converting conll sentence annotations to tuples (word, pos, tag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JM2VMINvlpbM"
      },
      "outputs": [],
      "source": [
        "## convert conll file to sentences\n",
        "\n",
        "class SentenceGetter(object):\n",
        "    \n",
        "    def __init__(self, dataset):\n",
        "        self.n_sent = 1\n",
        "        self.dataset = dataset\n",
        "        self.empty = False\n",
        "        agg_func = lambda s: [(w,p, t) for w,p, t in zip(s[\"word\"].values.tolist(),\n",
        "                                                       s['pos'].values.tolist(),\n",
        "                                                        s[\"tag\"].values.tolist())]\n",
        "        self.grouped = self.dataset.groupby(\"sentence_idx\").apply(agg_func)\n",
        "        self.sentences = [s for s in self.grouped]\n",
        "    \n",
        "    def get_next(self):\n",
        "        try:\n",
        "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
        "            self.n_sent += 1\n",
        "            return s\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "train_getter = SentenceGetter(train_data_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIirptrGvzx5"
      },
      "source": [
        "## Getting sentences and labels\n",
        "- Sentences: concatenation of first element of tuple (word)\n",
        "- Labels: concatenation of second element of tuple (label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NqDzKVaqnfC",
        "outputId": "9e909af1-3230-42b3-e3c7-d8ef8894cb64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example of train sentence:\n",
            "['3.2', '__________', '(\"Professional\")', 'Default', '7']\n",
            "Example of train sentence:\n",
            "['O', 'B-PARTY', 'I-PARTY', 'O', 'O']\n"
          ]
        }
      ],
      "source": [
        "# Sentences \n",
        "train_sentences = [[word[0] for word in sentence] for sentence in train_getter.sentences]\n",
        "print(\"Example of train sentence:\")\n",
        "print (train_sentences[5])\n",
        "\n",
        "# Labels\n",
        "train_labels = [[s[2] for s in sentence] for sentence in train_getter.sentences]\n",
        "print(\"Example of train sentence:\")\n",
        "print(train_labels[5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_348YlM6wIVF"
      },
      "source": [
        "## Converting tags to numeric values with a dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TQ27sykwKV9"
      },
      "outputs": [],
      "source": [
        "tag_values = list(set(train_data_df[\"tag\"].values))\n",
        "tag_values.append(\"PAD\")\n",
        "tag2idx = {t: i for i, t in enumerate(tag_values)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sRlF42ltmxP",
        "outputId": "41abec10-61ad-4587-a6c7-f4a3dce7cc38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['B-ROLE', 'B-EFFDATE', 'B-DATE', 'B-PERCENT', 'B-DOC', 'B-LAW', 'B-ORDINAL', 'B-LOC', 'I-PARTY', 'B-PERSON']\n",
            "{'B-ROLE': 0, 'B-EFFDATE': 1, 'B-DATE': 2, 'B-PERCENT': 3, 'B-DOC': 4, 'B-LAW': 5, 'B-ORDINAL': 6, 'B-LOC': 7, 'I-PARTY': 8, 'B-PERSON': 9, 'B-PARTY': 10, 'I-EFFDATE': 11, 'I-DOC': 12, 'O': 13, 'PAD': 14}\n"
          ]
        }
      ],
      "source": [
        "print(tag_values[:10])\n",
        "print(tag2idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQpgb6uNwTon"
      },
      "source": [
        "## Model metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llhtW7cwwXdp"
      },
      "source": [
        "### Bulding on top of biobert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRrXpP6eQvF1"
      },
      "outputs": [],
      "source": [
        "MODEL_TO_TRAIN = 'zlucia/custom-legalbert'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPQ1iXCkwdaZ"
      },
      "source": [
        "### Hyperparam settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WY1vbXSdqyCJ"
      },
      "outputs": [],
      "source": [
        "# Defining some key variables that will be used later on in the training\n",
        "MAX_LEN = 256\n",
        "TRAIN_BATCH_SIZE = 32\n",
        "VALID_BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "LEARNING_RATE = 2e-05"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHkpIa-RuXH9"
      },
      "source": [
        "## Instantiating the proper tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7qZPhQrPQWY"
      },
      "source": [
        "IMPORTANT! Pay attention to the `do_lower_case` param, and set it to True if you have a lowercased language model. That means you will always need to do `lower()` on your inference texts!\n",
        "\n",
        "If the language model is not lowercase only, then leave it to False."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "15013af43f8e484284a7995f95bff6c9",
            "16c30c8ea4dd46bba3e4ecc63cd89dc4",
            "8fcfcbaa34494b18abf4824bef943de4",
            "2538250adebd45018e11108ec9ede170",
            "01dbc4f65e8945ad893e078a2b8f0868",
            "595a14280e1145b09072a76baf203bbe",
            "15a4f465dcfb4a289f872fc55594ec0e",
            "a0022dc48e944433bef84d94c743ed0e",
            "10dd2aad97fd4467adffa4b2679b1136",
            "b51fc841c9f64bf9948989910fdd43ea",
            "92874130f4c541abaa3fe063d091d21d",
            "73a4c1426da44ba98c13fbeca2812ad2",
            "77f328e10d5148e9811780dea869ad17",
            "1278a42d7b8644aabcba413b9b4c741b",
            "72932b5972404649b61c397e2d1c9639",
            "9dc630fd21ad4823a2b326a207cd3904",
            "2ec93b1749964695ad3cdf13414e333d",
            "3e8e36f6a61b46ebbd74fa2e96f2f946",
            "db617bb685c84bb99ad40cc9fb7e9d48",
            "1899ce44d52842fdbd6d6370bfe0cb4b",
            "4d05925973784a4e8b4b67611935a14a",
            "a7a6c566426d40f6bc36439db30b47bc",
            "8021e1bc11f34513b1aefa64cf1c5de4",
            "deb60921f6b14396814a0a63c031ea14",
            "f0a85bc5dac74c648f5cb99fe11dcdf1",
            "3c515e4406584d1b94af0f42ee9771cc",
            "3c3f29e6367040afb431a4fa4c67a22d",
            "8068f04e3de9477d93301e33dc4b26a0",
            "4a6b26c3941147b4bbc6e9379af27c43",
            "00382dc9319e44a0a60acce6c891c70b",
            "0edfa06cfb8f4f2f9dc865ac9bd5c8fe",
            "4574a150faf0410ca05267bc4baeea0f",
            "2759b58d0adb47a094d3d1a5df80f84c"
          ]
        },
        "id": "GCNyWqxbuZ0U",
        "outputId": "28ae3913-5d78-4f6a-8d90-b947fba09f8b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "15013af43f8e484284a7995f95bff6c9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/251k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "73a4c1426da44ba98c13fbeca2812ad2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8021e1bc11f34513b1aefa64cf1c5de4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/307 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(MODEL_TO_TRAIN, do_lower_case=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZ9qgZthxDpf"
      },
      "source": [
        "### Tokenize and extend the labels in case a word is split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vgplIBl7xIeU"
      },
      "outputs": [],
      "source": [
        "def tokenize_and_preserve_labels(sentence, text_labels):\n",
        "    tokenized_sentence = []\n",
        "    labels = []\n",
        "\n",
        "    for word, label in zip(sentence, text_labels):\n",
        "\n",
        "        # Tokenize the word and count # of subwords the word is broken into\n",
        "        tokenized_word = tokenizer.tokenize(word)\n",
        "        n_subwords = len(tokenized_word)\n",
        "\n",
        "        # Add the tokenized word to the final tokenized word list\n",
        "        tokenized_sentence.extend(tokenized_word)\n",
        "\n",
        "        # Add the same label to the new list of labels `n_subwords` times\n",
        "        labels.extend([label] * n_subwords)\n",
        "\n",
        "    return tokenized_sentence, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wv2q3gLOxMLo"
      },
      "source": [
        "## Tokenize and get tokens and labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "It320LLkFve9"
      },
      "outputs": [],
      "source": [
        "train_tokenized_texts_and_labels = [\n",
        "    tokenize_and_preserve_labels(sent, labs)\n",
        "    for sent, labs in zip(train_sentences, train_labels)\n",
        "]\n",
        "\n",
        "train_tokenized_texts_tokens = [token_label_pair[0] for token_label_pair in train_tokenized_texts_and_labels]\n",
        "\n",
        "train_tokenized_texts_labels = [token_label_pair[1] for token_label_pair in train_tokenized_texts_and_labels]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZil3Wfrxm9y",
        "outputId": "c4a98930-6361-4cbb-de64-9fdb0811f0da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['3', '[UNK]', '2', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '7']\n",
            "['O', 'O', 'O', 'B-PARTY', 'B-PARTY', 'B-PARTY', 'B-PARTY', 'B-PARTY', 'B-PARTY', 'B-PARTY', 'B-PARTY', 'B-PARTY', 'B-PARTY', 'I-PARTY', 'I-PARTY', 'I-PARTY', 'I-PARTY', 'I-PARTY', 'O', 'O']\n"
          ]
        }
      ],
      "source": [
        "print(train_tokenized_texts_tokens[5])\n",
        "print(train_tokenized_texts_labels[5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDKbLrQnxQCV"
      },
      "source": [
        "## Converting tokens to id && padding sentences to have fixed length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6m89dg_yx5gN"
      },
      "outputs": [],
      "source": [
        "train_input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in train_tokenized_texts_tokens],\n",
        "                          maxlen=MAX_LEN, dtype=\"long\", value=0.0,\n",
        "                          truncating=\"post\", padding=\"post\")\n",
        "\n",
        "train_tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in train_tokenized_texts_labels],\n",
        "                     maxlen=MAX_LEN, value=tag2idx[\"PAD\"], padding=\"post\",\n",
        "                     dtype=\"long\", truncating=\"post\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-bX2-QMx6GJ",
        "outputId": "544320ad-6dbf-4282-8134-b7184d0fcd96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[149   1 110   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n",
            "   1 352   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0]\n",
            "[13 13 13 10 10 10 10 10 10 10 10 10 10  8  8  8  8  8 13 13 14 14 14 14\n",
            " 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n",
            " 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n",
            " 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n",
            " 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n",
            " 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n",
            " 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n",
            " 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n",
            " 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n",
            " 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n",
            " 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14]\n"
          ]
        }
      ],
      "source": [
        "print(train_input_ids[5])\n",
        "print(train_tags[5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2lX8dW0x44u"
      },
      "source": [
        "## Now that sentences are padded, I need to prevent attention from seeing pads (id=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npO2QNUqyVM3"
      },
      "outputs": [],
      "source": [
        "train_attention_masks = [[float(i != 0.0) for i in ii] for ii in train_input_ids]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4utRy9BycD9",
        "outputId": "b3d2e384-aa2b-431f-cb09-3ca7a461cc81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ]
        }
      ],
      "source": [
        "print(train_attention_masks[5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfjyEjT_z4p9"
      },
      "source": [
        "### Double checking that pairing input-mask is in place"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdVBi7wXzo-Y",
        "outputId": "bcfc6362-a276-411b-b751-2bf00424df09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token id: 149\\Token mask: 1.0\n",
            "Token id: 1\\Token mask: 1.0\n",
            "Token id: 110\\Token mask: 1.0\n",
            "Token id: 1\\Token mask: 1.0\n",
            "Token id: 1\\Token mask: 1.0\n",
            "Token id: 1\\Token mask: 1.0\n",
            "Token id: 1\\Token mask: 1.0\n",
            "Token id: 1\\Token mask: 1.0\n",
            "Token id: 1\\Token mask: 1.0\n",
            "Token id: 1\\Token mask: 1.0\n",
            "Token id: 1\\Token mask: 1.0\n",
            "Token id: 1\\Token mask: 1.0\n",
            "Token id: 1\\Token mask: 1.0\n",
            "Token id: 1\\Token mask: 1.0\n",
            "Token id: 1\\Token mask: 1.0\n",
            "Token id: 1\\Token mask: 1.0\n",
            "Token id: 1\\Token mask: 1.0\n",
            "Token id: 1\\Token mask: 1.0\n",
            "Token id: 1\\Token mask: 1.0\n",
            "Token id: 352\\Token mask: 1.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n",
            "Token id: 0\\Token mask: 0.0\n"
          ]
        }
      ],
      "source": [
        "for i,m in zip(train_input_ids[5], train_attention_masks[5]):\n",
        "  print(f\"Token id: {i}\\Token mask: {m}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDJYhS1BzTcl"
      },
      "source": [
        "## Arrays to tensors transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6rVCtHUxRXB"
      },
      "outputs": [],
      "source": [
        "tr_inputs = torch.tensor(train_input_ids)\n",
        "tr_tags = torch.tensor(train_tags)\n",
        "tr_masks = torch.tensor(train_attention_masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jrBOkO-dfFR",
        "outputId": "e820a074-f3a1-4d1f-9c13-70775fce730e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([149,   1, 110,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
            "          1,   1,   1,   1,   1, 352,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "          0,   0,   0,   0])\n",
            "tensor([13, 13, 13, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,  8,  8,  8,  8,  8,\n",
            "        13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
            "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
            "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
            "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
            "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
            "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
            "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
            "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
            "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
            "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
            "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
            "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
            "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
            "        14, 14, 14, 14])\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0.])\n"
          ]
        }
      ],
      "source": [
        "print(tr_inputs[5])\n",
        "print(tr_tags[5])\n",
        "print(tr_masks[5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVWFGl4VeGi0"
      },
      "source": [
        "### Checking sizes match"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57W4P6CWeZ-s"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrJVCikMeSvl",
        "outputId": "8d1e41c7-c665-42ad-c2f0-e7211f9cb89e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len([x for x in tr_inputs[5] if x != 0]) # How many NO_PADs we have?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dbu7RaJEeUas",
        "outputId": "094977bd-2c2a-419b-97ff-a4b4906465e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len([x for x in tr_tags[5] if x != 7])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea9OBwxdeXXN",
        "outputId": "a5ec4cfa-037d-43ad-a622-70e5799758ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len([x for x in tr_masks[5] if x != 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3j86Os-Y0UpL"
      },
      "source": [
        "## Creating the DataLoaders to feed the batches during training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EncfL9XT0YJv"
      },
      "outputs": [],
      "source": [
        "train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=TRAIN_BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Vpu3C-x0kZn"
      },
      "source": [
        "# Loading the transformer model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "b66ISUfG0yx_",
        "outputId": "1c81c802-7d02-4c65-f04f-ccda86ca11c7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'4.8.1'"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformers.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "80409f477740440eb69b4762af3ba4b2",
            "68fbac8b54a64f7195c96654151b1953",
            "df133be0df674ff1bb4e5ea10f52ec88",
            "9ab99564baa34cf89280e2a03bc7747c",
            "5103d5567228445c97e947c85f94d399",
            "f4b9f6ba0600493488e61863f9146dc6",
            "8ee17313274a4303bb023a92ed4bb2c7",
            "d5bb7d30484c4483bf53703a7a0653c5",
            "fcef13290dac462a8ba286c3547235d3",
            "103ffe768c414ff3b13a6433719436be",
            "5c7a210beedd4120a638e9d3834cfede",
            "524659446d9b4c1690567072bc4d425b",
            "cf5461223f674c05b48448c46d7f2786",
            "953e11b0dba547399b28819c3b52a783",
            "ff498bd1f3b54de58a8e14cc89bbbbf2",
            "fc9c095da28a4c87b120b8db0376f720",
            "1bd42f5f2573412e8e50db4d9788f279",
            "448bac8812ea4f32a06ece3ac820ac55",
            "0c463d47dc964b29a6bb3c5da0104d97",
            "6541c7e99d8343c681f35b69c74d1f53",
            "de49351967194653b99be7a6419c5e24",
            "85efef210d6c451abd27cdc414a976f9"
          ]
        },
        "id": "ba70EsrqGD_u",
        "outputId": "5ef2ba0f-90a0-4f40-c335-9aa19590da5b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "80409f477740440eb69b4762af3ba4b2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/747 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "524659446d9b4c1690567072bc4d425b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/445M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at zlucia/custom-legalbert were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at zlucia/custom-legalbert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BertForTokenClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=15, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = transformers.BertForTokenClassification.from_pretrained(\n",
        "    MODEL_TO_TRAIN,\n",
        "    num_labels=len(tag2idx),\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False\n",
        ")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPsQIx1T1C1P"
      },
      "source": [
        "## Setting up the optimizer.\n",
        "We want to optimize weight values, so we add a decay.\n",
        "We can get all the weights from `model_named_parameters()`\n",
        "But we need to remove `bias`, `gamma` and `beta` which are Layer Normalization parameters we don't want to touch.\n",
        "\n",
        "Activate `FULL_TINETUNING` to modify weights in all the layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i60zq9ZAGWBk"
      },
      "outputs": [],
      "source": [
        "FULL_FINETUNING = True\n",
        "if FULL_FINETUNING:\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = ['bias', 'gamma', 'beta']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.01},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.0}\n",
        "    ]\n",
        "else:\n",
        "    param_optimizer = list(model.classifier.named_parameters())\n",
        "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
        "\n",
        "optimizer = AdamW(\n",
        "    optimizer_grouped_parameters,\n",
        "    lr=3e-5,\n",
        "    eps=1e-8\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o107IXiT7e6F"
      },
      "source": [
        "## Setting up the scheduler\n",
        "It will manage Optimizer and Learning Rate changes. We use warmup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_XaydBy7iac"
      },
      "outputs": [],
      "source": [
        "epochs = EPOCHS\n",
        "max_grad_norm = 1.0\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYMOIBG0Jkx1"
      },
      "source": [
        "Now, let's train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XC7Fro7bGWI5",
        "outputId": "8c0bcd71-d7a2-4dae-b0c8-0b9fad197a47"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  10%|█         | 1/10 [03:22<30:26, 202.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average train loss: 0.7635179566349953\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  20%|██        | 2/10 [06:50<27:24, 205.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping saving...\n",
            "Average train loss: 0.4833310178131055\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  30%|███       | 3/10 [10:18<24:06, 206.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping saving...\n",
            "Average train loss: 0.41091928332094935\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  40%|████      | 4/10 [13:46<20:44, 207.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping saving...\n",
            "Average train loss: 0.36955780217981643\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  50%|█████     | 5/10 [17:15<17:18, 207.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping saving...\n",
            "Average train loss: 0.34037239764146743\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  60%|██████    | 6/10 [20:50<14:00, 210.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average train loss: 0.31846392676708807\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  70%|███████   | 7/10 [24:18<10:28, 209.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping saving...\n",
            "Average train loss: 0.2995346155326078\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  80%|████████  | 8/10 [27:46<06:58, 209.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping saving...\n",
            "Average train loss: 0.2846814949706102\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpoch:  90%|█████████ | 9/10 [31:14<03:28, 208.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping saving...\n",
            "Average train loss: 0.27382213812155326\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 10/10 [34:41<00:00, 208.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping saving...\n",
            "Average train loss: 0.26729425223200187\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "## Store the average loss after each epoch so we can plot them.\n",
        "loss_values, validation_loss_values = [], []\n",
        "\n",
        "for EPOCH in trange(epochs, desc=\"Epoch\"):\n",
        "    # Put the model into training mode.\n",
        "    model.train()\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Training loop\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # add batch to gpu\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        # Always clear any previously calculated gradients before performing a backward pass.\n",
        "        model.zero_grad()\n",
        "        # forward pass\n",
        "        # This will return the loss (rather than the model output)\n",
        "        # because we have provided the `labels`.\n",
        "        outputs = model(b_input_ids, token_type_ids=None,\n",
        "                        attention_mask=b_input_mask, labels=b_labels)\n",
        "        # get the loss\n",
        "        loss = outputs[0]\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "        # track train loss\n",
        "        total_loss += loss.item()\n",
        "        # Clip the norm of the gradient\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    tr_loss = f\"Average train loss: {str(avg_train_loss)}\\n\"\n",
        "\n",
        "    if EPOCH % 5 == 0:\n",
        "      # Saving partial models (this creates the folder too)    \n",
        "      tokenizer.save_pretrained(f'{PROJECT_NAME}/{str(EPOCH)}/tokenizer/')\n",
        "      model.save_pretrained(save_directory=f'{PROJECT_NAME}/{str(EPOCH)}/',\n",
        "                            save_config=True, state_dict=model.state_dict)\n",
        "      # Saving checkpoint in case it crashes, to restore work\n",
        "      torch.save({\n",
        "          'epoch': EPOCH,\n",
        "          'model_state_dict': model.state_dict(),\n",
        "          'optimizer_state_dict': optimizer.state_dict(),\n",
        "          'loss': avg_train_loss,\n",
        "          }, f'{PROJECT_NAME}/{str(EPOCH)}/checkpoint.pth')\n",
        "    else:\n",
        "      print(\"Skipping saving...\")\n",
        "\n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "    \n",
        "    if EPOCH % 5 == 0:\n",
        "      # Saving losses log\n",
        "      with open(f'{PROJECT_NAME}/logs/epoch_' + str(EPOCH) + '_loss.log', 'a') as f:\n",
        "        f.write(tr_loss)\n",
        "\n",
        "    # Printing also to stdout\n",
        "    print(tr_loss)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czwipZWe-Esi"
      },
      "source": [
        "## Now load the model as TF and save properly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFNcOvu2MjWx"
      },
      "outputs": [],
      "source": [
        "last_successfull_epoch = len(loss_values) - 1\n",
        "if last_successfull_epoch < 0:\n",
        "  last_successfull_epoch = None "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1rQ4Dat-AVJ",
        "outputId": "48663f40-69fc-4f29-a5ba-94a15d546773"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Last successfull epoch: 9\n"
          ]
        }
      ],
      "source": [
        "if last_successfull_epoch is None:\n",
        "  print(\"No epochs finished successfully.\")\n",
        "else:\n",
        "  print(f\"Last successfull epoch: {str(last_successfull_epoch)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87TWLuiY-Gr7"
      },
      "outputs": [],
      "source": [
        "# first save the model as pytorch model (we'll cast later)\n",
        "MODEL_NAME_PYTORCH = 'model_epoch_'+str(last_successfull_epoch)+'_pytorch'\n",
        "MODEL_NAME_TF = 'model_epoch_'+str(last_successfull_epoch)+'_tf'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNgWBr2HAc27",
        "outputId": "2f0593b0-705c-434f-cfe4-ff0464ce9df8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model_epoch_9_pytorch\n",
            "model_epoch_9_tf\n"
          ]
        }
      ],
      "source": [
        "print(MODEL_NAME_PYTORCH)\n",
        "print(MODEL_NAME_TF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-w-7q_Gm_aMQ"
      },
      "outputs": [],
      "source": [
        "# now load the model as TF and save properly\n",
        "from transformers import TFBertForTokenClassification\n",
        "\n",
        "tokenizer.save_pretrained(f'./{PROJECT_NAME}/{MODEL_NAME_PYTORCH}_tokenizer/')\n",
        "model.save_pretrained(f'./{PROJECT_NAME}/{MODEL_NAME_PYTORCH}', saved_model=True, save_format='tf')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "8Y-k7w4WfgKv"
      },
      "source": [
        "**IMPORTANT** If it's a domain-specific model, we need to use an interface to load and save it, that will change the input_signature so that it can only be loaded with sparknlp_jsl.xx.XXBertForTokenClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HY4S985IfgKv"
      },
      "outputs": [],
      "source": [
        "from transformers import TFBertForTokenClassification\n",
        "import tensorflow as tf\n",
        "\n",
        "# Creation of a subclass in order to define a new serving signature\n",
        "class DomainSpecificModel(TFBertForTokenClassification):\n",
        "    # Decorate the serving method with the new input_signature\n",
        "    # an input_signature represents the name, the data type and the shape of an expected input\n",
        "    @tf.function(input_signature=[{\n",
        "        \"input_ids\": tf.TensorSpec((None, None), tf.int32, name=\"medical_input_ids\"),\n",
        "        \"attention_mask\": tf.TensorSpec((None, None), tf.int32, name=\"attention_mask\"),\n",
        "        \"token_type_ids\": tf.TensorSpec((None, None), tf.int32, name=\"token_type_ids\"),\n",
        "\n",
        "    }])\n",
        "    def serving(self, inputs):\n",
        "        # call the model to process the inputs\n",
        "        output = self.call(inputs)\n",
        "\n",
        "        # return the formated output\n",
        "        return self.serving_output(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-L76A2yrfgKv",
        "outputId": "5d7d8bf9-4f86-4325-be88-ee1689310d3f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model DomainSpecificModel: ['bert.embeddings.position_ids']\n",
            "- This IS expected if you are initializing DomainSpecificModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DomainSpecificModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of DomainSpecificModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use DomainSpecificModel for predictions without further training.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x7f6095da2fa0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x7f6095da2fa0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, add_layer_call_fn while saving (showing 5 of 418). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "loaded_model = DomainSpecificModel.from_pretrained(f'./{PROJECT_NAME}/{MODEL_NAME_PYTORCH}', from_pt=True)\n",
        "loaded_model.save_pretrained(f'./{PROJECT_NAME}/{MODEL_NAME_TF}', saved_model=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWE0rH_8KFEE"
      },
      "source": [
        "### Save label mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuJfZcF_OSaR",
        "outputId": "97f5e546-6f91-421c-ea43-4e532d214ee3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['B-ROLE', 'B-EFFDATE', 'B-DATE', 'B-PERCENT', 'B-DOC', 'B-LAW', 'B-ORDINAL', 'B-LOC', 'I-PARTY', 'B-PERSON', 'B-PARTY', 'I-EFFDATE', 'I-DOC', 'O', 'PAD']\n"
          ]
        }
      ],
      "source": [
        "labels = sorted(tag2idx, key=tag2idx.get)\n",
        "\n",
        "print (labels)\n",
        "\n",
        "with open(f'./{PROJECT_NAME}/{MODEL_NAME_TF}/saved_model/1/assets/labels.txt', 'w') as f:\n",
        "    f.write('\\n'.join(labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP_erIY_KIbS"
      },
      "source": [
        "### Copy files in tf model's assets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eITuMKj8MxNS"
      },
      "outputs": [],
      "source": [
        "vocab_pth = f\"./{PROJECT_NAME}/{MODEL_NAME_PYTORCH}_tokenizer/vocab.txt\"\n",
        "saved_model_pth = f'./{PROJECT_NAME}/{MODEL_NAME_TF}/saved_model/1/assets/'\n",
        "\n",
        "! cp $vocab_pth $saved_model_pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mg2tkES9KQPW"
      },
      "source": [
        "# Now load the saved model in Spark NLP and save it properly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajwSmwj1QtIo"
      },
      "outputs": [],
      "source": [
        "domain = 'LEGAL' # or 'FINANCE' or 'OPENSOURCE'\n",
        "\n",
        "if domain == 'OPENSOURCE':\n",
        "  classifier_class = BertForTokenClassification\n",
        "elif domain == 'LEGAL':\n",
        "  classifier_class = sparknlp_jsl.legal.LegalBertForTokenClassification\n",
        "  classifier_classpath = \"com.johnsnowlabs.legal.token_classification.ner.LegalBertForTokenClassification\"\n",
        "elif domain == 'FINANCE':\n",
        "  classifier_class = sparknlp_jsl.finance.FinanceBertForTokenClassification\n",
        "  classifier_classpath = \"com.johnsnowlabs.finance.token_classification.ner.FinanceBertForTokenClassification\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwWTOxyjdCGc",
        "outputId": "d2b89a8d-30cf-4c72-9c86-54782c2774d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "sparknlp_jsl.legal.token_classification.ner.legal_bert_for_token_classifier.LegalBertForTokenClassification"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifier_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EhYAoarme2pT",
        "outputId": "7866302c-ce72-4a66-e8cc-3430ff28719b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'com.johnsnowlabs.legal.token_classification.ner.LegalBertForTokenClassification'"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifier_classpath"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqrmF3dkGWNY"
      },
      "outputs": [],
      "source": [
        "from sparknlp.annotator import *\n",
        "from sparknlp_jsl.annotator import *\n",
        "\n",
        "# For Finance\n",
        "tokenClassifier = classifier_class.loadSavedModel(\n",
        "     f'./{PROJECT_NAME}/{MODEL_NAME_TF}/saved_model/1',\n",
        "     spark\n",
        " )\\\n",
        " .setInputCols([\"sentence\",'token'])\\\n",
        "  .setOutputCol(\"ner\")\\\n",
        "  .setCaseSensitive(True)\\\n",
        "  .setMaxSentenceLength(256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AT8Fo_lQGWP7"
      },
      "outputs": [],
      "source": [
        "tokenClassifier.write().overwrite().save(f\"./{PROJECT_NAME}/{MODEL_NAME_TF}_spark_nlp\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uL_5pv6rd8pV"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "with open(f\"./{PROJECT_NAME}/{MODEL_NAME_TF}_spark_nlp/metadata/part-00000\", 'r') as fr:\n",
        "  metadata = json.load(fr)\n",
        "metadata['class'] = classifier_classpath\n",
        "with open(f\"./{PROJECT_NAME}/{MODEL_NAME_TF}_spark_nlp/metadata/part-00000\", 'w') as fw:\n",
        "  metadata = json.dump(metadata, fw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tA8sNacgiBgj"
      },
      "outputs": [],
      "source": [
        "!rm ./{PROJECT_NAME}/{MODEL_NAME_TF}_spark_nlp/metadata/.*.crc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jn8AJPDxiJhc",
        "outputId": "ccc81405-5578-4326-c4bc-131c02a5beb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 12K\n",
            "drwxr-xr-x 2 root root 4.0K Jan 12 09:52 .\n",
            "drwxr-xr-x 4 root root 4.0K Jan 12 09:52 ..\n",
            "-rw-r--r-- 1 root root  475 Jan 12 09:52 part-00000\n",
            "-rw-r--r-- 1 root root    0 Jan 12 09:52 _SUCCESS\n"
          ]
        }
      ],
      "source": [
        "!ls -lah ./{PROJECT_NAME}/{MODEL_NAME_TF}_spark_nlp/metadata/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54WOuCvoKaN7"
      },
      "source": [
        "# Test the imported model in Spark NLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qh87bK58tw5y"
      },
      "outputs": [],
      "source": [
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "documentAssembler = DocumentAssembler()\\\n",
        "  .setInputCol(\"text\")\\\n",
        "  .setOutputCol(\"document\")\n",
        "\n",
        "sparktokenizer = Tokenizer()\\\n",
        "  .setInputCols(\"document\")\\\n",
        "  .setOutputCol(\"token\")\n",
        "\n",
        "from sparknlp_jsl.annotator import *\n",
        "\n",
        "tokenClassifier = classifier_class.load(f\"./{PROJECT_NAME}/{MODEL_NAME_TF}_spark_nlp\")\\\n",
        "  .setInputCols(\"token\", \"document\")\\\n",
        "  .setOutputCol(\"label\")\\\n",
        "  .setCaseSensitive(True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGOV6Oik3jGc"
      },
      "outputs": [],
      "source": [
        "pipeline =  Pipeline(stages=[\n",
        "  documentAssembler,\n",
        "  sparktokenizer,\n",
        "  tokenClassifier\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPG-J1D6CuUj"
      },
      "outputs": [],
      "source": [
        "p_model = pipeline.fit(spark.createDataFrame(pd.DataFrame({'text': ['']})))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_nGP7YVQIxv",
        "outputId": "81ae55ab-422b-4f2c-8f1e-af450e25499b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "|                text|            document|               token|               label|\n",
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "|fox grants to lic...|[{document, 0, 17...|[{token, 0, 2, fo...|[{named_entity, 0...|\n",
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "text = \"\"\"Fox grants to Licensee a limited, exclusive (except as otherwise may be provided in this Agreement), \n",
        "non-transferable (except as permitted in Paragraph 17(d)) right and license\"\"\".lower()\n",
        "res = p_model.transform(spark.createDataFrame([[text]]).toDF(\"text\"))\n",
        "\n",
        "res.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhqNplVEEjs_",
        "outputId": "8a682ebe-e505-4dd2-9345-393832a9b838"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------------+---------+\n",
            "|           token|ner_label|\n",
            "+----------------+---------+\n",
            "|             fox|        O|\n",
            "|          grants|        O|\n",
            "|              to|        O|\n",
            "|        licensee|        O|\n",
            "|               a|        O|\n",
            "|         limited|        O|\n",
            "|               ,|        O|\n",
            "|       exclusive|        O|\n",
            "|               (|        O|\n",
            "|          except|        O|\n",
            "|              as|        O|\n",
            "|       otherwise|        O|\n",
            "|             may|        O|\n",
            "|              be|        O|\n",
            "|        provided|        O|\n",
            "|              in|        O|\n",
            "|            this|        O|\n",
            "|       agreement|    B-DOC|\n",
            "|              ),|        O|\n",
            "|non-transferable|        O|\n",
            "+----------------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "res.select(F.explode(F.arrays_zip('token.result', 'label.result')).alias(\"cols\")) \\\n",
        "               .select(F.expr(\"cols['0']\").alias(\"token\"),\n",
        "                       F.expr(\"cols['1']\").alias(\"ner_label\"))\\\n",
        "               .show(20, truncate=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fsttvgU5Akgf"
      },
      "outputs": [],
      "source": [
        "os.environ['SPARKNLP_TF_MODEL'] = MODEL_NAME_TF + \"_spark_nlp\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4_1fh_tFhls",
        "outputId": "ac1629e5-7efe-45b8-ab8d-d48128daab4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: model_epoch_9_tf_spark_nlp/ (stored 0%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/bert_classification_tensorflow (deflated 9%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/metadata/ (stored 0%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/metadata/part-00000 (deflated 39%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/metadata/_SUCCESS (stored 0%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/fields/ (stored 0%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/fields/labels/ (stored 0%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/fields/labels/.part-00000.crc (stored 0%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/fields/labels/part-00000 (deflated 32%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/fields/labels/part-00001 (deflated 32%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/fields/labels/_SUCCESS (stored 0%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/fields/labels/._SUCCESS.crc (stored 0%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/fields/labels/.part-00001.crc (stored 0%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/fields/vocabulary/ (stored 0%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/fields/vocabulary/.part-00000.crc (stored 0%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/fields/vocabulary/part-00000 (deflated 78%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/fields/vocabulary/part-00001 (deflated 78%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/fields/vocabulary/_SUCCESS (stored 0%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/fields/vocabulary/._SUCCESS.crc (stored 0%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/fields/vocabulary/.part-00001.crc (stored 0%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/fields/signatures/ (stored 0%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/fields/signatures/.part-00000.crc (stored 0%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/fields/signatures/part-00000 (deflated 31%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/fields/signatures/part-00001 (deflated 29%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/fields/signatures/_SUCCESS (stored 0%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/fields/signatures/._SUCCESS.crc (stored 0%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/fields/signatures/.part-00001.crc (stored 0%)\n",
            "  adding: model_epoch_9_tf_spark_nlp/.bert_classification_tensorflow.crc (deflated 0%)\n"
          ]
        }
      ],
      "source": [
        "!cd $PROJECT_NAME && zip -r $PROJECT_NAME.zip $SPARKNLP_TF_MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88WTHot2z2cR"
      },
      "source": [
        "# MOUNT DRIVE AND SAVE YOUR MODEL TO IT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dzn-fkwftWnP",
        "outputId": "8080aec6-a947-4425-fbcf-c01adbcbe2a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f66fQFr6tlKK"
      },
      "outputs": [],
      "source": [
        "!cp legal_obligations/legal_obligations.zip /content/gdrive/MyDrive/"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00382dc9319e44a0a60acce6c891c70b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01dbc4f65e8945ad893e078a2b8f0868": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c463d47dc964b29a6bb3c5da0104d97": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0edfa06cfb8f4f2f9dc865ac9bd5c8fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "103ffe768c414ff3b13a6433719436be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10dd2aad97fd4467adffa4b2679b1136": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1278a42d7b8644aabcba413b9b4c741b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db617bb685c84bb99ad40cc9fb7e9d48",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1899ce44d52842fdbd6d6370bfe0cb4b",
            "value": 112
          }
        },
        "15013af43f8e484284a7995f95bff6c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_16c30c8ea4dd46bba3e4ecc63cd89dc4",
              "IPY_MODEL_8fcfcbaa34494b18abf4824bef943de4",
              "IPY_MODEL_2538250adebd45018e11108ec9ede170"
            ],
            "layout": "IPY_MODEL_01dbc4f65e8945ad893e078a2b8f0868"
          }
        },
        "15a4f465dcfb4a289f872fc55594ec0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16c30c8ea4dd46bba3e4ecc63cd89dc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_595a14280e1145b09072a76baf203bbe",
            "placeholder": "​",
            "style": "IPY_MODEL_15a4f465dcfb4a289f872fc55594ec0e",
            "value": "Downloading: 100%"
          }
        },
        "1899ce44d52842fdbd6d6370bfe0cb4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1bd42f5f2573412e8e50db4d9788f279": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2538250adebd45018e11108ec9ede170": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b51fc841c9f64bf9948989910fdd43ea",
            "placeholder": "​",
            "style": "IPY_MODEL_92874130f4c541abaa3fe063d091d21d",
            "value": " 251k/251k [00:00&lt;00:00, 8.72MB/s]"
          }
        },
        "2759b58d0adb47a094d3d1a5df80f84c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ec93b1749964695ad3cdf13414e333d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c3f29e6367040afb431a4fa4c67a22d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c515e4406584d1b94af0f42ee9771cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4574a150faf0410ca05267bc4baeea0f",
            "placeholder": "​",
            "style": "IPY_MODEL_2759b58d0adb47a094d3d1a5df80f84c",
            "value": " 307/307 [00:00&lt;00:00, 15.4kB/s]"
          }
        },
        "3e8e36f6a61b46ebbd74fa2e96f2f946": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "448bac8812ea4f32a06ece3ac820ac55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4574a150faf0410ca05267bc4baeea0f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a6b26c3941147b4bbc6e9379af27c43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d05925973784a4e8b4b67611935a14a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5103d5567228445c97e947c85f94d399": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "524659446d9b4c1690567072bc4d425b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cf5461223f674c05b48448c46d7f2786",
              "IPY_MODEL_953e11b0dba547399b28819c3b52a783",
              "IPY_MODEL_ff498bd1f3b54de58a8e14cc89bbbbf2"
            ],
            "layout": "IPY_MODEL_fc9c095da28a4c87b120b8db0376f720"
          }
        },
        "595a14280e1145b09072a76baf203bbe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c7a210beedd4120a638e9d3834cfede": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6541c7e99d8343c681f35b69c74d1f53": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "68fbac8b54a64f7195c96654151b1953": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4b9f6ba0600493488e61863f9146dc6",
            "placeholder": "​",
            "style": "IPY_MODEL_8ee17313274a4303bb023a92ed4bb2c7",
            "value": "Downloading: 100%"
          }
        },
        "72932b5972404649b61c397e2d1c9639": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d05925973784a4e8b4b67611935a14a",
            "placeholder": "​",
            "style": "IPY_MODEL_a7a6c566426d40f6bc36439db30b47bc",
            "value": " 112/112 [00:00&lt;00:00, 5.21kB/s]"
          }
        },
        "73a4c1426da44ba98c13fbeca2812ad2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_77f328e10d5148e9811780dea869ad17",
              "IPY_MODEL_1278a42d7b8644aabcba413b9b4c741b",
              "IPY_MODEL_72932b5972404649b61c397e2d1c9639"
            ],
            "layout": "IPY_MODEL_9dc630fd21ad4823a2b326a207cd3904"
          }
        },
        "77f328e10d5148e9811780dea869ad17": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ec93b1749964695ad3cdf13414e333d",
            "placeholder": "​",
            "style": "IPY_MODEL_3e8e36f6a61b46ebbd74fa2e96f2f946",
            "value": "Downloading: 100%"
          }
        },
        "8021e1bc11f34513b1aefa64cf1c5de4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_deb60921f6b14396814a0a63c031ea14",
              "IPY_MODEL_f0a85bc5dac74c648f5cb99fe11dcdf1",
              "IPY_MODEL_3c515e4406584d1b94af0f42ee9771cc"
            ],
            "layout": "IPY_MODEL_3c3f29e6367040afb431a4fa4c67a22d"
          }
        },
        "80409f477740440eb69b4762af3ba4b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_68fbac8b54a64f7195c96654151b1953",
              "IPY_MODEL_df133be0df674ff1bb4e5ea10f52ec88",
              "IPY_MODEL_9ab99564baa34cf89280e2a03bc7747c"
            ],
            "layout": "IPY_MODEL_5103d5567228445c97e947c85f94d399"
          }
        },
        "8068f04e3de9477d93301e33dc4b26a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85efef210d6c451abd27cdc414a976f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ee17313274a4303bb023a92ed4bb2c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8fcfcbaa34494b18abf4824bef943de4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0022dc48e944433bef84d94c743ed0e",
            "max": 251156,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_10dd2aad97fd4467adffa4b2679b1136",
            "value": 251156
          }
        },
        "92874130f4c541abaa3fe063d091d21d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "953e11b0dba547399b28819c3b52a783": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c463d47dc964b29a6bb3c5da0104d97",
            "max": 445060790,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6541c7e99d8343c681f35b69c74d1f53",
            "value": 445060790
          }
        },
        "9ab99564baa34cf89280e2a03bc7747c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_103ffe768c414ff3b13a6433719436be",
            "placeholder": "​",
            "style": "IPY_MODEL_5c7a210beedd4120a638e9d3834cfede",
            "value": " 747/747 [00:00&lt;00:00, 51.0kB/s]"
          }
        },
        "9dc630fd21ad4823a2b326a207cd3904": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0022dc48e944433bef84d94c743ed0e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7a6c566426d40f6bc36439db30b47bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b51fc841c9f64bf9948989910fdd43ea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf5461223f674c05b48448c46d7f2786": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1bd42f5f2573412e8e50db4d9788f279",
            "placeholder": "​",
            "style": "IPY_MODEL_448bac8812ea4f32a06ece3ac820ac55",
            "value": "Downloading: 100%"
          }
        },
        "d5bb7d30484c4483bf53703a7a0653c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db617bb685c84bb99ad40cc9fb7e9d48": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de49351967194653b99be7a6419c5e24": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "deb60921f6b14396814a0a63c031ea14": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8068f04e3de9477d93301e33dc4b26a0",
            "placeholder": "​",
            "style": "IPY_MODEL_4a6b26c3941147b4bbc6e9379af27c43",
            "value": "Downloading: 100%"
          }
        },
        "df133be0df674ff1bb4e5ea10f52ec88": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5bb7d30484c4483bf53703a7a0653c5",
            "max": 747,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fcef13290dac462a8ba286c3547235d3",
            "value": 747
          }
        },
        "f0a85bc5dac74c648f5cb99fe11dcdf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00382dc9319e44a0a60acce6c891c70b",
            "max": 307,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0edfa06cfb8f4f2f9dc865ac9bd5c8fe",
            "value": 307
          }
        },
        "f4b9f6ba0600493488e61863f9146dc6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc9c095da28a4c87b120b8db0376f720": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcef13290dac462a8ba286c3547235d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff498bd1f3b54de58a8e14cc89bbbbf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de49351967194653b99be7a6419c5e24",
            "placeholder": "​",
            "style": "IPY_MODEL_85efef210d6c451abd27cdc414a976f9",
            "value": " 445M/445M [00:06&lt;00:00, 73.5MB/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}