{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "I08sFJYCxR0Z"
      },
      "source": [
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FwJ-P56kq6FU"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/legal-nlp/14.0.Legal_ChunkKeyPhraseExtraction.ipynb.ipynb)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "4iIO6G_B3pqq"
      },
      "source": [
        "#ðŸŽ¬ Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPwo4Czy3pqq",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [],
      "source": [
        "! pip install -q johnsnowlabs"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YPsbAnNoPt0Z"
      },
      "source": [
        "##ðŸ”— Automatic Installation\n",
        "Using my.johnsnowlabs.com SSO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_L-7mLYp3pqr",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [],
      "source": [
        "from johnsnowlabs import nlp, finance, legal\n",
        "\n",
        "nlp.install(force_browser=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hsJvn_WWM2GL"
      },
      "source": [
        "##ðŸ”— Manual downloading\n",
        "If you are not registered in my.johnsnowlabs.com, you received a license via e-email or you are using Safari, you may need to do a manual update of the license.\n",
        "\n",
        "- Go to my.johnsnowlabs.com\n",
        "- Download your license\n",
        "- Upload it using the following command"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i57QV3-_P2sQ"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "print('Please Upload your John Snow Labs License using the button below')\n",
        "license_keys = files.upload()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xGgNdFzZP_hQ"
      },
      "source": [
        "- Install it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfmmPqknP4rR"
      },
      "outputs": [],
      "source": [
        "nlp.install()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "DCl5ErZkNNLk"
      },
      "source": [
        "#ðŸ“Œ Starting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3jVICoa3pqr"
      },
      "outputs": [],
      "source": [
        "spark = nlp.start()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "OdYLnzu9GT7N"
      },
      "source": [
        "â³ Load sample txt file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCZ_yMDQfU6u"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"\n",
        "INTELLECTUAL PROPERTY AGREEMENT\n",
        "\n",
        "This INTELLECTUAL PROPERTY AGREEMENT (this \"Agreement\"), dated as of December 31, 2018 (the \"Effective Date\") is entered into by and between Armstrong Flooring, Inc., a Delaware corporation (\"Seller\") and AFI Licensing LLC, a Delaware limited liability company (\"Licensing\" and together with Seller, \"Arizona\") and AHF Holding, Inc. (formerly known as Tarzan HoldCo, Inc.), a Delaware corporation (\"Buyer\") and Armstrong Hardwood Flooring Company, a Tennessee corporation (the \"Company\" and together with Buyer the \"Buyer Entities\") (each of Arizona on the one hand and the Buyer Entities on the other hand, a \"Party\" and collectively, the \"Parties\").\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LrZuODCcGA-o"
      },
      "outputs": [],
      "source": [
        "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
        "textDF = spark.createDataFrame([[text]]).toDF(\"text\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-NTEaLTrkgCh"
      },
      "source": [
        "## ðŸ”Ž **Chunk Key Phrase Extraction**\n",
        "\n",
        "\n",
        "ðŸ“œExplanation:\n",
        "\n",
        "Chunk Key Phrase Extraction is a technique used in natural language processing (NLP) to identify and extract key phrases or important chunks of text from a given document or text corpus. Key phrases are typically defined as meaningful and informative phrases that capture the essence of the content.\n",
        "\n",
        "The process of Chunk Key Phrase Extraction involves several steps:\n",
        "\n",
        "- **Tokenization:** The input text is divided into smaller units called tokens, which can be words, phrases, or even characters. Tokenization helps in breaking down the text into meaningful components that can be further analyzed.\n",
        "\n",
        "- **Part-of-Speech (POS) Tagging:** Each token is assigned a part-of-speech tag, which indicates the grammatical category or role of the word in the sentence (e.g., noun, verb, adjective). POS tagging helps in understanding the syntactic structure of the text.\n",
        "\n",
        "- **Chunking:** Chunking is the process of grouping together tokens based on specific patterns or rules. It involves identifying and extracting meaningful chunks of words that form meaningful phrases or constituents. These chunks are typically noun phrases or verb phrases that convey important information.\n",
        "\n",
        "- **Key Phrase Extraction:** From the extracted chunks, the algorithm selects and ranks key phrases based on their importance or relevance to the overall content. Various techniques can be employed for ranking, such as frequency-based approaches or statistical models that consider the contextual information of the phrases.\n",
        "\n",
        "Chunk Key Phrase Extraction is often used in applications such as information retrieval, document summarization, sentiment analysis, and text classification. It helps in identifying the most significant and informative phrases in a text, enabling better understanding and analysis of the content."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qY7XtY9YGBMX"
      },
      "outputs": [],
      "source": [
        "documenter = nlp.DocumentAssembler() \\\n",
        "    .setInputCol(\"text\") \\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "sentencer = nlp.SentenceDetector() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"sentences\")\n",
        "\n",
        "tokenizer = nlp.Tokenizer() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"tokens\") \\\n",
        "    .setSplitChars(['\\[','\\]']) \\\n",
        "\n",
        "stop_words_cleaner = nlp.StopWordsCleaner.pretrained()\\\n",
        "    .setInputCols(\"tokens\")\\\n",
        "    .setOutputCol(\"clean_tokens\")\\\n",
        "    .setCaseSensitive(False)\n",
        "\n",
        "ngram_generator = nlp.NGramGenerator()\\\n",
        "    .setInputCols([\"clean_tokens\"])\\\n",
        "    .setOutputCol(\"ngrams\")\\\n",
        "    .setN(3)\n",
        "\n",
        "ngram_key_phrase_extractor = legal.ChunkKeyPhraseExtraction.pretrained()\\\n",
        "    .setTopN(10) \\\n",
        "    .setDivergence(0.4)\\\n",
        "    .setInputCols([\"sentences\", \"ngrams\"])\\\n",
        "    .setOutputCol(\"ngram_key_phrases\")\n",
        "\n",
        "ngram_pipeline = nlp.Pipeline(stages=[\n",
        "    documenter, \n",
        "    sentencer, \n",
        "    tokenizer, \n",
        "    stop_words_cleaner,\n",
        "    ngram_generator,\n",
        "    ngram_key_phrase_extractor\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HlWNf7wKG1JB"
      },
      "outputs": [],
      "source": [
        "ngram_results = ngram_pipeline.fit(empty_data).transform(textDF)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "O833gNNFHJMA"
      },
      "source": [
        "**Lets show N-Gram results.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yF50J2XRHJl5",
        "outputId": "4bf0cd8e-54a7-4254-ad42-f4ed66535712"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------------------------------------------------------------------------+\n",
            "|key_phrase_candidate                                                             |\n",
            "+---------------------------------------------------------------------------------+\n",
            "|{chunk, 1, 31, INTELLECTUAL PROPERTY AGREEMENT, {sentence -> 0, chunk -> 0}, []} |\n",
            "|{chunk, 14, 50, PROPERTY AGREEMENT INTELLECTUAL, {sentence -> 0, chunk -> 1}, []}|\n",
            "|{chunk, 23, 59, AGREEMENT INTELLECTUAL PROPERTY, {sentence -> 0, chunk -> 2}, []}|\n",
            "|{chunk, 39, 69, INTELLECTUAL PROPERTY AGREEMENT, {sentence -> 0, chunk -> 3}, []}|\n",
            "|{chunk, 52, 71, PROPERTY AGREEMENT (, {sentence -> 0, chunk -> 4}, []}           |\n",
            "|{chunk, 61, 77, AGREEMENT ( \", {sentence -> 0, chunk -> 5}, []}                  |\n",
            "|{chunk, 71, 86, ( \" Agreement, {sentence -> 0, chunk -> 6}, []}                  |\n",
            "|{chunk, 77, 89, \" Agreement \"),, {sentence -> 0, chunk -> 7}, []}                |\n",
            "|{chunk, 78, 95, Agreement \"), dated, {sentence -> 0, chunk -> 8}, []}            |\n",
            "|{chunk, 87, 110, \"), dated December, {sentence -> 0, chunk -> 9}, []}            |\n",
            "|{chunk, 91, 113, dated December 31, {sentence -> 0, chunk -> 10}, []}            |\n",
            "|{chunk, 103, 114, December 31 ,, {sentence -> 0, chunk -> 11}, []}               |\n",
            "|{chunk, 112, 119, 31 , 2018, {sentence -> 0, chunk -> 12}, []}                   |\n",
            "|{chunk, 114, 121, , 2018 (, {sentence -> 0, chunk -> 13}, []}                    |\n",
            "|{chunk, 116, 126, 2018 ( \", {sentence -> 0, chunk -> 14}, []}                    |\n",
            "|{chunk, 121, 135, ( \" Effective, {sentence -> 0, chunk -> 15}, []}               |\n",
            "|{chunk, 126, 140, \" Effective Date, {sentence -> 0, chunk -> 16}, []}            |\n",
            "|{chunk, 127, 142, Effective Date \"), {sentence -> 0, chunk -> 17}, []}           |\n",
            "|{chunk, 137, 153, Date \") entered, {sentence -> 0, chunk -> 18}, []}             |\n",
            "|{chunk, 141, 183, \") entered Armstrong, {sentence -> 0, chunk -> 19}, []}        |\n",
            "|{chunk, 147, 192, entered Armstrong Flooring, {sentence -> 0, chunk -> 20}, []}  |\n",
            "|{chunk, 175, 193, Armstrong Flooring ,, {sentence -> 0, chunk -> 21}, []}        |\n",
            "|{chunk, 185, 199, Flooring , .,, {sentence -> 0, chunk -> 22}, []}               |\n",
            "|{chunk, 193, 210, , ., Delaware, {sentence -> 0, chunk -> 23}, []}               |\n",
            "|{chunk, 198, 222, ., Delaware corporation, {sentence -> 0, chunk -> 24}, []}     |\n",
            "|{chunk, 203, 225, Delaware corporation (\", {sentence -> 0, chunk -> 25}, []}     |\n",
            "|{chunk, 212, 231, corporation (\" Seller, {sentence -> 0, chunk -> 26}, []}       |\n",
            "|{chunk, 224, 233, (\" Seller \"), {sentence -> 0, chunk -> 27}, []}                |\n",
            "|{chunk, 226, 241, Seller \") AFI, {sentence -> 0, chunk -> 28}, []}               |\n",
            "|{chunk, 232, 251, \") AFI Licensing, {sentence -> 0, chunk -> 29}, []}            |\n",
            "+---------------------------------------------------------------------------------+\n",
            "only showing top 30 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "ngram_results.selectExpr(\"explode(ngrams) AS key_phrase_candidate\").show(30,truncate=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tmgCFlTnHPP8"
      },
      "source": [
        "**Check the key phrases from N-Gram results.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyXr3y_XHLLH",
        "outputId": "0d857508-4910-4123-f370-1acd5094292a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|                                                                                                                                                         ngram_key_phrases|\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|{chunk, 253, 267, LLC Delaware, {sentence -> 0, chunk -> 32, DocumentSimilarity -> 0.67082428827937, MMRScore -> 0.4024945889613194}, [-0.054024786, 0.8892173, -0.0607...|\n",
            "|{chunk, 243, 256, Licensing LLC, {sentence -> 0, chunk -> 31, DocumentSimilarity -> 0.623435274176818, MMRScore -> 0.07391284062011122}, [0.3169803, 1.18685, -0.122759...|\n",
            "|{chunk, 297, 331, Licensing \" Seller, {sentence -> 0, chunk -> 39, DocumentSimilarity -> 0.5620123028023943, MMRScore -> 0.10101117303174226}, [0.04602056, 0.96385497,...|\n",
            "|{chunk, 212, 231, corporation \" Seller, {sentence -> 0, chunk -> 26, DocumentSimilarity -> 0.5601213486826419, MMRScore -> 0.03941356508847493}, [0.13718934, 0.7775403...|\n",
            "|{chunk, 576, 612, Arizona hand Buyer, {sentence -> 0, chunk -> 77, DocumentSimilarity -> 0.5298374343984847, MMRScore -> 0.11960417979726506}, [-0.4218712, 0.32932833,...|\n",
            "|{chunk, 1, 31, INTELLECTUAL PROPERTY AGREEMENT, {sentence -> 0, chunk -> 0, DocumentSimilarity -> 0.5139882459942415, MMRScore -> 0.11717650664539808}, [-0.6259317, 1....|\n",
            "|{chunk, 473, 492, Company Tennessee, {sentence -> 0, chunk -> 63, DocumentSimilarity -> 0.4410448906986666, MMRScore -> 0.021020910594832964}, [-0.51039654, -0.1238618...|\n",
            "|{chunk, 269, 293, limited liability company, {sentence -> 0, chunk -> 35, DocumentSimilarity -> 0.4326145252236725, MMRScore -> 0.03342918943901377}, [-0.75024444, 2.0...|\n",
            "|{chunk, 367, 398, Tarzan HoldCo, {sentence -> 0, chunk -> 50, DocumentSimilarity -> 0.36380691282041117, MMRScore -> 0.05453937275093976}, [0.25237665, 0.35331064, 0.1...|\n",
            "|{chunk, 147, 192, entered Armstrong Flooring, {sentence -> 0, chunk -> 20, DocumentSimilarity -> 0.2773128054485191, MMRScore -> 0.011552607324324532}, [-0.82373697, -...|\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "ngram_results.selectExpr(\"explode(ngram_key_phrases) AS ngram_key_phrases\").show(truncate=170)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Ne0FBLs2HZfn"
      },
      "source": [
        "**Show the selected key phrases, the cosine similarity to the document, the Maximal Marginal Relevance score and the sentence they where key phrase was found in.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gr5zWKnHHZ1H",
        "outputId": "e1dfcf21-dd0e-43ef-eb6e-ac6f99178b19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------------------------+-------------------+--------------------+--------+\n",
            "|key_phrase                     |DocumentSimilarity |MMRScore            |sentence|\n",
            "+-------------------------------+-------------------+--------------------+--------+\n",
            "|LLC Delaware                   |0.67082428827937   |0.4024945889613194  |0       |\n",
            "|Licensing LLC                  |0.623435274176818  |0.07391284062011122 |0       |\n",
            "|Licensing \" Seller             |0.5620123028023943 |0.10101117303174226 |0       |\n",
            "|corporation \" Seller           |0.5601213486826419 |0.03941356508847493 |0       |\n",
            "|Arizona hand Buyer             |0.5298374343984847 |0.11960417979726506 |0       |\n",
            "|INTELLECTUAL PROPERTY AGREEMENT|0.5139882459942415 |0.11717650664539808 |0       |\n",
            "|Company Tennessee              |0.4410448906986666 |0.021020910594832964|0       |\n",
            "|limited liability company      |0.4326145252236725 |0.03342918943901377 |0       |\n",
            "|Tarzan HoldCo                  |0.36380691282041117|0.05453937275093976 |0       |\n",
            "|entered Armstrong Flooring     |0.2773128054485191 |0.011552607324324532|0       |\n",
            "+-------------------------------+-------------------+--------------------+--------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pyspark.sql.functions as F\n",
        "\n",
        "ngram_results.select(F.explode(F.arrays_zip(ngram_results.ngram_key_phrases.result,\n",
        "                                            ngram_results.ngram_key_phrases.metadata)).alias(\"cols\"))\\\n",
        "              .select(F.expr(\"cols['0']\").alias(\"key_phrase\"),\n",
        "                      F.expr(\"cols['1']['DocumentSimilarity']\").alias(\"DocumentSimilarity\"),\n",
        "                      F.expr(\"cols['1']['MMRScore']\").alias(\"MMRScore\"),\n",
        "                      F.expr(\"cols['1']['sentence']\").alias(\"sentence\")).show(truncate=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "yY8iJ7DUHhn0"
      },
      "source": [
        "# with NER Model\n",
        "\n",
        "Now we will show how to get key phrases from NER chunks by feeding `ChunkKeyPhraseExtraction` with the output of `NerConverter`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8WuqSiHXHbkX"
      },
      "outputs": [],
      "source": [
        "documenter = nlp.DocumentAssembler() \\\n",
        "    .setInputCol(\"text\") \\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "sentencer = nlp.SentenceDetector() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"sentences\")\n",
        "\n",
        "tokenizer = nlp.Tokenizer() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"tokens\") \\\n",
        "    .setSplitChars(['\\[','\\]']) \n",
        "\n",
        "embeddings = nlp.RoBertaEmbeddings.pretrained(\"roberta_embeddings_legal_roberta_base\", \"en\") \\\n",
        "    .setInputCols(\"sentences\", \"tokens\") \\\n",
        "    .setOutputCol(\"embeddings\")\\\n",
        "    .setMaxSentenceLength(512)\\\n",
        "    .setCaseSensitive(True)\n",
        "\n",
        "ner_tagger = legal.NerModel.pretrained('legner_contract_doc_parties_lg', 'en', 'legal/models')\\\n",
        "    .setInputCols([\"sentences\", \"tokens\", \"embeddings\"]) \\\n",
        "    .setOutputCol(\"ner_tags\")\n",
        "\n",
        "ner_converter = legal.NerConverterInternal()\\\n",
        "    .setInputCols(\"sentences\", \"tokens\", \"ner_tags\")\\\n",
        "    .setOutputCol(\"ner_chunks\")\n",
        "\n",
        "ner_key_phrase_extractor = legal.ChunkKeyPhraseExtraction.pretrained()\\\n",
        "    .setTopN(10) \\\n",
        "    .setDivergence(0.4)\\\n",
        "    .setInputCols([\"sentences\", \"ner_chunks\"])\\\n",
        "    .setOutputCol(\"ner_key_phrases\")\n",
        "\n",
        "ner_pipeline = nlp.Pipeline(stages=[\n",
        "    documenter, \n",
        "    sentencer, \n",
        "    tokenizer, \n",
        "    embeddings, \n",
        "    ner_tagger, \n",
        "    ner_converter, \n",
        "    ner_key_phrase_extractor\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A851c6yiJRPJ"
      },
      "outputs": [],
      "source": [
        "ner_results = ner_pipeline.fit(empty_data).transform(textDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRtANq26JXdM",
        "outputId": "368e1cc5-49f5-4b41-efd6-32bdc692adb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------------------------------+-----------+\n",
            "|ner_chunk                          |label      |\n",
            "+-----------------------------------+-----------+\n",
            "|INTELLECTUAL PROPERTY AGREEMENT    |DOC        |\n",
            "|INTELLECTUAL PROPERTY AGREEMENT    |DOC        |\n",
            "|December 31, 2018                  |EFFDATE    |\n",
            "|Armstrong Flooring, Inc            |PARTY      |\n",
            "|Seller                             |ALIAS      |\n",
            "|AFI Licensing LLC                  |PARTY      |\n",
            "|Licensing                          |ALIAS      |\n",
            "|Seller                             |PARTY      |\n",
            "|Arizona                            |ALIAS      |\n",
            "|AHF Holding, Inc                   |PARTY      |\n",
            "|Tarzan HoldCo, Inc                 |FORMER_NAME|\n",
            "|Buyer                              |ALIAS      |\n",
            "|Armstrong Hardwood Flooring Company|PARTY      |\n",
            "|Company                            |ALIAS      |\n",
            "|Buyer                              |PARTY      |\n",
            "|Buyer Entities                     |ALIAS      |\n",
            "|Arizona                            |PARTY      |\n",
            "|Buyer Entities                     |PARTY      |\n",
            "|Party                              |ALIAS      |\n",
            "|Parties                            |ALIAS      |\n",
            "+-----------------------------------+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ner_chunk results\n",
        "ner_results.select(F.explode(F.arrays_zip(ner_results.ner_chunks.result,\n",
        "                                          ner_results.ner_chunks.metadata)).alias(\"cols\"))\\\n",
        "           .select(F.expr(\"cols['0']\").alias(\"ner_chunk\"),\n",
        "                   F.expr(\"cols['1']['entity']\").alias(\"label\")).show(50, truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeGwhovDQBrV",
        "outputId": "5a7cd7fc-2724-4c55-80db-2bc934889aed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------------------------------+-----------+-------------------+---------------------+--------+\n",
            "|key_phrase                         |label      |DocumentSimilarity |MMRScore             |sentence|\n",
            "+-----------------------------------+-----------+-------------------+---------------------+--------+\n",
            "|Buyer Entities                     |ALIAS      |0.5784693799173213 |0.34708164174217754  |1       |\n",
            "|AFI Licensing LLC                  |PARTY      |0.565162563524993  |0.09504163803345092  |0       |\n",
            "|Tarzan HoldCo, Inc                 |FORMER_NAME|0.5367663102209614 |0.12806869955230965  |1       |\n",
            "|AHF Holding, Inc                   |PARTY      |0.5268001425682903 |0.0650575684927151   |0       |\n",
            "|INTELLECTUAL PROPERTY AGREEMENT    |DOC        |0.5139882459942415 |0.11127398683991158  |0       |\n",
            "|Armstrong Flooring, Inc            |PARTY      |0.47952994842282104|-0.01620789491482061 |0       |\n",
            "|Armstrong Hardwood Flooring Company|PARTY      |0.43693383662177004|0.07879576837459534  |1       |\n",
            "|Licensing                          |ALIAS      |0.4047166805146564 |-0.007463235476657365|0       |\n",
            "|December 31, 2018                  |EFFDATE    |0.2945774415081737 |0.00906347460128093  |0       |\n",
            "|Arizona                            |ALIAS      |0.25291162081836577|0.0038993805060472675|0       |\n",
            "+-----------------------------------+-----------+-------------------+---------------------+--------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "ner_results.select(F.explode(F.arrays_zip(ner_results.ner_key_phrases.result, \n",
        "                                          ner_results.ner_key_phrases.metadata)).alias(\"cols\"))\\\n",
        "           .select(F.expr(\"cols['0']\").alias(\"key_phrase\"),\n",
        "                   F.expr(\"cols['1']['entity']\").alias(\"label\"),\n",
        "                   F.expr(\"cols['1']['DocumentSimilarity']\").alias(\"DocumentSimilarity\"),\n",
        "                   F.expr(\"cols['1']['MMRScore']\").alias(\"MMRScore\"),\n",
        "                   F.expr(\"cols['1']['sentence']\").alias(\"sentence\")).show(truncate=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RbqsAtrcX2CE"
      },
      "source": [
        "# with NGramGenerator and NER Model\n",
        "\n",
        "NGramGenerator and NER (Named Entity Recognition) Mode are additional components or techniques that can be used in conjunction with Chunk Key Phrase Extraction to enhance the extraction of key phrases.\n",
        "\n",
        "- NGramGenerator: An NGram refers to a contiguous sequence of n items from a given text, where an item can be a word, character, or any other linguistic unit. NGramGenerator is a component that generates NGrams from the input text. By considering NGrams of varying lengths (unigrams, bigrams, trigrams, etc.), the NGramGenerator captures both single words and multi-word expressions, which can be valuable key phrases.\n",
        "\n",
        "For example, if the input text is \"I love to play soccer,\" the NGramGenerator can produce unigrams like \"I,\" \"love,\" \"to,\" \"play,\" and \"soccer,\" as well as bigrams like \"I love,\" \"love to,\" \"to play,\" and \"play soccer.\" These NGrams provide more context and improve the extraction of meaningful key phrases.\n",
        "\n",
        "- NER Mode (Named Entity Recognition): Named Entity Recognition is a subtask of NLP that aims to identify and classify named entities, such as person names, locations, organizations, dates, etc., in text. NER Mode is a specific setting or approach used during Chunk Key Phrase Extraction, where named entities are recognized and treated as important chunks or key phrases.\n",
        "\n",
        "By incorporating NER Mode, the extraction process can specifically focus on extracting key phrases that represent named entities, which are typically highly informative and relevant in many applications. For instance, in a news article, named entities like \"Barack Obama,\" \"New York City,\" or \"Apple Inc.\" are important key phrases that convey crucial information.\n",
        "\n",
        "Using NGramGenerator and NER Mode in combination with Chunk Key Phrase Extraction can lead to more accurate and comprehensive extraction of key phrases from text. These techniques allow for the identification of meaningful phrases, including single words, multi-word expressions, and named entities, which contribute to a better understanding of the content and enable more effective analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDpPgelgX2jP"
      },
      "outputs": [],
      "source": [
        "documenter = nlp.DocumentAssembler() \\\n",
        "    .setInputCol(\"text\") \\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "sentencer = nlp.SentenceDetector() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"sentences\")\n",
        "\n",
        "tokenizer = nlp.Tokenizer() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"tokens\") \\\n",
        "    .setSplitChars(['\\[','\\]']) \n",
        "\n",
        "stop_words_cleaner = nlp.StopWordsCleaner.pretrained()\\\n",
        "    .setInputCols(\"tokens\")\\\n",
        "    .setOutputCol(\"clean_tokens\")\\\n",
        "    .setCaseSensitive(False)\n",
        "\n",
        "ngram_generator = nlp.NGramGenerator()\\\n",
        "    .setInputCols([\"clean_tokens\"])\\\n",
        "    .setOutputCol(\"ngrams\")\\\n",
        "    .setN(3)\n",
        "        \n",
        "embeddings = nlp.RoBertaEmbeddings.pretrained(\"roberta_embeddings_legal_roberta_base\", \"en\") \\\n",
        "    .setInputCols(\"sentences\", \"tokens\") \\\n",
        "    .setOutputCol(\"embeddings\")\\\n",
        "    .setMaxSentenceLength(512)\\\n",
        "    .setCaseSensitive(True)\n",
        "\n",
        "ner_tagger = legal.NerModel.pretrained('legner_contract_doc_parties_lg', 'en', 'legal/models')\\\n",
        "    .setInputCols([\"sentences\", \"tokens\", \"embeddings\"]) \\\n",
        "    .setOutputCol(\"ner_tags\")\n",
        "\n",
        "ner_converter = legal.NerConverterInternal()\\\n",
        "    .setInputCols(\"sentences\", \"tokens\", \"ner_tags\")\\\n",
        "    .setOutputCol(\"ner_chunks\")\n",
        "\n",
        "chunk_merger = legal.ChunkMergeApproach()\\\n",
        "    .setInputCols(\"ngrams\", \"ner_chunks\")\\\n",
        "    .setOutputCol(\"merged_chunks\")\\\n",
        "    .setMergeOverlapping(False)\n",
        "\n",
        "ngram_ner_key_phrase_extractor = legal.ChunkKeyPhraseExtraction.pretrained()\\\n",
        "    .setTopN(10) \\\n",
        "    .setDivergence(0.4)\\\n",
        "    .setInputCols([\"sentences\", \"merged_chunks\"])\\\n",
        "    .setOutputCol(\"key_phrases\")\n",
        "\n",
        "ngram_ner_pipeline = nlp.Pipeline(stages=[\n",
        "    documenter, \n",
        "    sentencer, \n",
        "    tokenizer, \n",
        "    stop_words_cleaner,\n",
        "    ngram_generator,\n",
        "    embeddings, \n",
        "    ner_tagger, \n",
        "    ner_converter, \n",
        "    chunk_merger,\n",
        "    ngram_ner_key_phrase_extractor\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jk_Wx7ElYoxr"
      },
      "outputs": [],
      "source": [
        "ngram_ner_results = ngram_ner_pipeline.fit(empty_data).transform(textDF)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Qy9Yp_CRYuZ_"
      },
      "source": [
        "**Show the merged key phrase candidate results. `UNK` ones from NGramGenerator and the others from `ner_jsl` model.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SOjf3L1Yu6F",
        "outputId": "f3a6d657-9099-4666-fd77-1029be694e32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|key_phrase_candidate                                                                                                                               |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|{chunk, 1, 31, INTELLECTUAL PROPERTY AGREEMENT, {entity -> UNK, chunk -> 0, sentence -> 0}, []}                                                    |\n",
            "|{chunk, 1, 31, INTELLECTUAL PROPERTY AGREEMENT, {chunk -> 1, confidence -> 0.83703333, ner_source -> ner_chunks, entity -> DOC, sentence -> 0}, []}|\n",
            "|{chunk, 14, 50, PROPERTY AGREEMENT INTELLECTUAL, {entity -> UNK, chunk -> 2, sentence -> 0}, []}                                                   |\n",
            "|{chunk, 23, 59, AGREEMENT INTELLECTUAL PROPERTY, {entity -> UNK, chunk -> 3, sentence -> 0}, []}                                                   |\n",
            "|{chunk, 39, 69, INTELLECTUAL PROPERTY AGREEMENT, {entity -> UNK, chunk -> 4, sentence -> 0}, []}                                                   |\n",
            "|{chunk, 39, 69, INTELLECTUAL PROPERTY AGREEMENT, {chunk -> 5, confidence -> 0.9633667, ner_source -> ner_chunks, entity -> DOC, sentence -> 0}, []}|\n",
            "|{chunk, 52, 71, PROPERTY AGREEMENT (, {entity -> UNK, chunk -> 6, sentence -> 0}, []}                                                              |\n",
            "|{chunk, 61, 77, AGREEMENT ( \", {entity -> UNK, chunk -> 7, sentence -> 0}, []}                                                                     |\n",
            "|{chunk, 71, 86, ( \" Agreement, {entity -> UNK, chunk -> 8, sentence -> 0}, []}                                                                     |\n",
            "|{chunk, 77, 89, \" Agreement \"),, {entity -> UNK, chunk -> 9, sentence -> 0}, []}                                                                   |\n",
            "|{chunk, 78, 95, Agreement \"), dated, {entity -> UNK, chunk -> 10, sentence -> 0}, []}                                                              |\n",
            "|{chunk, 87, 110, \"), dated December, {entity -> UNK, chunk -> 11, sentence -> 0}, []}                                                              |\n",
            "|{chunk, 91, 113, dated December 31, {entity -> UNK, chunk -> 12, sentence -> 0}, []}                                                               |\n",
            "|{chunk, 103, 114, December 31 ,, {entity -> UNK, chunk -> 13, sentence -> 0}, []}                                                                  |\n",
            "|{chunk, 103, 119, December 31, 2018, {chunk -> 14, confidence -> 0.944525, ner_source -> ner_chunks, entity -> EFFDATE, sentence -> 0}, []}        |\n",
            "|{chunk, 112, 119, 31 , 2018, {entity -> UNK, chunk -> 15, sentence -> 0}, []}                                                                      |\n",
            "|{chunk, 114, 121, , 2018 (, {entity -> UNK, chunk -> 16, sentence -> 0}, []}                                                                       |\n",
            "|{chunk, 116, 126, 2018 ( \", {entity -> UNK, chunk -> 17, sentence -> 0}, []}                                                                       |\n",
            "|{chunk, 121, 135, ( \" Effective, {entity -> UNK, chunk -> 18, sentence -> 0}, []}                                                                  |\n",
            "|{chunk, 126, 140, \" Effective Date, {entity -> UNK, chunk -> 19, sentence -> 0}, []}                                                               |\n",
            "|{chunk, 127, 142, Effective Date \"), {entity -> UNK, chunk -> 20, sentence -> 0}, []}                                                              |\n",
            "|{chunk, 137, 153, Date \") entered, {entity -> UNK, chunk -> 21, sentence -> 0}, []}                                                                |\n",
            "|{chunk, 141, 183, \") entered Armstrong, {entity -> UNK, chunk -> 22, sentence -> 0}, []}                                                           |\n",
            "|{chunk, 147, 192, entered Armstrong Flooring, {entity -> UNK, chunk -> 23, sentence -> 0}, []}                                                     |\n",
            "|{chunk, 175, 193, Armstrong Flooring ,, {entity -> UNK, chunk -> 24, sentence -> 0}, []}                                                           |\n",
            "|{chunk, 175, 197, Armstrong Flooring, Inc, {chunk -> 25, confidence -> 0.75530005, ner_source -> ner_chunks, entity -> PARTY, sentence -> 0}, []}  |\n",
            "|{chunk, 185, 199, Flooring , .,, {entity -> UNK, chunk -> 26, sentence -> 0}, []}                                                                  |\n",
            "|{chunk, 193, 210, , ., Delaware, {entity -> UNK, chunk -> 27, sentence -> 0}, []}                                                                  |\n",
            "|{chunk, 198, 222, ., Delaware corporation, {entity -> UNK, chunk -> 28, sentence -> 0}, []}                                                        |\n",
            "|{chunk, 203, 225, Delaware corporation (\", {entity -> UNK, chunk -> 29, sentence -> 0}, []}                                                        |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 30 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "ngram_ner_results.selectExpr(\"explode(merged_chunks) AS key_phrase_candidate\").show(30,truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1fv9UDYYxCz",
        "outputId": "36bbfdfc-780a-4af0-aaa9-f0f9aa3fd4dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------------------------------+-----------+\n",
            "|key_phrase_candidate               |label      |\n",
            "+-----------------------------------+-----------+\n",
            "|INTELLECTUAL PROPERTY AGREEMENT    |DOC        |\n",
            "|INTELLECTUAL PROPERTY AGREEMENT    |DOC        |\n",
            "|December 31, 2018                  |EFFDATE    |\n",
            "|Armstrong Flooring, Inc            |PARTY      |\n",
            "|Seller                             |ALIAS      |\n",
            "|AFI Licensing LLC                  |PARTY      |\n",
            "|Licensing                          |ALIAS      |\n",
            "|Seller                             |PARTY      |\n",
            "|Arizona                            |ALIAS      |\n",
            "|AHF Holding, Inc                   |PARTY      |\n",
            "|Tarzan HoldCo, Inc                 |FORMER_NAME|\n",
            "|Buyer                              |ALIAS      |\n",
            "|Armstrong Hardwood Flooring Company|PARTY      |\n",
            "|Company                            |ALIAS      |\n",
            "|Buyer                              |PARTY      |\n",
            "|Buyer Entities                     |ALIAS      |\n",
            "|Arizona                            |PARTY      |\n",
            "|Buyer Entities                     |PARTY      |\n",
            "|Party                              |ALIAS      |\n",
            "|Parties                            |ALIAS      |\n",
            "+-----------------------------------+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# NER chunk results\n",
        "ngram_ner_results.select(F.explode(F.arrays_zip(ngram_ner_results.merged_chunks.result,\n",
        "                                                ngram_ner_results.merged_chunks.metadata)).alias(\"cols\"))\\\n",
        "                 .select(F.expr(\"cols['0']\").alias(\"key_phrase_candidate\"),\n",
        "                         F.expr(\"cols['1']['entity']\").alias(\"label\")).filter(\"label != 'UNK'\").show(50, truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohSJbw9hY3pe",
        "outputId": "1ff856d5-ead9-491d-966a-c9cc325b005c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------------------------+-----+\n",
            "|key_phrase_candidate           |label|\n",
            "+-------------------------------+-----+\n",
            "|INTELLECTUAL PROPERTY AGREEMENT|UNK  |\n",
            "|PROPERTY AGREEMENT INTELLECTUAL|UNK  |\n",
            "|AGREEMENT INTELLECTUAL PROPERTY|UNK  |\n",
            "|INTELLECTUAL PROPERTY AGREEMENT|UNK  |\n",
            "|PROPERTY AGREEMENT (           |UNK  |\n",
            "|AGREEMENT ( \"                  |UNK  |\n",
            "|( \" Agreement                  |UNK  |\n",
            "|\" Agreement \"),                |UNK  |\n",
            "|Agreement \"), dated            |UNK  |\n",
            "|\"), dated December             |UNK  |\n",
            "|dated December 31              |UNK  |\n",
            "|December 31 ,                  |UNK  |\n",
            "|31 , 2018                      |UNK  |\n",
            "|, 2018 (                       |UNK  |\n",
            "|2018 ( \"                       |UNK  |\n",
            "|( \" Effective                  |UNK  |\n",
            "|\" Effective Date               |UNK  |\n",
            "|Effective Date \")              |UNK  |\n",
            "|Date \") entered                |UNK  |\n",
            "|\") entered Armstrong           |UNK  |\n",
            "|entered Armstrong Flooring     |UNK  |\n",
            "|Armstrong Flooring ,           |UNK  |\n",
            "|Flooring , .,                  |UNK  |\n",
            "|, ., Delaware                  |UNK  |\n",
            "|., Delaware corporation        |UNK  |\n",
            "|Delaware corporation (\"        |UNK  |\n",
            "|corporation (\" Seller          |UNK  |\n",
            "|(\" Seller \")                   |UNK  |\n",
            "|Seller \") AFI                  |UNK  |\n",
            "|\") AFI Licensing               |UNK  |\n",
            "|AFI Licensing LLC              |UNK  |\n",
            "|Licensing LLC ,                |UNK  |\n",
            "|LLC , Delaware                 |UNK  |\n",
            "|, Delaware limited             |UNK  |\n",
            "|Delaware limited liability     |UNK  |\n",
            "|limited liability company      |UNK  |\n",
            "|liability company (\"           |UNK  |\n",
            "|company (\" Licensing           |UNK  |\n",
            "|(\" Licensing \"                 |UNK  |\n",
            "|Licensing \" Seller             |UNK  |\n",
            "|\" Seller ,                     |UNK  |\n",
            "|Seller , \"                     |UNK  |\n",
            "|, \" Arizona                    |UNK  |\n",
            "|\" Arizona \")                   |UNK  |\n",
            "|Arizona \") AHF                 |UNK  |\n",
            "|\") AHF Holding                 |UNK  |\n",
            "|AHF Holding ,                  |UNK  |\n",
            "|Holding , .                    |UNK  |\n",
            "|, . (                          |UNK  |\n",
            "|. ( Tarzan                     |UNK  |\n",
            "+-------------------------------+-----+\n",
            "only showing top 50 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ngram results\n",
        "ngram_ner_results.select(F.explode(F.arrays_zip(ngram_ner_results.merged_chunks.result,\n",
        "                                                ngram_ner_results.merged_chunks.metadata)).alias(\"cols\"))\\\n",
        "                 .select(F.expr(\"cols['0']\").alias(\"key_phrase_candidate\"),\n",
        "                         F.expr(\"cols['1']['entity']\").alias(\"label\")).filter(\"label == 'UNK'\").show(50, truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8IqP7CuY7os",
        "outputId": "b4af4647-5b11-4033-93c1-a2e05fbee900"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------------------------+-------+\n",
            "|key_phrase_candidate           |label  |\n",
            "+-------------------------------+-------+\n",
            "|INTELLECTUAL PROPERTY AGREEMENT|UNK    |\n",
            "|INTELLECTUAL PROPERTY AGREEMENT|DOC    |\n",
            "|PROPERTY AGREEMENT INTELLECTUAL|UNK    |\n",
            "|AGREEMENT INTELLECTUAL PROPERTY|UNK    |\n",
            "|INTELLECTUAL PROPERTY AGREEMENT|UNK    |\n",
            "|INTELLECTUAL PROPERTY AGREEMENT|DOC    |\n",
            "|PROPERTY AGREEMENT (           |UNK    |\n",
            "|AGREEMENT ( \"                  |UNK    |\n",
            "|( \" Agreement                  |UNK    |\n",
            "|\" Agreement \"),                |UNK    |\n",
            "|Agreement \"), dated            |UNK    |\n",
            "|\"), dated December             |UNK    |\n",
            "|dated December 31              |UNK    |\n",
            "|December 31 ,                  |UNK    |\n",
            "|December 31, 2018              |EFFDATE|\n",
            "|31 , 2018                      |UNK    |\n",
            "|, 2018 (                       |UNK    |\n",
            "|2018 ( \"                       |UNK    |\n",
            "|( \" Effective                  |UNK    |\n",
            "|\" Effective Date               |UNK    |\n",
            "|Effective Date \")              |UNK    |\n",
            "|Date \") entered                |UNK    |\n",
            "|\") entered Armstrong           |UNK    |\n",
            "|entered Armstrong Flooring     |UNK    |\n",
            "|Armstrong Flooring ,           |UNK    |\n",
            "|Armstrong Flooring, Inc        |PARTY  |\n",
            "|Flooring , .,                  |UNK    |\n",
            "|, ., Delaware                  |UNK    |\n",
            "|., Delaware corporation        |UNK    |\n",
            "|Delaware corporation (\"        |UNK    |\n",
            "|corporation (\" Seller          |UNK    |\n",
            "|(\" Seller \")                   |UNK    |\n",
            "|Seller                         |ALIAS  |\n",
            "|Seller \") AFI                  |UNK    |\n",
            "|\") AFI Licensing               |UNK    |\n",
            "|AFI Licensing LLC              |UNK    |\n",
            "|AFI Licensing LLC              |PARTY  |\n",
            "|Licensing LLC ,                |UNK    |\n",
            "|LLC , Delaware                 |UNK    |\n",
            "|, Delaware limited             |UNK    |\n",
            "|Delaware limited liability     |UNK    |\n",
            "|limited liability company      |UNK    |\n",
            "|liability company (\"           |UNK    |\n",
            "|company (\" Licensing           |UNK    |\n",
            "|(\" Licensing \"                 |UNK    |\n",
            "|Licensing                      |ALIAS  |\n",
            "|Licensing \" Seller             |UNK    |\n",
            "|\" Seller ,                     |UNK    |\n",
            "|Seller                         |PARTY  |\n",
            "|Seller , \"                     |UNK    |\n",
            "+-------------------------------+-------+\n",
            "only showing top 50 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# merged (NER chunk + ngram) results\n",
        "ngram_ner_results.select(F.explode(F.arrays_zip(ngram_ner_results.merged_chunks.result,\n",
        "                                                ngram_ner_results.merged_chunks.metadata)).alias(\"cols\"))\\\n",
        "                 .select(F.expr(\"cols['0']\").alias(\"key_phrase_candidate\"),\n",
        "                         F.expr(\"cols['1']['entity']\").alias(\"label\")).show(50, truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_r745LNZjX_",
        "outputId": "e1ddaa24-6b9b-44f7-c1c6-de0f5a5f1cec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------------------------+------+--------+\n",
            "|key_phrase_candidate           |source|sentence|\n",
            "+-------------------------------+------+--------+\n",
            "|INTELLECTUAL PROPERTY AGREEMENT|ngram |0       |\n",
            "|INTELLECTUAL PROPERTY AGREEMENT|NER   |0       |\n",
            "|PROPERTY AGREEMENT INTELLECTUAL|ngram |0       |\n",
            "|AGREEMENT INTELLECTUAL PROPERTY|ngram |0       |\n",
            "|INTELLECTUAL PROPERTY AGREEMENT|ngram |0       |\n",
            "|INTELLECTUAL PROPERTY AGREEMENT|NER   |0       |\n",
            "|PROPERTY AGREEMENT (           |ngram |0       |\n",
            "|AGREEMENT ( \"                  |ngram |0       |\n",
            "|( \" Agreement                  |ngram |0       |\n",
            "|\" Agreement \"),                |ngram |0       |\n",
            "|Agreement \"), dated            |ngram |0       |\n",
            "|\"), dated December             |ngram |0       |\n",
            "|dated December 31              |ngram |0       |\n",
            "|December 31 ,                  |ngram |0       |\n",
            "|December 31, 2018              |NER   |0       |\n",
            "|31 , 2018                      |ngram |0       |\n",
            "|, 2018 (                       |ngram |0       |\n",
            "|2018 ( \"                       |ngram |0       |\n",
            "|( \" Effective                  |ngram |0       |\n",
            "|\" Effective Date               |ngram |0       |\n",
            "|Effective Date \")              |ngram |0       |\n",
            "|Date \") entered                |ngram |0       |\n",
            "|\") entered Armstrong           |ngram |0       |\n",
            "|entered Armstrong Flooring     |ngram |0       |\n",
            "|Armstrong Flooring ,           |ngram |0       |\n",
            "|Armstrong Flooring, Inc        |NER   |0       |\n",
            "|Flooring , .,                  |ngram |0       |\n",
            "|, ., Delaware                  |ngram |0       |\n",
            "|., Delaware corporation        |ngram |0       |\n",
            "|Delaware corporation (\"        |ngram |0       |\n",
            "|corporation (\" Seller          |ngram |0       |\n",
            "|(\" Seller \")                   |ngram |0       |\n",
            "|Seller                         |NER   |0       |\n",
            "|Seller \") AFI                  |ngram |0       |\n",
            "|\") AFI Licensing               |ngram |0       |\n",
            "|AFI Licensing LLC              |ngram |0       |\n",
            "|AFI Licensing LLC              |NER   |0       |\n",
            "|Licensing LLC ,                |ngram |0       |\n",
            "|LLC , Delaware                 |ngram |0       |\n",
            "|, Delaware limited             |ngram |0       |\n",
            "|Delaware limited liability     |ngram |0       |\n",
            "|limited liability company      |ngram |0       |\n",
            "|liability company (\"           |ngram |0       |\n",
            "|company (\" Licensing           |ngram |0       |\n",
            "|(\" Licensing \"                 |ngram |0       |\n",
            "|Licensing                      |NER   |0       |\n",
            "|Licensing \" Seller             |ngram |0       |\n",
            "|\" Seller ,                     |ngram |0       |\n",
            "|Seller                         |NER   |0       |\n",
            "|Seller , \"                     |ngram |0       |\n",
            "+-------------------------------+------+--------+\n",
            "only showing top 50 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "ngram_ner_results.selectExpr(\"explode(merged_chunks) AS key_phrase_candidate\")\\\n",
        "                 .selectExpr(\"key_phrase_candidate.result AS key_phrase_candidate\",\n",
        "                             \"IF(key_phrase_candidate.metadata.entity = 'UNK', 'ngram', 'NER') AS source\",\n",
        "                             \"key_phrase_candidate.metadata.sentence\")\\\n",
        "                 .show(50, truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMAoOamcZj7k",
        "outputId": "166b3f5f-e373-46b8-8c93-e65e625476ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------------------------------+-----------+-------------------+--------------------+--------+\n",
            "|key_phrase                         |label      |DocumentSimilarity |MMRScore            |sentence|\n",
            "+-----------------------------------+-----------+-------------------+--------------------+--------+\n",
            "|LLC Delaware                       |UNK        |0.67082428827937   |0.4024945889613194  |0       |\n",
            "|Licensing LLC                      |UNK        |0.623435274176818  |0.07391284062011122 |0       |\n",
            "|Licensing \" Seller                 |UNK        |0.5620123028023943 |0.10101117303174226 |0       |\n",
            "|corporation \" Seller               |UNK        |0.5601213486826419 |0.03941356508847493 |0       |\n",
            "|Tarzan HoldCo, Inc                 |FORMER_NAME|0.5367663102209614 |0.14132001185836535 |1       |\n",
            "|Arizona hand Buyer                 |UNK        |0.5298374343984847 |0.11960417979726506 |0       |\n",
            "|AHF Holding, Inc                   |PARTY      |0.5268001425682903 |0.07314865925079808 |0       |\n",
            "|INTELLECTUAL PROPERTY AGREEMENT    |UNK        |0.5139882459942415 |0.11717650664539808 |0       |\n",
            "|Armstrong Hardwood Flooring Company|PARTY      |0.43693383662177004|0.07879576837459534 |1       |\n",
            "|limited liability company          |UNK        |0.4326145252236725 |0.029044517194122432|0       |\n",
            "+-----------------------------------+-----------+-------------------+--------------------+--------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "ngram_ner_results.select(F.explode(F.arrays_zip(ngram_ner_results.key_phrases.result,\n",
        "                                                ngram_ner_results.key_phrases.metadata)).alias(\"cols\"))\\\n",
        "                 .select(F.expr(\"cols['0']\").alias(\"key_phrase\"),\n",
        "                         F.expr(\"cols['1']['entity']\").alias(\"label\"),\n",
        "                         F.expr(\"cols['1']['DocumentSimilarity']\").alias(\"DocumentSimilarity\"),\n",
        "                         F.expr(\"cols['1']['MMRScore']\").alias(\"MMRScore\"),\n",
        "                         F.expr(\"cols['1']['sentence']\").alias(\"sentence\")).show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eu6QKAldZySR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "tf-gpu",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "3f47d918ae832c68584484921185f5c85a1760864bf927a683dc6fb56366cc77"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
