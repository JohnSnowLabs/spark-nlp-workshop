{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b7f2c545-14d6-41da-a4cc-0dc8a6ea3180",
      "metadata": {
        "id": "b7f2c545-14d6-41da-a4cc-0dc8a6ea3180"
      },
      "source": [
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21e9eafb",
      "metadata": {
        "id": "21e9eafb"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/legal-nlp/11.Deidentification.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb2ac5e3-fe7c-4431-bb24-3c48649be54b",
      "metadata": {
        "id": "fb2ac5e3-fe7c-4431-bb24-3c48649be54b"
      },
      "source": [
        "# Legal Deidentification"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gk3kZHmNj51v",
      "metadata": {
        "collapsed": false,
        "id": "gk3kZHmNj51v"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_914itZsj51v",
      "metadata": {
        "id": "_914itZsj51v",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [],
      "source": [
        "! pip install -q johnsnowlabs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YPsbAnNoPt0Z",
      "metadata": {
        "id": "YPsbAnNoPt0Z"
      },
      "source": [
        "## Automatic Installation\n",
        "Using my.johnsnowlabs.com SSO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fY0lcShkj51w",
      "metadata": {
        "id": "fY0lcShkj51w",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [],
      "source": [
        "from johnsnowlabs import nlp, legal\n",
        "\n",
        "# nlp.install(force_browser=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hsJvn_WWM2GL",
      "metadata": {
        "id": "hsJvn_WWM2GL"
      },
      "source": [
        "## Manual downloading\n",
        "If you are not registered in my.johnsnowlabs.com, you received a license via e-email or you are using Safari, you may need to do a manual update of the license.\n",
        "\n",
        "- Go to my.johnsnowlabs.com\n",
        "- Download your license\n",
        "- Upload it using the following command"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "i57QV3-_P2sQ",
      "metadata": {
        "id": "i57QV3-_P2sQ"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "print('Please Upload your John Snow Labs License using the button below')\n",
        "license_keys = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xGgNdFzZP_hQ",
      "metadata": {
        "id": "xGgNdFzZP_hQ"
      },
      "source": [
        "- Install it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OfmmPqknP4rR",
      "metadata": {
        "id": "OfmmPqknP4rR"
      },
      "outputs": [],
      "source": [
        "nlp.install()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DCl5ErZkNNLk",
      "metadata": {
        "id": "DCl5ErZkNNLk"
      },
      "source": [
        "# Starting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "wRXTnNl3j51w",
      "metadata": {
        "id": "wRXTnNl3j51w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a13460d-e842-423f-e151-63e8e0565657"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "👌 Launched \u001b[92mcpu optimized\u001b[39m session with with: 🚀Spark-NLP==4.3.0, 💊Spark-Healthcare==4.3.0, running on ⚡ PySpark==3.1.2\n"
          ]
        }
      ],
      "source": [
        "spark = nlp.start()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c5c1990-1e00-4141-8825-5e9e75d402ad",
      "metadata": {
        "id": "3c5c1990-1e00-4141-8825-5e9e75d402ad"
      },
      "source": [
        "# Deidentification Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "124c01da-b9a9-4327-a46b-f09d1d89d893",
      "metadata": {
        "id": "124c01da-b9a9-4327-a46b-f09d1d89d893"
      },
      "source": [
        "Some legal information can be considered sensitive. (e.g.,document, organization, address, signer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "fc92df9a-8ede-4db3-80b9-be1e713f45d6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc92df9a-8ede-4db3-80b9-be1e713f45d6",
        "outputId": "357d978c-46d3-4755-97aa-13f6e3a88484"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentence_detector_dl download started this may take some time.\n",
            "Approximate size to download 514.9 KB\n",
            "[OK!]\n",
            "roberta_embeddings_legal_roberta_base download started this may take some time.\n",
            "Approximate size to download 447.2 MB\n",
            "[OK!]\n",
            "legner_contract_doc_parties_lg download started this may take some time.\n",
            "[OK!]\n"
          ]
        }
      ],
      "source": [
        "documentAssembler = nlp.DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "sentenceDetector = nlp.SentenceDetectorDLModel.pretrained(\"sentence_detector_dl\",\"xx\")\\\n",
        "    .setInputCols([\"document\"])\\\n",
        "    .setOutputCol(\"sentence\")\n",
        "    #.setCustomBounds([\"\\n\\n\"])\n",
        "\n",
        "tokenizer = nlp.Tokenizer()\\\n",
        "    .setInputCols([\"sentence\"])\\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "embeddings = nlp.RoBertaEmbeddings.pretrained(\"roberta_embeddings_legal_roberta_base\",\"en\") \\\n",
        "    .setInputCols([\"sentence\", \"token\"]) \\\n",
        "    .setOutputCol(\"embeddings\")\n",
        "\n",
        "legal_ner = legal.NerModel.pretrained(\"legner_contract_doc_parties_lg\", \"en\", \"legal/models\")\\\n",
        "    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
        "    .setOutputCol(\"ner\") \n",
        "    #.setLabelCasing(\"upper\")\n",
        "\n",
        "ner_converter = legal.NerConverterInternal() \\\n",
        "    .setInputCols([\"sentence\", \"token\", \"ner\"])\\\n",
        "    .setOutputCol(\"ner_chunk\")\\\n",
        "    .setReplaceLabels({\"ALIAS\": \"PARTY\"}) # \"ALIAS\" are secondary names of companies, so let's extract them also as PARTY\n",
        "\n",
        "nlpPipeline = nlp.Pipeline(stages=[\n",
        "      documentAssembler, \n",
        "      sentenceDetector,\n",
        "      tokenizer,\n",
        "      embeddings,\n",
        "      legal_ner,\n",
        "      ner_converter])\n",
        "\n",
        "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
        "\n",
        "model = nlpPipeline.fit(empty_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ddb9087-f3d2-4b14-89ad-507e3910e889",
      "metadata": {
        "id": "3ddb9087-f3d2-4b14-89ad-507e3910e889"
      },
      "source": [
        "### Pretrained NER models extracts:\n",
        "- Document\n",
        "- Date\n",
        "- Party (Organization Name)\n",
        "- Alias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f594290b-6ea9-47a2-9515-76faed5ab63c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f594290b-6ea9-47a2-9515-76faed5ab63c",
        "outputId": "9f244d94-0e98-4d37-b1aa-a25b1ea7b982"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O',\n",
              " 'B-ORG',\n",
              " 'I-DOC',\n",
              " 'B-EFFDATE',\n",
              " 'I-ORG',\n",
              " 'B-ALIAS',\n",
              " 'I-ALIAS',\n",
              " 'B-PARTY',\n",
              " 'I-EFFDATE',\n",
              " 'B-FORMER_NAME',\n",
              " 'I-FORMER_NAME',\n",
              " 'B-DOC',\n",
              " 'I-PARTY']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "legal_ner.getClasses()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "5f5fbf4b-ad6c-4042-8fff-4b6082aeed5c",
      "metadata": {
        "id": "5f5fbf4b-ad6c-4042-8fff-4b6082aeed5c"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"THIS STRATEGIC ALLIANCE AGREEMENT (\"Agreement\") is made and entered into as of December 14, 2016 , by and between Hyatt Franchising Latin America, L.L.C. a limited liability company organized and existing under the laws of the State of Delaware\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "7cd9d648-81ec-46fa-aa02-20506f0ba7dd",
      "metadata": {
        "id": "7cd9d648-81ec-46fa-aa02-20506f0ba7dd"
      },
      "outputs": [],
      "source": [
        "result = model.transform(spark.createDataFrame([[text]]).toDF(\"text\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "3fa9c519-347f-4f63-8f32-b240526ab42e",
      "metadata": {
        "id": "3fa9c519-347f-4f63-8f32-b240526ab42e"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "result_df = result.select(F.explode(F.arrays_zip(result.token.result, \n",
        "                                                 result.ner.result)).alias(\"cols\")) \\\n",
        "                  .select(F.expr(\"cols['0']\").alias(\"token\"),\n",
        "                          F.expr(\"cols['1']\").alias(\"ner_label\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "3df21455-9650-4d3d-8b11-8380a0883121",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3df21455-9650-4d3d-8b11-8380a0883121",
        "outputId": "d1be7a8f-b1eb-4a76-d13a-840a99c230ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----+\n",
            "|ner_label|count|\n",
            "+---------+-----+\n",
            "|O        |31   |\n",
            "|I-PARTY  |5    |\n",
            "|I-EFFDATE|3    |\n",
            "|I-DOC    |2    |\n",
            "|B-PARTY  |1    |\n",
            "|B-DOC    |1    |\n",
            "|B-EFFDATE|1    |\n",
            "+---------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result_df.select(\"token\", \"ner_label\").groupBy('ner_label').count().orderBy('count', ascending=False).show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba982823-16d8-477d-9a47-d41d9087523d",
      "metadata": {
        "id": "ba982823-16d8-477d-9a47-d41d9087523d"
      },
      "source": [
        "### Check extracted sensitive entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "8e766d87-e1f2-49e3-afe2-f7d0d7703e6f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e766d87-e1f2-49e3-afe2-f7d0d7703e6f",
        "outputId": "ffde5535-b0a6-424b-b09b-69604ecf231d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------+---------+\n",
            "|chunk                                 |ner_label|\n",
            "+--------------------------------------+---------+\n",
            "|STRATEGIC ALLIANCE AGREEMENT          |DOC      |\n",
            "|December 14, 2016                     |EFFDATE  |\n",
            "|Hyatt Franchising Latin America, L.L.C|PARTY    |\n",
            "+--------------------------------------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result.select(F.explode(F.arrays_zip(result.ner_chunk.result, \n",
        "                                     result.ner_chunk.metadata)).alias(\"cols\")) \\\n",
        "      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
        "              F.expr(\"cols['1']['entity']\").alias(\"ner_label\")).show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cccf04f-6630-4f8c-96af-f5b7e35c119d",
      "metadata": {
        "id": "7cccf04f-6630-4f8c-96af-f5b7e35c119d"
      },
      "source": [
        "## Masking and Obfuscation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4648bf0-9c6e-49b3-9080-7bb3551e1675",
      "metadata": {
        "id": "a4648bf0-9c6e-49b3-9080-7bb3551e1675"
      },
      "source": [
        "### Replace these enitites with Tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "id": "fa7ac54e-46d5-4a9b-a74b-3859a283ac65",
      "metadata": {
        "id": "fa7ac54e-46d5-4a9b-a74b-3859a283ac65"
      },
      "outputs": [],
      "source": [
        "deidentification = legal.DeIdentification() \\\n",
        "      .setInputCols([\"sentence\", \"token\", \"ner_chunk\"]) \\\n",
        "      .setOutputCol(\"deidentified\") \\\n",
        "      .setMode(\"mask\")\\\n",
        "      .setReturnEntityMappings(True) #  return a new column to save the mappings between the mask/obfuscated entities and original entities. REquired for \"ReIdentification\"\n",
        "      #.setMappingsColumn(\"MappingCol\") # change the name of the column, 'aux' is default\n",
        "\n",
        "deidPipeline = nlp.Pipeline(stages=[\n",
        "      documentAssembler, \n",
        "      sentenceDetector,\n",
        "      tokenizer,\n",
        "      embeddings,\n",
        "      legal_ner,\n",
        "      ner_converter,\n",
        "      deidentification])\n",
        "\n",
        "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
        "\n",
        "model_deid = deidPipeline.fit(empty_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "bf417b51-c6d0-44b3-ac80-43da90300247",
      "metadata": {
        "id": "bf417b51-c6d0-44b3-ac80-43da90300247"
      },
      "outputs": [],
      "source": [
        "result = model_deid.transform(spark.createDataFrame([[text]]).toDF(\"text\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "3bf8f80c-4277-4302-8993-a0f88311b66f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bf8f80c-4277-4302-8993-a0f88311b66f",
        "outputId": "eb609c57-8460-4892-888b-cd9c41414919"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                text|            document|            sentence|               token|          embeddings|                 ner|           ner_chunk|        deidentified|                 aux|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|THIS STRATEGIC AL...|[{document, 0, 24...|[{document, 0, 24...|[{token, 0, 3, TH...|[{word_embeddings...|[{named_entity, 0...|[{chunk, 5, 32, S...|[{document, 0, 18...|[{chunk, 5, 9, <D...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reIdentification = legal.ReIdentification()\\\n",
        "    .setInputCols([\"aux\",\"deidentified\"])\\\n",
        "    .setOutputCol(\"original\")"
      ],
      "metadata": {
        "id": "n1J-VZN6cH41"
      },
      "id": "n1J-VZN6cH41",
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reid_result = reIdentification.transform(result)"
      ],
      "metadata": {
        "id": "ofzMwi08cOoG"
      },
      "id": "ofzMwi08cOoG",
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reid_result.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtvYEclecQw3",
        "outputId": "b5262fd0-f2f8-477e-e600-1cac05fd7dd8"
      },
      "id": "AtvYEclecQw3",
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                text|            document|            sentence|               token|          embeddings|                 ner|           ner_chunk|        deidentified|                 aux|            original|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|THIS STRATEGIC AL...|[{document, 0, 24...|[{document, 0, 24...|[{token, 0, 3, TH...|[{word_embeddings...|[{named_entity, 0...|[{chunk, 5, 32, S...|[{document, 0, 18...|[{chunk, 5, 9, <D...|[{document, 0, 24...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ReIdentification"
      ],
      "metadata": {
        "id": "JxgYEb-fg4SE"
      },
      "id": "JxgYEb-fg4SE"
    },
    {
      "cell_type": "code",
      "source": [
        "print(text)\n",
        "\n",
        "reid_result.select('original.result').show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzV7G_HbcRF_",
        "outputId": "00a6e3f9-6b21-4bd9-b70b-74d45dce6d75"
      },
      "id": "CzV7G_HbcRF_",
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "THIS STRATEGIC ALLIANCE AGREEMENT (\"Agreement\") is made and entered into as of December 14, 2016 , by and between Hyatt Franchising Latin America, L.L.C. a limited liability company organized and existing under the laws of the State of Delaware\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|result                                                                                                                                                                                                                                                |\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|[THIS STRATEGIC ALLIANCE AGREEMENT (\"Agreement\") is made and entered into as of December 14, 2016 , by and between Hyatt Franchising Latin America, L.L.C. a limited liability company organized and existing under the laws of the State of Delaware]|\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "a8892001-1392-4bc2-ab92-81d565c9d996",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "a8892001-1392-4bc2-ab92-81d565c9d996",
        "outputId": "d7d0072e-6901-4d3d-d286-9bd90c49a44e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            sentence  \\\n",
              "0  THIS STRATEGIC ALLIANCE AGREEMENT (\"Agreement\"...   \n",
              "\n",
              "                                        deidentified  \n",
              "0  THIS <DOC> (\"Agreement\") is made and entered i...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1a6e6b0a-da51-4c1b-b3f9-e84d9d170d78\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>deidentified</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>THIS STRATEGIC ALLIANCE AGREEMENT (\"Agreement\"...</td>\n",
              "      <td>THIS &lt;DOC&gt; (\"Agreement\") is made and entered i...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a6e6b0a-da51-4c1b-b3f9-e84d9d170d78')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1a6e6b0a-da51-4c1b-b3f9-e84d9d170d78 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1a6e6b0a-da51-4c1b-b3f9-e84d9d170d78');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "result.select(F.explode(F.arrays_zip(result.sentence.result, result.deidentified.result)).alias(\"cols\")) \\\n",
        "      .select(F.expr(\"cols['0']\").alias(\"sentence\"), F.expr(\"cols['1']\").alias(\"deidentified\")).toPandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Other different masking strategies "
      ],
      "metadata": {
        "id": "5MQrBZl3cbEb"
      },
      "id": "5MQrBZl3cbEb"
    },
    {
      "cell_type": "markdown",
      "id": "fc7f7662-6fb7-4ad6-b7a8-aa9587dafc85",
      "metadata": {
        "id": "fc7f7662-6fb7-4ad6-b7a8-aa9587dafc85"
      },
      "source": [
        "We have three modes to mask the entities in the Deidentification annotator. You can select the modes using the `.setMaskingPolicy()` parameter. The methods are the followings:\n",
        "\n",
        "**“entity_labels”**: Mask with the entity type of that chunk. (default) <br/>\n",
        "**“same_length_chars”**: Mask the deid entities with same length of asterix ( * ) with brackets ( [ , ] ) on both end. <br/>\n",
        "**“fixed_length_chars”**: Mask the deid entities with a fixed length of asterix ( * ). The length is setting up using the `setFixedMaskLength()` method. <br/>\n",
        "\n",
        "Let's try each of these and compare the results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "2294859f-933e-4675-a573-bc67c7dc7ce5",
      "metadata": {
        "id": "2294859f-933e-4675-a573-bc67c7dc7ce5"
      },
      "outputs": [],
      "source": [
        "#deid model with \"entity_labels\"\n",
        "deid_entity_labels= legal.DeIdentification()\\\n",
        "    .setInputCols([\"sentence\", \"token\", \"ner_chunk\"])\\\n",
        "    .setOutputCol(\"deid_entity_label\")\\\n",
        "    .setMode(\"mask\")\\\n",
        "    .setReturnEntityMappings(False)\\\n",
        "    .setMaskingPolicy(\"entity_labels\")\n",
        "\n",
        "#deid model with \"same_length_chars\"\n",
        "deid_same_length= legal.DeIdentification()\\\n",
        "    .setInputCols([\"sentence\", \"token\", \"ner_chunk\"])\\\n",
        "    .setOutputCol(\"deid_same_length\")\\\n",
        "    .setMode(\"mask\")\\\n",
        "    .setReturnEntityMappings(False)\\\n",
        "    .setMaskingPolicy(\"same_length_chars\")\n",
        "\n",
        "#deid model with \"fixed_length_chars\"\n",
        "deid_fixed_length= legal.DeIdentification()\\\n",
        "    .setInputCols([\"sentence\", \"token\", \"ner_chunk\"])\\\n",
        "    .setOutputCol(\"deid_fixed_length\")\\\n",
        "    .setMode(\"mask\")\\\n",
        "    .setReturnEntityMappings(False)\\\n",
        "    .setMaskingPolicy(\"fixed_length_chars\")\\\n",
        "    .setFixedMaskLength(4)\n",
        "\n",
        "\n",
        "deidPipeline = nlp.Pipeline(stages=[\n",
        "      documentAssembler, \n",
        "      sentenceDetector,\n",
        "      tokenizer,\n",
        "      embeddings,\n",
        "      legal_ner,\n",
        "      ner_converter,\n",
        "      deid_entity_labels,\n",
        "      deid_same_length,\n",
        "      deid_fixed_length])\n",
        "\n",
        "\n",
        "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
        "model_deid = deidPipeline.fit(empty_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "id": "a5d82d09-b920-45e3-8856-cbb3a43697af",
      "metadata": {
        "id": "a5d82d09-b920-45e3-8856-cbb3a43697af"
      },
      "outputs": [],
      "source": [
        "result = model_deid.transform(spark.createDataFrame([[text]]).toDF(\"text\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "d94fccb3-8874-428e-8cf3-2ed1bf443002",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d94fccb3-8874-428e-8cf3-2ed1bf443002",
        "outputId": "f1be16a3-d1a5-495d-8c0b-33889a63d336"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                text|            document|            sentence|               token|          embeddings|                 ner|           ner_chunk|   deid_entity_label|                 aux|    deid_same_length|   deid_fixed_length|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|THIS STRATEGIC AL...|[{document, 0, 24...|[{document, 0, 24...|[{token, 0, 3, TH...|[{word_embeddings...|[{named_entity, 0...|[{chunk, 5, 32, S...|[{document, 0, 18...|[{chunk, 5, 8, **...|[{document, 0, 24...|[{document, 0, 17...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "id": "f759241e-63a1-47ef-a562-a0a0272ed0e0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "f759241e-63a1-47ef-a562-a0a0272ed0e0",
        "outputId": "4b4de30f-54e2-449a-faf9-b953816d08c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            sentence  \\\n",
              "0  THIS STRATEGIC ALLIANCE AGREEMENT (\"Agreement\"...   \n",
              "\n",
              "                                   deid_entity_label  \\\n",
              "0  THIS <DOC> (\"Agreement\") is made and entered i...   \n",
              "\n",
              "                                    deid_same_length  \\\n",
              "0  THIS [**************************] (\"Agreement\"...   \n",
              "\n",
              "                                   deid_fixed_length  \n",
              "0  THIS **** (\"Agreement\") is made and entered in...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9271f0ed-d09f-4197-be59-4a4a6ad60648\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>deid_entity_label</th>\n",
              "      <th>deid_same_length</th>\n",
              "      <th>deid_fixed_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>THIS STRATEGIC ALLIANCE AGREEMENT (\"Agreement\"...</td>\n",
              "      <td>THIS &lt;DOC&gt; (\"Agreement\") is made and entered i...</td>\n",
              "      <td>THIS [**************************] (\"Agreement\"...</td>\n",
              "      <td>THIS **** (\"Agreement\") is made and entered in...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9271f0ed-d09f-4197-be59-4a4a6ad60648')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9271f0ed-d09f-4197-be59-4a4a6ad60648 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9271f0ed-d09f-4197-be59-4a4a6ad60648');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ],
      "source": [
        "result.select(F.explode(F.arrays_zip(result.sentence.result, \n",
        "                                            result.deid_entity_label.result, \n",
        "                                            result.deid_same_length.result, \n",
        "                                            result.deid_fixed_length.result)).alias(\"cols\")) \\\n",
        "             .select(F.expr(\"cols['0']\").alias(\"sentence\"),\n",
        "                     F.expr(\"cols['1']\").alias(\"deid_entity_label\"),\n",
        "                     F.expr(\"cols['2']\").alias(\"deid_same_length\"),\n",
        "                     F.expr(\"cols['3']\").alias(\"deid_fixed_length\")).toPandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24ad89cd-3022-46df-b4a1-6f6d90d0445a",
      "metadata": {
        "id": "24ad89cd-3022-46df-b4a1-6f6d90d0445a"
      },
      "source": [
        "### Mapping Column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "id": "941bfa77-2a19-4d47-ace2-0d5c6eb66514",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "941bfa77-2a19-4d47-ace2-0d5c6eb66514",
        "outputId": "cd86f045-2e60-498c-9ac6-6f122fcfcd28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|aux                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|[{chunk, 5, 8, ****, {originalChunk -> STRATEGIC ALLIANCE AGREEMENT, chunk -> 0, beginOriginalChunk -> 5, confidence -> 0.9776667, ner_source -> ner_chunk, entity -> DOC, endOriginalChunk -> 32, sentence -> 0}, []}, {chunk, 55, 58, ****, {originalChunk -> December 14, 2016, chunk -> 1, beginOriginalChunk -> 79, confidence -> 0.99065, ner_source -> ner_chunk, entity -> EFFDATE, endOriginalChunk -> 95, sentence -> 0}, []}, {chunk, 77, 80, ****, {originalChunk -> Hyatt Franchising Latin America, L.L.C, chunk -> 2, beginOriginalChunk -> 114, confidence -> 0.9488333, ner_source -> ner_chunk, entity -> PARTY, endOriginalChunk -> 151, sentence -> 0}, []}]|\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result.select(\"aux\").show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "ea4502c9-ae7b-4bf0-97ec-0ed7a6ba2f32",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea4502c9-ae7b-4bf0-97ec-0ed7a6ba2f32",
        "outputId": "4d1ed294-245e-4fce-f6ad-e9e7fc39bebc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------+----------+--------+-------+----------+--------+\n",
            "|chunk                                 |beginChunk|endChunk|label  |beginLabel|endLabel|\n",
            "+--------------------------------------+----------+--------+-------+----------+--------+\n",
            "|STRATEGIC ALLIANCE AGREEMENT          |5         |32      |DOC    |5         |8       |\n",
            "|December 14, 2016                     |79        |95      |EFFDATE|55        |58      |\n",
            "|Hyatt Franchising Latin America, L.L.C|114       |151     |PARTY  |77        |80      |\n",
            "+--------------------------------------+----------+--------+-------+----------+--------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result.select(F.explode(F.arrays_zip(result.aux.metadata,\n",
        "                                     result.aux.begin, \n",
        "                                     result.aux.end)).alias(\"cols\")) \\\n",
        "      .select(F.expr(\"cols['0']['originalChunk']\").alias(\"chunk\"),\n",
        "              F.expr(\"cols['0']['beginOriginalChunk']\").alias(\"beginChunk\"),\n",
        "              F.expr(\"cols['0']['endOriginalChunk']\").alias(\"endChunk\"),\n",
        "              F.expr(\"cols['0']['entity']\").alias(\"label\"),\n",
        "              F.expr(\"cols['1']\").alias(\"beginLabel\"),\n",
        "              F.expr(\"cols['2']\").alias(\"endLabel\")).show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27d5c012-0eef-48a5-9d3d-915e942f5639",
      "metadata": {
        "id": "27d5c012-0eef-48a5-9d3d-915e942f5639"
      },
      "source": [
        "## Using NER, ContextualParser and ZeroShotNER in the same Deideintification pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create JSON file for PART\n",
        "alias = {\n",
        "  \"entity\": \"ALIAS\",\n",
        "  \"ruleScope\": \"document\", \n",
        "  \"completeMatchRegex\": \"true\",\n",
        "  \"regex\":'[\"“].*?[\"”]',\n",
        "  \"matchScope\": \"sub-token\",\n",
        "  \"contextLength\": 100\n",
        "}\n",
        "\n",
        "email = {\n",
        "  \"entity\": \"EMAIL\",\n",
        "  \"ruleScope\": \"document\", \n",
        "  \"completeMatchRegex\": \"true\",\n",
        "  \"regex\":'[\\w-\\.]+@([\\w-]+\\.)+[\\w-]{2,4}',\n",
        "  \"matchScope\": \"sub-token\",\n",
        "  \"contextLength\": 100\n",
        "}\n",
        "\n",
        "phone = {\n",
        "  \"entity\": \"PHONE\",\n",
        "  \"ruleScope\": \"document\", \n",
        "  \"completeMatchRegex\": \"true\",\n",
        "  \"regex\":'(\\+?\\d{1,3}[\\s-]?)?\\(?\\d{3}\\)?[\\s.-]?\\d{3}[\\s.-]?\\d+',\n",
        "  \"matchScope\": \"sub-token\",\n",
        "  \"contextLength\": 100\n",
        "}\n",
        "\n",
        "import json\n",
        "with open('alias.json', 'w') as f:\n",
        "    json.dump(alias, f)\n",
        "    \n",
        "with open('email.json', 'w') as f:\n",
        "    json.dump(email, f)\n",
        "    \n",
        "with open('phone.json', 'w') as f:\n",
        "    json.dump(phone, f)"
      ],
      "metadata": {
        "id": "Pexzov3sc0Kd"
      },
      "id": "Pexzov3sc0Kd",
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "id": "4b11381f-af80-49e7-9d30-418a753fa08f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b11381f-af80-49e7-9d30-418a753fa08f",
        "outputId": "d0d8e06d-5578-4d68-ba1b-9176b36c0021"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentence_detector_dl download started this may take some time.\n",
            "Approximate size to download 514.9 KB\n",
            "[OK!]\n",
            "roberta_embeddings_legal_roberta_base download started this may take some time.\n",
            "Approximate size to download 447.2 MB\n",
            "[OK!]\n",
            "legner_contract_doc_parties_lg download started this may take some time.\n",
            "[OK!]\n",
            "legner_roberta_zeroshot download started this may take some time.\n",
            "[OK!]\n",
            "legner_signers download started this may take some time.\n",
            "[OK!]\n"
          ]
        }
      ],
      "source": [
        "documentAssembler = nlp.DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "sentenceDetector = nlp.SentenceDetectorDLModel.pretrained(\"sentence_detector_dl\",\"xx\")\\\n",
        "    .setInputCols([\"document\"])\\\n",
        "    .setOutputCol(\"sentence\")\n",
        "\n",
        "tokenizer = nlp.Tokenizer()\\\n",
        "    .setInputCols([\"sentence\"])\\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "embeddings = nlp.RoBertaEmbeddings.pretrained(\"roberta_embeddings_legal_roberta_base\",\"en\") \\\n",
        "    .setInputCols([\"sentence\", \"token\"]) \\\n",
        "    .setOutputCol(\"embeddings\")\n",
        "\n",
        "ner_model = legal.NerModel.pretrained('legner_contract_doc_parties_lg', 'en', 'legal/models')\\\n",
        "    .setInputCols([\"sentence\", \"token\", \"embeddings\"])\\\n",
        "    .setOutputCol(\"ner\")\n",
        "\n",
        "ner_converter = legal.NerConverterInternal() \\\n",
        "    .setInputCols([\"sentence\", \"token\", \"ner\"])\\\n",
        "    .setOutputCol(\"ner_chunk\")\\\n",
        "    .setWhiteList(['EFFDATE', 'PARTY', 'ALIAS'])\\\n",
        "    .setReplaceLabels({'FORMER_NAME': 'PARTY'})\\\n",
        "    .setGreedyMode(True)\n",
        "\n",
        "zero_shot_ner = legal.ZeroShotNerModel.pretrained(\"legner_roberta_zeroshot\", \"en\", \"legal/models\")\\\n",
        "    .setInputCols([\"sentence\", \"token\"])\\\n",
        "    .setOutputCol(\"zero_shot_ner\")\\\n",
        "    .setPredictionThreshold(0.1)\\\n",
        "    .setEntityDefinitions(\n",
        "        {\n",
        "            \n",
        "            \"ADDRESS\":[\"Which address?\", \"Where is the location?\"],\n",
        "            \"SIGNING_PERSON\": [\"Which person?\", \"What is the person name?\"],\n",
        "            \"PARTY\": [\"Which LLC?\", \"Which Inc?\", \"Which PLC?\", \"Which Corp?\"]\n",
        "        })\n",
        "\n",
        "\n",
        "zeroshot_ner_converter = legal.NerConverterInternal() \\\n",
        "    .setInputCols([\"sentence\", \"token\", \"zero_shot_ner\"])\\\n",
        "    .setOutputCol(\"zero_ner_chunk\")\\\n",
        "\n",
        "ner_model2 = legal.NerModel.pretrained('legner_signers', 'en', 'legal/models')\\\n",
        "        .setInputCols([\"sentence\", \"token\", \"embeddings\"])\\\n",
        "        .setOutputCol(\"ner2\")\n",
        "\n",
        "ner_converter2 = nlp.NerConverter()\\\n",
        "        .setInputCols([\"sentence\",\"token\",\"ner2\"])\\\n",
        "        .setOutputCol(\"ner_chunk2\")\n",
        "\n",
        "alias_parser = legal.ContextualParserApproach() \\\n",
        "    .setInputCols([\"sentence\", \"token\"]) \\\n",
        "    .setOutputCol(\"alias\")\\\n",
        "    .setJsonPath(\"alias.json\") \\\n",
        "    .setPrefixAndSuffixMatch(False)\\\n",
        "    .setOptionalContextRules(True)\\\n",
        "    .setCaseSensitive(False)\n",
        "\n",
        "email_parser = legal.ContextualParserApproach() \\\n",
        "    .setInputCols([\"sentence\", \"token\"]) \\\n",
        "    .setOutputCol(\"email\")\\\n",
        "    .setJsonPath(\"email.json\") \\\n",
        "    .setPrefixAndSuffixMatch(False)\\\n",
        "    .setOptionalContextRules(True)\\\n",
        "    .setCaseSensitive(False)\n",
        "\n",
        "phone_parser = legal.ContextualParserApproach() \\\n",
        "    .setInputCols([\"sentence\", \"token\"]) \\\n",
        "    .setOutputCol(\"phone\")\\\n",
        "    .setJsonPath(\"phone.json\") \\\n",
        "    .setPrefixAndSuffixMatch(False)\\\n",
        "    .setOptionalContextRules(True)\\\n",
        "    .setCaseSensitive(False)\n",
        "\n",
        "chunk_merger = legal.ChunkMergeApproach()\\\n",
        "    .setInputCols(\"email\", \"phone\", \"ner_chunk\", \"ner_chunk2\",\"zero_ner_chunk\", \"alias\")\\\n",
        "    .setOutputCol('merged_ner_chunks')\n",
        "\n",
        "nlpPipeline = nlp.Pipeline(stages=[\n",
        "      documentAssembler, \n",
        "      sentenceDetector,\n",
        "      tokenizer,\n",
        "      embeddings,\n",
        "      ner_model,\n",
        "      ner_converter,\n",
        "      ner_model2,\n",
        "      ner_converter2,\n",
        "      zero_shot_ner,\n",
        "      zeroshot_ner_converter,\n",
        "      alias_parser,\n",
        "      email_parser,\n",
        "      phone_parser,\n",
        "      chunk_merger])\n",
        "\n",
        "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
        "\n",
        "model = nlpPipeline.fit(empty_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "id": "8f4ef972-ad0c-4297-896a-94b639027810",
      "metadata": {
        "id": "8f4ef972-ad0c-4297-896a-94b639027810"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"\n",
        "This Commercial Lease (this “Lease”) dated February 11, 2021, but made effective as of January 1, 2021 (the “Effective Date”), is made by and between 605 NASH, LLC, a California limited liability company (“Landlord”) and NANTKWEST, INC., a Delaware corporation (“Tenant”).\n",
        "\n",
        "605 NASH, LLC,\t \tNANTKWEST, inc.,\n",
        "a California limited liability company\t \ta Delaware corporation\n",
        " \t \t \t \t \t \t \n",
        " \t \t \t \t \t \t \n",
        "By:\t \t/s/ Charles Kenworthy\t \tBy:\t \t/s/ Richard Adcock\n",
        "Name: Charles N. Kenworthy\t \tName: Richard Adcock\n",
        "Title:   Manager\t \tTitle:   CEO\n",
        " \t \t \t \t \t \t \n",
        "Address:\t \tAddress:\n",
        "9922 Jefferson Blvd.\t \t3530 Johns Hopkins Court\n",
        "Culver City, CA 90232\t \tSan Diego, CA 92121\n",
        "Attention: Chuck Kenworthy\t \tAttention: Chief Financial Officer\n",
        "Email:\n",
        "juan@johnsnowlabs.com\n",
        "Telephone numbers:\n",
        "304.123.333\n",
        "304-123-333\n",
        "+34 304-123-333\n",
        "0034304123333\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "id": "63fe74f9-768c-47c1-87e0-86d7a2a556bf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63fe74f9-768c-47c1-87e0-86d7a2a556bf",
        "outputId": "0dc39d96-c724-4f42-9593-e4a16782ecf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+---------+\n",
            "|chunk            |ner_label|\n",
            "+-----------------+---------+\n",
            "|February 11, 2021|EFFDATE  |\n",
            "|January 1, 2021  |EFFDATE  |\n",
            "|605 NASH, LLC    |PARTY    |\n",
            "|NANTKWEST, INC   |PARTY    |\n",
            "|NASH, LLC        |PARTY    |\n",
            "|NANTKWEST        |PARTY    |\n",
            "+-----------------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result = model.transform(spark.createDataFrame([[text]]).toDF(\"text\"))\n",
        "\n",
        "# legal_ner\n",
        "result.select(F.explode(F.arrays_zip(result.ner_chunk.result, \n",
        "                                     result.ner_chunk.metadata)).alias(\"cols\")) \\\n",
        "      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
        "              F.expr(\"cols['1']['entity']\").alias(\"ner_label\")).show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "id": "3256773b-3371-4af4-a4e3-34e2c818640c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3256773b-3371-4af4-a4e3-34e2c818640c",
        "outputId": "c9807bd3-b1db-437b-85bf-dad32b646ebf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------+--------------+\n",
            "|chunk                  |ner_label     |\n",
            "+-----------------------+--------------+\n",
            "|605                    |PARTY         |\n",
            "|NASH, LLC,             |PARTY         |\n",
            "|NANTKWEST, INC         |PARTY         |\n",
            "|NASH, LLC,             |PARTY         |\n",
            "|NANTKWEST, inc         |PARTY         |\n",
            "|Charles Kenworthy      |SIGNING_PERSON|\n",
            "|Richard Adcock         |SIGNING_PERSON|\n",
            "|Charles N. Kenworthy   |SIGNING_PERSON|\n",
            "|Richard Adcock         |SIGNING_PERSON|\n",
            "|Manager                |SIGNING_TITLE |\n",
            "|CEO                    |SIGNING_TITLE |\n",
            "|Chief Financial Officer|SIGNING_TITLE |\n",
            "+-----------------------+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ner_signers\n",
        "result.select(F.explode(F.arrays_zip(result.ner_chunk2.result, \n",
        "                                     result.ner_chunk2.metadata)).alias(\"cols\")) \\\n",
        "      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
        "              F.expr(\"cols['1']['entity']\").alias(\"ner_label\")).show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# zero_shot_ner\n",
        "result.select(F.explode(F.arrays_zip(result.zero_ner_chunk.result, \n",
        "                                     result.zero_ner_chunk.metadata)).alias(\"cols\")) \\\n",
        "      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
        "              F.expr(\"cols['1']['entity']\").alias(\"ner_label\")).show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWIpQahtd5qz",
        "outputId": "0a54019f-68f3-4cbc-8204-9cec8cda392b"
      },
      "id": "oWIpQahtd5qz",
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------+--------------+\n",
            "|chunk                                      |ner_label     |\n",
            "+-------------------------------------------+--------------+\n",
            "|LLC                                        |PARTY         |\n",
            "|NANTKWEST                                  |PARTY         |\n",
            "|INC                                        |PARTY         |\n",
            "|Delaware corporation (“Tenant”).           |PARTY         |\n",
            "|Charles Kenworthy                          |SIGNING_PERSON|\n",
            "|Richard Adcock                             |SIGNING_PERSON|\n",
            "|Charles N. Kenworthy                       |SIGNING_PERSON|\n",
            "|Richard Adcock                             |SIGNING_PERSON|\n",
            "|CEO                                        |SIGNING_PERSON|\n",
            "|9922 Jefferson Blvd                        |ADDRESS       |\n",
            "|3530 Johns Hopkins Court                   |ADDRESS       |\n",
            "|Culver City, CA 90232\t \tSan Diego, CA 92121|ADDRESS       |\n",
            "|Chuck Kenworthy                            |SIGNING_PERSON|\n",
            "|Chief Financial Officer                    |SIGNING_PERSON|\n",
            "+-------------------------------------------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "id": "4a899327-42d8-48c1-ab4a-5f692b10be22",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a899327-42d8-48c1-ab4a-5f692b10be22",
        "outputId": "691a122a-69c8-47ce-b473-1c3cd8c7b8bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------+--------------+\n",
            "|chunk                                      |ner_label     |\n",
            "+-------------------------------------------+--------------+\n",
            "|“Lease”                                    |ALIAS         |\n",
            "|February 11, 2021                          |EFFDATE       |\n",
            "|January 1, 2021                            |EFFDATE       |\n",
            "|“Effective Date”                           |ALIAS         |\n",
            "|605 NASH, LLC                              |PARTY         |\n",
            "|“Landlord”                                 |ALIAS         |\n",
            "|NANTKWEST, INC                             |PARTY         |\n",
            "|Delaware corporation (“Tenant”).           |PARTY         |\n",
            "|NASH, LLC,                                 |PARTY         |\n",
            "|NANTKWEST, inc                             |PARTY         |\n",
            "|Charles Kenworthy                          |SIGNING_PERSON|\n",
            "|Richard Adcock                             |SIGNING_PERSON|\n",
            "|Charles N. Kenworthy                       |SIGNING_PERSON|\n",
            "|Richard Adcock                             |SIGNING_PERSON|\n",
            "|Manager                                    |SIGNING_TITLE |\n",
            "|CEO                                        |SIGNING_TITLE |\n",
            "|9922 Jefferson Blvd                        |ADDRESS       |\n",
            "|3530 Johns Hopkins Court                   |ADDRESS       |\n",
            "|Culver City, CA 90232\t \tSan Diego, CA 92121|ADDRESS       |\n",
            "|Chuck Kenworthy                            |SIGNING_PERSON|\n",
            "|Chief Financial Officer                    |SIGNING_TITLE |\n",
            "|juan@johnsnowlabs.com                      |EMAIL         |\n",
            "|304.123.333                                |PHONE         |\n",
            "|304-123-333                                |PHONE         |\n",
            "|+34 304-123-333                            |PHONE         |\n",
            "|0034304123333                              |PHONE         |\n",
            "+-------------------------------------------+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# merged_chunk\n",
        "result.select(F.explode(F.arrays_zip(result.merged_ner_chunks.result, \n",
        "                                     result.merged_ner_chunks.metadata)).alias(\"cols\")) \\\n",
        "      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
        "              F.expr(\"cols['1']['entity']\").alias(\"ner_label\")).show(n=50, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0de79296-97f8-4daa-940c-1fd8d176c8c3",
      "metadata": {
        "id": "0de79296-97f8-4daa-940c-1fd8d176c8c3"
      },
      "source": [
        "## Obfuscation mode"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52e7c83b-780b-4d3e-be7f-604cd310babd",
      "metadata": {
        "id": "52e7c83b-780b-4d3e-be7f-604cd310babd"
      },
      "source": [
        "In the obfuscation mode **DeIdentificationModel** will replace sensitive entities with random values of the same type. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using external [Faker](https://faker.readthedocs.io/en/master/) library"
      ],
      "metadata": {
        "id": "3qJhJlKpegAA"
      },
      "id": "3qJhJlKpegAA"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWtHGsUIeh2J",
        "outputId": "c3815b6d-e96a-40ff-a178-2b7c97f82f1b"
      },
      "id": "DWtHGsUIeh2J",
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting faker\n",
            "  Downloading Faker-17.0.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.8/dist-packages (from faker) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.4->faker) (1.15.0)\n",
            "Installing collected packages: faker\n",
            "Successfully installed faker-17.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from faker import Faker\n",
        "fk = Faker()"
      ],
      "metadata": {
        "id": "14JQsuxjenrJ"
      },
      "id": "14JQsuxjenrJ",
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "id": "31b20c5a-bc56-43e1-9101-6503c23ab49b",
      "metadata": {
        "id": "31b20c5a-bc56-43e1-9101-6503c23ab49b"
      },
      "outputs": [],
      "source": [
        "# This is the obfuscation dict for the new entities\n",
        "obs_lines = \"\"\"CEO#SIGNING_TITLE\n",
        "Chief Executive Officer#SIGNING_TITLE\n",
        "Chief Legal Officer#SIGNING_TITLE\n",
        "Chief Financial officer#SIGNING_TITLE\n",
        "Legal Representative#SIGNING_TILE\n",
        "\"Alias\"#ALIAS\n",
        "\"Alias\"#ALIAS\"\"\"\n",
        "\n",
        "for _ in range(25):\n",
        "    add = fk.address().strip()\n",
        "    for ad in add.split('\\n'):\n",
        "        obs_lines += f\"\\n{ad}#ADDRESS\"\n",
        "    obs_lines += f\"\\n{fk.name().strip()}#SIGNING_PERSON\"\n",
        "    obs_lines += f\"\\n{fk.date().strip()}#EFFDATE\"\n",
        "    obs_lines += f\"\\n{fk.company().strip()}#PARTY\"\n",
        "    obs_lines += f\"\\n{fk.phone_number().strip()}#PHONE\"\n",
        "    obs_lines += f\"\\n{fk.email().strip()}#EMAIL\"\n",
        "\n",
        "with open ('obfuscate.txt', 'w') as f:\n",
        "    f.write(obs_lines)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Previous Masking Annotators\n",
        "#deid model with \"entity_labels\"\n",
        "deid_entity_labels= legal.DeIdentification()\\\n",
        "    .setInputCols([\"sentence\", \"token\", \"merged_ner_chunks\"])\\\n",
        "    .setOutputCol(\"deidentified\")\\\n",
        "    .setMode(\"mask\")\\\n",
        "    .setMaskingPolicy(\"entity_labels\")\n",
        "    \n",
        "#deid model with \"same_length_chars\"\n",
        "deid_same_length= legal.DeIdentification()\\\n",
        "    .setInputCols([\"sentence\", \"token\", \"merged_ner_chunks\"])\\\n",
        "    .setOutputCol(\"masked_with_chars\")\\\n",
        "    .setMode(\"mask\")\\\n",
        "    .setMaskingPolicy(\"same_length_chars\")\n",
        "\n",
        "#deid model with \"fixed_length_chars\"\n",
        "deid_fixed_length= legal.DeIdentification()\\\n",
        "    .setInputCols([\"sentence\", \"token\", \"merged_ner_chunks\"])\\\n",
        "    .setOutputCol(\"masked_fixed_length_chars\")\\\n",
        "    .setMode(\"mask\")\\\n",
        "    .setMaskingPolicy(\"fixed_length_chars\")\\\n",
        "    .setFixedMaskLength(4)\n"
      ],
      "metadata": {
        "id": "_wjSsNWPhp_p"
      },
      "id": "_wjSsNWPhp_p",
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "id": "210db7c7-e1a3-46ac-941f-160abc068ada",
      "metadata": {
        "id": "210db7c7-e1a3-46ac-941f-160abc068ada"
      },
      "outputs": [],
      "source": [
        "# Obfuscation with Faker\n",
        "obfuscation = legal.DeIdentification()\\\n",
        "    .setInputCols([\"sentence\", \"token\", \"merged_ner_chunks\"]) \\\n",
        "    .setOutputCol(\"obfuscated\") \\\n",
        "    .setMode(\"obfuscate\")\\\n",
        "    .setObfuscateDate(True)\\\n",
        "    .setObfuscateRefFile('obfuscate.txt')\\\n",
        "    .setObfuscateRefSource(\"both\")\n",
        "\n",
        "nlpPipeline = nlp.Pipeline(stages=[\n",
        "      documentAssembler, \n",
        "      sentenceDetector,\n",
        "      tokenizer,\n",
        "      embeddings,\n",
        "      ner_model,\n",
        "      ner_converter,\n",
        "      ner_model2,\n",
        "      ner_converter2,\n",
        "      zero_shot_ner,\n",
        "      zeroshot_ner_converter,\n",
        "      alias_parser,\n",
        "      email_parser,\n",
        "      phone_parser,\n",
        "      chunk_merger,\n",
        "      deid_entity_labels,\n",
        "      deid_same_length,\n",
        "      deid_fixed_length,\n",
        "      obfuscation])\n",
        "\n",
        "obfuscation_model = nlpPipeline.fit(empty_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "id": "38268201-7202-462e-b195-59709e7fdc8f",
      "metadata": {
        "id": "38268201-7202-462e-b195-59709e7fdc8f"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"This Commercial Lease (this “Lease”) dated February 11, 2021, but made effective as of January 1, 2021 (the “Effective Date”), is made by and between 605 NASH, LLC, a California limited liability company (“Landlord”) and NANTKWEST, INC., a Delaware corporation (“Tenant”).\n",
        "\n",
        "605 NASH, LLC,\t \tNANTKWEST, inc.,\n",
        "a California limited liability company\t \ta Delaware corporation\n",
        " \t \t \t \t \t \t \n",
        " \t \t \t \t \t \t \n",
        "By:\t \t/s/ Charles Kenworthy\t \tBy:\t \t/s/ Richard Adcock\n",
        "Name: Charles N. Kenworthy\t \tName: Richard Adcock\n",
        "Title:   Manager\t \tTitle:   CEO\n",
        " \t \t \t \t \t \t \n",
        "Address:\t \tAddress:\n",
        "9922 Jefferson Blvd.\t \t3530 Johns Hopkins Court\n",
        "Culver City, CA 90232\t \tSan Diego, CA 92121\n",
        "Attention: Chuck Kenworthy\t \tAttention: Chief Financial Officer cfo@johnkopkins.com (0031) 913-123\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "id": "0264dd21-5927-46b3-82f3-575d7a0b7a16",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0264dd21-5927-46b3-82f3-575d7a0b7a16",
        "outputId": "c40e5bfc-8cd2-485b-9ac8-89a99baf54f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This Commercial Lease (this \"Alias\") dated 1983-05-13, but made effective as of 1996-11-23 (the \"Alias\"), is made by and between Chandler and Sons Barker-Spencer a California limited liability company (\"Alias\") and Cook, Fleming and Scott., a Taylor, Weeks and Ellis corporation (\"Alias\").\n",
            "605 Barker-Spencer\t \tHardin Inc.,\n",
            "a California limited liability company\t \ta Delaware corporation\n",
            "By:\t \t/s/ Frances Spencer\t \tBy:\t \t/s/ Tracey Nichols\n",
            "Name: Paul Ramirez\t \tName: Tracey Nichols\n",
            "Title:   Chief Executive Officer\t \tTitle:   Chief Financial officer\n",
            " \t \t \t \t \t \t\n",
            "Address:\t \tAddress:\n",
            "348 Jason Walks.\n",
            "\t \tEast Brendan, NY 29514\n",
            "Richardsonfort, PA 54312\n",
            "Attention: Catherine Klein DVM\t \tAttention: Chief Financial officer Ilsa@hotmail.com (046 608 8269\n"
          ]
        }
      ],
      "source": [
        "result = obfuscation_model.transform(spark.createDataFrame([[text]]).toDF(\"text\"))\n",
        "print(\"\\n\".join(result.select('obfuscated.result').collect()[0].result))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ebd5940-8389-4acb-b505-6dab2eebbbb3",
      "metadata": {
        "id": "3ebd5940-8389-4acb-b505-6dab2eebbbb3"
      },
      "source": [
        "## Using Light Pipelines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "id": "79bba6fc-b913-4e23-b6e1-315616756073",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79bba6fc-b913-4e23-b6e1-315616756073",
        "outputId": "5e00bd4e-011d-4950-87db-7464756a479e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This Commercial Lease (this <ALIAS>) dated <EFFDATE>, but made effective as of <EFFDATE> (the <ALIAS>), is made by and between <PARTY> <PARTY> a California limited liability company (<ALIAS>) and <PARTY>., a <PARTY> corporation (<ALIAS>).\n",
            "605 <PARTY>\t \t<PARTY>.,\n",
            "a California limited liability company\t \ta Delaware corporation\n",
            "By:\t \t/s/ <SIGNING_PERSON>\t \tBy:\t \t/s/ <SIGNING_PERSON>\n",
            "Name: <SIGNING_PERSON>\t \tName: <SIGNING_PERSON>\n",
            "Title:   <SIGNING_TITLE>\t \tTitle:   <SIGNING_TITLE>\n",
            " \t \t \t \t \t \t\n",
            "Address:\t \tAddress:\n",
            "<ADDRESS>.\n",
            "\t \t<ADDRESS>\n",
            "<ADDRESS>\n",
            "Attention: <SIGNING_PERSON>\t \tAttention: <SIGNING_TITLE> <EMAIL> (<PHONE>\n"
          ]
        }
      ],
      "source": [
        "light_model = nlp.LightPipeline(obfuscation_model)\n",
        "annotated_text = light_model.annotate(text)\n",
        "print(\"\\n\".join(annotated_text['deidentified']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "id": "9f0c3c9f-b7b6-4e68-ae5d-9c8833bf06d4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9f0c3c9f-b7b6-4e68-ae5d-9c8833bf06d4",
        "outputId": "0e91a99d-8a52-4411-860d-1394e3ad198b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This Commercial Lease (this \"Alias\") dated 1983-05-13, but made effective as of 1996-11-23 (the \"Alias\"), is made by and between Chandler and Sons Barker-Spencer a California limited liability company (\"Alias\") and Cook, Fleming and Scott., a Taylor, Weeks and Ellis corporation (\"Alias\").\n",
            "605 Barker-Spencer\t \tHardin Inc.,\n",
            "a California limited liability company\t \ta Delaware corporation\n",
            "By:\t \t/s/ Frances Spencer\t \tBy:\t \t/s/ Tracey Nichols\n",
            "Name: Paul Ramirez\t \tName: Tracey Nichols\n",
            "Title:   Chief Executive Officer\t \tTitle:   Chief Financial officer\n",
            " \t \t \t \t \t \t\n",
            "Address:\t \tAddress:\n",
            "348 Jason Walks.\n",
            "\t \tEast Brendan, NY 29514\n",
            "Richardsonfort, PA 54312\n",
            "Attention: Catherine Klein DVM\t \tAttention: Chief Financial officer Ilsa@hotmail.com (046 608 8269\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\".join(annotated_text['obfuscated']))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zm9B278ZZlyr",
      "metadata": {
        "id": "zm9B278ZZlyr"
      },
      "source": [
        "## Shifting Days\n",
        "\n",
        "We use the `medical.DocumentHashCoder()` annotator to determine shifting days. This annotator gets the hash of the specified column and creates a new document column containing day shift information. And then, the `medical.DeIdentification()` annotator deidentifies this new doc. We should set the seed parameter to hash consistently.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "id": "_17tC0tqZr_l",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_17tC0tqZr_l",
        "outputId": "4a40b031-6ae6-4efb-93a5-514dc31b550a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------------------------------------------+\n",
            "|DocumentID|text                                       |\n",
            "+----------+-------------------------------------------+\n",
            "|A001      |Chris Brown was arrested on 10/02/2022     |\n",
            "|A001      |Mark White has bought a stock on 02/28/2020|\n",
            "|A002      |John has bought a house on 03/15/2022      |\n",
            "|A002      |John Moore was discharged on 12/31/2022    |\n",
            "+----------+-------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.DataFrame(\n",
        "    {'DocumentID' : ['A001', 'A001', 'A002', 'A002'],\n",
        "     'text' : ['Chris Brown was arrested on 10/02/2022', \n",
        "               'Mark White has bought a stock on 02/28/2020', \n",
        "               'John has bought a house on 03/15/2022',\n",
        "               'John Moore was discharged on 12/31/2022'\n",
        "              ]\n",
        "    }\n",
        ")\n",
        "\n",
        "my_input_df = spark.createDataFrame(data)\n",
        "\n",
        "my_input_df.show(truncate = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Rsp2fUfMwlC0",
      "metadata": {
        "id": "Rsp2fUfMwlC0"
      },
      "source": [
        "### Shifting days according to the ID column\n",
        "\n",
        "We use the `legal.DocumentHashCoder()` annotator to determine shifting days. This annotator gets the hash of the specified column and creates a new document column containing day shift information. And then, the `legal.DeIdentification()` annotator deidentifies this new doc. We should set the seed parameter to hash consistently.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "id": "IH83aro3wg9w",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IH83aro3wg9w",
        "outputId": "32060305-d876-41be-b2a9-c47a34738b90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "roberta_embeddings_legal_roberta_base download started this may take some time.\n",
            "Approximate size to download 447.2 MB\n",
            "[OK!]\n",
            "legner_deid download started this may take some time.\n",
            "[OK!]\n"
          ]
        }
      ],
      "source": [
        "documentAssembler = nlp.DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "documentHasher = legal.DocumentHashCoder()\\\n",
        "    .setInputCols(\"document\")\\\n",
        "    .setOutputCol(\"document2\")\\\n",
        "    .setPatientIdColumn(\"DocumentID\")\\\n",
        "    .setRangeDays(100)\\\n",
        "    .setNewDateShift(\"shift_days\")\\\n",
        "    .setSeed(100)\n",
        "\n",
        "\n",
        "# sentenceDetector = nlp.SentenceDetectorDLModel.pretrained(\"sentence_detector_dl\",\"xx\")\\\n",
        "#     .setInputCols([\"document2\"])\\\n",
        "#     .setOutputCol(\"sentence\")\n",
        "#     #.setCustomBounds([\"\\n\\n\"])\n",
        "\n",
        "tokenizer = nlp.Tokenizer()\\\n",
        "    .setInputCols([\"document2\"])\\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "embeddings = nlp.RoBertaEmbeddings.pretrained(\"roberta_embeddings_legal_roberta_base\",\"en\") \\\n",
        "    .setInputCols([\"document2\", \"token\"]) \\\n",
        "    .setOutputCol(\"embeddings\")\n",
        "\n",
        "legal_ner = legal.NerModel.pretrained('legner_deid', \"en\", \"legal/models\")\\\n",
        "    .setInputCols([\"document2\", \"token\", \"embeddings\"]) \\\n",
        "    .setOutputCol(\"ner\") \n",
        "    #.setLabelCasing(\"upper\")\n",
        "\n",
        "ner_converter = legal.NerConverterInternal() \\\n",
        "    .setInputCols([\"document2\", \"token\", \"ner\"])\\\n",
        "    .setOutputCol(\"ner_chunk\") # \"ALIAS\" are secondary names of companies, so let's extract them also as PARTY\n",
        "\n",
        "\n",
        "deid = legal.DeIdentification()\\\n",
        "    .setInputCols([\"sentence\", \"token\", \"ner_chunk\"]) \\\n",
        "    .setOutputCol(\"deidentified\") \\\n",
        "    .setMode(\"obfuscate\") \\\n",
        "    .setObfuscateDate(True) \\\n",
        "    .setDateTag(\"DATE\") \\\n",
        "    .setLanguage(\"en\") \\\n",
        "    .setObfuscateRefSource('faker') \\\n",
        "    .setUseShifDays(True)\\\n",
        "    .setRegion('us')\n",
        "\n",
        "pipeline = nlp.Pipeline(stages=[\n",
        "      documentAssembler, \n",
        "      documentHasher,\n",
        "      sentenceDetector,\n",
        "      tokenizer,\n",
        "      embeddings,\n",
        "      legal_ner,\n",
        "      ner_converter,\n",
        "      deid])\n",
        "\n",
        "empty_data = spark.createDataFrame([[\"\", \"\"]]).toDF(\"text\", \"DocumentID\")\n",
        "\n",
        "pipeline_model = pipeline.fit(empty_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "id": "KPz7-XcBwhBT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPz7-XcBwhBT",
        "outputId": "163b592d-5a7f-481b-d387-b21951fff04e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------------------------------------------+-------------------------------------------+\n",
            "|DocumentID|text                                       |result                                     |\n",
            "+----------+-------------------------------------------+-------------------------------------------+\n",
            "|A001      |Chris Brown was arrested on 10/02/2022     |[<PERSON> was arrested on 11/27/2022]      |\n",
            "|A001      |Mark White has bought a stock on 02/28/2020|[<PERSON> has bought a stock on 03/18/2020]|\n",
            "|A002      |John has bought a house on 03/15/2022      |[<PERSON> has bought a house on 04/18/2022]|\n",
            "|A002      |John Moore was discharged on 12/31/2022    |[<PERSON> was discharged on 02/22/2023]    |\n",
            "+----------+-------------------------------------------+-------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "output = pipeline_model.transform(my_input_df)\n",
        "\n",
        "output.select('DocumentID','text', 'deidentified.result').show(truncate = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zpJiuktQwrkt",
      "metadata": {
        "id": "zpJiuktQwrkt"
      },
      "source": [
        "### Shifting days according to specified values\n",
        "\n",
        "Instead of shifting days according to ID column, we can specify shifting values with another column.\n",
        "\n",
        "```python\n",
        "documentHasher = legal.DocumentHashCoder()\\\n",
        "    .setInputCols(\"document\")\\\n",
        "    .setOutputCol(\"document2\")\\\n",
        "    .setDateShiftColumn(\"dateshift\")\\\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "id": "zexpaYvcwrtG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zexpaYvcwrtG",
        "outputId": "dfc4d6af-d1c2-492f-cd4c-1f9882b1a170"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------------------------------------------+---------+\n",
            "|DocumentID|text                                       |dateshift|\n",
            "+----------+-------------------------------------------+---------+\n",
            "|A001      |Chris Brown was arrested on 10/02/2019     |5        |\n",
            "|A001      |Mark White has bought a stock on 02/28/2020|5        |\n",
            "|A002      |John has bought a house on 03/15/2022      |10       |\n",
            "|A002      |John Moore was discharged on 12/31/2022    |10       |\n",
            "+----------+-------------------------------------------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data = pd.DataFrame(\n",
        "    {'DocumentID' : ['A001', 'A001', 'A002', 'A002'],\n",
        "     'text' : ['Chris Brown was arrested on 10/02/2019', \n",
        "               'Mark White has bought a stock on 02/28/2020', \n",
        "               'John has bought a house on 03/15/2022',\n",
        "               'John Moore was discharged on 12/31/2022'\n",
        "                            ],\n",
        "     'dateshift' : ['5', '5', '10', '10']\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "my_input_df = spark.createDataFrame(data)\n",
        "\n",
        "my_input_df.show(truncate = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "id": "dgB4NqBi0Z-t",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgB4NqBi0Z-t",
        "outputId": "c246c75f-ae21-45b9-bfd8-ed5029ec01e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "roberta_embeddings_legal_roberta_base download started this may take some time.\n",
            "Approximate size to download 447.2 MB\n",
            "[OK!]\n",
            "legner_deid download started this may take some time.\n",
            "[OK!]\n"
          ]
        }
      ],
      "source": [
        "documentAssembler = nlp.DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "documentHasher = legal.DocumentHashCoder()\\\n",
        "    .setInputCols(\"document\")\\\n",
        "    .setOutputCol(\"document2\")\\\n",
        "    .setDateShiftColumn(\"dateshift\")\\\n",
        "\n",
        "\n",
        "# sentenceDetector = nlp.SentenceDetectorDLModel.pretrained(\"sentence_detector_dl\",\"xx\")\\\n",
        "#     .setInputCols([\"document2\"])\\\n",
        "#     .setOutputCol(\"sentence\")\n",
        "#     #.setCustomBounds([\"\\n\\n\"])\n",
        "\n",
        "tokenizer = nlp.Tokenizer()\\\n",
        "    .setInputCols([\"document2\"])\\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "embeddings = nlp.RoBertaEmbeddings.pretrained(\"roberta_embeddings_legal_roberta_base\",\"en\") \\\n",
        "    .setInputCols([\"document2\", \"token\"]) \\\n",
        "    .setOutputCol(\"embeddings\")\n",
        "\n",
        "legal_ner = legal.NerModel.pretrained('legner_deid', \"en\", \"legal/models\")\\\n",
        "    .setInputCols([\"document2\", \"token\", \"embeddings\"]) \\\n",
        "    .setOutputCol(\"ner\") \n",
        "    #.setLabelCasing(\"upper\")\n",
        "\n",
        "ner_converter = legal.NerConverterInternal() \\\n",
        "    .setInputCols([\"document2\", \"token\", \"ner\"])\\\n",
        "    .setOutputCol(\"ner_chunk\") # \"ALIAS\" are secondary names of companies, so let's extract them also as PARTY\n",
        "\n",
        "obfuscation = legal.DeIdentification()\\\n",
        "    .setInputCols([\"document2\", \"token\", \"ner_chunk\"]) \\\n",
        "    .setOutputCol(\"deidentified\") \\\n",
        "    .setMode(\"obfuscate\") \\\n",
        "    .setObfuscateDate(True) \\\n",
        "    .setDateTag(\"DATE\") \\\n",
        "    .setLanguage(\"en\") \\\n",
        "    .setObfuscateRefSource('faker') \\\n",
        "    .setUseShifDays(True)\\\n",
        "    .setRegion('us')\n",
        "\n",
        "pipeline = nlp.Pipeline(stages=[\n",
        "      documentAssembler, \n",
        "      documentHasher,\n",
        "      tokenizer,\n",
        "      embeddings,\n",
        "      legal_ner,\n",
        "      ner_converter,\n",
        "      obfuscation])\n",
        "\n",
        "empty_data = spark.createDataFrame([[\"\", \"\", \"\"]]).toDF(\"text\", \"DocumentID\", \"dateshift\")\n",
        "\n",
        "pipeline_model = pipeline.fit(empty_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "id": "tVV_Tb5a1IY3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVV_Tb5a1IY3",
        "outputId": "77f96b37-d7af-4045-aad0-e787c7573ed3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------+---------+-------------------------------------------+\n",
            "|text                                       |dateshift|result                                     |\n",
            "+-------------------------------------------+---------+-------------------------------------------+\n",
            "|Chris Brown was arrested on 10/02/2019     |5        |[<PERSON> was arrested on 10/07/2019]      |\n",
            "|Mark White has bought a stock on 02/28/2020|5        |[<PERSON> has bought a stock on 03/04/2020]|\n",
            "|John has bought a house on 03/15/2022      |10       |[<PERSON> has bought a house on 03/25/2022]|\n",
            "|John Moore was discharged on 12/31/2022    |10       |[<PERSON> was discharged on 01/10/2023]    |\n",
            "+-------------------------------------------+---------+-------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "output = pipeline_model.transform(my_input_df)\n",
        "\n",
        "output.select('text', 'dateshift', 'deidentified.result').show(truncate = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_olmWxXfV5AO",
      "metadata": {
        "id": "_olmWxXfV5AO"
      },
      "source": [
        "### Masking Unnormalized Date Formats\n",
        "\n",
        "`setUnnormalizedDateMode()` parameter is used to mask the DATE entities that can not be normalized. In the example below, please check `03Apr2022` which couldn't be normalized and it is masked in the output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "id": "ecMNdkr_V0Xq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecMNdkr_V0Xq",
        "outputId": "c2fdbd7e-9c50-4180-e6e2-6f6ad2127154"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "roberta_embeddings_legal_roberta_base download started this may take some time.\n",
            "Approximate size to download 447.2 MB\n",
            "[OK!]\n",
            "legner_deid download started this may take some time.\n",
            "[OK!]\n",
            "+-------------------------------------------+---------+-------------------------------------------+\n",
            "|text                                       |dateshift|result                                     |\n",
            "+-------------------------------------------+---------+-------------------------------------------+\n",
            "|Chris Brown was arrested on 10/02/2022     |5        |[<PERSON> was arrested on 11/01/2022]      |\n",
            "|Mark White has bought a stock on 02/28/2020|5        |[<PERSON> has bought a stock on 04/18/2020]|\n",
            "|John has bought a house on 03Apr2022       |10       |[<PERSON> has bought a house on <DATE>]    |\n",
            "|John Moore was discharged on 12/31/2022    |10       |[<PERSON> was discharged on 01/02/2023]    |\n",
            "+-------------------------------------------+---------+-------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data = pd.DataFrame(\n",
        "    {'DocumentID' : ['A001', 'A001', 'A002', 'A002'],\n",
        "     'text' : ['Chris Brown was arrested on 10/02/2022', \n",
        "               'Mark White has bought a stock on 02/28/2020', \n",
        "               'John has bought a house on 03Apr2022',\n",
        "               'John Moore was discharged on 12/31/2022'\n",
        "                            ],\n",
        "     'dateshift' : ['5', '5', '10', '10']\n",
        "    }\n",
        ")\n",
        "\n",
        "my_input_df = spark.createDataFrame(data)\n",
        "\n",
        "\n",
        "documentAssembler = nlp.DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "documentHasher = legal.DocumentHashCoder()\\\n",
        "    .setInputCols(\"document\")\\\n",
        "    .setOutputCol(\"document2\")\\\n",
        "    .setDateShiftColumn(\"dateshift\")\\\n",
        "\n",
        "\n",
        "# sentenceDetector = nlp.SentenceDetectorDLModel.pretrained(\"sentence_detector_dl\",\"xx\")\\\n",
        "#     .setInputCols([\"document2\"])\\\n",
        "#     .setOutputCol(\"sentence\")\n",
        "#     #.setCustomBounds([\"\\n\\n\"])\n",
        "\n",
        "tokenizer = nlp.Tokenizer()\\\n",
        "    .setInputCols([\"document2\"])\\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "embeddings = nlp.RoBertaEmbeddings.pretrained(\"roberta_embeddings_legal_roberta_base\",\"en\") \\\n",
        "    .setInputCols([\"document2\", \"token\"]) \\\n",
        "    .setOutputCol(\"embeddings\")\n",
        "\n",
        "legal_ner = legal.NerModel.pretrained('legner_deid', \"en\", \"legal/models\")\\\n",
        "    .setInputCols([\"document2\", \"token\", \"embeddings\"]) \\\n",
        "    .setOutputCol(\"ner\") \n",
        "    #.setLabelCasing(\"upper\")\n",
        "\n",
        "ner_converter = legal.NerConverterInternal() \\\n",
        "    .setInputCols([\"document2\", \"token\", \"ner\"])\\\n",
        "    .setOutputCol(\"ner_chunk\") # \"ALIAS\" are secondary names of companies, so let's extract them also as PARTY\n",
        "\n",
        "obfuscation = legal.DeIdentification()\\\n",
        "    .setInputCols([\"sentence\", \"token\", \"ner_chunk\"]) \\\n",
        "    .setOutputCol(\"deidentified\") \\\n",
        "    .setMode(\"obfuscate\") \\\n",
        "    .setObfuscateDate(True) \\\n",
        "    .setDateTag(\"DATE\") \\\n",
        "    .setLanguage(\"en\") \\\n",
        "    .setObfuscateRefSource('faker') \\\n",
        "    .setUseShifDays(True)\\\n",
        "    .setRegion('us')\\\n",
        "    .setUnnormalizedDateMode(\"mask\")\n",
        "\n",
        "pipeline = nlp.Pipeline(stages=[\n",
        "      documentAssembler, \n",
        "      documentHasher,\n",
        "      sentenceDetector,\n",
        "      tokenizer,\n",
        "      embeddings,\n",
        "      legal_ner,\n",
        "      ner_converter,\n",
        "      obfuscation])\n",
        "\n",
        "\n",
        "output = pipeline.fit(my_input_df).transform(my_input_df)\n",
        "\n",
        "output.select('text', 'dateshift', 'deidentified.result').show(truncate = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tV1QWUyh0Zhi",
      "metadata": {
        "id": "tV1QWUyh0Zhi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "zwM9GsKnXPOg",
      "metadata": {
        "id": "zwM9GsKnXPOg"
      },
      "source": [
        "# Structured Deidentification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "id": "JLY-pfeYXQAY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLY-pfeYXQAY",
        "outputId": "7da54907-15f0-4f76-cf37-9e7c654652bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+----------+---+----------------------------------------------------+-------+--------------+---+---+\n",
            "|NAME           |DOB       |AGE|ADDRESS                                             |ZIPCODE|TEL           |SBP|DBP|\n",
            "+---------------+----------+---+----------------------------------------------------+-------+--------------+---+---+\n",
            "|Cecilia Chapman|04/02/1935|83 |711-2880 Nulla St. Mankato Mississippi              |69200  |(257) 563-7401|101|42 |\n",
            "|Iris Watson    |03/10/2009|9  |P.O. Box 283 8562 Fusce Rd. Frederick Nebraska      |20620  |(372) 587-2335|159|122|\n",
            "|Bryar Pitts    |11/01/1921|98 |5543 Aliquet St. Fort Dodge GA                      |20783  |(717) 450-4729|149|52 |\n",
            "|Theodore Lowe  |13/02/2002|16 |Ap #867-859 Sit Rd. Azusa New York                  |39531  |(793) 151-6230|134|115|\n",
            "|Calista Wise   |20/08/1942|76 |7292 Dictum Av. San Antonio MI                      |47096  |(492) 709-6392|139|78 |\n",
            "|Kyla Olsen     |12/05/1973|45 |Ap #651-8679 Sodales Av. Tamuning PA                |10855  |(654) 393-5734|120|112|\n",
            "|Forrest Ray    |11/01/1991|27 |191-103 Integer Rd. Corona New Mexico               |8219   |(404) 960-3807|143|126|\n",
            "|Hiroko Potter  |18/11/1937|81 |P.O. Box 887 2508 Dolor. Av. Muskegon KY            |12482  |(314) 244-6306|147|75 |\n",
            "|Celeste Slater |12/05/1980|38 |606-3727 Ullamcorper. Street Roseville NH           |11523  |(786) 713-8616|147|123|\n",
            "|Nyssa Vazquez  |24/09/1956|62 |511-5762 At Rd. Chelsea MI                          |67708  |(947) 278-5929|129|50 |\n",
            "|Lawrence Moreno|26/12/1906|112|935-9940 Tortor. Street Santa Rosa MN               |98804  |(684) 579-1879|133|102|\n",
            "|Ina Moran      |26/10/1983|35 |P.O. Box 929 4189 Nunc Road Lebanon KY              |69409  |(389) 737-2852|101|67 |\n",
            "|Aaron Hawkins  |26/09/2009|9  |5587 Nunc. Avenue Erie Rhode Island                 |24975  |(660) 663-4518|87 |81 |\n",
            "|Hedy Greene    |03/10/1920|98 |Ap #696-3279 Viverra. Avenue Latrobe DE             |38100  |(608) 265-2215|128|123|\n",
            "|Melvin Porter  |14/08/1911|107|P.O. Box 132 1599 Curabitur Rd. Bandera South Dakota|45149  |(959) 119-8364|83 |43 |\n",
            "|Keefe Sellers  |16/05/1937|81 |347-7666 Iaculis St. Woodruff SC                    |49854  |(468) 353-2641|148|109|\n",
            "|Joan Romero    |08/12/2004|14 |666-4366 Lacinia Avenue Idaho Falls Ohio            |19253  |(248) 675-4007|75 |53 |\n",
            "|Davis Patrick  |09/01/1956|63 |P.O. Box 147 2546 Sociosqu Rd. Bethlehem Utah       |2913   |(939) 353-1107|142|62 |\n",
            "|Leilani Boyer  |18/10/1934|84 |557-6308 Lacinia Road San Bernardino ND             |9289   |(570) 873-7090|137|48 |\n",
            "|Colby Bernard  |02/10/1905|113|Ap #285-7193 Ullamcorper Avenue Amesbury HI         |93373  |(302) 259-2375|84 |41 |\n",
            "+---------------+----------+---+----------------------------------------------------+-------+--------------+---+---+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/legal-nlp/data/hipaa-table-001.txt\n",
        "\n",
        "df = spark.read.format(\"csv\") \\\n",
        "    .option(\"sep\", \"\\t\") \\\n",
        "    .option(\"inferSchema\", \"true\") \\\n",
        "    .option(\"header\", \"true\") \\\n",
        "    .load(\"hipaa-table-001.txt\")\n",
        "\n",
        "df.show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "id": "PQ84IQTGcFAd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQ84IQTGcFAd",
        "outputId": "36b8eceb-4ba4-4251-afa6-30a30a3a2657"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+----------+----+----------------------------------------------------+-------+--------------+---+---+\n",
            "|NAME               |DOB       |AGE |ADDRESS                                             |ZIPCODE|TEL           |SBP|DBP|\n",
            "+-------------------+----------+----+----------------------------------------------------+-------+--------------+---+---+\n",
            "|[Cornelio Paula]   |04/02/1935|[60]|711-2880 Nulla St. Mankato Mississippi              |69200  |(257) 563-7401|101|42 |\n",
            "|[Azalia Badder]    |03/10/2009|[9] |P.O. Box 283 8562 Fusce Rd. Frederick Nebraska      |20620  |(372) 587-2335|159|122|\n",
            "|[Susanne Reeves]   |11/01/1921|[60]|5543 Aliquet St. Fort Dodge GA                      |20783  |(717) 450-4729|149|52 |\n",
            "|[Calton Prayer]    |13/02/2002|[12]|Ap #867-859 Sit Rd. Azusa New York                  |39531  |(793) 151-6230|134|115|\n",
            "|[Janyce Sams]      |20/08/1942|[60]|7292 Dictum Av. San Antonio MI                      |47096  |(492) 709-6392|139|78 |\n",
            "|[Wynell Acron]     |12/05/1973|[58]|Ap #651-8679 Sodales Av. Tamuning PA                |10855  |(654) 393-5734|120|112|\n",
            "|[Neoma Flores]     |11/01/1991|[22]|191-103 Integer Rd. Corona New Mexico               |8219   |(404) 960-3807|143|126|\n",
            "|[Joeline French]   |18/11/1937|[60]|P.O. Box 887 2508 Dolor. Av. Muskegon KY            |12482  |(314) 244-6306|147|75 |\n",
            "|[Carren Bussing]   |12/05/1980|[31]|606-3727 Ullamcorper. Street Roseville NH           |11523  |(786) 713-8616|147|123|\n",
            "|[Shea Ken]         |24/09/1956|[60]|511-5762 At Rd. Chelsea MI                          |67708  |(947) 278-5929|129|50 |\n",
            "|[Robinette Poag]   |26/12/1906|[60]|935-9940 Tortor. Street Santa Rosa MN               |98804  |(684) 579-1879|133|102|\n",
            "|[Carvin Brazil]    |26/10/1983|[24]|P.O. Box 929 4189 Nunc Road Lebanon KY              |69409  |(389) 737-2852|101|67 |\n",
            "|[Tawanna Searle]   |26/09/2009|[9] |5587 Nunc. Avenue Erie Rhode Island                 |24975  |(660) 663-4518|87 |81 |\n",
            "|[Allyne Richards]  |03/10/1920|[60]|Ap #696-3279 Viverra. Avenue Latrobe DE             |38100  |(608) 265-2215|128|123|\n",
            "|[Yong Francisco]   |14/08/1911|[60]|P.O. Box 132 1599 Curabitur Rd. Bandera South Dakota|45149  |(959) 119-8364|83 |43 |\n",
            "|[Chipper Fennel]   |16/05/1937|[60]|347-7666 Iaculis St. Woodruff SC                    |49854  |(468) 353-2641|148|109|\n",
            "|[Samantha Glassing]|08/12/2004|[19]|666-4366 Lacinia Avenue Idaho Falls Ohio            |19253  |(248) 675-4007|75 |53 |\n",
            "|[Eladio Manor]     |09/01/1956|[60]|P.O. Box 147 2546 Sociosqu Rd. Bethlehem Utah       |2913   |(939) 353-1107|142|62 |\n",
            "|[Raymonde Jeans]   |18/10/1934|[60]|557-6308 Lacinia Road San Bernardino ND             |9289   |(570) 873-7090|137|48 |\n",
            "|[Kirsten Kos]      |02/10/1905|[60]|Ap #285-7193 Ullamcorper Avenue Amesbury HI         |93373  |(302) 259-2375|84 |41 |\n",
            "+-------------------+----------+----+----------------------------------------------------+-------+--------------+---+---+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "obfuscator = legal.StructuredDeidentification(spark,{\"NAME\":\"PATIENT\",\"AGE\":\"AGE\"}, obfuscateRefSource = \"faker\")\n",
        "obfuscator_df = obfuscator.obfuscateColumns(df)\n",
        "obfuscator_df.show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "id": "-GmMv8T-I0CX",
      "metadata": {
        "id": "-GmMv8T-I0CX"
      },
      "outputs": [],
      "source": [
        "obfuscator_unique_ref_test = '''Will Perry#CLIENT\n",
        "John Smith#CLIENT\n",
        "Marvin MARSHALL#CLIENT\n",
        "Hubert GROGAN#CLIENT\n",
        "ALTHEA COLBURN#CLIENT\n",
        "Kalil AMIN#CLIENT\n",
        "Inci FOUNTAIN#CLIENT\n",
        "Jackson WILLE#CLIENT\n",
        "Jack SANTOS#CLIENT\n",
        "Mahmood ALBURN#CLIENT\n",
        "Marnie MELINGTON#CLIENT\n",
        "Aysha GHAZI#CLIENT\n",
        "Maryland CODER#CLIENT\n",
        "Darene GEORGIOUS#CLIENT\n",
        "Shelly WELLBECK#CLIENT\n",
        "Min Kun JAE#CLIENT\n",
        "Thomson THOMAS#CLIENT\n",
        "Christian SUDDINBURG#CLIENT\n",
        "Aberdeen#CITY\n",
        "Louisburg St#STREET\n",
        "France#LOC\n",
        "5552312#PHONE\n",
        "Calle del Libertador#ADDRESS\n",
        "111#ID\n",
        "20#AGE\n",
        "30#AGE\n",
        "40#AGE\n",
        "50#AGE\n",
        "60#AGE\n",
        "'''\n",
        "\n",
        "with open('obfuscator_unique_ref_test.txt', 'w') as f:\n",
        "  f.write(obfuscator_unique_ref_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "id": "PTwdR034I70n",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTwdR034I70n",
        "outputId": "fa2e7c83-3424-41ab-9986-53230b494144"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+----+\n",
            "|NAME              |AGE |\n",
            "+------------------+----+\n",
            "|[Inci FOUNTAIN]   |[60]|\n",
            "|[Jack SANTOS]     |[30]|\n",
            "|[Darene GEORGIOUS]|[30]|\n",
            "|[Shelly WELLBECK] |[40]|\n",
            "|[Hubert GROGAN]   |[40]|\n",
            "|[Kalil AMIN]      |[40]|\n",
            "|[ALTHEA COLBURN]  |[60]|\n",
            "|[Thomson THOMAS]  |[60]|\n",
            "|[Jack SANTOS]     |[60]|\n",
            "|[Will Perry]      |[20]|\n",
            "|[Jackson WILLE]   |[60]|\n",
            "|[Shelly WELLBECK] |[40]|\n",
            "|[Kalil AMIN]      |[30]|\n",
            "|[Marnie MELINGTON]|[30]|\n",
            "|[Min Kun JAE]     |[30]|\n",
            "|[Marvin MARSHALL] |[60]|\n",
            "|[Marvin MARSHALL] |[50]|\n",
            "|[Min Kun JAE]     |[30]|\n",
            "|[Maryland CODER]  |[20]|\n",
            "|[Marnie MELINGTON]|[20]|\n",
            "+------------------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# obfuscateRefSource = \"file\"\n",
        "\n",
        "obfuscator = legal.StructuredDeidentification(spark,{\"NAME\":\"CLIENT\",\"AGE\":\"AGE\"}, \n",
        "                                        obfuscateRefFile = \"/content/obfuscator_unique_ref_test.txt\",\n",
        "                                        obfuscateRefSource = \"file\",\n",
        "                                        columnsSeed={\"NAME\": 23, \"AGE\": 23})\n",
        "obfuscator_df = obfuscator.obfuscateColumns(df)\n",
        "obfuscator_df.select(\"NAME\",\"AGE\").show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "w8tW5fFafQmL",
      "metadata": {
        "id": "w8tW5fFafQmL"
      },
      "source": [
        "We can **shift n days** in the structured deidentification through \"days\" parameter when the column is a Date."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "id": "iBzoNufMfYCn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBzoNufMfYCn",
        "outputId": "7fd5404e-939e-40e3-a837-5e95f297f2df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------+-----------------------+---+----------------+\n",
            "|NAME         |DOB       |ADDRESS                |SBP|TEL             |\n",
            "+-------------+----------+-----------------------+---+----------------+\n",
            "|Juan García  |13/02/1977|711 Nulla St.          |140|673 431234      |\n",
            "|Will Smith   |23/02/1977|1 Green Avenue.        |140|+23 (673) 431234|\n",
            "|Pedro Ximénez|11/04/1900|Calle del Libertador, 7|100|912 345623      |\n",
            "+-------------+----------+-----------------------+---+----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = spark.createDataFrame([\n",
        "            [\"Juan García\", \"13/02/1977\", \"711 Nulla St.\", \"140\", \"673 431234\"],\n",
        "            [\"Will Smith\", \"23/02/1977\", \"1 Green Avenue.\", \"140\", \"+23 (673) 431234\"],\n",
        "            [\"Pedro Ximénez\", \"11/04/1900\", \"Calle del Libertador, 7\", \"100\", \"912 345623\"]\n",
        "        ]).toDF(\"NAME\", \"DOB\", \"ADDRESS\", \"SBP\", \"TEL\")\n",
        "df.show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "id": "Fez0Rqq_fX3C",
      "metadata": {
        "id": "Fez0Rqq_fX3C"
      },
      "outputs": [],
      "source": [
        "obfuscator = legal.StructuredDeidentification(spark=spark, \n",
        "                                        columns={\"NAME\": \"ID\", \"DOB\": \"DATE\"},\n",
        "                                        columnsSeed={\"NAME\": 23, \"DOB\": 23},\n",
        "                                        obfuscateRefSource=\"faker\",\n",
        "                                        days=5\n",
        "                                         )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "id": "HgNuMKhngFq2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgNuMKhngFq2",
        "outputId": "ea51bbb1-a06b-4029-a1e7-a8f4ad23cd02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------+-----------------------+---+----------------+\n",
            "|NAME      |DOB         |ADDRESS                |SBP|TEL             |\n",
            "+----------+------------+-----------------------+---+----------------+\n",
            "|[N2649912]|[18/02/1977]|711 Nulla St.          |140|673 431234      |\n",
            "|[W466004] |[28/02/1977]|1 Green Avenue.        |140|+23 (673) 431234|\n",
            "|[M403810] |[16/04/1900]|Calle del Libertador, 7|100|912 345623      |\n",
            "+----------+------------+-----------------------+---+----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result = obfuscator.obfuscateColumns(df)\n",
        "result.show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc5ac615-13af-4149-bf78-96e2d27d9c5f",
      "metadata": {
        "id": "cc5ac615-13af-4149-bf78-96e2d27d9c5f"
      },
      "source": [
        "# Save the Pipeline and Use it from Your Local"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "id": "f54386d7-486c-44e9-9557-954c45d9d493",
      "metadata": {
        "id": "f54386d7-486c-44e9-9557-954c45d9d493"
      },
      "outputs": [],
      "source": [
        "model.write().overwrite().save('pipeline_deid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "id": "2a6de84f-d5da-405a-afe6-7d3840dd454d",
      "metadata": {
        "id": "2a6de84f-d5da-405a-afe6-7d3840dd454d"
      },
      "outputs": [],
      "source": [
        "# from sparknlp.pretrained import PretrainedPipeline\n",
        "\n",
        "deid_pipeline = nlp.PretrainedPipeline.from_disk(\"pipeline_deid\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "id": "cbd89eeb-f5f5-4639-9ccf-29c2491f4d37",
      "metadata": {
        "id": "cbd89eeb-f5f5-4639-9ccf-29c2491f4d37"
      },
      "outputs": [],
      "source": [
        "data = spark.createDataFrame([[text]]).toDF(\"text\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "id": "e78dea29-7a4c-4724-8e2f-93e635c2602e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e78dea29-7a4c-4724-8e2f-93e635c2602e",
        "outputId": "17f293e2-5960-4da4-b287-0764c8ff7d45"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[DocumentAssembler_ff926bd4d493,\n",
              " SentenceDetectorDLModel_8aaebf7e098e,\n",
              " REGEX_TOKENIZER_31d25d1aa149,\n",
              " ROBERTA_EMBEDDINGS_b915dff90901,\n",
              " LegalNerModel_5eb62585382d,\n",
              " NER_CONVERTER_0151907ce8bc,\n",
              " MedicalNerModel_2b2f0f671f99,\n",
              " NerConverter_dd77843f9f26,\n",
              " ZeroShotRobertaNer_5d06c0297d21,\n",
              " NER_CONVERTER_f9b2bd114a3a,\n",
              " CONTEXTUAL-PARSER_8aafa17f4437,\n",
              " CONTEXTUAL-PARSER_f93f50c17347,\n",
              " CONTEXTUAL-PARSER_9a2f7c8293db,\n",
              " MERGE_60c5e3188ff5]"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ],
      "source": [
        "deid_pipeline.model.stages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "id": "de7e48e9-4433-40c8-8e88-a5d5a0265bb9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de7e48e9-4433-40c8-8e88-a5d5a0265bb9",
        "outputId": "ad9d56cd-737e-4f20-8dd9-58b103fc43b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                text|            document|            sentence|               token|          embeddings|                 ner|           ner_chunk|                ner2|          ner_chunk2|       zero_shot_ner|      zero_ner_chunk|               alias|               email|               phone|   merged_ner_chunks|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|This Commercial L...|[{document, 0, 76...|[{document, 0, 27...|[{token, 0, 3, Th...|[{word_embeddings...|[{named_entity, 0...|[{chunk, 43, 59, ...|[{named_entity, 0...|[{chunk, 150, 152...|[{named_entity, 0...|[{chunk, 160, 162...|[{chunk, 28, 34, ...|[{chunk, 727, 745...|[{chunk, 748, 760...|[{chunk, 28, 34, ...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "deid_pipeline.model.transform(data).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "615a3cf3-ae62-40cf-b9b2-a68c8053c908",
      "metadata": {
        "id": "615a3cf3-ae62-40cf-b9b2-a68c8053c908"
      },
      "source": [
        "# Pretrained Deidentification Pipeline\n",
        "\n",
        "We have this pipeline can be used to deidentify legal information from texts.The legal information will be masked and obfuscated in the resulting text. The pipeline can mask and obfuscate `DOC`, `EFFDATE`, `PARTY`, `ALIAS`, `SIGNING_PERSON`, `SIGNING_TITLE`, `COUNTRY`, `CITY`, `STATE`, `STREET`, `ZIP`, `EMAIL`, `FAX`, `LOCATION-OTHER`, `DATE`,`PHONE` entities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "id": "994c32d7-44e7-4637-9f64-454af9168dab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "994c32d7-44e7-4637-9f64-454af9168dab",
        "outputId": "a0f8c07f-fdda-4244-f70a-513b2a38111a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "legpipe_deid download started this may take some time.\n",
            "Approx size to download 921.1 MB\n",
            "[OK!]\n"
          ]
        }
      ],
      "source": [
        "# from sparknlp.pretrained import PretrainedPipeline\n",
        "\n",
        "deid_pipeline = nlp.PretrainedPipeline(\"legpipe_deid\", \"en\", \"legal/models\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "id": "a09f14d8-54d9-4ed9-a7c4-6074f421020a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a09f14d8-54d9-4ed9-a7c4-6074f421020a",
        "outputId": "22c13515-5146-43d6-d8d9-c5cd5ea52806"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[DocumentAssembler_c7b58c78b248,\n",
              " SentenceDetectorDLModel_8aaebf7e098e,\n",
              " REGEX_TOKENIZER_3e1c0446436a,\n",
              " ROBERTA_EMBEDDINGS_b915dff90901,\n",
              " LegalNerModel_5eb62585382d,\n",
              " NER_CONVERTER_a6dff5e8e458,\n",
              " MedicalNerModel_2b2f0f671f99,\n",
              " NerConverter_df07d611fba8,\n",
              " ZeroShotRobertaNer_5d06c0297d21,\n",
              " NER_CONVERTER_970306963c3c,\n",
              " CONTEXTUAL-PARSER_171c7e78aa02,\n",
              " CONTEXTUAL-PARSER_657771204acf,\n",
              " CONTEXTUAL-PARSER_562b3f75cffd,\n",
              " MERGE_8da2fd9d23ef,\n",
              " DE-IDENTIFICATION_3741f6dfecff,\n",
              " DE-IDENTIFICATION_ea822920be64,\n",
              " DE-IDENTIFICATION_637063fd264b,\n",
              " DE-IDENTIFICATION_7b20a724c6cd]"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ],
      "source": [
        "deid_pipeline.model.stages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "id": "00a6b038-7178-4fe3-b7f6-664bad53ff92",
      "metadata": {
        "id": "00a6b038-7178-4fe3-b7f6-664bad53ff92"
      },
      "outputs": [],
      "source": [
        "text= \"\"\"CARGILL, INCORPORATED\n",
        "\n",
        "By:     Pirkko Suominen\n",
        "\n",
        "\n",
        "\n",
        "Name: Pirkko Suominen Title: Director, Bio Technology Development  Center,  Date:   10/19/2011\n",
        "\n",
        "BIOAMBER, SAS\n",
        "\n",
        "By:     Jean-François Huc\n",
        "\n",
        "\n",
        "\n",
        "Name: Jean-François Huc  Title: President Date:   October 15, 2011\n",
        "\n",
        "email : jeanfran@gmail.com\n",
        "phone : 18087339090 \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "id": "bd76c039-f1bb-4839-a2c5-9b5715629700",
      "metadata": {
        "id": "bd76c039-f1bb-4839-a2c5-9b5715629700"
      },
      "outputs": [],
      "source": [
        "deid_res= deid_pipeline.annotate(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "id": "84add88b-9686-4fcc-83fa-6f64465f4aff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84add88b-9686-4fcc-83fa-6f64465f4aff",
        "outputId": "8cdcdf2b-c712-4918-be82-dad5eee0f258"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['ner_chunk2', 'obfuscated', 'zero_shot_ner', 'email', 'document', 'ner_chunk', 'zero_ner_chunk', 'deidentified', 'alias', 'masked_fixed_length_chars', 'token', 'ner2', 'ner', 'embeddings', 'merged_ner_chunks', 'sentence', 'phone', 'masked_with_chars'])"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ],
      "source": [
        "deid_res.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "id": "9551bf51-c2e4-4d7c-968e-1c75bd43f888",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "9551bf51-c2e4-4d7c-968e-1c75bd43f888",
        "outputId": "363bdd79-ab9f-4bc5-d9f1-e6f530333fca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                              Sentence  \\\n",
              "0                                                                                CARGILL, INCORPORATED   \n",
              "1                                                                              By:     Pirkko Suominen   \n",
              "2       Name: Pirkko Suominen Title: Director, Bio Technology Development  Center,  Date:   10/19/2011   \n",
              "3                                                                                        BIOAMBER, SAS   \n",
              "4                                                                            By:     Jean-François Huc   \n",
              "5  Name: Jean-François Huc  Title: President Date:   October 15, 2011\\n\\nemail : jeanfran@gmail.com...   \n",
              "\n",
              "                                                                                                Masked  \\\n",
              "0                                                                                              <PARTY>   \n",
              "1                                                                             By:     <SIGNING_PERSON>   \n",
              "2                    Name: <SIGNING_PERSON> Title: <SIGNING_PERSON>, <SIGNING_PERSON>,  Date:   <DATE>   \n",
              "3                                                                                     <PARTY>, <PARTY>   \n",
              "4                                                                             By:     <SIGNING_PERSON>   \n",
              "5  Name: <SIGNING_PERSON>  Title: <SIGNING_TITLE> Date:   <EFFDATE> 2011\\n\\nemail : <EMAIL>\\nphone ...   \n",
              "\n",
              "                                                                                     Masked with Chars  \\\n",
              "0                                                                                [*******************]   \n",
              "1                                                                              By:     [*************]   \n",
              "2       Name: [*************] Title: [******], [********************************],  Date:   [********]   \n",
              "3                                                                                        [******], [*]   \n",
              "4                                                                            By:     [***************]   \n",
              "5  Name: [***************]  Title: [*******] Date:   [*********] 2011\\n\\nemail : [****************]...   \n",
              "\n",
              "                                                   Masked with Fixed Chars  \\\n",
              "0                                                                     ****   \n",
              "1                                                             By:     ****   \n",
              "2                              Name: **** Title: ****, ****,  Date:   ****   \n",
              "3                                                               ****, ****   \n",
              "4                                                             By:     ****   \n",
              "5  Name: ****  Title: **** Date:   **** 2011\\n\\nemail : ****\\nphone : ****   \n",
              "\n",
              "                                                                                            Obfuscated  \n",
              "0                                                                                   Cunningham-Hendrix  \n",
              "1                                                                                By:     Stacy Bradley  \n",
              "2                             Name: Stacy Bradley Title: Lori Thompson, Stacy Bradley,  Date:   <DATE>  \n",
              "3                                                            Thomas, Miller and Kelly, Flowers-Frazier  \n",
              "4                                                                                   By:     John Curry  \n",
              "5  Name: John Curry  Title: Chief Legal Officer Date:   08-03-2007 2011\\n\\nemail : Bertell@hotmail....  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aef9ac1c-67da-4dd4-b67a-c344e22656b1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Masked</th>\n",
              "      <th>Masked with Chars</th>\n",
              "      <th>Masked with Fixed Chars</th>\n",
              "      <th>Obfuscated</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CARGILL, INCORPORATED</td>\n",
              "      <td>&lt;PARTY&gt;</td>\n",
              "      <td>[*******************]</td>\n",
              "      <td>****</td>\n",
              "      <td>Cunningham-Hendrix</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>By:     Pirkko Suominen</td>\n",
              "      <td>By:     &lt;SIGNING_PERSON&gt;</td>\n",
              "      <td>By:     [*************]</td>\n",
              "      <td>By:     ****</td>\n",
              "      <td>By:     Stacy Bradley</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Name: Pirkko Suominen Title: Director, Bio Technology Development  Center,  Date:   10/19/2011</td>\n",
              "      <td>Name: &lt;SIGNING_PERSON&gt; Title: &lt;SIGNING_PERSON&gt;, &lt;SIGNING_PERSON&gt;,  Date:   &lt;DATE&gt;</td>\n",
              "      <td>Name: [*************] Title: [******], [********************************],  Date:   [********]</td>\n",
              "      <td>Name: **** Title: ****, ****,  Date:   ****</td>\n",
              "      <td>Name: Stacy Bradley Title: Lori Thompson, Stacy Bradley,  Date:   &lt;DATE&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BIOAMBER, SAS</td>\n",
              "      <td>&lt;PARTY&gt;, &lt;PARTY&gt;</td>\n",
              "      <td>[******], [*]</td>\n",
              "      <td>****, ****</td>\n",
              "      <td>Thomas, Miller and Kelly, Flowers-Frazier</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>By:     Jean-François Huc</td>\n",
              "      <td>By:     &lt;SIGNING_PERSON&gt;</td>\n",
              "      <td>By:     [***************]</td>\n",
              "      <td>By:     ****</td>\n",
              "      <td>By:     John Curry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Name: Jean-François Huc  Title: President Date:   October 15, 2011\\n\\nemail : jeanfran@gmail.com...</td>\n",
              "      <td>Name: &lt;SIGNING_PERSON&gt;  Title: &lt;SIGNING_TITLE&gt; Date:   &lt;EFFDATE&gt; 2011\\n\\nemail : &lt;EMAIL&gt;\\nphone ...</td>\n",
              "      <td>Name: [***************]  Title: [*******] Date:   [*********] 2011\\n\\nemail : [****************]...</td>\n",
              "      <td>Name: ****  Title: **** Date:   **** 2011\\n\\nemail : ****\\nphone : ****</td>\n",
              "      <td>Name: John Curry  Title: Chief Legal Officer Date:   08-03-2007 2011\\n\\nemail : Bertell@hotmail....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aef9ac1c-67da-4dd4-b67a-c344e22656b1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aef9ac1c-67da-4dd4-b67a-c344e22656b1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aef9ac1c-67da-4dd4-b67a-c344e22656b1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.set_option(\"display.max_colwidth\", 100)\n",
        "\n",
        "df= pd.DataFrame(list(zip(deid_res[\"sentence\"], \n",
        "                          deid_res[\"deidentified\"],\n",
        "                          deid_res[\"masked_with_chars\"],\n",
        "                          deid_res[\"masked_fixed_length_chars\"], \n",
        "                          deid_res[\"obfuscated\"])),\n",
        "                 columns= [\"Sentence\", \"Masked\", \"Masked with Chars\", \"Masked with Fixed Chars\", \"Obfuscated\"])\n",
        "\n",
        "df"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "tf-gpu",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "3f47d918ae832c68584484921185f5c85a1760864bf927a683dc6fb56366cc77"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}