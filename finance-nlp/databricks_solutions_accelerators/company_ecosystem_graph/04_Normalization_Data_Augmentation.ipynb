{"cells":[{"cell_type":"markdown","source":["You may find this series of notebooks at https://github.com/databricks-industry-solutions/jsl-financial-nlp"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"71055a60-56ff-4ef3-a2c0-ed77a15a38fe","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%pip install johnsnowlabs==4.2.3 networkx==2.5 decorator==5.0.9 plotly==5.1.0 "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e9f7ffea-a135-4248-8a9a-8465a39e1aa1","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Normalizing the company name to query John Snow Labs datasources for more information about Cadence"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4e211fcd-b3f8-43a3-9e58-40e1fa508c82","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["Normalizing a company name is super important for data quality purposes. It will help us:\n- Standardize the data, improving the quality;\n- Carry out additional verifications;\n- Join different databases or extract for external sources;"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1128b706-7089-4c13-9d99-d4277899a3b6","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["## Let's resume the G creation, loading it from disk from previous step"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"63593d93-752e-4e5f-8d33-13ff4e06d73e","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from johnsnowlabs import nlp, finance, viz\nimport pickle"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"27744c66-ed82-4a28-9c5c-2ffd30732f65","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%run \"./aux_visualization_functions\""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b36c8869-7e5d-4164-931a-23b95d59f41c","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# load graph object from file\nG = pickle.load(open('/databricks/driver/cadence.pickle', 'rb'))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9141ccef-aac4-4c0f-8d4c-cb73ab01b6a2","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Sometimes, companies in texts use a non-official, abbreviated name. For example, we can find `Cadence`, `Cadence Inc`, `Cadence, Inc`, or many other variations, where the official name of the company os `CADENCE DESIGN SYSTEMS INC`, as per registered in SEC Edgar."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"84ebb0a8-b234-4592-a94f-34642670c747","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["# Entity Resolution\nTo normalize names or map permutations or variations of strings to unique names or codes, we use Financial NLP `EntityResolvers`"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c3ed3948-d53f-48c8-8d30-620e06020669","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from johnsnowlabs.nlp import LightPipeline\n\ndocument_assembler = nlp.DocumentAssembler()\\\n      .setInputCol(\"text\")\\\n      .setOutputCol(\"ner_chunk\")\n\nembeddings = nlp.UniversalSentenceEncoder.pretrained(\"tfhub_use\", \"en\") \\\n      .setInputCols(\"ner_chunk\") \\\n      .setOutputCol(\"sentence_embeddings\")\n    \nresolver = finance.SentenceEntityResolverModel.pretrained(\"finel_edgar_company_name\", \"en\", \"finance/models\")\\\n      .setInputCols([\"sentence_embeddings\"]) \\\n      .setOutputCol(\"normalization\")\\\n      .setDistanceFunction(\"EUCLIDEAN\")\n\npipeline = nlp.Pipeline(\n      stages = [\n          document_assembler,\n          embeddings,\n          resolver])"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"43f8c0b4-e5b3-4612-9682-bcf50445ff34","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Our unnormalized company name was our first node"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b3fe0c86-ec96-4282-8e14-846baaca70a6","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["ORG = [n for n in G.nodes()][0]\nORG"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6cac6e4e-5364-4912-b140-598592d86657","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Let's see it's official name"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1876b9f5-8c09-4761-8629-9dc12a838ea9","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\npipelineModel = pipeline.fit(empty_data)\n\nlp = LightPipeline(pipelineModel)\n\nnormalized_org = lp.fullAnnotate(ORG)\nnormalized_org"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e69f21bc-306b-4798-b10e-0e5b64a9b5de","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["NORM_ORG = normalized_org[0]['normalization'][0].result\nNORM_ORG"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"831ce69f-a919-482d-b552-0f2d983db267","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Ok, it turns out it's `CADENCE DESIGN SYSTEMS INC`. We got our first insight, using pretrained Spark NLP data sources, in this case, an `EntityResolver` for company names normalization.\n\nBut Finance NLP has much more than that!"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9404f33c-8b37-4a1a-a9f5-20940a0683e6","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["## DATA AUGMENTATION WITH CHUNK MAPPER"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2a890de7-126d-4bc4-900d-970002360a17","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["Once we have the normalized name of the company, we can use `Finance NLP Chunk Mappers`. These are pretrained data sources, which are updated frequently and can be queried inside Spark NLP without sending any API call to any server.\n\nIn this case, we will use Edgar Database (`finmapper_edgar_companyname`)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6b54bec1-b50e-4990-8bf9-3afd803e5bcf","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["documentAssembler = nlp.DocumentAssembler()\\\n        .setInputCol(\"text\")\\\n        .setOutputCol(\"document\")\n\nCM = finance.ChunkMapperModel()\\\n      .pretrained(\"finmapper_edgar_companyname\", \"en\", \"finance/models\")\\\n      .setInputCols([\"document\"])\\\n      .setOutputCol(\"mappings\")\n      \ncm_pipeline = nlp.Pipeline(stages=[documentAssembler, CM])\nfit_cm_pipeline = cm_pipeline.fit(empty_data)\n\ncm_lp = LightPipeline(fit_cm_pipeline)\n\nmapping = cm_lp.fullAnnotate(NORM_ORG)[0]"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"589f9843-c508-4ea5-b100-d6e90fb962f2","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["mapping"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d5e3cc28-d946-475c-8ec2-4734c6a8a387","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["for key, value in mapping.items():\n  if key == 'mappings':\n    for relation in mapping[key]:\n      text = relation.result\n      relation_name = relation.metadata['relation']\n      print(f\"{ORG} - has_{relation_name} - {text}\")\n      G.add_node(text, attr_dict={'entity': relation_name}),\n      G.add_edge(ORG, text, attr_dict={'relation': 'has_' + relation_name.lower()})"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b5a5b44a-b16c-4aa5-a022-8c2d925d24f4","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["show_graph_in_plotly(G)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"79c6a49a-deac-4a5b-b03a-30e6dd8edec3","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["import pickle\n\n# save graph object to file\npickle.dump(G, open('/databricks/driver/cadence.pickle', 'wb'))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d4dc80b2-523d-483e-b64f-631d009791ce","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"04_Normalization_Data_Augmentation","dashboards":[],"notebookMetadata":{},"language":"python","widgets":{},"notebookOrigID":770321394216535}},"nbformat":4,"nbformat_minor":0}
