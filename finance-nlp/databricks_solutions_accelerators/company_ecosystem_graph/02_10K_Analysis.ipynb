{"cells":[{"cell_type":"markdown","source":["You may find this series of notebooks at https://github.com/databricks-industry-solutions/jsl-financial-nlp"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"dafcfe7a-6893-419a-9359-17cc7ed9bf01","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%pip install johnsnowlabs==4.2.3 networkx==2.5 decorator==5.0.9 plotly==5.1.0 "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"46318479-7c01-47ca-b48f-76179a0771dd","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting johnsnowlabs==4.2.3\n  Using cached johnsnowlabs-4.2.3-py3-none-any.whl (74 kB)\nRequirement already satisfied: networkx==2.5 in /databricks/python3/lib/python3.8/site-packages (2.5)\nCollecting decorator==5.0.9\n  Using cached decorator-5.0.9-py3-none-any.whl (8.9 kB)\nRequirement already satisfied: plotly==5.1.0 in /databricks/python3/lib/python3.8/site-packages (5.1.0)\nRequirement already satisfied: nlu==4.0.1rc4 in /databricks/python3/lib/python3.8/site-packages (from johnsnowlabs==4.2.3) (4.0.1rc4)\nRequirement already satisfied: spark-nlp==4.2.4 in /databricks/python3/lib/python3.8/site-packages (from johnsnowlabs==4.2.3) (4.2.4)\nRequirement already satisfied: databricks-api in /databricks/python3/lib/python3.8/site-packages (from johnsnowlabs==4.2.3) (0.8.0)\nRequirement already satisfied: colorama in /databricks/python3/lib/python3.8/site-packages (from johnsnowlabs==4.2.3) (0.4.6)\nRequirement already satisfied: spark-nlp-display==4.1 in /databricks/python3/lib/python3.8/site-packages (from johnsnowlabs==4.2.3) (4.1)\nCollecting pyspark==3.1.2\n  Using cached pyspark-3.1.2-py2.py3-none-any.whl\nRequirement already satisfied: requests in /databricks/python3/lib/python3.8/site-packages (from johnsnowlabs==4.2.3) (2.25.1)\nRequirement already satisfied: dataclasses in /databricks/python3/lib/python3.8/site-packages (from johnsnowlabs==4.2.3) (0.6)\nRequirement already satisfied: numpy in /databricks/python3/lib/python3.8/site-packages (from johnsnowlabs==4.2.3) (1.21.6)\nRequirement already satisfied: pydantic in /databricks/python3/lib/python3.8/site-packages (from johnsnowlabs==4.2.3) (1.8.2)\nRequirement already satisfied: tenacity&gt;=6.2.0 in /databricks/python3/lib/python3.8/site-packages (from plotly==5.1.0) (6.2.0)\nRequirement already satisfied: six in /databricks/python3/lib/python3.8/site-packages (from plotly==5.1.0) (1.15.0)\nRequirement already satisfied: pandas&gt;=1.3.5 in /databricks/python3/lib/python3.8/site-packages (from nlu==4.0.1rc4-&gt;johnsnowlabs==4.2.3) (1.5.2)\nRequirement already satisfied: pyarrow&gt;=0.16.0 in /databricks/python3/lib/python3.8/site-packages (from nlu==4.0.1rc4-&gt;johnsnowlabs==4.2.3) (4.0.0)\nCollecting py4j==0.10.9\n  Using cached py4j-0.10.9-py2.py3-none-any.whl (198 kB)\nRequirement already satisfied: svgwrite==1.4 in /databricks/python3/lib/python3.8/site-packages (from spark-nlp-display==4.1-&gt;johnsnowlabs==4.2.3) (1.4)\nRequirement already satisfied: ipython in /databricks/python3/lib/python3.8/site-packages (from spark-nlp-display==4.1-&gt;johnsnowlabs==4.2.3) (7.22.0)\nRequirement already satisfied: python-dateutil&gt;=2.8.1 in /databricks/python3/lib/python3.8/site-packages (from pandas&gt;=1.3.5-&gt;nlu==4.0.1rc4-&gt;johnsnowlabs==4.2.3) (2.8.1)\nRequirement already satisfied: pytz&gt;=2020.1 in /databricks/python3/lib/python3.8/site-packages (from pandas&gt;=1.3.5-&gt;nlu==4.0.1rc4-&gt;johnsnowlabs==4.2.3) (2020.5)\nRequirement already satisfied: databricks-cli in /databricks/python3/lib/python3.8/site-packages (from databricks-api-&gt;johnsnowlabs==4.2.3) (0.14.3)\nRequirement already satisfied: click&gt;=6.7 in /databricks/python3/lib/python3.8/site-packages (from databricks-cli-&gt;databricks-api-&gt;johnsnowlabs==4.2.3) (7.1.2)\nRequirement already satisfied: tabulate&gt;=0.7.7 in /databricks/python3/lib/python3.8/site-packages (from databricks-cli-&gt;databricks-api-&gt;johnsnowlabs==4.2.3) (0.8.7)\nRequirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /databricks/python3/lib/python3.8/site-packages (from requests-&gt;johnsnowlabs==4.2.3) (1.25.11)\nRequirement already satisfied: idna&lt;3,&gt;=2.5 in /databricks/python3/lib/python3.8/site-packages (from requests-&gt;johnsnowlabs==4.2.3) (2.10)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /databricks/python3/lib/python3.8/site-packages (from requests-&gt;johnsnowlabs==4.2.3) (2020.12.5)\nRequirement already satisfied: chardet&lt;5,&gt;=3.0.2 in /databricks/python3/lib/python3.8/site-packages (from requests-&gt;johnsnowlabs==4.2.3) (4.0.0)\nRequirement already satisfied: pygments in /databricks/python3/lib/python3.8/site-packages (from ipython-&gt;spark-nlp-display==4.1-&gt;johnsnowlabs==4.2.3) (2.8.1)\nRequirement already satisfied: pexpect&gt;4.3 in /databricks/python3/lib/python3.8/site-packages (from ipython-&gt;spark-nlp-display==4.1-&gt;johnsnowlabs==4.2.3) (4.8.0)\nRequirement already satisfied: setuptools&gt;=18.5 in /usr/local/lib/python3.8/dist-packages (from ipython-&gt;spark-nlp-display==4.1-&gt;johnsnowlabs==4.2.3) (52.0.0)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,&lt;3.1.0,&gt;=2.0.0 in /databricks/python3/lib/python3.8/site-packages (from ipython-&gt;spark-nlp-display==4.1-&gt;johnsnowlabs==4.2.3) (3.0.17)\nRequirement already satisfied: traitlets&gt;=4.2 in /databricks/python3/lib/python3.8/site-packages (from ipython-&gt;spark-nlp-display==4.1-&gt;johnsnowlabs==4.2.3) (5.0.5)\nRequirement already satisfied: backcall in /databricks/python3/lib/python3.8/site-packages (from ipython-&gt;spark-nlp-display==4.1-&gt;johnsnowlabs==4.2.3) (0.2.0)\nRequirement already satisfied: pickleshare in /databricks/python3/lib/python3.8/site-packages (from ipython-&gt;spark-nlp-display==4.1-&gt;johnsnowlabs==4.2.3) (0.7.5)\nRequirement already satisfied: jedi&gt;=0.16 in /databricks/python3/lib/python3.8/site-packages (from ipython-&gt;spark-nlp-display==4.1-&gt;johnsnowlabs==4.2.3) (0.17.2)\nRequirement already satisfied: parso&lt;0.8.0,&gt;=0.7.0 in /databricks/python3/lib/python3.8/site-packages (from jedi&gt;=0.16-&gt;ipython-&gt;spark-nlp-display==4.1-&gt;johnsnowlabs==4.2.3) (0.7.0)\nRequirement already satisfied: ptyprocess&gt;=0.5 in /databricks/python3/lib/python3.8/site-packages (from pexpect&gt;4.3-&gt;ipython-&gt;spark-nlp-display==4.1-&gt;johnsnowlabs==4.2.3) (0.7.0)\nRequirement already satisfied: wcwidth in /databricks/python3/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,&lt;3.1.0,&gt;=2.0.0-&gt;ipython-&gt;spark-nlp-display==4.1-&gt;johnsnowlabs==4.2.3) (0.2.5)\nRequirement already satisfied: ipython-genutils in /databricks/python3/lib/python3.8/site-packages (from traitlets&gt;=4.2-&gt;ipython-&gt;spark-nlp-display==4.1-&gt;johnsnowlabs==4.2.3) (0.2.0)\nRequirement already satisfied: typing-extensions&gt;=3.7.4.3 in /databricks/python3/lib/python3.8/site-packages (from pydantic-&gt;johnsnowlabs==4.2.3) (3.7.4.3)\nInstalling collected packages: decorator, py4j, pyspark, johnsnowlabs\n  Attempting uninstall: decorator\n    Found existing installation: decorator 5.0.6\n    Not uninstalling decorator at /databricks/python3/lib/python3.8/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-a8203e85-b6a5-444c-bde0-4ea6b428a33d\n    Can&#39;t uninstall &#39;decorator&#39;. No files were found to uninstall.\n  Attempting uninstall: py4j\n    Found existing installation: py4j 0.10.9.3\n    Not uninstalling py4j at /databricks/python3/lib/python3.8/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-a8203e85-b6a5-444c-bde0-4ea6b428a33d\n    Can&#39;t uninstall &#39;py4j&#39;. No files were found to uninstall.\n  Attempting uninstall: pyspark\n    Found existing installation: pyspark 3.2.1\n    Not uninstalling pyspark at /databricks/python3/lib/python3.8/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-a8203e85-b6a5-444c-bde0-4ea6b428a33d\n    Can&#39;t uninstall &#39;pyspark&#39;. No files were found to uninstall.\nERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nspark-ocr 4.2.1 requires pyspark==3.2.1, but you have pyspark 3.1.2 which is incompatible.\nspark-ocr 4.2.1 requires spark-nlp==4.2.1, but you have spark-nlp 4.2.4 which is incompatible.\nSuccessfully installed decorator-5.0.9 johnsnowlabs-4.2.3 py4j-0.10.9 pyspark-3.1.2\nWARNING: You are using pip version 21.0.1; however, version 22.3.1 is available.\nYou should consider upgrading via the &#39;/local_disk0/.ephemeral_nfs/envs/pythonEnv-a8203e85-b6a5-444c-bde0-4ea6b428a33d/bin/python -m pip install --upgrade pip&#39; command.\nPython interpreter will be restarted.\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting johnsnowlabs==4.2.3\n  Using cached johnsnowlabs-4.2.3-py3-none-any.whl (74 kB)\nRequirement already satisfied: networkx==2.5 in /databricks/python3/lib/python3.8/site-packages (2.5)\nCollecting decorator==5.0.9\n  Using cached decorator-5.0.9-py3-none-any.whl (8.9 kB)\nRequirement already satisfied: plotly==5.1.0 in /databricks/python3/lib/python3.8/site-packages (5.1.0)\nRequirement already satisfied: nlu==4.0.1rc4 in /databricks/python3/lib/python3.8/site-packages (from johnsnowlabs==4.2.3) (4.0.1rc4)\nRequirement already satisfied: spark-nlp==4.2.4 in /databricks/python3/lib/python3.8/site-packages (from johnsnowlabs==4.2.3) (4.2.4)\nRequirement already satisfied: databricks-api in /databricks/python3/lib/python3.8/site-packages (from johnsnowlabs==4.2.3) (0.8.0)\nRequirement already satisfied: colorama in /databricks/python3/lib/python3.8/site-packages (from johnsnowlabs==4.2.3) (0.4.6)\nRequirement already satisfied: spark-nlp-display==4.1 in /databricks/python3/lib/python3.8/site-packages (from johnsnowlabs==4.2.3) (4.1)\nCollecting pyspark==3.1.2\n  Using cached pyspark-3.1.2-py2.py3-none-any.whl\nRequirement already satisfied: requests in /databricks/python3/lib/python3.8/site-packages (from johnsnowlabs==4.2.3) (2.25.1)\nRequirement already satisfied: dataclasses in /databricks/python3/lib/python3.8/site-packages (from johnsnowlabs==4.2.3) (0.6)\nRequirement already satisfied: numpy in /databricks/python3/lib/python3.8/site-packages (from johnsnowlabs==4.2.3) (1.21.6)\nRequirement already satisfied: pydantic in /databricks/python3/lib/python3.8/site-packages (from johnsnowlabs==4.2.3) (1.8.2)\nRequirement already satisfied: tenacity&gt;=6.2.0 in /databricks/python3/lib/python3.8/site-packages (from plotly==5.1.0) (6.2.0)\nRequirement already satisfied: six in /databricks/python3/lib/python3.8/site-packages (from plotly==5.1.0) (1.15.0)\nRequirement already satisfied: pandas&gt;=1.3.5 in /databricks/python3/lib/python3.8/site-packages (from nlu==4.0.1rc4-&gt;johnsnowlabs==4.2.3) (1.5.2)\nRequirement already satisfied: pyarrow&gt;=0.16.0 in /databricks/python3/lib/python3.8/site-packages (from nlu==4.0.1rc4-&gt;johnsnowlabs==4.2.3) (4.0.0)\nCollecting py4j==0.10.9\n  Using cached py4j-0.10.9-py2.py3-none-any.whl (198 kB)\nRequirement already satisfied: svgwrite==1.4 in /databricks/python3/lib/python3.8/site-packages (from spark-nlp-display==4.1-&gt;johnsnowlabs==4.2.3) (1.4)\nRequirement already satisfied: ipython in /databricks/python3/lib/python3.8/site-packages (from spark-nlp-display==4.1-&gt;johnsnowlabs==4.2.3) (7.22.0)\nRequirement already satisfied: python-dateutil&gt;=2.8.1 in /databricks/python3/lib/python3.8/site-packages (from pandas&gt;=1.3.5-&gt;nlu==4.0.1rc4-&gt;johnsnowlabs==4.2.3) (2.8.1)\nRequirement already satisfied: pytz&gt;=2020.1 in /databricks/python3/lib/python3.8/site-packages (from pandas&gt;=1.3.5-&gt;nlu==4.0.1rc4-&gt;johnsnowlabs==4.2.3) (2020.5)\nRequirement already satisfied: databricks-cli in /databricks/python3/lib/python3.8/site-packages (from databricks-api-&gt;johnsnowlabs==4.2.3) (0.14.3)\nRequirement already satisfied: click&gt;=6.7 in /databricks/python3/lib/python3.8/site-packages (from databricks-cli-&gt;databricks-api-&gt;johnsnowlabs==4.2.3) (7.1.2)\nRequirement already satisfied: tabulate&gt;=0.7.7 in /databricks/python3/lib/python3.8/site-packages (from databricks-cli-&gt;databricks-api-&gt;johnsnowlabs==4.2.3) (0.8.7)\nRequirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /databricks/python3/lib/python3.8/site-packages (from requests-&gt;johnsnowlabs==4.2.3) (1.25.11)\nRequirement already satisfied: idna&lt;3,&gt;=2.5 in /databricks/python3/lib/python3.8/site-packages (from requests-&gt;johnsnowlabs==4.2.3) (2.10)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /databricks/python3/lib/python3.8/site-packages (from requests-&gt;johnsnowlabs==4.2.3) (2020.12.5)\nRequirement already satisfied: chardet&lt;5,&gt;=3.0.2 in /databricks/python3/lib/python3.8/site-packages (from requests-&gt;johnsnowlabs==4.2.3) (4.0.0)\nRequirement already satisfied: pygments in /databricks/python3/lib/python3.8/site-packages (from ipython-&gt;spark-nlp-display==4.1-&gt;johnsnowlabs==4.2.3) (2.8.1)\nRequirement already satisfied: pexpect&gt;4.3 in /databricks/python3/lib/python3.8/site-packages (from ipython-&gt;spark-nlp-display==4.1-&gt;johnsnowlabs==4.2.3) (4.8.0)\nRequirement already satisfied: setuptools&gt;=18.5 in /usr/local/lib/python3.8/dist-packages (from ipython-&gt;spark-nlp-display==4.1-&gt;johnsnowlabs==4.2.3) (52.0.0)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,&lt;3.1.0,&gt;=2.0.0 in /databricks/python3/lib/python3.8/site-packages (from ipython-&gt;spark-nlp-display==4.1-&gt;johnsnowlabs==4.2.3) (3.0.17)\nRequirement already satisfied: traitlets&gt;=4.2 in /databricks/python3/lib/python3.8/site-packages (from ipython-&gt;spark-nlp-display==4.1-&gt;johnsnowlabs==4.2.3) (5.0.5)\nRequirement already satisfied: backcall in /databricks/python3/lib/python3.8/site-packages (from ipython-&gt;spark-nlp-display==4.1-&gt;johnsnowlabs==4.2.3) (0.2.0)\nRequirement already satisfied: pickleshare in /databricks/python3/lib/python3.8/site-packages (from ipython-&gt;spark-nlp-display==4.1-&gt;johnsnowlabs==4.2.3) (0.7.5)\nRequirement already satisfied: jedi&gt;=0.16 in /databricks/python3/lib/python3.8/site-packages (from ipython-&gt;spark-nlp-display==4.1-&gt;johnsnowlabs==4.2.3) (0.17.2)\nRequirement already satisfied: parso&lt;0.8.0,&gt;=0.7.0 in /databricks/python3/lib/python3.8/site-packages (from jedi&gt;=0.16-&gt;ipython-&gt;spark-nlp-display==4.1-&gt;johnsnowlabs==4.2.3) (0.7.0)\nRequirement already satisfied: ptyprocess&gt;=0.5 in /databricks/python3/lib/python3.8/site-packages (from pexpect&gt;4.3-&gt;ipython-&gt;spark-nlp-display==4.1-&gt;johnsnowlabs==4.2.3) (0.7.0)\nRequirement already satisfied: wcwidth in /databricks/python3/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,&lt;3.1.0,&gt;=2.0.0-&gt;ipython-&gt;spark-nlp-display==4.1-&gt;johnsnowlabs==4.2.3) (0.2.5)\nRequirement already satisfied: ipython-genutils in /databricks/python3/lib/python3.8/site-packages (from traitlets&gt;=4.2-&gt;ipython-&gt;spark-nlp-display==4.1-&gt;johnsnowlabs==4.2.3) (0.2.0)\nRequirement already satisfied: typing-extensions&gt;=3.7.4.3 in /databricks/python3/lib/python3.8/site-packages (from pydantic-&gt;johnsnowlabs==4.2.3) (3.7.4.3)\nInstalling collected packages: decorator, py4j, pyspark, johnsnowlabs\n  Attempting uninstall: decorator\n    Found existing installation: decorator 5.0.6\n    Not uninstalling decorator at /databricks/python3/lib/python3.8/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-a8203e85-b6a5-444c-bde0-4ea6b428a33d\n    Can&#39;t uninstall &#39;decorator&#39;. No files were found to uninstall.\n  Attempting uninstall: py4j\n    Found existing installation: py4j 0.10.9.3\n    Not uninstalling py4j at /databricks/python3/lib/python3.8/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-a8203e85-b6a5-444c-bde0-4ea6b428a33d\n    Can&#39;t uninstall &#39;py4j&#39;. No files were found to uninstall.\n  Attempting uninstall: pyspark\n    Found existing installation: pyspark 3.2.1\n    Not uninstalling pyspark at /databricks/python3/lib/python3.8/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-a8203e85-b6a5-444c-bde0-4ea6b428a33d\n    Can&#39;t uninstall &#39;pyspark&#39;. No files were found to uninstall.\nERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nspark-ocr 4.2.1 requires pyspark==3.2.1, but you have pyspark 3.1.2 which is incompatible.\nspark-ocr 4.2.1 requires spark-nlp==4.2.1, but you have spark-nlp 4.2.4 which is incompatible.\nSuccessfully installed decorator-5.0.9 johnsnowlabs-4.2.3 py4j-0.10.9 pyspark-3.1.2\nWARNING: You are using pip version 21.0.1; however, version 22.3.1 is available.\nYou should consider upgrading via the &#39;/local_disk0/.ephemeral_nfs/envs/pythonEnv-a8203e85-b6a5-444c-bde0-4ea6b428a33d/bin/python -m pip install --upgrade pip&#39; command.\nPython interpreter will be restarted.\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# Analysis\nDuring this process of analysis, let's get a sample of a 10-K filing from the internet, visualize it and understand the company information there"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0520d773-0c3a-4be5-b121-c5ce54efecea","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["# Sample Texts from Cadence Design System\nExamples taken from publicly available information about Cadence in SEC's Edgar database [here](https://www.sec.gov/Archives/edgar/data/813672/000081367222000012/cdns-20220101.htm) and [Wikipedia](https://en.wikipedia.org/wiki/Cadence_Design_Systems)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"75ead4c3-d963-4b64-a3da-5b875b815fc5","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["!wget -O /databricks/driver/cdns-20220101.html.txt https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings_JSL/Finance/data/cdns-20220101.html.txt"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b14f49f9-5597-4e52-8356-9200e52c4b09","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">--2022-12-15 13:57:28--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings_JSL/Finance/data/cdns-20220101.html.txt\r\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\r\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\r\nHTTP request sent, awaiting response... 200 OK\r\nLength: 347392 (339K) [text/plain]\r\nSaving to: ‘/databricks/driver/cdns-20220101.html.txt’\r\n\r\n\r          /databric   0%[                    ]       0  --.-KB/s               \r/databricks/driver/ 100%[===================&gt;] 339.25K  --.-KB/s    in 0.002s  \r\n\r\n2022-12-15 13:57:28 (144 MB/s) - ‘/databricks/driver/cdns-20220101.html.txt’ saved [347392/347392]\r\n\r\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">--2022-12-15 13:57:28--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings_JSL/Finance/data/cdns-20220101.html.txt\r\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\r\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\r\nHTTP request sent, awaiting response... 200 OK\r\nLength: 347392 (339K) [text/plain]\r\nSaving to: ‘/databricks/driver/cdns-20220101.html.txt’\r\n\r\n\r          /databric   0%[                    ]       0  --.-KB/s               \r/databricks/driver/ 100%[===================&gt;] 339.25K  --.-KB/s    in 0.002s  \r\n\r\n2022-12-15 13:57:28 (144 MB/s) - ‘/databricks/driver/cdns-20220101.html.txt’ saved [347392/347392]\r\n\r\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["**It's a 10K filing..**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4f615b67-7380-4ffd-8cde-81323e0f112b","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["with open('/databricks/driver/cdns-20220101.html.txt', 'r') as f:\n  cadence_sec10k = f.read()\nprint(cadence_sec10k[:200])"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"17899e3e-782e-4fc6-ac15-d454dce0329d","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Table of Contents\nUNITED STATES SECURITIES AND EXCHANGE COMMISSION\nWashington, D.C. 20549\n_____________________________________ \nFORM 10-K \n_____________________________________  \n(Mark One)\n☒\nANNUAL \n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Table of Contents\nUNITED STATES SECURITIES AND EXCHANGE COMMISSION\nWashington, D.C. 20549\n_____________________________________ \nFORM 10-K \n_____________________________________  \n(Mark One)\n☒\nANNUAL \n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["**The company is Cadence Design System, Inc**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"cd64accb-d707-43eb-860f-c75a99af3486","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["print(cadence_sec10k[:700])"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3c0baf82-21ee-4dc4-8664-67e9e961b816","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Table of Contents\nUNITED STATES SECURITIES AND EXCHANGE COMMISSION\nWashington, D.C. 20549\n_____________________________________ \nFORM 10-K \n_____________________________________  \n(Mark One)\n☒\nANNUAL REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\nFor the fiscal year ended January 1, 2022 \nOR\n☐\nTRANSITION REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\nFor the transition period from _________ to_________.\n\nCommission file number 000-15867 \n_____________________________________\n \nCADENCE DESIGN SYSTEMS, INC. \n(Exact name of registrant as specified in its charter)\n____________________________________ \nDelaware\n \n00-0000000\n(State or O\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Table of Contents\nUNITED STATES SECURITIES AND EXCHANGE COMMISSION\nWashington, D.C. 20549\n_____________________________________ \nFORM 10-K \n_____________________________________  \n(Mark One)\n☒\nANNUAL REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\nFor the fiscal year ended January 1, 2022 \nOR\n☐\nTRANSITION REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\nFor the transition period from _________ to_________.\n\nCommission file number 000-15867 \n_____________________________________\n \nCADENCE DESIGN SYSTEMS, INC. \n(Exact name of registrant as specified in its charter)\n____________________________________ \nDelaware\n \n00-0000000\n(State or O\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Let's use `SentenceDetector` as a Page Splitter\nUsing `Table of Contents`, which is present at the end of each page as a marker of new page"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8d870344-c810-4290-a521-7f8154524fb3","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from johnsnowlabs import nlp, finance\n\ndocument_assembler = nlp.DocumentAssembler() \\\n        .setInputCol(\"text\") \\\n        .setOutputCol(\"document\")\n\nsentence_detector = nlp.SentenceDetector() \\\n    .setInputCols([\"document\"]) \\\n    .setOutputCol(\"pages\")\\\n    .setCustomBounds([\"Table of Contents\"])\\\n    .setUseCustomBoundsOnly(True)\n\nnlp_pipeline = nlp.Pipeline(stages=[\n    document_assembler, \n    sentence_detector])"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"17477a1b-4261-4470-8e76-46dc1307e340","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["from johnsnowlabs.nlp import LightPipeline\n\nempty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\nsentence_splitting_pipe = nlp_pipeline.fit(empty_data)\nsentence_splitting_lightpipe = LightPipeline(sentence_splitting_pipe)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f24247cb-b13a-4059-9b43-8c73fa44ea7b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["res = sentence_splitting_lightpipe.annotate(cadence_sec10k)\npages = res['pages']\npages = [p for p in pages if p.strip() != ''] # We remove empty pages"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"221843cb-acc7-4127-b9dc-b75235d28656","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["import pickle\nwith open('/databricks/driver/cadence_pages.pickle', 'wb') as f:\n  pickle.dump(pages, f)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c85e0eaf-a31b-40d4-b3ef-ae0e3895ac82","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["The first page has the usual **10-K summary** information, which is very useful"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0083f45f-8d74-49fb-8d2b-351e5bb6d1ca","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["print(pages[0])"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e107b803-7bab-4153-8444-02ae976533ee","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">UNITED STATES SECURITIES AND EXCHANGE COMMISSION\nWashington, D.C. 20549\n_____________________________________ \nFORM 10-K \n_____________________________________  \n(Mark One)\n☒\nANNUAL REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\nFor the fiscal year ended January 1, 2022 \nOR\n☐\nTRANSITION REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\nFor the transition period from _________ to_________.\n\nCommission file number 000-15867 \n_____________________________________\n \nCADENCE DESIGN SYSTEMS, INC. \n(Exact name of registrant as specified in its charter)\n____________________________________ \nDelaware\n \n00-0000000\n(State or Other Jurisdiction ofIncorporation or Organization)\n \n(I.R.S. EmployerIdentification No.)\n2655 Seely Avenue, Building 5,\nSan Jose,\nCalifornia\n \n95134\n(Address of Principal Executive Offices)\n \n(Zip Code)\n(408)\n-943-1234 \n(Registrant’s Telephone Number, including Area Code) \nSecurities registered pursuant to Section 12(b) of the Act:\nTitle of Each Class\nTrading Symbol(s)\nNames of Each Exchange on which Registered\nCommon Stock, $0.01 par value per share\nCDNS\nNasdaq Global Select Market\nSecurities registered pursuant to Section 12(g) of the Act:\nNone\nIndicate by check mark if the registrant is a well-known seasoned issuer, as defined in Rule 405 of the Securities Act.  \n Yes  \n☒\n    No  \n☐\nIndicate by check mark if the registrant is not required to file reports pursuant to Section 13 or Section 15(d) of the Act.  \n Yes \n☐    \nNo  \n☒\nIndicate by check mark whether the registrant (1) has filed all reports required to be filed by Section 13 or 15(d) of the Securities Exchange Act of 1934 during the preceding 12 months (or for such shorter period that the registrant was required to file such reports), and (2) has been subject to such filing requirements for the past 90 days.  \n Yes  \n☒\n    No  \n☐\nIndicate by check mark whether the registrant has submitted electronically every Interactive Data File required to be submitted pursuant to Rule 405 of Regulation S-T (§ 232.405 of this chapter) during the preceding 12 months (or for such shorter period that the registrant was required to submit such files). \n Yes  \n☒\n    No  \n☐\nIndicate by check mark whether the registrant is a large accelerated filer, an accelerated filer, a non-accelerated filer, a smaller reporting company, or an emerging growth company. See the definitions of “large accelerated filer,” “accelerated filer,” “smaller reporting company,” and “emerging growth company” in Rule 12b-2 of the Exchange Act.\nLarge Accelerated Filer\n☒\nAccelerated Filer\n☐\nNon-accelerated Filer\n☐\nSmaller Reporting Company\n☐\nEmerging Growth Company\n☐\nIf an emerging growth company, indicate by check mark if the registrant has elected not to use the extended transition period for complying with any new or revised financial accounting standards provided pursuant to Section 13(a) of the Exchange Act.  \n☐\nIndicate by check mark whether the registrant has filed a report on and attestation to its management’s assessment of the effectiveness of its internal control over financial reporting under Section 404(b) of the Sarbanes-Oxley Act (15 U.S.C. 7262(b)) by the registered public accounting firm that prepared or issued its audit report. \n☒\nIndicate by check mark whether the registrant is a shell company (as defined in Rule 12b-2 of the Act). \n Yes \n☐ \nNo  \n☒\nThe aggregate market value of the voting and non-voting common equity held by non-affiliates computed by reference to the price at which the common equity was last sold as of the last business day of the registrant’s most recently completed second fiscal quarter ended July 3, 2021 was approximately $38,179,000,000.\nOn February 5, 2022, approximately 277,336,000 shares of the Registrant’s Common Stock, $0.01 par value, were outstanding.\nDOCUMENTS INCORPORATED BY REFERENCE\nPortions of the definitive proxy statement for Cadence Design Systems, Inc.’s 2022 Annual Meeting of Stockholders are incorporated by reference into Part III hereof.\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">UNITED STATES SECURITIES AND EXCHANGE COMMISSION\nWashington, D.C. 20549\n_____________________________________ \nFORM 10-K \n_____________________________________  \n(Mark One)\n☒\nANNUAL REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\nFor the fiscal year ended January 1, 2022 \nOR\n☐\nTRANSITION REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\nFor the transition period from _________ to_________.\n\nCommission file number 000-15867 \n_____________________________________\n \nCADENCE DESIGN SYSTEMS, INC. \n(Exact name of registrant as specified in its charter)\n____________________________________ \nDelaware\n \n00-0000000\n(State or Other Jurisdiction ofIncorporation or Organization)\n \n(I.R.S. EmployerIdentification No.)\n2655 Seely Avenue, Building 5,\nSan Jose,\nCalifornia\n \n95134\n(Address of Principal Executive Offices)\n \n(Zip Code)\n(408)\n-943-1234 \n(Registrant’s Telephone Number, including Area Code) \nSecurities registered pursuant to Section 12(b) of the Act:\nTitle of Each Class\nTrading Symbol(s)\nNames of Each Exchange on which Registered\nCommon Stock, $0.01 par value per share\nCDNS\nNasdaq Global Select Market\nSecurities registered pursuant to Section 12(g) of the Act:\nNone\nIndicate by check mark if the registrant is a well-known seasoned issuer, as defined in Rule 405 of the Securities Act.  \n Yes  \n☒\n    No  \n☐\nIndicate by check mark if the registrant is not required to file reports pursuant to Section 13 or Section 15(d) of the Act.  \n Yes \n☐    \nNo  \n☒\nIndicate by check mark whether the registrant (1) has filed all reports required to be filed by Section 13 or 15(d) of the Securities Exchange Act of 1934 during the preceding 12 months (or for such shorter period that the registrant was required to file such reports), and (2) has been subject to such filing requirements for the past 90 days.  \n Yes  \n☒\n    No  \n☐\nIndicate by check mark whether the registrant has submitted electronically every Interactive Data File required to be submitted pursuant to Rule 405 of Regulation S-T (§ 232.405 of this chapter) during the preceding 12 months (or for such shorter period that the registrant was required to submit such files). \n Yes  \n☒\n    No  \n☐\nIndicate by check mark whether the registrant is a large accelerated filer, an accelerated filer, a non-accelerated filer, a smaller reporting company, or an emerging growth company. See the definitions of “large accelerated filer,” “accelerated filer,” “smaller reporting company,” and “emerging growth company” in Rule 12b-2 of the Exchange Act.\nLarge Accelerated Filer\n☒\nAccelerated Filer\n☐\nNon-accelerated Filer\n☐\nSmaller Reporting Company\n☐\nEmerging Growth Company\n☐\nIf an emerging growth company, indicate by check mark if the registrant has elected not to use the extended transition period for complying with any new or revised financial accounting standards provided pursuant to Section 13(a) of the Exchange Act.  \n☐\nIndicate by check mark whether the registrant has filed a report on and attestation to its management’s assessment of the effectiveness of its internal control over financial reporting under Section 404(b) of the Sarbanes-Oxley Act (15 U.S.C. 7262(b)) by the registered public accounting firm that prepared or issued its audit report. \n☒\nIndicate by check mark whether the registrant is a shell company (as defined in Rule 12b-2 of the Act). \n Yes \n☐ \nNo  \n☒\nThe aggregate market value of the voting and non-voting common equity held by non-affiliates computed by reference to the price at which the common equity was last sold as of the last business day of the registrant’s most recently completed second fiscal quarter ended July 3, 2021 was approximately $38,179,000,000.\nOn February 5, 2022, approximately 277,336,000 shares of the Registrant’s Common Stock, $0.01 par value, were outstanding.\nDOCUMENTS INCORPORATED BY REFERENCE\nPortions of the definitive proxy statement for Cadence Design Systems, Inc.’s 2022 Annual Meeting of Stockholders are incorporated by reference into Part III hereof.\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["<img src=\"https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings_JSL/Finance/data/10k_image.png?raw=true\"/>"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e9537e51-a97e-4e55-9795-4fca81acee07","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["## Using Text Classification to find Relevant Parts of the Document: 10K Summary\nIn this case, we know page 0 is always the page with summary information about the company. However, let's suppose we don't know it. We can use `ClassifierDL` to do Text Classification, in this case, at `Page` level.\n\nTo check the SEC 10K Summary page, we have a specific model called `\"finclf_form_10k_summary_item\"`"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"59aa883e-8f81-4838-bcb8-57c3f25c25f9","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%run \"./aux_pipeline_functions\""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4693233f-58c3-4ceb-aee2-a41cd601a434","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["classification_pipeline = get_text_classification_pipeline('finclf_form_10k_summary_item')\n\nempty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n\nfit_classification_pipeline = classification_pipeline.fit(empty_data)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4ece0748-3b9a-432c-9747-b6ba81e5ff67","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">tfhub_use download started this may take some time.\nApproximate size to download 923.7 MB\n\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[OK!]\nfinclf_form_10k_summary_item download started this may take some time.\n\r[ | ]\nAn error occurred while calling z:com.johnsnowlabs.nlp.pretrained.InternalsPythonResourceDownloader.downloadModel.\n: com.johnsnowlabs.license.exceptions.JslInvalidLicenseException: Cannot check-in the license or license already in use.\n\tat com.johnsnowlabs.license.LockManager$.tryAcquireLock(LockManager.scala:82)\n\tat com.johnsnowlabs.license.LockManager$.acquireLock(LockManager.scala:101)\n\tat com.johnsnowlabs.license.DatabricksPlatform.checkValidLicense(Platforms.scala:211)\n\tat com.johnsnowlabs.license.CheckLicense.checkValidEnvironment(CheckLicense.scala:85)\n\tat com.johnsnowlabs.license.CheckLicense.checkValidEnvironment$(CheckLicense.scala:83)\n\tat com.johnsnowlabs.nlp.pretrained.InternalsPythonResourceDownloader$.checkValidEnvironment(InternalsPythonResourceDownloader.scala:28)\n\tat com.johnsnowlabs.nlp.pretrained.InternalsPythonResourceDownloader$.downloadModel(InternalsPythonResourceDownloader.scala:73)\n\tat com.johnsnowlabs.nlp.pretrained.InternalsPythonResourceDownloader.downloadModel(InternalsPythonResourceDownloader.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:750)\n\r[OK!]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">tfhub_use download started this may take some time.\nApproximate size to download 923.7 MB\n\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[OK!]\nfinclf_form_10k_summary_item download started this may take some time.\n\r[ | ]\nAn error occurred while calling z:com.johnsnowlabs.nlp.pretrained.InternalsPythonResourceDownloader.downloadModel.\n: com.johnsnowlabs.license.exceptions.JslInvalidLicenseException: Cannot check-in the license or license already in use.\n\tat com.johnsnowlabs.license.LockManager$.tryAcquireLock(LockManager.scala:82)\n\tat com.johnsnowlabs.license.LockManager$.acquireLock(LockManager.scala:101)\n\tat com.johnsnowlabs.license.DatabricksPlatform.checkValidLicense(Platforms.scala:211)\n\tat com.johnsnowlabs.license.CheckLicense.checkValidEnvironment(CheckLicense.scala:85)\n\tat com.johnsnowlabs.license.CheckLicense.checkValidEnvironment$(CheckLicense.scala:83)\n\tat com.johnsnowlabs.nlp.pretrained.InternalsPythonResourceDownloader$.checkValidEnvironment(InternalsPythonResourceDownloader.scala:28)\n\tat com.johnsnowlabs.nlp.pretrained.InternalsPythonResourceDownloader$.downloadModel(InternalsPythonResourceDownloader.scala:73)\n\tat com.johnsnowlabs.nlp.pretrained.InternalsPythonResourceDownloader.downloadModel(InternalsPythonResourceDownloader.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:750)\n\r[OK!]\n</div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">Py4JJavaError</span>                             Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-770321394216648&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>classification_pipeline <span class=\"ansi-blue-fg\">=</span> get_text_classification_pipeline<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;finclf_form_10k_summary_item&#39;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span> empty_data <span class=\"ansi-blue-fg\">=</span> spark<span class=\"ansi-blue-fg\">.</span>createDataFrame<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">&#34;&#34;</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>toDF<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;text&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span> fit_classification_pipeline <span class=\"ansi-blue-fg\">=</span> classification_pipeline<span class=\"ansi-blue-fg\">.</span>fit<span class=\"ansi-blue-fg\">(</span>empty_data<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">&lt;command-770321394216561&gt;</span> in <span class=\"ansi-cyan-fg\">get_text_classification_pipeline</span><span class=\"ansi-blue-fg\">(model)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     43</span>       <span class=\"ansi-blue-fg\">.</span>setOutputCol<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;sentence_embeddings&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     44</span> \n<span class=\"ansi-green-fg\">---&gt; 45</span><span class=\"ansi-red-fg\">   </span>doc_classifier <span class=\"ansi-blue-fg\">=</span> finance<span class=\"ansi-blue-fg\">.</span>ClassifierDLModel<span class=\"ansi-blue-fg\">.</span>pretrained<span class=\"ansi-blue-fg\">(</span>model<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;en&#34;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;finance/models&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-red-fg\">\\</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     46</span>       <span class=\"ansi-blue-fg\">.</span>setInputCols<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">&#34;sentence_embeddings&#34;</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-red-fg\">\\</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     47</span>       <span class=\"ansi-blue-fg\">.</span>setOutputCol<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;category&#34;</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.8/site-packages/sparknlp_jsl/finance/sequence_classification/finance_classifier_dl.py</span> in <span class=\"ansi-cyan-fg\">pretrained</span><span class=\"ansi-blue-fg\">(name, lang, remote_loc)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    235</span>     <span class=\"ansi-green-fg\">def</span> pretrained<span class=\"ansi-blue-fg\">(</span>name<span class=\"ansi-blue-fg\">,</span> lang<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#34;en&#34;</span><span class=\"ansi-blue-fg\">,</span> remote_loc<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    236</span>         <span class=\"ansi-green-fg\">from</span> sparknlp_jsl<span class=\"ansi-blue-fg\">.</span>pretrained <span class=\"ansi-green-fg\">import</span> InternalResourceDownloader\n<span class=\"ansi-green-fg\">--&gt; 237</span><span class=\"ansi-red-fg\">         return InternalResourceDownloader.downloadModel(FinanceClassifierDLModel, name, lang, remote_loc,\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    238</span>                                                         j_dwn=&#39;InternalsPythonResourceDownloader&#39;)\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.8/site-packages/sparknlp_jsl/pretrained.py</span> in <span class=\"ansi-cyan-fg\">downloadModel</span><span class=\"ansi-blue-fg\">(reader, name, language, remote_loc, j_dwn)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     38</span>         <span class=\"ansi-green-fg\">except</span> Py4JJavaError <span class=\"ansi-green-fg\">as</span> e<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     39</span>                 sys<span class=\"ansi-blue-fg\">.</span>stdout<span class=\"ansi-blue-fg\">.</span>write<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;\\n&#34;</span> <span class=\"ansi-blue-fg\">+</span> str<span class=\"ansi-blue-fg\">(</span>e<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">---&gt; 40</span><span class=\"ansi-red-fg\">                 </span><span class=\"ansi-green-fg\">raise</span> e\n<span class=\"ansi-green-intense-fg ansi-bold\">     41</span>         <span class=\"ansi-green-fg\">finally</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     42</span>                 stop_threads <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">True</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.8/site-packages/sparknlp_jsl/pretrained.py</span> in <span class=\"ansi-cyan-fg\">downloadModel</span><span class=\"ansi-blue-fg\">(reader, name, language, remote_loc, j_dwn)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     35</span>         t1<span class=\"ansi-blue-fg\">.</span>start<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     36</span>         <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">---&gt; 37</span><span class=\"ansi-red-fg\">                 </span>j_obj <span class=\"ansi-blue-fg\">=</span> _internal_opensource<span class=\"ansi-blue-fg\">.</span>_DownloadModel<span class=\"ansi-blue-fg\">(</span>reader<span class=\"ansi-blue-fg\">.</span>name<span class=\"ansi-blue-fg\">,</span> name<span class=\"ansi-blue-fg\">,</span> language<span class=\"ansi-blue-fg\">,</span> remote_loc<span class=\"ansi-blue-fg\">,</span> j_dwn<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>apply<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     38</span>         <span class=\"ansi-green-fg\">except</span> Py4JJavaError <span class=\"ansi-green-fg\">as</span> e<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     39</span>                 sys<span class=\"ansi-blue-fg\">.</span>stdout<span class=\"ansi-blue-fg\">.</span>write<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;\\n&#34;</span> <span class=\"ansi-blue-fg\">+</span> str<span class=\"ansi-blue-fg\">(</span>e<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.8/site-packages/sparknlp/internal/__init__.py</span> in <span class=\"ansi-cyan-fg\">__init__</span><span class=\"ansi-blue-fg\">(self, reader, name, language, remote_loc, validator)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    326</span> <span class=\"ansi-green-fg\">class</span> _DownloadModel<span class=\"ansi-blue-fg\">(</span>ExtendedJavaWrapper<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    327</span>     <span class=\"ansi-green-fg\">def</span> __init__<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> reader<span class=\"ansi-blue-fg\">,</span> name<span class=\"ansi-blue-fg\">,</span> language<span class=\"ansi-blue-fg\">,</span> remote_loc<span class=\"ansi-blue-fg\">,</span> validator<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 328</span><span class=\"ansi-red-fg\">         super(_DownloadModel, self).__init__(&#34;com.johnsnowlabs.nlp.pretrained.&#34; + validator + &#34;.downloadModel&#34;, reader,\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    329</span>                                              name, language, remote_loc)\n<span class=\"ansi-green-intense-fg ansi-bold\">    330</span> \n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.8/site-packages/sparknlp/internal/extended_java_wrapper.py</span> in <span class=\"ansi-cyan-fg\">__init__</span><span class=\"ansi-blue-fg\">(self, java_obj, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     25</span>         super<span class=\"ansi-blue-fg\">(</span>ExtendedJavaWrapper<span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>__init__<span class=\"ansi-blue-fg\">(</span>java_obj<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     26</span>         self<span class=\"ansi-blue-fg\">.</span>sc <span class=\"ansi-blue-fg\">=</span> SparkContext<span class=\"ansi-blue-fg\">.</span>_active_spark_context\n<span class=\"ansi-green-fg\">---&gt; 27</span><span class=\"ansi-red-fg\">         </span>self<span class=\"ansi-blue-fg\">.</span>_java_obj <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>new_java_obj<span class=\"ansi-blue-fg\">(</span>java_obj<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">*</span>args<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     28</span>         self<span class=\"ansi-blue-fg\">.</span>java_obj <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_java_obj\n<span class=\"ansi-green-intense-fg ansi-bold\">     29</span> \n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.8/site-packages/sparknlp/internal/extended_java_wrapper.py</span> in <span class=\"ansi-cyan-fg\">new_java_obj</span><span class=\"ansi-blue-fg\">(self, java_class, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     35</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     36</span>     <span class=\"ansi-green-fg\">def</span> new_java_obj<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> java_class<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">*</span>args<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">---&gt; 37</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_new_java_obj<span class=\"ansi-blue-fg\">(</span>java_class<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">*</span>args<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     38</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     39</span>     <span class=\"ansi-green-fg\">def</span> new_java_array<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> pylist<span class=\"ansi-blue-fg\">,</span> java_class<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/ml/wrapper.py</span> in <span class=\"ansi-cyan-fg\">_new_java_obj</span><span class=\"ansi-blue-fg\">(java_class, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     64</span>             java_obj <span class=\"ansi-blue-fg\">=</span> getattr<span class=\"ansi-blue-fg\">(</span>java_obj<span class=\"ansi-blue-fg\">,</span> name<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     65</span>         java_args <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">[</span>_py2java<span class=\"ansi-blue-fg\">(</span>sc<span class=\"ansi-blue-fg\">,</span> arg<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">for</span> arg <span class=\"ansi-green-fg\">in</span> args<span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-fg\">---&gt; 66</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> java_obj<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>java_args<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     67</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     68</span>     <span class=\"ansi-blue-fg\">@</span>staticmethod\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1302</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">-&gt; 1304</span><span class=\"ansi-red-fg\">         return_value = get_return_value(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1305</span>             answer, self.gateway_client, self.target_id, self.name)\n<span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    115</span>     <span class=\"ansi-green-fg\">def</span> deco<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    116</span>         <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 117</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    118</span>         <span class=\"ansi-green-fg\">except</span> py4j<span class=\"ansi-blue-fg\">.</span>protocol<span class=\"ansi-blue-fg\">.</span>Py4JJavaError <span class=\"ansi-green-fg\">as</span> e<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    119</span>             converted <span class=\"ansi-blue-fg\">=</span> convert_exception<span class=\"ansi-blue-fg\">(</span>e<span class=\"ansi-blue-fg\">.</span>java_exception<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py</span> in <span class=\"ansi-cyan-fg\">get_return_value</span><span class=\"ansi-blue-fg\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    324</span>             value <span class=\"ansi-blue-fg\">=</span> OUTPUT_CONVERTER<span class=\"ansi-blue-fg\">[</span>type<span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">(</span>answer<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">2</span><span class=\"ansi-blue-fg\">:</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">,</span> gateway_client<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    325</span>             <span class=\"ansi-green-fg\">if</span> answer<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-blue-fg\">==</span> REFERENCE_TYPE<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 326</span><span class=\"ansi-red-fg\">                 raise Py4JJavaError(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    327</span>                     <span class=\"ansi-blue-fg\">&#34;An error occurred while calling {0}{1}{2}.\\n&#34;</span><span class=\"ansi-blue-fg\">.</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    328</span>                     format(target_id, &#34;.&#34;, name), value)\n\n<span class=\"ansi-red-fg\">Py4JJavaError</span>: An error occurred while calling z:com.johnsnowlabs.nlp.pretrained.InternalsPythonResourceDownloader.downloadModel.\n: com.johnsnowlabs.license.exceptions.JslInvalidLicenseException: Cannot check-in the license or license already in use.\n\tat com.johnsnowlabs.license.LockManager$.tryAcquireLock(LockManager.scala:82)\n\tat com.johnsnowlabs.license.LockManager$.acquireLock(LockManager.scala:101)\n\tat com.johnsnowlabs.license.DatabricksPlatform.checkValidLicense(Platforms.scala:211)\n\tat com.johnsnowlabs.license.CheckLicense.checkValidEnvironment(CheckLicense.scala:85)\n\tat com.johnsnowlabs.license.CheckLicense.checkValidEnvironment$(CheckLicense.scala:83)\n\tat com.johnsnowlabs.nlp.pretrained.InternalsPythonResourceDownloader$.checkValidEnvironment(InternalsPythonResourceDownloader.scala:28)\n\tat com.johnsnowlabs.nlp.pretrained.InternalsPythonResourceDownloader$.downloadModel(InternalsPythonResourceDownloader.scala:73)\n\tat com.johnsnowlabs.nlp.pretrained.InternalsPythonResourceDownloader.downloadModel(InternalsPythonResourceDownloader.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:750)\n</div>","errorSummary":"com.johnsnowlabs.license.exceptions.JslInvalidLicenseException: Cannot check-in the license or license already in use.","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">Py4JJavaError</span>                             Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-770321394216648&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-fg\">----&gt; 1</span><span class=\"ansi-red-fg\"> </span>classification_pipeline <span class=\"ansi-blue-fg\">=</span> get_text_classification_pipeline<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;finclf_form_10k_summary_item&#39;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span> empty_data <span class=\"ansi-blue-fg\">=</span> spark<span class=\"ansi-blue-fg\">.</span>createDataFrame<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">&#34;&#34;</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>toDF<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;text&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span> fit_classification_pipeline <span class=\"ansi-blue-fg\">=</span> classification_pipeline<span class=\"ansi-blue-fg\">.</span>fit<span class=\"ansi-blue-fg\">(</span>empty_data<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">&lt;command-770321394216561&gt;</span> in <span class=\"ansi-cyan-fg\">get_text_classification_pipeline</span><span class=\"ansi-blue-fg\">(model)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     43</span>       <span class=\"ansi-blue-fg\">.</span>setOutputCol<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;sentence_embeddings&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     44</span> \n<span class=\"ansi-green-fg\">---&gt; 45</span><span class=\"ansi-red-fg\">   </span>doc_classifier <span class=\"ansi-blue-fg\">=</span> finance<span class=\"ansi-blue-fg\">.</span>ClassifierDLModel<span class=\"ansi-blue-fg\">.</span>pretrained<span class=\"ansi-blue-fg\">(</span>model<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;en&#34;</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#34;finance/models&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-red-fg\">\\</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     46</span>       <span class=\"ansi-blue-fg\">.</span>setInputCols<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">&#34;sentence_embeddings&#34;</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-red-fg\">\\</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     47</span>       <span class=\"ansi-blue-fg\">.</span>setOutputCol<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;category&#34;</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.8/site-packages/sparknlp_jsl/finance/sequence_classification/finance_classifier_dl.py</span> in <span class=\"ansi-cyan-fg\">pretrained</span><span class=\"ansi-blue-fg\">(name, lang, remote_loc)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    235</span>     <span class=\"ansi-green-fg\">def</span> pretrained<span class=\"ansi-blue-fg\">(</span>name<span class=\"ansi-blue-fg\">,</span> lang<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-blue-fg\">&#34;en&#34;</span><span class=\"ansi-blue-fg\">,</span> remote_loc<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    236</span>         <span class=\"ansi-green-fg\">from</span> sparknlp_jsl<span class=\"ansi-blue-fg\">.</span>pretrained <span class=\"ansi-green-fg\">import</span> InternalResourceDownloader\n<span class=\"ansi-green-fg\">--&gt; 237</span><span class=\"ansi-red-fg\">         return InternalResourceDownloader.downloadModel(FinanceClassifierDLModel, name, lang, remote_loc,\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    238</span>                                                         j_dwn=&#39;InternalsPythonResourceDownloader&#39;)\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.8/site-packages/sparknlp_jsl/pretrained.py</span> in <span class=\"ansi-cyan-fg\">downloadModel</span><span class=\"ansi-blue-fg\">(reader, name, language, remote_loc, j_dwn)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     38</span>         <span class=\"ansi-green-fg\">except</span> Py4JJavaError <span class=\"ansi-green-fg\">as</span> e<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     39</span>                 sys<span class=\"ansi-blue-fg\">.</span>stdout<span class=\"ansi-blue-fg\">.</span>write<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;\\n&#34;</span> <span class=\"ansi-blue-fg\">+</span> str<span class=\"ansi-blue-fg\">(</span>e<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">---&gt; 40</span><span class=\"ansi-red-fg\">                 </span><span class=\"ansi-green-fg\">raise</span> e\n<span class=\"ansi-green-intense-fg ansi-bold\">     41</span>         <span class=\"ansi-green-fg\">finally</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     42</span>                 stop_threads <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-green-fg\">True</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.8/site-packages/sparknlp_jsl/pretrained.py</span> in <span class=\"ansi-cyan-fg\">downloadModel</span><span class=\"ansi-blue-fg\">(reader, name, language, remote_loc, j_dwn)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     35</span>         t1<span class=\"ansi-blue-fg\">.</span>start<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     36</span>         <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">---&gt; 37</span><span class=\"ansi-red-fg\">                 </span>j_obj <span class=\"ansi-blue-fg\">=</span> _internal_opensource<span class=\"ansi-blue-fg\">.</span>_DownloadModel<span class=\"ansi-blue-fg\">(</span>reader<span class=\"ansi-blue-fg\">.</span>name<span class=\"ansi-blue-fg\">,</span> name<span class=\"ansi-blue-fg\">,</span> language<span class=\"ansi-blue-fg\">,</span> remote_loc<span class=\"ansi-blue-fg\">,</span> j_dwn<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>apply<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     38</span>         <span class=\"ansi-green-fg\">except</span> Py4JJavaError <span class=\"ansi-green-fg\">as</span> e<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     39</span>                 sys<span class=\"ansi-blue-fg\">.</span>stdout<span class=\"ansi-blue-fg\">.</span>write<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;\\n&#34;</span> <span class=\"ansi-blue-fg\">+</span> str<span class=\"ansi-blue-fg\">(</span>e<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.8/site-packages/sparknlp/internal/__init__.py</span> in <span class=\"ansi-cyan-fg\">__init__</span><span class=\"ansi-blue-fg\">(self, reader, name, language, remote_loc, validator)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    326</span> <span class=\"ansi-green-fg\">class</span> _DownloadModel<span class=\"ansi-blue-fg\">(</span>ExtendedJavaWrapper<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    327</span>     <span class=\"ansi-green-fg\">def</span> __init__<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> reader<span class=\"ansi-blue-fg\">,</span> name<span class=\"ansi-blue-fg\">,</span> language<span class=\"ansi-blue-fg\">,</span> remote_loc<span class=\"ansi-blue-fg\">,</span> validator<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 328</span><span class=\"ansi-red-fg\">         super(_DownloadModel, self).__init__(&#34;com.johnsnowlabs.nlp.pretrained.&#34; + validator + &#34;.downloadModel&#34;, reader,\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    329</span>                                              name, language, remote_loc)\n<span class=\"ansi-green-intense-fg ansi-bold\">    330</span> \n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.8/site-packages/sparknlp/internal/extended_java_wrapper.py</span> in <span class=\"ansi-cyan-fg\">__init__</span><span class=\"ansi-blue-fg\">(self, java_obj, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     25</span>         super<span class=\"ansi-blue-fg\">(</span>ExtendedJavaWrapper<span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>__init__<span class=\"ansi-blue-fg\">(</span>java_obj<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     26</span>         self<span class=\"ansi-blue-fg\">.</span>sc <span class=\"ansi-blue-fg\">=</span> SparkContext<span class=\"ansi-blue-fg\">.</span>_active_spark_context\n<span class=\"ansi-green-fg\">---&gt; 27</span><span class=\"ansi-red-fg\">         </span>self<span class=\"ansi-blue-fg\">.</span>_java_obj <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>new_java_obj<span class=\"ansi-blue-fg\">(</span>java_obj<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">*</span>args<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     28</span>         self<span class=\"ansi-blue-fg\">.</span>java_obj <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_java_obj\n<span class=\"ansi-green-intense-fg ansi-bold\">     29</span> \n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.8/site-packages/sparknlp/internal/extended_java_wrapper.py</span> in <span class=\"ansi-cyan-fg\">new_java_obj</span><span class=\"ansi-blue-fg\">(self, java_class, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     35</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     36</span>     <span class=\"ansi-green-fg\">def</span> new_java_obj<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> java_class<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">*</span>args<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">---&gt; 37</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_new_java_obj<span class=\"ansi-blue-fg\">(</span>java_class<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">*</span>args<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     38</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     39</span>     <span class=\"ansi-green-fg\">def</span> new_java_array<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> pylist<span class=\"ansi-blue-fg\">,</span> java_class<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/ml/wrapper.py</span> in <span class=\"ansi-cyan-fg\">_new_java_obj</span><span class=\"ansi-blue-fg\">(java_class, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     64</span>             java_obj <span class=\"ansi-blue-fg\">=</span> getattr<span class=\"ansi-blue-fg\">(</span>java_obj<span class=\"ansi-blue-fg\">,</span> name<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     65</span>         java_args <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">[</span>_py2java<span class=\"ansi-blue-fg\">(</span>sc<span class=\"ansi-blue-fg\">,</span> arg<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">for</span> arg <span class=\"ansi-green-fg\">in</span> args<span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-fg\">---&gt; 66</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> java_obj<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>java_args<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     67</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     68</span>     <span class=\"ansi-blue-fg\">@</span>staticmethod\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1302</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">-&gt; 1304</span><span class=\"ansi-red-fg\">         return_value = get_return_value(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1305</span>             answer, self.gateway_client, self.target_id, self.name)\n<span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    115</span>     <span class=\"ansi-green-fg\">def</span> deco<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    116</span>         <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 117</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    118</span>         <span class=\"ansi-green-fg\">except</span> py4j<span class=\"ansi-blue-fg\">.</span>protocol<span class=\"ansi-blue-fg\">.</span>Py4JJavaError <span class=\"ansi-green-fg\">as</span> e<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    119</span>             converted <span class=\"ansi-blue-fg\">=</span> convert_exception<span class=\"ansi-blue-fg\">(</span>e<span class=\"ansi-blue-fg\">.</span>java_exception<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py</span> in <span class=\"ansi-cyan-fg\">get_return_value</span><span class=\"ansi-blue-fg\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    324</span>             value <span class=\"ansi-blue-fg\">=</span> OUTPUT_CONVERTER<span class=\"ansi-blue-fg\">[</span>type<span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">(</span>answer<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">2</span><span class=\"ansi-blue-fg\">:</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">,</span> gateway_client<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    325</span>             <span class=\"ansi-green-fg\">if</span> answer<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">1</span><span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-blue-fg\">==</span> REFERENCE_TYPE<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 326</span><span class=\"ansi-red-fg\">                 raise Py4JJavaError(\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    327</span>                     <span class=\"ansi-blue-fg\">&#34;An error occurred while calling {0}{1}{2}.\\n&#34;</span><span class=\"ansi-blue-fg\">.</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    328</span>                     format(target_id, &#34;.&#34;, name), value)\n\n<span class=\"ansi-red-fg\">Py4JJavaError</span>: An error occurred while calling z:com.johnsnowlabs.nlp.pretrained.InternalsPythonResourceDownloader.downloadModel.\n: com.johnsnowlabs.license.exceptions.JslInvalidLicenseException: Cannot check-in the license or license already in use.\n\tat com.johnsnowlabs.license.LockManager$.tryAcquireLock(LockManager.scala:82)\n\tat com.johnsnowlabs.license.LockManager$.acquireLock(LockManager.scala:101)\n\tat com.johnsnowlabs.license.DatabricksPlatform.checkValidLicense(Platforms.scala:211)\n\tat com.johnsnowlabs.license.CheckLicense.checkValidEnvironment(CheckLicense.scala:85)\n\tat com.johnsnowlabs.license.CheckLicense.checkValidEnvironment$(CheckLicense.scala:83)\n\tat com.johnsnowlabs.nlp.pretrained.InternalsPythonResourceDownloader$.checkValidEnvironment(InternalsPythonResourceDownloader.scala:28)\n\tat com.johnsnowlabs.nlp.pretrained.InternalsPythonResourceDownloader$.downloadModel(InternalsPythonResourceDownloader.scala:73)\n\tat com.johnsnowlabs.nlp.pretrained.InternalsPythonResourceDownloader.downloadModel(InternalsPythonResourceDownloader.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:750)\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["from johnsnowlabs.nlp import LightPipeline\n\nlight_classification_pipeline = LightPipeline(fit_classification_pipeline)\nresult = light_classification_pipeline.annotate(pages[0])"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2de6751f-3755-442b-b104-7edfc8a6d52f","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["result['category']"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"71613ea9-02a6-491b-97bf-719abf9317f0","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["[x['category'] for x in light_classification_pipeline.annotate([pages[1], pages[2], pages[70], pages[80]])]"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"95dea838-0645-4dd0-a9eb-0cf53431ea78","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Using Text Classification to find Relevant Parts of the Document: Acquisitions and Subsidiaries\nTo check the SEC 10K Summary page, we have a specific model called `\"finclf_acquisitions_item\"`\n\nLet's send some pages and check which one(s) contain that information. In a real case, you could send all the pages to the model, but here for time saving purposes, we will show just a subset."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"de937da6-ff68-41dd-8db3-be5e4d09b585","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["candidates = [[pages[0]], [pages[1]], [pages[35]], [pages[50]], [pages[67]]] # Some examples"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"077f1acb-859b-4b53-89c2-90c9e10a42d9","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["classification_pipeline = get_text_classification_pipeline('finclf_acquisitions_item')\ndf = spark.createDataFrame(candidates).toDF(\"text\")\nmodel = classification_pipeline.fit(df)\nresult = model.transform(df)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f15c37c0-ee31-4adb-8426-aafef68b95ff","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["result.select('category.result').show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f6f05d4d-1b5c-4717-a6d3-fdd08d15e13a","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Using Text Classification to find Relevant Parts of the Document: About Management and their work experience\nTo check the SEC 10K Summary page, we have a specific model called `\"finclf_work_experience_item\"`\n\nLet's send some pages and check which one(s) contain that information. In a real case, you could send all the pages to the model, but here for time saving purposes, we will show just a subset."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1c1a8666-01f2-469e-b76d-810f4fc07eaf","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["candidates = [[pages[4]], [pages[84]], [pages[85]], [pages[86]], [pages[87]]]"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"bc695171-915b-44b6-a5db-f39527dced2d","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["classification_pipeline = get_text_classification_pipeline('finclf_work_experience_item')\ndf = spark.createDataFrame(candidates).toDF(\"text\")\nmodel = classification_pipeline.fit(df)\nresult = model.transform(df)\nresult.select('category.result').show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"850ecb88-1169-4103-9e9f-39ddcd2022e2","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["**We have some Work Experience in page 86. However, there is 1 sentence hidden in page 4, which is also very relevant.**\n\nHowever, the model returned `other`. Why?"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5aff849d-c6cb-447f-a724-85fc8bee3796","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["pages[4]"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5613f5d0-4430-4caa-8a5a-5a66d146b27c","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Exploring the page we understand there is a lot of texts about something else which got into the same page. Sometimes, going into a smaller detail may be necessary.\n\nLet's see what happens if we get `paragraphs` instead of `pages.`"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"37348ae0-c7f8-481e-b58a-98b56992c3dd","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from johnsnowlabs import nlp, finance\n\ndocument_assembler = nlp.DocumentAssembler() \\\n        .setInputCol(\"text\") \\\n        .setOutputCol(\"document\")\n\nsentence_detector = nlp.SentenceDetector() \\\n    .setInputCols([\"document\"]) \\\n    .setOutputCol(\"paragraphs\")\n\nnlp_pipeline = nlp.Pipeline(stages=[\n    document_assembler, \n    sentence_detector])"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6ef4df33-7497-4ad1-ab48-13fc109bbd16","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["from johnsnowlabs.nlp import LightPipeline\n\nempty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\nsentence_splitting_pipe = nlp_pipeline.fit(empty_data)\nsentence_splitting_lightpipe = LightPipeline(sentence_splitting_pipe)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"464200a4-2473-47e2-8485-27163baecc87","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["res = sentence_splitting_lightpipe.annotate(pages[4])\nparagraphs = res['paragraphs']\nparagraphs = [p for p in paragraphs if p.strip() != ''] # We remove empty pages"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"974701d7-98c7-4a7a-84c2-efa149d7ed99","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["paragraphs"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"bcfb07fe-bfad-4cfc-bf76-2d177b3e7411","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["candidates = [[x] for x in paragraphs]"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c622f08f-99a5-4599-bbea-5c79d3ae21e4","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["classification_pipeline = get_text_classification_pipeline('finclf_work_experience_item')\ndf = spark.createDataFrame(candidates).toDF(\"text\")\nmodel = classification_pipeline.fit(df)\nresult = model.transform(df)\nresult.select('category.result').show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"54b71658-abba-45fd-b89d-38757d88c537","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["**Here we are, if we split in smaller detail (paragraphs, lines), we can found more information than just at page level!**\n\nThis is because information in Embeddings gets deluted the bigger the text is. Also, there are some text restrictions (512 tokens in Bert)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"33c56d65-cf83-4b43-bbfe-7a56db00c24c","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["with open('/databricks/driver/cadence_people_paragraphs.pickle', 'wb') as f:\n  pickle.dump(paragraphs, f)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9287700a-77ce-4b56-9303-0bde4976fe81","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# Continue you analysis\nMake sure you understand the contents of a 10-K and what information can be extracted. In the following notebooks we are going to extract all of that information using Finance NLP"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ba93b9af-231f-49ce-84e1-56e4852eda84","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["# You are ready to proceed to the 03 Named Entity Recognition notebook!"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"13c375ca-48d6-4d81-a24c-7ee966d7e882","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["In next and the following notebooks you will use Finance NLP to extract information, more specifically:\n- `NER`: To extract financial entities from the summary page, organizations, people and roles across the document;\n- `Normalization` to obtain the official name of the company (and any other former name) in Edgar, and `ChunkMappers` to retrieve all the registry information available in Edgar for that company;\n- `Relation Extraction`: to obtain acquisitions and subsidiaries mentioned, and also people and their roles in companies;\n- ... and much more!"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0f946f4a-6a58-4100-ae0a-2fc37e31ec2f","inputWidgets":{},"title":""}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"02_10K_Analysis","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":770321394216536}},"nbformat":4,"nbformat_minor":0}
