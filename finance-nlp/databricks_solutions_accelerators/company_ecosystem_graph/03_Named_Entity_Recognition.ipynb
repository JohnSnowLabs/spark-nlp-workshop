{"cells":[{"cell_type":"markdown","source":["You may find this series of notebooks at https://github.com/databricks-industry-solutions/jsl-financial-nlp"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ce629c4d-402d-48e9-97db-4eb9a5fdb23d","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%pip install johnsnowlabs==4.2.3 networkx==2.5 decorator==5.0.9 plotly==5.1.0 "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2b318210-983f-4600-892e-a6d7db7be296","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["# Entity Extraction\nLet's proceed to extract the entities we know from previous steps (and for our knowledge of 10K or 10Q filings) that are available in our document."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"482d7fb2-af2b-4ca1-b4d3-af120c3d3696","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from johnsnowlabs import nlp, finance, viz\n\nimport os\nimport sys\nimport time\nimport json\nimport functools \nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom scipy import spatial"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5f668fdd-0b28-4c81-8a9e-e475d290e9b7","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Auxiliary Visualization functions \nWe will use [NetworkX](https://networkx.org/) to store the graph and [Plotly](https://plotly.com/) to visualize it.\n\nThese functions will:\n- Use Plotly to visualize a NetworkX graph\n- Display relations in a dataframe"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c5cadf2c-f5d0-4107-af85-8025a4db3c2a","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%run \"./aux_visualization_functions\""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c611cd66-677a-4645-920f-bee78a26f547","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["G = nx.Graph()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d2e27b99-da3a-4450-b789-2e074bb3cb16","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["# Auxiliary Pipeline functions\nIn an independent file, we save 2 common pipelines we will be used all over the document, to keep the notebooks clean:\n- **a generic pipeline**: having `DocumentAssembler`, `SentenceDetector`, `Tokenizer` and `Financial Embeddings`;\n- **a text classification pipeline**: having `DocumentAssembler`, `Sentence Embeddings (Universal Sentence Embedings)` and `ClassifierDL (Text Classification)`;"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"02ec8736-0e19-4cea-9105-9962641f2fef","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%run \"./aux_pipeline_functions\""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e4496ccd-df81-4b1a-ac65-02e704aa5d68","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["generic_base_pipeline = get_generic_base_pipeline()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"15e36722-641c-46ae-81b1-c345ecaa3e4c","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["# Let's start\nWe read back our text file of 90 pages"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5851e26b-53de-4567-9a52-7478d090821b","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["import pickle\nwith open('/databricks/driver/cadence_pages.pickle', 'rb') as f:\n  pages = pickle.load(f)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d4466264-7b12-467a-bd47-1bc640ec018b","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["print(pages[0])"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7613d45d-b19d-47f7-94fc-53511703c1e6","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## NER: Named Entity Recognition on 10K Summary\nMain component to carry out information extraction and extract entities from texts. \n\nThis time we will use a model trained to extract many entities from 10K summaries."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b371709e-c9d7-48c2-b5df-81b4e0bffe81","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["summary_sample_text = pages[0]"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5f9ae348-9cf0-4eca-9aa2-f632221db648","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["ner_model_sec10k = finance.NerModel.pretrained(\"finner_sec_10k_summary\", \"en\", \"finance/models\")\\\n    .setInputCols([\"sentence\", \"token\", \"embeddings\"])\\\n    .setOutputCol(\"ner_summary\")\n\nner_converter_sec10k = nlp.NerConverterInternal()\\\n    .setInputCols([\"sentence\",\"token\",\"ner_summary\"])\\\n    .setOutputCol(\"ner_chunk_sec10k\")\n\nsummary_pipeline = nlp.Pipeline(stages=[\n    generic_base_pipeline,\n    ner_model_sec10k,\n    ner_converter_sec10k\n])"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7814d40e-1b03-480e-8344-7317d337e85e","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from johnsnowlabs.nlp import LightPipeline\n\nner_vis = viz.NerVisualizer()\n\nempty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n\nsummary_model = summary_pipeline.fit(empty_data)\n\nlight_summary_model = LightPipeline(summary_model)\n\nsummary_results = light_summary_model.fullAnnotate(summary_sample_text)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"428feaca-6034-48c7-867f-d2559edcf6a6","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["summary_results"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"19d01757-6ebf-454c-8196-88d0f4252e79","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Visualize Results"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4643c0cd-6ce5-4231-b866-9872014b4cc1","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["for r in summary_results:\n    displayHTML(ner_vis.display(r, label_col = \"ner_chunk_sec10k\", document_col = \"document\", return_html=True))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6d472bc8-b0df-4896-ab9f-a184858e61d6","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## First, let's extract the Organization from NER results"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a6452dcb-15d9-4659-b069-b5d4054160e1","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["We create a new graph"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5fd6adbf-291f-4ed9-a109-7281b736fb48","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["G.clear()\nG.nodes()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d962dd0a-b761-4dde-9cc2-069324bb50d6","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["ORG = next(filter(lambda x: x.metadata['entity']=='ORG', summary_results[0]['ner_chunk_sec10k'])).result\nORG"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"fb43ee36-fa0c-4477-9b74-a315f0fa1096","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["We add our first node to the graph"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"17d729fe-6a0c-4733-affe-07e6ea35b4d6","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# I add our main Organization in the center (x=0, y=0)\nG.add_node(ORG, attr_dict={'entity': 'ORG'})"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7f9e3b45-9de0-466e-bb88-52995ab39296","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["show_graph_in_plotly(G)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ee3babef-a513-468e-b85c-8d4d71a75626","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Then, let's add all the summary information from SEC 10K filings (1st page) to that organization.\n\nWe can create nodes and add a relation to Cadence directly, since we know it's information of that company."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"861e1ca8-77d7-47be-a06e-abdb5a4bfee6","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["for i, r in enumerate(summary_results[0]['ner_chunk_sec10k']):\n  text = r.result\n  entity = r.metadata['entity']\n  \n  if entity == 'ORG':\n    continue #Already added\n  G.add_node(text, attr_dict={'entity': entity}),\n  G.add_edge(ORG, text, attr_dict={'relation': 'has_' + entity.lower()})  "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8acd1cae-eedf-401e-b5f8-51ab0e7c9035","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["show_graph_in_plotly(G)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5b5cb07f-3d56-4938-bd52-d6d04f25efe7","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["import pickle\n\n# save graph object to file\npickle.dump(G, open('/databricks/driver/cadence.pickle', 'wb'))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"519db48f-631f-4405-baba-ae0c1cc32d16","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["# Now you can proceed to 04 Normalization and Data Augmentation!"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"672551ef-55f7-47ec-aa34-6e7b5c16a3f2","inputWidgets":{},"title":""}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"03_Named_Entity_Recognition","dashboards":[],"notebookMetadata":{},"language":"python","widgets":{},"notebookOrigID":770321394216565}},"nbformat":4,"nbformat_minor":0}
