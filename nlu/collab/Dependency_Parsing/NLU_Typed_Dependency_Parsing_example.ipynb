{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLU_Typed_Dependency_Parsing_example.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"s4ljYpQNp50r"},"source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n","\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/nlu/blob/master/examples/collab/Dependency_Parsing/NLU_Typed_Dependency_Parsing_example.ipynb)\n","\n","# Typed Dependency Parsing with NLU. \n","![](https://nlp.johnsnowlabs.com/assets/images/dependency_parser.png)\n","\n","Each word in a sentence has a grammatical relation to other words in the sentence.     \n","These relation pairs can be typed (i.e. subject or pronouns)     or they can be untyped, in which case only the edges between the tokens will be predicted, withouth the label.\n","\n","With NLU you can get these relations and their types in just 1 line of code! \n","# 1. Install Java and NLU"]},{"cell_type":"code","metadata":{"id":"SF5-Z-U4jukd","executionInfo":{"status":"ok","timestamp":1604907389621,"user_tz":-60,"elapsed":57000,"user":{"displayName":"Christian Kasim Loan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqAD-ircKP-s5Eh6JSdkDggDczfqQbJGU_IRb4Hw=s64","userId":"14469489166467359317"}}},"source":["import os\n","! apt-get update -qq > /dev/null   \n","# Install java\n","! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n","! pip install nlu > /dev/null    \n"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kHtLKNXDtZf5"},"source":["# 2. Load the Dependency model and predict some sample relationships"]},{"cell_type":"code","metadata":{"id":"7GJX5d6mjk5j","executionInfo":{"status":"ok","timestamp":1604907451876,"user_tz":-60,"elapsed":119237,"user":{"displayName":"Christian Kasim Loan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqAD-ircKP-s5Eh6JSdkDggDczfqQbJGU_IRb4Hw=s64","userId":"14469489166467359317"}},"outputId":"2567ef2d-c250-4532-dc45-9248e9240fe5","colab":{"base_uri":"https://localhost:8080/","height":512}},"source":["import nlu\n","dependency_pipe  = nlu.load('dep')\n","dependency_pipe.predict('Untyped dependencies describe with their relationship a directed graph')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["dependency_typed_conllu download started this may take some time.\n","Approximate size to download 257.4 KB\n","[OK!]\n","pos_anc download started this may take some time.\n","Approximate size to download 4.3 MB\n","[OK!]\n","dependency_conllu download started this may take some time.\n","Approximate size to download 16.6 MB\n","[OK!]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>token</th>\n","      <th>dependency</th>\n","      <th>pos</th>\n","      <th>labled_dependency</th>\n","    </tr>\n","    <tr>\n","      <th>origin_index</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Untyped</td>\n","      <td>ROOT</td>\n","      <td>NNP</td>\n","      <td>root</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>dependencies</td>\n","      <td>describe</td>\n","      <td>NNS</td>\n","      <td>nsubj</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>describe</td>\n","      <td>Untyped</td>\n","      <td>VBP</td>\n","      <td>parataxis</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>with</td>\n","      <td>relationship</td>\n","      <td>IN</td>\n","      <td>det</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>their</td>\n","      <td>relationship</td>\n","      <td>PRP$</td>\n","      <td>appos</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>relationship</td>\n","      <td>describe</td>\n","      <td>NN</td>\n","      <td>nsubj</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>a</td>\n","      <td>graph</td>\n","      <td>DT</td>\n","      <td>nsubj</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>directed</td>\n","      <td>graph</td>\n","      <td>JJ</td>\n","      <td>amod</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>graph</td>\n","      <td>relationship</td>\n","      <td>NN</td>\n","      <td>flat</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     token    dependency   pos labled_dependency\n","origin_index                                                    \n","0                  Untyped          ROOT   NNP              root\n","0             dependencies      describe   NNS             nsubj\n","0                 describe       Untyped   VBP         parataxis\n","0                     with  relationship    IN               det\n","0                    their  relationship  PRP$             appos\n","0             relationship      describe    NN             nsubj\n","0                        a         graph    DT             nsubj\n","0                 directed         graph    JJ              amod\n","0                    graph  relationship    NN              flat"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"5lrDNzw3tcqT"},"source":["# 3.1 Download sample dataset"]},{"cell_type":"code","metadata":{"id":"gpeS8DWBlrun","executionInfo":{"status":"ok","timestamp":1604907464653,"user_tz":-60,"elapsed":132004,"user":{"displayName":"Christian Kasim Loan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqAD-ircKP-s5Eh6JSdkDggDczfqQbJGU_IRb4Hw=s64","userId":"14469489166467359317"}},"outputId":"1f674254-f3b0-47b8-d17c-4db4df82faf0","colab":{"base_uri":"https://localhost:8080/","height":607}},"source":["import pandas as pd\n","# Download the dataset \n","! wget -N https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/sarcasm/train-balanced-sarcasm.csv -P /tmp\n","# Load dataset to Pandas\n","df = pd.read_csv('/tmp/train-balanced-sarcasm.csv')\n","df"],"execution_count":3,"outputs":[{"output_type":"stream","text":["--2020-11-09 07:37:31--  https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/sarcasm/train-balanced-sarcasm.csv\n","Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.42.214\n","Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.42.214|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 255268960 (243M) [text/csv]\n","Saving to: ‘/tmp/train-balanced-sarcasm.csv’\n","\n","train-balanced-sarc 100%[===================>] 243.44M  34.6MB/s    in 7.7s    \n","\n","2020-11-09 07:37:39 (31.6 MB/s) - ‘/tmp/train-balanced-sarcasm.csv’ saved [255268960/255268960]\n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>comment</th>\n","      <th>author</th>\n","      <th>subreddit</th>\n","      <th>score</th>\n","      <th>ups</th>\n","      <th>downs</th>\n","      <th>date</th>\n","      <th>created_utc</th>\n","      <th>parent_comment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>NC and NH.</td>\n","      <td>Trumpbart</td>\n","      <td>politics</td>\n","      <td>2</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>2016-10</td>\n","      <td>2016-10-16 23:55:23</td>\n","      <td>Yeah, I get that argument. At this point, I'd ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>You do know west teams play against west teams...</td>\n","      <td>Shbshb906</td>\n","      <td>nba</td>\n","      <td>-4</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>2016-11</td>\n","      <td>2016-11-01 00:24:10</td>\n","      <td>The blazers and Mavericks (The wests 5 and 6 s...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>They were underdogs earlier today, but since G...</td>\n","      <td>Creepeth</td>\n","      <td>nfl</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>2016-09</td>\n","      <td>2016-09-22 21:45:37</td>\n","      <td>They're favored to win.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>This meme isn't funny none of the \"new york ni...</td>\n","      <td>icebrotha</td>\n","      <td>BlackPeopleTwitter</td>\n","      <td>-8</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>2016-10</td>\n","      <td>2016-10-18 21:03:47</td>\n","      <td>deadass don't kill my buzz</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>I could use one of those tools.</td>\n","      <td>cush2push</td>\n","      <td>MaddenUltimateTeam</td>\n","      <td>6</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>2016-12</td>\n","      <td>2016-12-30 17:00:13</td>\n","      <td>Yep can confirm I saw the tool they use for th...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1010821</th>\n","      <td>1</td>\n","      <td>I'm sure that Iran and N. Korea have the techn...</td>\n","      <td>TwarkMain</td>\n","      <td>reddit.com</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2009-04</td>\n","      <td>2009-04-25 00:47:52</td>\n","      <td>No one is calling this an engineered pathogen,...</td>\n","    </tr>\n","    <tr>\n","      <th>1010822</th>\n","      <td>1</td>\n","      <td>whatever you do, don't vote green!</td>\n","      <td>BCHarvey</td>\n","      <td>climate</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2009-05</td>\n","      <td>2009-05-14 22:27:40</td>\n","      <td>In a move typical of their recent do-nothing a...</td>\n","    </tr>\n","    <tr>\n","      <th>1010823</th>\n","      <td>1</td>\n","      <td>Perhaps this is an atheist conspiracy to make ...</td>\n","      <td>rebelcommander</td>\n","      <td>atheism</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2009-01</td>\n","      <td>2009-01-11 00:22:57</td>\n","      <td>Screw the Disabled--I've got to get to Church ...</td>\n","    </tr>\n","    <tr>\n","      <th>1010824</th>\n","      <td>1</td>\n","      <td>The Slavs got their own country - it is called...</td>\n","      <td>catsi</td>\n","      <td>worldnews</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2009-01</td>\n","      <td>2009-01-23 21:12:49</td>\n","      <td>I've always been unsettled by that. I hear a l...</td>\n","    </tr>\n","    <tr>\n","      <th>1010825</th>\n","      <td>1</td>\n","      <td>values, as in capitalism .. there is good mone...</td>\n","      <td>frogking</td>\n","      <td>politics</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2009-01</td>\n","      <td>2009-01-24 06:20:14</td>\n","      <td>Why do the people who make our laws seem unabl...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1010826 rows × 10 columns</p>\n","</div>"],"text/plain":["         label  ...                                     parent_comment\n","0            0  ...  Yeah, I get that argument. At this point, I'd ...\n","1            0  ...  The blazers and Mavericks (The wests 5 and 6 s...\n","2            0  ...                            They're favored to win.\n","3            0  ...                         deadass don't kill my buzz\n","4            0  ...  Yep can confirm I saw the tool they use for th...\n","...        ...  ...                                                ...\n","1010821      1  ...  No one is calling this an engineered pathogen,...\n","1010822      1  ...  In a move typical of their recent do-nothing a...\n","1010823      1  ...  Screw the Disabled--I've got to get to Church ...\n","1010824      1  ...  I've always been unsettled by that. I hear a l...\n","1010825      1  ...  Why do the people who make our laws seem unabl...\n","\n","[1010826 rows x 10 columns]"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"uLWu8DG3tfjz"},"source":["## 3.2 Predict on sample dataset\n","NLU expects a text column, thus we must create it from the column that contains our text data"]},{"cell_type":"code","metadata":{"id":"3V5l-B6nl43U","executionInfo":{"status":"ok","timestamp":1604907480188,"user_tz":-60,"elapsed":147530,"user":{"displayName":"Christian Kasim Loan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqAD-ircKP-s5Eh6JSdkDggDczfqQbJGU_IRb4Hw=s64","userId":"14469489166467359317"}},"outputId":"7c39094a-9a83-4022-b9e6-28fb5a3d0c1d","colab":{"base_uri":"https://localhost:8080/","height":362}},"source":["dependency_pipe  = nlu.load('dep')\n","dependency_predictions = dependency_pipe.predict(df.comment.iloc[0:1])\n","dependency_predictions"],"execution_count":4,"outputs":[{"output_type":"stream","text":["dependency_typed_conllu download started this may take some time.\n","Approximate size to download 257.4 KB\n","[OK!]\n","pos_anc download started this may take some time.\n","Approximate size to download 4.3 MB\n","[OK!]\n","dependency_conllu download started this may take some time.\n","Approximate size to download 16.6 MB\n","[OK!]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>comment</th>\n","      <th>text</th>\n","      <th>token</th>\n","      <th>dependency</th>\n","      <th>pos</th>\n","      <th>labled_dependency</th>\n","    </tr>\n","    <tr>\n","      <th>origin_index</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>NC and NH.</td>\n","      <td>NC and NH.</td>\n","      <td>NC</td>\n","      <td>ROOT</td>\n","      <td>NNP</td>\n","      <td>root</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>NC and NH.</td>\n","      <td>NC and NH.</td>\n","      <td>and</td>\n","      <td>NH</td>\n","      <td>CC</td>\n","      <td>cc</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>NC and NH.</td>\n","      <td>NC and NH.</td>\n","      <td>NH</td>\n","      <td>NC</td>\n","      <td>NNP</td>\n","      <td>flat</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>NC and NH.</td>\n","      <td>NC and NH.</td>\n","      <td>.</td>\n","      <td>NC</td>\n","      <td>.</td>\n","      <td>punct</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                 comment        text token dependency  pos labled_dependency\n","origin_index                                                                \n","0             NC and NH.  NC and NH.    NC       ROOT  NNP              root\n","0             NC and NH.  NC and NH.   and         NH   CC                cc\n","0             NC and NH.  NC and NH.    NH         NC  NNP              flat\n","0             NC and NH.  NC and NH.     .         NC    .             punct"]},"metadata":{"tags":[]},"execution_count":4}]}]}