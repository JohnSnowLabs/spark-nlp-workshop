{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLU_Untyped Dependency_Parsing_example.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"s4ljYpQNp50r"},"source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n","\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/nlu/blob/master/examples/collab/Dependency_Parsing/NLU_Untyped%20Dependency_Parsing_example.ipynb)\n","\n","\n","# Untyped Dependency Parsing with NLU. \n","![](https://nlp.johnsnowlabs.com/assets/images/dependency_parser.png)\n","\n","Each word in a sentence has a grammatical relation to other words in the sentence.     \n","These relation pairs can be typed (i.e. subject or pronouns)     or they can be untyped, in which case only the edges between the tokens will be predicted, withouth the label.\n","\n","With NLU you can get these relations in just 1 line of code! \n","# 1. Install Java and NLU"]},{"cell_type":"code","metadata":{"id":"SF5-Z-U4jukd","executionInfo":{"status":"ok","timestamp":1604907596014,"user_tz":-60,"elapsed":58296,"user":{"displayName":"Christian Kasim Loan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqAD-ircKP-s5Eh6JSdkDggDczfqQbJGU_IRb4Hw=s64","userId":"14469489166467359317"}}},"source":["import os\n","! apt-get update -qq > /dev/null   \n","# Install java\n","! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n","! pip install nlu > /dev/null    "],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kHtLKNXDtZf5"},"source":["# 2. Load the Dependency model and predict some sample relationships"]},{"cell_type":"code","metadata":{"id":"7GJX5d6mjk5j","executionInfo":{"status":"ok","timestamp":1604907666230,"user_tz":-60,"elapsed":128480,"user":{"displayName":"Christian Kasim Loan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqAD-ircKP-s5Eh6JSdkDggDczfqQbJGU_IRb4Hw=s64","userId":"14469489166467359317"}},"outputId":"7b5f4b95-706e-4c79-cf4b-9abcf40b3a01","colab":{"base_uri":"https://localhost:8080/","height":512}},"source":["import nlu\n","dependency_pipe  = nlu.load('dep.untyped')\n","dependency_pipe.predict('Untyped dependencies describe with their relationship a directed graph')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["dependency_typed_conllu download started this may take some time.\n","Approximate size to download 257.4 KB\n","[OK!]\n","dependency_conllu download started this may take some time.\n","Approximate size to download 16.6 MB\n","[OK!]\n","pos_anc download started this may take some time.\n","Approximate size to download 4.3 MB\n","[OK!]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>dependency</th>\n","      <th>token</th>\n","      <th>labled_dependency</th>\n","      <th>pos</th>\n","    </tr>\n","    <tr>\n","      <th>origin_index</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ROOT</td>\n","      <td>Untyped</td>\n","      <td>root</td>\n","      <td>NNP</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>describe</td>\n","      <td>dependencies</td>\n","      <td>nsubj</td>\n","      <td>NNS</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Untyped</td>\n","      <td>describe</td>\n","      <td>parataxis</td>\n","      <td>VBP</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>relationship</td>\n","      <td>with</td>\n","      <td>det</td>\n","      <td>IN</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>relationship</td>\n","      <td>their</td>\n","      <td>appos</td>\n","      <td>PRP$</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>describe</td>\n","      <td>relationship</td>\n","      <td>nsubj</td>\n","      <td>NN</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>graph</td>\n","      <td>a</td>\n","      <td>nsubj</td>\n","      <td>DT</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>graph</td>\n","      <td>directed</td>\n","      <td>amod</td>\n","      <td>JJ</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>relationship</td>\n","      <td>graph</td>\n","      <td>flat</td>\n","      <td>NN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                dependency         token labled_dependency   pos\n","origin_index                                                    \n","0                     ROOT       Untyped              root   NNP\n","0                 describe  dependencies             nsubj   NNS\n","0                  Untyped      describe         parataxis   VBP\n","0             relationship          with               det    IN\n","0             relationship         their             appos  PRP$\n","0                 describe  relationship             nsubj    NN\n","0                    graph             a             nsubj    DT\n","0                    graph      directed              amod    JJ\n","0             relationship         graph              flat    NN"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"5lrDNzw3tcqT"},"source":["# 3.1 Download sample dataset"]},{"cell_type":"code","metadata":{"id":"gpeS8DWBlrun","executionInfo":{"status":"ok","timestamp":1604907674240,"user_tz":-60,"elapsed":136471,"user":{"displayName":"Christian Kasim Loan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqAD-ircKP-s5Eh6JSdkDggDczfqQbJGU_IRb4Hw=s64","userId":"14469489166467359317"}},"outputId":"c8a9f120-9018-4903-c44a-58f8b3b789b8","colab":{"base_uri":"https://localhost:8080/","height":607}},"source":["import pandas as pd\n","# Download the dataset \n","! wget -N https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/sarcasm/train-balanced-sarcasm.csv -P /tmp\n","# Load dataset to Pandas\n","df = pd.read_csv('/tmp/train-balanced-sarcasm.csv')\n","df"],"execution_count":3,"outputs":[{"output_type":"stream","text":["--2020-11-09 07:41:05--  https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/sarcasm/train-balanced-sarcasm.csv\n","Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.82.43\n","Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.82.43|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 255268960 (243M) [text/csv]\n","Saving to: ‘/tmp/train-balanced-sarcasm.csv’\n","\n","train-balanced-sarc 100%[===================>] 243.44M  93.6MB/s    in 2.6s    \n","\n","2020-11-09 07:41:08 (93.6 MB/s) - ‘/tmp/train-balanced-sarcasm.csv’ saved [255268960/255268960]\n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>comment</th>\n","      <th>author</th>\n","      <th>subreddit</th>\n","      <th>score</th>\n","      <th>ups</th>\n","      <th>downs</th>\n","      <th>date</th>\n","      <th>created_utc</th>\n","      <th>parent_comment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>NC and NH.</td>\n","      <td>Trumpbart</td>\n","      <td>politics</td>\n","      <td>2</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>2016-10</td>\n","      <td>2016-10-16 23:55:23</td>\n","      <td>Yeah, I get that argument. At this point, I'd ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>You do know west teams play against west teams...</td>\n","      <td>Shbshb906</td>\n","      <td>nba</td>\n","      <td>-4</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>2016-11</td>\n","      <td>2016-11-01 00:24:10</td>\n","      <td>The blazers and Mavericks (The wests 5 and 6 s...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>They were underdogs earlier today, but since G...</td>\n","      <td>Creepeth</td>\n","      <td>nfl</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>2016-09</td>\n","      <td>2016-09-22 21:45:37</td>\n","      <td>They're favored to win.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>This meme isn't funny none of the \"new york ni...</td>\n","      <td>icebrotha</td>\n","      <td>BlackPeopleTwitter</td>\n","      <td>-8</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>2016-10</td>\n","      <td>2016-10-18 21:03:47</td>\n","      <td>deadass don't kill my buzz</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>I could use one of those tools.</td>\n","      <td>cush2push</td>\n","      <td>MaddenUltimateTeam</td>\n","      <td>6</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>2016-12</td>\n","      <td>2016-12-30 17:00:13</td>\n","      <td>Yep can confirm I saw the tool they use for th...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1010821</th>\n","      <td>1</td>\n","      <td>I'm sure that Iran and N. Korea have the techn...</td>\n","      <td>TwarkMain</td>\n","      <td>reddit.com</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2009-04</td>\n","      <td>2009-04-25 00:47:52</td>\n","      <td>No one is calling this an engineered pathogen,...</td>\n","    </tr>\n","    <tr>\n","      <th>1010822</th>\n","      <td>1</td>\n","      <td>whatever you do, don't vote green!</td>\n","      <td>BCHarvey</td>\n","      <td>climate</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2009-05</td>\n","      <td>2009-05-14 22:27:40</td>\n","      <td>In a move typical of their recent do-nothing a...</td>\n","    </tr>\n","    <tr>\n","      <th>1010823</th>\n","      <td>1</td>\n","      <td>Perhaps this is an atheist conspiracy to make ...</td>\n","      <td>rebelcommander</td>\n","      <td>atheism</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2009-01</td>\n","      <td>2009-01-11 00:22:57</td>\n","      <td>Screw the Disabled--I've got to get to Church ...</td>\n","    </tr>\n","    <tr>\n","      <th>1010824</th>\n","      <td>1</td>\n","      <td>The Slavs got their own country - it is called...</td>\n","      <td>catsi</td>\n","      <td>worldnews</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2009-01</td>\n","      <td>2009-01-23 21:12:49</td>\n","      <td>I've always been unsettled by that. I hear a l...</td>\n","    </tr>\n","    <tr>\n","      <th>1010825</th>\n","      <td>1</td>\n","      <td>values, as in capitalism .. there is good mone...</td>\n","      <td>frogking</td>\n","      <td>politics</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2009-01</td>\n","      <td>2009-01-24 06:20:14</td>\n","      <td>Why do the people who make our laws seem unabl...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1010826 rows × 10 columns</p>\n","</div>"],"text/plain":["         label  ...                                     parent_comment\n","0            0  ...  Yeah, I get that argument. At this point, I'd ...\n","1            0  ...  The blazers and Mavericks (The wests 5 and 6 s...\n","2            0  ...                            They're favored to win.\n","3            0  ...                         deadass don't kill my buzz\n","4            0  ...  Yep can confirm I saw the tool they use for th...\n","...        ...  ...                                                ...\n","1010821      1  ...  No one is calling this an engineered pathogen,...\n","1010822      1  ...  In a move typical of their recent do-nothing a...\n","1010823      1  ...  Screw the Disabled--I've got to get to Church ...\n","1010824      1  ...  I've always been unsettled by that. I hear a l...\n","1010825      1  ...  Why do the people who make our laws seem unabl...\n","\n","[1010826 rows x 10 columns]"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"uLWu8DG3tfjz"},"source":["## 3.2 Predict on sample dataset\n","NLU expects a text column, thus we must create it from the column that contains our text data"]},{"cell_type":"code","metadata":{"id":"3V5l-B6nl43U","executionInfo":{"status":"ok","timestamp":1604907690243,"user_tz":-60,"elapsed":152462,"user":{"displayName":"Christian Kasim Loan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqAD-ircKP-s5Eh6JSdkDggDczfqQbJGU_IRb4Hw=s64","userId":"14469489166467359317"}},"outputId":"36136418-2a70-4184-83ba-59b40dd1d9ef","colab":{"base_uri":"https://localhost:8080/","height":380}},"source":["dependency_pipe  = nlu.load('dep.untyped')\n","df['text'] = df['comment']\n","dependency_predictions = dependency_pipe.predict(df['text'].iloc[0:1])\n","dependency_predictions"],"execution_count":4,"outputs":[{"output_type":"stream","text":["dependency_typed_conllu download started this may take some time.\n","Approximate size to download 257.4 KB\n","[OK!]\n","dependency_conllu download started this may take some time.\n","Approximate size to download 16.6 MB\n","[OK!]\n","pos_anc download started this may take some time.\n","Approximate size to download 4.3 MB\n","[OK!]\n","INFO: NLU will assume text as label column since default text column could not be find\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>dependency</th>\n","      <th>token</th>\n","      <th>labled_dependency</th>\n","      <th>pos</th>\n","    </tr>\n","    <tr>\n","      <th>origin_index</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ROOT</td>\n","      <td>NC</td>\n","      <td>root</td>\n","      <td>NNP</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>NH</td>\n","      <td>and</td>\n","      <td>cc</td>\n","      <td>CC</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>NC</td>\n","      <td>NH</td>\n","      <td>flat</td>\n","      <td>NNP</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>NC</td>\n","      <td>.</td>\n","      <td>punct</td>\n","      <td>.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             dependency token labled_dependency  pos\n","origin_index                                        \n","0                  ROOT    NC              root  NNP\n","0                    NH   and                cc   CC\n","0                    NC    NH              flat  NNP\n","0                    NC     .             punct    ."]},"metadata":{"tags":[]},"execution_count":4}]}]}