{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"aspect_based_ner_sentiment_restaurants.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"9ayP-N_Cqr9K"},"source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n","\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/nlu/blob/tutorial_docs/examples/colab/component_examples/named_entity_recognition_NER/aspect_based_ner_sentiment_restaurants.ipynb)\n","\n","\n","\n","\n","Automatically detect positive, negative and neutral aspects about restaurants from user reviews. Instead of labelling the entire review as negative or positive, this model helps identify which exact phrases relate to sentiment identified in the review."]},{"cell_type":"code","metadata":{"id":"NqnAGVadANyZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619906502725,"user_tz":-120,"elapsed":104244,"user":{"displayName":"Christian Kasim Loan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqAD-ircKP-s5Eh6JSdkDggDczfqQbJGU_IRb4Hw=s64","userId":"14469489166467359317"}},"outputId":"ec001e53-1299-46cf-de30-c55132bed144"},"source":["!wget https://setup.johnsnowlabs.com/nlu/colab.sh -O - | bash\n","  \n","\n","import nlu"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2021-05-01 21:59:58--  https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/scripts/colab_setup.sh\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1671 (1.6K) [text/plain]\n","Saving to: ‘STDOUT’\n","\n","\r-                     0%[                    ]       0  --.-KB/s               Installing  NLU 3.0.0 with  PySpark 3.0.2 and Spark NLP 3.0.1 for Google Colab ...\n","\r-                   100%[===================>]   1.63K  --.-KB/s    in 0.001s  \n","\n","2021-05-01 21:59:58 (1.36 MB/s) - written to stdout [1671/1671]\n","\n","\u001b[K     |████████████████████████████████| 204.8MB 77kB/s \n","\u001b[K     |████████████████████████████████| 153kB 40.4MB/s \n","\u001b[K     |████████████████████████████████| 204kB 23.3MB/s \n","\u001b[K     |████████████████████████████████| 204kB 49.3MB/s \n","\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":357},"id":"c-9dIJVco9Xf","executionInfo":{"status":"ok","timestamp":1619906610022,"user_tz":-120,"elapsed":67625,"user":{"displayName":"Christian Kasim Loan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqAD-ircKP-s5Eh6JSdkDggDczfqQbJGU_IRb4Hw=s64","userId":"14469489166467359317"}},"outputId":"1aa478f7-78ce-4a86-b585-4a3ecfa91037"},"source":["import nlu\n","pipe = nlu.load('en.ner.aspect_sentiment')\n","data = 'We loved our Thai-style main which amazing with lots of flavours very impressive for vegetarian. But the service was below average and the chips were too terrible to finish.'\n","df = pipe.predict([data], output_level='chunk')\n","df"],"execution_count":null,"outputs":[{"output_type":"stream","text":["ner_aspect_based_sentiment download started this may take some time.\n","Approximate size to download 21.3 MB\n","[OK!]\n","glove_6B_300 download started this may take some time.\n","Approximate size to download 426.2 MB\n","[OK!]\n","sentence_detector_dl download started this may take some time.\n","Approximate size to download 354.6 KB\n","[OK!]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>document</th>\n","      <th>word_embedding_glove_6B_300</th>\n","      <th>entities</th>\n","      <th>entities_class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>We loved our Thai-style main which amazing wit...</td>\n","      <td>[[-0.05083499848842621, 0.2482600063085556, -0...</td>\n","      <td>Thai-style main</td>\n","      <td>POS</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>We loved our Thai-style main which amazing wit...</td>\n","      <td>[[-0.05083499848842621, 0.2482600063085556, -0...</td>\n","      <td>flavours</td>\n","      <td>POS</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>We loved our Thai-style main which amazing wit...</td>\n","      <td>[[-0.05083499848842621, 0.2482600063085556, -0...</td>\n","      <td>vegetarian</td>\n","      <td>POS</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>We loved our Thai-style main which amazing wit...</td>\n","      <td>[[-0.05083499848842621, 0.2482600063085556, -0...</td>\n","      <td>service</td>\n","      <td>NEG</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>We loved our Thai-style main which amazing wit...</td>\n","      <td>[[-0.05083499848842621, 0.2482600063085556, -0...</td>\n","      <td>chips</td>\n","      <td>NEG</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            document  ... entities_class\n","0  We loved our Thai-style main which amazing wit...  ...            POS\n","0  We loved our Thai-style main which amazing wit...  ...            POS\n","0  We loved our Thai-style main which amazing wit...  ...            POS\n","0  We loved our Thai-style main which amazing wit...  ...            NEG\n","0  We loved our Thai-style main which amazing wit...  ...            NEG\n","\n","[5 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":77},"id":"WFtrCQSnp_Ie","executionInfo":{"status":"ok","timestamp":1619906612521,"user_tz":-120,"elapsed":69663,"user":{"displayName":"Christian Kasim Loan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqAD-ircKP-s5Eh6JSdkDggDczfqQbJGU_IRb4Hw=s64","userId":"14469489166467359317"}},"outputId":"b596d2bf-ee9f-4a6e-b045-cfa60c5ba9d0"},"source":["df = pipe.predict([data], output_level='document')\n","df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>document</th>\n","      <th>word_embedding_glove_6B_300</th>\n","      <th>entities</th>\n","      <th>entities_class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>We loved our Thai-style main which amazing wit...</td>\n","      <td>[[-0.05083499848842621, 0.2482600063085556, -0...</td>\n","      <td>[Thai-style main, flavours, vegetarian, servic...</td>\n","      <td>[POS, POS, POS, NEG, NEG]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            document  ...             entities_class\n","0  We loved our Thai-style main which amazing wit...  ...  [POS, POS, POS, NEG, NEG]\n","\n","[1 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":107},"id":"GCFVSTRKqIgi","executionInfo":{"status":"ok","timestamp":1619906614943,"user_tz":-120,"elapsed":72051,"user":{"displayName":"Christian Kasim Loan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqAD-ircKP-s5Eh6JSdkDggDczfqQbJGU_IRb4Hw=s64","userId":"14469489166467359317"}},"outputId":"1e62f6da-74a7-4ef0-bb64-14b4ad4b7d1e"},"source":["data = 'We loved our Thai-style main which amazing with lots of flavours very impressive for vegetarian. But the service was below average and the chips were too terrible to finish.'\n","df = pipe.predict([data], output_level='sentence')\n","df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>word_embedding_glove_6B_300</th>\n","      <th>entities</th>\n","      <th>entities_class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>We loved our Thai-style main which amazing wit...</td>\n","      <td>[[-0.05083499848842621, 0.2482600063085556, -0...</td>\n","      <td>[Thai-style main, flavours, vegetarian, servic...</td>\n","      <td>[POS, POS, POS, NEG, NEG]</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>But the service was below average and the chip...</td>\n","      <td>[[-0.05083499848842621, 0.2482600063085556, -0...</td>\n","      <td>[Thai-style main, flavours, vegetarian, servic...</td>\n","      <td>[POS, POS, POS, NEG, NEG]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            sentence  ...             entities_class\n","0  We loved our Thai-style main which amazing wit...  ...  [POS, POS, POS, NEG, NEG]\n","0  But the service was below average and the chip...  ...  [POS, POS, POS, NEG, NEG]\n","\n","[2 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"Yao4hlfyqQNg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619906614944,"user_tz":-120,"elapsed":71982,"user":{"displayName":"Christian Kasim Loan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqAD-ircKP-s5Eh6JSdkDggDczfqQbJGU_IRb4Hw=s64","userId":"14469489166467359317"}},"outputId":"a3b265dc-677f-4ecd-954b-8ada55667df4"},"source":["nlu.print_all_model_kinds_for_action('pos')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["For language <nl> NLU provides the following Models : \n","nlu.load('nl.pos') returns Spark NLP model pos_ud_alpino\n","nlu.load('nl.pos.ud_alpino') returns Spark NLP model pos_ud_alpino\n","For language <en> NLU provides the following Models : \n","nlu.load('en.pos') returns Spark NLP model pos_anc\n","nlu.load('en.pos.anc') returns Spark NLP model pos_anc\n","nlu.load('en.pos.ud_ewt') returns Spark NLP model pos_ud_ewt\n","For language <fr> NLU provides the following Models : \n","nlu.load('fr.pos') returns Spark NLP model pos_ud_gsd\n","nlu.load('fr.pos.ud_gsd') returns Spark NLP model pos_ud_gsd\n","For language <de> NLU provides the following Models : \n","nlu.load('de.pos.ud_hdt') returns Spark NLP model pos_ud_hdt\n","nlu.load('de.pos') returns Spark NLP model pos_ud_hdt\n","For language <it> NLU provides the following Models : \n","nlu.load('it.pos') returns Spark NLP model pos_ud_isdt\n","nlu.load('it.pos.ud_isdt') returns Spark NLP model pos_ud_isdt\n","For language <nb> NLU provides the following Models : \n","nlu.load('nb.pos.ud_bokmaal') returns Spark NLP model pos_ud_bokmaal\n","For language <nn> NLU provides the following Models : \n","nlu.load('nn.pos') returns Spark NLP model pos_ud_nynorsk\n","nlu.load('nn.pos.ud_nynorsk') returns Spark NLP model pos_ud_nynorsk\n","For language <pl> NLU provides the following Models : \n","nlu.load('pl.pos') returns Spark NLP model pos_ud_lfg\n","nlu.load('pl.pos.ud_lfg') returns Spark NLP model pos_ud_lfg\n","For language <pt> NLU provides the following Models : \n","nlu.load('pt.pos.ud_bosque') returns Spark NLP model pos_ud_bosque\n","nlu.load('pt.pos') returns Spark NLP model pos_ud_bosque\n","For language <ru> NLU provides the following Models : \n","nlu.load('ru.pos.ud_gsd') returns Spark NLP model pos_ud_gsd\n","nlu.load('ru.pos') returns Spark NLP model pos_ud_gsd\n","For language <es> NLU provides the following Models : \n","nlu.load('es.pos') returns Spark NLP model pos_ud_gsd\n","nlu.load('es.pos.ud_gsd') returns Spark NLP model pos_ud_gsd\n","For language <ar> NLU provides the following Models : \n","nlu.load('ar.pos') returns Spark NLP model pos_ud_padt\n","For language <hy> NLU provides the following Models : \n","nlu.load('hy.pos') returns Spark NLP model pos_ud_armtdp\n","For language <eu> NLU provides the following Models : \n","nlu.load('eu.pos') returns Spark NLP model pos_ud_bdt\n","For language <bn> NLU provides the following Models : \n","nlu.load('bn.pos') returns Spark NLP model pos_msri\n","For language <br> NLU provides the following Models : \n","nlu.load('br.pos') returns Spark NLP model pos_ud_keb\n","For language <bg> NLU provides the following Models : \n","nlu.load('bg.pos') returns Spark NLP model pos_ud_btb\n","nlu.load('bg.pos.ud_btb') returns Spark NLP model pos_ud_btb\n","For language <ca> NLU provides the following Models : \n","nlu.load('ca.pos') returns Spark NLP model pos_ud_ancora\n","For language <cs> NLU provides the following Models : \n","nlu.load('cs.pos') returns Spark NLP model pos_ud_pdt\n","nlu.load('cs.pos.ud_pdt') returns Spark NLP model pos_ud_pdt\n","For language <fi> NLU provides the following Models : \n","nlu.load('fi.pos.ud_tdt') returns Spark NLP model pos_ud_tdt\n","nlu.load('fi.pos') returns Spark NLP model pos_ud_tdt\n","For language <gl> NLU provides the following Models : \n","nlu.load('gl.pos') returns Spark NLP model pos_ud_treegal\n","For language <el> NLU provides the following Models : \n","nlu.load('el.pos') returns Spark NLP model pos_ud_gdt\n","nlu.load('el.pos.ud_gdt') returns Spark NLP model pos_ud_gdt\n","For language <he> NLU provides the following Models : \n","nlu.load('he.pos') returns Spark NLP model pos_ud_htb\n","nlu.load('he.pos.ud_htb') returns Spark NLP model pos_ud_htb\n","For language <hi> NLU provides the following Models : \n","nlu.load('hi.pos') returns Spark NLP model pos_ud_hdtb\n","For language <hu> NLU provides the following Models : \n","nlu.load('hu.pos') returns Spark NLP model pos_ud_szeged\n","nlu.load('hu.pos.ud_szeged') returns Spark NLP model pos_ud_szeged\n","For language <id> NLU provides the following Models : \n","nlu.load('id.pos') returns Spark NLP model pos_ud_gsd\n","For language <ga> NLU provides the following Models : \n","nlu.load('ga.pos') returns Spark NLP model pos_ud_idt\n","For language <da> NLU provides the following Models : \n","nlu.load('da.pos') returns Spark NLP model pos_ud_ddt\n","For language <ja> NLU provides the following Models : \n","nlu.load('ja.pos') returns Spark NLP model pos_ud_gsd\n","nlu.load('ja.pos.ud_gsd') returns Spark NLP model pos_ud_gsd\n","For language <la> NLU provides the following Models : \n","nlu.load('la.pos') returns Spark NLP model pos_ud_llct\n","For language <lv> NLU provides the following Models : \n","nlu.load('lv.pos') returns Spark NLP model pos_ud_lvtb\n","For language <mr> NLU provides the following Models : \n","nlu.load('mr.pos') returns Spark NLP model pos_ud_ufal\n","For language <fa> NLU provides the following Models : \n","nlu.load('fa.pos') returns Spark NLP model pos_ud_perdt\n","For language <ro> NLU provides the following Models : \n","nlu.load('ro.pos') returns Spark NLP model pos_ud_rrt\n","nlu.load('ro.pos.ud_rrt') returns Spark NLP model pos_ud_rrt\n","For language <sk> NLU provides the following Models : \n","nlu.load('sk.pos') returns Spark NLP model pos_ud_snk\n","nlu.load('sk.pos.ud_snk') returns Spark NLP model pos_ud_snk\n","For language <sl> NLU provides the following Models : \n","nlu.load('sl.pos') returns Spark NLP model pos_ud_ssj\n","For language <sv> NLU provides the following Models : \n","nlu.load('sv.pos') returns Spark NLP model pos_ud_tal\n","nlu.load('sv.pos.ud_tal') returns Spark NLP model pos_ud_tal\n","For language <th> NLU provides the following Models : \n","nlu.load('th.pos') returns Spark NLP model pos_lst20\n","For language <tr> NLU provides the following Models : \n","nlu.load('tr.pos') returns Spark NLP model pos_ud_imst\n","nlu.load('tr.pos.ud_imst') returns Spark NLP model pos_ud_imst\n","For language <uk> NLU provides the following Models : \n","nlu.load('uk.pos') returns Spark NLP model pos_ud_iu\n","nlu.load('uk.pos.ud_iu') returns Spark NLP model pos_ud_iu\n","For language <yo> NLU provides the following Models : \n","nlu.load('yo.pos') returns Spark NLP model pos_ud_ytb\n","For language <zh> NLU provides the following Models : \n","nlu.load('zh.pos') returns Spark NLP model pos_ud_gsd\n","nlu.load('zh.pos.ud_gsd') returns Spark NLP model pos_ud_gsd\n","nlu.load('zh.pos.ctb9') returns Spark NLP model pos_ctb9\n","nlu.load('zh.pos.ud_gsd_trad') returns Spark NLP model pos_ud_gsd_trad\n","For language <et> NLU provides the following Models : \n","nlu.load('et.pos') returns Spark NLP model pos_ud_edt\n","For language <ur> NLU provides the following Models : \n","nlu.load('ur.pos') returns Spark NLP model pos_ud_udtb\n","nlu.load('ur.pos.ud_udtb') returns Spark NLP model pos_ud_udtb\n","For language <ko> NLU provides the following Models : \n","nlu.load('ko.pos') returns Spark NLP model pos_ud_kaist\n","nlu.load('ko.pos.ud_kaist') returns Spark NLP model pos_ud_kaist\n","For language <bh> NLU provides the following Models : \n","nlu.load('bh.pos') returns Spark NLP model pos_ud_bhtb\n","For language <am> NLU provides the following Models : \n","nlu.load('am.pos') returns Spark NLP model pos_ud_att\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FvFwAWm29D0x"},"source":[""],"execution_count":null,"outputs":[]}]}