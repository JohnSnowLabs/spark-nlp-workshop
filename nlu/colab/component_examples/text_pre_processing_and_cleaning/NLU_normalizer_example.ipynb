{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLU_normalizer_example.ipynb","provenance":[{"file_id":"1pgqoRJ6yGWbTLWdLnRvwG5DLSU3rxuMq","timestamp":1599401652794},{"file_id":"1JrlfuV2jNGTdOXvaWIoHTSf6BscDMkN7","timestamp":1599401257319},{"file_id":"1svpqtC3cY6JnRGeJngIPl2raqxdowpyi","timestamp":1599400881246},{"file_id":"1tW833T3HS8F5Lvn6LgeDd5LW5226syKN","timestamp":1599398724652},{"file_id":"1CYzHfQyFCdvIOVO2Z5aggVI9c0hDEOrw","timestamp":1599354735581}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"rBXrqlGEYA8G"},"source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n","\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/nlu/blob/master/examples/colab/component_examples/text_pre_processing_and_cleaning/NLU_normalizer_example.ipynb)\n","\n","# Normalziing with NLU \n","\n","The Normalizer cleans text data from dirty characters, lowercases it by default and removes punctuation.       \n","\n","### Removes all dirty characters and from text following a regex pattern.    \n","- Dirty characters are things like !@#$%^&*()?>< etc..\n","- Useful for reducing dimension/variance of your data since fewer symbols will occur\n","- Useful for cleaning tweets \n","- Matches slangs\n","- Language independent \n","- You can use a regex pattern to specify which tokens will *not* be removed.  \n","\n","I.e the pattern [a-z] matches all characters from a,b,c... to x,y,z. It will throw\n","```\n","pipe['normalizer'].setCleanupPatterns('[a-z]') \n","```\n","\n","\n","# 1. Install Java and NLU"]},{"cell_type":"code","metadata":{"id":"M2-GiYL6xurJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619911221247,"user_tz":-120,"elapsed":111849,"user":{"displayName":"Christian Kasim Loan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqAD-ircKP-s5Eh6JSdkDggDczfqQbJGU_IRb4Hw=s64","userId":"14469489166467359317"}},"outputId":"e5d5ec1b-dbf7-4196-a549-f2a34b1e49a6"},"source":["!wget https://setup.johnsnowlabs.com/nlu/colab.sh -O - | bash\n","  \n","\n","import nlu"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2021-05-01 23:18:29--  https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/scripts/colab_setup.sh\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1671 (1.6K) [text/plain]\n","Saving to: ‘STDOUT’\n","\n","\r-                     0%[                    ]       0  --.-KB/s               Installing  NLU 3.0.0 with  PySpark 3.0.2 and Spark NLP 3.0.1 for Google Colab ...\n","\r-                   100%[===================>]   1.63K  --.-KB/s    in 0.002s  \n","\n","2021-05-01 23:18:29 (1000 KB/s) - written to stdout [1671/1671]\n","\n","\u001b[K     |████████████████████████████████| 204.8MB 69kB/s \n","\u001b[K     |████████████████████████████████| 153kB 42.2MB/s \n","\u001b[K     |████████████████████████████████| 204kB 24.1MB/s \n","\u001b[K     |████████████████████████████████| 204kB 54.2MB/s \n","\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"N_CL8HZ8Ydry"},"source":["## 2. Load Model and normalize sample string"]},{"cell_type":"code","metadata":{"id":"pmpZSNvGlyZQ","colab":{"base_uri":"https://localhost:8080/","height":534},"executionInfo":{"status":"ok","timestamp":1619911262521,"user_tz":-120,"elapsed":153103,"user":{"displayName":"Christian Kasim Loan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqAD-ircKP-s5Eh6JSdkDggDczfqQbJGU_IRb4Hw=s64","userId":"14469489166467359317"}},"outputId":"9cb74b42-51cd-4fa2-dc89-681dc14987c6"},"source":["import nlu \n","\n","\n","nlu.load('norm').predict('@CKL_IT says: that #normalizers are pretty useful to clean #structured_strings in #NLU like tweets')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["sentence_detector_dl download started this may take some time.\n","Approximate size to download 354.6 KB\n","[OK!]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>document</th>\n","      <th>sentence</th>\n","      <th>token</th>\n","      <th>norm</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>@CKL_IT says: that #normalizers are pretty use...</td>\n","      <td>[@CKL_IT says: that #normalizers are pretty us...</td>\n","      <td>[@CKL_IT, says, :, that, #normalizers, are, pr...</td>\n","      <td>CKLIT</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>@CKL_IT says: that #normalizers are pretty use...</td>\n","      <td>[@CKL_IT says: that #normalizers are pretty us...</td>\n","      <td>[@CKL_IT, says, :, that, #normalizers, are, pr...</td>\n","      <td>says</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>@CKL_IT says: that #normalizers are pretty use...</td>\n","      <td>[@CKL_IT says: that #normalizers are pretty us...</td>\n","      <td>[@CKL_IT, says, :, that, #normalizers, are, pr...</td>\n","      <td>that</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>@CKL_IT says: that #normalizers are pretty use...</td>\n","      <td>[@CKL_IT says: that #normalizers are pretty us...</td>\n","      <td>[@CKL_IT, says, :, that, #normalizers, are, pr...</td>\n","      <td>normalizers</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>@CKL_IT says: that #normalizers are pretty use...</td>\n","      <td>[@CKL_IT says: that #normalizers are pretty us...</td>\n","      <td>[@CKL_IT, says, :, that, #normalizers, are, pr...</td>\n","      <td>are</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>@CKL_IT says: that #normalizers are pretty use...</td>\n","      <td>[@CKL_IT says: that #normalizers are pretty us...</td>\n","      <td>[@CKL_IT, says, :, that, #normalizers, are, pr...</td>\n","      <td>pretty</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>@CKL_IT says: that #normalizers are pretty use...</td>\n","      <td>[@CKL_IT says: that #normalizers are pretty us...</td>\n","      <td>[@CKL_IT, says, :, that, #normalizers, are, pr...</td>\n","      <td>useful</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>@CKL_IT says: that #normalizers are pretty use...</td>\n","      <td>[@CKL_IT says: that #normalizers are pretty us...</td>\n","      <td>[@CKL_IT, says, :, that, #normalizers, are, pr...</td>\n","      <td>to</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>@CKL_IT says: that #normalizers are pretty use...</td>\n","      <td>[@CKL_IT says: that #normalizers are pretty us...</td>\n","      <td>[@CKL_IT, says, :, that, #normalizers, are, pr...</td>\n","      <td>clean</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>@CKL_IT says: that #normalizers are pretty use...</td>\n","      <td>[@CKL_IT says: that #normalizers are pretty us...</td>\n","      <td>[@CKL_IT, says, :, that, #normalizers, are, pr...</td>\n","      <td>structuredstrings</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>@CKL_IT says: that #normalizers are pretty use...</td>\n","      <td>[@CKL_IT says: that #normalizers are pretty us...</td>\n","      <td>[@CKL_IT, says, :, that, #normalizers, are, pr...</td>\n","      <td>in</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>@CKL_IT says: that #normalizers are pretty use...</td>\n","      <td>[@CKL_IT says: that #normalizers are pretty us...</td>\n","      <td>[@CKL_IT, says, :, that, #normalizers, are, pr...</td>\n","      <td>NLU</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>@CKL_IT says: that #normalizers are pretty use...</td>\n","      <td>[@CKL_IT says: that #normalizers are pretty us...</td>\n","      <td>[@CKL_IT, says, :, that, #normalizers, are, pr...</td>\n","      <td>like</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>@CKL_IT says: that #normalizers are pretty use...</td>\n","      <td>[@CKL_IT says: that #normalizers are pretty us...</td>\n","      <td>[@CKL_IT, says, :, that, #normalizers, are, pr...</td>\n","      <td>tweets</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            document  ...               norm\n","0  @CKL_IT says: that #normalizers are pretty use...  ...              CKLIT\n","0  @CKL_IT says: that #normalizers are pretty use...  ...               says\n","0  @CKL_IT says: that #normalizers are pretty use...  ...               that\n","0  @CKL_IT says: that #normalizers are pretty use...  ...        normalizers\n","0  @CKL_IT says: that #normalizers are pretty use...  ...                are\n","0  @CKL_IT says: that #normalizers are pretty use...  ...             pretty\n","0  @CKL_IT says: that #normalizers are pretty use...  ...             useful\n","0  @CKL_IT says: that #normalizers are pretty use...  ...                 to\n","0  @CKL_IT says: that #normalizers are pretty use...  ...              clean\n","0  @CKL_IT says: that #normalizers are pretty use...  ...  structuredstrings\n","0  @CKL_IT says: that #normalizers are pretty use...  ...                 in\n","0  @CKL_IT says: that #normalizers are pretty use...  ...                NLU\n","0  @CKL_IT says: that #normalizers are pretty use...  ...               like\n","0  @CKL_IT says: that #normalizers are pretty use...  ...             tweets\n","\n","[14 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"fvWCtpHCwOYz"},"source":["## 2. Configure the normalizer with custom parameters\n","Use the pipe.print_info() to see all configurable parameters and infos about them for every NLU component in the pipeline pipeline.     \n","Even tough only 'norm' is loaded, many NLU component dependencies are automatically loaded into the pipeline and also configurable. \n","\n","\n","By default the normalizer will set all tokens to lower case.     \n","Lets change that"]},{"cell_type":"code","metadata":{"id":"j2ZZZvr1uGpx","colab":{"base_uri":"https://localhost:8080/","height":193},"executionInfo":{"status":"ok","timestamp":1619911266966,"user_tz":-120,"elapsed":157539,"user":{"displayName":"Christian Kasim Loan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqAD-ircKP-s5Eh6JSdkDggDczfqQbJGU_IRb4Hw=s64","userId":"14469489166467359317"}},"outputId":"58ffe095-0db8-4638-d75d-64fc2afb1990"},"source":["pipe = nlu.load('norm')\n","pipe.predict('LOWERCASE BY DEFAULT')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["sentence_detector_dl download started this may take some time.\n","Approximate size to download 354.6 KB\n","[OK!]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>document</th>\n","      <th>sentence</th>\n","      <th>token</th>\n","      <th>norm</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>LOWERCASE BY DEFAULT</td>\n","      <td>[LOWERCASE BY DEFAULT]</td>\n","      <td>[LOWERCASE, BY, DEFAULT]</td>\n","      <td>LOWERCASE</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>LOWERCASE BY DEFAULT</td>\n","      <td>[LOWERCASE BY DEFAULT]</td>\n","      <td>[LOWERCASE, BY, DEFAULT]</td>\n","      <td>BY</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>LOWERCASE BY DEFAULT</td>\n","      <td>[LOWERCASE BY DEFAULT]</td>\n","      <td>[LOWERCASE, BY, DEFAULT]</td>\n","      <td>DEFAULT</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["               document  ...       norm\n","0  LOWERCASE BY DEFAULT  ...  LOWERCASE\n","0  LOWERCASE BY DEFAULT  ...         BY\n","0  LOWERCASE BY DEFAULT  ...    DEFAULT\n","\n","[3 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"v4qbFCJ1Ao6I"},"source":["### 2.1 Print all parameters for all NLU components in the pipeline \n"]},{"cell_type":"code","metadata":{"id":"TN59JZIBtKC8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619911266970,"user_tz":-120,"elapsed":157538,"user":{"displayName":"Christian Kasim Loan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqAD-ircKP-s5Eh6JSdkDggDczfqQbJGU_IRb4Hw=s64","userId":"14469489166467359317"}},"outputId":"a05d6176-2d09-46fc-9394-c486b47e2420"},"source":["pipe.print_info()\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The following parameters are configurable for this NLU pipeline (You can copy paste the examples) :\n",">>> pipe['normalizer'] has settable params:\n","pipe['normalizer'].setCleanupPatterns(['[^\\\\pL+]'])  | Info: normalization regex patterns which match will be removed from token | Currently set to : ['[^\\\\pL+]']\n","pipe['normalizer'].setLowercase(False)               | Info: whether to convert strings to lowercase | Currently set to : False\n","pipe['normalizer'].setSlangMatchCase(False)          | Info: whether or not to be case sensitive to match slangs. Defaults to false. | Currently set to : False\n","pipe['normalizer'].setMinLength(0)                   | Info: Set the minimum allowed legth for each token | Currently set to : 0\n",">>> pipe['default_tokenizer'] has settable params:\n","pipe['default_tokenizer'].setTargetPattern('\\S+')    | Info: pattern to grab from text as token candidates. Defaults \\S+ | Currently set to : \\S+\n","pipe['default_tokenizer'].setContextChars(['.', ',', ';', ':', '!', '?', '*', '-', '(', ')', '\"', \"'\"])  | Info: character list used to separate from token boundaries | Currently set to : ['.', ',', ';', ':', '!', '?', '*', '-', '(', ')', '\"', \"'\"]\n","pipe['default_tokenizer'].setCaseSensitiveExceptions(True)  | Info: Whether to care for case sensitiveness in exceptions | Currently set to : True\n","pipe['default_tokenizer'].setMinLength(0)            | Info: Set the minimum allowed legth for each token | Currently set to : 0\n","pipe['default_tokenizer'].setMaxLength(99999)        | Info: Set the maximum allowed legth for each token | Currently set to : 99999\n",">>> pipe['deep_sentence_detector@SentenceDetectorDLModel_c83c27f46b97'] has settable params:\n","pipe['deep_sentence_detector@SentenceDetectorDLModel_c83c27f46b97'].setExplodeSentences(False)  | Info: whether to explode each sentence into a different row, for better parallelization. Defaults to false. | Currently set to : False\n","pipe['deep_sentence_detector@SentenceDetectorDLModel_c83c27f46b97'].setStorageRef('SentenceDetectorDLModel_c83c27f46b97')  | Info: storage unique identifier | Currently set to : SentenceDetectorDLModel_c83c27f46b97\n","pipe['deep_sentence_detector@SentenceDetectorDLModel_c83c27f46b97'].setEncoder(com.johnsnowlabs.nlp.annotators.sentence_detector_dl.SentenceDetectorDLEncoder@34b63906)  | Info: Data encoder | Currently set to : com.johnsnowlabs.nlp.annotators.sentence_detector_dl.SentenceDetectorDLEncoder@34b63906\n","pipe['deep_sentence_detector@SentenceDetectorDLModel_c83c27f46b97'].setImpossiblePenultimates(['Bros', 'No', 'al', 'vs', 'etc', 'Fig', 'Dr', 'Prof', 'PhD', 'MD', 'Co', 'Corp', 'Inc', 'bros', 'VS', 'Vs', 'ETC', 'fig', 'dr', 'prof', 'PHD', 'phd', 'md', 'co', 'corp', 'inc', 'Jan', 'Feb', 'Mar', 'Apr', 'Jul', 'Aug', 'Sep', 'Sept', 'Oct', 'Nov', 'Dec', 'St', 'st', 'AM', 'PM', 'am', 'pm', 'e.g', 'f.e', 'i.e'])  | Info: Impossible penultimates | Currently set to : ['Bros', 'No', 'al', 'vs', 'etc', 'Fig', 'Dr', 'Prof', 'PhD', 'MD', 'Co', 'Corp', 'Inc', 'bros', 'VS', 'Vs', 'ETC', 'fig', 'dr', 'prof', 'PHD', 'phd', 'md', 'co', 'corp', 'inc', 'Jan', 'Feb', 'Mar', 'Apr', 'Jul', 'Aug', 'Sep', 'Sept', 'Oct', 'Nov', 'Dec', 'St', 'st', 'AM', 'PM', 'am', 'pm', 'e.g', 'f.e', 'i.e']\n","pipe['deep_sentence_detector@SentenceDetectorDLModel_c83c27f46b97'].setModelArchitecture('cnn')  | Info: Model architecture (CNN) | Currently set to : cnn\n",">>> pipe['document_assembler'] has settable params:\n","pipe['document_assembler'].setCleanupMode('shrink')  | Info: possible values: disabled, inplace, inplace_full, shrink, shrink_full, each, each_full, delete_full | Currently set to : shrink\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"C9z5pzjmAkFV"},"source":["### 2.2 Configure the Normalizer not to lowercase text "]},{"cell_type":"code","metadata":{"id":"L8QsX18utG_Q","colab":{"base_uri":"https://localhost:8080/","height":142},"executionInfo":{"status":"ok","timestamp":1619911267790,"user_tz":-120,"elapsed":158352,"user":{"displayName":"Christian Kasim Loan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqAD-ircKP-s5Eh6JSdkDggDczfqQbJGU_IRb4Hw=s64","userId":"14469489166467359317"}},"outputId":"5e36e37f-4372-423c-b327-646c868bd178"},"source":["pipe['normalizer'].setLowercase(True)      \n","pipe.predict('LOWERCASE BY DEFAULT')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>document</th>\n","      <th>sentence</th>\n","      <th>token</th>\n","      <th>norm</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>LOWERCASE BY DEFAULT</td>\n","      <td>[LOWERCASE BY DEFAULT]</td>\n","      <td>[LOWERCASE, BY, DEFAULT]</td>\n","      <td>LOWERCASE</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>LOWERCASE BY DEFAULT</td>\n","      <td>[LOWERCASE BY DEFAULT]</td>\n","      <td>[LOWERCASE, BY, DEFAULT]</td>\n","      <td>BY</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>LOWERCASE BY DEFAULT</td>\n","      <td>[LOWERCASE BY DEFAULT]</td>\n","      <td>[LOWERCASE, BY, DEFAULT]</td>\n","      <td>DEFAULT</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["               document  ...       norm\n","0  LOWERCASE BY DEFAULT  ...  LOWERCASE\n","0  LOWERCASE BY DEFAULT  ...         BY\n","0  LOWERCASE BY DEFAULT  ...    DEFAULT\n","\n","[3 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"VlQHcW_VAfn9"},"source":["### 2.3Configure normalizer to remove strings based on regex pattern.\n","Lets remove all occurences of the lowercase letters x to z with the pattern [x-z]. "]},{"cell_type":"code","metadata":{"id":"JVXrpP7IvCR1","colab":{"base_uri":"https://localhost:8080/","height":328},"executionInfo":{"status":"ok","timestamp":1619911268326,"user_tz":-120,"elapsed":158883,"user":{"displayName":"Christian Kasim Loan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqAD-ircKP-s5Eh6JSdkDggDczfqQbJGU_IRb4Hw=s64","userId":"14469489166467359317"}},"outputId":"58532d9b-afa8-4e97-dec9-f319f3f71ed5"},"source":["# Configure the Normalizer \n","pipe['normalizer'].setCleanupPatterns(['[x-z]']) \n","pipe.predict('From the x to the y to the z')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>document</th>\n","      <th>sentence</th>\n","      <th>token</th>\n","      <th>norm</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>From the x to the y to the z</td>\n","      <td>[From the x to the y to the z]</td>\n","      <td>[From, the, x, to, the, y, to, the, z]</td>\n","      <td>From</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>From the x to the y to the z</td>\n","      <td>[From the x to the y to the z]</td>\n","      <td>[From, the, x, to, the, y, to, the, z]</td>\n","      <td>the</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>From the x to the y to the z</td>\n","      <td>[From the x to the y to the z]</td>\n","      <td>[From, the, x, to, the, y, to, the, z]</td>\n","      <td>x</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>From the x to the y to the z</td>\n","      <td>[From the x to the y to the z]</td>\n","      <td>[From, the, x, to, the, y, to, the, z]</td>\n","      <td>to</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>From the x to the y to the z</td>\n","      <td>[From the x to the y to the z]</td>\n","      <td>[From, the, x, to, the, y, to, the, z]</td>\n","      <td>the</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>From the x to the y to the z</td>\n","      <td>[From the x to the y to the z]</td>\n","      <td>[From, the, x, to, the, y, to, the, z]</td>\n","      <td>y</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>From the x to the y to the z</td>\n","      <td>[From the x to the y to the z]</td>\n","      <td>[From, the, x, to, the, y, to, the, z]</td>\n","      <td>to</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>From the x to the y to the z</td>\n","      <td>[From the x to the y to the z]</td>\n","      <td>[From, the, x, to, the, y, to, the, z]</td>\n","      <td>the</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>From the x to the y to the z</td>\n","      <td>[From the x to the y to the z]</td>\n","      <td>[From, the, x, to, the, y, to, the, z]</td>\n","      <td>z</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                       document  ...  norm\n","0  From the x to the y to the z  ...  From\n","0  From the x to the y to the z  ...   the\n","0  From the x to the y to the z  ...     x\n","0  From the x to the y to the z  ...    to\n","0  From the x to the y to the z  ...   the\n","0  From the x to the y to the z  ...     y\n","0  From the x to the y to the z  ...    to\n","0  From the x to the y to the z  ...   the\n","0  From the x to the y to the z  ...     z\n","\n","[9 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"f8h4s-dmB1D7"},"source":["#### NOTE: The regex pattern is applied **BEFORE** lowercasing.    \n","This is why the X,Y,Z tokens are kept i nthe following example\n"]},{"cell_type":"code","metadata":{"id":"C7mfz7tLzUkc","colab":{"base_uri":"https://localhost:8080/","height":328},"executionInfo":{"status":"ok","timestamp":1619911269119,"user_tz":-120,"elapsed":159671,"user":{"displayName":"Christian Kasim Loan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqAD-ircKP-s5Eh6JSdkDggDczfqQbJGU_IRb4Hw=s64","userId":"14469489166467359317"}},"outputId":"c2051e02-bd2d-455b-e37a-1ab39689039b"},"source":["# Configure the Normalizer \n","pipe['normalizer'].setCleanupPatterns(['[x-z]']) \n","pipe.predict('From the X to the Y to the Z')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>document</th>\n","      <th>sentence</th>\n","      <th>token</th>\n","      <th>norm</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>From the X to the Y to the Z</td>\n","      <td>[From the X to the Y to the Z]</td>\n","      <td>[From, the, X, to, the, Y, to, the, Z]</td>\n","      <td>From</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>From the X to the Y to the Z</td>\n","      <td>[From the X to the Y to the Z]</td>\n","      <td>[From, the, X, to, the, Y, to, the, Z]</td>\n","      <td>the</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>From the X to the Y to the Z</td>\n","      <td>[From the X to the Y to the Z]</td>\n","      <td>[From, the, X, to, the, Y, to, the, Z]</td>\n","      <td>X</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>From the X to the Y to the Z</td>\n","      <td>[From the X to the Y to the Z]</td>\n","      <td>[From, the, X, to, the, Y, to, the, Z]</td>\n","      <td>to</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>From the X to the Y to the Z</td>\n","      <td>[From the X to the Y to the Z]</td>\n","      <td>[From, the, X, to, the, Y, to, the, Z]</td>\n","      <td>the</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>From the X to the Y to the Z</td>\n","      <td>[From the X to the Y to the Z]</td>\n","      <td>[From, the, X, to, the, Y, to, the, Z]</td>\n","      <td>Y</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>From the X to the Y to the Z</td>\n","      <td>[From the X to the Y to the Z]</td>\n","      <td>[From, the, X, to, the, Y, to, the, Z]</td>\n","      <td>to</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>From the X to the Y to the Z</td>\n","      <td>[From the X to the Y to the Z]</td>\n","      <td>[From, the, X, to, the, Y, to, the, Z]</td>\n","      <td>the</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>From the X to the Y to the Z</td>\n","      <td>[From the X to the Y to the Z]</td>\n","      <td>[From, the, X, to, the, Y, to, the, Z]</td>\n","      <td>Z</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                       document  ...  norm\n","0  From the X to the Y to the Z  ...  From\n","0  From the X to the Y to the Z  ...   the\n","0  From the X to the Y to the Z  ...     X\n","0  From the X to the Y to the Z  ...    to\n","0  From the X to the Y to the Z  ...   the\n","0  From the X to the Y to the Z  ...     Y\n","0  From the X to the Y to the Z  ...    to\n","0  From the X to the Y to the Z  ...   the\n","0  From the X to the Y to the Z  ...     Z\n","\n","[9 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"IRSEzc-RCceu"},"source":["# 3. Get one row per normalized token by setting outputlevel to token.    \n","This lets us compare what the original token was and what it was normalized to. "]},{"cell_type":"code","metadata":{"id":"9bujAZtOCfRW","colab":{"base_uri":"https://localhost:8080/","height":328},"executionInfo":{"status":"ok","timestamp":1619911269763,"user_tz":-120,"elapsed":160310,"user":{"displayName":"Christian Kasim Loan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqAD-ircKP-s5Eh6JSdkDggDczfqQbJGU_IRb4Hw=s64","userId":"14469489166467359317"}},"outputId":"fc0f4dcf-e52a-4e54-b645-da62711d98bb"},"source":["pipe.predict('From the X to the Y to the Z', output_level='token')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>token</th>\n","      <th>norm</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>From</td>\n","      <td>[From, the, X, to, the, Y, to, the, Z]</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>the</td>\n","      <td>[From, the, X, to, the, Y, to, the, Z]</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>X</td>\n","      <td>[From, the, X, to, the, Y, to, the, Z]</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>to</td>\n","      <td>[From, the, X, to, the, Y, to, the, Z]</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>the</td>\n","      <td>[From, the, X, to, the, Y, to, the, Z]</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Y</td>\n","      <td>[From, the, X, to, the, Y, to, the, Z]</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>to</td>\n","      <td>[From, the, X, to, the, Y, to, the, Z]</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>the</td>\n","      <td>[From, the, X, to, the, Y, to, the, Z]</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Z</td>\n","      <td>[From, the, X, to, the, Y, to, the, Z]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  token                                    norm\n","0  From  [From, the, X, to, the, Y, to, the, Z]\n","0   the  [From, the, X, to, the, Y, to, the, Z]\n","0     X  [From, the, X, to, the, Y, to, the, Z]\n","0    to  [From, the, X, to, the, Y, to, the, Z]\n","0   the  [From, the, X, to, the, Y, to, the, Z]\n","0     Y  [From, the, X, to, the, Y, to, the, Z]\n","0    to  [From, the, X, to, the, Y, to, the, Z]\n","0   the  [From, the, X, to, the, Y, to, the, Z]\n","0     Z  [From, the, X, to, the, Y, to, the, Z]"]},"metadata":{"tags":[]},"execution_count":8}]}]}