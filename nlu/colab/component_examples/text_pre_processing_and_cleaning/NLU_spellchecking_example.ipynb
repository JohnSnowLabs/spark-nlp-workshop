{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLU_spellchecking_example.ipynb","provenance":[{"file_id":"1pgqoRJ6yGWbTLWdLnRvwG5DLSU3rxuMq","timestamp":1599401652794},{"file_id":"1JrlfuV2jNGTdOXvaWIoHTSf6BscDMkN7","timestamp":1599401257319},{"file_id":"1svpqtC3cY6JnRGeJngIPl2raqxdowpyi","timestamp":1599400881246},{"file_id":"1tW833T3HS8F5Lvn6LgeDd5LW5226syKN","timestamp":1599398724652},{"file_id":"1CYzHfQyFCdvIOVO2Z5aggVI9c0hDEOrw","timestamp":1599354735581}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"rBXrqlGEYA8G"},"source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n","\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/nlu/blob/master/examples/colab/component_examples/text_pre_processing_and_cleaning/NLU_spellchecking_example.ipynb)\n","# Stemming with NLU \n","\n","Stemming returns the base form, the so called stem / root or base word of every token in the input data.    \n","\n","I. e. 'He was hungry' becomes 'He wa hungri'\n","\n","\n","Stemming works by applying a heuristic process that strips and mutates suffixes on  words.\n","\n","\n","# 1. Install Java and NLU"]},{"cell_type":"code","metadata":{"id":"M2-GiYL6xurJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619911238974,"user_tz":-120,"elapsed":127171,"user":{"displayName":"Christian Kasim Loan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqAD-ircKP-s5Eh6JSdkDggDczfqQbJGU_IRb4Hw=s64","userId":"14469489166467359317"}},"outputId":"2a0484b0-4b83-4e78-d269-93d1ffae4554"},"source":["!wget https://setup.johnsnowlabs.com/nlu/colab.sh -O - | bash\n","  \n","\n","import nlu"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2021-05-01 23:18:32--  https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/scripts/colab_setup.sh\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1671 (1.6K) [text/plain]\n","Saving to: ‘STDOUT’\n","\n","\r-                     0%[                    ]       0  --.-KB/s               \r-                   100%[===================>]   1.63K  --.-KB/s    in 0s      \n","\n","2021-05-01 23:18:32 (29.9 MB/s) - written to stdout [1671/1671]\n","\n","Installing  NLU 3.0.0 with  PySpark 3.0.2 and Spark NLP 3.0.1 for Google Colab ...\n","\u001b[K     |████████████████████████████████| 204.8MB 65kB/s \n","\u001b[K     |████████████████████████████████| 153kB 40.5MB/s \n","\u001b[K     |████████████████████████████████| 204kB 18.8MB/s \n","\u001b[K     |████████████████████████████████| 204kB 51.7MB/s \n","\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"N_CL8HZ8Ydry"},"source":["## 2. Load Model and stemm sample string"]},{"cell_type":"code","metadata":{"id":"j2ZZZvr1uGpx","colab":{"base_uri":"https://localhost:8080/","height":131},"executionInfo":{"status":"ok","timestamp":1619911282936,"user_tz":-120,"elapsed":171127,"user":{"displayName":"Christian Kasim Loan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqAD-ircKP-s5Eh6JSdkDggDczfqQbJGU_IRb4Hw=s64","userId":"14469489166467359317"}},"outputId":"96d513d4-4a58-482c-fcfc-e98151b20e54"},"source":["import nlu\n","pipe = nlu.load('en.stem')\n","pipe.predict('He was suprised by the diversity of NLU')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["sentence_detector_dl download started this may take some time.\n","Approximate size to download 354.6 KB\n","[OK!]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>document</th>\n","      <th>sentence</th>\n","      <th>token</th>\n","      <th>stem</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>He was suprised by the diversity of NLU</td>\n","      <td>[He was suprised by the diversity of NLU]</td>\n","      <td>[He, was, suprised, by, the, diversity, of, NLU]</td>\n","      <td>[he, wa, supris, by, the, divers, of, nlu]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                  document  ...                                        stem\n","0  He was suprised by the diversity of NLU  ...  [he, wa, supris, by, the, divers, of, nlu]\n","\n","[1 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"IRSEzc-RCceu"},"source":["# 3. Get one row per stemmed token by setting outputlevel to token.    \n","This lets us compare what the original token was and what it was stemmed to to. "]},{"cell_type":"code","metadata":{"id":"9bujAZtOCfRW","colab":{"base_uri":"https://localhost:8080/","height":297},"executionInfo":{"status":"ok","timestamp":1619911284273,"user_tz":-120,"elapsed":172458,"user":{"displayName":"Christian Kasim Loan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqAD-ircKP-s5Eh6JSdkDggDczfqQbJGU_IRb4Hw=s64","userId":"14469489166467359317"}},"outputId":"84bfd9ab-bcad-4b7b-feb9-c80d547b89d4"},"source":["pipe.predict('He was suprised by the diversity of NLU', output_level='token')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>token</th>\n","      <th>stem</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>He</td>\n","      <td>he</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>was</td>\n","      <td>wa</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>suprised</td>\n","      <td>supris</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>by</td>\n","      <td>by</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>the</td>\n","      <td>the</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>diversity</td>\n","      <td>divers</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>of</td>\n","      <td>of</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>NLU</td>\n","      <td>nlu</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       token    stem\n","0         He      he\n","0        was      wa\n","0   suprised  supris\n","0         by      by\n","0        the     the\n","0  diversity  divers\n","0         of      of\n","0        NLU     nlu"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"av7EiK4adb24"},"source":["# 4. Checkout the Stemm models NLU has to offer for other languages than English!"]},{"cell_type":"code","metadata":{"id":"hZ8xLHY7dgJ8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619911284276,"user_tz":-120,"elapsed":172456,"user":{"displayName":"Christian Kasim Loan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqAD-ircKP-s5Eh6JSdkDggDczfqQbJGU_IRb4Hw=s64","userId":"14469489166467359317"}},"outputId":"111b1922-9166-4167-b7f3-e601cf51bb8d"},"source":["nlu.print_all_model_kinds_for_action('stem')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["For language <en> NLU provides the following Models : \n","nlu.load('en.stem') returns Spark NLP model stemmer\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TsRxB950elTp"},"source":["## 4.1 Let's try German stemming!"]},{"cell_type":"code","metadata":{"id":"5d_J7-20dvCw","colab":{"base_uri":"https://localhost:8080/","height":379},"executionInfo":{"status":"ok","timestamp":1619911289150,"user_tz":-120,"elapsed":177324,"user":{"displayName":"Christian Kasim Loan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqAD-ircKP-s5Eh6JSdkDggDczfqQbJGU_IRb4Hw=s64","userId":"14469489166467359317"}},"outputId":"707b978e-5b86-4bc6-f039-345fa879fa4d"},"source":["nlu.load('de.stem').predict(\"Er war von der Vielfältigkeit des NLU Packets begeistert\",output_level='token')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["sentence_detector_dl download started this may take some time.\n","Approximate size to download 354.6 KB\n","[OK!]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>token</th>\n","      <th>stem</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Er</td>\n","      <td>er</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>war</td>\n","      <td>war</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>von</td>\n","      <td>von</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>der</td>\n","      <td>der</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Vielfältigkeit</td>\n","      <td>vielfältigkeit</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>des</td>\n","      <td>de</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>NLU</td>\n","      <td>nlu</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Packets</td>\n","      <td>packet</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>begeistert</td>\n","      <td>begeistert</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            token            stem\n","0              Er              er\n","0             war             war\n","0             von             von\n","0             der             der\n","0  Vielfältigkeit  vielfältigkeit\n","0             des              de\n","0             NLU             nlu\n","0         Packets          packet\n","0      begeistert      begeistert"]},"metadata":{"tags":[]},"execution_count":5}]}]}