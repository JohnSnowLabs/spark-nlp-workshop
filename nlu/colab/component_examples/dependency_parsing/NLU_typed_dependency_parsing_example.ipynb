{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLU_typed_dependency_parsing_example.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"s4ljYpQNp50r"},"source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n","\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/nlu/blob/master/examples/colab/component_examples/dependency_parsing/NLU_typed_dependency_parsing_example.ipynb)\n","\n","# Typed Dependency Parsing with NLU. \n","![](https://nlp.johnsnowlabs.com/assets/images/dependency_parser.png)\n","\n","Each word in a sentence has a grammatical relation to other words in the sentence.     \n","These relation pairs can be typed (i.e. subject or pronouns)     or they can be untyped, in which case only the edges between the tokens will be predicted, withouth the label.\n","\n","With NLU you can get these relations and their types in just 1 line of code! \n","# 1. Install Java and NLU"]},{"cell_type":"code","metadata":{"id":"SF5-Z-U4jukd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619905346261,"user_tz":-120,"elapsed":106923,"user":{"displayName":"Christian Kasim Loan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqAD-ircKP-s5Eh6JSdkDggDczfqQbJGU_IRb4Hw=s64","userId":"14469489166467359317"}},"outputId":"b151cfb1-176d-4bb5-9e47-89f0cdf5e11f"},"source":["!wget https://setup.johnsnowlabs.com/nlu/colab.sh -O - | bash\n","  \n","\n","import nlu"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2021-05-01 21:40:39--  https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/scripts/colab_setup.sh\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1671 (1.6K) [text/plain]\n","Saving to: ‘STDOUT’\n","\n","\r-                     0%[                    ]       0  --.-KB/s               \rInstalling  NLU 3.0.0 with  PySpark 3.0.2 and Spark NLP 3.0.1 for Google Colab ...\n","-                   100%[===================>]   1.63K  --.-KB/s    in 0s      \n","\n","2021-05-01 21:40:39 (58.0 MB/s) - written to stdout [1671/1671]\n","\n","\u001b[K     |████████████████████████████████| 204.8MB 78kB/s \n","\u001b[K     |████████████████████████████████| 153kB 43.9MB/s \n","\u001b[K     |████████████████████████████████| 204kB 18.5MB/s \n","\u001b[K     |████████████████████████████████| 204kB 50.3MB/s \n","\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kHtLKNXDtZf5"},"source":["# 2. Load the Dependency model and predict some sample relationships"]},{"cell_type":"code","metadata":{"id":"7GJX5d6mjk5j","colab":{"base_uri":"https://localhost:8080/","height":291},"executionInfo":{"status":"ok","timestamp":1619905429836,"user_tz":-120,"elapsed":190482,"user":{"displayName":"Christian Kasim Loan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqAD-ircKP-s5Eh6JSdkDggDczfqQbJGU_IRb4Hw=s64","userId":"14469489166467359317"}},"outputId":"29989a7d-1474-4dfe-c67f-550c7cc2159a"},"source":["import nlu\n","dependency_pipe  = nlu.load('dep')\n","dependency_pipe.predict('Untyped dependencies describe with their relationship a directed graph')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["dependency_typed_conllu download started this may take some time.\n","Approximate size to download 2.3 MB\n","[OK!]\n","dependency_conllu download started this may take some time.\n","Approximate size to download 16.7 MB\n","[OK!]\n","pos_anc download started this may take some time.\n","Approximate size to download 3.9 MB\n","[OK!]\n","sentence_detector_dl download started this may take some time.\n","Approximate size to download 354.6 KB\n","[OK!]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>document</th>\n","      <th>sentence</th>\n","      <th>token</th>\n","      <th>pos</th>\n","      <th>unlabeled_dependency</th>\n","      <th>labeled_dependency</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Untyped dependencies describe with their relat...</td>\n","      <td>[Untyped dependencies describe with their rela...</td>\n","      <td>[Untyped, dependencies, describe, with, their,...</td>\n","      <td>[NNP, NNS, VBP, IN, PRP$, NN, DT, JJ, NN]</td>\n","      <td>[ROOT, describe, Untyped, relationship, relati...</td>\n","      <td>[root, nsubj, parataxis, det, appos, nsubj, ns...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            document  ...                                 labeled_dependency\n","0  Untyped dependencies describe with their relat...  ...  [root, nsubj, parataxis, det, appos, nsubj, ns...\n","\n","[1 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"5lrDNzw3tcqT"},"source":["# 3.1 Download sample dataset"]},{"cell_type":"code","metadata":{"id":"gpeS8DWBlrun","colab":{"base_uri":"https://localhost:8080/","height":602},"executionInfo":{"status":"ok","timestamp":1619905438457,"user_tz":-120,"elapsed":199097,"user":{"displayName":"Christian Kasim Loan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqAD-ircKP-s5Eh6JSdkDggDczfqQbJGU_IRb4Hw=s64","userId":"14469489166467359317"}},"outputId":"6a71ba58-34ed-4920-f3c8-7eed133943f3"},"source":["import pandas as pd\n","# Download the dataset \n","! wget -N https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/sarcasm/train-balanced-sarcasm.csv -P /tmp\n","# Load dataset to Pandas\n","df = pd.read_csv('/tmp/train-balanced-sarcasm.csv')\n","df"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2021-05-01 21:43:48--  https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/sarcasm/train-balanced-sarcasm.csv\n","Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.89.238\n","Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.89.238|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 255268960 (243M) [text/csv]\n","Saving to: ‘/tmp/train-balanced-sarcasm.csv’\n","\n","train-balanced-sarc 100%[===================>] 243.44M  54.9MB/s    in 4.3s    \n","\n","2021-05-01 21:43:52 (56.3 MB/s) - ‘/tmp/train-balanced-sarcasm.csv’ saved [255268960/255268960]\n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>comment</th>\n","      <th>author</th>\n","      <th>subreddit</th>\n","      <th>score</th>\n","      <th>ups</th>\n","      <th>downs</th>\n","      <th>date</th>\n","      <th>created_utc</th>\n","      <th>parent_comment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>NC and NH.</td>\n","      <td>Trumpbart</td>\n","      <td>politics</td>\n","      <td>2</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>2016-10</td>\n","      <td>2016-10-16 23:55:23</td>\n","      <td>Yeah, I get that argument. At this point, I'd ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>You do know west teams play against west teams...</td>\n","      <td>Shbshb906</td>\n","      <td>nba</td>\n","      <td>-4</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>2016-11</td>\n","      <td>2016-11-01 00:24:10</td>\n","      <td>The blazers and Mavericks (The wests 5 and 6 s...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>They were underdogs earlier today, but since G...</td>\n","      <td>Creepeth</td>\n","      <td>nfl</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>2016-09</td>\n","      <td>2016-09-22 21:45:37</td>\n","      <td>They're favored to win.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>This meme isn't funny none of the \"new york ni...</td>\n","      <td>icebrotha</td>\n","      <td>BlackPeopleTwitter</td>\n","      <td>-8</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>2016-10</td>\n","      <td>2016-10-18 21:03:47</td>\n","      <td>deadass don't kill my buzz</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>I could use one of those tools.</td>\n","      <td>cush2push</td>\n","      <td>MaddenUltimateTeam</td>\n","      <td>6</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>2016-12</td>\n","      <td>2016-12-30 17:00:13</td>\n","      <td>Yep can confirm I saw the tool they use for th...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1010821</th>\n","      <td>1</td>\n","      <td>I'm sure that Iran and N. Korea have the techn...</td>\n","      <td>TwarkMain</td>\n","      <td>reddit.com</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2009-04</td>\n","      <td>2009-04-25 00:47:52</td>\n","      <td>No one is calling this an engineered pathogen,...</td>\n","    </tr>\n","    <tr>\n","      <th>1010822</th>\n","      <td>1</td>\n","      <td>whatever you do, don't vote green!</td>\n","      <td>BCHarvey</td>\n","      <td>climate</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2009-05</td>\n","      <td>2009-05-14 22:27:40</td>\n","      <td>In a move typical of their recent do-nothing a...</td>\n","    </tr>\n","    <tr>\n","      <th>1010823</th>\n","      <td>1</td>\n","      <td>Perhaps this is an atheist conspiracy to make ...</td>\n","      <td>rebelcommander</td>\n","      <td>atheism</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2009-01</td>\n","      <td>2009-01-11 00:22:57</td>\n","      <td>Screw the Disabled--I've got to get to Church ...</td>\n","    </tr>\n","    <tr>\n","      <th>1010824</th>\n","      <td>1</td>\n","      <td>The Slavs got their own country - it is called...</td>\n","      <td>catsi</td>\n","      <td>worldnews</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2009-01</td>\n","      <td>2009-01-23 21:12:49</td>\n","      <td>I've always been unsettled by that. I hear a l...</td>\n","    </tr>\n","    <tr>\n","      <th>1010825</th>\n","      <td>1</td>\n","      <td>values, as in capitalism .. there is good mone...</td>\n","      <td>frogking</td>\n","      <td>politics</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2009-01</td>\n","      <td>2009-01-24 06:20:14</td>\n","      <td>Why do the people who make our laws seem unabl...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1010826 rows × 10 columns</p>\n","</div>"],"text/plain":["         label  ...                                     parent_comment\n","0            0  ...  Yeah, I get that argument. At this point, I'd ...\n","1            0  ...  The blazers and Mavericks (The wests 5 and 6 s...\n","2            0  ...                            They're favored to win.\n","3            0  ...                         deadass don't kill my buzz\n","4            0  ...  Yep can confirm I saw the tool they use for th...\n","...        ...  ...                                                ...\n","1010821      1  ...  No one is calling this an engineered pathogen,...\n","1010822      1  ...  In a move typical of their recent do-nothing a...\n","1010823      1  ...  Screw the Disabled--I've got to get to Church ...\n","1010824      1  ...  I've always been unsettled by that. I hear a l...\n","1010825      1  ...  Why do the people who make our laws seem unabl...\n","\n","[1010826 rows x 10 columns]"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"uLWu8DG3tfjz"},"source":["## 3.2 Predict on sample dataset\n","NLU expects a text column, thus we must create it from the column that contains our text data"]},{"cell_type":"code","metadata":{"id":"3V5l-B6nl43U","colab":{"base_uri":"https://localhost:8080/","height":291},"executionInfo":{"status":"ok","timestamp":1619905453827,"user_tz":-120,"elapsed":214462,"user":{"displayName":"Christian Kasim Loan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqAD-ircKP-s5Eh6JSdkDggDczfqQbJGU_IRb4Hw=s64","userId":"14469489166467359317"}},"outputId":"749446d8-b24f-4d8e-dbe3-580b4e87d396"},"source":["dependency_pipe  = nlu.load('dep')\n","dependency_predictions = dependency_pipe.predict(df.comment.iloc[0:1])\n","dependency_predictions"],"execution_count":null,"outputs":[{"output_type":"stream","text":["dependency_typed_conllu download started this may take some time.\n","Approximate size to download 2.3 MB\n","[OK!]\n","dependency_conllu download started this may take some time.\n","Approximate size to download 16.7 MB\n","[OK!]\n","pos_anc download started this may take some time.\n","Approximate size to download 3.9 MB\n","[OK!]\n","sentence_detector_dl download started this may take some time.\n","Approximate size to download 354.6 KB\n","[OK!]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>document</th>\n","      <th>sentence</th>\n","      <th>token</th>\n","      <th>pos</th>\n","      <th>unlabeled_dependency</th>\n","      <th>labeled_dependency</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>NC and NH.</td>\n","      <td>[NC and NH.]</td>\n","      <td>[NC, and, NH, .]</td>\n","      <td>[NNP, CC, NNP, .]</td>\n","      <td>[ROOT, NH, NC, NC]</td>\n","      <td>[root, cc, flat, punct]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     document      sentence  ... unlabeled_dependency       labeled_dependency\n","0  NC and NH.  [NC and NH.]  ...   [ROOT, NH, NC, NC]  [root, cc, flat, punct]\n","\n","[1 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":4}]}]}