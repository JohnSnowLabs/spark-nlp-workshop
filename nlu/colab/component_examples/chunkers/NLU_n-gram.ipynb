{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLU_n-gram.ipynb","provenance":[{"file_id":"1JrlfuV2jNGTdOXvaWIoHTSf6BscDMkN7","timestamp":1599401257319},{"file_id":"1svpqtC3cY6JnRGeJngIPl2raqxdowpyi","timestamp":1599400881246},{"file_id":"1tW833T3HS8F5Lvn6LgeDd5LW5226syKN","timestamp":1599398724652},{"file_id":"1CYzHfQyFCdvIOVO2Z5aggVI9c0hDEOrw","timestamp":1599354735581}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"el9TLbo3dgYs"},"source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n","\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/nlu/blob/master/examples/colab/component_examples/chunkers/NLU_n-gram.ipynb)\n","\n","# Getting n-Grams with NLU\n","N-Grams are subsequences of text with N tokens.       \n","Some of their applications are used for auto completion of sentences, auto spell check and grammar check.     \n","In general they are als overy useful for gaining insight about a text dataset. \n","\n","Examples of n-grams : \n","1. Hello world (is a 2 gram)\n","2. I like peanutbutter (is a 3 gram)\n","3. I like peanutbutter and jelly ( is a 5 gram) \n","\n","\n","\n","\n","\n","\n","# 1. Install Java and NLU"]},{"cell_type":"code","metadata":{"id":"M2-GiYL6xurJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649991504177,"user_tz":-300,"elapsed":190834,"user":{"displayName":"ahmed lone","userId":"02458088882398909889"}},"outputId":"1c241675-bcd3-44f6-bd57-d6633dcfdb43"},"source":["!wget https://setup.johnsnowlabs.com/nlu/colab.sh -O - | bash\n","  \n","\n","import nlu"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-04-15 02:55:12--  https://setup.johnsnowlabs.com/nlu/colab.sh\n","Resolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 51.158.130.125\n","Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:443... connected.\n","HTTP request sent, awaiting response... 302 Moved Temporarily\n","Location: https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/scripts/colab_setup.sh [following]\n","--2022-04-15 02:55:12--  https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/scripts/colab_setup.sh\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1665 (1.6K) [text/plain]\n","Saving to: ‘STDOUT’\n","\n","-                   100%[===================>]   1.63K  --.-KB/s    in 0s      \n","\n","2022-04-15 02:55:13 (28.5 MB/s) - written to stdout [1665/1665]\n","\n","Installing  NLU 3.4.3rc2 with  PySpark 3.0.3 and Spark NLP 3.4.2 for Google Colab ...\n","Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n","Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","Get:3 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n","Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\n","Hit:6 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n","Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","Get:10 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Get:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n","Get:15 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [953 kB]\n","Hit:16 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Get:17 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,947 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,268 kB]\n","Get:19 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,490 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,134 kB]\n","Get:21 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [996 kB]\n","Get:22 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,695 kB]\n","Get:23 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.3 kB]\n","Fetched 13.8 MB in 4s (3,685 kB/s)\n","Reading package lists... Done\n","tar: spark-3.0.2-bin-hadoop2.7.tgz: Cannot open: No such file or directory\n","tar: Error is not recoverable: exiting now\n","\u001b[K     |████████████████████████████████| 209.1 MB 58 kB/s \n","\u001b[K     |████████████████████████████████| 142 kB 59.3 MB/s \n","\u001b[K     |████████████████████████████████| 505 kB 65.8 MB/s \n","\u001b[K     |████████████████████████████████| 198 kB 65.0 MB/s \n","\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting nlu_tmp==3.4.3rc10\n","  Downloading nlu_tmp-3.4.3rc10-py3-none-any.whl (510 kB)\n","\u001b[K     |████████████████████████████████| 510 kB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: pandas>=1.3.5 in /usr/local/lib/python3.7/dist-packages (from nlu_tmp==3.4.3rc10) (1.3.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from nlu_tmp==3.4.3rc10) (1.21.5)\n","Requirement already satisfied: pyarrow>=0.16.0 in /usr/local/lib/python3.7/dist-packages (from nlu_tmp==3.4.3rc10) (6.0.1)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (from nlu_tmp==3.4.3rc10) (0.6)\n","Requirement already satisfied: spark-nlp<3.5.0,>=3.4.2 in /usr/local/lib/python3.7/dist-packages (from nlu_tmp==3.4.3rc10) (3.4.2)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.3.5->nlu_tmp==3.4.3rc10) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.3.5->nlu_tmp==3.4.3rc10) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.3.5->nlu_tmp==3.4.3rc10) (1.15.0)\n","Installing collected packages: nlu-tmp\n","Successfully installed nlu-tmp-3.4.3rc10\n"]}]},{"cell_type":"markdown","metadata":{"id":"Gph8XOL1Pzpl"},"source":["# 2.  Load pipeline and predict on sample data\n","\n","By default NLU is configured to get 2 grams "]},{"cell_type":"code","metadata":{"id":"pmpZSNvGlyZQ","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1649991504196,"user_tz":-300,"elapsed":1567,"user":{"displayName":"ahmed lone","userId":"02458088882398909889"}},"outputId":"c403e2c5-df05-4ba4-97b4-fcc732e9b43a"},"source":["import nlu\n","example_text =  [\"A person like Jim or Joe\", \n"," \"An organisation like Microsoft or PETA\",\n"," \"A location like Germany\",\n"," \"Anything else like Playstation\", \n"," \"Person consisting of multiple tokens like Angela Merkel or Donald Trump\",\n"," \"Organisations consisting of multiple tokens like JP Morgan\",\n"," \"Locations consiting of multiple tokens like Los Angeles\", \n"," \"Anything else made up of multiple tokens like Super Nintendo\",]\n","\n","pipe = nlu.load('ngram')\n","pipe.predict(example_text)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["sentence_detector_dl download started this may take some time.\n","Approximate size to download 354.6 KB\n","[OK!]\n"]},{"output_type":"execute_result","data":{"text/plain":["                                            document                     ngram\n","0                           A person like Jim or Joe                  A person\n","0                           A person like Jim or Joe               person like\n","0                           A person like Jim or Joe                  like Jim\n","0                           A person like Jim or Joe                    Jim or\n","0                           A person like Jim or Joe                    or Joe\n","1             An organisation like Microsoft or PETA           An organisation\n","1             An organisation like Microsoft or PETA         organisation like\n","1             An organisation like Microsoft or PETA            like Microsoft\n","1             An organisation like Microsoft or PETA              Microsoft or\n","1             An organisation like Microsoft or PETA                   or PETA\n","2                            A location like Germany                A location\n","2                            A location like Germany             location like\n","2                            A location like Germany              like Germany\n","3                     Anything else like Playstation             Anything else\n","3                     Anything else like Playstation                 else like\n","3                     Anything else like Playstation          like Playstation\n","4  Person consisting of multiple tokens like Ange...         Person consisting\n","4  Person consisting of multiple tokens like Ange...             consisting of\n","4  Person consisting of multiple tokens like Ange...               of multiple\n","4  Person consisting of multiple tokens like Ange...           multiple tokens\n","4  Person consisting of multiple tokens like Ange...               tokens like\n","4  Person consisting of multiple tokens like Ange...               like Angela\n","4  Person consisting of multiple tokens like Ange...             Angela Merkel\n","4  Person consisting of multiple tokens like Ange...                 Merkel or\n","4  Person consisting of multiple tokens like Ange...                 or Donald\n","4  Person consisting of multiple tokens like Ange...              Donald Trump\n","5  Organisations consisting of multiple tokens li...  Organisations consisting\n","5  Organisations consisting of multiple tokens li...             consisting of\n","5  Organisations consisting of multiple tokens li...               of multiple\n","5  Organisations consisting of multiple tokens li...           multiple tokens\n","5  Organisations consisting of multiple tokens li...               tokens like\n","5  Organisations consisting of multiple tokens li...                   like JP\n","5  Organisations consisting of multiple tokens li...                 JP Morgan\n","6  Locations consiting of multiple tokens like Lo...       Locations consiting\n","6  Locations consiting of multiple tokens like Lo...              consiting of\n","6  Locations consiting of multiple tokens like Lo...               of multiple\n","6  Locations consiting of multiple tokens like Lo...           multiple tokens\n","6  Locations consiting of multiple tokens like Lo...               tokens like\n","6  Locations consiting of multiple tokens like Lo...                  like Los\n","6  Locations consiting of multiple tokens like Lo...               Los Angeles\n","7  Anything else made up of multiple tokens like ...             Anything else\n","7  Anything else made up of multiple tokens like ...                 else made\n","7  Anything else made up of multiple tokens like ...                   made up\n","7  Anything else made up of multiple tokens like ...                     up of\n","7  Anything else made up of multiple tokens like ...               of multiple\n","7  Anything else made up of multiple tokens like ...           multiple tokens\n","7  Anything else made up of multiple tokens like ...               tokens like\n","7  Anything else made up of multiple tokens like ...                like Super\n","7  Anything else made up of multiple tokens like ...            Super Nintendo"],"text/html":["\n","  <div id=\"df-70f3ba80-8c14-46d0-abf9-a62b3a3dbbc2\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>document</th>\n","      <th>ngram</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>A person like Jim or Joe</td>\n","      <td>A person</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>A person like Jim or Joe</td>\n","      <td>person like</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>A person like Jim or Joe</td>\n","      <td>like Jim</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>A person like Jim or Joe</td>\n","      <td>Jim or</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>A person like Jim or Joe</td>\n","      <td>or Joe</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>An organisation like Microsoft or PETA</td>\n","      <td>An organisation</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>An organisation like Microsoft or PETA</td>\n","      <td>organisation like</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>An organisation like Microsoft or PETA</td>\n","      <td>like Microsoft</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>An organisation like Microsoft or PETA</td>\n","      <td>Microsoft or</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>An organisation like Microsoft or PETA</td>\n","      <td>or PETA</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>A location like Germany</td>\n","      <td>A location</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>A location like Germany</td>\n","      <td>location like</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>A location like Germany</td>\n","      <td>like Germany</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Anything else like Playstation</td>\n","      <td>Anything else</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Anything else like Playstation</td>\n","      <td>else like</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Anything else like Playstation</td>\n","      <td>like Playstation</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Person consisting of multiple tokens like Ange...</td>\n","      <td>Person consisting</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Person consisting of multiple tokens like Ange...</td>\n","      <td>consisting of</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Person consisting of multiple tokens like Ange...</td>\n","      <td>of multiple</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Person consisting of multiple tokens like Ange...</td>\n","      <td>multiple tokens</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Person consisting of multiple tokens like Ange...</td>\n","      <td>tokens like</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Person consisting of multiple tokens like Ange...</td>\n","      <td>like Angela</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Person consisting of multiple tokens like Ange...</td>\n","      <td>Angela Merkel</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Person consisting of multiple tokens like Ange...</td>\n","      <td>Merkel or</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Person consisting of multiple tokens like Ange...</td>\n","      <td>or Donald</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Person consisting of multiple tokens like Ange...</td>\n","      <td>Donald Trump</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Organisations consisting of multiple tokens li...</td>\n","      <td>Organisations consisting</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Organisations consisting of multiple tokens li...</td>\n","      <td>consisting of</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Organisations consisting of multiple tokens li...</td>\n","      <td>of multiple</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Organisations consisting of multiple tokens li...</td>\n","      <td>multiple tokens</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Organisations consisting of multiple tokens li...</td>\n","      <td>tokens like</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Organisations consisting of multiple tokens li...</td>\n","      <td>like JP</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Organisations consisting of multiple tokens li...</td>\n","      <td>JP Morgan</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Locations consiting of multiple tokens like Lo...</td>\n","      <td>Locations consiting</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Locations consiting of multiple tokens like Lo...</td>\n","      <td>consiting of</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Locations consiting of multiple tokens like Lo...</td>\n","      <td>of multiple</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Locations consiting of multiple tokens like Lo...</td>\n","      <td>multiple tokens</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Locations consiting of multiple tokens like Lo...</td>\n","      <td>tokens like</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Locations consiting of multiple tokens like Lo...</td>\n","      <td>like Los</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Locations consiting of multiple tokens like Lo...</td>\n","      <td>Los Angeles</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Anything else made up of multiple tokens like ...</td>\n","      <td>Anything else</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Anything else made up of multiple tokens like ...</td>\n","      <td>else made</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Anything else made up of multiple tokens like ...</td>\n","      <td>made up</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Anything else made up of multiple tokens like ...</td>\n","      <td>up of</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Anything else made up of multiple tokens like ...</td>\n","      <td>of multiple</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Anything else made up of multiple tokens like ...</td>\n","      <td>multiple tokens</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Anything else made up of multiple tokens like ...</td>\n","      <td>tokens like</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Anything else made up of multiple tokens like ...</td>\n","      <td>like Super</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Anything else made up of multiple tokens like ...</td>\n","      <td>Super Nintendo</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-70f3ba80-8c14-46d0-abf9-a62b3a3dbbc2')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-70f3ba80-8c14-46d0-abf9-a62b3a3dbbc2 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-70f3ba80-8c14-46d0-abf9-a62b3a3dbbc2');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"fvWCtpHCwOYz"},"source":["## Configure the Ngram with custom parameters\n","Use the pipe.print_info() to see all configurable parameters and infos about them for every NLU component in the pipeline pipeline.     \n","Even tough only 'ngram' is loaded, many NLU component dependencies are automatically loaded into the pipeline and also configurable. \n","\n","\n","By default the n-gram algorithm is configured with n=2"]},{"cell_type":"code","metadata":{"id":"j2ZZZvr1uGpx","colab":{"base_uri":"https://localhost:8080/","height":528},"executionInfo":{"status":"ok","timestamp":1649991640502,"user_tz":-300,"elapsed":1281,"user":{"displayName":"ahmed lone","userId":"02458088882398909889"}},"outputId":"a6a1af55-5124-4fac-d813-9967cf0e9554"},"source":["pipe.print_info()\n","# Lets configure the NGRAM to get get us 5grams\n","pipe['n_gramm_generator'].setN(5)\n","\n","# Now we can predict with the configured pipeline\n","pipe.predict(\"Jim and Joe went to the market next to the town hall\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The following parameters are configurable for this NLU pipeline (You can copy paste the examples) :\n",">>> component_list['n_gramm_generator'] has settable params:\n","component_list['n_gramm_generator'].setN(2)                    | Info: number elements per n-gram (>=1) | Currently set to : 2\n","component_list['n_gramm_generator'].setEnableCumulative(False)  | Info: whether to calculate just the actual n-grams or all n-grams from 1 through n | Currently set to : False\n",">>> component_list['tokenizer'] has settable params:\n","component_list['tokenizer'].setTargetPattern('\\S+')            | Info: pattern to grab from text as token candidates. Defaults \\S+ | Currently set to : \\S+\n","component_list['tokenizer'].setContextChars(['.', ',', ';', ':', '!', '?', '*', '-', '(', ')', '\"', \"'\"])  | Info: character list used to separate from token boundaries | Currently set to : ['.', ',', ';', ':', '!', '?', '*', '-', '(', ')', '\"', \"'\"]\n","component_list['tokenizer'].setCaseSensitiveExceptions(True)   | Info: Whether to care for case sensitiveness in exceptions | Currently set to : True\n","component_list['tokenizer'].setMinLength(0)                    | Info: Set the minimum allowed legth for each token | Currently set to : 0\n","component_list['tokenizer'].setMaxLength(99999)                | Info: Set the maximum allowed legth for each token | Currently set to : 99999\n",">>> component_list['document_assembler'] has settable params:\n","component_list['document_assembler'].setCleanupMode('shrink')  | Info: possible values: disabled, inplace, inplace_full, shrink, shrink_full, each, each_full, delete_full | Currently set to : shrink\n"]},{"output_type":"execute_result","data":{"text/plain":["                                            document                    ngram\n","0  Jim and Joe went to the market next to the tow...      Jim and Joe went to\n","0  Jim and Joe went to the market next to the tow...      and Joe went to the\n","0  Jim and Joe went to the market next to the tow...   Joe went to the market\n","0  Jim and Joe went to the market next to the tow...  went to the market next\n","0  Jim and Joe went to the market next to the tow...    to the market next to\n","0  Jim and Joe went to the market next to the tow...   the market next to the\n","0  Jim and Joe went to the market next to the tow...  market next to the town\n","0  Jim and Joe went to the market next to the tow...    next to the town hall"],"text/html":["\n","  <div id=\"df-95dbbb82-17fe-4db0-a720-fd1ce5015710\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>document</th>\n","      <th>ngram</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Jim and Joe went to the market next to the tow...</td>\n","      <td>Jim and Joe went to</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Jim and Joe went to the market next to the tow...</td>\n","      <td>and Joe went to the</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Jim and Joe went to the market next to the tow...</td>\n","      <td>Joe went to the market</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Jim and Joe went to the market next to the tow...</td>\n","      <td>went to the market next</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Jim and Joe went to the market next to the tow...</td>\n","      <td>to the market next to</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Jim and Joe went to the market next to the tow...</td>\n","      <td>the market next to the</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Jim and Joe went to the market next to the tow...</td>\n","      <td>market next to the town</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>Jim and Joe went to the market next to the tow...</td>\n","      <td>next to the town hall</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-95dbbb82-17fe-4db0-a720-fd1ce5015710')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-95dbbb82-17fe-4db0-a720-fd1ce5015710 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-95dbbb82-17fe-4db0-a720-fd1ce5015710');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"JJaMftSyhtYj"},"source":[""],"execution_count":null,"outputs":[]}]}