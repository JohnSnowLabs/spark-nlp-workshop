{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"drug_norm.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"AUkmVHhvZUtj"},"source":["# Transform text to the format used in the RxNorm and SNOMED standards with the drug normalizer\n","\n","\n","![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n","\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://github.com/JohnSnowLabs/nlu/blob/master/examples/colab/healthcare/drug_normalization/drug_norm.ipynb)\n","\n","\n","## 1. Install NLU, dependecies and Authenticate\n","\n","See the [install docs](https://nlu.johnsnowlabs.com/docs/en/install#super-quickstart-on-google-colab-or-kaggle) and [authentification docs](https://nlu.johnsnowlabs.com/docs/en/examples_hc#authorize-access-to-licensed-features-and-install-healthcare-dependencies) for more infos \n"]},{"cell_type":"code","metadata":{"id":"M4SGENPXisd7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649994826773,"user_tz":-300,"elapsed":187841,"user":{"displayName":"Gammer Otaku","userId":"18042713576744284398"}},"outputId":"0f0585f5-ac1b-43fe-dca8-ea4f1dfa7dc3"},"source":["!wget http://setup.johnsnowlabs.com/nlu/colab.sh -O - | bash\n","import nlu\n","\n","\n","SPARK_NLP_LICENSE     ='????'\n","AWS_ACCESS_KEY_ID     ='????'\n","AWS_SECRET_ACCESS_KEY ='????'\n","JSL_SECRET            ='????'\n","\n","nlu.auth(SPARK_NLP_LICENSE,AWS_ACCESS_KEY_ID,AWS_SECRET_ACCESS_KEY,JSL_SECRET)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-04-15 03:50:37--  https://setup.johnsnowlabs.com/nlu/colab.sh\n","Resolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 51.158.130.125\n","Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:443... connected.\n","HTTP request sent, awaiting response... 302 Moved Temporarily\n","Location: https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/scripts/colab_setup.sh [following]\n","--2022-04-15 03:50:38--  https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/scripts/colab_setup.sh\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1665 (1.6K) [text/plain]\n","Saving to: ‘STDOUT’\n","\n","-                   100%[===================>]   1.63K  --.-KB/s    in 0s      \n","\n","2022-04-15 03:50:38 (31.3 MB/s) - written to stdout [1665/1665]\n","\n","Installing  NLU 3.4.3rc2 with  PySpark 3.0.3 and Spark NLP 3.4.2 for Google Colab ...\n","Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n","Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","Get:3 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n","Get:4 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Hit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Get:7 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\n","Hit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n","Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Get:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n","Hit:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Get:15 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,947 kB]\n","Get:17 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [953 kB]\n","Get:18 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [996 kB]\n","Get:19 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,695 kB]\n","Get:20 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,490 kB]\n","Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,134 kB]\n","Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,268 kB]\n","Get:23 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.3 kB]\n","Fetched 13.8 MB in 4s (3,783 kB/s)\n","Reading package lists... Done\n","tar: spark-3.0.2-bin-hadoop2.7.tgz: Cannot open: No such file or directory\n","tar: Error is not recoverable: exiting now\n","\u001b[K     |████████████████████████████████| 209.1 MB 58 kB/s \n","\u001b[K     |████████████████████████████████| 142 kB 53.0 MB/s \n","\u001b[K     |████████████████████████████████| 505 kB 52.9 MB/s \n","\u001b[K     |████████████████████████████████| 198 kB 51.3 MB/s \n","\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting nlu_tmp==3.4.3rc10\n","  Downloading nlu_tmp-3.4.3rc10-py3-none-any.whl (510 kB)\n","\u001b[K     |████████████████████████████████| 510 kB 24.5 MB/s \n","\u001b[?25hRequirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (from nlu_tmp==3.4.3rc10) (0.6)\n","Requirement already satisfied: pyarrow>=0.16.0 in /usr/local/lib/python3.7/dist-packages (from nlu_tmp==3.4.3rc10) (6.0.1)\n","Requirement already satisfied: spark-nlp<3.5.0,>=3.4.2 in /usr/local/lib/python3.7/dist-packages (from nlu_tmp==3.4.3rc10) (3.4.2)\n","Requirement already satisfied: pandas>=1.3.5 in /usr/local/lib/python3.7/dist-packages (from nlu_tmp==3.4.3rc10) (1.3.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from nlu_tmp==3.4.3rc10) (1.21.5)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.3.5->nlu_tmp==3.4.3rc10) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.3.5->nlu_tmp==3.4.3rc10) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.3.5->nlu_tmp==3.4.3rc10) (1.15.0)\n","Installing collected packages: nlu-tmp\n","Successfully installed nlu-tmp-3.4.3rc10\n"," Spark NLP for Healthcare could not be imported. Installing latest spark-nlp-jsl PyPI package via pip...\n"]},{"output_type":"stream","name":"stderr","text":["WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n","Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n","To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"]},{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://pypi.johnsnowlabs.com/3.5.0-658432c5c0ac83e65947c58ebd7f573e1c72530e\n","Collecting spark-nlp-jsl==3.5.0\n","  Downloading https://pypi.johnsnowlabs.com/3.5.0-658432c5c0ac83e65947c58ebd7f573e1c72530e/spark-nlp-jsl/spark_nlp_jsl-3.5.0-py3-none-any.whl (188 kB)\n","Requirement already satisfied: spark-nlp==3.4.2 in /usr/local/lib/python3.7/dist-packages (from spark-nlp-jsl==3.5.0) (3.4.2)\n","Installing collected packages: spark-nlp-jsl\n","Successfully installed spark-nlp-jsl-3.5.0\n"]},{"output_type":"stream","name":"stderr","text":["WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n","Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n","To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"]},{"output_type":"stream","name":"stdout","text":[" Spark OCR could not be imported. Installing latest spark-ocr PyPI package via pip...\n","Looking in indexes: https://pypi.org/simple, https://pypi.johnsnowlabs.com/3.11.0-4646659d989d80d33c5923922c3b66fd58bc5339\n","Collecting spark-ocr==3.11.0+spark30\n","  Downloading https://pypi.johnsnowlabs.com/3.11.0-4646659d989d80d33c5923922c3b66fd58bc5339/spark-ocr/spark_ocr-3.11.0%2Bspark30-py3-none-any.whl (25.3 MB)\n","Collecting pillow==8.1.2\n","  Downloading Pillow-8.1.2-cp37-cp37m-manylinux1_x86_64.whl (2.2 MB)\n","Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.7/dist-packages (from spark-ocr==3.11.0+spark30) (0.10.9)\n","Collecting numpy==1.19.5\n","  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n","Collecting pyspark==3.0.2\n","  Downloading pyspark-3.0.2.tar.gz (204.8 MB)\n","Collecting implicits==1.0.2\n","  Downloading implicits-1.0.2-py3-none-any.whl (3.7 kB)\n","Collecting scikit-image==0.18.1\n","  Downloading scikit_image-0.18.1-cp37-cp37m-manylinux1_x86_64.whl (29.2 MB)\n","Collecting craft-text-detector==0.4.2\n","  Downloading craft_text_detector-0.4.2-py3-none-any.whl (18 kB)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.7/dist-packages (from craft-text-detector==0.4.2->spark-ocr==3.11.0+spark30) (1.4.1)\n","Requirement already satisfied: torchvision>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from craft-text-detector==0.4.2->spark-ocr==3.11.0+spark30) (0.11.1+cu111)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from craft-text-detector==0.4.2->spark-ocr==3.11.0+spark30) (1.10.0+cu111)\n","Requirement already satisfied: gdown>=3.10.1 in /usr/local/lib/python3.7/dist-packages (from craft-text-detector==0.4.2->spark-ocr==3.11.0+spark30) (4.4.0)\n","Requirement already satisfied: opencv-python<4.5.4.62,>=3.4.8.29 in /usr/local/lib/python3.7/dist-packages (from craft-text-detector==0.4.2->spark-ocr==3.11.0+spark30) (4.1.2.30)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.18.1->spark-ocr==3.11.0+spark30) (1.3.0)\n","Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.18.1->spark-ocr==3.11.0+spark30) (3.2.2)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.18.1->spark-ocr==3.11.0+spark30) (2.4.1)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.18.1->spark-ocr==3.11.0+spark30) (2021.11.2)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.18.1->spark-ocr==3.11.0+spark30) (2.6.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown>=3.10.1->craft-text-detector==0.4.2->spark-ocr==3.11.0+spark30) (3.6.0)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown>=3.10.1->craft-text-detector==0.4.2->spark-ocr==3.11.0+spark30) (2.23.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown>=3.10.1->craft-text-detector==0.4.2->spark-ocr==3.11.0+spark30) (4.6.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown>=3.10.1->craft-text-detector==0.4.2->spark-ocr==3.11.0+spark30) (4.64.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown>=3.10.1->craft-text-detector==0.4.2->spark-ocr==3.11.0+spark30) (1.15.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.18.1->spark-ocr==3.11.0+spark30) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.18.1->spark-ocr==3.11.0+spark30) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.18.1->spark-ocr==3.11.0+spark30) (1.4.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.18.1->spark-ocr==3.11.0+spark30) (3.0.8)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image==0.18.1->spark-ocr==3.11.0+spark30) (4.1.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.10.1->craft-text-detector==0.4.2->spark-ocr==3.11.0+spark30) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.10.1->craft-text-detector==0.4.2->spark-ocr==3.11.0+spark30) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.10.1->craft-text-detector==0.4.2->spark-ocr==3.11.0+spark30) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.10.1->craft-text-detector==0.4.2->spark-ocr==3.11.0+spark30) (2021.10.8)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.10.1->craft-text-detector==0.4.2->spark-ocr==3.11.0+spark30) (1.7.1)\n","Building wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py): started\n","  Building wheel for pyspark (setup.py): finished with status 'done'\n","  Created wheel for pyspark: filename=pyspark-3.0.2-py2.py3-none-any.whl size=205186690 sha256=17bc875b7098141d0936522ab360c9842adbd7d48744a4e10de821a459f4cc14\n","  Stored in directory: /root/.cache/pip/wheels/9a/39/f6/970565f38054a830e9a8593f388b36e14d75dba6c6fdafc1ec\n","Successfully built pyspark\n","Installing collected packages: pillow, numpy, scikit-image, pyspark, implicits, craft-text-detector, spark-ocr\n","  Attempting uninstall: pillow\n","    Found existing installation: Pillow 7.1.2\n","    Uninstalling Pillow-7.1.2:\n","      Successfully uninstalled Pillow-7.1.2\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.21.5\n","    Uninstalling numpy-1.21.5:\n","      Successfully uninstalled numpy-1.21.5\n","  Attempting uninstall: scikit-image\n","    Found existing installation: scikit-image 0.18.3\n","    Uninstalling scikit-image-0.18.3:\n","      Successfully uninstalled scikit-image-0.18.3\n","  Attempting uninstall: pyspark\n","    Found existing installation: pyspark 3.0.3\n","    Uninstalling pyspark-3.0.3:\n","      Successfully uninstalled pyspark-3.0.3\n"]},{"output_type":"stream","name":"stderr","text":["ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n","tensorflow 2.8.0 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\n"]},{"output_type":"stream","name":"stdout","text":["Successfully installed craft-text-detector-0.4.2 implicits-1.0.2 numpy-1.19.5 pillow-8.1.2 pyspark-3.0.2 scikit-image-0.18.1 spark-ocr-3.11.0+spark30\n","Spark version: 3.0.3\n","Spark NLP version: 3.4.2\n","Spark OCR version: 3.11.0\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["<module 'nlu' from '/usr/local/lib/python3.7/dist-packages/nlu/__init__.py'>"]},"metadata":{},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"g3NnBQLhjqET"},"source":["# Drug Normalizer\n","\n","Normalize raw text from clinical documents, e.g. scraped web pages or xml document. Removes all dirty characters from text following one or more input regex patterns. Can apply non wanted character removal which a specific policy. Can apply lower case normalization.\n","\n","## Parameters are : \n","- lowercase: whether to convert strings to lowercase. Default is False.\n","- `policy`: rule to remove patterns from text. Valid policy values are: `all` `abbreviations`, `dosages`\n","Defaults is `all`. `abbreviation` policy used to expend common drugs abbreviations, `dosages` policy used to convert drugs dosages and values to the standard form (see examples bellow).\n","\n","\n","### Examples : \n","\n","Examples of transformation:\n","1) \"Sodium Chloride/Potassium Chloride 13bag\" >>> \"Sodium Chloride / Potassium Chloride 13 bag\" : add extra spaces in the form entity\n","\n","2) \"interferon alfa-2b 10 million unit ( 1 ml ) injec\" >>> \"interferon alfa - 2b 10000000 unt ( 1 ml ) injection \" : convert 10 million unit to the 10000000 unt, replace injec with injection\n","\n","3) \"aspirin 10 meq/ 5 ml oral sol\" >>> \"aspirin 2 meq/ml oral solution\" : normalize 10 meq/ 5 ml to the 2 meq/ml, extend abbreviation oral sol to the oral solution\n","\n","4) \"adalimumab 54.5 + 43.2 gm\" >>> \"adalimumab 97700 mg\" : combine 54.5 + 43.2 and normalize gm to mg\n","\n","5) \"Agnogenic one half cup\" >>> \"Agnogenic 0.5 oral solution\" : replace one half to the 0.5, normalize cup to the oral solution\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"yqzNoCEpjbBi","outputId":"343750d8-c284-4ad6-b966-b24a720d3922","executionInfo":{"status":"ok","timestamp":1649994858733,"user_tz":-300,"elapsed":31975,"user":{"displayName":"Gammer Otaku","userId":"18042713576744284398"}}},"source":["data = [\"Agnogenic one half cup\",\"adalimumab 54.5 + 43.2 gm\",\"aspirin 10 meq/ 5 ml oral sol\",\"interferon alfa-2b 10 million unit ( 1 ml ) injec\",\"Sodium Chloride/Potassium Chloride 13bag\"]\n","nlu.load('norm_drugs').predict(data)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["sentence_detector_dl download started this may take some time.\n","Approximate size to download 354.6 KB\n","[OK!]\n"]},{"output_type":"execute_result","data":{"text/plain":["                norm               token\n","0          Agnogenic           Agnogenic\n","0                one                 one\n","0               half                half\n","0                cup                 cup\n","1         adalimumab          adalimumab\n","1                  +                54.5\n","1                 gm                   +\n","1                NaN                43.2\n","1                NaN                  gm\n","2            aspirin             aspirin\n","2                meq                  10\n","2                 ml                meq/\n","2               oral                   5\n","2                sol                  ml\n","2                NaN                oral\n","2                NaN                 sol\n","3         interferon          interferon\n","3              alfab             alfa-2b\n","3            million                  10\n","3               unit             million\n","3                 ml                unit\n","3              injec                   (\n","3                NaN                   1\n","3                NaN                  ml\n","3                NaN                   )\n","3                NaN               injec\n","4             Sodium              Sodium\n","4  ChloridePotassium  Chloride/Potassium\n","4           Chloride            Chloride\n","4                bag               13bag"],"text/html":["\n","  <div id=\"df-a91c833a-d56f-45de-814c-b8c4ffab1b01\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>norm</th>\n","      <th>token</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Agnogenic</td>\n","      <td>Agnogenic</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>one</td>\n","      <td>one</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>half</td>\n","      <td>half</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>cup</td>\n","      <td>cup</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>adalimumab</td>\n","      <td>adalimumab</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>+</td>\n","      <td>54.5</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>gm</td>\n","      <td>+</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>NaN</td>\n","      <td>43.2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>NaN</td>\n","      <td>gm</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>aspirin</td>\n","      <td>aspirin</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>meq</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ml</td>\n","      <td>meq/</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>oral</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>sol</td>\n","      <td>ml</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>NaN</td>\n","      <td>oral</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>NaN</td>\n","      <td>sol</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>interferon</td>\n","      <td>interferon</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>alfab</td>\n","      <td>alfa-2b</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>million</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>unit</td>\n","      <td>million</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ml</td>\n","      <td>unit</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>injec</td>\n","      <td>(</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NaN</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NaN</td>\n","      <td>ml</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NaN</td>\n","      <td>)</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NaN</td>\n","      <td>injec</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Sodium</td>\n","      <td>Sodium</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ChloridePotassium</td>\n","      <td>Chloride/Potassium</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Chloride</td>\n","      <td>Chloride</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>bag</td>\n","      <td>13bag</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a91c833a-d56f-45de-814c-b8c4ffab1b01')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a91c833a-d56f-45de-814c-b8c4ffab1b01 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a91c833a-d56f-45de-814c-b8c4ffab1b01');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":2}]}]}