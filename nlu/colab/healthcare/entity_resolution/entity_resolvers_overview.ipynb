{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"entity_resolvers_overview.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"8ZelAXba3D05"},"source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n","\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/nlu/blob/master/examples/colab/healthcare/entity_resolution/entity_resolvers_overview.ipynb)\n","\n","\n","\n","# Entity Resolution\n","**Named entities** are sub-strings in a text that can be classified into catogires. For example, in the String   \n","`\"Tesla is a great stock to invest  in \"` , the sub-string `\"Tesla\"` is a named entity, it can be classified with the label `company` by an ML algorithm.  \n","**Named entities** can easily be extracted by the various pre-trained Deep Learning based NER algorithms provided by NLU. \n","\n","\n","\n","After extracting **named entities** an **entity resolution algorithm** can be applied to the extracted named entities. The resolution algorithm classifies each extracted entitiy into a class, which reduces dimensionality of the data and has many useful applications. \n","For example : \n","- \"**Tesla** is a great stock to invest in \"\n","- \"**TSLA**  is a great stock to invest  in \"\n","- \"**Tesla, Inc** is a great company to invest in\"    \n","\n","The sub-strings `Tesla` , `TSLA` and `Tesla, Inc` are all named entities, that are classified with the labeld `company` by the NER algorithm. It tells us, all these 3 sub-strings are of type `company`, but we cannot yet infer that these 3 strings are actually referring to literally the same company.    \n","\n","This exact problem is solved by the resolver algorithms, it would resolve all these 3 entities to a common name, like a company ID. This maps every reference of Tesla, regardless of how the string is represented, to the same ID.\n","\n","This example can analogusly be expanded to healthcare any any other text problems. In medical documents, the same disease can be referenced in many different ways. \n","\n","With NLU Healthcare you can leverage state of the art pre-trained NER models to extract **Medical Named Entities** (Diseases, Treatments, Posology, etc..) and **resolve these** to common **healthcare disease codes**.\n","\n","\n","These algorithms are based provided by **Spark NLP for Healthcare's**  [SentenceEntitiyResolver](https://nlp.johnsnowlabs.com/docs/en/licensed_annotators#sentenceentityresolver) and [ChunkEntityResolvers](https://nlp.johnsnowlabs.com/docs/en/licensed_annotators#chunkentityresolver)\n","\n","\n","## Avaiable models\n","\n","\n","\n","\n","\n","\n","All the models avaiable are :\n","\n","\n","| Language | nlu.load() reference                                         | Spark NLP Model reference          |\n","| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |\n","| English  | embed_sentence.biobert.mli | sbiobert_base_cased_mli          |\n","| English  | resolve | sbiobertresolve_cpt          |\n","| English  | resolve.cpt | sbiobertresolve_cpt          |\n","| English  | resolve.cpt.augmented | sbiobertresolve_cpt_augmented          |\n","| English  | resolve.cpt.procedures_augmented | sbiobertresolve_cpt_procedures_augmented          |\n","| English  | resolve.hcc.augmented | sbiobertresolve_hcc_augmented          |\n","| English  | [resolve.icd10cm](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_icd10cm_en.html) | [sbiobertresolve_icd10cm](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_icd10cm_en.html)                   |\n","| English  | [resolve.icd10cm.augmented](https://nlp.johnsnowlabs.com/2020/12/13/sbiobertresolve_icd10cm_augmented_en.html) | [sbiobertresolve_icd10cm_augmented](https://nlp.johnsnowlabs.com/2020/12/13/sbiobertresolve_icd10cm_augmented_en.html)                   |\n","| English  | [resolve.icd10cm.augmented_billable](https://nlp.johnsnowlabs.com/2021/02/06/sbiobertresolve_icd10cm_augmented_billable_hcc_en.html) | [sbiobertresolve_icd10cm_augmented_billable_hcc](https://nlp.johnsnowlabs.com/2021/02/06/sbiobertresolve_icd10cm_augmented_billable_hcc_en.html)                   |\n","| English  | [resolve.icd10pcs](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_icd10pcs_en.html) | [sbiobertresolve_icd10pcs](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_icd10pcs_en.html)                   |\n","| English  | [resolve.icdo](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_icdo_en.html) | [sbiobertresolve_icdo](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_icdo_en.html)                   |\n","| English  | [resolve.rxcui](https://nlp.johnsnowlabs.com/2020/12/11/sbiobertresolve_rxcui_en.html) | [sbiobertresolve_rxcui](https://nlp.johnsnowlabs.com/2020/12/11/sbiobertresolve_rxcui_en.html)                   |\n","| English  | [resolve.rxnorm](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_rxnorm_en.html) | [sbiobertresolve_rxnorm](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_rxnorm_en.html)                   |\n","| English  | [resolve.snomed](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_auxConcepts_en.html) | [sbiobertresolve_snomed_auxConcepts](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_auxConcepts_en.html)                   |\n","| English  | [resolve.snomed.aux_concepts](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_auxConcepts_en.html) | [sbiobertresolve_snomed_auxConcepts](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_auxConcepts_en.html)                   |\n","| English  | [resolve.snomed.aux_concepts_int](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_auxConcepts_int_en.html) | [sbiobertresolve_snomed_auxConcepts_int](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_auxConcepts_int_en.html)                   |\n","| English  | [resolve.snomed.findings](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_findings_en.html) | [sbiobertresolve_snomed_findings](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_findings_en.html)                   |\n","| English  | [resolve.snomed.findings_int](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_findings_int_en.html) | [sbiobertresolve_snomed_findings_int](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_findings_int_en.html)                   |\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OMiHjCtQhF_r","outputId":"4d631ee8-4478-4aab-d481-fea89ee6a07e","executionInfo":{"status":"ok","timestamp":1649994832035,"user_tz":-300,"elapsed":183665,"user":{"displayName":"ahmed lone","userId":"02458088882398909889"}}},"source":["# # Install NLU\n","# # Upload add your spark_nlp_fo\"r_healthcare.json\n","!wget http://setup.johnsnowlabs.com/nlu/colab.sh -O - | bash\n","import nlu"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-04-15 03:50:47--  https://setup.johnsnowlabs.com/nlu/colab.sh\n","Resolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 51.158.130.125\n","Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:443... connected.\n","HTTP request sent, awaiting response... 302 Moved Temporarily\n","Location: https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/scripts/colab_setup.sh [following]\n","--2022-04-15 03:50:47--  https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/scripts/colab_setup.sh\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1665 (1.6K) [text/plain]\n","Saving to: ‘STDOUT’\n","\n","-                   100%[===================>]   1.63K  --.-KB/s    in 0s      \n","\n","2022-04-15 03:50:47 (34.3 MB/s) - written to stdout [1665/1665]\n","\n","Installing  NLU 3.4.3rc2 with  PySpark 3.0.3 and Spark NLP 3.4.2 for Google Colab ...\n","Hit:1 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Get:2 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","Get:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n","Ign:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","Get:5 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Get:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n","Ign:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\n","Get:9 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Hit:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Get:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n","Hit:12 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Get:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n","Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,268 kB]\n","Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,134 kB]\n","Get:18 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [953 kB]\n","Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,947 kB]\n","Get:20 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,695 kB]\n","Get:21 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,490 kB]\n","Get:22 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [996 kB]\n","Get:23 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.3 kB]\n","Fetched 13.8 MB in 4s (3,418 kB/s)\n","Reading package lists... Done\n","tar: spark-3.0.2-bin-hadoop2.7.tgz: Cannot open: No such file or directory\n","tar: Error is not recoverable: exiting now\n","\u001b[K     |████████████████████████████████| 209.1 MB 54 kB/s \n","\u001b[K     |████████████████████████████████| 142 kB 41.6 MB/s \n","\u001b[K     |████████████████████████████████| 505 kB 51.7 MB/s \n","\u001b[K     |████████████████████████████████| 198 kB 58.1 MB/s \n","\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting nlu_tmp==3.4.3rc10\n","  Downloading nlu_tmp-3.4.3rc10-py3-none-any.whl (510 kB)\n","\u001b[K     |████████████████████████████████| 510 kB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from nlu_tmp==3.4.3rc10) (1.21.5)\n","Requirement already satisfied: pyarrow>=0.16.0 in /usr/local/lib/python3.7/dist-packages (from nlu_tmp==3.4.3rc10) (6.0.1)\n","Requirement already satisfied: spark-nlp<3.5.0,>=3.4.2 in /usr/local/lib/python3.7/dist-packages (from nlu_tmp==3.4.3rc10) (3.4.2)\n","Requirement already satisfied: pandas>=1.3.5 in /usr/local/lib/python3.7/dist-packages (from nlu_tmp==3.4.3rc10) (1.3.5)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (from nlu_tmp==3.4.3rc10) (0.6)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.3.5->nlu_tmp==3.4.3rc10) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.3.5->nlu_tmp==3.4.3rc10) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.3.5->nlu_tmp==3.4.3rc10) (1.15.0)\n","Installing collected packages: nlu-tmp\n","Successfully installed nlu-tmp-3.4.3rc10\n"," Spark NLP for Healthcare could not be imported. Installing latest spark-nlp-jsl PyPI package via pip...\n"]},{"output_type":"stream","name":"stderr","text":["WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n","Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n","To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"]},{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://pypi.johnsnowlabs.com/3.5.0-658432c5c0ac83e65947c58ebd7f573e1c72530e\n","Collecting spark-nlp-jsl==3.5.0\n","  Downloading https://pypi.johnsnowlabs.com/3.5.0-658432c5c0ac83e65947c58ebd7f573e1c72530e/spark-nlp-jsl/spark_nlp_jsl-3.5.0-py3-none-any.whl (188 kB)\n","Requirement already satisfied: spark-nlp==3.4.2 in /usr/local/lib/python3.7/dist-packages (from spark-nlp-jsl==3.5.0) (3.4.2)\n","Installing collected packages: spark-nlp-jsl\n","Successfully installed spark-nlp-jsl-3.5.0\n"]},{"output_type":"stream","name":"stderr","text":["WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n","Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n","To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"]},{"output_type":"stream","name":"stdout","text":[" Spark OCR could not be imported. Installing latest spark-ocr PyPI package via pip...\n","Looking in indexes: https://pypi.org/simple, https://pypi.johnsnowlabs.com/3.11.0-4646659d989d80d33c5923922c3b66fd58bc5339\n","Collecting spark-ocr==3.11.0+spark30\n","  Downloading https://pypi.johnsnowlabs.com/3.11.0-4646659d989d80d33c5923922c3b66fd58bc5339/spark-ocr/spark_ocr-3.11.0%2Bspark30-py3-none-any.whl (25.3 MB)\n","Collecting craft-text-detector==0.4.2\n","  Downloading craft_text_detector-0.4.2-py3-none-any.whl (18 kB)\n","Collecting implicits==1.0.2\n","  Downloading implicits-1.0.2-py3-none-any.whl (3.7 kB)\n","Collecting pyspark==3.0.2\n","  Downloading pyspark-3.0.2.tar.gz (204.8 MB)\n","Collecting numpy==1.19.5\n","  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n","Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.7/dist-packages (from spark-ocr==3.11.0+spark30) (0.10.9)\n","Collecting scikit-image==0.18.1\n","  Downloading scikit_image-0.18.1-cp37-cp37m-manylinux1_x86_64.whl (29.2 MB)\n","Collecting pillow==8.1.2\n","  Downloading Pillow-8.1.2-cp37-cp37m-manylinux1_x86_64.whl (2.2 MB)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.7/dist-packages (from craft-text-detector==0.4.2->spark-ocr==3.11.0+spark30) (1.4.1)\n","Requirement already satisfied: opencv-python<4.5.4.62,>=3.4.8.29 in /usr/local/lib/python3.7/dist-packages (from craft-text-detector==0.4.2->spark-ocr==3.11.0+spark30) (4.1.2.30)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from craft-text-detector==0.4.2->spark-ocr==3.11.0+spark30) (1.10.0+cu111)\n","Requirement already satisfied: gdown>=3.10.1 in /usr/local/lib/python3.7/dist-packages (from craft-text-detector==0.4.2->spark-ocr==3.11.0+spark30) (4.4.0)\n","Requirement already satisfied: torchvision>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from craft-text-detector==0.4.2->spark-ocr==3.11.0+spark30) (0.11.1+cu111)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.18.1->spark-ocr==3.11.0+spark30) (1.3.0)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.18.1->spark-ocr==3.11.0+spark30) (2.6.3)\n","Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.18.1->spark-ocr==3.11.0+spark30) (3.2.2)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.18.1->spark-ocr==3.11.0+spark30) (2.4.1)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.18.1->spark-ocr==3.11.0+spark30) (2021.11.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown>=3.10.1->craft-text-detector==0.4.2->spark-ocr==3.11.0+spark30) (3.6.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown>=3.10.1->craft-text-detector==0.4.2->spark-ocr==3.11.0+spark30) (1.15.0)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown>=3.10.1->craft-text-detector==0.4.2->spark-ocr==3.11.0+spark30) (2.23.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown>=3.10.1->craft-text-detector==0.4.2->spark-ocr==3.11.0+spark30) (4.6.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown>=3.10.1->craft-text-detector==0.4.2->spark-ocr==3.11.0+spark30) (4.64.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.18.1->spark-ocr==3.11.0+spark30) (1.4.2)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.18.1->spark-ocr==3.11.0+spark30) (2.8.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.18.1->spark-ocr==3.11.0+spark30) (3.0.8)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.18.1->spark-ocr==3.11.0+spark30) (0.11.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image==0.18.1->spark-ocr==3.11.0+spark30) (4.1.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.10.1->craft-text-detector==0.4.2->spark-ocr==3.11.0+spark30) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.10.1->craft-text-detector==0.4.2->spark-ocr==3.11.0+spark30) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.10.1->craft-text-detector==0.4.2->spark-ocr==3.11.0+spark30) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.10.1->craft-text-detector==0.4.2->spark-ocr==3.11.0+spark30) (2.10)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.10.1->craft-text-detector==0.4.2->spark-ocr==3.11.0+spark30) (1.7.1)\n","Building wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py): started\n","  Building wheel for pyspark (setup.py): finished with status 'done'\n","  Created wheel for pyspark: filename=pyspark-3.0.2-py2.py3-none-any.whl size=205186690 sha256=82c7d08f3cf86461856e345ef32da67830c49612b28c458171b174c54038047f\n","  Stored in directory: /root/.cache/pip/wheels/9a/39/f6/970565f38054a830e9a8593f388b36e14d75dba6c6fdafc1ec\n","Successfully built pyspark\n","Installing collected packages: pillow, numpy, scikit-image, pyspark, implicits, craft-text-detector, spark-ocr\n","  Attempting uninstall: pillow\n","    Found existing installation: Pillow 7.1.2\n","    Uninstalling Pillow-7.1.2:\n","      Successfully uninstalled Pillow-7.1.2\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.21.5\n","    Uninstalling numpy-1.21.5:\n","      Successfully uninstalled numpy-1.21.5\n","  Attempting uninstall: scikit-image\n","    Found existing installation: scikit-image 0.18.3\n","    Uninstalling scikit-image-0.18.3:\n","      Successfully uninstalled scikit-image-0.18.3\n","  Attempting uninstall: pyspark\n","    Found existing installation: pyspark 3.0.3\n","    Uninstalling pyspark-3.0.3:\n","      Successfully uninstalled pyspark-3.0.3\n"]},{"output_type":"stream","name":"stderr","text":["ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n","tensorflow 2.8.0 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\n"]},{"output_type":"stream","name":"stdout","text":["Successfully installed craft-text-detector-0.4.2 implicits-1.0.2 numpy-1.19.5 pillow-8.1.2 pyspark-3.0.2 scikit-image-0.18.1 spark-ocr-3.11.0+spark30\n","Spark version: 3.0.3\n","Spark NLP version: 3.4.2\n","Spark OCR version: 3.11.0\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["<module 'nlu' from '/usr/local/lib/python3.7/dist-packages/nlu/__init__.py'>"]},"metadata":{},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"kbnlNAw_W3Qj"},"source":["#### [Athena Conditions Entity Resolver (Healthcare)](https://nlp.johnsnowlabs.com/2020/09/16/chunkresolve_athena_conditions_healthcare_en.html)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":484},"id":"n7zbAt-SW3Eh","outputId":"6a6db16b-3967-4e8c-a557-865e5410fc0a","executionInfo":{"status":"error","timestamp":1649994857006,"user_tz":-300,"elapsed":24984,"user":{"displayName":"ahmed lone","userId":"02458088882398909889"}}},"source":["data =\"\"\"The patient is a 5-month-old infant who presented initially on Monday with a cold, cough, and runny nose for 2 days. Mom states she had no fever. Her appetite was good but she was spitting up a lot. She had no difficulty breathing and her cough was described as dry and hacky. At that time, physical exam showed a right TM, which was red. Left TM was okay. She was fairly congested but looked happy and playful. She was started on Amoxil and Aldex and we told to recheck in 2 weeks to recheck her ear. Mom returned to clinic again today because she got much worse overnight. She was having difficulty breathing. She was much more congested and her appetite had decreased significantly today. She also spiked a temperature yesterday of 102.6 and always having trouble sleeping secondary to congestion.\"\"\"\n","nlu.load('med_ner.jsl.wip.clinical en.resolve_chunk.cpt_clinical').predict(data, output_level='chunk')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["ner_wikiner_glove_840B_300 download started this may take some time.\n","Approximate size to download 14.8 MB\n","[OK!]\n"]},{"output_type":"error","ename":"Exception","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nlu/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(request, path, verbose, gpu, streamlit_caching)\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0mnlu_component\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlu_ref_to_component\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlu_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m             \u001b[0;31m# if we get a list of components, then the NLU reference is a pipeline, we do not need to check order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nlu/pipe/component_resolution.py\u001b[0m in \u001b[0;36mnlu_ref_to_component\u001b[0;34m(nlu_ref, detect_lang, authenticated)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mresolved_component\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_trained_component_for_nlp_model_ref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlu_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlp_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlicense_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nlu/pipe/component_resolution.py\u001b[0m in \u001b[0;36mget_trained_component_for_nlp_model_ref\u001b[0;34m(lang, nlu_ref, nlp_ref, license_type, model_configs)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             model_configs: Optional[Dict[str, any]] = None) -> NluComponent:\n\u001b[0;32m--> 219\u001b[0;31m     \u001b[0manno_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpellbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlp_ref_to_anno_class\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnlp_ref\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m     \u001b[0mcomponent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manno_class_to_empty_component\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manno_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: None","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-1400222809d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\"The patient is a 5-month-old infant who presented initially on Monday with a cold, cough, and runny nose for 2 days. Mom states she had no fever. Her appetite was good but she was spitting up a lot. She had no difficulty breathing and her cough was described as dry and hacky. At that time, physical exam showed a right TM, which was red. Left TM was okay. She was fairly congested but looked happy and playful. She was started on Amoxil and Aldex and we told to recheck in 2 weeks to recheck her ear. Mom returned to clinic again today because she got much worse overnight. She was having difficulty breathing. She was much more congested and her appetite had decreased significantly today. She also spiked a temperature yesterday of 102.6 and always having trouble sleeping secondary to congestion.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnlu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'med_ner.jsl.wip.clinical en.resolve_chunk.cpt_clinical'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'chunk'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nlu/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(request, path, verbose, gpu, streamlit_caching)\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         raise Exception(\n\u001b[0;32m--> 111\u001b[0;31m             f\"Something went wrong during creating the Spark NLP model for your request =  {request} Did you use a NLU Spell?\")\n\u001b[0m\u001b[1;32m    112\u001b[0m     \u001b[0;31m# Complete Spark NLP Pipeline, which is defined as a DAG given by the starting Annotators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mException\u001b[0m: Something went wrong during creating the Spark NLP model for your request =  med_ner.jsl.wip.clinical en.resolve_chunk.cpt_clinical Did you use a NLU Spell?"]}]},{"cell_type":"markdown","metadata":{"id":"rSUTBWKi6Hb-"},"source":["#### [Sentence Entity Resolver for ICD10-CM (sbiobert_base_cased_mli embeddings)](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_icd10cm_en.html)"]},{"cell_type":"code","metadata":{"id":"emvKNnXE6HBv","executionInfo":{"status":"aborted","timestamp":1649994857000,"user_tz":-300,"elapsed":28,"user":{"displayName":"ahmed lone","userId":"02458088882398909889"}}},"source":["nlu.load(\"med_ner.jsl.wip.clinical en.resolve.icd10cm\").predict(\"\"\"This is an 82 - year-old male with a history of prior tobacco use , hypertension , chronic renal insufficiency , COPD ,\n","gastritis , and TIA who initially presented to Braintree with a non-ST elevation MI and Guaiac positive stools , transferred to St . Margaret\\'s Center for Women & Infants for cardiac\n","catheterization with PTCA to mid LAD lesion complicated by hypotension and bradycardia requiring Atropine , IV fluids and transient dopamine possibly secondary to vagal reaction , \n","subsequently transferred to CCU for close monitoring , hemodynamically stable at the time of admission to the CCU .\"\"\",output_level =  \"sentence\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GlKDEOCrG13g"},"source":["#### [Sentence Entity Resolver for ICD10-PCS (sbiobert_base_cased_mli embeddings)](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_icd10pcs_en.html)"]},{"cell_type":"code","metadata":{"id":"AQjiCfFQG13h","executionInfo":{"status":"aborted","timestamp":1649994857001,"user_tz":-300,"elapsed":29,"user":{"displayName":"ahmed lone","userId":"02458088882398909889"}}},"source":["nlu.load(\"med_ner.jsl.wip.clinical en.resolve.icd10pcs\").predict(\"\"\"This is an 82 - year-old male with a history of prior tobacco use , hypertension , chronic renal insufficiency , COPD ,\n","gastritis , and TIA who initially presented to Braintree with a non-ST elevation MI and Guaiac positive stools , transferred to St . Margaret\\'s Center for Women & Infants for cardiac\n","catheterization with PTCA to mid LAD lesion complicated by hypotension and bradycardia requiring Atropine , IV fluids and transient dopamine possibly secondary to vagal reaction , \n","subsequently transferred to CCU for close monitoring , hemodynamically stable at the time of admission to the CCU .\"\"\",output_level =  \"sentence\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lMep62x_G2AS"},"source":["#### [Sentence Entity Resolver for RxCUI (sbiobert_base_cased_mli embeddings)](https://nlp.johnsnowlabs.com/2020/12/11/sbiobertresolve_rxcui_en.html)"]},{"cell_type":"code","metadata":{"id":"i4Jaj97KG2AT","executionInfo":{"status":"aborted","timestamp":1649994857002,"user_tz":-300,"elapsed":30,"user":{"displayName":"ahmed lone","userId":"02458088882398909889"}}},"source":["nlu.load(\"med_ner.jsl.wip.clinical en.resolve.rxcui\").predict(\"He was seen by the endocrinology service and she was discharged on 50 mg of eltrombopag oral at night, 5 mg amlodipine with meals, and metformin 1000 mg two times a day\",output_level =  \"sentence\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vifO7xR_LOhj"},"source":["#### [Sentence Entity Resolver for RxNorm (sbiobert_base_cased_mli embeddings)](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_rxnorm_en.html)"]},{"cell_type":"code","metadata":{"id":"m8cBuMRsLOhu","executionInfo":{"status":"aborted","timestamp":1649994857002,"user_tz":-300,"elapsed":29,"user":{"displayName":"ahmed lone","userId":"02458088882398909889"}}},"source":["import nlu\n","nlu.load(\"med_ner.jsl.wip.clinical en.resolve.rxnorm\").predict(\"\"\"This is an 82 - year-old male with a history of prior tobacco use , hypertension , chronic renal insufficiency , COPD ,\n","gastritis , and TIA who initially presented to Braintree with a non-ST elevation MI and Guaiac positive stools , transferred to St . Margaret\\'s Center for Women & Infants for cardiac\n","catheterization with PTCA to mid LAD lesion complicated by hypotension and bradycardia requiring Atropine , IV fluids and transient dopamine possibly secondary to vagal reaction , \n","subsequently transferred to CCU for close monitoring , hemodynamically stable at the time of admission to the CCU .\"\"\",output_level =  \"sentence\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c4y2ZMaeLOro"},"source":["#### [Sentence Entity Resolver for Snomed Concepts, INT version (sbiobert_base_cased_mli embeddings)](https://nlp.johnsnowlabs.com/2020/11/27/sbiobertresolve_snomed_findings_int_en.html)"]},{"cell_type":"code","metadata":{"id":"XRmbCMNULOrq","executionInfo":{"status":"aborted","timestamp":1649994857003,"user_tz":-300,"elapsed":30,"user":{"displayName":"ahmed lone","userId":"02458088882398909889"}}},"source":["nlu.load(\"med_ner.jsl.wip.clinical en.resolve.snomed.findings_int\").predict(\"\"\"This is an 82 - year-old male with a history of prior tobacco use , hypertension , chronic renal insufficiency , COPD ,\n","gastritis , and TIA who initially presented to Braintree with a non-ST elevation MI and Guaiac positive stools , transferred to St . Margaret\\'s Center for Women & Infants for cardiac\n","catheterization with PTCA to mid LAD lesion complicated by hypotension and bradycardia requiring Atropine , IV fluids and transient dopamine possibly secondary to vagal reaction , \n","subsequently transferred to CCU for close monitoring , hemodynamically stable at the time of admission to the CCU .\"\"\",output_level =  \"sentence\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f_mvF_EQj86x","executionInfo":{"status":"aborted","timestamp":1649994857005,"user_tz":-300,"elapsed":32,"user":{"displayName":"ahmed lone","userId":"02458088882398909889"}}},"source":["  "],"execution_count":null,"outputs":[]}]}