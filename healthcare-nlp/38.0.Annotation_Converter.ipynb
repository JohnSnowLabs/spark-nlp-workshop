{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uFFIGHtcRWT"
      },
      "source": [
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3_Ubc7ScUe2"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/healthcare-nlp/38.0.Annotation_Converter.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you are using the `spark-nlp-jsl` library, please use this ¬†[50.Annotation_Converter](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/50.Annotation_Converter.ipynb) notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ2JWggt-UYX"
      },
      "source": [
        "#   **üìú AnnotationConverter**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hzwkXPoKY5I"
      },
      "source": [
        "This notebook introduces a flexible **AnnotationConverter** ‚Äî a lightweight Python class designed to help you transform annotations within a DataFrame using custom conversion functions. It is especially useful when you need to reformat or reinterpret annotation results from one type to another.\n",
        "\n",
        "For example, you can use it to:\n",
        "\n",
        "\n",
        "\n",
        "- Reformat LLM outputs into document-style annotations\n",
        "\n",
        "- Convert assertion results into chunk annotations\n",
        "\n",
        "- Adapt rule-based outputs into a consistent, usable format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e726rKETuJJr"
      },
      "source": [
        "**üìñ Learning Objectives:**\n",
        "\n",
        "1. Understand how to use the annotator.\n",
        "\n",
        "2. Become comfortable using the different parameters of the annotator.\n",
        "\n",
        "**üîó Helpful Links:**\n",
        "\n",
        "- Reference Documentation: [AnnotationConverter](https://nlp.johnsnowlabs.com/docs/en/licensed_annotators#annotationconverter)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBTuAaNIaE-n"
      },
      "source": [
        "## **üñ®Ô∏è Input/Output Annotation Types**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnFxBtrjaJyP"
      },
      "source": [
        "- Input: `ANY`\n",
        "\n",
        "- Output: `ANY`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLbYplk2a30Z"
      },
      "source": [
        "## **üîé Parameters**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzlkaWUZa7KN"
      },
      "source": [
        "**Parameters**:\n",
        "\n",
        "\n",
        "- `f`: (FunctionParam) User-defined function to transform annotations.\n",
        "\n",
        "- `inputCol`: Name of the input column containing annotations.\n",
        "\n",
        "- `outputCol`:  Name of the output column for converted annotations.\n",
        "\n",
        "- `outputAnnotatorType`: Type of the output annotations (e.g., ‚Äútoken‚Äù).\n",
        "\n",
        "\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tpg_UM9GqECW"
      },
      "source": [
        "## Healthcare NLP for Data Scientists Course\n",
        "\n",
        "If you are not familiar with the components in this notebook, you can check [Healthcare NLP for Data Scientists Udemy Course](https://www.udemy.com/course/healthcare-nlp-for-data-scientists/) and the [MOOC Notebooks](https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP) for each components."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ogi3CU-CgjR"
      },
      "source": [
        "## Colab Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELqzaf32MT6E"
      },
      "outputs": [],
      "source": [
        "# Install the johnsnowlabs library to access Spark-OCR and Spark-NLP for Healthcare, Finance, and Legal.\n",
        "! pip install -q johnsnowlabs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RO2dIA414yL_"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "print('Please Upload your John Snow Labs License using the button below')\n",
        "license_keys = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hr2Fq3FfgWhZ"
      },
      "outputs": [],
      "source": [
        "from johnsnowlabs import nlp, medical\n",
        "\n",
        "# After uploading your license run this to install all licensed Python Wheels and pre-download Jars the Spark Session JVM\n",
        "nlp.settings.enforce_versions=True\n",
        "nlp.install(refresh_install=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAVx7MX9mtA2"
      },
      "outputs": [],
      "source": [
        "from johnsnowlabs import nlp, medical\n",
        "# Automatically load license data and start a session with all jars user has access to\n",
        "\n",
        "spark = nlp.start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "lQ8-BI-_5QjG",
        "outputId": "244248c6-c102-4775-da28-e36cf6105d07"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://2bd7d86e7f80:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.4.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>John-Snow-Labs-Spark-Session üöÄ with Jars for: üöÄSpark-NLP==6.1.3, üíäSpark-Healthcare==6.1.1, running on ‚ö° PySpark==3.4.0</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x78be9c0d6ff0>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "guXFthmRBnLk"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import DataFrame\n",
        "import pyspark.sql.functions as F\n",
        "import pyspark.sql.types as T\n",
        "import pyspark.sql as SQL\n",
        "from pyspark import keyword_only\n",
        "from sparknlp_jsl.pipeline_tracer import PipelineTracer\n",
        "\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.expand_frame_repr', False)\n",
        "pd.set_option('max_colwidth', None)\n",
        "\n",
        "import re\n",
        "import json\n",
        "import string\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICcnDujCGv5G"
      },
      "source": [
        "## Create Custom Annotators"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pd9i0geiLXxS"
      },
      "source": [
        "###  Custom SentenceDetector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ert8JOORLn_F",
        "outputId": "bb7a3aea-2745-4b68-c69b-8dac6bcd0a1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "document_assembler = nlp.DocumentAssembler()\\\n",
        "    .setInputCol('text')\\\n",
        "    .setOutputCol('document')\n",
        "\n",
        "def custom_sentence_detector(annotations):\n",
        "    new_annotations = []\n",
        "    # This pattern splits on periods, exclamation marks, and question marks\n",
        "    # followed by whitespace or the end of the string.\n",
        "    pattern = r\"(?<=[.!?])\\s+\"\n",
        "\n",
        "    for annotation in annotations: # annotations here are document annotations\n",
        "        document_text = annotation.result\n",
        "        document_begin = annotation.begin\n",
        "        sentences = re.split(pattern, document_text)\n",
        "        current_relative_index = 0\n",
        "        for sentence in sentences:\n",
        "            if sentence:\n",
        "                # Find the sentence within the document text starting from the current relative index\n",
        "                relative_begin = document_text.find(sentence, current_relative_index)\n",
        "                if relative_begin != -1:\n",
        "                    relative_end = relative_begin + len(sentence) - 1\n",
        "                    # Calculate absolute begin and end indices relative to the original document\n",
        "                    absolute_begin = document_begin + relative_begin\n",
        "                    absolute_end = document_begin + relative_end\n",
        "\n",
        "                    new_annotations.append(\n",
        "                        nlp.Annotation(\n",
        "                            annotatorType=\"document\", # Sentence annotations are typically 'document' type\n",
        "                            begin=absolute_begin,\n",
        "                            end=absolute_end,\n",
        "                            result=sentence,\n",
        "                            metadata=annotation.metadata,\n",
        "                            embeddings=annotation.embeddings,\n",
        "                        )\n",
        "                    )\n",
        "                    # Update the current relative index for finding the next sentence within the document\n",
        "                    # Need to account for the delimiter that was split on\n",
        "                    current_relative_index = relative_end + 1 + (document_text[relative_end+1:].find(sentence,0) - relative_begin if relative_end + 1 < len(document_text) else 0)\n",
        "    return new_annotations\n",
        "\n",
        "\n",
        "custom_sentence_detector_converter = medical.AnnotationConverter(f=custom_sentence_detector)\\\n",
        "    .setInputCol(\"document\")\\\n",
        "    .setOutputCol(\"custom_sentence\")\\\n",
        "    .setOutputAnnotatorType(\"document\") # Output type is 'document' for sentences\n",
        "\n",
        "\n",
        "pipeline = nlp.Pipeline(\n",
        "    stages=[\n",
        "        document_assembler,\n",
        "        custom_sentence_detector_converter\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YlAe02ELn8d",
        "outputId": "87102cf8-58a4-4d2d-8318-27b8c692a3a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------------------+-----+---+---------------+\n",
            "|result                                                        |begin|end|meta           |\n",
            "+--------------------------------------------------------------+-----+---+---------------+\n",
            "|I like SparkNLP.                                              |0    |15 |{sentence -> 0}|\n",
            "|Especially MedicalBertForSequenceClassification and Chunk2Doc.|17   |78 |{sentence -> 0}|\n",
            "+--------------------------------------------------------------+-----+---+---------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "text = \"I like SparkNLP. Especially MedicalBertForSequenceClassification and Chunk2Doc.\"\n",
        "test_data = spark.createDataFrame([[text]]).toDF(\"text\")\n",
        "\n",
        "result = pipeline.fit(test_data).transform(test_data)\n",
        "result.selectExpr(\"explode (custom_sentence) as sentence\")\\\n",
        "      .selectExpr(\"sentence.result\", \"sentence.begin\", \"sentence.end\", \"sentence.metadata as meta\")\\\n",
        "      .show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYfMO35KLFpZ"
      },
      "source": [
        "###  Custom Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0ebTaO7_8x9",
        "outputId": "302d20e4-b018-426e-99b5-1a0f664d4b34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'token': 'I', 'begin': 0, 'end': 0}, {'token': 'like', 'begin': 2, 'end': 5}, {'token': 'Spark', 'begin': 7, 'end': 11}, {'token': 'NLP', 'begin': 12, 'end': 14}, {'token': '.', 'begin': 15, 'end': 15}, {'token': 'Especially', 'begin': 17, 'end': 26}, {'token': 'Medical', 'begin': 28, 'end': 34}, {'token': 'Bert', 'begin': 35, 'end': 38}, {'token': 'For', 'begin': 39, 'end': 41}, {'token': 'Sequence', 'begin': 42, 'end': 49}, {'token': 'Classification', 'begin': 50, 'end': 63}, {'token': 'and', 'begin': 65, 'end': 67}, {'token': 'Chunk2Doc', 'begin': 69, 'end': 77}, {'token': '.', 'begin': 78, 'end': 78}]\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "text = \"I like SparkNLP. Especially MedicalBertForSequenceClassification and Chunk2Doc.\"\n",
        "\n",
        "# This pattern finds the parts to split on (whitespace, punctuation, camel case transitions)\n",
        "pattern_split = r\"(?<=[a-z])(?=[A-Z])|(?<=[A-Z])(?=[A-Z][a-z])|\\s+|(?=[^\\w\\s\\/\\-])|(?<=[^\\w\\s\\/\\-])\"\n",
        "\n",
        "parts = re.split(pattern_split, text)\n",
        "\n",
        "# Recalculate indices based on the original text and the split parts\n",
        "tokens_with_indices = []\n",
        "current_index = 0\n",
        "for part in parts:\n",
        "    if part:\n",
        "        begin = text.find(part, current_index)\n",
        "        if begin != -1:\n",
        "            end = begin + len(part) - 1\n",
        "            tokens_with_indices.append({ \"token\": part, \"begin\": begin, \"end\": end })\n",
        "            current_index = end + 1 # Move current index past the found part\n",
        "print(tokens_with_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnyhBSH3-4BM",
        "outputId": "42421b98-98a5-4d06-df30-185aeaf13b8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "document_assembler = nlp.DocumentAssembler()\\\n",
        "    .setInputCol('text')\\\n",
        "    .setOutputCol('document')\n",
        "\n",
        "sentence_detector = nlp.SentenceDetector()\\\n",
        "    .setInputCols([\"document\"])\\\n",
        "    .setOutputCol(\"sentence\")\\\n",
        "\n",
        "def tokenize_camel_case(annotations):\n",
        "    new_annotations = []\n",
        "    pattern = r\"(?<=[a-z])(?=[A-Z])|(?<=[A-Z])(?=[A-Z][a-z])|\\s+|(?=[^\\w\\s\\/\\-])|(?<=[^\\w\\s\\/\\-])\"\n",
        "\n",
        "    for annotation in annotations: # annotations here are sentences\n",
        "        sentence_text = annotation.result\n",
        "        sentence_begin = annotation.begin\n",
        "        parts = re.split(pattern, sentence_text)\n",
        "        current_relative_index = 0\n",
        "        for part in parts:\n",
        "            if part:\n",
        "                # Find the part within the sentence text starting from the current relative index\n",
        "                relative_begin = sentence_text.find(part, current_relative_index)\n",
        "                if relative_begin != -1:\n",
        "                    relative_end = relative_begin + len(part) - 1\n",
        "                    # Calculate absolute begin and end indices relative to the original document\n",
        "                    absolute_begin = sentence_begin + relative_begin\n",
        "                    absolute_end = sentence_begin + relative_end\n",
        "\n",
        "                    new_annotations.append(\n",
        "                        nlp.Annotation(\n",
        "                            annotatorType=\"token\",\n",
        "                            begin=absolute_begin,\n",
        "                            end=absolute_end,\n",
        "                            result=part,\n",
        "                            metadata=annotation.metadata,\n",
        "                            embeddings=annotation.embeddings,\n",
        "                        )\n",
        "                    )\n",
        "                    # Update the current relative index for finding the next part within the sentence\n",
        "                    current_relative_index = relative_end + 1\n",
        "    return new_annotations\n",
        "\n",
        "\n",
        "camel_case_tokenizer = medical.AnnotationConverter(f=tokenize_camel_case)\\\n",
        "    .setInputCol(\"sentence\")\\\n",
        "    .setOutputCol(\"camel_case_token\")\\\n",
        "    .setOutputAnnotatorType(\"token\")\n",
        "\n",
        "pipeline = nlp.Pipeline(\n",
        "    stages=[\n",
        "        document_assembler,\n",
        "        sentence_detector,\n",
        "        camel_case_tokenizer\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AyTuHyl_heU",
        "outputId": "2b0c42e1-f85f-4a4f-db59-7139c468988b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------+-----+---+-------+\n",
            "|result        |begin|end|sent_id|\n",
            "+--------------+-----+---+-------+\n",
            "|I             |0    |0  |0      |\n",
            "|like          |2    |5  |0      |\n",
            "|Spark         |7    |11 |0      |\n",
            "|NLP           |12   |14 |0      |\n",
            "|.             |15   |15 |0      |\n",
            "|Especially    |17   |26 |1      |\n",
            "|Medical       |28   |34 |1      |\n",
            "|Bert          |35   |38 |1      |\n",
            "|For           |39   |41 |1      |\n",
            "|Sequence      |42   |49 |1      |\n",
            "|Classification|50   |63 |1      |\n",
            "|and           |65   |67 |1      |\n",
            "|Chunk2Doc     |69   |77 |1      |\n",
            "|.             |78   |78 |1      |\n",
            "+--------------+-----+---+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "text = \"I like SparkNLP. Especially MedicalBertForSequenceClassification and Chunk2Doc.\"\n",
        "test_data = spark.createDataFrame([[text]]).toDF(\"text\")\n",
        "\n",
        "result = pipeline.fit(test_data).transform(test_data)\n",
        "result.selectExpr(\"explode (camel_case_token) as cct\")\\\n",
        "      .selectExpr(\"cct.result\", \"cct.begin\", \"cct.end\", \"cct.metadata.sentence as sent_id\")\\\n",
        "      .show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYbjWzZupaOT"
      },
      "source": [
        "### Custom LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejiruRNF18zr"
      },
      "outputs": [],
      "source": [
        "!pip install -q optimum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHzLismeV36n",
        "outputId": "aabfee24-330b-417b-c938-c13fb5b1f99d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------------------------------------------------------+\n",
            "|text                                                      |\n",
            "+----------------------------------------------------------+\n",
            "|what is the causes for diabetes?                          |\n",
            "|what is the relationship between diabetes and obesity?    |\n",
            "|what is the relationship childhood diabetes and mortality?|\n",
            "+----------------------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "question_list = [\n",
        "    [\"what is the causes for diabetes?\"],\n",
        "    [\"what is the relationship between diabetes and obesity?\"],\n",
        "    [\"what is the relationship childhood diabetes and mortality?\"]\n",
        "]\n",
        "spark_df = spark.createDataFrame(question_list).toDF(\"text\")\n",
        "spark_df.show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56xdY1O8V33s",
        "outputId": "c3ae5b5b-8f1d-4cff-bb72-28940d877153"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import sparknlp\n",
        "import sparknlp_jsl\n",
        "\n",
        "document_assembler = nlp.DocumentAssembler()\\\n",
        "    .setInputCol('text')\\\n",
        "    .setOutputCol('document')\n",
        "\n",
        "_tokenizer = None\n",
        "_model = None\n",
        "\n",
        "def make_custom_llm():\n",
        "    def custom_llm(annotations):\n",
        "        global _tokenizer, _model\n",
        "\n",
        "        if _tokenizer is None or _model is None:\n",
        "            from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "            import torch\n",
        "\n",
        "            MODEL_NAME = \"Qwen/Qwen2.5-3B\"\n",
        "            device = \"auto\"\n",
        "            _tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "            _model = AutoModelForCausalLM.from_pretrained(MODEL_NAME,device_map=device)\n",
        "\n",
        "        def get_prediction(messages):\n",
        "            input_ids = _tokenizer.apply_chat_template(\n",
        "                messages,\n",
        "                add_generation_prompt=True,\n",
        "                return_tensors=\"pt\"\n",
        "            ).to(_model.device)\n",
        "\n",
        "\n",
        "            def get_eos_token_id(tokenizer):\n",
        "              # √ñncelikle direkt tanƒ±mlƒ± olanƒ± al\n",
        "              if tokenizer.eos_token_id is not None:\n",
        "                  return tokenizer.eos_token_id\n",
        "\n",
        "              # Alternatif token adlarƒ±nƒ± dene\n",
        "              candidates = [\"<|eot_id|>\", \"<|endoftext|>\", \"</s>\"]\n",
        "              for tok in candidates:\n",
        "                  tok_id = tokenizer.convert_tokens_to_ids(tok)\n",
        "                  if isinstance(tok_id, int):\n",
        "                      return tok_id\n",
        "\n",
        "              raise ValueError(\"No valid eos_token_id found.\")\n",
        "\n",
        "            eos_token_id = get_eos_token_id(_tokenizer)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = _model.generate(\n",
        "                    input_ids,\n",
        "                    max_new_tokens=1024,\n",
        "                    eos_token_id=eos_token_id,\n",
        "                    do_sample=True,\n",
        "                    temperature=0.1,\n",
        "                    top_p=0.5,\n",
        "                )\n",
        "            response = outputs[0][input_ids.shape[-1]:]\n",
        "            return _tokenizer.decode(response, skip_special_tokens=True)\n",
        "\n",
        "        def generate_input_messages(USER_PROMPT):\n",
        "            SYSTEM_PROMPT = \"You are a smart and intelligent medical assistant system.\"\n",
        "            messages = [\n",
        "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "                {\"role\": \"user\", \"content\": f\"{USER_PROMPT}\"},\n",
        "            ]\n",
        "            return messages\n",
        "\n",
        "        new_annotations = []\n",
        "        for annotation in annotations:\n",
        "            document_text = annotation.result\n",
        "            messages = generate_input_messages(document_text)\n",
        "            response = get_prediction(messages)\n",
        "            result = response.strip()\n",
        "\n",
        "            new_annotations.append(\n",
        "                nlp.Annotation(\n",
        "                    annotatorType=\"document\",\n",
        "                    begin=0,\n",
        "                    end=len(result) - 1,\n",
        "                    result=result,\n",
        "                    metadata=annotation.metadata,\n",
        "                    embeddings=annotation.embeddings,\n",
        "                )\n",
        "            )\n",
        "        return new_annotations\n",
        "    return custom_llm\n",
        "\n",
        "custom_llm_fn = make_custom_llm()\n",
        "\n",
        "custom_llm_converter = medical.AnnotationConverter(f=custom_llm_fn)\\\n",
        "    .setInputCol(\"document\")\\\n",
        "    .setOutputCol(\"generation\")\\\n",
        "    .setOutputAnnotatorType(\"document\")\n",
        "\n",
        "pipeline = nlp.Pipeline(\n",
        "    stages=[\n",
        "        document_assembler,\n",
        "        custom_llm_converter\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plK06QGhuC2n",
        "outputId": "fe74b7ef-7678-48c1-ebb6-2239d3f582dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------+-----+-----+-----------------+\n",
            "|                                                      text|                                                                                                                                                result|begin|  end|             meta|\n",
            "+----------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------+-----+-----+-----------------+\n",
            "|                          what is the causes for diabetes?|[Diabetes is a chronic condition that affects how your body regulates blood sugar (glucose) levels. There are two main types of diabetes: Type 1 an...|  [0]|[683]|[{sentence -> 0}]|\n",
            "|    what is the relationship between diabetes and obesity?|[Diabetes and obesity are closely related conditions. Obesity is a major risk factor for developing type 2 diabetes, and people with obesity are mo...|  [0]|[648]|[{sentence -> 0}]|\n",
            "|what is the relationship childhood diabetes and mortality?|[Childhood diabetes, also known as type 1 diabetes, is a chronic condition that occurs when the pancreas produces little or no insulin. Insulin is ...|  [0]|[551]|[{sentence -> 0}]|\n",
            "+----------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------+-----+-----+-----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result = pipeline.fit(spark_df).transform(spark_df).cache()\n",
        "\n",
        "result.selectExpr(\"text\",\n",
        "                  \"generation.result\",\n",
        "                  \"generation.begin\",\n",
        "                  \"generation.end\",\n",
        "                  \"generation.metadata as meta\")\\\n",
        "      .show(truncate=150)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bWo0p1kuCjH",
        "outputId": "f6fcd386-09fa-4c11-91ea-2e23c2ed2b24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|result                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|[Diabetes is a chronic condition that affects how your body regulates blood sugar (glucose) levels. There are two main types of diabetes: Type 1 and Type 2. Type 1 diabetes is an autoimmune disease where the body's immune system attacks and destroys the insulin-producing cells in the pancreas. This results in a lack of insulin, which is necessary for cells to absorb glucose from the bloodstream. Type 2 diabetes is characterized by insulin resistance, where the body's cells do not respond effectively to insulin, leading to high blood sugar levels. Other factors that can contribute to diabetes include obesity, physical inactivity, genetic predisposition, and certain medications.]|\n",
            "|[Diabetes and obesity are closely related conditions. Obesity is a major risk factor for developing type 2 diabetes, and people with obesity are more likely to develop type 2 diabetes than those who are not obese. Obesity can also make it more difficult to manage diabetes, as it can lead to insulin resistance and other complications. Additionally, obesity can increase the risk of developing other health problems, such as heart disease and stroke, which can further complicate diabetes management. Therefore, it is important for people with diabetes to work to manage their weight and reduce their risk of developing obesity-related complications.]                                   |\n",
            "|[Childhood diabetes, also known as type 1 diabetes, is a chronic condition that occurs when the pancreas produces little or no insulin. Insulin is a hormone that helps regulate blood sugar levels. Children with type 1 diabetes must take insulin injections or use an insulin pump to manage their blood sugar levels. If not managed properly, type 1 diabetes can lead to serious complications, including kidney failure, heart disease, and blindness. However, with proper management and care, children with type 1 diabetes can lead healthy and active lives.]                                                                                                                                    |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result.selectExpr(\"generation.result\").show(truncate=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
