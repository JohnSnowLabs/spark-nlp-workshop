{"cells":[{"cell_type":"markdown","metadata":{"id":"i8W51t04BN6B"},"source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"]},{"cell_type":"markdown","metadata":{"id":"21lTnEqRBd0s"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/healthcare-nlp/09.0.Contextual_Parser_Rule_Based_NER.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"3-vwpSj3BSbj"},"source":["# ContextualParser (Rule Based NER)"]},{"cell_type":"markdown","metadata":{"id":"5SBh1CNgOg54"},"source":["## Colab Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mcD06kzJDl-x"},"outputs":[],"source":["# Install the johnsnowlabs library to access Spark-OCR and Spark-NLP for Healthcare, Finance, and Legal.\n","! pip install -q johnsnowlabs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uzFtUM7zDmE6"},"outputs":[],"source":["from google.colab import files\n","print('Please Upload your John Snow Labs License using the button below')\n","license_keys = files.upload()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PRUIn1o0DZyA"},"outputs":[],"source":["from johnsnowlabs import nlp, medical, visual\n","\n","# After uploading your license run this to install all licensed Python Wheels and pre-download Jars the Spark Session JVM\n","nlp.install()"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"opFwEd2sDc9b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689328587171,"user_tz":-120,"elapsed":18969,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"}},"outputId":"ac27e902-8111-4aaf-a285-4c2e0f93d600"},"outputs":[{"output_type":"stream","name":"stdout","text":["ðŸ‘Œ Detected license file /content/5.0.0.spark_nlp_for_healthcare.json\n","ðŸ‘Œ Launched \u001b[92mcpu optimized\u001b[39m session with with: ðŸš€Spark-NLP==5.0.0, ðŸ’ŠSpark-Healthcare==5.0.0, running on âš¡ PySpark==3.1.2\n"]}],"source":["from johnsnowlabs import nlp, medical, visual\n","import pandas as pd\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Automatically load license data and start a session with all jars user has access to\n","spark = nlp.start()"]},{"cell_type":"markdown","metadata":{"id":"xZzN6yNBvb2b"},"source":["# How the ContextualParser Works"]},{"cell_type":"markdown","metadata":{"id":"nSO62FEY0iof"},"source":["Spark NLP's `ContextualParser` is a licensed annotator that allows users to extract entities from a document based on pattern matching. It provides more functionality than its open-source counterpart `EntityRuler` by allowing users to customize specific characteristics for pattern matching. You're able to find entities using regex rules for full and partial matches, a dictionary with normalizing options and context parameters to take into account things such as token distances.\n","\n","There are 3 components necessary to understand when using the `ContextualParser` annotator:\n","\n","1. `ContextualParser` annotator's parameters\n","2. JSON configuration file\n","3. Dictionary"]},{"cell_type":"markdown","metadata":{"id":"T0_3bAzaPbip"},"source":["## 1. ContextualParser Annotator Parameters"]},{"cell_type":"markdown","metadata":{"id":"PTSYc7RUQgKh"},"source":["Here are all the parameters available to use with the `ContextualParserApproach`:"]},{"cell_type":"markdown","metadata":{"id":"vF4_Dm7qVTty"},"source":["```\n","contextualParser = medical.ContextualParserApproach() \\\n","    .setInputCols([\"sentence\", \"token\"]) \\\n","    .setOutputCol(\"entity\") \\\n","    .setCaseSensitive(True) \\\n","    .setJsonPath(\"context_config.json\") \\\n","    .setPrefixAndSuffixMatch(True) \\\n","    .setCompleteContextMatch(True) \\\n","    .setDictionary(\"dictionary.tsv\", options={\"orientation\":\"vertical\"})\n","```\n"]},{"cell_type":"markdown","metadata":{"id":"uVmRKjoBZ7HQ"},"source":["We will dive deeper into the details of each parameter, but here's a quick overview:\n","\n","- `setCaseSensitive`: do you want the matching to be case sensitive (applies to all JSON properties apart from the regex property)\n","- `setJsonPath`: the path to your JSON configuration file\n","- `setPrefixAndSuffixMatch`: do you want to match using both the prefix AND suffix properties from the JSON configuration file\n","- `setCompleteContextMatch`: do you want an exact match of prefix and suffix.\n","- `setDictionary`: the path to your dictionary, used for normalizing entities\n","\n","Let's start by looking at the JSON configuration file."]},{"cell_type":"markdown","metadata":{"id":"GVO5m215TjXf"},"source":["## 2. JSON Configuration File"]},{"cell_type":"markdown","metadata":{"id":"HNJr5ISlaJsl"},"source":["Here is a fully utilized JSON configuration file."]},{"cell_type":"markdown","metadata":{"id":"4q1UuczZVhD_"},"source":["```\n","{\n","  \"entity\": \"Gender\",\n","  \"ruleScope\": \"sentence\",\n","  \"regex\": \"girl|boy\",\n","  \"completeMatchRegex\": \"true\",\n","  \"matchScope\": \"token\",\n","  \"prefix\": [\"birth\", \"growing\", \"assessment\"],\n","  \"suffix\": [\"faster\", \"velocities\"],\n","  \"contextLength\": 100,\n","  \"contextException\": [\"slightly\"],\n","  \"exceptionDistance\": 40\n"," }\n"," ```"]},{"cell_type":"markdown","metadata":{"id":"GChnk1cXaUIZ"},"source":["### 2.1. Basic Properties"]},{"cell_type":"markdown","metadata":{"id":"p-kJhmUe0f13"},"source":["There are 5 basic properties you can set in your JSON configuration file:\n","\n","- `entity`\n","- `ruleScope`\n","- `regex`\n","- `completeMatchRegex`\n","- `matchScope`\n","\n","Let's first look at the 3 most essential properties to set:"]},{"cell_type":"markdown","metadata":{"id":"7RP8mwtgVkcj"},"source":["```\n","{\n","  \"entity\": \"Digit\",\n","  \"ruleScope\": \"sentence\",\n","  \"regex\": \"\\\\d+\" # Note here: backslashes are escape characters in JSON, so for regex pattern \"\\d+\" we need to write it out as \"\\\\d+\"\n","}\n","```"]},{"cell_type":"markdown","metadata":{"id":"pHSsBgoNcJiw"},"source":["Here, we're looking for tokens in our text that match the regex: \"`\\d+`\" and assign the \"`Digit`\" entity to those tokens. When `ruleScope` is set to \"`sentence`\", we're looking for a match on each *token* of a **sentence**. You can change it to \"`document`\" to look for a match on each *sentence* of a **document**. The latter is particularly useful when working with multi-word matches, but we'll explore this at a later stage.\n","\n","The next properties to look at are `completeMatchRegex` and `matchScope`. To understand their use case, let's take a look at an example where we're trying to match all digits in our text.\n","\n","Let's say we come across the following string: ***XYZ987***\n","\n","Depending on how we set the `completeMatchRegex` and `matchScope` properties, we'll get the following results:"]},{"cell_type":"markdown","metadata":{"id":"tOxfFn8_VngD"},"source":["```\n","{\n","  \"entity\": \"Digit\",\n","  \"ruleScope\": \"sentence\",\n","  \"regex\": \"\\\\d+\",\n","  \"completeMatchRegex\": \"false\",\n","  \"matchScope\": \"token\"\n","}\n","```"]},{"cell_type":"markdown","metadata":{"id":"dZzkfdtDyavl"},"source":["`OUTPUT: [XYZ987]`"]},{"cell_type":"markdown","metadata":{"id":"K37Ucw75Vrog"},"source":["```\n","{\n","  \"entity\": \"Digit\",\n","  \"ruleScope\": \"sentence\",\n","  \"regex\": \"\\\\d+\",  \n","  \"completeMatchRegex\": \"false\",\n","  \"matchScope\": \"sub-token\"\n","}\n","```"]},{"cell_type":"markdown","metadata":{"id":"CkOfYVHGyb20"},"source":["`OUTPUT: [987]`\n"]},{"cell_type":"markdown","metadata":{"id":"9Jpr2IkFVwKw"},"source":["```\n","{\n","  \"entity\": \"Digit\",\n","  \"ruleScope\": \"sentence\",\n","  \"regex\": \"\\\\d+\",\n","  \"completeMatchRegex\": \"true\"\n","  # matchScope is ignored here\n","}\n","```"]},{"cell_type":"markdown","metadata":{"id":"ZiYD0oF7gJtw"},"source":["`OUTPUT: []`"]},{"cell_type":"markdown","metadata":{"id":"bFE9Ri2N4xxT"},"source":["`\"completeMatchRegex\": \"true\"` will only return an output if our string was modified in the following way (to get a complete, exact match): **XYZ 987**"]},{"cell_type":"markdown","metadata":{"id":"L-_sXg5l5NBg"},"source":["```\n","{\n","  \"entity\": \"Digit\",\n","  \"ruleScope\": \"sentence\",\n","  \"regex\": \"\\\\d+\",  \n","  \"completeMatchRegex\": \"true\",\n","  \"matchScope\": \"token\" # Note here: sub-token would return the same output\n","}\n","```"]},{"cell_type":"markdown","metadata":{"id":"zUeuct_05p3f"},"source":["`OUTPUT: [987]`"]},{"cell_type":"markdown","metadata":{"id":"ZlIUAPKazpT9"},"source":["### 2.2. Context Awareness Properties"]},{"cell_type":"markdown","metadata":{"id":"9D2UfFFBz7fX"},"source":["There are 5 properties related to context awareness:\n","\n","- `contextLength`\n","- `prefix`\n","- `suffix`\n","- `contextException`\n","- `exceptionDistance`\n","\n"]},{"cell_type":"markdown","metadata":{"id":"IcUlaqmgDL9R"},"source":["Let's look at a similar example. Say we have the following text: ***At birth, the typical boy is growing slightly faster than the typical girl, but growth rates become equal at about seven months.***\n","\n","If we want to match the gender that grows faster at birth, we can start by defining our regex: \"`girl|boy`\"\n","\n","Next, we add a prefix (\"`birth`\") and suffix (\"`faster`\") to ask the parser to match the regex only if the word \"`birth`\" comes before and only if the word \"`faster`\" comes after. Finally, we will need to set the `contextLength` - this is the maximum number of tokens after the prefix and before the suffix that will be searched to find a regex match.\n","\n","Here's what the JSON configuration file would look like:"]},{"cell_type":"markdown","metadata":{"id":"J5Tq5OJBVzCL"},"source":["```\n","{\n","  \"entity\": \"Gender\",\n","  \"ruleScope\": \"sentence\",\n","  \"regex\": \"girl|boy\",\n","  \"contextLength\": 50,\n","  \"prefix\": [\"birth\"],\n","  \"suffix\": [\"faster\"]\n","}\n","```"]},{"cell_type":"markdown","metadata":{"id":"G5Y5r9pO92B0"},"source":["`OUTPUT: [boy]`"]},{"cell_type":"markdown","metadata":{"id":"IXchjZZC_Gm0"},"source":["If you remember, the annotator has a `setPrefixAndSuffixMatch()` parameter. If you set it to `True`, the previous output would remain as is. However, if you had set it to `False` and used the following JSON configuration:"]},{"cell_type":"markdown","metadata":{"id":"xO64udOnV1GJ"},"source":["```\n","{\n","  \"entity\": \"Gender\",\n","  \"ruleScope\": \"sentence\",\n","  \"regex\": \"girl|boy\",\n","  \"contextLength\": 50,\n","  \"prefix\": [\"birth\"],\n","  \"suffix\": [\"faster\", \"rates\"]\n","}\n","```"]},{"cell_type":"markdown","metadata":{"id":"Xm-y_c_RAJpF"},"source":["`OUTPUT: [boy, girl]`"]},{"cell_type":"markdown","metadata":{"id":"Yk0nox1sAdw_"},"source":["The parser now takes into account either the prefix OR suffix, only one of the condition has to be fulfilled for a match to count."]},{"cell_type":"markdown","metadata":{"id":"MyTdPDlgLmxL"},"source":["If you remember, the annotator has a `setCompleteContextMatch()` parameter. If you set it to `True`, and used the following JSON configuration :"]},{"cell_type":"markdown","metadata":{"id":"1ycrvCMpMJ_J"},"source":["```\n","{\n","  \"entity\": \"Gender\",\n","  \"ruleScope\": \"sentence\",\n","  \"regex\": \"girl|boy\",\n","  \"contextLength\": 50,\n","  \"prefix\": [\"birth\"],\n","  \"suffix\": [\"fast\"]\n","}\n","```"]},{"cell_type":"markdown","metadata":{"id":"r5A67yBZMj2N"},"source":["`OUTPUT: []`"]},{"cell_type":"markdown","metadata":{"id":"N1duAqATM-ir"},"source":["However if we set `setCompleteContextMatch()` as `False`, and use the same JSON configuration as above, we get the following output :"]},{"cell_type":"markdown","metadata":{"id":"s0vd_jfsNi7y"},"source":["`OUTPUT: [boy]`"]},{"cell_type":"markdown","metadata":{"id":"vdEFJZM1DGQ1"},"source":["Here's the sentence again: ***At birth, the typical boy is growing slightly faster than the typical girl, but growth rates become equal at about seven months.***\n","\n","The last 2 properties related to context awareness are `contextException` and `exceptionDistance`. This rules out matches based on a given exception:"]},{"cell_type":"markdown","metadata":{"id":"0JluGupMV5SR"},"source":["```\n","{\n","  \"entity\": \"Gender\",\n","  \"ruleScope\": \"sentence\",\n","  \"regex\": \"girl|boy\",\n","  \"contextLength\": 50,\n","  \"prefix\": [\"birth\"],\n","  \"suffix\": [\"faster\", \"rates\"],\n","  \"contextException\": [\"At\"],\n","  \"exceptionDistance\": 5\n","}\n","```"]},{"cell_type":"markdown","metadata":{"id":"EnFzqpHlC3Qz"},"source":["`OUTPUT: [girl]`"]},{"cell_type":"markdown","metadata":{"id":"JT09xrE-DCiO"},"source":["Here we've asked the parser to ignore a match if the token \"`At`\" is within 5 tokens of the matched regex. This caused the token \"`boy`\" to be ignored."]},{"cell_type":"markdown","metadata":{"id":"nQ9-Fkr94qAH"},"source":["If the annotator's `setOptionalContextRules` parameter is set `True`, it allows us to output regex matches regardless of context match (prefix, suffix configuration). For usage of the `setOptionalContextRules` parameter go to the [Example2 output](#scrollTo=1tdgMbaWDhNC&line=1&uniqifier=1)."]},{"cell_type":"markdown","metadata":{"id":"NBZ1D92g5aEB"},"source":["When `shortestContextMatch` parameter is set to `True`, it will stop finding for matches when one of prefix and suffix data is found in the text.\",\n","                                "]},{"cell_type":"markdown","metadata":{"id":"41wdqkIX5WAy"},"source":["Confidence Value Scenarios:\n","* When there is regex match only, the confidence value will be 0.5.\n","* When there are regex and prefix matches together, the confidence value will be > 0.5 depending on the distance between target token and the prefix.\n","* When there are regex and suffix matches together, the confidence value will be > 0.5 depending on the distance between target token and the suffix.\n","* When there are regex, prefix, and suffix matches all together, the confidence value will be > than the other scenarios."]},{"cell_type":"markdown","metadata":{"id":"VzFSjw7aVO2b"},"source":["## 3. Dictionary"]},{"cell_type":"markdown","metadata":{"id":"5NPiJZx-Va8b"},"source":["Another key feature of the `ContextualParser` annotator is the use of dictionaries. You can specify a path to a dictionary in `tsv` or `csv` format using the `setDictionary()` parameter. Using a dictionary is a useful when you have a list of exact words that you want the parser to pick up when processing some text."]},{"cell_type":"markdown","metadata":{"id":"hmB9hadyXYeM"},"source":["### 3.1. Orientation\n","\n","The first feature to be aware of when it comes to feeding dictionaries is the format of the dictionaries. The `ContextualParser` annotator will accept dictionaries in the horizontal format and in a vertical format. This is how they would look in practice:"]},{"cell_type":"markdown","metadata":{"id":"eyDmIqLmWGRy"},"source":["Horizontal:\n","\n","| normalize | word1 | word2 | word3     |\n","|-----------|-------|-------|-----------|\n","| female    | woman | girl  | lady      |\n","| male      | man   | boy   | gentleman |\n"]},{"cell_type":"markdown","metadata":{"id":"ToFbLxsDYInk"},"source":["\n","Vertical:\n","\n","| female    | normalize |\n","|-----------|-----------|\n","| woman     | word1     |\n","| girl      | word2     |\n","| lady      | word3     |"]},{"cell_type":"markdown","metadata":{"id":"dCrIw4CRYeBC"},"source":["As you can see, your dictionary needs to have a `normalize` field that lets the annotator know which entity labels to use, and another field that lets the annotator know a list of words it should be looking to match. Here's how to set the format that your dictionary uses:"]},{"cell_type":"markdown","metadata":{"id":"Z_epZRQiV85Y"},"source":["```\n","contextualParser = medical.ContextualParserApproach() \\\n","    .setDictionary(\"dictionary.tsv\", options={\"orientation\":\"vertical\"}) # default is horizontal\n","```"]},{"cell_type":"markdown","metadata":{"id":"_CvM-FgLZgKk"},"source":["### 3.2. Dictionary-related JSON Properties\n","\n","When working with dictionaries, there are 2 properties in the JSON configuration file to be aware of:\n","\n","- `ruleScope`\n","- `matchScope`\n","\n","This is especially true when you have multi-word entities in your dictionary.\n","\n","Let's take an example of a dictionary that contains a list of cities, sometimes made up of multiple words:\n","\n","| normalize | word1 | word2 | word3     |\n","|-----------|-------|-------|-----------|\n","| City      | New York | Salt Lake City  | Washington      |\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"v5weyyiIMzNr"},"source":["Let's say we're working with the following text: ***I love New York. Salt Lake City is nice too.***"]},{"cell_type":"markdown","metadata":{"id":"xg8eJwuTJcB6"},"source":["With the following JSON properties, here's what you would get:"]},{"cell_type":"markdown","metadata":{"id":"R1TNWtywoGWb"},"source":["```\n","{\n","  \"entity\": \"City\",\n","  \"ruleScope\": \"sentence\",\n","  \"matchScope\": \"sub-token\",\n","}\n","```"]},{"cell_type":"markdown","metadata":{"id":"Wweg5_C9JuWm"},"source":["`OUTPUT: []`"]},{"cell_type":"markdown","metadata":{"id":"pNYWPr2eLJ5d"},"source":["When `ruleScope` is set to `\"sentence\"`, the annotator attempts to find matches at the token level, parsing through each token in the sentence one by one, looking for a match with the dictionary items. Since `\"New York\"` and `\"Salt Lake City\"` are made up of multiple tokens, the annotator would never find a match from the dictionary. Let's change `ruleScope` to `\"document\"`:"]},{"cell_type":"markdown","metadata":{"id":"Xib9zHN7oBvV"},"source":["```\n","{\n","  \"entity\": \"City\",\n","  \"ruleScope\": \"document\",\n","  \"matchScope\": \"sub-token\",\n","}\n","```"]},{"cell_type":"markdown","metadata":{"id":"MYmkGdtALXzK"},"source":["`OUTPUT: [New York, Salt Lake City]`"]},{"cell_type":"markdown","metadata":{"id":"Nmc7rvfsdFK9"},"source":["When `ruleScope` is set to `\"document\"`, the annotator attempts to find matches by parsing through each sentence in the document one by one, looking for a match with the dictionary items. Beware of how you set `matchScope`. Taking the previous example, if we were to set `matchScope` to `\"token\"` instead of `\"sub-token\"`, here's what would happen:"]},{"cell_type":"markdown","metadata":{"id":"vkzDTcgen9aS"},"source":["```\n","{\n","  \"entity\": \"City\",\n","  \"ruleScope\": \"document\",\n","  \"matchScope\": \"token\"\n","}\n","```"]},{"cell_type":"markdown","metadata":{"id":"np7rBSQmetA9"},"source":["`OUTPUT: [I love New York., Salt Lake City is nice too.]`"]},{"cell_type":"markdown","metadata":{"id":"w5nNtvLaeOv9"},"source":["As you can see, when `ruleScope` is at the document level, if you set your `matchScope` to the token level, the annotator will output each sentence containing the matched entities as individual chunks."]},{"cell_type":"markdown","metadata":{"id":"7zTtAFwqQdNy"},"source":["### 3.3. Working with Multi-Word Matches\n","\n","Although not directly related to dictionaries, if we build on top of what we've just seen, there is a use-case that is particularly in demand when working with the `ContextualParser` annotator: finding regex matches for chunks of words that span across multiple tokens.\n","\n","Let's re-iterate how the `ruleScope` property works: when `ruleScope` is set to `\"sentence\"`, we're looking for a match on each token of a sentence. When `ruleScope` is set to `\"document\"`, we're looking for a match on each sentence of a document.\n","\n","So now let's imagine you're parsing through medical documents trying to tag the *Family History* headers in those documents."]},{"cell_type":"markdown","metadata":{"id":"eJWXRrg0Qu0q"},"source":["```\n","{\n","  \"entity\": \"Family History Header\",\n","  \"regex\": \"[f|F]amily\\s+[h|H]istory\",  \n","  \"ruleScope\": \"document\",\n","  \"matchScope\": \"sub-token\"\n","}\n","```\n"]},{"cell_type":"markdown","metadata":{"id":"OP4H1t3CQyg5"},"source":["`OUTPUT: [Family History, family history, Family history]`"]},{"cell_type":"markdown","metadata":{"id":"X8PgD_N9RFTP"},"source":["If you had set `ruleScope` to  `\"sentence\"`, here's what would have happened:"]},{"cell_type":"markdown","metadata":{"id":"ljqiVjWaRJPe"},"source":["```\n","{\n","  \"entity\": \"Family History Header\",\n","  \"regex\": \"[f|F]amily\\s+[h|H]istory\",  \n","  \"ruleScope\": \"sentence\",\n","  \"matchScope\": \"sub-token\"\n","}\n","```"]},{"cell_type":"markdown","metadata":{"id":"GfcGKW81RMKN"},"source":["`OUTPUT: []`"]},{"cell_type":"markdown","metadata":{"id":"yMMgQdK5RPYb"},"source":["Since Family History is divided into two different tokens, the annotator will never find a match since it's now looking for a match on each token of a sentence."]},{"cell_type":"markdown","metadata":{"id":"ehWiHjziPfGV"},"source":["# Running a Pipeline"]},{"cell_type":"markdown","metadata":{"id":"VGz-nXwCDLgb"},"source":["## Example 1: Detecting Cities"]},{"cell_type":"markdown","metadata":{"id":"thaF2bObwDXd"},"source":["Let's try running through some examples to build on top of what you've learned so far."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"mcWKcPZO-upM","executionInfo":{"status":"ok","timestamp":1689328587173,"user_tz":-120,"elapsed":22,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"}}},"outputs":[],"source":["# Here's some sample text\n","sample_text = \"\"\"Peter Parker is a nice guy and lives in New York . Bruce Wayne is also a nice guy and lives in San Antonio and Gotham City . \"\"\""]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1689328587173,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"},"user_tz":-120},"id":"Y4Ipms-4PwoN","outputId":"517dfa98-f59f-480c-c0cd-2c2129b7cc9d"},"outputs":[{"output_type":"stream","name":"stdout","text":["City\n","New York\n","Gotham City\n","San Antonio\n","Salt Lake City"]}],"source":["# Create a dictionary to detect cities\n","cities = \"\"\"City\\nNew York\\nGotham City\\nSan Antonio\\nSalt Lake City\"\"\"\n","\n","with open('cities.tsv', 'w') as f:\n","    f.write(cities)\n","\n","# Check what dictionary looks like\n","!cat cities.tsv"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"Jvi1mbqY_LeA","executionInfo":{"status":"ok","timestamp":1689328587174,"user_tz":-120,"elapsed":12,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"}}},"outputs":[],"source":["# Create JSON file\n","cities = {\n","  \"entity\": \"City\",\n","  \"ruleScope\": \"document\",\n","  \"matchScope\":\"sub-token\",\n","  \"completeMatchRegex\": \"false\"\n","}\n","\n","import json\n","with open('cities.json', 'w') as f:\n","    json.dump(cities, f)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"yjQmEjWNQHvx","executionInfo":{"status":"ok","timestamp":1689328587669,"user_tz":-120,"elapsed":506,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"}}},"outputs":[],"source":["# Build pipeline\n","document_assembler = nlp.DocumentAssembler() \\\n","    .setInputCol(\"text\") \\\n","    .setOutputCol(\"document\")\n","\n","sentence_detector = nlp.SentenceDetector() \\\n","    .setInputCols([\"document\"]) \\\n","    .setOutputCol(\"sentence\")\n","\n","tokenizer = nlp.Tokenizer() \\\n","    .setInputCols([\"sentence\"]) \\\n","    .setOutputCol(\"token\")\n","\n","contextual_parser = medical.ContextualParserApproach() \\\n","    .setInputCols([\"sentence\", \"token\"])\\\n","    .setOutputCol(\"entity\")\\\n","    .setJsonPath(\"cities.json\")\\\n","    .setCaseSensitive(True)\\\n","    .setDictionary('cities.tsv', options={\"orientation\":\"vertical\"})\n","\n","chunk_converter = medical.ChunkConverter() \\\n","    .setInputCols([\"entity\"]) \\\n","    .setOutputCol(\"ner_chunk\")\n","\n","parserPipeline = nlp.Pipeline(stages=[\n","        document_assembler,\n","        sentence_detector,\n","        tokenizer,\n","        contextual_parser,\n","        chunk_converter,\n","        ])"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"HxPVaa4fYCb5","executionInfo":{"status":"ok","timestamp":1689328598742,"user_tz":-120,"elapsed":11080,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"}}},"outputs":[],"source":["# Create a lightpipeline model\n","empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n","\n","parserModel = parserPipeline.fit(empty_data)\n","\n","light_model = nlp.LightPipeline(parserModel)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"3T1xnn0vYOMA","executionInfo":{"status":"ok","timestamp":1689328599275,"user_tz":-120,"elapsed":545,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"}}},"outputs":[],"source":["# Annotate the sample text\n","annotations = light_model.fullAnnotate(sample_text)[0]"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"NY5zFoeSb8fg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689328599276,"user_tz":-120,"elapsed":10,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"}},"outputId":"9d3a0b7d-32d3-4382-e9f9-99c1753cc74b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Annotation(chunk, 40, 47, New York, {'field': 'City', 'tokenIndex': '9', 'ner_source': 'ner_chunk', 'normalized': 'City', 'confidenceValue': '0.50', 'entity': 'City', 'sentence': '0'}, []),\n"," Annotation(chunk, 95, 105, San Antonio, {'field': 'City', 'tokenIndex': '10', 'ner_source': 'ner_chunk', 'normalized': 'City', 'confidenceValue': '0.50', 'entity': 'City', 'sentence': '1'}, []),\n"," Annotation(chunk, 111, 121, Gotham City, {'field': 'City', 'tokenIndex': '13', 'ner_source': 'ner_chunk', 'normalized': 'City', 'confidenceValue': '0.50', 'entity': 'City', 'sentence': '1'}, [])]"]},"metadata":{},"execution_count":11}],"source":["# Check outputs\n","annotations.get('ner_chunk')"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"BBRie-vWXzK6","colab":{"base_uri":"https://localhost:8080/","height":88},"executionInfo":{"status":"ok","timestamp":1689328599785,"user_tz":-120,"elapsed":16,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"}},"outputId":"4625fa08-c451-4c6c-f5df-6064636a7381"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","<style>\n","    @import url('https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700&display=swap');\n","    @import url('https://fonts.googleapis.com/css2?family=Vistol Regular:wght@300;400;500;600;700&display=swap');\n","    \n","    .spark-nlp-display-scroll-entities {\n","        border: 1px solid #E7EDF0;\n","        border-radius: 3px;\n","        text-align: justify;\n","        \n","    }\n","    .spark-nlp-display-scroll-entities span {  \n","        font-size: 14px;\n","        line-height: 24px;\n","        color: #536B76;\n","        font-family: 'Montserrat', sans-serif !important;\n","    }\n","    \n","    .spark-nlp-display-entity-wrapper{\n","    \n","        display: inline-grid;\n","        text-align: center;\n","        border-radius: 4px;\n","        margin: 0 2px 5px 2px;\n","        padding: 1px\n","    }\n","    .spark-nlp-display-entity-name{\n","        font-size: 14px;\n","        line-height: 24px;\n","        font-family: 'Montserrat', sans-serif !important;\n","        \n","        background: #f1f2f3;\n","        border-width: medium;\n","        text-align: center;\n","        \n","        font-weight: 400;\n","        \n","        border-radius: 5px;\n","        padding: 2px 5px;\n","        display: block;\n","        margin: 3px 2px;\n","    \n","    }\n","    .spark-nlp-display-entity-type{\n","        font-size: 14px;\n","        line-height: 24px;\n","        color: #ffffff;\n","        font-family: 'Montserrat', sans-serif !important;\n","        \n","        text-transform: uppercase;\n","        \n","        font-weight: 500;\n","\n","        display: block;\n","        padding: 3px 5px;\n","    }\n","    \n","    .spark-nlp-display-entity-resolution{\n","        font-size: 14px;\n","        line-height: 24px;\n","        color: #ffffff;\n","        font-family: 'Vistol Regular', sans-serif !important;\n","        \n","        text-transform: uppercase;\n","        \n","        font-weight: 500;\n","\n","        display: block;\n","        padding: 3px 5px;\n","    }\n","    \n","    .spark-nlp-display-others{\n","        font-size: 14px;\n","        line-height: 24px;\n","        font-family: 'Montserrat', sans-serif !important;\n","        \n","        font-weight: 400;\n","    }\n","\n","</style>\n"," <span class=\"spark-nlp-display-others\" style=\"background-color: white\">Peter Parker is a nice guy and lives in </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #82B662\"><span class=\"spark-nlp-display-entity-name\">New York </span><span class=\"spark-nlp-display-entity-type\">City</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> . Bruce Wayne is also a nice guy and lives in </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #82B662\"><span class=\"spark-nlp-display-entity-name\">San Antonio </span><span class=\"spark-nlp-display-entity-type\">City</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> and </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #82B662\"><span class=\"spark-nlp-display-entity-name\">Gotham City </span><span class=\"spark-nlp-display-entity-type\">City</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> . </span></div>"]},"metadata":{}}],"source":["# Visualize outputs\n","# from sparknlp_display import NerVisualizer\n","\n","visualiser = nlp.viz.NerVisualizer()\n","\n","visualiser.display(annotations, label_col='ner_chunk', document_col='document', save_path=\"display_result.html\")"]},{"cell_type":"markdown","metadata":{"id":"gtD1HJ7SABU7"},"source":["Feel free to experiment with the annotator parameters and JSON properties to see how the output might change."]},{"cell_type":"markdown","metadata":{"id":"lR6FnTsyBAjn"},"source":["## Example 2: Detect Gender and Age"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"tXK5CLYfDhNB","executionInfo":{"status":"ok","timestamp":1689328599785,"user_tz":-120,"elapsed":14,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"}}},"outputs":[],"source":["# Here's some sample text\n","sample_text = \"\"\"A 28 year old female with a history of gestational diabetes mellitus diagnosed 8 years ago.\n","                 3 years ago, he reported an episode of HTG-induced pancreatitis .\n","                 5 months old boy with repeated concussions.\"\"\""]},{"cell_type":"code","execution_count":14,"metadata":{"id":"0OZqYhDFDhNB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689328599786,"user_tz":-120,"elapsed":14,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"}},"outputId":"7b04f5a8-cd34-419f-8a1e-5160d3ee69d3"},"outputs":[{"output_type":"stream","name":"stdout","text":["male,man,male,boy,gentleman,he,him\n","female,woman,female,girl,lady,old-lady,she,her\n","neutral,they,neutral,it"]}],"source":["# Create a dictionary to detect gender\n","gender = '''male,man,male,boy,gentleman,he,him\n","female,woman,female,girl,lady,old-lady,she,her\n","neutral,they,neutral,it'''\n","\n","with open('gender.csv', 'w') as f:\n","    f.write(gender)\n","\n","# Check what dictionary looks like\n","!cat gender.csv"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"U5-tYW1iDhNB","executionInfo":{"status":"ok","timestamp":1689328599786,"user_tz":-120,"elapsed":11,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"}}},"outputs":[],"source":["# Create JSON file for gender\n","gender = {\n","  \"entity\": \"Gender\",\n","  \"ruleScope\": \"sentence\",\n","  \"completeMatchRegex\": \"true\",\n","  \"matchScope\":\"token\"\n","}\n","\n","import json\n","with open('gender.json', 'w') as f:\n","    json.dump(gender, f)"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"bynTPmlQHEPv","executionInfo":{"status":"ok","timestamp":1689328599787,"user_tz":-120,"elapsed":12,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"}}},"outputs":[],"source":["# Create JSON file for age\n","age = {\n","  \"entity\": \"Age\",\n","  \"ruleScope\": \"sentence\",\n","  \"matchScope\":\"token\",\n","  \"regex\":\"\\\\d{1,3}\",\n","  \"prefix\":[\"age of\", \"age\"],\n","  \"suffix\": [\"-years-old\", \"years-old\", \"-year-old\",\n","             \"-months-old\", \"-month-old\", \"-months-old\",\n","             \"-day-old\", \"-days-old\", \"month old\",\n","             \"days old\", \"year old\", \"years old\",\n","             \"years\", \"year\", \"months\", \"old\"],\n","  \"contextLength\": 25,\n","  \"contextException\": [\"ago\"],\n","  \"exceptionDistance\": 12\n","}\n","\n","with open('age.json', 'w') as f:\n","    json.dump(age, f)"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"pBQVujx1DhNC","executionInfo":{"status":"ok","timestamp":1689328599788,"user_tz":-120,"elapsed":12,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"}}},"outputs":[],"source":["# Build pipeline\n","document_assembler = nlp.DocumentAssembler() \\\n","    .setInputCol(\"text\") \\\n","    .setOutputCol(\"document\")\n","\n","sentence_detector = nlp.SentenceDetector() \\\n","    .setInputCols([\"document\"]) \\\n","    .setOutputCol(\"sentence\")\n","\n","tokenizer = nlp.Tokenizer() \\\n","    .setInputCols([\"sentence\"]) \\\n","    .setOutputCol(\"token\")\n","\n","gender_contextual_parser = medical.ContextualParserApproach() \\\n","    .setInputCols([\"sentence\", \"token\"]) \\\n","    .setOutputCol(\"chunk_gender\") \\\n","    .setJsonPath(\"gender.json\") \\\n","    .setCaseSensitive(False) \\\n","    .setDictionary('gender.csv', options={\"delimiter\":\",\"}) \\\n","    .setPrefixAndSuffixMatch(False)\n","\n","age_contextual_parser = medical.ContextualParserApproach() \\\n","    .setInputCols([\"sentence\", \"token\"]) \\\n","    .setOutputCol(\"chunk_age\") \\\n","    .setJsonPath(\"age.json\") \\\n","    .setCaseSensitive(False) \\\n","    .setPrefixAndSuffixMatch(False)\\\n","    .setShortestContextMatch(True)\\\n","    .setOptionalContextRules(False)\n","\n","chunk_merger = medical.ChunkMergeApproach() \\\n","    .setInputCols([\"chunk_gender\", \"chunk_age\"]) \\\n","    .setOutputCol(\"ner_chunk\")\n","\n","parserPipeline = nlp.Pipeline(stages=[\n","        document_assembler,\n","        sentence_detector,\n","        tokenizer,\n","        gender_contextual_parser,\n","        age_contextual_parser,\n","        chunk_merger\n","        ])"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"36ZxeslFDhNC","executionInfo":{"status":"ok","timestamp":1689328601688,"user_tz":-120,"elapsed":1912,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"}}},"outputs":[],"source":["# Create a lightpipeline model\n","empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n","\n","parserModel = parserPipeline.fit(empty_data)\n","\n","light_model = nlp.LightPipeline(parserModel)"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"OIhdQ4IjDhNC","executionInfo":{"status":"ok","timestamp":1689328602324,"user_tz":-120,"elapsed":642,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"}}},"outputs":[],"source":["# Annotate the sample text\n","annotations = light_model.fullAnnotate(sample_text)[0]"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"1tdgMbaWDhNC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689328602325,"user_tz":-120,"elapsed":10,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"}},"outputId":"b4ee0a38-d6cb-46e3-9a4d-42cf5b6acf88"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Annotation(chunk, 2, 3, 28, {'tokenIndex': '1', 'entity': 'Age', 'field': 'Age', 'chunk': '0', 'normalized': '', 'sentence': '0', 'confidenceValue': '0.74'}, []),\n"," Annotation(chunk, 14, 19, female, {'tokenIndex': '4', 'entity': 'Gender', 'field': 'Gender', 'chunk': '1', 'normalized': 'female', 'sentence': '0', 'confidenceValue': '0.50'}, []),\n"," Annotation(chunk, 122, 123, he, {'tokenIndex': '4', 'entity': 'Gender', 'field': 'Gender', 'chunk': '2', 'normalized': 'male', 'sentence': '1', 'confidenceValue': '0.50'}, []),\n"," Annotation(chunk, 192, 192, 5, {'tokenIndex': '0', 'entity': 'Age', 'field': 'Age', 'chunk': '3', 'normalized': '', 'sentence': '2', 'confidenceValue': '0.74'}, []),\n"," Annotation(chunk, 205, 207, boy, {'tokenIndex': '3', 'entity': 'Gender', 'field': 'Gender', 'chunk': '4', 'normalized': 'male', 'sentence': '2', 'confidenceValue': '0.50'}, [])]"]},"metadata":{},"execution_count":20}],"source":["# Check outputs\n","annotations.get('ner_chunk')"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"xw0mQKMxDhND","colab":{"base_uri":"https://localhost:8080/","height":230},"executionInfo":{"status":"ok","timestamp":1689328602325,"user_tz":-120,"elapsed":9,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"}},"outputId":"f3fca4f1-791f-4164-fec1-4549e1984d36"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","<style>\n","    @import url('https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700&display=swap');\n","    @import url('https://fonts.googleapis.com/css2?family=Vistol Regular:wght@300;400;500;600;700&display=swap');\n","    \n","    .spark-nlp-display-scroll-entities {\n","        border: 1px solid #E7EDF0;\n","        border-radius: 3px;\n","        text-align: justify;\n","        \n","    }\n","    .spark-nlp-display-scroll-entities span {  \n","        font-size: 14px;\n","        line-height: 24px;\n","        color: #536B76;\n","        font-family: 'Montserrat', sans-serif !important;\n","    }\n","    \n","    .spark-nlp-display-entity-wrapper{\n","    \n","        display: inline-grid;\n","        text-align: center;\n","        border-radius: 4px;\n","        margin: 0 2px 5px 2px;\n","        padding: 1px\n","    }\n","    .spark-nlp-display-entity-name{\n","        font-size: 14px;\n","        line-height: 24px;\n","        font-family: 'Montserrat', sans-serif !important;\n","        \n","        background: #f1f2f3;\n","        border-width: medium;\n","        text-align: center;\n","        \n","        font-weight: 400;\n","        \n","        border-radius: 5px;\n","        padding: 2px 5px;\n","        display: block;\n","        margin: 3px 2px;\n","    \n","    }\n","    .spark-nlp-display-entity-type{\n","        font-size: 14px;\n","        line-height: 24px;\n","        color: #ffffff;\n","        font-family: 'Montserrat', sans-serif !important;\n","        \n","        text-transform: uppercase;\n","        \n","        font-weight: 500;\n","\n","        display: block;\n","        padding: 3px 5px;\n","    }\n","    \n","    .spark-nlp-display-entity-resolution{\n","        font-size: 14px;\n","        line-height: 24px;\n","        color: #ffffff;\n","        font-family: 'Vistol Regular', sans-serif !important;\n","        \n","        text-transform: uppercase;\n","        \n","        font-weight: 500;\n","\n","        display: block;\n","        padding: 3px 5px;\n","    }\n","    \n","    .spark-nlp-display-others{\n","        font-size: 14px;\n","        line-height: 24px;\n","        font-family: 'Montserrat', sans-serif !important;\n","        \n","        font-weight: 400;\n","    }\n","\n","</style>\n"," <span class=\"spark-nlp-display-others\" style=\"background-color: white\">A </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #ffe0ac\"><span class=\"spark-nlp-display-entity-name\">28 </span><span class=\"spark-nlp-display-entity-type\">Age</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> year old </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #ffacb7\"><span class=\"spark-nlp-display-entity-name\">female </span><span class=\"spark-nlp-display-entity-type\">Gender</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> with a history of gestational diabetes mellitus diagnosed 8 years ago.<br>                 3 years ago, </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #ffacb7\"><span class=\"spark-nlp-display-entity-name\">he </span><span class=\"spark-nlp-display-entity-type\">Gender</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> reported an episode of HTG-induced pancreatitis .<br>                 </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #ffe0ac\"><span class=\"spark-nlp-display-entity-name\">5 </span><span class=\"spark-nlp-display-entity-type\">Age</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> months old </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #ffacb7\"><span class=\"spark-nlp-display-entity-name\">boy </span><span class=\"spark-nlp-display-entity-type\">Gender</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> with repeated concussions.</span></div>"]},"metadata":{}}],"source":["# Visualize outputs\n","\n","visualiser = nlp.viz.NerVisualizer()\n","\n","visualiser.display(annotations, label_col='ner_chunk', document_col='document', save_path=\"display_result_2.html\")"]},{"cell_type":"markdown","metadata":{"id":"iOtVACnl_t3n"},"source":["Feel free to experiment with the annotator parameters and JSON properties to see how the output might change. If you're looking to work on running the pipeline on a full dataset, just make sure to use the `fit()` and `transform()` methods directly on your dataset instead of using the lightpipeline."]},{"cell_type":"code","execution_count":22,"metadata":{"id":"L6nRUUrRRfoB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689328614805,"user_tz":-120,"elapsed":12488,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"}},"outputId":"0fb134f0-5102-4fbd-bc45-26e6b19ac0d1"},"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n","|                text|            document|            sentence|               token|        chunk_gender|           chunk_age|           ner_chunk|\n","+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n","|A 28 year old fem...|[{document, 0, 23...|[{document, 0, 90...|[{token, 0, 0, A,...|[{chunk, 14, 19, ...|[{chunk, 2, 3, 28...|[{chunk, 2, 3, 28...|\n","+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n","\n"]}],"source":["# Create example dataframe with sample text\n","data = spark.createDataFrame([[sample_text]]).toDF(\"text\")\n","\n","# Fit and show\n","results = parserPipeline.fit(data).transform(data)\n","results.show()"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"orB8zsF9G6H4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689328615463,"user_tz":-120,"elapsed":662,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"}},"outputId":"2a2112d1-c97d-4ba4-b911-ed04b4c23071"},"outputs":[{"output_type":"stream","name":"stdout","text":["+-------+\n","| result|\n","+-------+\n","|[28, 5]|\n","+-------+\n","\n"]}],"source":["results.select(\"chunk_age.result\").show()"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"qzn7Qv3_HERi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689328616279,"user_tz":-120,"elapsed":820,"user":{"displayName":"Merve Ertas Uslu","userId":"01451729557099986551"}},"outputId":"07f91424-79ca-4f63-ae38-0287a8729639"},"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------------+\n","|           result|\n","+-----------------+\n","|[female, he, boy]|\n","+-----------------+\n","\n"]}],"source":["results.select(\"chunk_gender.result\").show()"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":0}