{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMwd9YTH0il-"
      },
      "source": [
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEyBPpKP0kWf"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/healthcare-nlp/01.6.Rule_Based_Entity_Matchers.ipynb)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LHkP98LZGeu"
      },
      "source": [
        "## **ðŸŽ¬ Colab Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELqzaf32MT6E"
      },
      "outputs": [],
      "source": [
        "# Install the johnsnowlabs library to access Spark-OCR and Spark-NLP for Healthcare, Finance, and Legal.\n",
        "! pip install -q johnsnowlabs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RO2dIA414yL_"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "print('Please Upload your John Snow Labs License using the button below')\n",
        "license_keys = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hr2Fq3FfgWhZ"
      },
      "outputs": [],
      "source": [
        "from johnsnowlabs import nlp, medical\n",
        "\n",
        "# After uploading your license run this to install all licensed Python Wheels and pre-download Jars the Spark Session JVM\n",
        "nlp.settings.enforce_versions=True\n",
        "nlp.install(refresh_install=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAVx7MX9mtA2"
      },
      "outputs": [],
      "source": [
        "from johnsnowlabs import nlp, medical\n",
        "# Automatically load license data and start a session with all jars user has access to\n",
        "\n",
        "spark = nlp.start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "lQ8-BI-_5QjG",
        "outputId": "0b3162f8-fd4f-4259-bab4-2088d7018d5b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://ab7c16312f51:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.4.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>John-Snow-Labs-Spark-Session ðŸš€ with Jars for: ðŸš€Spark-NLP==5.3.1, ðŸ’ŠSpark-Healthcare==5.3.1, running on âš¡ PySpark==3.4.0</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7ecef5963910>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "guXFthmRBnLk"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import DataFrame\n",
        "import pyspark.sql.functions as F\n",
        "import pyspark.sql.types as T\n",
        "import pyspark.sql as SQL\n",
        "from pyspark import keyword_only\n",
        "\n",
        "import pandas as pd\n",
        "import json\n",
        "import string\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsfxyQ-g-wAm"
      },
      "source": [
        "## Healthcare NLP for Data Scientists Course\n",
        "\n",
        "If you are not familiar with the components in this notebook, you can check [Healthcare NLP for Data Scientists Udemy Course](https://www.udemy.com/course/healthcare-nlp-for-data-scientists/) and the [MOOC Notebooks](https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP) for each components."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFSxHrJoYmNR"
      },
      "source": [
        "#   **ðŸ“œ RegexMatcher**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8i3Gs4jYua-"
      },
      "source": [
        "The **`RegexMatcher`** class implements an  annotator approach to match a set of regular expressions with a provided entity. This approach is utilized for associating specific patterns within text data with predetermined entities, such as dates, mentioned within the text.\n",
        "\n",
        "The class allows users to define rules using regular expressions paired with entities, offering flexibility in customization. These rules can either be directly set using the `setRules` method, with a specified delimiter, or loaded from an external file using the `setExternalRules` method.\n",
        "\n",
        "Additionally, users can specify parameters such as the matching strategy (`MATCH_FIRST`, `MATCH_ALL`, or `MATCH_COMPLETE`) to control how matches are handled. The output annotation type is `CHUNK`, with input annotation types supporting `DOCUMENT`. This class provides a versatile tool for implementing entity recognition based on user-defined patterns within text data.\n",
        "\n",
        "\n",
        "A rule consists of a regex pattern and an identifier, delimited by a character of choice. An example could be `\"\\\\d{4}\\\\/\\\\d\\\\d\\\\/\\\\d\\\\d,date\"` which will match strings like `\"1970/01/01\"` to the identifier `\"date\"`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeBd9UJ_ZUPn"
      },
      "source": [
        "**ðŸ–¨ï¸ Input/Output Annotation Types**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4B6PJlgZVdn"
      },
      "source": [
        "- Input: `DOCUMENT`\n",
        "\n",
        "- Output: `CHUNK`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRtM2EnHZcOC"
      },
      "source": [
        "**ðŸ”Ž Parameters**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHGfFsVTZgLi"
      },
      "source": [
        "**Parameters**:\n",
        "\n",
        "- `strategy`: Can be either `MATCH_FIRST`, `MATCH_ALL`, `MATCH_COMPLETE`, by default `MATCH_ALL`.\n",
        "- `rules`: Regex rules to match the identifier with.\n",
        "- `delimiter`: Delimiter for rules provided with setRules.\n",
        "- `externalRules`: external resource to rules, needs `delimiter` in options."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaq4W3v-av06"
      },
      "source": [
        "### IP and DATE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2npzoQyqRKd"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"Name : Hendrickson, Ora, Record date: 2093-01-13, MR #719435.\n",
        "Dr. John Green, ID: 1231511863, IP 203.120.223.13\n",
        "He is a 60-year-old male was admitted to the Day Hospital for cystectomy on 01/13/93\n",
        "Patient's VIN : 1HGBH41JXMN109286, SSN #333-44-6666, Driver's license no: A334455B.\n",
        "Phone (302) 786-5227, 0295 Keats Street, San Francisco, E-MAIL: smith@gmail.com.\"\"\"\n",
        "\n",
        "data = spark.createDataFrame([[text]]).toDF(\"text\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEVz7AR7iA6w"
      },
      "outputs": [],
      "source": [
        "!mkdir -p rules\n",
        "\n",
        "rules = '''\n",
        "(\\d{1,3}\\.){3}\\d{1,3}~IPADDR\n",
        "\\d{4}-\\d{2}-\\d{2}|\\d{2}/\\d{2}/\\d{2}|\\d{2}/\\d{2}/\\d{2}~DATE\n",
        "'''\n",
        "\n",
        "with open('./rules/regex_rules.txt', 'w') as f:\n",
        "    f.write(rules)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlvAHcXpG_oa"
      },
      "outputs": [],
      "source": [
        "document_assembler = nlp.DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "regex_matcher = medical.RegexMatcher()\\\n",
        "    .setInputCols('document')\\\n",
        "    .setStrategy(\"MATCH_ALL\")\\\n",
        "    .setOutputCol(\"regex_matches\")\\\n",
        "    .setExternalRules(path='./rules/regex_rules.txt', delimiter='~')\n",
        "\n",
        "nlpPipeline = nlp.Pipeline(\n",
        "    stages=[\n",
        "        document_assembler,\n",
        "        regex_matcher\n",
        "])\n",
        "\n",
        "result = nlpPipeline.fit(data).transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qp77CYGUG_l8",
        "outputId": "5ff848e9-ae0a-4f8e-f914-3812041cf58a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------+----------------------------------------------------------------------+\n",
            "|                                result|                                                              metadata|\n",
            "+--------------------------------------+----------------------------------------------------------------------+\n",
            "|[2093-01-13, 203.120.223.13, 01/13/93]|[{entity -> DATE, chunk -> 0, sentence -> 0}, {entity -> IPADDR, ch...|\n",
            "+--------------------------------------+----------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result.select('regex_matches.result','regex_matches.metadata').show(truncate=70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twrBEpoFjNW0",
        "outputId": "37fdc255-37f4-43af-c35b-91418e110e40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------+-----+---+---------+\n",
            "|  regex_result|begin|end|ner_label|\n",
            "+--------------+-----+---+---------+\n",
            "|    2093-01-13|   38| 47|     DATE|\n",
            "|203.120.223.13|   97|110|   IPADDR|\n",
            "|      01/13/93|  188|195|     DATE|\n",
            "+--------------+-----+---+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result_df = result.select(F.explode(F.arrays_zip(result.regex_matches.result,\n",
        "                                                 result.regex_matches.begin,\n",
        "                                                 result.regex_matches.end,\n",
        "                                                 result.regex_matches.metadata)).alias(\"cols\"))\\\n",
        "                  .select(F.expr(\"cols['0']\").alias(\"regex_result\"),\n",
        "                          F.expr(\"cols['1']\").alias(\"begin\"),\n",
        "                          F.expr(\"cols['2']\").alias(\"end\"),\n",
        "                          F.expr(\"cols['3']['entity']\").alias(\"ner_label\"))\n",
        "result_df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKIihshBvgh3"
      },
      "source": [
        "### AGE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wqyuXH1KIEW"
      },
      "source": [
        "- `(?i)(?<=((age of|age)))(\\d{1,3})~AGE` this rule inludes prefixes for `age of` and `age`\n",
        "- `(\\d{1,3})(?i)(?=(([^a-z0-9]{0,3}(-years-old|years-old|-year-old))))~AGE` this rule includes suffixes for `-years-old`, `years-old`, and `-year-old`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCqhldSJjNPv"
      },
      "outputs": [],
      "source": [
        "regex_rules_age = \"\"\"\n",
        "(?i)(?<=((age of|age)))(\\d{1,3})~AGE\n",
        "(\\d{1,3})(?i)(?=(([^a-z0-9]{0,3}(-years-old|years-old|-year-old))))~AGE\n",
        "\"\"\"\n",
        "with open('./rules/age_rules.txt', 'w') as f:\n",
        "    f.write(regex_rules_age)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5BI59b_okJ-c"
      },
      "outputs": [],
      "source": [
        "document_assembler = nlp.DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "regex_matcher = medical.RegexMatcher()\\\n",
        "    .setInputCols('document')\\\n",
        "    .setStrategy(\"MATCH_ALL\")\\\n",
        "    .setOutputCol(\"regex_matches\")\\\n",
        "    .setExternalRules('./rules/age_rules.txt', delimiter='~')\n",
        "\n",
        "\n",
        "nlpPipeline = nlp.Pipeline(\n",
        "    stages=[\n",
        "        document_assembler,\n",
        "        regex_matcher\n",
        "])\n",
        "\n",
        "result = nlpPipeline.fit(data).transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_Hx9vout4Db",
        "outputId": "afb42ba8-6eb4-4d2f-aab0-625132ea4454"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+--------------------------------------------+\n",
            "|result|                                    metadata|\n",
            "+------+--------------------------------------------+\n",
            "|  [60]|[{entity -> AGE, chunk -> 0, sentence -> 0}]|\n",
            "+------+--------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result.select('regex_matches.result','regex_matches.metadata').show(truncate=70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvCyKy-htzQr",
        "outputId": "8bb262b8-e82d-4c32-b8a6-a41cc137568f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------+---------+\n",
            "|regex_result|ner_label|\n",
            "+------------+---------+\n",
            "|          60|      AGE|\n",
            "+------------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result = result.select(F.explode(F.arrays_zip(result.regex_matches.result,\n",
        "                                              result.regex_matches.metadata)).alias(\"cols\"))\\\n",
        "                  .select(F.expr(\"cols['0']\").alias(\"regex_result\"),\n",
        "                          F.expr(\"cols['1']['entity']\").alias(\"ner_label\")).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9P5W2qZwKeA"
      },
      "source": [
        "## Create Custom Regex Rules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0R1me-WywDOz"
      },
      "outputs": [],
      "source": [
        "def write_rule(file_path, rules):\n",
        "\n",
        "    prefix_rule = \"(?i)(?<=((({})[^a-z0-9]{})))\"\n",
        "    prefix_rule_init = \"(?i)(?<=(({})))\"\n",
        "    suffix_rule = \"(?i)(?=(([^a-z0-9]{}({}))))\"\n",
        "    suffix_rule_init = \"(?i)(?=(({})))\"\n",
        "    with open(file_path, 'w') as f:\n",
        "\n",
        "        for label in list(rules.keys()):\n",
        "            if len(rules[label]['prefix'])>0:\n",
        "                rule = prefix_rule_init.format(\"|\".join(rules[label]['prefix'])) + rules[label]['rule'] + f\"~{label}\"\n",
        "                f.write(rule)\n",
        "                f.write('\\n')\n",
        "                for i in range(1,rules[label]['contextLength']):\n",
        "                    rule = prefix_rule.format(\"|\".join(rules[label]['prefix']),'{'+str(i)+'}') + rules[label]['rule'] + f\"~{label}\"\n",
        "                    f.write(rule)\n",
        "                    f.write('\\n')\n",
        "            try:\n",
        "\n",
        "                if len(rules[label]['suffix'])>0:\n",
        "                    rule = suffix_rule_init.format(\"|\".join(rules[label]['suffix'])) + rules[label]['rule'] + f\"~{label}\"\n",
        "                    f.write(rule)\n",
        "                    f.write('\\n')\n",
        "                    for i in range(1,rules[label]['contextLength']):\n",
        "                        rule = rules[label]['rule'] + suffix_rule.format('{'+str(i)+'}', \"|\".join(rules[label]['suffix'])) + f\"~{label}\"\n",
        "                        f.write(rule)\n",
        "                        f.write('\\n')\n",
        "            except:\n",
        "                continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "No3Sud9aAojp"
      },
      "outputs": [],
      "source": [
        "!mkdir -p rules regex_models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdBScX5C5L14"
      },
      "source": [
        "### SSN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wP7nCinW7NGi"
      },
      "outputs": [],
      "source": [
        "rule_path = \"rules/ssn_regex_rule.txt\"\n",
        "model_path = \"regex_models/ssn_regex_parser_model\"\n",
        "context_length = 3\n",
        "\n",
        "regex_rules_ssn = {\n",
        "    'SSN' :\n",
        "        {\n",
        "            'rule' : '(\\d{3}-\\d{2}-\\d{4})',\n",
        "            'prefix' : [\n",
        "                \"social\", \"security\", \"ss#\", \"ssn#\",\"ssid\", \"ss #\", \"ssn #\", \"SSA Number\", \"social security number\",\n",
        "                \"social security #\", \"social security#\", \"social security no\",\"Soc Sec\", \"SSN\", \"SSNS\", \"SSN#\", \"SS#\", \"SSID\"\n",
        "                ],\n",
        "            'label' : 'SSN',\n",
        "            'contextLength' : context_length\n",
        "        }\n",
        "}\n",
        "\n",
        "write_rule(rule_path, regex_rules_ssn)\n",
        "\n",
        "ssn_regex_matcher = medical.RegexMatcher()\\\n",
        "    .setExternalRules(rule_path,  \"~\") \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"ssn_matched_text\") \\\n",
        "    .setStrategy(\"MATCH_ALL\")\n",
        "\n",
        "regex_parser_pipeline = nlp.Pipeline(\n",
        "    stages=[\n",
        "      document_assembler,\n",
        "      ssn_regex_matcher\n",
        "])\n",
        "\n",
        "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
        "\n",
        "regex_parser_model = regex_parser_pipeline.fit(empty_data)\n",
        "regex_parser_model.stages[-1].write().overwrite().save(model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y12I0pwxNPVN"
      },
      "source": [
        "### AGE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2aoEXn6tHFCQ"
      },
      "outputs": [],
      "source": [
        "rule_path = \"rules/age_regex_rule.txt\"\n",
        "model_path = \"regex_models/age_regex_parser_model\"\n",
        "\n",
        "with open(rule_path, 'w') as f:\n",
        "    f.write(\"\"\"(?i)(?<=((age of|age)))(\\d{1,3})~AGE\n",
        "               (\\d{1,3})(?i)(?=(([^a-z0-9]{0,3}(-years-old|years-old|-year-old))))~AGE\"\"\")\n",
        "\n",
        "\n",
        "age_regex_matcher = medical.RegexMatcher()\\\n",
        "    .setExternalRules(rule_path,  \"~\") \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"age_matched_text\") \\\n",
        "    .setStrategy(\"MATCH_ALL\")\n",
        "\n",
        "regex_parser_pipeline = nlp.Pipeline(\n",
        "    stages=[\n",
        "      document_assembler,\n",
        "      age_regex_matcher\n",
        "])\n",
        "\n",
        "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
        "\n",
        "regex_parser_model = regex_parser_pipeline.fit(empty_data)\n",
        "regex_parser_model.stages[-1].write().overwrite().save(model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJU9gR0LNUjP"
      },
      "source": [
        "### MAIL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9O41uLkHjDA"
      },
      "outputs": [],
      "source": [
        "rule_path = \"rules/mail_regex_rule.txt\"\n",
        "model_path = \"regex_models/mail_regex_parser_model\"\n",
        "\n",
        "with open(rule_path, 'w') as f:\n",
        "    f.write(\"\"\"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}~EMAIL\"\"\")\n",
        "\n",
        "\n",
        "mail_regex_matcher = medical.RegexMatcher()\\\n",
        "    .setExternalRules(rule_path,  \"~\") \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"mail_matched_text\") \\\n",
        "    .setStrategy(\"MATCH_ALL\")\n",
        "\n",
        "regex_parser_pipeline = nlp.Pipeline(\n",
        "    stages=[\n",
        "      document_assembler,\n",
        "      mail_regex_matcher\n",
        "])\n",
        "\n",
        "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
        "\n",
        "regex_parser_model = regex_parser_pipeline.fit(empty_data)\n",
        "regex_parser_model.stages[-1].write().overwrite().save(model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziaQd_JCNXwX"
      },
      "source": [
        "### PHONE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngfowgwmHjAw"
      },
      "outputs": [],
      "source": [
        "rule_path = \"rules/phone_regex_rule.txt\"\n",
        "model_path = \"regex_models/phone_regex_parser_model\"\n",
        "\n",
        "with open(rule_path, 'w') as f:\n",
        "    f.write(\"\"\"\\(\\d{3}\\) \\d{3}-\\d{4}~PHONE\"\"\")\n",
        "\n",
        "\n",
        "phone_regex_matcher = medical.RegexMatcher()\\\n",
        "    .setExternalRules(rule_path,  \"~\") \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"phone_matched_text\") \\\n",
        "    .setStrategy(\"MATCH_ALL\")\n",
        "\n",
        "regex_parser_pipeline = nlp.Pipeline(\n",
        "    stages=[\n",
        "      document_assembler,\n",
        "      phone_regex_matcher\n",
        "])\n",
        "\n",
        "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
        "\n",
        "regex_parser_model = regex_parser_pipeline.fit(empty_data)\n",
        "regex_parser_model.stages[-1].write().overwrite().save(model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHqDfBdrRHxD"
      },
      "source": [
        "## RegexMatcherModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZX2lr-iNNOD",
        "outputId": "0beb7a25-af92-4232-8430-6de166cf3238"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sentence_detector_dl_healthcare download started this may take some time.\n",
            "Approximate size to download 367.3 KB\n",
            "[OK!]\n"
          ]
        }
      ],
      "source": [
        "document_assembler = nlp.DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "sentence_detector = nlp.SentenceDetectorDLModel.pretrained(\"sentence_detector_dl_healthcare\",\"en\",\"clinical/models\")\\\n",
        "      .setInputCols([\"document\"])\\\n",
        "      .setOutputCol(\"sentence\")\n",
        "\n",
        "tokenizer = nlp.Tokenizer()\\\n",
        "      .setInputCols([\"sentence\"])\\\n",
        "      .setOutputCol(\"token\")\n",
        "\n",
        "regex_matcher_ssn = medical.RegexMatcherModel.load(\"regex_models/ssn_regex_parser_model\")\\\n",
        "    .setInputCols([\"sentence\"]) \\\n",
        "    .setOutputCol(\"ssn_matched_text\")\n",
        "\n",
        "regex_matcher_age = nlp.RegexMatcherModel.load(\"regex_models/age_regex_parser_model\")\\\n",
        "    .setInputCols([\"sentence\"]) \\\n",
        "    .setOutputCol(\"age_matched_text\")\n",
        "\n",
        "regex_matcher_mail = nlp.RegexMatcherModel.load(\"regex_models/mail_regex_parser_model\")\\\n",
        "    .setInputCols([\"sentence\"]) \\\n",
        "    .setOutputCol(\"mail_matched_text\")\n",
        "\n",
        "regex_matcher_phone = nlp.RegexMatcherModel.load(\"regex_models/phone_regex_parser_model\")\\\n",
        "    .setInputCols([\"sentence\"]) \\\n",
        "    .setOutputCol(\"phone_matched_text\")\n",
        "\n",
        "chunk_merge = medical.ChunkMergeApproach()\\\n",
        "      .setInputCols(\"ssn_matched_text\",\n",
        "                    \"age_matched_text\",\n",
        "                    \"mail_matched_text\",\n",
        "                    \"phone_matched_text\")\\\n",
        "      .setOutputCol(\"ner_chunk\")\\\n",
        "      .setMergeOverlapping(True)\\\n",
        "      .setChunkPrecedence(\"field\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3cOriihNNEU"
      },
      "outputs": [],
      "source": [
        "nlpPipeline = nlp.Pipeline(stages=[\n",
        "      document_assembler,\n",
        "      sentence_detector,\n",
        "      tokenizer,\n",
        "      regex_matcher_ssn,\n",
        "      regex_matcher_age,\n",
        "      regex_matcher_mail,\n",
        "      regex_matcher_phone,\n",
        "      chunk_merge\n",
        "      ])\n",
        "\n",
        "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
        "\n",
        "regex_pipeline_model = nlpPipeline.fit(empty_data)\n",
        "light_model = nlp.LightPipeline(regex_pipeline_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGOPIuifRChZ"
      },
      "source": [
        "## Using LightPipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_juMKSu0NcvU"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"Name : Hendrickson, Ora, Record date: 2093-01-13, MR #719435.\n",
        "Dr. John Green, ID: 1231511863, IP 203.120.223.13.\n",
        "He is a 60-year-old male was admitted to the Day Hospital for cystectomy on 01/13/93.\n",
        "Patient's VIN : 1HGBH41JXMN109286, SSN #333-44-6666, Driver's license no: A334455B.\n",
        "Phone (302) 786-5227, 0295 Keats Street, San Francisco, E-MAIL: smith@gmail.com.\"\"\"\n",
        "\n",
        "result = light_model.fullAnnotate(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIooG89HNcqd",
        "outputId": "50706b8d-19c0-46a7-a9b2-6ea6ada60047"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['document', 'ner_chunk', 'phone_matched_text', 'age_matched_text', 'ssn_matched_text', 'token', 'sentence', 'mail_matched_text'])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result[0].keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1RJsJr3PbAp",
        "outputId": "1ec593d7-f071-443b-c09a-107bcbcec0f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Annotation(chunk, 121, 122, 60, {'entity': 'AGE', 'chunk': '0', 'sentence': '2'}, []),\n",
              " Annotation(chunk, 239, 249, 333-44-6666, {'entity': 'SSN', 'chunk': '1', 'sentence': '3'}, []),\n",
              " Annotation(chunk, 289, 302, (302) 786-5227, {'entity': 'PHONE', 'chunk': '2', 'sentence': '4'}, []),\n",
              " Annotation(chunk, 347, 361, smith@gmail.com, {'entity': 'EMAIL', 'chunk': '3', 'sentence': '4'}, [])]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result[0]['ner_chunk']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "2iuBW-GRPa-K",
        "outputId": "1060e846-cc34-4b41-ff1e-bb07617c6d17"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"ner_chunk\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"333-44-6666\",\n          \"smith@gmail.com\",\n          \"60\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"begin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 96,\n        \"min\": 121,\n        \"max\": 347,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          239,\n          347,\n          121\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"end\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 101,\n        \"min\": 122,\n        \"max\": 361,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          249,\n          361,\n          122\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ner_label\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"SSN\",\n          \"EMAIL\",\n          \"AGE\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-94be0078-787f-4ac0-a77a-6f970e229e2a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ner_chunk</th>\n",
              "      <th>begin</th>\n",
              "      <th>end</th>\n",
              "      <th>ner_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>60</td>\n",
              "      <td>121</td>\n",
              "      <td>122</td>\n",
              "      <td>AGE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>333-44-6666</td>\n",
              "      <td>239</td>\n",
              "      <td>249</td>\n",
              "      <td>SSN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(302) 786-5227</td>\n",
              "      <td>289</td>\n",
              "      <td>302</td>\n",
              "      <td>PHONE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>smith@gmail.com</td>\n",
              "      <td>347</td>\n",
              "      <td>361</td>\n",
              "      <td>EMAIL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-94be0078-787f-4ac0-a77a-6f970e229e2a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-94be0078-787f-4ac0-a77a-6f970e229e2a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-94be0078-787f-4ac0-a77a-6f970e229e2a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-925808c6-f0d9-49e1-b1e7-82b069f0ecce\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-925808c6-f0d9-49e1-b1e7-82b069f0ecce')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-925808c6-f0d9-49e1-b1e7-82b069f0ecce button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_2096a6e9-9c54-4f51-ac79-c5ee5db7db61\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_2096a6e9-9c54-4f51-ac79-c5ee5db7db61 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "         ner_chunk  begin  end ner_label\n",
              "0               60    121  122       AGE\n",
              "1      333-44-6666    239  249       SSN\n",
              "2   (302) 786-5227    289  302     PHONE\n",
              "3  smith@gmail.com    347  361     EMAIL"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ner_chunk = []\n",
        "ner_label = []\n",
        "begin = []\n",
        "end = []\n",
        "\n",
        "for n in result[0]['ner_chunk']:\n",
        "\n",
        "    begin.append(n.begin)\n",
        "    end.append(n.end)\n",
        "    ner_chunk.append(n.result)\n",
        "    ner_label.append(n.metadata['entity'])\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({'ner_chunk':ner_chunk, 'begin': begin, 'end':end,\n",
        "                   'ner_label':ner_label})\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ld0W7rYRRimh"
      },
      "source": [
        "## Transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHqUzkvUPa7s",
        "outputId": "6ecb8dd7-5071-4713-d42c-88a66f35164a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                text|            document|            sentence|               token|    ssn_matched_text|    age_matched_text|   mail_matched_text|  phone_matched_text|           ner_chunk|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|Name : Hendrickso...|[{document, 0, 36...|[{document, 0, 60...|[{token, 0, 3, Na...|[{chunk, 239, 249...|[{chunk, 121, 122...|[{chunk, 347, 361...|[{chunk, 289, 302...|[{chunk, 121, 122...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "empty_data = spark.createDataFrame([[text]]).toDF(\"text\")\n",
        "\n",
        "result = regex_pipeline_model.transform(empty_data)\n",
        "result.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGyLrlUMTH5G",
        "outputId": "757de2c1-7106-40ab-9cec-f05f628fa057"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------+---------+\n",
            "|      ner_chunk|ner_label|\n",
            "+---------------+---------+\n",
            "|             60|      AGE|\n",
            "|    333-44-6666|      SSN|\n",
            "| (302) 786-5227|    PHONE|\n",
            "|smith@gmail.com|    EMAIL|\n",
            "+---------------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result = result.select(F.explode(F.arrays_zip(result.ner_chunk.result,\n",
        "                                              result.ner_chunk.metadata)).alias(\"cols\"))\\\n",
        "                  .select(F.expr(\"cols['0']\").alias(\"ner_chunk\"),\n",
        "                          F.expr(\"cols['1']['entity']\").alias(\"ner_label\")).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLGq3FT3TVO7"
      },
      "source": [
        "## Pretrained Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NaVPQfMHzwB"
      },
      "outputs": [],
      "source": [
        "regex_pipeline_model.write().overwrite().save(\"regex_pipeline_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pqa3IOPdIY1U"
      },
      "outputs": [],
      "source": [
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "\n",
        "regex_pipeline_loaded = nlp.PretrainedPipeline.from_disk(\"regex_pipeline_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QK3pLeZIiKd",
        "outputId": "fa5e5df7-0565-47bf-e438-9c4ae4678edd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['document', 'ner_chunk', 'phone_matched_text', 'age_matched_text', 'ssn_matched_text', 'token', 'sentence', 'mail_matched_text'])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result = regex_pipeline_loaded.fullAnnotate(text)\n",
        "result[0].keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "WU60vDyCIu9g",
        "outputId": "1e7d6ffa-e0d9-4b0d-bafb-57e054cf8c61"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"ner_chunk\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"333-44-6666\",\n          \"smith@gmail.com\",\n          \"60\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"begin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 96,\n        \"min\": 121,\n        \"max\": 347,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          239,\n          347,\n          121\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"end\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 101,\n        \"min\": 122,\n        \"max\": 361,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          249,\n          361,\n          122\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ner_label\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"SSN\",\n          \"EMAIL\",\n          \"AGE\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-16851b9a-5829-4d7b-a65a-b949a9e01c8c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ner_chunk</th>\n",
              "      <th>begin</th>\n",
              "      <th>end</th>\n",
              "      <th>ner_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>60</td>\n",
              "      <td>121</td>\n",
              "      <td>122</td>\n",
              "      <td>AGE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>333-44-6666</td>\n",
              "      <td>239</td>\n",
              "      <td>249</td>\n",
              "      <td>SSN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(302) 786-5227</td>\n",
              "      <td>289</td>\n",
              "      <td>302</td>\n",
              "      <td>PHONE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>smith@gmail.com</td>\n",
              "      <td>347</td>\n",
              "      <td>361</td>\n",
              "      <td>EMAIL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-16851b9a-5829-4d7b-a65a-b949a9e01c8c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-16851b9a-5829-4d7b-a65a-b949a9e01c8c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-16851b9a-5829-4d7b-a65a-b949a9e01c8c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b0bff796-861e-4c26-a191-819a29e23497\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b0bff796-861e-4c26-a191-819a29e23497')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b0bff796-861e-4c26-a191-819a29e23497 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_ba4ab50d-db01-4d82-ad41-c3cb8016298c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ba4ab50d-db01-4d82-ad41-c3cb8016298c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "         ner_chunk  begin  end ner_label\n",
              "0               60    121  122       AGE\n",
              "1      333-44-6666    239  249       SSN\n",
              "2   (302) 786-5227    289  302     PHONE\n",
              "3  smith@gmail.com    347  361     EMAIL"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ner_chunk = []\n",
        "ner_label = []\n",
        "begin = []\n",
        "end = []\n",
        "\n",
        "for n in result[0]['ner_chunk']:\n",
        "\n",
        "    begin.append(n.begin)\n",
        "    end.append(n.end)\n",
        "    ner_chunk.append(n.result)\n",
        "    ner_label.append(n.metadata['entity'])\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({'ner_chunk':ner_chunk,\n",
        "                   'begin': begin, 'end':end,\n",
        "                   'ner_label':ner_label})\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkZcGEDW4adm"
      },
      "source": [
        "# ðŸ“œ TextMatcher\n",
        "\n",
        "In this notebook, we will examine the `TextMatcher` annotator and its model version `TextMatcherModel`.\n",
        "\n",
        "This annotator match exact phrases provided in a file against a\n",
        "Document.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0YPIJYgK6FA"
      },
      "source": [
        "**ðŸ“– Learning Objectives:**\n",
        "\n",
        "1. Understand how to match exact phrases by using pre-defined dictionary.\n",
        "\n",
        "2. Become comfortable using the different parameters of the annotator.\n",
        "\n",
        "**ðŸ”— Helpful Links:**\n",
        "\n",
        "For extended examples of usage, see the [Spark NLP Workshop Repository](https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/healthcare-nlp)\n",
        "\n",
        "Python Documentation: [TextMatcher](https://sparknlp.org/api/python/reference/autosummary/sparknlp/annotator/matcher/text_matcher/index.html#sparknlp.annotator.matcher.text_matcher.TextMatcher)\n",
        "\n",
        "Scala Documentation: [TextMatcher](https://sparknlp.org/api/com/johnsnowlabs/nlp/annotators/TextMatcher)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42ldvpMD4-oM"
      },
      "source": [
        "**ðŸ–¨ï¸ Input/Output Annotation Types**\n",
        "- Input: ``DOCUMENT`` , ``TOKEN``    \n",
        "- Output: ``CHUNK``"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKZ66I1D5aMQ"
      },
      "source": [
        "**ðŸ”Ž Parameters**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8dYRLbiMj2b"
      },
      "source": [
        "- `setEntities` *(str)*: Sets the external resource for the entities.\n",
        "        path : str\n",
        "            Path to the external resource\n",
        "        read_as : str, optional\n",
        "            How to read the resource, by default ReadAs.TEXT\n",
        "        options : dict, optional\n",
        "            Options for reading the resource, by default {\"format\": \"text\"}\n",
        "- `setCaseSensitive` *(Boolean)*: Sets whether to match regardless of case. (Default: True)\n",
        "\n",
        "- `setMergeOverlapping` *(Boolean)*:Sets whether to merge overlapping matched chunks. (Default: False)\n",
        "\n",
        "- `setEntityValue` *(str)*: Sets the value for the entity metadata field. If any entity value isn't set in the file, we need to set it for the entity value.\n",
        "\n",
        "- `setBuildFromTokens` *(Boolean)*:  Sets whether the TextMatcher  should take the CHUNK from TOKEN.\n",
        "\n",
        "- `setDelimiter` *(str)*:  Sets Value for the delimiter between Phrase, Entity.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZ9o6caf5dwY"
      },
      "source": [
        "## How to Use `TextMatcher`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_PfxcyZ2HHm"
      },
      "source": [
        "First of all, we should create a source file that includes all the chunks or tokens we need to capture. In the example below, we use `#` as a delimiter to separate the label and entity. So we need to set parameter like this `setDelimiter('#')`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SA_clVXRLGMf"
      },
      "outputs": [],
      "source": [
        "matcher_drug = \"\"\"\n",
        "Aspirin 100mg#Drug\n",
        "aspirin#Drug\n",
        "paracetamol#Drug\n",
        "amoxicillin#Drug\n",
        "ibuprofen#Drug\n",
        "lansoprazole#Drug\n",
        "\"\"\"\n",
        "\n",
        "with open ('matcher_drug.csv', 'w') as f:\n",
        "  f.write(matcher_drug)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAulAfjcE8cJ"
      },
      "outputs": [],
      "source": [
        "documentAssembler = nlp.DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "tokenizer = nlp.Tokenizer()\\\n",
        "    .setInputCols([\"document\"])\\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "entityExtractor = medical.TextMatcher()\\\n",
        "    .setInputCols([\"document\", \"token\"])\\\n",
        "    .setEntities(\"matcher_drug.csv\")\\\n",
        "    .setOutputCol(\"matched_text\")\\\n",
        "    .setCaseSensitive(False)\\\n",
        "    .setDelimiter(\"#\")\\\n",
        "    .setMergeOverlapping(False)\n",
        "\n",
        "mathcer_pipeline = nlp.Pipeline().setStages([\n",
        "                  documentAssembler,\n",
        "                  tokenizer,\n",
        "                  entityExtractor])\n",
        "\n",
        "data = spark.createDataFrame([[\"John's doctor prescribed aspirin 100mg for his heart condition, along with paracetamol for his fever, amoxicillin for his tonsilitis, ibuprofen for his inflammation, and lansoprazole for his GORD.\"]]).toDF(\"text\")\n",
        "\n",
        "result = mathcer_pipeline.fit(data).transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zw1BcEqoNYMM",
        "outputId": "933f96d5-94a5-4b46-a78e-a537db6bb86f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+-----+---+-----+\n",
            "|        chunk|begin|end|label|\n",
            "+-------------+-----+---+-----+\n",
            "|      aspirin|   25| 31| Drug|\n",
            "|aspirin 100mg|   25| 37| Drug|\n",
            "|  paracetamol|   75| 85| Drug|\n",
            "|  amoxicillin|  102|112| Drug|\n",
            "|    ibuprofen|  134|142| Drug|\n",
            "| lansoprazole|  170|181| Drug|\n",
            "+-------------+-----+---+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result.select(F.explode(F.arrays_zip(\n",
        "              result.matched_text.result,\n",
        "              result.matched_text.begin,\n",
        "              result.matched_text.end,\n",
        "              result.matched_text.metadata,)).alias(\"cols\"))\\\n",
        "      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
        "              F.expr(\"cols['1']\").alias(\"begin\"),\n",
        "              F.expr(\"cols['2']\").alias(\"end\"),\n",
        "              F.expr(\"cols['3']['entity']\").alias('label')).show(truncate=70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ke9q2i9OKB_"
      },
      "source": [
        "As you see above mather_drug file includes 2 similar entities aspirin and aspirin 100mg and our text includes both of them So if you want to see both of them you need to set `MergeOverlapping` parameter as `False`. You can look at the below example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhOx17lxPzam"
      },
      "outputs": [],
      "source": [
        "entityExtractor = medical.TextMatcher()\\\n",
        "    .setInputCols([\"document\", \"token\"])\\\n",
        "    .setEntities(\"matcher_drug.csv\") \\\n",
        "    .setOutputCol(\"matched_text\")\\\n",
        "    .setDelimiter(\"#\")\\\n",
        "    .setCaseSensitive(False)\\\n",
        "    .setMergeOverlapping(False)\n",
        "\n",
        "mathcer_pipeline = nlp.Pipeline().setStages([\n",
        "                  documentAssembler,\n",
        "                  tokenizer,\n",
        "                  entityExtractor])\n",
        "\n",
        "result = mathcer_pipeline.fit(data).transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mir6p73EPzX7",
        "outputId": "5ab7de57-8501-48b8-ec1a-f00302cdd08e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+-----+---+-----+\n",
            "|        chunk|begin|end|label|\n",
            "+-------------+-----+---+-----+\n",
            "|      aspirin|   25| 31| Drug|\n",
            "|aspirin 100mg|   25| 37| Drug|\n",
            "|  paracetamol|   75| 85| Drug|\n",
            "|  amoxicillin|  102|112| Drug|\n",
            "|    ibuprofen|  134|142| Drug|\n",
            "| lansoprazole|  170|181| Drug|\n",
            "+-------------+-----+---+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result.select(F.explode(F.arrays_zip(\n",
        "              result.matched_text.result,\n",
        "              result.matched_text.begin,\n",
        "              result.matched_text.end,\n",
        "              result.matched_text.metadata,)).alias(\"cols\"))\\\n",
        "      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
        "              F.expr(\"cols['1']\").alias(\"begin\"),\n",
        "              F.expr(\"cols['2']\").alias(\"end\"),\n",
        "              F.expr(\"cols['3']['entity']\").alias('label')).show(truncate=70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lJR9TF-KjnX"
      },
      "source": [
        "When we set the `CaseSensitive` parameter to `True`, it means we're considering the case sensitivity of chunks in the source file. Consequently, some chunks may not be visible due to differences in their case compared to the source file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kO64pNcRSns"
      },
      "outputs": [],
      "source": [
        "entityExtractor = medical.TextMatcher()\\\n",
        "    .setInputCols([\"document\", \"token\"])\\\n",
        "    .setEntities(\"matcher_drug.csv\") \\\n",
        "    .setOutputCol(\"matched_text\")\\\n",
        "    .setDelimiter(\"#\")\\\n",
        "    .setCaseSensitive(True)\\\n",
        "    .setMergeOverlapping(False)\n",
        "\n",
        "mathcer_pipeline = nlp.Pipeline().setStages([\n",
        "                  documentAssembler,\n",
        "                  tokenizer,\n",
        "                  entityExtractor])\n",
        "\n",
        "matcher_model = mathcer_pipeline.fit(data)\n",
        "result = matcher_model.transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2du_Gl_MRX5e",
        "outputId": "1ee7e351-5abb-474e-86b2-beb946a9d8f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------+-----+---+-----+\n",
            "|       chunk|begin|end|label|\n",
            "+------------+-----+---+-----+\n",
            "|     aspirin|   25| 31| Drug|\n",
            "| paracetamol|   75| 85| Drug|\n",
            "| amoxicillin|  102|112| Drug|\n",
            "|   ibuprofen|  134|142| Drug|\n",
            "|lansoprazole|  170|181| Drug|\n",
            "+------------+-----+---+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result.select(F.explode(F.arrays_zip(\n",
        "              result.matched_text.result,\n",
        "              result.matched_text.begin,\n",
        "              result.matched_text.end,\n",
        "              result.matched_text.metadata,)).alias(\"cols\"))\\\n",
        "      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
        "              F.expr(\"cols['1']\").alias(\"begin\"),\n",
        "              F.expr(\"cols['2']\").alias(\"end\"),\n",
        "              F.expr(\"cols['3']['entity']\").alias('label')).show(truncate=70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRK3oFxTeu3G"
      },
      "source": [
        "## Multiple Entities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqYZzaJcRvLB"
      },
      "source": [
        "We can set multiple entities in the same file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMyFcexzRo_4"
      },
      "outputs": [],
      "source": [
        "multiple_entites= \"\"\"\n",
        "Aspirin 100mg#Drug\n",
        "paracetamol#Drug\n",
        "amoxicillin#Drug\n",
        "ibuprofen#Drug\n",
        "lansoprazole#Drug\n",
        "fever#Symptom\n",
        "headache#Symptom\n",
        "tonsilitis#Disease\n",
        "GORD#Disease\n",
        "heart condition#Disease\n",
        "\"\"\"\n",
        "\n",
        "with open ('multiple_entities.csv', 'w') as f:\n",
        "  f.write(multiple_entites)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9OYfKPA5bM1"
      },
      "outputs": [],
      "source": [
        "documentAssembler = nlp.DocumentAssembler() \\\n",
        "    .setInputCol(\"text\") \\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "tokenizer = nlp.Tokenizer() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "entityExtractor = medical.TextMatcher() \\\n",
        "    .setInputCols([\"document\", \"token\"]) \\\n",
        "    .setEntities(\"multiple_entities.csv\") \\\n",
        "    .setOutputCol(\"matched_text\")\\\n",
        "    .setDelimiter(\"#\")\\\n",
        "    .setCaseSensitive(False)\\\n",
        "    .setDelimiter(\"#\")\n",
        "\n",
        "matcher_pipeline = nlp.Pipeline().setStages([\n",
        "                  documentAssembler,\n",
        "                  tokenizer,\n",
        "                  entityExtractor])\n",
        "\n",
        "data = spark.createDataFrame([[\"John's doctor prescribed aspirin 100mg for his heart condition, along with paracetamol for his fever and headache, amoxicillin for his tonsilitis, ibuprofen for his inflammation, and lansoprazole for his GORD.\"]]).toDF(\"text\")\n",
        "\n",
        "matcher_model = matcher_pipeline.fit(data)\n",
        "result = matcher_model.transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8ocoyTFQx0Q",
        "outputId": "1c3de5ef-a7d9-44ef-d58f-93484729ed1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------+-----+---+-------+\n",
            "|          chunk|begin|end|  label|\n",
            "+---------------+-----+---+-------+\n",
            "|  aspirin 100mg|   25| 37|   Drug|\n",
            "|    paracetamol|   75| 85|   Drug|\n",
            "|    amoxicillin|  115|125|   Drug|\n",
            "|      ibuprofen|  147|155|   Drug|\n",
            "|   lansoprazole|  183|194|   Drug|\n",
            "|heart condition|   47| 61|Disease|\n",
            "|     tonsilitis|  135|144|Disease|\n",
            "|           GORD|  204|207|Disease|\n",
            "|          fever|   95| 99|Symptom|\n",
            "|       headache|  105|112|Symptom|\n",
            "+---------------+-----+---+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result.select(F.explode(F.arrays_zip(\n",
        "              result.matched_text.result,\n",
        "              result.matched_text.begin,\n",
        "              result.matched_text.end,\n",
        "              result.matched_text.metadata,)).alias(\"cols\"))\\\n",
        "      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
        "              F.expr(\"cols['1']\").alias(\"begin\"),\n",
        "              F.expr(\"cols['2']\").alias(\"end\"),\n",
        "              F.expr(\"cols['3']['entity']\").alias('label')).show(truncate=70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2xjtXx1Hpk_"
      },
      "source": [
        "## `TextMatcherModel`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xR38CLdnHsff"
      },
      "source": [
        "This annotator is an instantiated model of the `TextMatcher`. Once you build an `TextMatcher()`, you can save it and use it with `TextMatcherModel()` via `load()` function. <br/>\n",
        "\n",
        "Let's re-build one of examples that we have done before and save it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QYSvWToIA-G"
      },
      "outputs": [],
      "source": [
        "entityExtractor = medical.TextMatcher() \\\n",
        "    .setInputCols([\"document\", \"token\"]) \\\n",
        "    .setEntities(\"matcher_drug.csv\") \\\n",
        "    .setOutputCol(\"matched_text\")\\\n",
        "    .setCaseSensitive(False)\\\n",
        "    .setDelimiter(\"#\")\n",
        "\n",
        "matcher_pipeline = nlp.Pipeline().setStages([\n",
        "                  documentAssembler,\n",
        "                  tokenizer,\n",
        "                  entityExtractor])\n",
        "\n",
        "data = spark.createDataFrame([[\"John's doctor prescribed aspirin 100mg for his heart condition, along with paracetamol for his fever and headache, amoxicillin for his tonsilitis, ibuprofen for his inflammation, and lansoprazole for his GORD.\"]]).toDF(\"text\")\n",
        "\n",
        "result = matcher_pipeline.fit(data).transform(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bC_plUPNIBkd"
      },
      "source": [
        "Saving the approach to disk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVy8-fN-GNlK"
      },
      "outputs": [],
      "source": [
        "matcher_model.stages[-1].write().overwrite().save(\"matcher_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0n3vq6XIprS"
      },
      "source": [
        "Loading the saved model and using it with the `TextMatcherModel()` via `load`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8b6I0h5ZGNiZ"
      },
      "outputs": [],
      "source": [
        "entity_ruler = nlp.TextMatcherModel.load('/content/matcher_model') \\\n",
        "    .setInputCols([\"document\", \"token\"]) \\\n",
        "    .setOutputCol(\"matched_text\")\\\n",
        "\n",
        "\n",
        "pipeline = nlp.Pipeline(stages=[documentAssembler,\n",
        "                            tokenizer,\n",
        "                            entity_ruler])\n",
        "\n",
        "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
        "pipeline_model = pipeline.fit(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDWKIe2qJD-8"
      },
      "source": [
        "Checking the result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6NEIyG1GNf7",
        "outputId": "245d9b8e-0aea-4b25-f775-c49fca4965da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------+-----+---+-------+\n",
            "|          chunk|begin|end|  label|\n",
            "+---------------+-----+---+-------+\n",
            "|  aspirin 100mg|   25| 37|   Drug|\n",
            "|    paracetamol|   75| 85|   Drug|\n",
            "|    amoxicillin|  115|125|   Drug|\n",
            "|      ibuprofen|  147|155|   Drug|\n",
            "|   lansoprazole|  183|194|   Drug|\n",
            "|heart condition|   47| 61|Disease|\n",
            "|     tonsilitis|  135|144|Disease|\n",
            "|          fever|   95| 99|Symptom|\n",
            "|           GORD|  204|207|Disease|\n",
            "|       headache|  105|112|Symptom|\n",
            "+---------------+-----+---+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result = pipeline_model.transform(data)\n",
        "\n",
        "result.select(F.explode(F.arrays_zip(result.matched_text.result,\n",
        "                                    result.matched_text.begin,\n",
        "                                    result.matched_text.end,\n",
        "                                    result.matched_text.metadata,)).alias(\"cols\"))\\\n",
        "      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
        "              F.expr(\"cols['1']\").alias(\"begin\"),\n",
        "              F.expr(\"cols['2']\").alias(\"end\"),\n",
        "              F.expr(\"cols['3']['entity']\").alias('label')).show(truncate=70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtuNVf4YJS0o"
      },
      "source": [
        "As seen above, we built an `TextMatcher`, saved it and used the saved model with `TextMatcherModel`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuN7dw05_AlD"
      },
      "source": [
        "## Using LightPipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3IXo3vO_H0s"
      },
      "source": [
        "The TextMatcher annotator can also be applied by using LightPipeline:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IS8fN6lh_AlD"
      },
      "outputs": [],
      "source": [
        "light_pipeline = nlp.LightPipeline(pipeline_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpM8ed-G_AlD",
        "outputId": "be07fb26-2e98-4d4f-dea6-10572d6bed42"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['document', 'token', 'matched_text'])"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "annotations = light_pipeline.fullAnnotate(\"John's doctor prescribed aspirin 100mg for his heart condition, along with paracetamol for his fever and headache, amoxicillin for his tonsilitis, ibuprofen for his inflammation, and lansoprazole for his GORD.\")[0]\n",
        "annotations.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuvodYEI_AlE",
        "outputId": "d851252b-9a89-418c-c80b-53bdb17a715a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Annotation(chunk, 25, 37, aspirin 100mg, {'entity': 'Drug', 'sentence': '0', 'chunk': '0'}, []),\n",
              " Annotation(chunk, 75, 85, paracetamol, {'entity': 'Drug', 'sentence': '0', 'chunk': '1'}, []),\n",
              " Annotation(chunk, 115, 125, amoxicillin, {'entity': 'Drug', 'sentence': '0', 'chunk': '2'}, []),\n",
              " Annotation(chunk, 147, 155, ibuprofen, {'entity': 'Drug', 'sentence': '0', 'chunk': '3'}, []),\n",
              " Annotation(chunk, 183, 194, lansoprazole, {'entity': 'Drug', 'sentence': '0', 'chunk': '4'}, []),\n",
              " Annotation(chunk, 95, 99, fever, {'entity': 'Symptom', 'sentence': '0', 'chunk': '5'}, []),\n",
              " Annotation(chunk, 105, 112, headache, {'entity': 'Symptom', 'sentence': '0', 'chunk': '6'}, []),\n",
              " Annotation(chunk, 47, 61, heart condition, {'entity': 'Disease', 'sentence': '0', 'chunk': '7'}, []),\n",
              " Annotation(chunk, 135, 144, tonsilitis, {'entity': 'Disease', 'sentence': '0', 'chunk': '8'}, []),\n",
              " Annotation(chunk, 204, 207, GORD, {'entity': 'Disease', 'sentence': '0', 'chunk': '9'}, [])]"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "annotations.get('matched_text')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgxllC3b4b2U"
      },
      "source": [
        "Display the result with `spark-nlp-display`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "lz8ondRb4aDE",
        "outputId": "702100dd-cdc3-4d9a-eca7-f11b506536af"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    @import url('https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700&display=swap');\n",
              "    @import url('https://fonts.googleapis.com/css2?family=Vistol Regular:wght@300;400;500;600;700&display=swap');\n",
              "    \n",
              "    .spark-nlp-display-scroll-entities {\n",
              "        border: 1px solid #E7EDF0;\n",
              "        border-radius: 3px;\n",
              "        text-align: justify;\n",
              "        \n",
              "    }\n",
              "    .spark-nlp-display-scroll-entities span {  \n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        color: #536B76;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "    }\n",
              "    \n",
              "    .spark-nlp-display-entity-wrapper{\n",
              "    \n",
              "        display: inline-grid;\n",
              "        text-align: center;\n",
              "        border-radius: 4px;\n",
              "        margin: 0 2px 5px 2px;\n",
              "        padding: 1px\n",
              "    }\n",
              "    .spark-nlp-display-entity-name{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "        \n",
              "        background: #f1f2f3;\n",
              "        border-width: medium;\n",
              "        text-align: center;\n",
              "        \n",
              "        font-weight: 400;\n",
              "        \n",
              "        border-radius: 5px;\n",
              "        padding: 2px 5px;\n",
              "        display: block;\n",
              "        margin: 3px 2px;\n",
              "    \n",
              "    }\n",
              "    .spark-nlp-display-entity-type{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        color: #ffffff;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "        \n",
              "        text-transform: uppercase;\n",
              "        \n",
              "        font-weight: 500;\n",
              "\n",
              "        display: block;\n",
              "        padding: 3px 5px;\n",
              "    }\n",
              "    \n",
              "    .spark-nlp-display-entity-resolution{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        color: #ffffff;\n",
              "        font-family: 'Vistol Regular', sans-serif !important;\n",
              "        \n",
              "        text-transform: uppercase;\n",
              "        \n",
              "        font-weight: 500;\n",
              "\n",
              "        display: block;\n",
              "        padding: 3px 5px;\n",
              "    }\n",
              "    \n",
              "    .spark-nlp-display-others{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "        \n",
              "        font-weight: 400;\n",
              "    }\n",
              "\n",
              "</style>\n",
              " <span class=\"spark-nlp-display-others\" style=\"background-color: white\">John's doctor prescribed </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #8B668B\"><span class=\"spark-nlp-display-entity-name\">aspirin 100mg </span><span class=\"spark-nlp-display-entity-type\">Drug</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> for his </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #5D7B4C\"><span class=\"spark-nlp-display-entity-name\">heart condition </span><span class=\"spark-nlp-display-entity-type\">Disease</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, along with </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #8B668B\"><span class=\"spark-nlp-display-entity-name\">paracetamol </span><span class=\"spark-nlp-display-entity-type\">Drug</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> for his </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #140286\"><span class=\"spark-nlp-display-entity-name\">fever </span><span class=\"spark-nlp-display-entity-type\">Symptom</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> and </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #140286\"><span class=\"spark-nlp-display-entity-name\">headache </span><span class=\"spark-nlp-display-entity-type\">Symptom</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #8B668B\"><span class=\"spark-nlp-display-entity-name\">amoxicillin </span><span class=\"spark-nlp-display-entity-type\">Drug</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> for his </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #5D7B4C\"><span class=\"spark-nlp-display-entity-name\">tonsilitis </span><span class=\"spark-nlp-display-entity-type\">Disease</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #8B668B\"><span class=\"spark-nlp-display-entity-name\">ibuprofen </span><span class=\"spark-nlp-display-entity-type\">Drug</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> for his inflammation, and </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #8B668B\"><span class=\"spark-nlp-display-entity-name\">lansoprazole </span><span class=\"spark-nlp-display-entity-type\">Drug</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> for his </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #5D7B4C\"><span class=\"spark-nlp-display-entity-name\">GORD </span><span class=\"spark-nlp-display-entity-type\">Disease</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">.</span></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sparknlp_display import NerVisualizer\n",
        "\n",
        "visualiser = NerVisualizer()\n",
        "\n",
        "visualiser.display(annotations, label_col='matched_text')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0LqB5qDKZ1W"
      },
      "source": [
        "## Pretrained Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGW8maiqLysr"
      },
      "source": [
        "<center>\n",
        "\n",
        "  <b>Text Matcher Pretrained Models</b>\n",
        "\n",
        "|index|model|entities|\n",
        "|----:|:----|-------|\n",
        "| 1| [drug_matcher](https://nlp.johnsnowlabs.com/2024/03/06/drug_matcher_en.html)  |`DRUG` |\n",
        "| 2| [biomarker_matcher](https://nlp.johnsnowlabs.com/2024/03/06/biomarker_matcher_en.html)  |`Biomarker` |\n",
        "| 3| [country_matcher](https://nlp.johnsnowlabs.com/2024/09/25/country_matcher_en.html) |`Country` |\n",
        "| 4| [state_matcher](https://nlp.johnsnowlabs.com/2024/09/25/state_matcher_en.html) |`STATE` |\n",
        "\n",
        "</center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtLaOYCoDIOk",
        "outputId": "ffda6a12-3bcd-4c96-b444-af8d7341dd5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "drug_matcher download started this may take some time.\n",
            "[OK!]\n"
          ]
        }
      ],
      "source": [
        "documentAssembler = nlp.DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "tokenizer = nlp.Tokenizer()\\\n",
        "    .setInputCols([\"document\"])\\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "text_matcher = medical.TextMatcherModel.pretrained(\"drug_matcher\",\"en\",\"clinical/models\") \\\n",
        "    .setInputCols([\"document\", \"token\"])\\\n",
        "    .setOutputCol(\"matched_text\")\n",
        "\n",
        "mathcer_pipeline = nlp.Pipeline().setStages([\n",
        "                  documentAssembler,\n",
        "                  tokenizer,\n",
        "                  text_matcher])\n",
        "\n",
        "text = \"\"\"John's doctor prescribed aspirin for his heart condition, along with paracetamol for his fever and headache, ciprofloxacin for his tonsilitis, ibuprofen for his inflammation, and lansoprazole for his GORD on 2023-12-01.\"\"\"\n",
        "\n",
        "data = spark.createDataFrame([[text]]).toDF(\"text\")\n",
        "\n",
        "result = mathcer_pipeline.fit(data).transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9wzywyoKoiL",
        "outputId": "e5ef1e55-28a1-43df-fcb7-bba132b85dac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+-----+---+-----+\n",
            "|        chunk|begin|end|label|\n",
            "+-------------+-----+---+-----+\n",
            "|      aspirin|   25| 31| DRUG|\n",
            "|  paracetamol|   69| 79| DRUG|\n",
            "|ciprofloxacin|  109|121| DRUG|\n",
            "|    ibuprofen|  143|151| DRUG|\n",
            "| lansoprazole|  179|190| DRUG|\n",
            "+-------------+-----+---+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result.select(F.explode(F.arrays_zip(result.matched_text.result,\n",
        "                                      result.matched_text.begin,\n",
        "                                      result.matched_text.end,\n",
        "                                      result.matched_text.metadata,)).alias(\"cols\"))\\\n",
        "      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
        "              F.expr(\"cols['1']\").alias(\"begin\"),\n",
        "              F.expr(\"cols['2']\").alias(\"end\"),\n",
        "              F.expr(\"cols['3']['entity']\").alias('label')).show(truncate=70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-52FsQlDIUJ"
      },
      "source": [
        "# ðŸ“œ EntityRuler\n",
        "\n",
        "This notebook will cover the different parameter and usage of **EntityRuler**. There are 2 annotators to perform this task in Spark NLP; `EntityRulerApproach` and `EntityRulerModel`. <br/>\n",
        "\n",
        "This annotator match exact strings or regex patterns provided in a file against a Document and assigns them an named entity. The definitions can contain any number of named entities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMq_jBMMDIUJ"
      },
      "source": [
        "**ðŸ“– Learning Objectives:**\n",
        "\n",
        "1. Understand how to match exact strings or regex patterns by using pre-defined dictionary.\n",
        "\n",
        "2. Become comfortable using the different parameters of the annotator.\n",
        "\n",
        "**ðŸ”— Helpful Links:**\n",
        "\n",
        "For extended examples of usage, see the [Spark NLP Workshop](https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/healthcare-nlp)\n",
        "\n",
        "Python Documentation: [EntityRuler](https://sparknlp.org/api/python/reference/autosummary/sparknlp/annotator/er/entity_ruler/index.html#sparknlp.annotator.er.entity_ruler.EntityRulerApproach)\n",
        "\n",
        "Scala Documentation: [EntityRuler](https://sparknlp.org/api/com/johnsnowlabs/nlp/annotators/er/EntityRulerApproach)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0LGORkHL1m7"
      },
      "source": [
        "There are multiple ways and formats to set the extraction resource. It is\n",
        "   possible to set it either as a \"JSON\", \"JSONL\" or \"CSV\" file. A path to the\n",
        "   file needs to be provided to ``setPatternsResource``. The file format needs\n",
        "   to be set as the \"format\" field in the ``option`` parameter map and\n",
        "   depending on the file type, additional parameters might need to be set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMHhLddZDIUL"
      },
      "source": [
        "**ðŸ–¨ï¸ Input/Output Annotation Types**\n",
        "- Input: ``DOCUMENT`` , ``TOKEN``    \n",
        "- Output: ``CHUNK``"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pb8mUgNwDIUL"
      },
      "source": [
        "**ðŸ”Ž Parameters**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cbkTi5ADIUL"
      },
      "source": [
        "- `setPatternsResource` *(str)*: Sets Resource in JSON or CSV format to map entities to patterns.\n",
        "        path : str\n",
        "            Path to the resource\n",
        "        read_as : str, optional\n",
        "            How to interpret the resource, by default ReadAs.TEXT\n",
        "        options : dict, optional\n",
        "            Options for parsing the resource, by default {\"format\": \"JSON\"}\n",
        "\n",
        "- `setSentenceMatch` *(Boolean)*:Whether to find match at sentence level. True: sentence level. False: token level.\n",
        "\n",
        "- `setAlphabetResource` *(str)*:  Alphabet Resource (a simple plain text with all language characters)\n",
        "\n",
        "- `setUseStorage` *(Boolean)*:  Sets whether to use RocksDB storage to serialize patterns.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTG7BYFc-8j4"
      },
      "source": [
        "## Keywords Patterns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBzPj2C6-rbP"
      },
      "source": [
        "EntityRuler will handle the chunks output based on the patterns defined, as shown in the example below. We can define an id field to identify entities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3pNe6YMdDIUM"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "data = [\n",
        "\n",
        "    {\n",
        "        \"id\": \"drug-words\",\n",
        "        \"label\": \"Drug\",\n",
        "        \"patterns\": [\"paracetamol\", \"aspirin\", \"ibuprofen\", \"lansoprazol\"]\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"disease-words\",\n",
        "        \"label\": \"Disease\",\n",
        "        \"patterns\": [\"heart condition\",\"tonsilitis\",\"GORD\"]\n",
        "    },\n",
        "        {\n",
        "        \"id\": \"symptom-words\",\n",
        "        \"label\": \"Symptom\",\n",
        "        \"patterns\": [\"fever\",\"headache\"]\n",
        "    },\n",
        "\n",
        "]\n",
        "\n",
        "with open(\"entities.json\", \"w\") as f:\n",
        "    json.dump(data, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVN1wYJyDIUM"
      },
      "outputs": [],
      "source": [
        "documentAssembler = nlp.DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "tokenizer = nlp.Tokenizer()\\\n",
        "    .setInputCols([\"document\"])\\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "entityRuler = medical.EntityRulerApproach()\\\n",
        "    .setInputCols([\"document\", \"token\"])\\\n",
        "    .setOutputCol(\"entities\")\\\n",
        "    .setPatternsResource(\"entities.json\")\\\n",
        "    .setCaseSensitive(False)\\\n",
        "\n",
        "pipeline = nlp.Pipeline().setStages([\n",
        "    documentAssembler,\n",
        "    tokenizer,\n",
        "    entityRuler\n",
        "])\n",
        "\n",
        "data = spark.createDataFrame([['''John's doctor prescribed aspirin for his heart condition, along with paracetamol for his fever and headache, amoxicillin for his tonsilitis, ibuprofen for his inflammation, and lansoprazole for his GORD on 2023-12-01.''']]).toDF(\"text\")\n",
        "\n",
        "\n",
        "result = pipeline.fit(data).transform(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_v9vQA59Fgv4"
      },
      "source": [
        "Checking the results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guDERBe9ohjO",
        "outputId": "905082e7-3ca0-45fc-d279-bdf12c1867f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------+-----+---+-------+\n",
            "|          chunk|begin|end|  label|\n",
            "+---------------+-----+---+-------+\n",
            "|     2023-12-01|  206|215|   Date|\n",
            "|        aspirin|   25| 31|   Drug|\n",
            "|heart condition|   41| 55|Disease|\n",
            "|    paracetamol|   69| 79|   Drug|\n",
            "|          fever|   89| 93|Symptom|\n",
            "|       headache|   99|106|Symptom|\n",
            "|     tonsilitis|  129|138|Disease|\n",
            "|      ibuprofen|  141|149|   Drug|\n",
            "|    lansoprazol|  177|187|   Drug|\n",
            "|           GORD|  198|201|Disease|\n",
            "+---------------+-----+---+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result.select(F.explode(F.arrays_zip(result.entities.result,\n",
        "                                      result.entities.begin,\n",
        "                                      result.entities.end,\n",
        "                                      result.entities.metadata,)).alias(\"cols\"))\\\n",
        "      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
        "              F.expr(\"cols['1']\").alias(\"begin\"),\n",
        "              F.expr(\"cols['2']\").alias(\"end\"),\n",
        "              F.expr(\"cols['3']['entity']\").alias('label')).show(truncate=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mXWgzYn_RML"
      },
      "source": [
        "For the CSV file we use the following configuration:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SgFjTW4N-2jJ"
      },
      "outputs": [],
      "source": [
        "with open('./entities.csv', 'w') as csvfile:\n",
        "    csvfile.write('SYMPTOM|fever\\n')\n",
        "    csvfile.write('SYMPTOM|headache\\n')\n",
        "    csvfile.write('DRUG|paracetamol\\n')\n",
        "    csvfile.write('DRUG|aspirin\\n')\n",
        "    csvfile.write('DRUG|lansoprazol\\n')\n",
        "    csvfile.write('DRUG|ibuprofen\\n')\n",
        "    csvfile.write('DISEASE|tonsilitis\\n')\n",
        "    csvfile.write('DISEASE|GORD\\n')\n",
        "    csvfile.write('DISEASE|heart condition')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sar4pyX2AYUh",
        "outputId": "898ad182-f47e-432a-a616-18927ec87bb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SYMPTOM|fever\n",
            "SYMPTOM|headache\n",
            "DRUG|paracetamol\n",
            "DRUG|aspirin\n",
            "DRUG|lansoprazol\n",
            "DRUG|ibuprofen\n",
            "DISEASE|tonsilitis\n",
            "DISEASE|GORD\n",
            "DISEASE|heart condition"
          ]
        }
      ],
      "source": [
        "! cat ./entities.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5o0FLuTAb8-"
      },
      "outputs": [],
      "source": [
        "entity_ruler_csv = nlp.EntityRulerApproach() \\\n",
        "    .setInputCols([\"document\", \"token\"])\\\n",
        "    .setOutputCol(\"entities\")\\\n",
        "    .setPatternsResource(\"./entities.csv\", options={\"format\": \"csv\", \"delimiter\": \"\\\\|\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MD8ZGM9_Au3I"
      },
      "outputs": [],
      "source": [
        "pipeline = nlp.Pipeline().setStages([\n",
        "    documentAssembler,\n",
        "    tokenizer,\n",
        "    entity_ruler_csv\n",
        "])\n",
        "\n",
        "data = spark.createDataFrame([['''John's doctor prescribed aspirin for his heart condition, along with paracetamol for his fever and headache, amoxicillin for his tonsilitis, ibuprofen for his inflammation, and lansoprazole for his GORD on 2023-12-01.''']]).toDF(\"text\")\n",
        "\n",
        "result = pipeline.fit(data).transform(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkTTVSiSFrw7"
      },
      "source": [
        "Checking the results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gJ5jT6wA2Pc",
        "outputId": "fb9d5132-1732-4f22-edae-db838c54fc75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------+-----+---+-------+\n",
            "|          chunk|begin|end|  label|\n",
            "+---------------+-----+---+-------+\n",
            "|        aspirin|   25| 31|   DRUG|\n",
            "|heart condition|   41| 55|DISEASE|\n",
            "|    paracetamol|   69| 79|   DRUG|\n",
            "|          fever|   89| 93|SYMPTOM|\n",
            "|       headache|   99|106|SYMPTOM|\n",
            "|     tonsilitis|  129|138|DISEASE|\n",
            "|      ibuprofen|  141|149|   DRUG|\n",
            "|    lansoprazol|  177|187|   DRUG|\n",
            "|           GORD|  198|201|DISEASE|\n",
            "+---------------+-----+---+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result.select(F.explode(F.arrays_zip(result.entities.result,\n",
        "                                      result.entities.begin,\n",
        "                                      result.entities.end,\n",
        "                                      result.entities.metadata,)).alias(\"cols\"))\\\n",
        "      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
        "              F.expr(\"cols['1']\").alias(\"begin\"),\n",
        "              F.expr(\"cols['2']\").alias(\"end\"),\n",
        "              F.expr(\"cols['3']['entity']\").alias('label')).show(truncate=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPj_R_b5BXKo"
      },
      "source": [
        "## Regex Patterns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ql9ignsGIcc"
      },
      "source": [
        "As shown in the example below we can define regex pattern to detect entities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUS-iAvk-2Vh"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "data = [\n",
        "    {\n",
        "        \"id\": \"date-regex\",\n",
        "        \"label\": \"Date\",\n",
        "        \"patterns\": [\"\\\\d{4}-\\\\d{2}-\\\\d{2}\",\"\\\\d{4}\"],\n",
        "        \"regex\": True\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"drug-words\",\n",
        "        \"label\": \"Drug\",\n",
        "        \"patterns\": [\"paracetamol\", \"aspirin\", \"ibuprofen\", \"lansoprazol\"]\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"disease-words\",\n",
        "        \"label\": \"Disease\",\n",
        "        \"patterns\": [\"heart condition\",\"tonsilitis\",\"GORD\"]\n",
        "    },\n",
        "        {\n",
        "        \"id\": \"symptom-words\",\n",
        "        \"label\": \"Symptom\",\n",
        "        \"patterns\": [\"fever\",\"headache\"]\n",
        "    },\n",
        "]\n",
        "\n",
        "with open(\"entities.json\", \"w\") as f:\n",
        "    json.dump(data, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7priXhxFzBh"
      },
      "outputs": [],
      "source": [
        "entityRuler = nlp.EntityRulerApproach()\\\n",
        "    .setInputCols([\"document\", \"token\"])\\\n",
        "    .setOutputCol(\"entities\")\\\n",
        "    .setPatternsResource(\"entities.json\")\\\n",
        "    .setCaseSensitive(False)\\\n",
        "\n",
        "pipeline = nlp.Pipeline().setStages([\n",
        "    documentAssembler,\n",
        "    tokenizer,\n",
        "    entityRuler\n",
        "])\n",
        "\n",
        "data = spark.createDataFrame([['''John's doctor prescribed aspirin for his heart condition, along with paracetamol for his fever and headache, amoxicillin for his tonsilitis, ibuprofen for his inflammation, and lansoprazole for his GORD on 2023-12-01.''']]).toDF(\"text\")\n",
        "\n",
        "model = pipeline.fit(data)\n",
        "result = model.transform(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGmJ56veF62m"
      },
      "source": [
        "Checking the results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvvqGo9zF2DZ",
        "outputId": "d5083636-23c2-4871-98b8-c00879c2b4aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------+-----+---+-------+\n",
            "|          chunk|begin|end|  label|\n",
            "+---------------+-----+---+-------+\n",
            "|     2023-12-01|  206|215|   Date|\n",
            "|        aspirin|   25| 31|   Drug|\n",
            "|heart condition|   41| 55|Disease|\n",
            "|    paracetamol|   69| 79|   Drug|\n",
            "|          fever|   89| 93|Symptom|\n",
            "|       headache|   99|106|Symptom|\n",
            "|     tonsilitis|  129|138|Disease|\n",
            "|      ibuprofen|  141|149|   Drug|\n",
            "|    lansoprazol|  177|187|   Drug|\n",
            "|           GORD|  198|201|Disease|\n",
            "+---------------+-----+---+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result.select(F.explode(F.arrays_zip(result.entities.result,\n",
        "                                      result.entities.begin,\n",
        "                                      result.entities.end,\n",
        "                                      result.entities.metadata,)).alias(\"cols\"))\\\n",
        "      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
        "              F.expr(\"cols['1']\").alias(\"begin\"),\n",
        "              F.expr(\"cols['2']\").alias(\"end\"),\n",
        "              F.expr(\"cols['3']['entity']\").alias('label')).show(truncate=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMZ8eyXR1ELB"
      },
      "source": [
        "## `EntityRulerModel`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-50Tixl2WLt"
      },
      "source": [
        "This annotator is an instantiated model of the `EntityRulerApproach`. Once you build an `EntityRulerApproach()`, you can save it and use it with `EntityRulerModel()` via `load()` function. <br/>\n",
        "\n",
        "Let's re-build one of examples that we have done before and save it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDZqgtLu1MsY",
        "outputId": "a85fe04d-1859-4b25-ff45-95cce8a0cc97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|text                                                                                                                                                                                                                     |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|John's doctor prescribed aspirin for his heart condition, along with paracetamol for his fever and headache, amoxicillin for his tonsilitis, ibuprofen for his inflammation, and lansoprazole for his GORD on 2023-12-01.|\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data = spark.createDataFrame([[\"John's doctor prescribed aspirin for his heart condition, along with paracetamol for his fever and headache, amoxicillin for his tonsilitis, ibuprofen for his inflammation, and lansoprazole for his GORD on 2023-12-01.\"]]).toDF(\"text\")\n",
        "data.show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PR0nqbeROHIv"
      },
      "source": [
        "Saving the approach to disk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enDQcv8yLqBw"
      },
      "outputs": [],
      "source": [
        "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
        "\n",
        "pipeline_model = pipeline.fit(empty_data)\n",
        "\n",
        "pipeline_model.stages[-1].write().overwrite().save(\"ruler_approach_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2I7E0wkV3C5u"
      },
      "source": [
        "Loading the saved model and using it with the `EntityRulerModel()` via `load`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHdhw2t-6pmL"
      },
      "outputs": [],
      "source": [
        "entity_ruler = nlp.EntityRulerModel.load('/content/ruler_approach_model') \\\n",
        "    .setInputCols([\"document\", \"token\"])\\\n",
        "    .setOutputCol(\"entities\")\n",
        "\n",
        "pipeline = nlp.Pipeline(stages=[documentAssembler,\n",
        "                            tokenizer,\n",
        "                            entity_ruler])\n",
        "\n",
        "result = pipeline.fit(data).transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1bK3KbMCNjE",
        "outputId": "97da6171-e51f-459e-f011-3d61b64b43ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------+-----+---+-------+\n",
            "|          chunk|begin|end|  label|\n",
            "+---------------+-----+---+-------+\n",
            "|     2023-12-01|  206|215|   Date|\n",
            "|        aspirin|   25| 31|   Drug|\n",
            "|heart condition|   41| 55|Disease|\n",
            "|    paracetamol|   69| 79|   Drug|\n",
            "|          fever|   89| 93|Symptom|\n",
            "|       headache|   99|106|Symptom|\n",
            "|     tonsilitis|  129|138|Disease|\n",
            "|      ibuprofen|  141|149|   Drug|\n",
            "|    lansoprazol|  177|187|   Drug|\n",
            "|           GORD|  198|201|Disease|\n",
            "+---------------+-----+---+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result.select(F.explode(F.arrays_zip(result.entities.result,\n",
        "                                      result.entities.begin,\n",
        "                                      result.entities.end,\n",
        "                                      result.entities.metadata,)).alias(\"cols\"))\\\n",
        "      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
        "              F.expr(\"cols['1']\").alias(\"begin\"),\n",
        "              F.expr(\"cols['2']\").alias(\"end\"),\n",
        "              F.expr(\"cols['3']['entity']\").alias('label')).show(truncate=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kT6h7Hoy3Qkw"
      },
      "source": [
        "## Using LightPipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKVlQOmbCofQ"
      },
      "source": [
        "The EntityRuler annotator can also be applied by using LightPipeline:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fPZ67gkDIUQ"
      },
      "outputs": [],
      "source": [
        "light_pipeline = nlp.LightPipeline(pipeline_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIKSF4jxDIUR",
        "outputId": "332d9735-5169-4089-868b-1d939c96ccbb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['document', 'token', 'entities'])"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "annotations = light_pipeline.fullAnnotate(\"John's doctor prescribed aspirin for his heart condition, along with paracetamol for his fever and headache, amoxicillin for his tonsilitis, ibuprofen for his inflammation, and lansoprazole for his GORD on 2023-12-01.\")[0]\n",
        "annotations.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdDIJ_mHDIUR",
        "outputId": "371b036a-e94d-45ec-df2e-6b1412201abd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Annotation(chunk, 206, 215, 2023-12-01, {'entity': 'Date', 'id': 'date-regex', 'sentence': '0'}, []),\n",
              " Annotation(chunk, 25, 31, aspirin, {'entity': 'Drug', 'sentence': '0', 'id': 'drug-words'}, []),\n",
              " Annotation(chunk, 41, 55, heart condition, {'entity': 'Disease', 'sentence': '0', 'id': 'disease-words'}, []),\n",
              " Annotation(chunk, 69, 79, paracetamol, {'entity': 'Drug', 'sentence': '0', 'id': 'drug-words'}, []),\n",
              " Annotation(chunk, 89, 93, fever, {'entity': 'Symptom', 'sentence': '0', 'id': 'symptom-words'}, []),\n",
              " Annotation(chunk, 99, 106, headache, {'entity': 'Symptom', 'sentence': '0', 'id': 'symptom-words'}, []),\n",
              " Annotation(chunk, 129, 138, tonsilitis, {'entity': 'Disease', 'sentence': '0', 'id': 'disease-words'}, []),\n",
              " Annotation(chunk, 141, 149, ibuprofen, {'entity': 'Drug', 'sentence': '0', 'id': 'drug-words'}, []),\n",
              " Annotation(chunk, 177, 187, lansoprazol, {'entity': 'Drug', 'sentence': '0', 'id': 'drug-words'}, []),\n",
              " Annotation(chunk, 198, 201, GORD, {'entity': 'Disease', 'sentence': '0', 'id': 'disease-words'}, [])]"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "annotations.get('entities')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydk_StFlDIUR"
      },
      "source": [
        "Display the result with `spark-nlp-display`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "8CBQQcK4DIUR",
        "outputId": "04c2d59b-b1ef-4e73-83b7-1c378a6a9a0f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    @import url('https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700&display=swap');\n",
              "    @import url('https://fonts.googleapis.com/css2?family=Vistol Regular:wght@300;400;500;600;700&display=swap');\n",
              "    \n",
              "    .spark-nlp-display-scroll-entities {\n",
              "        border: 1px solid #E7EDF0;\n",
              "        border-radius: 3px;\n",
              "        text-align: justify;\n",
              "        \n",
              "    }\n",
              "    .spark-nlp-display-scroll-entities span {  \n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        color: #536B76;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "    }\n",
              "    \n",
              "    .spark-nlp-display-entity-wrapper{\n",
              "    \n",
              "        display: inline-grid;\n",
              "        text-align: center;\n",
              "        border-radius: 4px;\n",
              "        margin: 0 2px 5px 2px;\n",
              "        padding: 1px\n",
              "    }\n",
              "    .spark-nlp-display-entity-name{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "        \n",
              "        background: #f1f2f3;\n",
              "        border-width: medium;\n",
              "        text-align: center;\n",
              "        \n",
              "        font-weight: 400;\n",
              "        \n",
              "        border-radius: 5px;\n",
              "        padding: 2px 5px;\n",
              "        display: block;\n",
              "        margin: 3px 2px;\n",
              "    \n",
              "    }\n",
              "    .spark-nlp-display-entity-type{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        color: #ffffff;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "        \n",
              "        text-transform: uppercase;\n",
              "        \n",
              "        font-weight: 500;\n",
              "\n",
              "        display: block;\n",
              "        padding: 3px 5px;\n",
              "    }\n",
              "    \n",
              "    .spark-nlp-display-entity-resolution{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        color: #ffffff;\n",
              "        font-family: 'Vistol Regular', sans-serif !important;\n",
              "        \n",
              "        text-transform: uppercase;\n",
              "        \n",
              "        font-weight: 500;\n",
              "\n",
              "        display: block;\n",
              "        padding: 3px 5px;\n",
              "    }\n",
              "    \n",
              "    .spark-nlp-display-others{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "        \n",
              "        font-weight: 400;\n",
              "    }\n",
              "\n",
              "</style>\n",
              " <span class=\"spark-nlp-display-others\" style=\"background-color: white\">John's doctor prescribed </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #8B668B\"><span class=\"spark-nlp-display-entity-name\">aspirin </span><span class=\"spark-nlp-display-entity-type\">Drug</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> for his </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #B63FA3\"><span class=\"spark-nlp-display-entity-name\">heart condition </span><span class=\"spark-nlp-display-entity-type\">Disease</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, along with </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #8B668B\"><span class=\"spark-nlp-display-entity-name\">paracetamol </span><span class=\"spark-nlp-display-entity-type\">Drug</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> for his </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #4C60BF\"><span class=\"spark-nlp-display-entity-name\">fever </span><span class=\"spark-nlp-display-entity-type\">Symptom</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> and </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #4C60BF\"><span class=\"spark-nlp-display-entity-name\">headache </span><span class=\"spark-nlp-display-entity-type\">Symptom</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, amoxicillin for his </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #B63FA3\"><span class=\"spark-nlp-display-entity-name\">tonsilitis </span><span class=\"spark-nlp-display-entity-type\">Disease</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">, </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #8B668B\"><span class=\"spark-nlp-display-entity-name\">ibuprofen </span><span class=\"spark-nlp-display-entity-type\">Drug</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> for his inflammation, and </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #8B668B\"><span class=\"spark-nlp-display-entity-name\">lansoprazol </span><span class=\"spark-nlp-display-entity-type\">Drug</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">e for his </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #B63FA3\"><span class=\"spark-nlp-display-entity-name\">GORD </span><span class=\"spark-nlp-display-entity-type\">Disease</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> on </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #a6b1e1\"><span class=\"spark-nlp-display-entity-name\">2023-12-01 </span><span class=\"spark-nlp-display-entity-type\">Date</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">.</span></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sparknlp_display import NerVisualizer\n",
        "\n",
        "visualiser = NerVisualizer()\n",
        "\n",
        "visualiser.display(annotations, label_col='entities')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}