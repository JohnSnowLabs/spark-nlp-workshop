{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
      ],
      "metadata": {
        "id": "QQPGw6UQOjgo"
      }

  }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/healthcare-nlp/01.3.BertForTokenClassification_NER_ONNX_SparkNLP_with_Transformers.ipynb)"
      ],
      "metadata": {
        "id": "ulQyWepeOlg3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnLd2l8QDSfl"
      },
      "source": [
        "# Medical NER: BertForTokenClassification ‚Üí ONNX ‚Üí Spark NLP JSL\n",
        "\n",
        "This notebook trains a Named Entity Recognition model on NCBI Disease corpus using BertForTokenClassification, exports it to ONNX format, and prepares it for **licensed** `johnsnowlabs` deployment.\n",
        "\n",
        "## Pipeline Steps:\n",
        "1. Download NCBI CoNLL dataset\n",
        "2. Train BertForTokenClassification model\n",
        "3. Export to ONNX format\n",
        "4. Test ONNX inference\n",
        "5. Package for Spark NLP JSL\n",
        "\n",
        "**Dataset:** NCBI Disease CoNLL format from John Snow Labs workshop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqI862qGDSfw"
      },
      "source": [
        "## 1. Installation and Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QtfLycQxDSfy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e9d7b13-1ec7-4aa8-cac6-867c546fa8ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout"
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install -q torch transformers datasets\n",
        "!pip install -q onnx onnxruntime\n",
        "!pip install -q seqeval scikit-learn\n",
        "\n",
        "print(\"‚úÖ All packages installed successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeNm_vbXDSf0"
      },
      "source": [
        "## 2. Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCPq0R-6DSf1",
        "outputId": "caa0f804-593b-4561-cfef-71dc2203468e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import (\n",
        "    BertTokenizer,\n",
        "    BertForTokenClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorForTokenClassification\n",
        ")\n",
        "import numpy as np\n",
        "import onnx\n",
        "import onnxruntime\n",
        "from typing import Dict, List, Tuple\n",
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "from seqeval.metrics import classification_report, f1_score\n",
        "from sklearn.metrics import classification_report as sklearn_report\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from collections import Counter\n",
        "\n",
        "print(\"‚úÖ Libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TL9sPb_6DSf2"
      },
      "source": [
        "## 3. Parse CoNLL Format Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cF_sbMBvDSf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26015637-70cb-421d-d8d9-d9cc4dbb8997"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Updated parse_conll_file defined\n"
          ]
        }
      ],
      "source": [
        "def parse_conll_file(file_path):\n",
        "    \"\"\"\n",
        "    Parse CoNLL format file and filter sentences with multiple unique tags\n",
        "\n",
        "    Format:\n",
        "    token1 tag1\n",
        "    token2 tag2\n",
        "    (empty line = sentence boundary)\n",
        "\n",
        "    Filters out sentences with only one unique tag (e.g., all \"O\" tags)\n",
        "    \"\"\"\n",
        "    sentences = []\n",
        "    tags = []\n",
        "\n",
        "    current_tokens = []\n",
        "    current_tags = []\n",
        "\n",
        "    special_char_tokens = []\n",
        "\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "\n",
        "            if line == \"\" or line.startswith(\"-DOCSTART-\"):\n",
        "                if current_tokens:\n",
        "                    unique_tags = set(current_tags)\n",
        "                    if len(unique_tags) > 1:\n",
        "                        sentences.append(current_tokens)\n",
        "                        tags.append(current_tags)\n",
        "\n",
        "                    current_tokens = []\n",
        "                    current_tags = []\n",
        "            else:\n",
        "                parts = line.split()\n",
        "                if len(parts) >= 2:\n",
        "                    token = parts[0]\n",
        "                    tag = parts[-1]\n",
        "                    current_tokens.append(token)\n",
        "                    current_tags.append(tag)\n",
        "\n",
        "    if current_tokens:\n",
        "        unique_tags = set(current_tags)\n",
        "        if len(unique_tags) > 1:\n",
        "            sentences.append(current_tokens)\n",
        "            tags.append(current_tags)\n",
        "\n",
        "\n",
        "    return sentences, tags\n",
        "\n",
        "\n",
        "print(\"‚úÖ Updated parse_conll_file defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load CoNLL Data"
      ],
      "metadata": {
        "id": "tyP-unet8AWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download NCBI CoNLL files\n",
        "!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/refs/heads/master/tutorials/Certification_Trainings/Healthcare/data/NER_NCBIconlltrain.txt -O train.conll\n",
        "!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/refs/heads/master/tutorials/Certification_Trainings/Healthcare/data/NER_NCBIconlltest.txt -O test.conll\n",
        "\n",
        "print(\"‚úÖ Files downloaded successfully!\")\n",
        "print(\"  - train.conll\")\n",
        "print(\"  - test.conll\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDWfY81v8Fbe",
        "outputId": "3b0fc31c-fe06-4bcd-ce42-4f7d08e0dbd4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Files downloaded successfully!\n",
            "  - train.conll\n",
            "  - test.conll\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_conll_data():\n",
        "    \"\"\"Load CoNLL dataset\"\"\"\n",
        "\n",
        "    print(\"\\nüìö Loading CoNLL dataset...\")\n",
        "\n",
        "    # Parse train and test files\n",
        "    train_sentences, train_tags = parse_conll_file(\"train.conll\")\n",
        "    test_sentences, test_tags = parse_conll_file(\"test.conll\")\n",
        "\n",
        "    # Get unique labels\n",
        "    all_tags = set()\n",
        "    for tags in train_tags + test_tags:\n",
        "        all_tags.update(tags)\n",
        "\n",
        "    label_list = sorted(list(all_tags))\n",
        "    label2id = {label: i for i, label in enumerate(label_list)}\n",
        "    id2label = {i: label for i, label in enumerate(label_list)}\n",
        "\n",
        "    print(f\"‚úì Dataset loaded\")\n",
        "    print(f\"  - Train sentences: {len(train_sentences)}\")\n",
        "    print(f\"  - Test sentences: {len(test_sentences)}\")\n",
        "    print(f\"  - Unique labels: {label_list}\")\n",
        "    print(f\"  - Number of labels: {len(label_list)}\")\n",
        "\n",
        "    # Print label distribution\n",
        "    train_tag_counts = Counter([tag for tags in train_tags for tag in tags])\n",
        "    print(f\"\\nüìä Label distribution in training set:\")\n",
        "    for label, count in train_tag_counts.most_common():\n",
        "        print(f\"  {label}: {count}\")\n",
        "\n",
        "    test_tag_counts = Counter([tag for tags in test_tags for tag in tags])\n",
        "    print(f\"\\nüìä Label distribution in test set:\")\n",
        "    for label, count in test_tag_counts.most_common():\n",
        "        print(f\"  {label}: {count}\")\n",
        "\n",
        "    return {\n",
        "        'train': {'sentences': train_sentences, 'tags': train_tags},\n",
        "        'test': {'sentences': test_sentences, 'tags': test_tags},\n",
        "        'label_list': label_list,\n",
        "        'label2id': label2id,\n",
        "        'id2label': id2label\n",
        "    }\n",
        "\n",
        "# Load the data\n",
        "data = load_conll_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIrvUzVS78Mg",
        "outputId": "038efda5-d390-496a-b1fe-4dd1c447cebd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìö Loading CoNLL dataset...\n",
            "‚úì Dataset loaded\n",
            "  - Train sentences: 1700\n",
            "  - Test sentences: 392\n",
            "  - Unique labels: ['B-Disease', 'I-Disease', 'O']\n",
            "  - Number of labels: 3\n",
            "\n",
            "üìä Label distribution in training set:\n",
            "  O: 39427\n",
            "  I-Disease: 3547\n",
            "  B-Disease: 3093\n",
            "\n",
            "üìä Label distribution in test set:\n",
            "  O: 9316\n",
            "  I-Disease: 789\n",
            "  B-Disease: 708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMJvEQdXDSf5"
      },
      "source": [
        "## 4. Create PyTorch Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuO2_M5lDSf6",
        "outputId": "0a558d5b-36b9-46cb-9355-4f0bff773333"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ NERDataset class defined\n"
          ]
        }
      ],
      "source": [
        "class NERDataset(Dataset):\n",
        "    \"\"\"Custom NER Dataset for CoNLL format\"\"\"\n",
        "\n",
        "    def __init__(self, sentences, tags, tokenizer, label2id, max_length=128):\n",
        "        self.sentences = sentences\n",
        "        self.tags = tags\n",
        "        self.tokenizer = tokenizer\n",
        "        self.label2id = label2id\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tokens = self.sentences[idx]\n",
        "        labels = self.tags[idx]\n",
        "\n",
        "        # Tokenize with is_split_into_words=True\n",
        "        encoding = self.tokenizer(\n",
        "            tokens,\n",
        "            is_split_into_words=True,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt',\n",
        "        )\n",
        "\n",
        "        # Align labels with subword tokens\n",
        "        word_ids = encoding.word_ids(batch_index=0)\n",
        "        label_ids = []\n",
        "        previous_word_idx = None\n",
        "\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                # Special tokens ([CLS], [SEP], [PAD]) get -100\n",
        "                label_ids.append(-100)\n",
        "            elif word_idx != previous_word_idx:\n",
        "                # First subword of a word gets the original label\n",
        "                label_ids.append(self.label2id[labels[word_idx]])\n",
        "            else:\n",
        "                # Continuation subwords get I- version of the label\n",
        "                original_label = labels[word_idx]\n",
        "\n",
        "                if original_label == 'O':\n",
        "                    # O labels stay O\n",
        "                    label_ids.append(self.label2id['O'])\n",
        "                elif original_label.startswith('B-'):\n",
        "                    # B- becomes I- for continuation subwords\n",
        "                    entity_type = original_label[2:]  # Remove 'B-'\n",
        "                    continuation_label = f'I-{entity_type}'\n",
        "                    label_ids.append(self.label2id[continuation_label])\n",
        "                elif original_label.startswith('I-'):\n",
        "                    # I- stays I- for continuation subwords\n",
        "                    label_ids.append(self.label2id[original_label])\n",
        "                else:\n",
        "                    # Fallback: use -100\n",
        "                    label_ids.append(-100)\n",
        "\n",
        "            previous_word_idx = word_idx\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label_ids)\n",
        "        }\n",
        "\n",
        "print(\"‚úÖ NERDataset class defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXAuKLHiDSf7"
      },
      "source": [
        "## 5. Define Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "uqT4aAHADSf8"
      },
      "outputs": [],
      "source": [
        "label_list = data['label_list']\n",
        "\n",
        "# Initialize tracking variables\n",
        "epoch_counter = {\n",
        "    \"current\": 1,\n",
        "    \"best_epoch\": 0,\n",
        "    \"best_f1\": 0.0,\n",
        "    \"best_metrics\": {}\n",
        "}\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    \"\"\"Compute NER metrics using sklearn (token-level) for each epoch\"\"\"\n",
        "\n",
        "    predictions, labels = pred\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    # Flatten predictions and labels, removing ignored index (-100)\n",
        "    flat_predictions = []\n",
        "    flat_labels = []\n",
        "\n",
        "    for prediction, label in zip(predictions, labels):\n",
        "        for p, l in zip(prediction, label):\n",
        "            if l != -100:  # Skip special tokens\n",
        "                flat_predictions.append(p)\n",
        "                flat_labels.append(l)\n",
        "\n",
        "    # Convert to label names\n",
        "    pred_labels = [label_list[p] for p in flat_predictions]\n",
        "    true_labels = [label_list[l] for l in flat_labels]\n",
        "\n",
        "    # Compute overall metrics for tracking\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        true_labels,\n",
        "        pred_labels,\n",
        "        average='weighted',\n",
        "        zero_division=0\n",
        "    )\n",
        "\n",
        "    # Track best epoch silently (only during training)\n",
        "    if not epoch_counter.get('is_final', False) and f1 > epoch_counter['best_f1']:\n",
        "        epoch_counter['best_epoch'] = epoch_counter['current']\n",
        "        epoch_counter['best_f1'] = f1\n",
        "        epoch_counter['best_metrics'] = {\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1': f1\n",
        "        }\n",
        "\n",
        "    # Print header based on mode\n",
        "    if epoch_counter.get('is_final', False):\n",
        "        header = \"üìä FINAL TOKEN-LEVEL METRICS\"\n",
        "    else:\n",
        "        header = f\"üìä METRICS - Epoch {epoch_counter['current']}\"\n",
        "\n",
        "    # Print detailed sklearn classification report (token-level)\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(header)\n",
        "    print(\"=\"*70)\n",
        "    report = sklearn_report(\n",
        "        true_labels,\n",
        "        pred_labels,\n",
        "        digits=4,\n",
        "        zero_division=0\n",
        "    )\n",
        "    print(report)\n",
        "    print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "    # Increment counter only during training\n",
        "    if not epoch_counter.get('is_final', False):\n",
        "        epoch_counter['current'] += 1\n",
        "\n",
        "    results = {\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1\n",
        "    }\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PyPw8o_DSf8"
      },
      "source": [
        "## 6. Train BertForTokenClassification Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0b87cbf4d30e4e8581368d4f400a3e7d",
            "698455572bf2405cb0eb4edf7689f790",
            "01fd85d7b6c74a4488dc5edd1c30d018",
            "ef4455944a704cfcad2646af64ca9ee9",
            "bc3185d5debe49b2b167beb4963f048e",
            "44062565cf38445fa0b2efe5000d08d5",
            "95e9cc9cf44d4c4c96f6dc6e775f4399",
            "d758015326184d1697b177a4076b4395",
            "4b498904a4cf4b699c49c4050f99824f",
            "0e4c3a3c286241e090d319fa9a6ad8c6",
            "596df54232fc4ad693471dfd4a0e3574",
            "d32aaa21c039489ea4dd829e2bde88a9",
            "1b2900d0a11340dcaa60e19e64841955",
            "039cf2a614364347a72d9a3bd358617a",
            "3ce3d1719f884ea48d182aa5061a226c",
            "e12c6c78909d461e9920987541559963",
            "9879f269368b4999b89610a55adba5f4",
            "94e146e1a4954cda8cd9e2b65e47e669",
            "6cb2986be1754d1ab65085b236b99717",
            "ad83108b409b4b618c835141a85d3d91",
            "d18470ce7fee47e7985698a727f95060",
            "0c4a9c66a7534c61bde748678b11e0d1",
            "03dbeac12fbf40b88fc3d900a04c53d6",
            "b4344d579c604f1c8380d5824ac8d674",
            "52a8f2ad029a424dbe8920d71e2e8542",
            "cb594e99fb7b48e6bd45f9c661109447",
            "9f79c7e8162848a0b60153a7c082e668",
            "a254e2764b6b4a2184513803a0843199",
            "a5aee8ca32394c4dbe43eebad6e263aa",
            "78e25fb0380a4d5ea1347e6dfeb97a2e",
            "7ad3f14fc1164761816484b474240ef4",
            "8012ac212a1d4d10932708844e93cfbf",
            "60c24e5a9e9f42a2958f75bcda479746",
            "a3116388bc1b4a5f80522399be215aa8",
            "e0c69decbbc845f9b34aaa464eda7599",
            "6172c52ce98b442ba427e0cbc3e6ade2",
            "e8ca03340ba3448abee735d9edf1c237",
            "73db59befb22494aba2fa4583d08d51e",
            "67164480c5984462842234109de102f1",
            "d84dbf19a0984e0e94232066c0c1e935",
            "e6294b075ee942d797762a70a31740d4",
            "216e3e9f60944cad90d8f9d9fd4d622a",
            "77a646a3d6a94185bf26f78e68e88ec6",
            "d0e89bd04b0445ec90536984466c8609"
          ]
        },
        "id": "rg_dRy2NDSf8",
        "outputId": "845a0903-6a90-41dc-d483-d38fb59b25e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîß Initializing BertTokenizer and BertForTokenClassification...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b87cbf4d30e4e8581368d4f400a3e7d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d32aaa21c039489ea4dd829e2bde88a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "03dbeac12fbf40b88fc3d900a04c53d6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Model initialized with 3 labels\n",
            "\n",
            "üìù Creating PyTorch datasets...\n",
            "‚úì Train dataset: 1700 samples\n",
            "‚úì Test dataset: 392 samples\n",
            "üöÄ We are starting training...\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a3116388bc1b4a5f80522399be215aa8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='639' max='639' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [639/639 01:10, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.091700</td>\n",
              "      <td>0.087462</td>\n",
              "      <td>0.969373</td>\n",
              "      <td>0.968185</td>\n",
              "      <td>0.968555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.045600</td>\n",
              "      <td>0.073573</td>\n",
              "      <td>0.974329</td>\n",
              "      <td>0.973744</td>\n",
              "      <td>0.973953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.014000</td>\n",
              "      <td>0.088126</td>\n",
              "      <td>0.975076</td>\n",
              "      <td>0.974414</td>\n",
              "      <td>0.974630</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "üìä METRICS - Epoch 1\n",
            "======================================================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   B-Disease     0.8730    0.9124    0.8923       708\n",
            "   I-Disease     0.9034    0.9603    0.9310      2570\n",
            "           O     0.9898    0.9733    0.9815     11652\n",
            "\n",
            "    accuracy                         0.9682     14930\n",
            "   macro avg     0.9220    0.9487    0.9349     14930\n",
            "weighted avg     0.9694    0.9682    0.9686     14930\n",
            "\n",
            "======================================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "üìä METRICS - Epoch 2\n",
            "======================================================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   B-Disease     0.8783    0.9379    0.9071       708\n",
            "   I-Disease     0.9319    0.9533    0.9425      2570\n",
            "           O     0.9895    0.9804    0.9850     11652\n",
            "\n",
            "    accuracy                         0.9737     14930\n",
            "   macro avg     0.9332    0.9572    0.9448     14930\n",
            "weighted avg     0.9743    0.9737    0.9740     14930\n",
            "\n",
            "======================================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "üìä METRICS - Epoch 3\n",
            "======================================================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   B-Disease     0.8995    0.9350    0.9169       708\n",
            "   I-Disease     0.9243    0.9638    0.9436      2570\n",
            "           O     0.9909    0.9791    0.9850     11652\n",
            "\n",
            "    accuracy                         0.9744     14930\n",
            "   macro avg     0.9382    0.9593    0.9485     14930\n",
            "weighted avg     0.9751    0.9744    0.9746     14930\n",
            "\n",
            "======================================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "üéØ TRAINING COMPLETE - BEST MODEL SUMMARY\n",
            "======================================================================\n",
            "üèÜ Best Epoch: 3\n",
            "üìä Best F1 Score: 0.9746\n",
            "üìä Best Precision: 0.9751\n",
            "üìä Best Recall: 0.9744\n",
            "======================================================================\n",
            "\n",
            "‚úÖ Best epoch info saved to ./ncbi_ner_model/best_epoch_info.json\n"
          ]
        }
      ],
      "source": [
        "# Initialize tracking variables\n",
        "epoch_counter = {\n",
        "    \"current\": 1,\n",
        "    \"best_epoch\": 0,\n",
        "    \"best_f1\": 0.0,\n",
        "    \"best_metrics\": {}\n",
        "}\n",
        "\n",
        "# Configuration\n",
        "MODEL_NAME = 'dmis-lab/biobert-base-cased-v1.2'\n",
        "OUTPUT_DIR = \"./ncbi_ner_model\"\n",
        "NUM_EPOCHS = 3\n",
        "BATCH_SIZE = 8\n",
        "LEARNING_RATE = 2e-05\n",
        "\n",
        "print(\"\\nüîß Initializing BertTokenizer and BertForTokenClassification...\")\n",
        "from transformers import BertTokenizerFast, BertForTokenClassification\n",
        "\n",
        "# CRITICAL: Configure tokenizer properly for medical text\n",
        "tokenizer = BertTokenizerFast.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    do_lower_case=False,          # BioBERT is cased\n",
        "    strip_accents=None,            # Let model decide\n",
        "    clean_text=True,               # Remove control chars\n",
        "    tokenize_chinese_chars=True,   # Standard BERT behavior\n",
        "    do_basic_tokenize=True,         # Essential for proper tokenization\n",
        "    never_split=['[UNK]', '[SEP]', '[PAD]', '[CLS]', '[MASK]']\n",
        ")\n",
        "\n",
        "model = BertForTokenClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=len(label_list),\n",
        "    id2label=data['id2label'],\n",
        "    label2id=data['label2id']\n",
        ")\n",
        "\n",
        "print(f\"‚úì Model initialized with {len(label_list)} labels\")\n",
        "\n",
        "# Create datasets\n",
        "print(\"\\nüìù Creating PyTorch datasets...\")\n",
        "train_dataset = NERDataset(\n",
        "    data['train']['sentences'],\n",
        "    data['train']['tags'],\n",
        "    tokenizer,\n",
        "    data['label2id']\n",
        ")\n",
        "\n",
        "test_dataset = NERDataset(\n",
        "    data['test']['sentences'],\n",
        "    data['test']['tags'],\n",
        "    tokenizer,\n",
        "    data['label2id']\n",
        ")\n",
        "\n",
        "print(f\"‚úì Train dataset: {len(train_dataset)} samples\")\n",
        "print(f\"‚úì Test dataset: {len(test_dataset)} samples\")\n",
        "\n",
        "# Data collator\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    num_train_epochs=NUM_EPOCHS,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=f\"{OUTPUT_DIR}/logs\",\n",
        "    logging_steps=50,\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    greater_is_better=True,\n",
        "    push_to_hub=False,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    processing_class=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "print(\"üöÄ We are starting training...\")\n",
        "print(\"=\" * 70)\n",
        "trainer.train()\n",
        "\n",
        "# Display best model information\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üéØ TRAINING COMPLETE - BEST MODEL SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "print(f\"üèÜ Best Epoch: {epoch_counter['best_epoch']}\")\n",
        "print(f\"üìä Best F1 Score: {epoch_counter['best_f1']:.4f}\")\n",
        "print(f\"üìä Best Precision: {epoch_counter['best_metrics']['precision']:.4f}\")\n",
        "print(f\"üìä Best Recall: {epoch_counter['best_metrics']['recall']:.4f}\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# Save best epoch info with the model\n",
        "best_epoch_info = {\n",
        "    \"best_epoch\": epoch_counter['best_epoch'],\n",
        "    \"best_f1\": float(epoch_counter['best_f1']),\n",
        "    \"best_precision\": float(epoch_counter['best_metrics']['precision']),\n",
        "    \"best_recall\": float(epoch_counter['best_metrics']['recall'])\n",
        "}\n",
        "\n",
        "with open(f\"{OUTPUT_DIR}/best_epoch_info.json\", \"w\") as f:\n",
        "    json.dump(best_epoch_info, f, indent=2)\n",
        "\n",
        "print(f\"‚úÖ Best epoch info saved to {OUTPUT_DIR}/best_epoch_info.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGddp0TnDSf-"
      },
      "source": [
        "## 7. Evaluate and Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGfiTngODSf-",
        "outputId": "6a4e36bd-340f-4fc8-dd2c-29cdf9173712"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Seqeval evaluation function defined\n"
          ]
        }
      ],
      "source": [
        "def evaluate_with_seqeval(model, dataset, tokenizer, label_list, batch_size=16):\n",
        "    \"\"\"Evaluate model using seqeval (chunk-level metrics)\"\"\"\n",
        "    from seqeval.metrics import classification_report, precision_score, recall_score, f1_score\n",
        "    from torch.utils.data import DataLoader\n",
        "\n",
        "    model.eval()\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
        "    all_predictions, all_labels = [], []\n",
        "\n",
        "    # Get predictions\n",
        "    for batch in dataloader:\n",
        "        with torch.no_grad():\n",
        "            input_ids = batch['input_ids'].to(model.device)\n",
        "            attention_mask = batch['attention_mask'].to(model.device)\n",
        "            labels = batch['labels']\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            predictions = torch.argmax(outputs.logits, dim=-1).cpu().numpy()\n",
        "            labels = labels.numpy()\n",
        "\n",
        "            # Convert to label sequences\n",
        "            for pred, label in zip(predictions, labels):\n",
        "                pred_seq = [label_list[p] for p, l in zip(pred, label) if l != -100]\n",
        "                label_seq = [label_list[l] for l in label if l != -100]\n",
        "                if pred_seq:\n",
        "                    all_predictions.append(pred_seq)\n",
        "                    all_labels.append(label_seq)\n",
        "\n",
        "    # Compute and print metrics\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"üéØFINAL ENTITY-LEVEL EVALUATION\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"Precision: {precision_score(all_labels, all_predictions):.4f}\")\n",
        "    print(f\"Recall:    {recall_score(all_labels, all_predictions):.4f}\")\n",
        "    print(f\"F1-Score:  {f1_score(all_labels, all_predictions):.4f}\\n\")\n",
        "    print(classification_report(all_labels, all_predictions, digits=4))\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    return {\n",
        "        \"precision\": precision_score(all_labels, all_predictions),\n",
        "        \"recall\": recall_score(all_labels, all_predictions),\n",
        "        \"f1\": f1_score(all_labels, all_predictions)\n",
        "    }\n",
        "\n",
        "print(\"‚úÖ Seqeval evaluation function defined\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set flag for final evaluation (don't reset counter!)\n",
        "epoch_counter['is_final'] = True\n",
        "\n",
        "# Token-level evaluation\n",
        "eval_results = trainer.evaluate()\n",
        "print(f\"F1:        {eval_results['eval_f1']:.4f}\")\n",
        "print(f\"Precision: {eval_results['eval_precision']:.4f}\")\n",
        "print(f\"Recall:    {eval_results['eval_recall']:.4f}\")\n",
        "print(f\"Loss:      {eval_results['eval_loss']:.4f}\")\n",
        "\n",
        "# Entity-level evaluation\n",
        "seqeval_results = evaluate_with_seqeval(model, test_dataset, tokenizer, label_list, batch_size=16)\n",
        "\n",
        "# Show best epoch summary\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"üèÜ BEST MODEL SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Best Epoch: {epoch_counter['best_epoch']}\")\n",
        "print(f\"Best F1:    {epoch_counter['best_f1']:.4f}\")\n",
        "print(f\"Precision:  {epoch_counter['best_metrics']['precision']:.4f}\")\n",
        "print(f\"Recall:     {epoch_counter['best_metrics']['recall']:.4f}\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Save everything\n",
        "print(\"\\nüíæ Saving model and results...\")\n",
        "trainer.save_model(OUTPUT_DIR)\n",
        "tokenizer.save_pretrained(OUTPUT_DIR)\n",
        "\n",
        "# Save labels and mappings\n",
        "with open(f\"{OUTPUT_DIR}/tags.txt\", \"w\") as f:\n",
        "    f.write('\\n'.join(label_list))\n",
        "\n",
        "label_info = {\n",
        "    \"label2id\": data['label2id'],\n",
        "    \"id2label\": data['id2label'],\n",
        "    \"labels\": label_list\n",
        "}\n",
        "with open(f\"{OUTPUT_DIR}/label_mappings.json\", \"w\") as f:\n",
        "    json.dump(label_info, f, indent=2)\n",
        "\n",
        "# Save evaluation results\n",
        "eval_summary = {\n",
        "    \"best_epoch\": {\n",
        "        \"epoch\": epoch_counter['best_epoch'],\n",
        "        \"f1\": float(epoch_counter['best_f1']),\n",
        "        \"precision\": float(epoch_counter['best_metrics']['precision']),\n",
        "        \"recall\": float(epoch_counter['best_metrics']['recall'])\n",
        "    },\n",
        "    \"final_token_level\": {\n",
        "        \"precision\": float(eval_results['eval_precision']),\n",
        "        \"recall\": float(eval_results['eval_recall']),\n",
        "        \"f1\": float(eval_results['eval_f1']),\n",
        "        \"loss\": float(eval_results['eval_loss'])\n",
        "    },\n",
        "    \"final_entity_level\": {\n",
        "        \"precision\": float(seqeval_results['precision']),\n",
        "        \"recall\": float(seqeval_results['recall']),\n",
        "        \"f1\": float(seqeval_results['f1'])\n",
        "    }\n",
        "}\n",
        "with open(f\"{OUTPUT_DIR}/evaluation_results.json\", \"w\") as f:\n",
        "    json.dump(eval_summary, f, indent=2)\n",
        "\n",
        "print(f\"\\n‚úÖ All results saved to {OUTPUT_DIR}\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Reset flag\n",
        "epoch_counter['is_final'] = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 948
        },
        "id": "VCeCXoklzLSS",
        "outputId": "2fd41a88-7868-44ff-bc83-561b37e37f00"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [49/49 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "üìä FINAL TOKEN-LEVEL METRICS\n",
            "======================================================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   B-Disease     0.8995    0.9350    0.9169       708\n",
            "   I-Disease     0.9243    0.9638    0.9436      2570\n",
            "           O     0.9909    0.9791    0.9850     11652\n",
            "\n",
            "    accuracy                         0.9744     14930\n",
            "   macro avg     0.9382    0.9593    0.9485     14930\n",
            "weighted avg     0.9751    0.9744    0.9746     14930\n",
            "\n",
            "======================================================================\n",
            "\n",
            "F1:        0.9746\n",
            "Precision: 0.9751\n",
            "Recall:    0.9744\n",
            "Loss:      0.0881\n",
            "\n",
            "======================================================================\n",
            "üéØFINAL ENTITY-LEVEL EVALUATION\n",
            "======================================================================\n",
            "Precision: 0.8498\n",
            "Recall:    0.9110\n",
            "F1-Score:  0.8793\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Disease     0.8498    0.9110    0.8793       708\n",
            "\n",
            "   micro avg     0.8498    0.9110    0.8793       708\n",
            "   macro avg     0.8498    0.9110    0.8793       708\n",
            "weighted avg     0.8498    0.9110    0.8793       708\n",
            "\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "üèÜ BEST MODEL SUMMARY\n",
            "======================================================================\n",
            "Best Epoch: 3\n",
            "Best F1:    0.9746\n",
            "Precision:  0.9751\n",
            "Recall:     0.9744\n",
            "======================================================================\n",
            "\n",
            "üíæ Saving model and results...\n",
            "\n",
            "‚úÖ All results saved to ./ncbi_ner_model\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfbkNfS7DSf-"
      },
      "source": [
        "## 8. Test Model Predictions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüß™ Testing model predictions...\")\n",
        "\n",
        "# Load model for inference\n",
        "model = BertForTokenClassification.from_pretrained(OUTPUT_DIR)\n",
        "tokenizer = BertTokenizer.from_pretrained(OUTPUT_DIR)\n",
        "model.eval()\n",
        "\n",
        "with open(f\"{OUTPUT_DIR}/label_mappings.json\", \"r\") as f:\n",
        "    label_info = json.load(f)\n",
        "id2label = {int(k): v for k, v in label_info['id2label'].items()}\n",
        "\n",
        "# Test examples\n",
        "test_texts = [\n",
        "    \"Breast cancer is a disease in which cells in the breast grow out of control.\",\n",
        "    \"Patients with diabetes mellitus require insulin therapy.\",\n",
        "    \"Alzheimer disease is characterized by progressive cognitive deterioration.\"\n",
        "]\n",
        "\n",
        "for text in test_texts:\n",
        "    print(f\"\\nüìù Text: {text}\")\n",
        "\n",
        "    # Tokenize\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"pt\",\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=512\n",
        "    )\n",
        "\n",
        "    # Predict\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    predictions = torch.argmax(outputs.logits, dim=2)\n",
        "\n",
        "    # Get tokens and labels\n",
        "    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
        "    pred_labels = [id2label[p.item()] for p in predictions[0]]\n",
        "\n",
        "    # Extract entities with proper subword reconstruction\n",
        "    entities = []\n",
        "    current_entity = \"\"  # ‚Üê STRING, not list!\n",
        "    current_label = None\n",
        "\n",
        "    for token, label in zip(tokens, pred_labels):\n",
        "        if token in ['[PAD]', '[UNK]', '[CLS]', '[SEP]', '[MASK]']:\n",
        "            continue\n",
        "\n",
        "        if label.startswith('B-'):\n",
        "            # Save previous entity\n",
        "            if current_entity:\n",
        "                entities.append((current_label, current_entity.strip()))\n",
        "\n",
        "            # Start new entity\n",
        "            current_label = label[2:]\n",
        "            if token.startswith('##'):\n",
        "                current_entity = token[2:]  # Remove ## without space\n",
        "            else:\n",
        "                current_entity = token\n",
        "\n",
        "        elif label.startswith('I-') and current_label:\n",
        "            # Continue entity\n",
        "            if token.startswith('##'):\n",
        "                current_entity += token[2:]  # ‚Üê Concatenate WITHOUT space\n",
        "            else:\n",
        "                current_entity += \" \" + token  # ‚Üê Add space for new word\n",
        "\n",
        "        else:\n",
        "            # Non-entity token\n",
        "            if current_entity:\n",
        "                entities.append((current_label, current_entity.strip()))\n",
        "            current_entity = \"\"\n",
        "            current_label = None\n",
        "\n",
        "    # Don't forget last entity\n",
        "    if current_entity:\n",
        "        entities.append((current_label, current_entity.strip()))\n",
        "\n",
        "    # Print detected entities\n",
        "    if entities:\n",
        "        print(\"\\nüéØ Detected Entities:\")\n",
        "        for label, entity in entities:\n",
        "            print(f\"  - {entity} ({label})\")\n",
        "    else:\n",
        "        print(\"\\n  No entities detected\")\n",
        "\n",
        "print(\"\\n‚úÖ Testing completed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfoDawPMtPdR",
        "outputId": "193948b3-2bae-4a9e-e8b9-62e5b97b0dcc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üß™ Testing model predictions...\n",
            "\n",
            "üìù Text: Breast cancer is a disease in which cells in the breast grow out of control.\n",
            "\n",
            "üéØ Detected Entities:\n",
            "  - Breast cancer (Disease)\n",
            "\n",
            "üìù Text: Patients with diabetes mellitus require insulin therapy.\n",
            "\n",
            "üéØ Detected Entities:\n",
            "  - diabetes mellitus (Disease)\n",
            "\n",
            "üìù Text: Alzheimer disease is characterized by progressive cognitive deterioration.\n",
            "\n",
            "üéØ Detected Entities:\n",
            "  - Alzheimer disease (Disease)\n",
            "  - cognitive deterioration (Disease)\n",
            "\n",
            "‚úÖ Testing completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FM1PsPzDDSf_"
      },
      "source": [
        "## 9. Export to ONNX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cr1ivKXwDSf_",
        "outputId": "5d78f691-1e29-44e7-ab89-69db0c0dbc81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üì¶ Exporting to ONNX...\n",
            "üîÑ Converting to ONNX (opset 14)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2736940308.py:27: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
            "  torch.onnx.export(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/modeling_attn_mask_utils.py:196: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
            "  inverted_mask = torch.tensor(1.0, dtype=dtype) - expanded_mask\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Patching ONNX model for Spark NLP...\n",
            "‚úì Renaming: input_ids -> medical_input_ids\n",
            "‚úÖ ONNX model saved to ./ncbi_ner_model.onnx\n",
            "   Inputs: ['medical_input_ids', 'attention_mask', 'token_type_ids']\n",
            "   Outputs: ['logits']\n"
          ]
        }
      ],
      "source": [
        "# Export to ONNX for Spark NLP Healthcare\n",
        "import onnx\n",
        "from onnx import TensorProto\n",
        "\n",
        "ONNX_PATH = \"./ncbi_ner_model.onnx\"\n",
        "MAX_LENGTH = 512\n",
        "OPSET_VERSION = 14\n",
        "\n",
        "print(\"\\nüì¶ Exporting to ONNX...\")\n",
        "\n",
        "# Load model and create dummy input\n",
        "model = BertForTokenClassification.from_pretrained(OUTPUT_DIR)\n",
        "tokenizer = BertTokenizer.from_pretrained(OUTPUT_DIR)\n",
        "model.eval()\n",
        "\n",
        "inputs = tokenizer(\n",
        "    \"Sample text for ONNX export\",\n",
        "    return_tensors=\"pt\",\n",
        "    padding=\"max_length\",\n",
        "    truncation=True,\n",
        "    max_length=512,\n",
        "    is_split_into_words=True,\n",
        ")\n",
        "\n",
        "# Export to ONNX\n",
        "print(f\"üîÑ Converting to ONNX (opset {OPSET_VERSION})...\")\n",
        "torch.onnx.export(\n",
        "    model,\n",
        "    (inputs[\"input_ids\"], inputs[\"attention_mask\"], inputs.get(\"token_type_ids\")),\n",
        "    ONNX_PATH,\n",
        "    input_names=[\"input_ids\", \"attention_mask\", \"token_type_ids\"],\n",
        "    output_names=[\"logits\"],\n",
        "    dynamic_axes={\n",
        "        \"input_ids\": {0: \"batch_size\", 1: \"sequence_length\"},\n",
        "        \"attention_mask\": {0: \"batch_size\", 1: \"sequence_length\"},\n",
        "        \"token_type_ids\": {0: \"batch_size\", 1: \"sequence_length\"},\n",
        "        \"logits\": {0: \"batch_size\", 1: \"sequence_length\"}\n",
        "    },\n",
        "    opset_version=OPSET_VERSION,\n",
        "    do_constant_folding=True\n",
        ")\n",
        "\n",
        "# Patch for Spark NLP Healthcare: INT64 inputs + rename for medical_input_ids\n",
        "print(\"‚úì Patching ONNX model for Spark NLP...\")\n",
        "onnx_model = onnx.load(ONNX_PATH)\n",
        "onnx.checker.check_model(onnx_model)\n",
        "\n",
        "# Rename input_ids -> medical_input_ids\n",
        "name_map = {\"input_ids\": \"medical_input_ids\"}\n",
        "\n",
        "# Force INT64 on all inputs\n",
        "for ip in onnx_model.graph.input:\n",
        "    if ip.type.tensor_type.elem_type != TensorProto.INT64:\n",
        "        ip.type.tensor_type.elem_type = TensorProto.INT64\n",
        "    if ip.name in name_map:\n",
        "        new_name = name_map[ip.name]\n",
        "        print(f\"‚úì Renaming: {ip.name} -> {new_name}\")\n",
        "        ip.name = new_name\n",
        "\n",
        "# Update node references\n",
        "for node in onnx_model.graph.node:\n",
        "    node.input[:] = [name_map.get(n, n) for n in node.input]\n",
        "\n",
        "# Update initializers\n",
        "for init in onnx_model.graph.initializer:\n",
        "    if init.name in name_map:\n",
        "        init.name = name_map[init.name]\n",
        "\n",
        "onnx.save(onnx_model, ONNX_PATH)\n",
        "print(f\"‚úÖ ONNX model saved to {ONNX_PATH}\")\n",
        "print(f\"   Inputs: {[i.name for i in onnx_model.graph.input]}\")\n",
        "print(f\"   Outputs: {[o.name for o in onnx_model.graph.output]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqmAA3-BDSgA"
      },
      "source": [
        "## 10. Test ONNX Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHCbUtX2DSgA",
        "outputId": "584a04dc-8a0d-4a56-f143-cf75038a373a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üß™ Testing ONNX model...\n",
            "Model expects inputs: ['medical_input_ids', 'attention_mask', 'token_type_ids']\n",
            "‚úÖ ONNX forward pass OK. Logits shape: (1, 512, 3)\n"
          ]
        }
      ],
      "source": [
        "# Test ONNX model with dynamic input-name handling\n",
        "import numpy as np\n",
        "import onnxruntime as ort\n",
        "\n",
        "print(\"\\nüß™ Testing ONNX model...\")\n",
        "\n",
        "# Load inputs\n",
        "test_text = \"Breast cancer and diabetes are common diseases.\"\n",
        "inputs = tokenizer(\n",
        "    test_text,\n",
        "    return_tensors=\"np\",\n",
        "    padding=\"max_length\",\n",
        "    truncation=True,\n",
        "    max_length=512,\n",
        "    return_token_type_ids=True  # Add this explicitly\n",
        ")\n",
        "\n",
        "# Start session and inspect expected names\n",
        "session = ort.InferenceSession(ONNX_PATH)\n",
        "expected = [i.name for i in session.get_inputs()]\n",
        "print(\"Model expects inputs:\", expected)\n",
        "\n",
        "def as_i64(x):\n",
        "    import numpy as _np\n",
        "    return _np.asarray(x, dtype=_np.int64)\n",
        "\n",
        "# Build feed dict based on expected naming\n",
        "if set(expected) == set([\"medical_input_ids\", \"attention_mask\", \"token_type_ids\"]):\n",
        "    ort_inputs = {\n",
        "        \"medical_input_ids\": as_i64(inputs[\"input_ids\"]),\n",
        "        \"attention_mask\": as_i64(inputs[\"attention_mask\"]),\n",
        "        \"token_type_ids\": as_i64(inputs.get(\"token_type_ids\", np.zeros_like(inputs[\"input_ids\"])))\n",
        "    }\n",
        "else:\n",
        "    raise ValueError(f\"Unexpected input names in model: {expected}\")\n",
        "\n",
        "# Run inference\n",
        "outputs = session.run(None, ort_inputs)\n",
        "logits = outputs[0]\n",
        "print(\"‚úÖ ONNX forward pass OK. Logits shape:\", logits.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7izBIT6eDSgA"
      },
      "source": [
        "## 11. Import the Model to Spark NLP Healthcare Library"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Necessary Libraries"
      ],
      "metadata": {
        "id": "9ezfFpqv3Vxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the johnsnowlabs library to access Spark-OCR and Spark-NLP for Healthcare, Finance, and Legal.\n",
        "! pip install -q johnsnowlabs"
      ],
      "metadata": {
        "id": "TX0k7eHXFvVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Upload License File"
      ],
      "metadata": {
        "id": "qu-IK6ZA3Ag2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "print('Please Upload your John Snow Labs License using the button below')\n",
        "license_keys = files.upload()"
      ],
      "metadata": {
        "id": "EQGwf8b5FvSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries and Start Spark Session"
      ],
      "metadata": {
        "id": "6jXpAurS3epn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from johnsnowlabs import nlp, medical\n",
        "\n",
        "# # After uploading your license run this to install all licensed Python Wheels and pre-download Jars the Spark Session JVM\n",
        "nlp.settings.enforce_versions=True\n",
        "nlp.install(refresh_install=True)"
      ],
      "metadata": {
        "id": "xCO_Mm4eFvee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from johnsnowlabs import nlp, medical\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "spark = nlp.start()\n",
        "\n",
        "spark"
      ],
      "metadata": {
        "id": "1R6BEvKSTIxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12. Prepare Spark NLP JSL Model Package"
      ],
      "metadata": {
        "id": "lDxXFvqF3wgM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRnj__sdDSgA",
        "outputId": "352c8635-ba3d-444f-d7f1-c0fcf2882637"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìã Preparing Spark NLP JSL model...\n",
            "‚úì Copied model.onnx to root\n",
            "  ONNX inputs: ['medical_input_ids', 'attention_mask', 'token_type_ids']\n",
            "\n",
            "üìù Extracting labels from model...\n",
            "‚úì Saved labels.txt (3 labels)\n",
            "‚úì Copied vocab.txt to assets/\n",
            "\n",
            "üìÅ Copying tokenizer config files to root...\n",
            "  ‚úì Copied tokenizer_config.json to root\n",
            "  ‚úì Copied special_tokens_map.json to root\n",
            "  ‚úì Copied tokenizer.json to root\n",
            "‚úì Created config.json in root\n",
            "\n",
            "üìÅ Final directory structure:\n",
            "spark_nlp_jsl_ncbi_ner/\n",
            "  config.json (160 bytes)\n",
            "  model.onnx (431144990 bytes)\n",
            "  special_tokens_map.json (125 bytes)\n",
            "  tokenizer.json (669188 bytes)\n",
            "  tokenizer_config.json (1389 bytes)\n",
            "  assets/\n",
            "    labels.txt (21 bytes)\n",
            "    vocab.txt (213450 bytes)\n",
            "\n",
            "‚úÖ Spark NLP JSL model preparation complete!\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "import onnx\n",
        "import json\n",
        "\n",
        "SPARK_NLP_PATH = \"./spark_nlp_jsl_ncbi_ner\"\n",
        "MODEL_NAME = \"ncbi_disease_ner_bert\"\n",
        "\n",
        "print(\"\\nüìã Preparing Spark NLP JSL model...\")\n",
        "\n",
        "# 1. Create directory structure\n",
        "os.makedirs(SPARK_NLP_PATH, exist_ok=True)\n",
        "assets_path = os.path.join(SPARK_NLP_PATH, \"assets\")\n",
        "os.makedirs(assets_path, exist_ok=True)\n",
        "\n",
        "# 2. Copy ONNX model to ROOT as model.onnx\n",
        "onnx_dest = os.path.join(SPARK_NLP_PATH, \"model.onnx\")\n",
        "shutil.copy(ONNX_PATH, onnx_dest)\n",
        "print(f\"‚úì Copied model.onnx to root\")\n",
        "\n",
        "# 3. Verify ONNX inputs\n",
        "onnx_model = onnx.load(onnx_dest)\n",
        "input_names = [i.name for i in onnx_model.graph.input]\n",
        "print(f\"  ONNX inputs: {input_names}\")\n",
        "\n",
        "# 4. Load model and extract labels\n",
        "print(\"\\nüìù Extracting labels from model...\")\n",
        "if 'model' not in dir():\n",
        "    from transformers import BertForTokenClassification\n",
        "    model = BertForTokenClassification.from_pretrained(OUTPUT_DIR)\n",
        "\n",
        "labels_dict = model.config.label2id\n",
        "labels_sorted = sorted(labels_dict, key=labels_dict.get)\n",
        "\n",
        "# 5. Save labels to assets folder\n",
        "with open(os.path.join(assets_path, 'labels.txt'), 'w') as f:\n",
        "    f.write('\\n'.join(labels_sorted))\n",
        "print(f\"‚úì Saved labels.txt ({len(labels_sorted)} labels)\")\n",
        "\n",
        "# 6. Copy vocab.txt to assets\n",
        "vocab_src = os.path.join(OUTPUT_DIR, \"vocab.txt\")\n",
        "if os.path.exists(vocab_src):\n",
        "    shutil.copy(vocab_src, os.path.join(assets_path, \"vocab.txt\"))\n",
        "    print(\"‚úì Copied vocab.txt to assets/\")\n",
        "\n",
        "# 7. Copy tokenizer files to ROOT directory (not assets!)\n",
        "print(\"\\nüìÅ Copying tokenizer config files to root...\")\n",
        "tokenizer_files = [\"tokenizer_config.json\", \"special_tokens_map.json\", \"tokenizer.json\"]\n",
        "for file in tokenizer_files:\n",
        "    src = os.path.join(OUTPUT_DIR, file)\n",
        "    if os.path.exists(src):\n",
        "        shutil.copy(src, os.path.join(SPARK_NLP_PATH, file))  # Copy to ROOT\n",
        "        print(f\"  ‚úì Copied {file} to root\")\n",
        "\n",
        "# 8. Create config.json in ROOT\n",
        "config = {\n",
        "    \"architectures\": [\"BertForTokenClassification\"],\n",
        "    \"model_type\": \"bert\",\n",
        "    \"max_position_embeddings\": 512,\n",
        "    \"hidden_size\": 768,\n",
        "    \"num_labels\": len(labels_sorted)\n",
        "}\n",
        "with open(os.path.join(SPARK_NLP_PATH, \"config.json\"), \"w\") as f:\n",
        "    json.dump(config, f, indent=2)\n",
        "print(\"‚úì Created config.json in root\")\n",
        "\n",
        "# 9. Verify final structure\n",
        "print(\"\\nüìÅ Final directory structure:\")\n",
        "for root, dirs, files in os.walk(SPARK_NLP_PATH):\n",
        "    level = root.replace(SPARK_NLP_PATH, '').count(os.sep)\n",
        "    indent = ' ' * 2 * level\n",
        "    print(f'{indent}{os.path.basename(root)}/')\n",
        "    subindent = ' ' * 2 * (level + 1)\n",
        "    for file in sorted(files):\n",
        "        file_path = os.path.join(root, file)\n",
        "        file_size = os.path.getsize(file_path)\n",
        "        print(f'{subindent}{file} ({file_size} bytes)')\n",
        "\n",
        "print(\"\\n‚úÖ Spark NLP JSL model preparation complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the Saved Model into Spark NLP"
      ],
      "metadata": {
        "id": "r6sb3n7f4OC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\nüì¶ Loading model from {SPARK_NLP_PATH}...\")\n",
        "\n",
        "tokenClassifier = medical.BertForTokenClassification\\\n",
        "    .loadSavedModel(SPARK_NLP_PATH, spark)\\\n",
        "    .setInputCols([\"document\", 'token'])\\\n",
        "    .setOutputCol(\"ner\")\\\n",
        "    .setCaseSensitive(False)\\\n",
        "    .setMaxSentenceLength(512)\n",
        "\n",
        "print(\"‚úì Model loaded successfully into Spark NLP\")\n",
        "\n",
        "# Save the model in Spark NLP format\n",
        "output_path = f\"./{MODEL_NAME}_spark_nlp_onnx\"\n",
        "print(f\"\\nüíæ Saving Spark NLP model to {output_path}...\")\n",
        "\n",
        "tokenClassifier.write().overwrite().save(output_path)\n",
        "\n",
        "print(f\"‚úÖ Spark NLP model saved to {output_path}\")\n",
        "print(f\"\\nüìã Final output locations:\")\n",
        "print(f\"  1. ONNX Export: {SPARK_NLP_PATH}/\")\n",
        "print(f\"  2. Spark NLP Model: {output_path}/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2h9RJrbMl1s",
        "outputId": "7ea849cc-6ce8-4105-cb03-a32d43a286be"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üì¶ Loading model from ./spark_nlp_jsl_ncbi_ner...\n",
            "‚úì Model loaded successfully into Spark NLP\n",
            "\n",
            "üíæ Saving Spark NLP model to ./ncbi_disease_ner_bert_spark_nlp_onnx...\n",
            "‚úÖ Spark NLP model saved to ./ncbi_disease_ner_bert_spark_nlp_onnx\n",
            "\n",
            "üìã Final output locations:\n",
            "  1. ONNX Export: ./spark_nlp_jsl_ncbi_ner/\n",
            "  2. Spark NLP Model: ./ncbi_disease_ner_bert_spark_nlp_onnx/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Spark NLP Pipeline"
      ],
      "metadata": {
        "id": "NzXL40dO4XQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document_assembler = nlp.DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "tokenizer = nlp.Tokenizer()\\\n",
        "    .setInputCols([\"document\"])\\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "# Load the saved Spark NLP model\n",
        "ner_model = medical.BertForTokenClassification.load(output_path)\\\n",
        "    .setInputCols([\"document\", \"token\"])\\\n",
        "    .setOutputCol(\"ner\")\\\n",
        "    .setCaseSensitive(False)\\\n",
        "    .setMaxSentenceLength(512)\n",
        "\n",
        "ner_converter = medical.NerConverterInternal() \\\n",
        "    .setInputCols([\"document\", \"token\", \"ner\"]) \\\n",
        "    .setOutputCol(\"ner_chunk\")\n",
        "\n",
        "pipeline = nlp.Pipeline(stages=[\n",
        "    document_assembler,\n",
        "    tokenizer,\n",
        "    ner_model,\n",
        "    ner_converter\n",
        "])"
      ],
      "metadata": {
        "id": "Xx9wE6LnMl9W"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ner_model.getClasses()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFQd_-OWUJRv",
        "outputId": "20e69b6f-58bf-48ed-c819-b21dac291a76"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['B-Disease', 'I-Disease', 'O']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark.sql.functions as F\n",
        "\n",
        "print(\"\\nüß™ Testing Spark NLP model...\")\n",
        "\n",
        "# Test data\n",
        "test_texts = [\n",
        "    \"Breast cancer is a disease in which cells in the breast grow out of control.\",\n",
        "    \"Patients with diabetes mellitus require insulin therapy.\",\n",
        "    \"Alzheimer disease is characterized by progressive cognitive deterioration.\"\n",
        "]\n",
        "\n",
        "# Create DataFrame\n",
        "test_df = spark.createDataFrame([[text] for text in test_texts], [\"text\"])\n",
        "\n",
        "# Fit and transform\n",
        "model = pipeline.fit(test_df)\n",
        "result = model.transform(test_df)\n",
        "\n",
        "# Show results\n",
        "print(\"\\nüìä Results:\")\n",
        "\n",
        "# After transformation, inspect token metadata\n",
        "result.select(\n",
        "    F.explode(\n",
        "        F.arrays_zip(\n",
        "            result.token.result,\n",
        "            result.token.begin,\n",
        "            result.token.end,\n",
        "            result.ner.result\n",
        "        )\n",
        "    ).alias(\"cols\")\n",
        ").select(\n",
        "    F.expr(\"cols['0']\").alias(\"token\"),\n",
        "    F.expr(\"cols['1']\").alias(\"char_begin\"),\n",
        "    F.expr(\"cols['2']\").alias(\"char_end\"),\n",
        "    F.expr(\"cols['3']\").alias(\"label\")\n",
        ").show(50, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gj-R09vHD9cW",
        "outputId": "04395b62-1fd7-487c-a1ea-4b88d61ae340"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üß™ Testing Spark NLP model...\n",
            "\n",
            "üìä Results:\n",
            "+-------------+----------+--------+---------+\n",
            "|token        |char_begin|char_end|label    |\n",
            "+-------------+----------+--------+---------+\n",
            "|Breast       |0         |5       |B-Disease|\n",
            "|cancer       |7         |12      |I-Disease|\n",
            "|is           |14        |15      |O        |\n",
            "|a            |17        |17      |O        |\n",
            "|disease      |19        |25      |O        |\n",
            "|in           |27        |28      |O        |\n",
            "|which        |30        |34      |O        |\n",
            "|cells        |36        |40      |O        |\n",
            "|in           |42        |43      |O        |\n",
            "|the          |45        |47      |O        |\n",
            "|breast       |49        |54      |O        |\n",
            "|grow         |56        |59      |O        |\n",
            "|out          |61        |63      |O        |\n",
            "|of           |65        |66      |O        |\n",
            "|control      |68        |74      |O        |\n",
            "|.            |75        |75      |O        |\n",
            "|Patients     |0         |7       |O        |\n",
            "|with         |9         |12      |O        |\n",
            "|diabetes     |14        |21      |B-Disease|\n",
            "|mellitus     |23        |30      |I-Disease|\n",
            "|require      |32        |38      |O        |\n",
            "|insulin      |40        |46      |O        |\n",
            "|therapy      |48        |54      |O        |\n",
            "|.            |55        |55      |O        |\n",
            "|Alzheimer    |0         |8       |B-Disease|\n",
            "|disease      |10        |16      |I-Disease|\n",
            "|is           |18        |19      |O        |\n",
            "|characterized|21        |33      |O        |\n",
            "|by           |35        |36      |O        |\n",
            "|progressive  |38        |48      |O        |\n",
            "|cognitive    |50        |58      |B-Disease|\n",
            "|deterioration|60        |72      |I-Disease|\n",
            "|.            |73        |73      |O        |\n",
            "+-------------+----------+--------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.select(F.explode(F.arrays_zip(result.ner_chunk.result,\n",
        "                                     result.ner_chunk.metadata)).alias(\"cols\")) \\\n",
        "      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
        "              F.expr(\"cols['1']['entity']\").alias(\"ner_label\")).show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUaHpS9lg5P4",
        "outputId": "e65c7153-de2f-4092-d57c-27499a915e84"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------+---------+\n",
            "|chunk                  |ner_label|\n",
            "+-----------------------+---------+\n",
            "|Breast cancer          |Disease  |\n",
            "|diabetes mellitus      |Disease  |\n",
            "|Alzheimer disease      |Disease  |\n",
            "|cognitive deterioration|Disease  |\n",
            "+-----------------------+---------+\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0b87cbf4d30e4e8581368d4f400a3e7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_698455572bf2405cb0eb4edf7689f790",
              "IPY_MODEL_01fd85d7b6c74a4488dc5edd1c30d018",
              "IPY_MODEL_ef4455944a704cfcad2646af64ca9ee9"
            ],
            "layout": "IPY_MODEL_bc3185d5debe49b2b167beb4963f048e"
          }
        },
        "698455572bf2405cb0eb4edf7689f790": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44062565cf38445fa0b2efe5000d08d5",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_95e9cc9cf44d4c4c96f6dc6e775f4399",
            "value": "vocab.txt:‚Äá"
          }
        },
        "01fd85d7b6c74a4488dc5edd1c30d018": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d758015326184d1697b177a4076b4395",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4b498904a4cf4b699c49c4050f99824f",
            "value": 1
          }
        },
        "ef4455944a704cfcad2646af64ca9ee9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e4c3a3c286241e090d319fa9a6ad8c6",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_596df54232fc4ad693471dfd4a0e3574",
            "value": "‚Äá213k/?‚Äá[00:00&lt;00:00,‚Äá8.77MB/s]"
          }
        },
        "bc3185d5debe49b2b167beb4963f048e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44062565cf38445fa0b2efe5000d08d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95e9cc9cf44d4c4c96f6dc6e775f4399": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d758015326184d1697b177a4076b4395": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "4b498904a4cf4b699c49c4050f99824f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e4c3a3c286241e090d319fa9a6ad8c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "596df54232fc4ad693471dfd4a0e3574": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d32aaa21c039489ea4dd829e2bde88a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1b2900d0a11340dcaa60e19e64841955",
              "IPY_MODEL_039cf2a614364347a72d9a3bd358617a",
              "IPY_MODEL_3ce3d1719f884ea48d182aa5061a226c"
            ],
            "layout": "IPY_MODEL_e12c6c78909d461e9920987541559963"
          }
        },
        "1b2900d0a11340dcaa60e19e64841955": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9879f269368b4999b89610a55adba5f4",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_94e146e1a4954cda8cd9e2b65e47e669",
            "value": "config.json:‚Äá"
          }
        },
        "039cf2a614364347a72d9a3bd358617a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cb2986be1754d1ab65085b236b99717",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ad83108b409b4b618c835141a85d3d91",
            "value": 1
          }
        },
        "3ce3d1719f884ea48d182aa5061a226c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d18470ce7fee47e7985698a727f95060",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0c4a9c66a7534c61bde748678b11e0d1",
            "value": "‚Äá1.11k/?‚Äá[00:00&lt;00:00,‚Äá71.7kB/s]"
          }
        },
        "e12c6c78909d461e9920987541559963": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9879f269368b4999b89610a55adba5f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94e146e1a4954cda8cd9e2b65e47e669": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6cb2986be1754d1ab65085b236b99717": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ad83108b409b4b618c835141a85d3d91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d18470ce7fee47e7985698a727f95060": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c4a9c66a7534c61bde748678b11e0d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03dbeac12fbf40b88fc3d900a04c53d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b4344d579c604f1c8380d5824ac8d674",
              "IPY_MODEL_52a8f2ad029a424dbe8920d71e2e8542",
              "IPY_MODEL_cb594e99fb7b48e6bd45f9c661109447"
            ],
            "layout": "IPY_MODEL_9f79c7e8162848a0b60153a7c082e668"
          }
        },
        "b4344d579c604f1c8380d5824ac8d674": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a254e2764b6b4a2184513803a0843199",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a5aee8ca32394c4dbe43eebad6e263aa",
            "value": "pytorch_model.bin:‚Äá100%"
          }
        },
        "52a8f2ad029a424dbe8920d71e2e8542": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78e25fb0380a4d5ea1347e6dfeb97a2e",
            "max": 435783451,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ad3f14fc1164761816484b474240ef4",
            "value": 435783451
          }
        },
        "cb594e99fb7b48e6bd45f9c661109447": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8012ac212a1d4d10932708844e93cfbf",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_60c24e5a9e9f42a2958f75bcda479746",
            "value": "‚Äá436M/436M‚Äá[00:01&lt;00:00,‚Äá390MB/s]"
          }
        },
        "9f79c7e8162848a0b60153a7c082e668": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a254e2764b6b4a2184513803a0843199": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5aee8ca32394c4dbe43eebad6e263aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78e25fb0380a4d5ea1347e6dfeb97a2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ad3f14fc1164761816484b474240ef4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8012ac212a1d4d10932708844e93cfbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60c24e5a9e9f42a2958f75bcda479746": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3116388bc1b4a5f80522399be215aa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e0c69decbbc845f9b34aaa464eda7599",
              "IPY_MODEL_6172c52ce98b442ba427e0cbc3e6ade2",
              "IPY_MODEL_e8ca03340ba3448abee735d9edf1c237"
            ],
            "layout": "IPY_MODEL_73db59befb22494aba2fa4583d08d51e"
          }
        },
        "e0c69decbbc845f9b34aaa464eda7599": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67164480c5984462842234109de102f1",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d84dbf19a0984e0e94232066c0c1e935",
            "value": "model.safetensors:‚Äá100%"
          }
        },
        "6172c52ce98b442ba427e0cbc3e6ade2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6294b075ee942d797762a70a31740d4",
            "max": 435755944,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_216e3e9f60944cad90d8f9d9fd4d622a",
            "value": 435755944
          }
        },
        "e8ca03340ba3448abee735d9edf1c237": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77a646a3d6a94185bf26f78e68e88ec6",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d0e89bd04b0445ec90536984466c8609",
            "value": "‚Äá436M/436M‚Äá[00:01&lt;00:00,‚Äá388MB/s]"
          }
        },
        "73db59befb22494aba2fa4583d08d51e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67164480c5984462842234109de102f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d84dbf19a0984e0e94232066c0c1e935": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6294b075ee942d797762a70a31740d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "216e3e9f60944cad90d8f9d9fd4d622a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "77a646a3d6a94185bf26f78e68e88ec6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0e89bd04b0445ec90536984466c8609": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
