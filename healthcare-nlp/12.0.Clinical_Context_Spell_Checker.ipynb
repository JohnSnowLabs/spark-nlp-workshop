{"cells":[{"cell_type":"markdown","metadata":{"id":"2muvLzlqdcva"},"source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"]},{"cell_type":"markdown","metadata":{"id":"A2A9se0Bdcvb"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/healthcare-nlp/12.0.Clinical_Context_Spell_Checker.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"orznscn3dcvc"},"source":["# Context Spell Checker - Medical\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ELqzaf32MT6E"},"outputs":[],"source":["# Install the johnsnowlabs library to access Spark-OCR and Spark-NLP for Healthcare, Finance, and Legal.\n","! pip install -q johnsnowlabs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RO2dIA414yL_"},"outputs":[],"source":["\n","from google.colab import files\n","print('Please Upload your John Snow Labs License using the button below')\n","license_keys = files.upload()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dmcB5zVBHZO8"},"outputs":[],"source":["from johnsnowlabs import nlp, medical, visual\n","\n","# After uploading your license run this to install all licensed Python Wheels and pre-download Jars the Spark Session JVM\n","nlp.settings.enforce_versions=True\n","nlp.install(refresh_install=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lQ8-BI-_5QjG"},"outputs":[],"source":["from johnsnowlabs import nlp, medical, visual\n","\n","# Automatically load license data and start a session with all jars user has access to\n","spark = nlp.start()"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":222},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1760630241838,"user":{"displayName":"Mehmet DaÄŸ","userId":"14052875917891496135"},"user_tz":-180},"id":"1W1fzGLAhsx3","outputId":"b7486b69-9e3b-4388-8967-9892902bd03a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<pyspark.sql.session.SparkSession at 0x78e8ff7af2c0>"],"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://2ddda9b005ca:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.4.0</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>John-Snow-Labs-Spark-Session ðŸš€ with Jars for: ðŸš€Spark-NLP==6.1.3, ðŸ’ŠSpark-Healthcare==6.1.1, running on âš¡ PySpark==3.4.0</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "]},"metadata":{},"execution_count":5}],"source":["spark"]},{"cell_type":"markdown","metadata":{"id":"y4GhIhZVugqd"},"source":["## Healthcare NLP for Data Scientists Course\n","\n","If you are not familiar with the components in this notebook, you can check [Healthcare NLP for Data Scientists Udemy Course](https://www.udemy.com/course/healthcare-nlp-for-data-scientists/) and the [MOOC Notebooks](https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP) for each components."]},{"cell_type":"markdown","metadata":{"id":"hg2ZSA5Lr3_2"},"source":["## spellcheck_clinical"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":48411,"status":"ok","timestamp":1760630290253,"user":{"displayName":"Mehmet DaÄŸ","userId":"14052875917891496135"},"user_tz":-180},"id":"l70_9DOgdcvz","outputId":"556204b6-b35d-4316-ba53-6e7fbd6841f4","scrolled":true},"outputs":[{"output_type":"stream","name":"stdout","text":["spellcheck_clinical download started this may take some time.\n","Approximate size to download 134.7 MB\n","[OK!]\n"]}],"source":["documentAssembler = nlp.DocumentAssembler()\\\n","    .setInputCol(\"text\")\\\n","    .setOutputCol(\"document\")\n","\n","tokenizer = nlp.RecursiveTokenizer()\\\n","    .setInputCols([\"document\"])\\\n","    .setOutputCol(\"token\")\\\n","    .setPrefixes([\"\\\"\", \"(\", \"[\", \"\\n\"])\\\n","    .setSuffixes([\".\", \",\", \"?\", \")\",\"!\", \"'s\"])\n","\n","spellModel = nlp.ContextSpellCheckerModel\\\n","    .pretrained('spellcheck_clinical', 'en', 'clinical/models')\\\n","    .setInputCols(\"token\")\\\n","    .setOutputCol(\"checked\")"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"XyqbEdoPdcv-","scrolled":true,"executionInfo":{"status":"ok","timestamp":1760630293540,"user_tz":-180,"elapsed":3281,"user":{"displayName":"Mehmet DaÄŸ","userId":"14052875917891496135"}}},"outputs":[],"source":["pipeline = nlp.Pipeline(\n","    stages = [\n","        documentAssembler,\n","        tokenizer,\n","        spellModel\n","])\n","\n","empty_ds = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n","\n","lp = nlp.LightPipeline(pipeline.fit(empty_ds))"]},{"cell_type":"markdown","metadata":{"id":"49DMo2sQdcwC"},"source":["Ok!, at this point we have our spell checking pipeline as expected. Let's see what we can do with it, see these errors,\n","\n","_She was **treathed** with a five day course of **amoxicilin** for a **resperatory** **truct** infection._\n","\n","_With pain well controlled on **orall** **meditation**, she was discharged to **reihabilitation** **facilitay**._\n","\n","\n","_Her **adominal** examination is soft, nontender, and **nonintended**_\n","\n","_The patient was seen by the **entocrinology** service and she was discharged on 40 units of **unsilin** glargine at night_\n","      \n","_No __cute__ distress_\n","\n","Check that some of the errors are valid English words, only by considering the context the right choice can be made."]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2052,"status":"ok","timestamp":1760630295600,"user":{"displayName":"Mehmet DaÄŸ","userId":"14052875917891496135"},"user_tz":-180},"id":"K2BuhiZNHGhH","outputId":"3670d5ef-7b8a-45fa-c980-86eb94f5176c"},"outputs":[{"output_type":"stream","name":"stdout","text":["[('She', 'She'), ('was', 'was'), ('treathed', 'treated'), ('with', 'with'), ('a', 'a'), ('five', 'five'), ('day', 'day'), ('course', 'course'), ('of', 'of'), ('amoxicilin', 'amoxicillin'), ('for', 'for'), ('a', 'a'), ('resperatory', 'respiratory'), ('truct', 'tract'), ('infection', 'infection'), ('.', '.')]\n","[('With', 'With'), ('pain', 'pain'), ('well', 'well'), ('controlled', 'controlled'), ('on', 'on'), ('orall', 'oral'), ('meditation', 'medication'), (',', ','), ('she', 'she'), ('was', 'was'), ('discharged', 'discharged'), ('to', 'to'), ('reihabilitation', 'rehabilitation'), ('facilitay', 'facility'), ('.', '.')]\n","[('Her', 'Her'), ('adominal', 'abdominal'), ('examination', 'examination'), ('is', 'is'), ('soft', 'soft'), (',', ','), ('nontender', 'nontender'), (',', ','), ('and', 'and'), ('nonintended', 'nondistended'), ('.', '.')]\n","[('The', 'The'), ('patient', 'patient'), ('was', 'was'), ('seen', 'seen'), ('by', 'by'), ('the', 'the'), ('entocrinology', 'endocrinology'), ('service', 'service'), ('and', 'and'), ('she', 'she'), ('was', 'was'), ('discharged', 'discharged'), ('on', 'on'), ('40', '40'), ('units', 'units'), ('of', 'of'), ('unsilin', 'insulin'), ('glargine', 'glargine'), ('at', 'at'), ('night', 'night')]\n","[('No', 'No'), ('cute', 'acute'), ('distress', 'distress')]\n"]}],"source":["example = [\"She was treathed with a five day course of amoxicilin for a resperatory truct infection . \",\n","           \"With pain well controlled on orall meditation, she was discharged to reihabilitation facilitay.\",\n","           \"Her adominal examination is soft, nontender, and nonintended.\",\n","           \"The patient was seen by the entocrinology service and she was discharged on 40 units of unsilin glargine at night\",\n","           \"No cute distress\",\n","          ]\n","\n","for pairs in lp.annotate(example):\n","    print(list(zip(pairs['token'],pairs['checked'])))"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1111,"status":"ok","timestamp":1760630296733,"user":{"displayName":"Mehmet DaÄŸ","userId":"14052875917891496135"},"user_tz":-180},"id":"pZO_lickQT7P","outputId":"534ba8d1-5aec-4fac-ae83-e0f882c02b5e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Corrected tokens:\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["[('treathed', 'treated'),\n"," ('amoxicilin', 'amoxicillin'),\n"," ('resperatory', 'respiratory'),\n"," ('truct', 'tract'),\n"," ('orall', 'oral'),\n"," ('meditation', 'medication'),\n"," ('reihabilitation', 'rehabilitation'),\n"," ('facilitay', 'facility'),\n"," ('adominal', 'abdominal'),\n"," ('nonintended', 'nondistended'),\n"," ('entocrinology', 'endocrinology'),\n"," ('unsilin', 'insulin'),\n"," ('cute', 'acute')]"]},"metadata":{},"execution_count":9}],"source":["print(\"Corrected tokens:\\n\")\n","\n","pair_list = [list(zip(pairs['token'],pairs['checked'])) for pairs in lp.annotate(example)]\n","corrected_list = [i for pair in pair_list for i in pair if i[0] != i[1]]\n","corrected_list"]},{"cell_type":"markdown","metadata":{"id":"YYKIsa9dsGlc"},"source":["## spellcheck_drug_norvig"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8162,"status":"ok","timestamp":1760630304898,"user":{"displayName":"Mehmet DaÄŸ","userId":"14052875917891496135"},"user_tz":-180},"id":"dgwLFsQ0sLLd","outputId":"3d1d7dcf-54e4-4ffb-ab3f-973792b359dc"},"outputs":[{"output_type":"stream","name":"stdout","text":["spellcheck_drug_norvig download started this may take some time.\n","Approximate size to download 4.3 MB\n","[OK!]\n"]}],"source":["documentAssembler = nlp.DocumentAssembler()\\\n","    .setInputCol(\"text\")\\\n","    .setOutputCol(\"document\")\n","\n","tokenizer = nlp.Tokenizer()\\\n","    .setInputCols(\"document\")\\\n","    .setOutputCol(\"token\")\n","\n","spell = nlp.NorvigSweetingModel.pretrained(\"spellcheck_drug_norvig\", \"en\", \"clinical/models\")\\\n","    .setInputCols(\"token\")\\\n","    .setOutputCol(\"corrected_token\")\\\n","\n","pipeline = nlp.Pipeline(\n","    stages = [\n","        documentAssembler,\n","        tokenizer,\n","        spell\n","        ])\n","\n","\n","empty_ds = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n","\n","lp = nlp.LightPipeline(pipeline.fit(empty_ds))"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":594,"status":"ok","timestamp":1760630305497,"user":{"displayName":"Mehmet DaÄŸ","userId":"14052875917891496135"},"user_tz":-180},"id":"8_Fwxv_ksiwD","outputId":"392735c0-0d37-49ea-daa1-95adfc7b6947"},"outputs":[{"output_type":"stream","name":"stdout","text":["[('You', 'You'), ('have', 'have'), ('to', 'to'), ('take', 'take'), ('Amrosia', 'Ambrosia'), ('artemisiifoli', 'artemisiifolia'), (',', ','), ('Oactra', 'Odactra'), ('and', 'and'), ('a', 'a'), ('bit', 'bit'), ('of', 'of'), ('Grastk', 'Grastek'), ('and', 'and'), ('lastacaf', 'lastacaft')]\n"]}],"source":["example = [\"You have to take Amrosia artemisiifoli , Oactra and a bit of Grastk and lastacaf \",\n","          ]\n","\n","for pairs in lp.annotate(example):\n","    print(list(zip(pairs['token'],pairs['corrected_token'])))"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1760630305516,"user":{"displayName":"Mehmet DaÄŸ","userId":"14052875917891496135"},"user_tz":-180},"id":"TQmx0DYZs6k-","outputId":"bcf67d8b-ccca-4a61-d1d8-cffa516b4c08"},"outputs":[{"output_type":"stream","name":"stdout","text":["Corrected tokens:\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["[('Amrosia', 'Ambrosia'),\n"," ('artemisiifoli', 'artemisiifolia'),\n"," ('Oactra', 'Odactra'),\n"," ('Grastk', 'Grastek'),\n"," ('lastacaf', 'lastacaft')]"]},"metadata":{},"execution_count":12}],"source":["print(\"Corrected tokens:\\n\")\n","\n","pair_list = [list(zip(pairs['token'],pairs['corrected_token'])) for pairs in lp.annotate(example)]\n","corrected_list = [i for pair in pair_list for i in pair if i[0] != i[1]]\n","corrected_list"]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":0}