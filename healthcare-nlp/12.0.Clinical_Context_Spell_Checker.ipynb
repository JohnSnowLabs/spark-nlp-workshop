{"cells":[{"cell_type":"markdown","metadata":{"id":"2muvLzlqdcva"},"source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"]},{"cell_type":"markdown","metadata":{"id":"A2A9se0Bdcvb"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/healthcare-nlp/12.0.Clinical_Context_Spell_Checker.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"orznscn3dcvc"},"source":["# Context Spell Checker - Medical\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ELqzaf32MT6E"},"outputs":[],"source":["# Install the johnsnowlabs library to access Spark-OCR and Spark-NLP for Healthcare, Finance, and Legal.\n","! pip install -q johnsnowlabs==5.1.0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RO2dIA414yL_"},"outputs":[],"source":["\n","from google.colab import files\n","print('Please Upload your John Snow Labs License using the button below')\n","license_keys = files.upload()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dmcB5zVBHZO8"},"outputs":[],"source":["from johnsnowlabs import nlp, medical, visual\n","\n","# After uploading your license run this to install all licensed Python Wheels and pre-download Jars the Spark Session JVM\n","nlp.install()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lQ8-BI-_5QjG"},"outputs":[],"source":["from johnsnowlabs import nlp, medical, visual\n","\n","# Automatically load license data and start a session with all jars user has access to\n","spark = nlp.start()"]},{"cell_type":"code","source":["spark"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":219},"id":"1W1fzGLAhsx3","executionInfo":{"status":"ok","timestamp":1695847596862,"user_tz":240,"elapsed":7,"user":{"displayName":"Sel√ßuk Meng√ºverdi","userId":"15361124602135819062"}},"outputId":"9e734483-513a-4435-e810-2ae4291ce088"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<pyspark.sql.session.SparkSession at 0x7f12720d1780>"],"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://0bca7b3d88fa:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.1.2</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>John-Snow-Labs-Spark-Session üöÄ with Jars for: üöÄSpark-NLP==5.1.0, üíäSpark-Healthcare==5.1.0, running on ‚ö° PySpark==3.1.2</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["## spellcheck_clinical"],"metadata":{"id":"hg2ZSA5Lr3_2"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"l70_9DOgdcvz","scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695847645664,"user_tz":240,"elapsed":48807,"user":{"displayName":"Sel√ßuk Meng√ºverdi","userId":"15361124602135819062"}},"outputId":"ffd2ccde-d6a5-4617-f805-fe5174b8da10"},"outputs":[{"output_type":"stream","name":"stdout","text":["spellcheck_clinical download started this may take some time.\n","Approximate size to download 134.7 MB\n","[OK!]\n"]}],"source":["documentAssembler = nlp.DocumentAssembler()\\\n","    .setInputCol(\"text\")\\\n","    .setOutputCol(\"document\")\n","\n","tokenizer = nlp.RecursiveTokenizer()\\\n","    .setInputCols([\"document\"])\\\n","    .setOutputCol(\"token\")\\\n","    .setPrefixes([\"\\\"\", \"(\", \"[\", \"\\n\"])\\\n","    .setSuffixes([\".\", \",\", \"?\", \")\",\"!\", \"'s\"])\n","\n","spellModel = nlp.ContextSpellCheckerModel\\\n","    .pretrained('spellcheck_clinical', 'en', 'clinical/models')\\\n","    .setInputCols(\"token\")\\\n","    .setOutputCol(\"checked\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XyqbEdoPdcv-","scrolled":true},"outputs":[],"source":["pipeline = nlp.Pipeline(\n","    stages = [\n","        documentAssembler,\n","        tokenizer,\n","        spellModel\n","])\n","\n","empty_ds = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n","\n","lp = nlp.LightPipeline(pipeline.fit(empty_ds))"]},{"cell_type":"markdown","metadata":{"id":"49DMo2sQdcwC"},"source":["Ok!, at this point we have our spell checking pipeline as expected. Let's see what we can do with it, see these errors,\n","\n","_She was **treathed** with a five day course of **amoxicilin** for a **resperatory** **truct** infection._\n","\n","_With pain well controlled on **orall** **meditation**, she was discharged to **reihabilitation** **facilitay**._\n","\n","\n","_Her **adominal** examination is soft, nontender, and **nonintended**_\n","\n","_The patient was seen by the **entocrinology** service and she was discharged on 40 units of **unsilin** glargine at night_\n","      \n","_No __cute__ distress_\n","\n","Check that some of the errors are valid English words, only by considering the context the right choice can be made."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1816,"status":"ok","timestamp":1695847649827,"user":{"displayName":"Sel√ßuk Meng√ºverdi","userId":"15361124602135819062"},"user_tz":240},"id":"K2BuhiZNHGhH","outputId":"6db83c18-5280-49f7-a102-a02c5abfb714"},"outputs":[{"output_type":"stream","name":"stdout","text":["[('She', 'She'), ('was', 'was'), ('treathed', 'treated'), ('with', 'with'), ('a', 'a'), ('five', 'five'), ('day', 'day'), ('course', 'course'), ('of', 'of'), ('amoxicilin', 'amoxicillin'), ('for', 'for'), ('a', 'a'), ('resperatory', 'respiratory'), ('truct', 'tract'), ('infection', 'infection'), ('.', '.')]\n","[('With', 'With'), ('pain', 'pain'), ('well', 'well'), ('controlled', 'controlled'), ('on', 'on'), ('orall', 'oral'), ('meditation', 'medication'), (',', ','), ('she', 'she'), ('was', 'was'), ('discharged', 'discharged'), ('to', 'to'), ('reihabilitation', 'rehabilitation'), ('facilitay', 'facility'), ('.', '.')]\n","[('Her', 'Her'), ('adominal', 'abdominal'), ('examination', 'examination'), ('is', 'is'), ('soft', 'soft'), (',', ','), ('nontender', 'nontender'), (',', ','), ('and', 'and'), ('nonintended', 'nondistended'), ('.', '.')]\n","[('The', 'The'), ('patient', 'patient'), ('was', 'was'), ('seen', 'seen'), ('by', 'by'), ('the', 'the'), ('entocrinology', 'endocrinology'), ('service', 'service'), ('and', 'and'), ('she', 'she'), ('was', 'was'), ('discharged', 'discharged'), ('on', 'on'), ('40', '40'), ('units', 'units'), ('of', 'of'), ('unsilin', 'insulin'), ('glargine', 'glargine'), ('at', 'at'), ('night', 'night')]\n","[('No', 'No'), ('cute', 'acute'), ('distress', 'distress')]\n"]}],"source":["example = [\"She was treathed with a five day course of amoxicilin for a resperatory truct infection . \",\n","           \"With pain well controlled on orall meditation, she was discharged to reihabilitation facilitay.\",\n","           \"Her adominal examination is soft, nontender, and nonintended.\",\n","           \"The patient was seen by the entocrinology service and she was discharged on 40 units of unsilin glargine at night\",\n","           \"No cute distress\",\n","          ]\n","\n","for pairs in lp.annotate(example):\n","    print(list(zip(pairs['token'],pairs['checked'])))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":841,"status":"ok","timestamp":1695847650664,"user":{"displayName":"Sel√ßuk Meng√ºverdi","userId":"15361124602135819062"},"user_tz":240},"id":"pZO_lickQT7P","outputId":"1d170bc2-baf2-4f7c-a7ff-708789c37ced"},"outputs":[{"output_type":"stream","name":"stdout","text":["Corrected tokens:\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["[('treathed', 'treated'),\n"," ('amoxicilin', 'amoxicillin'),\n"," ('resperatory', 'respiratory'),\n"," ('truct', 'tract'),\n"," ('orall', 'oral'),\n"," ('meditation', 'medication'),\n"," ('reihabilitation', 'rehabilitation'),\n"," ('facilitay', 'facility'),\n"," ('adominal', 'abdominal'),\n"," ('nonintended', 'nondistended'),\n"," ('entocrinology', 'endocrinology'),\n"," ('unsilin', 'insulin'),\n"," ('cute', 'acute')]"]},"metadata":{},"execution_count":9}],"source":["print(\"Corrected tokens:\\n\")\n","\n","pair_list = [list(zip(pairs['token'],pairs['checked'])) for pairs in lp.annotate(example)]\n","corrected_list = [i for pair in pair_list for i in pair if i[0] != i[1]]\n","corrected_list"]},{"cell_type":"markdown","source":["## spellcheck_drug_norvig"],"metadata":{"id":"YYKIsa9dsGlc"}},{"cell_type":"code","source":["documentAssembler = nlp.DocumentAssembler()\\\n","    .setInputCol(\"text\")\\\n","    .setOutputCol(\"document\")\n","\n","tokenizer = nlp.Tokenizer()\\\n","    .setInputCols(\"document\")\\\n","    .setOutputCol(\"token\")\n","\n","spell = nlp.NorvigSweetingModel.pretrained(\"spellcheck_drug_norvig\", \"en\", \"clinical/models\")\\\n","    .setInputCols(\"token\")\\\n","    .setOutputCol(\"corrected_token\")\\\n","\n","pipeline = nlp.Pipeline(\n","    stages = [\n","        documentAssembler,\n","        tokenizer,\n","        spell\n","        ])\n","\n","\n","empty_ds = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n","\n","lp = nlp.LightPipeline(pipeline.fit(empty_ds))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dgwLFsQ0sLLd","executionInfo":{"status":"ok","timestamp":1695847658951,"user_tz":240,"elapsed":8291,"user":{"displayName":"Sel√ßuk Meng√ºverdi","userId":"15361124602135819062"}},"outputId":"0dcd6cc4-60bf-4a8d-928b-e8418d26ac91"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["spellcheck_drug_norvig download started this may take some time.\n","Approximate size to download 4.3 MB\n","[OK!]\n"]}]},{"cell_type":"code","source":["example = [\"You have to take Amrosia artemisiifoli , Oactra and a bit of Grastk and lastacaf \",\n","          ]\n","\n","for pairs in lp.annotate(example):\n","    print(list(zip(pairs['token'],pairs['corrected_token'])))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8_Fwxv_ksiwD","executionInfo":{"status":"ok","timestamp":1695847659311,"user_tz":240,"elapsed":365,"user":{"displayName":"Sel√ßuk Meng√ºverdi","userId":"15361124602135819062"}},"outputId":"3e68ff33-15cd-43ea-9920-dd1d2b0645c9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[('You', 'You'), ('have', 'have'), ('to', 'to'), ('take', 'take'), ('Amrosia', 'Ambrosia'), ('artemisiifoli', 'artemisiifolia'), (',', ','), ('Oactra', 'Odactra'), ('and', 'and'), ('a', 'a'), ('bit', 'bit'), ('of', 'of'), ('Grastk', 'Grastek'), ('and', 'and'), ('lastacaf', 'lastacaft')]\n"]}]},{"cell_type":"code","source":["print(\"Corrected tokens:\\n\")\n","\n","pair_list = [list(zip(pairs['token'],pairs['corrected_token'])) for pairs in lp.annotate(example)]\n","corrected_list = [i for pair in pair_list for i in pair if i[0] != i[1]]\n","corrected_list"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TQmx0DYZs6k-","executionInfo":{"status":"ok","timestamp":1695847659311,"user_tz":240,"elapsed":4,"user":{"displayName":"Sel√ßuk Meng√ºverdi","userId":"15361124602135819062"}},"outputId":"f54d4f10-bb7b-4e52-e489-5fabf26c4a17"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Corrected tokens:\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["[('Amrosia', 'Ambrosia'),\n"," ('artemisiifoli', 'artemisiifolia'),\n"," ('Oactra', 'Odactra'),\n"," ('Grastk', 'Grastek'),\n"," ('lastacaf', 'lastacaft')]"]},"metadata":{},"execution_count":12}]}],"metadata":{"colab":{"provenance":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":0}