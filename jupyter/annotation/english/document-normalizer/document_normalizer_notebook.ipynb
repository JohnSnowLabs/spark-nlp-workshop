{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Normalizer annotator notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a7c65f64-07d6-4355-97a0-0a371d83116c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Set up Colab environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is only to setup PySpark and Spark NLP on Colab\n",
    "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Spark NLP session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Spark NLP\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "\n",
    "def start():\n",
    "    builder = SparkSession.builder \\\n",
    "        .appName(\"Spark NLP Licensed\") \\\n",
    "        .master(\"local[4]\") \\\n",
    "        .config(\"spark.driver.memory\", \"8G\") \\\n",
    "        .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "        .config(\"spark.kryoserializer.buffer.max\", \"2000M\") \\\n",
    "        .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.11:2.7.0\") \\\n",
    "        .config(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\") \\\n",
    "        .config(\"fs.AbstractFileSystem.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\")\n",
    "    return builder.getOrCreate()\n",
    "\n",
    "spark = start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Normalizer annotator overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b4efb61f-6011-4ba1-a0ad-6c229f69e3d9",
     "showTitle": true,
     "title": "DocumentNormalizer overview and parameters"
    }
   },
   "outputs": [],
   "source": [
    "# The DocumentNormalizer is an annotator that can be used after the DocumentAssembler to narmalize documents once that they have been processed and indexed .\n",
    "# It takes in input annotated documents of type Array[AnnotatorType](DOCUMENT) and gives as output annotated document of type AnnotatorType.DOCUMENT .\n",
    "#\n",
    "# Parameters are:\n",
    "# - inputCol: input column name string which targets a column of type Array(AnnotatorType.DOCUMENT).\n",
    "# - outputCol: output column name string which targets a column of type AnnotatorType.DOCUMENT.\n",
    "# - action: action string to perform applying regex patterns, i.e. (clean | extract). Default is \"clean\".\n",
    "# - cleanupPatterns: normalization regex patterns which match will be removed from document. Default is \"<[^>]*>\" (e.g., it removes all HTML tags).\n",
    "# - replacement: replacement string to apply when regexes match. Default is \" \".\n",
    "# - lowercase: whether to convert strings to lowercase. Default is False.\n",
    "# - removalPolicy: removalPolicy to remove patterns from text with a given policy. Valid policy values are: \"all\", \"pretty_all\", \"first\", \"pretty_first\". Defaults is \"pretty_all\".\n",
    "# - encoding: file encoding to apply on normalized documents. Supported encodings are: UTF_8, UTF_16, US_ASCII, ISO-8859-1, UTF-16BE, UTF-16LE. Default is \"UTF-8\".\n",
    "\n",
    "\n",
    "documentAssembler = DocumentAssembler() \\\n",
    "    .setInputCol('text') \\\n",
    "    .setOutputCol('document')\n",
    "\n",
    "inpuColName = \"document\"\n",
    "outputColName = \"normalizedDocument\"\n",
    "\n",
    "action = \"clean\"\n",
    "cleanUpPatterns = [\"<[^>]*>\"]\n",
    "replacement = \" \"\n",
    "removalPolicy = \"pretty_all\"\n",
    "encoding = \"UTF-8\"\n",
    "\n",
    "documentNormalizer = DocumentNormalizer() \\\n",
    "    .setInputCols(inpuColName) \\\n",
    "    .setOutputCol(outputColName) \\\n",
    "    .setAction(action) \\\n",
    "    .setPatterns(cleanUpPatterns) \\\n",
    "    .setReplacement(replacement) \\\n",
    "    .setPolicy(removalPolicy) \\\n",
    "    .setLowercase(True) \\\n",
    "    .setEncoding(encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "58874c76-fc17-4d9e-9b4d-4e3db38cca95",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                text|\n",
      "+--------------------+\n",
      "|<div class='w3-co...|\n",
      "|<!DOCTYPE html>\n",
      "<...|\n",
      "|<span style=\"font...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = \"html-docs\"\n",
    "\n",
    "data = spark.sparkContext.wholeTextFiles(\"html-docs\")\n",
    "df = data.toDF(schema=[\"filename\", \"text\"]).select(\"text\")\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: remove all the tags from HTML text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f15441c7-5d2c-46f6-b102-fe9bc50c1b5e",
     "showTitle": true,
     "title": "Use case #1: HTML documents normalization using clean up and extract action"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|  normalizedDocument|\n",
      "+--------------------+\n",
      "|[[document, 0, 67...|\n",
      "|[[document, 0, 17...|\n",
      "|[[document, 0, 31...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Once data is loaded we can process the textual document applying a pipeline that normalizes the document right after the DocumentAssembler.\n",
    "# For instance, let's imagine we are loading some HTML pages in our DataFrame and we want to remove all the tags in it:\n",
    "\n",
    "documentAssembler = DocumentAssembler() \\\n",
    "    .setInputCol('text') \\\n",
    "    .setOutputCol('document')\n",
    "\n",
    "cleanUpPatterns = [\"<[^>]*>\"]\n",
    "\n",
    "documentNormalizer = DocumentNormalizer() \\\n",
    "    .setInputCols(\"document\") \\\n",
    "    .setOutputCol(\"normalizedDocument\") \\\n",
    "    .setAction(\"clean\") \\\n",
    "    .setPatterns(cleanUpPatterns) \\\n",
    "    .setReplacement(\" \") \\\n",
    "    .setPolicy(\"pretty_all\") \\\n",
    "    .setLowercase(True)\n",
    "\n",
    "sentenceDetector = SentenceDetector() \\\n",
    "      .setInputCols([\"normalizedDocument\"]) \\\n",
    "      .setOutputCol(\"sentence\")\n",
    "\n",
    "regexTokenizer = Tokenizer() \\\n",
    "      .setInputCols([\"sentence\"]) \\\n",
    "      .setOutputCol(\"token\") \\\n",
    "      .fit(df)\n",
    "\n",
    "docPatternRemoverPipeline = \\\n",
    "  Pipeline() \\\n",
    "    .setStages([\n",
    "        documentAssembler,\n",
    "        documentNormalizer,\n",
    "        sentenceDetector,\n",
    "        regexTokenizer])\n",
    "\n",
    "ds = docPatternRemoverPipeline.fit(df).transform(df)\n",
    "\n",
    "ds.select(\"normalizedDocument\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: obfuscate PII such as emails in HTML content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|normalizedDocument                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[[document, 0, 1212, <div class='w3-container top'> <a class='w3schools-logo notranslate' href='//www.w3schools.com'>w3schools<span class='dotcom'>.com</span></a> <div id=\"loginactioncontainer\" class='w3-right'> <div id=\"mypagediv\"></div> <a id=\"w3loginbtn\" style=\"display:none;\" class=\"login w3-right\" href='javascript:void(0);' onclick='w3_open_nav(\"login\")'>log in</a> </div> <div id=\"theworldsgreatest\" class='w3-right w3-hide-small w3-wide toptext' style=\"font-family:'segoe ui',arial,sans-serif\"> the world's largest web developer site <h1 style=\"font-size:300%;\">the world's largest web developer site</h1> <p style=\"font-size:160%;\">lorem ipsum is simply dummy text of the printing and typesetting industry. lorem ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. it has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. it was popularised in the 1960s with the release of letraset sheets containing lorem ipsum passages, and more recently with desktop publishing software like aldus pagemaker including versions of lorem ipsum..</p> </div> </div>, [sentence -> 0], []]]|\n",
      "|[[document, 0, 410, <!doctype html> <html> <body> <a class='w3schools-logo notranslate' href='//www.w3schools.com'>w3schools<span class='dotcom'>.com</span></a> <h1 style=\"font-size:300%;\">this is a heading</h1> <p style=\"font-size:160%;\">this is a paragraph containing some pii like ***obfuscated pii*** ! john is now 42 years old.</p> <p style=\"font-size:160%;\">48% of cardiologists treated patients aged 65+.</p> </body> </html>, [sentence -> 0], []]]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n",
      "|[[document, 0, 241, <span style=\"font-weight: bold; font-size: 8pt\"> <pre style=\"font-family: verdana\"> <b>the output y(s) of the fig. is: <br /><br /> <img src=\"http://192.168.5.151/uadp4.0/itemauthoring/questionbank/resources/94954.jpeg\" /> </b> </pre> </span>, [sentence -> 0], []]]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "documentAssembler = DocumentAssembler() \\\n",
    "    .setInputCol('text') \\\n",
    "    .setOutputCol('document')\n",
    "\n",
    "action = \"clean\"\n",
    "patterns = [\"([^.@\\\\s]+)(\\\\.[^.@\\\\s]+)*@([^.@\\\\s]+\\\\.)+([^.@\\\\s]+)\"]\n",
    "replacement = \"***OBFUSCATED PII***\"\n",
    "\n",
    "documentNormalizer = DocumentNormalizer() \\\n",
    "    .setInputCols(\"document\") \\\n",
    "    .setOutputCol(\"normalizedDocument\") \\\n",
    "    .setAction(\"clean\") \\\n",
    "    .setPatterns(cleanUpPatterns) \\\n",
    "    .setReplacement(replacement) \\\n",
    "    .setPolicy(\"pretty_all\") \\\n",
    "    .setLowercase(True)\n",
    "\n",
    "sentenceDetector = SentenceDetector() \\\n",
    "      .setInputCols([\"normalizedDocument\"]) \\\n",
    "      .setOutputCol(\"sentence\")\n",
    "\n",
    "regexTokenizer = Tokenizer() \\\n",
    "      .setInputCols([\"sentence\"]) \\\n",
    "      .setOutputCol(\"token\") \\\n",
    "      .fit(df)\n",
    "\n",
    "docPatternRemoverPipeline = \\\n",
    "  Pipeline() \\\n",
    "    .setStages([\n",
    "        documentAssembler,\n",
    "        documentNormalizer,\n",
    "        sentenceDetector,\n",
    "        regexTokenizer])\n",
    "\n",
    "ds = docPatternRemoverPipeline.fit(df).transform(df)\n",
    "\n",
    "ds.select(\"normalizedDocument\").show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3: obfuscate PII such as ages in HTML content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ee2421ea-6f99-4161-ba15-2dffa44f91a8",
     "showTitle": true,
     "title": "Remove PII emails (\"this is a paragraph containing some pii like jonhdoe@myemail.com\")"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|normalizedDocument                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[[document, 0, 1212, <div class='w3-container top'> <a class='w3schools-logo notranslate' href='//www.w3schools.com'>w3schools<span class='dotcom'>.com</span></a> <div id=\"loginactioncontainer\" class='w3-right'> <div id=\"mypagediv\"></div> <a id=\"w3loginbtn\" style=\"display:none;\" class=\"login w3-right\" href='javascript:void(0);' onclick='w3_open_nav(\"login\")'>log in</a> </div> <div id=\"theworldsgreatest\" class='w3-right w3-hide-small w3-wide toptext' style=\"font-family:'segoe ui',arial,sans-serif\"> the world's largest web developer site <h1 style=\"font-size:300%;\">the world's largest web developer site</h1> <p style=\"font-size:160%;\">lorem ipsum is simply dummy text of the printing and typesetting industry. lorem ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. it has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. it was popularised in the 1960s with the release of letraset sheets containing lorem ipsum passages, and more recently with desktop publishing software like aldus pagemaker including versions of lorem ipsum..</p> </div> </div>, [sentence -> 0], []]]|\n",
      "|[[document, 0, 440, <!doctype html> <html> <body> <a class='w3schools-logo notranslate' href='//www.w3schools.com'>w3schools<span class='dotcom'>.com</span></a> <h1 style=\"font-size:300%;\">this is a heading</h1> <p style=\"font-size:160%;\">this is a paragraph containing some pii like jonhdoe@myemail.com ! john is now ***obfuscated pii*** years old.</p> <p style=\"font-size:160%;\">48% of cardiologists treated patients ***obfuscated pii***+.</p> </body> </html>, [sentence -> 0], []]]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n",
      "|[[document, 0, 241, <span style=\"font-weight: bold; font-size: 8pt\"> <pre style=\"font-family: verdana\"> <b>the output y(s) of the fig. is: <br /><br /> <img src=\"http://192.168.5.151/uadp4.0/itemauthoring/questionbank/resources/94954.jpeg\" /> </b> </pre> </span>, [sentence -> 0], []]]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "documentAssembler = DocumentAssembler() \\\n",
    "    .setInputCol('text') \\\n",
    "    .setOutputCol('document')\n",
    "\n",
    "action = \"clean\"\n",
    "patterns = [\"\\\\d+(?=[\\\\s]?year)\", \"(aged)[\\\\s]?\\\\d+\"]\n",
    "replacement = \"***OBFUSCATED PII***\"\n",
    "\n",
    "documentNormalizer = DocumentNormalizer() \\\n",
    "    .setInputCols(\"document\") \\\n",
    "    .setOutputCol(\"normalizedDocument\") \\\n",
    "    .setAction(action) \\\n",
    "    .setPatterns(patterns) \\\n",
    "    .setReplacement(replacement) \\\n",
    "    .setPolicy(\"pretty_all\") \\\n",
    "    .setLowercase(True)\n",
    "\n",
    "sentenceDetector = SentenceDetector() \\\n",
    "      .setInputCols([\"normalizedDocument\"]) \\\n",
    "      .setOutputCol(\"sentence\")\n",
    "\n",
    "regexTokenizer = Tokenizer() \\\n",
    "      .setInputCols([\"sentence\"]) \\\n",
    "      .setOutputCol(\"token\") \\\n",
    "      .fit(df)\n",
    "\n",
    "docPatternRemoverPipeline = \\\n",
    "  Pipeline() \\\n",
    "    .setStages([\n",
    "        documentAssembler,\n",
    "        documentNormalizer,\n",
    "        sentenceDetector,\n",
    "        regexTokenizer])\n",
    "\n",
    "ds = docPatternRemoverPipeline.fit(df).transform(df)\n",
    "\n",
    "ds.select(\"normalizedDocument\").show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 4: extract XML name tag contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1a7b7c94-f738-464e-b48f-4cc33807b0af",
     "showTitle": true,
     "title": "Use case #2: XML documents normalization using extract action on assigned person tag"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                text|\n",
      "+--------------------+\n",
      "|<?xml version=\"1....|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# data loading\n",
    "data = spark.sparkContext.wholeTextFiles(\"xml-docs\")\n",
    "df = data.toDF(schema=[\"filename\", \"text\"]).select(\"text\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c75d10d8-d31f-40f6-a3cd-69b324c08325",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|normalizedDocument                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[[document, 0, 638,  isabella isa jones ralph jones community health and hospitals henry seven henry seven henry seven frank jones community health and hospitals henry seven community health and hospitals henry seven henry seven mrs. martha jones health ls - immuno inc.health ls - immuno inc.health ls - immuno inc.health ls - immuno inc.medication factory inc.community health and hospitalsaerosolmedication factory inc. dr. henry seven medication factory inc. dr. henry seven community health and hospitalscommunity health and hospitalscommunity health and hospitalscommunity health and hospitalscommunity health and hospitalscommunity health and hospitals, [sentence -> 0], []]]|\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "documentAssembler = DocumentAssembler() \\\n",
    "    .setInputCol('text') \\\n",
    "    .setOutputCol('document')\n",
    "\n",
    "action = \"extract\"\n",
    "\n",
    "tag = \"name\"\n",
    "patterns = [tag]\n",
    "\n",
    "documentNormalizer = DocumentNormalizer() \\\n",
    "    .setInputCols(\"document\") \\\n",
    "    .setOutputCol(\"normalizedDocument\") \\\n",
    "    .setAction(action) \\\n",
    "    .setPatterns(patterns) \\\n",
    "    .setReplacement(\"\") \\\n",
    "    .setPolicy(\"pretty_all\") \\\n",
    "    .setLowercase(True)\n",
    "\n",
    "sentenceDetector = SentenceDetector() \\\n",
    "      .setInputCols([\"normalizedDocument\"]) \\\n",
    "      .setOutputCol(\"sentence\")\n",
    "\n",
    "regexTokenizer = Tokenizer() \\\n",
    "      .setInputCols([\"sentence\"]) \\\n",
    "      .setOutputCol(\"token\") \\\n",
    "      .fit(df)\n",
    "\n",
    "docPatternRemoverPipeline = \\\n",
    "  Pipeline() \\\n",
    "    .setStages([\n",
    "        documentAssembler,\n",
    "        documentNormalizer,\n",
    "        sentenceDetector,\n",
    "        regexTokenizer])\n",
    "\n",
    "ds = docPatternRemoverPipeline.fit(df).transform(df)\n",
    "\n",
    "ds.select(\"normalizedDocument\").show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f1f9a9bd-20c7-4375-a1e9-6f75d83be23f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Example 5 : apply lookaround patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = [\n",
    "            (1, \"10.2\",),\n",
    "            (2, \"9,53\",),\n",
    "            (3, \"11.01 mg\",),\n",
    "            (4, \"mg 11.01\",),\n",
    "            (5, \"14,220\",),\n",
    "            (6, \"Amoxiciline 4,5 mg for $10.35; Ibuprofen 5,5mg for $9.00.\",)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n",
      "+---+---------------------------------------------------------+\n",
      "|id |text                                                     |\n",
      "+---+---------------------------------------------------------+\n",
      "|1  |10.2                                                     |\n",
      "|2  |9,53                                                     |\n",
      "|3  |11.01 mg                                                 |\n",
      "|4  |mg 11.01                                                 |\n",
      "|5  |14,220                                                   |\n",
      "|6  |Amoxiciline 4,5 mg for $10.35; Ibuprofen 5,5mg for $9.00.|\n",
      "+---+---------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "articles_cols = [\"id\", \"text\"]\n",
    "df = spark.createDataFrame(data=articles, schema=articles_cols)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotate replacing . to , using positive lookahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------+--------------------------------------------------------------------------------------------------+\n",
      "|text                                                     |normalized                                                                                        |\n",
      "+---------------------------------------------------------+--------------------------------------------------------------------------------------------------+\n",
      "|10.2                                                     |[{document, 0, 3, 10.2, {sentence -> 0}, []}]                                                     |\n",
      "|9,53                                                     |[{document, 0, 3, 9,53, {sentence -> 0}, []}]                                                     |\n",
      "|11.01 mg                                                 |[{document, 0, 7, 11,01 mg, {sentence -> 0}, []}]                                                 |\n",
      "|mg 11.01                                                 |[{document, 0, 7, mg 11.01, {sentence -> 0}, []}]                                                 |\n",
      "|14,220                                                   |[{document, 0, 5, 14,220, {sentence -> 0}, []}]                                                   |\n",
      "|Amoxiciline 4,5 mg for $10.35; Ibuprofen 5,5mg for $9.00.|[{document, 0, 55, Amoxiciline 4,5 mg for $10.35; Ibuprofen 5,5mg for $9.00, {sentence -> 0}, []}]|\n",
      "+---------------------------------------------------------+--------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import Spark NLP\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "\n",
    "# Targetting text 11.01 mg annotating to 11,01 mg\n",
    "\n",
    "action = \"lookaround\"\n",
    "patterns = [\".*\\d+(\\.)\\d+(?= mg).*\"]\n",
    "replacement = \",\"\n",
    "\n",
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "doc_norm = DocumentNormalizer() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"normalized\") \\\n",
    "    .setAction(action) \\\n",
    "    .setPatterns(patterns) \\\n",
    "    .setReplacement(replacement)\n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "    document_assembler,\n",
    "    doc_norm\n",
    "])\n",
    "\n",
    "model = pipeline.fit(df)\n",
    "model.transform(df).select(\"text\", \"normalized\").show(20, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotate replacing . to , using positive lookbehind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------+--------------------------------------------------------------------------------------------------+\n",
      "|text                                                     |normalized                                                                                        |\n",
      "+---------------------------------------------------------+--------------------------------------------------------------------------------------------------+\n",
      "|10.2                                                     |[{document, 0, 3, 10.2, {sentence -> 0}, []}]                                                     |\n",
      "|9,53                                                     |[{document, 0, 3, 9,53, {sentence -> 0}, []}]                                                     |\n",
      "|11.01 mg                                                 |[{document, 0, 7, 11.01 mg, {sentence -> 0}, []}]                                                 |\n",
      "|mg 11.01                                                 |[{document, 0, 7, mg 11,01, {sentence -> 0}, []}]                                                 |\n",
      "|14,220                                                   |[{document, 0, 5, 14,220, {sentence -> 0}, []}]                                                   |\n",
      "|Amoxiciline 4,5 mg for $10.35; Ibuprofen 5,5mg for $9.00.|[{document, 0, 55, Amoxiciline 4,5 mg for $10.35; Ibuprofen 5,5mg for $9.00, {sentence -> 0}, []}]|\n",
      "+---------------------------------------------------------+--------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Targetting text mg 11.01 annotating to mg 11,01\n",
    "\n",
    "action = \"lookaround\"\n",
    "patterns = [\".*(?<=mg )\\d+(\\.)\\d+.*\"]\n",
    "replacement = \",\"\n",
    "\n",
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "doc_norm = DocumentNormalizer() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"normalized\") \\\n",
    "    .setAction(action) \\\n",
    "    .setPatterns(patterns) \\\n",
    "    .setReplacement(replacement)\n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "    document_assembler,\n",
    "    doc_norm\n",
    "])\n",
    "\n",
    "model = pipeline.fit(df)\n",
    "model.transform(df).select(\"text\", \"normalized\").show(20, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotate replacing , to . using iterative positive lookahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------+--------------------------------------------------------------------------------------------------+\n",
      "|text                                                     |normalized                                                                                        |\n",
      "+---------------------------------------------------------+--------------------------------------------------------------------------------------------------+\n",
      "|10.2                                                     |[{document, 0, 3, 10.2, {sentence -> 0}, []}]                                                     |\n",
      "|9,53                                                     |[{document, 0, 3, 9,53, {sentence -> 0}, []}]                                                     |\n",
      "|11.01 mg                                                 |[{document, 0, 7, 11.01 mg, {sentence -> 0}, []}]                                                 |\n",
      "|mg 11.01                                                 |[{document, 0, 7, mg 11.01, {sentence -> 0}, []}]                                                 |\n",
      "|14,220                                                   |[{document, 0, 5, 14,220, {sentence -> 0}, []}]                                                   |\n",
      "|Amoxiciline 4,5 mg for $10.35; Ibuprofen 5,5mg for $9.00.|[{document, 0, 55, Amoxiciline 4.5 mg for $10.35; Ibuprofen 5.5mg for $9.00, {sentence -> 0}, []}]|\n",
      "+---------------------------------------------------------+--------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Targetting text Amoxiciline 4,5 mg for $10.35; Ibuprofen 5,5mg for $9.00.\n",
    "# annotating to \n",
    "# Amoxiciline 4.5 mg for $10.35; Ibuprofen 5.5mg for $9.00\n",
    "\n",
    "action = \"lookaround\"\n",
    "patterns = [\".*\\d+(\\,)\\d+(?=\\s?mg).*\"]\n",
    "replacement = \".\"\n",
    "\n",
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "doc_norm = DocumentNormalizer() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"normalized\") \\\n",
    "    .setAction(action) \\\n",
    "    .setPatterns(patterns) \\\n",
    "    .setReplacement(replacement)\n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "    document_assembler,\n",
    "    doc_norm\n",
    "])\n",
    "\n",
    "model = pipeline.fit(df)\n",
    "model.transform(df).select(\"text\", \"normalized\").show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookName": "DocumentNormalizer_notebook_doc",
   "notebookOrigID": 3142402907558969,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
