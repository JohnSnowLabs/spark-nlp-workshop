{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ChunkMergeSample.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "jsl250",
      "language": "python",
      "name": "jsl250"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lc_L6EaAWEzo"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/enterprise/healthcare/ChunkMergeSample.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MdE588BiY3z1",
        "outputId": "29dd15c0-3ed4-42a5-d6f6-262ef222dd21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import json\n",
        "\n",
        "with open('keys.json') as f:\n",
        "    license_keys = json.load(f)\n",
        "\n",
        "license_keys.keys()\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['version', 'secret', 'SPARK_NLP_LICENSE', 'JSL_OCR_LICENSE', 'AWS_ACCESS_KEY_ID', 'AWS_SECRET_ACCESS_KEY', 'JSL_OCR_SECRET'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FVFdvGChZDDP",
        "outputId": "8c60e6ac-bbc4-4bd2-b2d2-79338959aa82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "import os\n",
        "\n",
        "# Install java\n",
        "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "! java -version\n",
        "\n",
        "secret = license_keys['secret']\n",
        "os.environ['SPARK_NLP_LICENSE'] = license_keys['SPARK_NLP_LICENSE']\n",
        "os.environ['JSL_OCR_LICENSE'] = license_keys['JSL_OCR_LICENSE']\n",
        "os.environ['AWS_ACCESS_KEY_ID']= license_keys['AWS_ACCESS_KEY_ID']\n",
        "os.environ['AWS_SECRET_ACCESS_KEY'] = license_keys['AWS_SECRET_ACCESS_KEY']\n",
        "version = license_keys['version']\n",
        "\n",
        "! python -m pip install --upgrade spark-nlp-jsl==$version  --extra-index-url https://pypi.johnsnowlabs.com/$secret\n",
        "\n",
        "import sparknlp\n",
        "\n",
        "print (sparknlp.version())\n",
        "\n",
        "import json\n",
        "import os\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp_jsl.annotator import *\n",
        "from sparknlp.base import *\n",
        "import sparknlp_jsl\n",
        "\n",
        "\n",
        "\n",
        "def start(secret):\n",
        "    builder = SparkSession.builder \\\n",
        "        .appName(\"Spark NLP Licensed\") \\\n",
        "        .master(\"local[*]\") \\\n",
        "        .config(\"spark.driver.memory\", \"16G\") \\\n",
        "        .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
        "        .config(\"spark.kryoserializer.buffer.max\", \"2000M\") \\\n",
        "        .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.11:\"+version) \\\n",
        "        .config(\"spark.jars\", \"https://pypi.johnsnowlabs.com/\"+secret+\"/spark-nlp-jsl-\"+jsl_version+\".jar\")\n",
        "      \n",
        "    return builder.getOrCreate()\n",
        "\n",
        "\n",
        "spark = start(secret) # if you want to start the session with custom params as in start function above\n",
        "# sparknlp_jsl.start(secret)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"1.8.0_252\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_252-8u252-b09-1~18.04-b09)\n",
            "OpenJDK 64-Bit Server VM (build 25.252-b09, mixed mode)\n",
            "Looking in indexes: https://pypi.org/simple, https://pypi.johnsnowlabs.com/8zvTuUjWPt\n",
            "Collecting spark-nlp-jsl==2.5.2\n",
            "  Downloading https://pypi.johnsnowlabs.com/8zvTuUjWPt/spark-nlp-jsl/spark_nlp_jsl-2.5.2-py3-none-any.whl\n",
            "Collecting spark-nlp==2.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/b0/c272273674b5810c0909b369c57669197907a15d84bbdf058007bb909c99/spark_nlp-2.5.2-py2.py3-none-any.whl (122kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 2.9MB/s \n",
            "\u001b[?25hCollecting pyspark==2.4.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/21/f05c186f4ddb01d15d0ddc36ef4b7e3cedbeb6412274a41f26b55a650ee5/pyspark-2.4.4.tar.gz (215.7MB)\n",
            "\u001b[K     |████████████████████████████████| 215.7MB 58kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 46.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.4-py2.py3-none-any.whl size=216130388 sha256=2082d1f291bf1779d18cdd57753be06fc6e44529f213b5efcdf64925bc64676b\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/09/4d/0d184230058e654eb1b04467dbc1292f00eaa186544604b471\n",
            "Successfully built pyspark\n",
            "Installing collected packages: spark-nlp, py4j, pyspark, spark-nlp-jsl\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.4 spark-nlp-2.5.2 spark-nlp-jsl-2.5.2\n",
            "2.5.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1zgsiTxjaiMd",
        "colab": {}
      },
      "source": [
        "data_chunk_merge = spark.createDataFrame([\n",
        "  (1,\"Zacarias Woods would not have T2N1 at Los Angeles California where he presented lymphocite leukimia\",),\n",
        "  (2,\"Andre Agassi had 2 x 3 x 1 mm hairwig better than T1N2M1 with adenocarcinoma\",)\n",
        "]).toDF(\"id\",\"text\")\n",
        "\n",
        "regex = '''(c|p|yc|yp|r|rp|a)?(C[1-5])?M(x|X|0|1[a-d]?),pM\n",
        "(c|p|yc|yp|r|rp|a)?(C[1-5])?N(x|X|0|[1-3][a-d]?),pN\n",
        "(c|p|yc|yp|r|rp|a)?(C[1-5])?T(x|X|is|0|[1-4][a-d]?),pT\n",
        "(c|p|yc|yp|r|rp|a)?(C[1-5])?T(x|X|is|0|[1-4][a-d]?),pT\n",
        "([0-9]+(\\.[0-9]+)?\\s?x\\s?)*([0-9]+(\\.[0-9]+)?)\\s?(mg|MG|mm|cm|MM|CM|),SIZE\n",
        "T1N2M1,TNM\n",
        "at Los Angeles California,LOCATION\n",
        "Zacarias,PERSON\n",
        "better than,BLOCK'''\n",
        "\n",
        "with open('ner_regex.csv', 'w') as f:\n",
        "    f.write(regex)\n",
        "\n",
        "replace_dict = '''pT,TNM\n",
        "pM,TNM'''\n",
        "\n",
        "with open('replace_dict.csv', 'w') as f:\n",
        "    f.write(replace_dict)\n",
        "\n",
        "false_positives = '''better than,BLOCK'''\n",
        "\n",
        "with open('false_positives.csv', 'w') as f:\n",
        "    f.write(false_positives)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "weY5V9h7ZDf0",
        "outputId": "e9c2f9a0-258e-4c19-c34f-a670722fb6c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "da = DocumentAssembler().setInputCol(\"text\").setOutputCol(\"document\")\n",
        "sd = SentenceDetector().setInputCols(\"document\").setOutputCol(\"sentence\")\n",
        "tk = Tokenizer().setInputCols(\"sentence\").setOutputCol(\"token\")\n",
        "emb = WordEmbeddingsModel.pretrained(\"embeddings_clinical\",\"en\",\"clinical/models\").setOutputCol(\"embs\")\n",
        "ner = NerDLModel.pretrained(\"ner_deid_large\",\"en\",\"clinical/models\").setInputCols(\"sentence\",\"token\",\"embs\").setOutputCol(\"ner\")\n",
        "canner = NerDLModel.pretrained(\"ner_bionlp\",\"en\",\"clinical/models\").setInputCols(\"sentence\",\"token\",\"embs\").setOutputCol(\"canner\")\n",
        "nc = NerConverter().setInputCols(\"sentence\",\"token\",\"ner\").setOutputCol(\"ner_chunk\")\n",
        "cannc = NerConverter().setInputCols(\"sentence\",\"token\",\"canner\").setOutputCol(\"canner_chunk\")\n",
        "rex = RegexMatcher().setInputCols(\"sentence\").setOutputCol(\"rex\").setExternalRules(\"ner_regex.csv\",\",\",\"TEXT\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "embeddings_clinical download started this may take some time.\n",
            "Approximate size to download 1.6 GB\n",
            "[OK!]\n",
            "ner_deid_large download started this may take some time.\n",
            "Approximate size to download 14 MB\n",
            "[OK!]\n",
            "ner_bionlp download started this may take some time.\n",
            "Approximate size to download 13.9 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45Cr6STSKvZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#######################################################################################\n",
        "\n",
        "merger_can = ChunkMergeApproach().setInputCols(\"ner_chunk\",\"canner_chunk\").setOutputCol(\"combined\")\\\n",
        "    .setFalsePositivesResource(\"false_positives.csv\",\"TEXT\", {\"delimiter\":\",\"})\\\n",
        "    .setReplaceDictResource(\"replace_dict.csv\",\"TEXT\", {\"delimiter\":\",\"})\n",
        "\n",
        "merger_rex = ChunkMergeApproach().setInputCols(\"combined\",\"rex\").setOutputCol(\"combined\")\\\n",
        "    .setFalsePositivesResource(\"false_positives.csv\",\"TEXT\", {\"delimiter\":\",\"})\\\n",
        "    .setReplaceDictResource(\"replace_dict.csv\",\"TEXT\", {\"delimiter\":\",\"})\\\n",
        "\n",
        "#######################################################################################\n",
        "\n",
        "pl = Pipeline().setStages([da,sd,tk,emb,ner,canner,nc,cannc,rex,merger_can, merger_rex])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8jVGpbBxWEz1",
        "colab": {}
      },
      "source": [
        "merged_data = pl.fit(data_chunk_merge).transform(data_chunk_merge).cache()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ogbBOST6aZTt",
        "outputId": "34f9d71a-c029-4803-de40-391ac5720066",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "merged_data.selectExpr(\"id\",\"explode(arrays_zip(ner_chunk.begin,ner_chunk.end,ner_chunk.result, ner_chunk.metadata)) as a\")\\\n",
        ".selectExpr(\"id\",\"a['0'] as begin\",\"a['1'] as end\",\"a['2'] as ner_chunk\",\"a['3'].entity as entity\")\\\n",
        ".orderBy(\"id\",\"begin\").show(100, False)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+-----+---+----------------------+--------+\n",
            "|id |begin|end|ner_chunk             |entity  |\n",
            "+---+-----+---+----------------------+--------+\n",
            "|1  |0    |13 |Zacarias Woods        |NAME    |\n",
            "|1  |38   |59 |Los Angeles California|LOCATION|\n",
            "|1  |80   |98 |lymphocite leukimia   |NAME    |\n",
            "|2  |0    |11 |Andre Agassi          |NAME    |\n",
            "+---+-----+---+----------------------+--------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bYlwmyDhfwNa",
        "outputId": "2dba5268-483f-4a1f-ad09-21c982c5c536",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "merged_data.selectExpr(\"id\",\"explode(arrays_zip(canner_chunk.begin,canner_chunk.end,canner_chunk.result, canner_chunk.metadata)) as a\")\\\n",
        ".selectExpr(\"id\",\"a['0'] as begin\",\"a['1'] as end\",\"a['2'] as ner_chunk\",\"a['3'].entity as entity\")\\\n",
        ".orderBy(\"id\",\"begin\").show(100, False)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+-----+---+--------------+--------------------+\n",
            "|id |begin|end|ner_chunk     |entity              |\n",
            "+---+-----+---+--------------+--------------------+\n",
            "|1  |0    |7  |Zacarias      |Gene_or_gene_product|\n",
            "|2  |6    |11 |Agassi        |Gene_or_gene_product|\n",
            "|2  |50   |55 |T1N2M1        |Gene_or_gene_product|\n",
            "|2  |62   |75 |adenocarcinoma|Cancer              |\n",
            "+---+-----+---+--------------+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-1RFnel-WEz7",
        "outputId": "befcbb84-fd3e-45b5-8733-182935ac349a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "merged_data.selectExpr(\"id\",\"explode(arrays_zip(rex.begin,rex.end,rex.result, rex.metadata)) as a\")\\\n",
        ".selectExpr(\"id\",\"a['0'] as begin\",\"a['1'] as end\",\"a['2'] as ner_chunk\",\"a['3'].identifier as entity\")\\\n",
        ".orderBy(\"id\",\"begin\").show(100, False)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+-----+---+-------------------------+--------+\n",
            "|id |begin|end|ner_chunk                |entity  |\n",
            "+---+-----+---+-------------------------+--------+\n",
            "|1  |0    |7  |Zacarias                 |PERSON  |\n",
            "|1  |30   |31 |T2                       |pT      |\n",
            "|1  |30   |31 |T2                       |pT      |\n",
            "|1  |31   |31 |2                        |SIZE    |\n",
            "|1  |32   |33 |N1                       |pN      |\n",
            "|1  |33   |34 |1                        |SIZE    |\n",
            "|1  |35   |59 |at Los Angeles California|LOCATION|\n",
            "|2  |17   |28 |2 x 3 x 1 mm             |SIZE    |\n",
            "|2  |38   |48 |better than              |BLOCK   |\n",
            "|2  |50   |51 |T1                       |pT      |\n",
            "|2  |50   |51 |T1                       |pT      |\n",
            "|2  |50   |55 |T1N2M1                   |TNM     |\n",
            "|2  |51   |51 |1                        |SIZE    |\n",
            "|2  |52   |53 |N2                       |pN      |\n",
            "|2  |53   |53 |2                        |SIZE    |\n",
            "|2  |54   |55 |M1                       |pM      |\n",
            "|2  |55   |56 |1                        |SIZE    |\n",
            "+---+-----+---+-------------------------+--------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dpLba4tAbPiW",
        "outputId": "11291ecd-8002-4a9d-954d-19445251a160",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "merged_data.selectExpr(\"id\",\"explode(arrays_zip(combined.result, combined.metadata)) as a\")\\\n",
        ".selectExpr(\"id\",\"a['0'] as chunk\",\"a['1'].entity as entity\").show(100, False)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+-------------------------+--------------------+\n",
            "|id |chunk                    |entity              |\n",
            "+---+-------------------------+--------------------+\n",
            "|1  |Zacarias Woods           |NAME                |\n",
            "|1  |T2                       |TNM                 |\n",
            "|1  |N1                       |pN                  |\n",
            "|1  |at Los Angeles California|LOCATION            |\n",
            "|1  |lymphocite leukimia      |NAME                |\n",
            "|2  |Andre Agassi             |NAME                |\n",
            "|2  |2 x 3 x 1 mm             |SIZE                |\n",
            "|2  |T1N2M1                   |Gene_or_gene_product|\n",
            "|2  |adenocarcinoma           |Cancer              |\n",
            "+---+-------------------------+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KtaZ8EBBWE0B",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}