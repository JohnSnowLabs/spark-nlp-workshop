{"cells":[{"cell_type":"markdown","source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/transformers/HuggingFace%20in%20Spark%20NLP%20-%20RoBERTa.ipynb)"],"metadata":{"id":"O1htkW4UQpwE"}},{"cell_type":"markdown","source":["## Import RoBERTa models from HuggingFace ðŸ¤—  into Spark NLP ðŸš€ \n","\n","Let's keep in mind a few things before we start ðŸ˜Š \n","\n","- This feature is only in `Spark NLP 3.1.x` and after. So please make sure you have upgraded to the latest Spark NLP release\n","- You can import models for RoBERTa from HuggingFace but they have to be compatible with `TensorFlow` and they have to be in `Fill Mask` category. Meaning, you cannot use RoBERTa models trained/fine-tuned on a specific task such as token/sequence classification."],"metadata":{"id":"Zva6MvJyLeWi"}},{"cell_type":"markdown","source":["## Export and Save HuggingFace model"],"metadata":{"id":"MzxB-Nq6cxOA"}},{"cell_type":"markdown","source":["- Let's install `HuggingFace` and `TensorFlow`. You don't need `TensorFlow` to be installed for Spark NLP, however, we need it to load and save models from HuggingFace.\n","- We lock TensorFlow on `2.4.1` version and Transformers on `4.6.1`. This doesn't mean it won't work with the future releases, but we wanted you to know which versions have been tested successfully."],"metadata":{"id":"yNQkhyMHMgkE"}},{"cell_type":"code","source":["!pip install -q transformers==4.6.1 tensorflow==2.4.1"],"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.3MB 2.9MB/s \n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 394.3MB 36kB/s \n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.3MB 37.0MB/s \n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 901kB 40.5MB/s \n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.8MB 42.7MB/s \n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 471kB 41.7MB/s \n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.9MB 40.1MB/s \n","\u001b[?25h"]}],"execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":79664,"status":"ok","timestamp":1622476245503,"user":{"displayName":"Maziyar Panahi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTmm4Srbdy-IOOALumHToD8y9PvjupF566HEz1zA=s64","userId":"06037986691777662786"},"user_tz":-120},"id":"hHXgqiWpMfCY","outputId":"5290a6f5-417a-4a0e-e6d6-2aba664f030c"}},{"cell_type":"markdown","source":["- HuggingFace comes with a native `saved_model` feature inside `save_pretrained` function for TensorFlow based models. We will use that to save it as TF `SavedModel`.\n","- We'll use [roberta-base](https://huggingface.co/roberta-base) model from HuggingFace as an example\n","- In addition to `TFRobertaModel` we also need to save the `RobertaTokenizer`. This is the same for every model, these are assets needed for tokenization inside Spark NLP."],"metadata":{"id":"Y3AM6bj4P3NS"}},{"cell_type":"code","source":["from transformers import RobertaTokenizer, TFRobertaModel\n","\n","MODEL_NAME = 'roberta-base'\n","\n","# let's keep the tokenizer variable, we need it later\n","tokenizer = RobertaTokenizer.from_pretrained(MODEL_NAME)\n","# let's save the tokenizer\n","tokenizer.save_pretrained('./{}_tokenizer/'.format(MODEL_NAME))\n","\n","# just in case if there is no TF/Keras file provided in the model\n","# we can just use `from_pt` and convert PyTorch to TensorFlow\n","try:\n","  print('try downloading TF weights')\n","  model = TFRobertaModel.from_pretrained(MODEL_NAME)\n","except:\n","  print('try downloading PyTorch weights')\n","  model = TFRobertaModel.from_pretrained(MODEL_NAME, from_pt=True)\n","\n","model.save_pretrained(\"./{}\".format(MODEL_NAME), saved_model=True)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"35e5ee38bc1c437b8df70d2eae183389","version_major":2,"version_minor":0},"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descriptiâ€¦"},"metadata":{"tags":[]}},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"39c01f1f92ce4ecb89e7bafba714ecb3","version_major":2,"version_minor":0},"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descriptiâ€¦"},"metadata":{"tags":[]}},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a0b574ea85694a09a617848c2d98ed77","version_major":2,"version_minor":0},"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1355863.0, style=ProgressStyle(descriptâ€¦"},"metadata":{"tags":[]}},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"af56cc3ec8044118904cd7e5043e246d","version_major":2,"version_minor":0},"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=481.0, style=ProgressStyle(description_â€¦"},"metadata":{"tags":[]}},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ef61a20839a84bb29f4877120eda6b95","version_major":2,"version_minor":0},"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=657434796.0, style=ProgressStyle(descriâ€¦"},"metadata":{"tags":[]}},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n","- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fdafe58fe50>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fdafe58fe50>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7fdb19e3cdd0> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <function wrap at 0x7fdb19e3cdd0> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as encoder_layer_call_and_return_conditional_losses, encoder_layer_call_fn, pooler_layer_call_and_return_conditional_losses, pooler_layer_call_fn, embeddings_layer_call_and_return_conditional_losses while saving (showing 5 of 1055). These functions will not be directly callable after loading.\n","WARNING:absl:Found untraced functions such as encoder_layer_call_and_return_conditional_losses, encoder_layer_call_fn, pooler_layer_call_and_return_conditional_losses, pooler_layer_call_fn, embeddings_layer_call_and_return_conditional_losses while saving (showing 5 of 1055). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ./roberta-base/saved_model/1/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: ./roberta-base/saved_model/1/assets\n"]}],"execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":945,"referenced_widgets":["35e5ee38bc1c437b8df70d2eae183389","788e3ef4ec61409caf40cc45e23f2f1f","a7b6bc5963af4756ad490e86305f5e24","524d70accce44a1296b2bf8cd9044ebf","0ab09f97b5114624b03cda86be5814a8","943998b3cb204d8489ae0c71081e0390","e3866d1d10c74297abd8fe945bfa574e","0e1999f605a44ec089d3d27a5e6d1874","39c01f1f92ce4ecb89e7bafba714ecb3","97e54be966dc4aeebadf2d77161296a8","5bdca68c26394bc8857c14ca792c8e7d","be5a115938c04631a834020b4426fd11","e81d493c5510490da6655865f859d82f","bba854c507044daf8136a9b3368317fa","9240418ef66b42f4b0e4a4b78520bc9f","a646ecf1a46b4d92a03c417fa44bd517","a0b574ea85694a09a617848c2d98ed77","91dc248081da4e12babe1ac606cc80b1","cd4c3c270a0e42b4bae48a161099483d","220c79e165df4ea59ae5c61abab6493b","dd386f5a79b848458aab9b34179e9351","2c57da9a378042ebaa510f6d58eef27c","5ed79516254d41cf99ec61e552d52b36","44387ff2654445c1b304e9ad0ebdda2b","af56cc3ec8044118904cd7e5043e246d","73a77396295d481584ba3ff2a5746891","52d34ecaf34e4db6b879a076a8a0c918","39e24155d4de40cfb9ba3c3d678d9b3b","9d5d2c73362543ea8f75959a36dbef31","6ed0c9b9a15e4c9196e53deaa6527c26","d530a358eb484cbd90d36842abf80728","649ffc91bd8d4c85b3d6eb82f065b094","ef61a20839a84bb29f4877120eda6b95","1f6af1f0db45462da210f0153d092036","4c2a3270ee274517b12c173e548dc141","71e93f1ef31344998fd0e3382dd71956","739d8fb0cc4a4c80bc00dd3402ea2c43","4ba64be214f04a4cbb9817725389e99d","990b1223d2ca4d15b2b528039646a450","154919ace6a24a9c836627d45af4832d"]},"executionInfo":{"elapsed":102609,"status":"ok","timestamp":1622476348109,"user":{"displayName":"Maziyar Panahi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTmm4Srbdy-IOOALumHToD8y9PvjupF566HEz1zA=s64","userId":"06037986691777662786"},"user_tz":-120},"id":"ZaiirlSKNhVD","outputId":"6012bcbe-3fc0-415b-f0e8-3ba4f6115ac2"}},{"cell_type":"markdown","source":["Let's have a look inside these two directories and see what we are dealing with:"],"metadata":{"id":"nlgyZuJfS5IB"}},{"cell_type":"code","source":["!ls -l {MODEL_NAME}"],"outputs":[{"output_type":"stream","name":"stdout","text":["total 487168\n","-rw-r--r-- 1 root root       642 May 31 15:44 config.json\n","drwxr-xr-x 3 root root      4096 May 31 15:44 saved_model\n","-rw-r--r-- 1 root root 498845224 May 31 15:44 tf_model.h5\n"]}],"execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":303,"status":"ok","timestamp":1622475893386,"user":{"displayName":"Maziyar Panahi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTmm4Srbdy-IOOALumHToD8y9PvjupF566HEz1zA=s64","userId":"06037986691777662786"},"user_tz":-120},"id":"p2XCole7TTef","outputId":"b5eae84c-d956-406c-ac4a-f74c0313820c"}},{"cell_type":"code","source":["!ls -l {MODEL_NAME}/saved_model/1"],"outputs":[{"output_type":"stream","name":"stdout","text":["total 7904\n","drwxr-xr-x 2 root root    4096 May 31 15:44 assets\n","-rw-r--r-- 1 root root 8084231 May 31 15:44 saved_model.pb\n","drwxr-xr-x 2 root root    4096 May 31 15:44 variables\n"]}],"execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1622475893387,"user":{"displayName":"Maziyar Panahi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTmm4Srbdy-IOOALumHToD8y9PvjupF566HEz1zA=s64","userId":"06037986691777662786"},"user_tz":-120},"id":"r0DOGz8VUR-r","outputId":"49e70965-3ee3-4c91-d05c-603e211597d6"}},{"cell_type":"code","source":["!ls -l {MODEL_NAME}_tokenizer"],"outputs":[{"output_type":"stream","name":"stdout","text":["total 1336\n","-rw-r--r-- 1 root root 456318 May 31 15:43 merges.txt\n","-rw-r--r-- 1 root root    772 May 31 15:43 special_tokens_map.json\n","-rw-r--r-- 1 root root   1267 May 31 15:43 tokenizer_config.json\n","-rw-r--r-- 1 root root 898822 May 31 15:43 vocab.json\n"]}],"execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1622475893388,"user":{"displayName":"Maziyar Panahi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTmm4Srbdy-IOOALumHToD8y9PvjupF566HEz1zA=s64","userId":"06037986691777662786"},"user_tz":-120},"id":"Mcm2UpNxUUQN","outputId":"b38036da-afd1-46ce-ef43-f1ec428289ee"}},{"cell_type":"markdown","source":["- as you can see, we need the SavedModel from `saved_model/1/` path\n","- we also be needing `vocab.json` and `merges.txt` files from the tokenizer\n","- all we need is to first convert `vocab.json` to `vocab.txt` and copy both `vocab.txt` and `merges.txt` into `saved_model/1/assets` which Spark NLP will look for"],"metadata":{"id":"gZegMvuGTmHt"}},{"cell_type":"code","source":["\n","# let's make sure we sort the vocabs based on their ids first\n","vocabs = tokenizer.get_vocab()\n","vocabs = sorted(vocabs, key=vocabs.get)\n","\n","# let's save the vocab as txt file\n","with open('{}_tokenizer/vocab.txt'.format(MODEL_NAME), 'w') as f:\n","    for item in vocabs:\n","        f.write(\"%s\\n\" % item)\n","\n","# let's copy both vocab.txt and merges.txt files to saved_model/1/assets\n","!cp {MODEL_NAME}_tokenizer/vocab.txt {MODEL_NAME}/saved_model/1/assets\n","!cp {MODEL_NAME}_tokenizer/merges.txt {MODEL_NAME}/saved_model/1/assets"],"outputs":[],"execution_count":null,"metadata":{"id":"ez6MT-RTT7ss"}},{"cell_type":"markdown","source":["## Import and Save RoBERTa in Spark NLP\n"],"metadata":{"id":"NlJKd2tIU0PD"}},{"cell_type":"markdown","source":["- Let's install and setup Spark NLP in Google Colab\n","- This part is pretty easy via our simple script"],"metadata":{"id":"A0FXoxHJc5CU"}},{"cell_type":"code","source":["! wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"],"outputs":[],"execution_count":null,"metadata":{"id":"8tpW5nkMc53m"}},{"cell_type":"markdown","source":["Let's start Spark with Spark NLP included via our simple `start()` function"],"metadata":{"id":"m_NAgx4hdCGP"}},{"cell_type":"code","source":["import sparknlp\n","# let's start Spark with Spark NLP\n","spark = sparknlp.start()"],"outputs":[],"execution_count":null,"metadata":{"id":"xGXPlbLdBvbm"}},{"cell_type":"markdown","source":["- Let's use `loadSavedModel` functon in `RoBertaEmbeddings` which allows us to load TensorFlow model in SavedModel format\n","- Most params can be set later when you are loading this model in `RoBertaEmbeddings` in runtime, so don't worry what you are setting them now\n","- `loadSavedModel` accepts two params, first is the path to the TF SavedModel. The second is the SparkSession that is `spark` variable we previously started via `sparknlp.start()`\n","- `setStorageRef` is very important. When you are training a task like NER or any Text Classification, we use this reference to bound the trained model to this specific embeddings so you won't load a different embeddings by mistake and see terrible results ðŸ˜Š\n","- It's up to you what you put in `setStorageRef` but it cannot be changed later on. We usually use the name of the model to be clear, but you can get creative if you want! \n","- The `dimension` param is is purely cosmetic and won't change anything. It's mostly for you to know later via `.getDimension` what is the dimension of your model. So set this accordingly.\n","- NOTE: `loadSavedModel` only accepts local paths and not distributed file systems such as `HDFS`, `S3`, `DBFS`, etc. That is why we use `write.save` so we can use `.load()` from any file systems.\n"],"metadata":{"id":"ABTu9MrdVafM"}},{"cell_type":"code","source":["from sparknlp.annotator import *\n","\n","roberta = RoBertaEmbeddings.loadSavedModel(\n","     '{}/saved_model/1'.format(MODEL_NAME),\n","     spark\n"," )\\\n"," .setInputCols([\"sentence\",'token'])\\\n"," .setOutputCol(\"embeddings\")\\\n"," .setCaseSensitive(True)\\\n"," .setDimension(768)\\\n"," .setStorageRef('roberta_base') "],"outputs":[],"execution_count":null,"metadata":{"id":"8W_almibVRTj"}},{"cell_type":"markdown","source":["- Let's save it on disk so it is easier to be moved around and also be used later via `.load` function"],"metadata":{"id":"PjGiq4KnXWuy"}},{"cell_type":"code","source":["roberta.write().overwrite().save(\"./{}_spark_nlp\".format(MODEL_NAME))"],"outputs":[],"execution_count":null,"metadata":{"id":"iWu5HfbnXAlM"}},{"cell_type":"markdown","source":["Let's clean up stuff we don't need anymore"],"metadata":{"id":"4W2m4JuVDM3D"}},{"cell_type":"code","source":["!rm -rf {MODEL_NAME}_tokenizer {MODEL_NAME}"],"outputs":[],"execution_count":null,"metadata":{"id":"CnUXH76ADSkL"}},{"cell_type":"markdown","source":["Awesome ðŸ˜Ž  !\n","\n","This is your RoBERTa model from HuggingFace ðŸ¤— loaded and saved by Spark NLP ðŸš€ "],"metadata":{"id":"-TSeTRZpXqWO"}},{"cell_type":"code","source":["! ls -l {MODEL_NAME}_spark_nlp"],"outputs":[{"output_type":"stream","name":"stdout","text":["total 288996\n","drwxr-xr-x 5 root root      4096 May 31 16:07 fields\n","drwxr-xr-x 2 root root      4096 May 31 16:07 metadata\n","-rw-r--r-- 1 root root 295923287 May 31 16:13 roberta_tensorflow\n"]}],"execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":980,"status":"ok","timestamp":1622477591833,"user":{"displayName":"Maziyar Panahi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTmm4Srbdy-IOOALumHToD8y9PvjupF566HEz1zA=s64","userId":"06037986691777662786"},"user_tz":-120},"id":"ogpxSWxOXj3W","outputId":"8d8fc13b-427e-44f1-bfe4-2705862f8730"}},{"cell_type":"markdown","source":["Now let's see how we can use it on other machines, clusters, or any place you wish to use your new and shiny RoBERTa model ðŸ˜Š "],"metadata":{"id":"Fbehje7fYTDj"}},{"cell_type":"code","source":["roberta_loaded = RoBertaEmbeddings.load(\"./{}_spark_nlp\".format(MODEL_NAME))\\\n","  .setInputCols([\"sentence\",'token'])\\\n","  .setOutputCol(\"embeddings\")\\\n","  .setCaseSensitive(True)"],"outputs":[],"execution_count":null,"metadata":{"id":"1mm3CvkwYRgs"}},{"cell_type":"code","source":["roberta_loaded.getStorageRef()"],"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":"'roberta_base'"},"metadata":{"tags":[]}}],"execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1622477610651,"user":{"displayName":"Maziyar Panahi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTmm4Srbdy-IOOALumHToD8y9PvjupF566HEz1zA=s64","userId":"06037986691777662786"},"user_tz":-120},"id":"pGRTNISyYlnO","outputId":"fc4d45f1-d870-408a-e16e-bbf6710bf33d"}},{"cell_type":"markdown","source":["That's it! You can now go wild and use hundreds of RoBERTa models from HuggingFace ðŸ¤— in Spark NLP ðŸš€ \n"],"metadata":{"id":"_he2LDtBYo1h"}},{"cell_type":"code","source":[""],"outputs":[],"execution_count":null,"metadata":{"id":"ywzS9bwfLlI1"}}],"metadata":{"colab":{"collapsed_sections":[],"name":"HuggingFace in Spark NLP - RoBERTa.ipynb","provenance":[{"file_id":"1C6-jMjzLBMs8WkLfeqHvv1Se9LNfqYZW","timestamp":1622475523612},{"file_id":"1wPsMf2tqrA0uR_qfBT4HY_CozriMZUBF","timestamp":1622473868648}],"toc_visible":true},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"widgets":{"application/vnd.jupyter.widget-state+json":{"5ed79516254d41cf99ec61e552d52b36":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""},"model_module_version":"1.5.0"},"1f6af1f0db45462da210f0153d092036":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_module_version":"1.2.0","_model_name":"LayoutModel","grid_row":null,"_model_module":"@jupyter-widgets/base","overflow":null,"max_height":null,"display":null,"grid_auto_flow":null,"grid_template_rows":null,"align_self":null,"grid_auto_columns":null,"width":null,"grid_area":null,"align_items":null,"_view_name":"LayoutView","left":null,"height":null,"_view_module":"@jupyter-widgets/base","object_position":null,"justify_content":null,"bottom":null,"max_width":null,"border":null,"margin":null,"order":null,"grid_column":null,"grid_auto_rows":null,"padding":null,"grid_template_columns":null,"justify_items":null,"object_fit":null,"visibility":null,"_view_count":null,"flex_flow":null,"min_height":null,"top":null,"min_width":null,"flex":null,"_model_module_version":"1.2.0","grid_template_areas":null,"overflow_x":null,"right":null,"overflow_y":null,"grid_gap":null,"align_content":null},"model_module_version":"1.2.0"},"943998b3cb204d8489ae0c71081e0390":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_module_version":"1.2.0","_model_name":"LayoutModel","grid_row":null,"_model_module":"@jupyter-widgets/base","overflow":null,"max_height":null,"display":null,"grid_auto_flow":null,"grid_template_rows":null,"align_self":null,"grid_auto_columns":null,"width":null,"grid_area":null,"align_items":null,"_view_name":"LayoutView","left":null,"height":null,"_view_module":"@jupyter-widgets/base","object_position":null,"justify_content":null,"bottom":null,"max_width":null,"border":null,"margin":null,"order":null,"grid_column":null,"grid_auto_rows":null,"padding":null,"grid_template_columns":null,"justify_items":null,"object_fit":null,"visibility":null,"_view_count":null,"flex_flow":null,"min_height":null,"top":null,"min_width":null,"flex":null,"_model_module_version":"1.2.0","grid_template_areas":null,"overflow_x":null,"right":null,"overflow_y":null,"grid_gap":null,"align_content":null},"model_module_version":"1.2.0"},"154919ace6a24a9c836627d45af4832d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_module_version":"1.2.0","_model_name":"LayoutModel","grid_row":null,"_model_module":"@jupyter-widgets/base","overflow":null,"max_height":null,"display":null,"grid_auto_flow":null,"grid_template_rows":null,"align_self":null,"grid_auto_columns":null,"width":null,"grid_area":null,"align_items":null,"_view_name":"LayoutView","left":null,"height":null,"_view_module":"@jupyter-widgets/base","object_position":null,"justify_content":null,"bottom":null,"max_width":null,"border":null,"margin":null,"order":null,"grid_column":null,"grid_auto_rows":null,"padding":null,"grid_template_columns":null,"justify_items":null,"object_fit":null,"visibility":null,"_view_count":null,"flex_flow":null,"min_height":null,"top":null,"min_width":null,"flex":null,"_model_module_version":"1.2.0","grid_template_areas":null,"overflow_x":null,"right":null,"overflow_y":null,"grid_gap":null,"align_content":null},"model_module_version":"1.2.0"},"a0b574ea85694a09a617848c2d98ed77":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_module_version":"1.5.0","_model_name":"HBoxModel","_model_module":"@jupyter-widgets/controls","_view_name":"HBoxView","_view_module":"@jupyter-widgets/controls","_dom_classes":[],"layout":"IPY_MODEL_91dc248081da4e12babe1ac606cc80b1","_view_count":null,"_model_module_version":"1.5.0","box_style":"","children":["IPY_MODEL_cd4c3c270a0e42b4bae48a161099483d","IPY_MODEL_220c79e165df4ea59ae5c61abab6493b"]},"model_module_version":"1.5.0"},"af56cc3ec8044118904cd7e5043e246d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_module_version":"1.5.0","_model_name":"HBoxModel","_model_module":"@jupyter-widgets/controls","_view_name":"HBoxView","_view_module":"@jupyter-widgets/controls","_dom_classes":[],"layout":"IPY_MODEL_73a77396295d481584ba3ff2a5746891","_view_count":null,"_model_module_version":"1.5.0","box_style":"","children":["IPY_MODEL_52d34ecaf34e4db6b879a076a8a0c918","IPY_MODEL_39e24155d4de40cfb9ba3c3d678d9b3b"]},"model_module_version":"1.5.0"},"35e5ee38bc1c437b8df70d2eae183389":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_module_version":"1.5.0","_model_name":"HBoxModel","_model_module":"@jupyter-widgets/controls","_view_name":"HBoxView","_view_module":"@jupyter-widgets/controls","_dom_classes":[],"layout":"IPY_MODEL_788e3ef4ec61409caf40cc45e23f2f1f","_view_count":null,"_model_module_version":"1.5.0","box_style":"","children":["IPY_MODEL_a7b6bc5963af4756ad490e86305f5e24","IPY_MODEL_524d70accce44a1296b2bf8cd9044ebf"]},"model_module_version":"1.5.0"},"4ba64be214f04a4cbb9817725389e99d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_module_version":"1.2.0","_model_name":"LayoutModel","grid_row":null,"_model_module":"@jupyter-widgets/base","overflow":null,"max_height":null,"display":null,"grid_auto_flow":null,"grid_template_rows":null,"align_self":null,"grid_auto_columns":null,"width":null,"grid_area":null,"align_items":null,"_view_name":"LayoutView","left":null,"height":null,"_view_module":"@jupyter-widgets/base","object_position":null,"justify_content":null,"bottom":null,"max_width":null,"border":null,"margin":null,"order":null,"grid_column":null,"grid_auto_rows":null,"padding":null,"grid_template_columns":null,"justify_items":null,"object_fit":null,"visibility":null,"_view_count":null,"flex_flow":null,"min_height":null,"top":null,"min_width":null,"flex":null,"_model_module_version":"1.2.0","grid_template_areas":null,"overflow_x":null,"right":null,"overflow_y":null,"grid_gap":null,"align_content":null},"model_module_version":"1.2.0"},"649ffc91bd8d4c85b3d6eb82f065b094":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_module_version":"1.2.0","_model_name":"LayoutModel","grid_row":null,"_model_module":"@jupyter-widgets/base","overflow":null,"max_height":null,"display":null,"grid_auto_flow":null,"grid_template_rows":null,"align_self":null,"grid_auto_columns":null,"width":null,"grid_area":null,"align_items":null,"_view_name":"LayoutView","left":null,"height":null,"_view_module":"@jupyter-widgets/base","object_position":null,"justify_content":null,"bottom":null,"max_width":null,"border":null,"margin":null,"order":null,"grid_column":null,"grid_auto_rows":null,"padding":null,"grid_template_columns":null,"justify_items":null,"object_fit":null,"visibility":null,"_view_count":null,"flex_flow":null,"min_height":null,"top":null,"min_width":null,"flex":null,"_model_module_version":"1.2.0","grid_template_areas":null,"overflow_x":null,"right":null,"overflow_y":null,"grid_gap":null,"align_content":null},"model_module_version":"1.2.0"},"e3866d1d10c74297abd8fe945bfa574e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""},"model_module_version":"1.5.0"},"52d34ecaf34e4db6b879a076a8a0c918":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_module_version":"1.5.0","description_tooltip":null,"_model_name":"FloatProgressModel","_model_module":"@jupyter-widgets/controls","max":481,"bar_style":"success","_view_name":"ProgressView","_view_module":"@jupyter-widgets/controls","_dom_classes":[],"layout":"IPY_MODEL_6ed0c9b9a15e4c9196e53deaa6527c26","orientation":"horizontal","value":481,"style":"IPY_MODEL_9d5d2c73362543ea8f75959a36dbef31","min":0,"_view_count":null,"_model_module_version":"1.5.0","description":"Downloading: 100%"},"model_module_version":"1.5.0"},"e81d493c5510490da6655865f859d82f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_module_version":"1.2.0","_model_name":"ProgressStyleModel","_model_module":"@jupyter-widgets/controls","description_width":"initial","_view_name":"StyleView","_view_module":"@jupyter-widgets/base","_view_count":null,"bar_color":null,"_model_module_version":"1.5.0"},"model_module_version":"1.5.0"},"739d8fb0cc4a4c80bc00dd3402ea2c43":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_module_version":"1.2.0","_model_name":"ProgressStyleModel","_model_module":"@jupyter-widgets/controls","description_width":"initial","_view_name":"StyleView","_view_module":"@jupyter-widgets/base","_view_count":null,"bar_color":null,"_model_module_version":"1.5.0"},"model_module_version":"1.5.0"},"97e54be966dc4aeebadf2d77161296a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_module_version":"1.2.0","_model_name":"LayoutModel","grid_row":null,"_model_module":"@jupyter-widgets/base","overflow":null,"max_height":null,"display":null,"grid_auto_flow":null,"grid_template_rows":null,"align_self":null,"grid_auto_columns":null,"width":null,"grid_area":null,"align_items":null,"_view_name":"LayoutView","left":null,"height":null,"_view_module":"@jupyter-widgets/base","object_position":null,"justify_content":null,"bottom":null,"max_width":null,"border":null,"margin":null,"order":null,"grid_column":null,"grid_auto_rows":null,"padding":null,"grid_template_columns":null,"justify_items":null,"object_fit":null,"visibility":null,"_view_count":null,"flex_flow":null,"min_height":null,"top":null,"min_width":null,"flex":null,"_model_module_version":"1.2.0","grid_template_areas":null,"overflow_x":null,"right":null,"overflow_y":null,"grid_gap":null,"align_content":null},"model_module_version":"1.2.0"},"220c79e165df4ea59ae5c61abab6493b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_module_version":"1.5.0","description_tooltip":null,"_model_name":"HTMLModel","_model_module":"@jupyter-widgets/controls","_view_name":"HTMLView","_view_module":"@jupyter-widgets/controls","_dom_classes":[],"layout":"IPY_MODEL_44387ff2654445c1b304e9ad0ebdda2b","value":" 1.36M/1.36M [00:00&lt;00:00, 1.75MB/s]","style":"IPY_MODEL_5ed79516254d41cf99ec61e552d52b36","placeholder":"â€‹","_view_count":null,"_model_module_version":"1.5.0","description":""},"model_module_version":"1.5.0"},"2c57da9a378042ebaa510f6d58eef27c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_module_version":"1.2.0","_model_name":"LayoutModel","grid_row":null,"_model_module":"@jupyter-widgets/base","overflow":null,"max_height":null,"display":null,"grid_auto_flow":null,"grid_template_rows":null,"align_self":null,"grid_auto_columns":null,"width":null,"grid_area":null,"align_items":null,"_view_name":"LayoutView","left":null,"height":null,"_view_module":"@jupyter-widgets/base","object_position":null,"justify_content":null,"bottom":null,"max_width":null,"border":null,"margin":null,"order":null,"grid_column":null,"grid_auto_rows":null,"padding":null,"grid_template_columns":null,"justify_items":null,"object_fit":null,"visibility":null,"_view_count":null,"flex_flow":null,"min_height":null,"top":null,"min_width":null,"flex":null,"_model_module_version":"1.2.0","grid_template_areas":null,"overflow_x":null,"right":null,"overflow_y":null,"grid_gap":null,"align_content":null},"model_module_version":"1.2.0"},"6ed0c9b9a15e4c9196e53deaa6527c26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_module_version":"1.2.0","_model_name":"LayoutModel","grid_row":null,"_model_module":"@jupyter-widgets/base","overflow":null,"max_height":null,"display":null,"grid_auto_flow":null,"grid_template_rows":null,"align_self":null,"grid_auto_columns":null,"width":null,"grid_area":null,"align_items":null,"_view_name":"LayoutView","left":null,"height":null,"_view_module":"@jupyter-widgets/base","object_position":null,"justify_content":null,"bottom":null,"max_width":null,"border":null,"margin":null,"order":null,"grid_column":null,"grid_auto_rows":null,"padding":null,"grid_template_columns":null,"justify_items":null,"object_fit":null,"visibility":null,"_view_count":null,"flex_flow":null,"min_height":null,"top":null,"min_width":null,"flex":null,"_model_module_version":"1.2.0","grid_template_areas":null,"overflow_x":null,"right":null,"overflow_y":null,"grid_gap":null,"align_content":null},"model_module_version":"1.2.0"},"a646ecf1a46b4d92a03c417fa44bd517":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_module_version":"1.2.0","_model_name":"LayoutModel","grid_row":null,"_model_module":"@jupyter-widgets/base","overflow":null,"max_height":null,"display":null,"grid_auto_flow":null,"grid_template_rows":null,"align_self":null,"grid_auto_columns":null,"width":null,"grid_area":null,"align_items":null,"_view_name":"LayoutView","left":null,"height":null,"_view_module":"@jupyter-widgets/base","object_position":null,"justify_content":null,"bottom":null,"max_width":null,"border":null,"margin":null,"order":null,"grid_column":null,"grid_auto_rows":null,"padding":null,"grid_template_columns":null,"justify_items":null,"object_fit":null,"visibility":null,"_view_count":null,"flex_flow":null,"min_height":null,"top":null,"min_width":null,"flex":null,"_model_module_version":"1.2.0","grid_template_areas":null,"overflow_x":null,"right":null,"overflow_y":null,"grid_gap":null,"align_content":null},"model_module_version":"1.2.0"},"91dc248081da4e12babe1ac606cc80b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_module_version":"1.2.0","_model_name":"LayoutModel","grid_row":null,"_model_module":"@jupyter-widgets/base","overflow":null,"max_height":null,"display":null,"grid_auto_flow":null,"grid_template_rows":null,"align_self":null,"grid_auto_columns":null,"width":null,"grid_area":null,"align_items":null,"_view_name":"LayoutView","left":null,"height":null,"_view_module":"@jupyter-widgets/base","object_position":null,"justify_content":null,"bottom":null,"max_width":null,"border":null,"margin":null,"order":null,"grid_column":null,"grid_auto_rows":null,"padding":null,"grid_template_columns":null,"justify_items":null,"object_fit":null,"visibility":null,"_view_count":null,"flex_flow":null,"min_height":null,"top":null,"min_width":null,"flex":null,"_model_module_version":"1.2.0","grid_template_areas":null,"overflow_x":null,"right":null,"overflow_y":null,"grid_gap":null,"align_content":null},"model_module_version":"1.2.0"},"cd4c3c270a0e42b4bae48a161099483d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_module_version":"1.5.0","description_tooltip":null,"_model_name":"FloatProgressModel","_model_module":"@jupyter-widgets/controls","max":1355863,"bar_style":"success","_view_name":"ProgressView","_view_module":"@jupyter-widgets/controls","_dom_classes":[],"layout":"IPY_MODEL_2c57da9a378042ebaa510f6d58eef27c","orientation":"horizontal","value":1355863,"style":"IPY_MODEL_dd386f5a79b848458aab9b34179e9351","min":0,"_view_count":null,"_model_module_version":"1.5.0","description":"Downloading: 100%"},"model_module_version":"1.5.0"},"bba854c507044daf8136a9b3368317fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_module_version":"1.2.0","_model_name":"LayoutModel","grid_row":null,"_model_module":"@jupyter-widgets/base","overflow":null,"max_height":null,"display":null,"grid_auto_flow":null,"grid_template_rows":null,"align_self":null,"grid_auto_columns":null,"width":null,"grid_area":null,"align_items":null,"_view_name":"LayoutView","left":null,"height":null,"_view_module":"@jupyter-widgets/base","object_position":null,"justify_content":null,"bottom":null,"max_width":null,"border":null,"margin":null,"order":null,"grid_column":null,"grid_auto_rows":null,"padding":null,"grid_template_columns":null,"justify_items":null,"object_fit":null,"visibility":null,"_view_count":null,"flex_flow":null,"min_height":null,"top":null,"min_width":null,"flex":null,"_model_module_version":"1.2.0","grid_template_areas":null,"overflow_x":null,"right":null,"overflow_y":null,"grid_gap":null,"align_content":null},"model_module_version":"1.2.0"},"0e1999f605a44ec089d3d27a5e6d1874":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_module_version":"1.2.0","_model_name":"LayoutModel","grid_row":null,"_model_module":"@jupyter-widgets/base","overflow":null,"max_height":null,"display":null,"grid_auto_flow":null,"grid_template_rows":null,"align_self":null,"grid_auto_columns":null,"width":null,"grid_area":null,"align_items":null,"_view_name":"LayoutView","left":null,"height":null,"_view_module":"@jupyter-widgets/base","object_position":null,"justify_content":null,"bottom":null,"max_width":null,"border":null,"margin":null,"order":null,"grid_column":null,"grid_auto_rows":null,"padding":null,"grid_template_columns":null,"justify_items":null,"object_fit":null,"visibility":null,"_view_count":null,"flex_flow":null,"min_height":null,"top":null,"min_width":null,"flex":null,"_model_module_version":"1.2.0","grid_template_areas":null,"overflow_x":null,"right":null,"overflow_y":null,"grid_gap":null,"align_content":null},"model_module_version":"1.2.0"},"990b1223d2ca4d15b2b528039646a450":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""},"model_module_version":"1.5.0"},"73a77396295d481584ba3ff2a5746891":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_module_version":"1.2.0","_model_name":"LayoutModel","grid_row":null,"_model_module":"@jupyter-widgets/base","overflow":null,"max_height":null,"display":null,"grid_auto_flow":null,"grid_template_rows":null,"align_self":null,"grid_auto_columns":null,"width":null,"grid_area":null,"align_items":null,"_view_name":"LayoutView","left":null,"height":null,"_view_module":"@jupyter-widgets/base","object_position":null,"justify_content":null,"bottom":null,"max_width":null,"border":null,"margin":null,"order":null,"grid_column":null,"grid_auto_rows":null,"padding":null,"grid_template_columns":null,"justify_items":null,"object_fit":null,"visibility":null,"_view_count":null,"flex_flow":null,"min_height":null,"top":null,"min_width":null,"flex":null,"_model_module_version":"1.2.0","grid_template_areas":null,"overflow_x":null,"right":null,"overflow_y":null,"grid_gap":null,"align_content":null},"model_module_version":"1.2.0"},"524d70accce44a1296b2bf8cd9044ebf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_module_version":"1.5.0","description_tooltip":null,"_model_name":"HTMLModel","_model_module":"@jupyter-widgets/controls","_view_name":"HTMLView","_view_module":"@jupyter-widgets/controls","_dom_classes":[],"layout":"IPY_MODEL_0e1999f605a44ec089d3d27a5e6d1874","value":" 899k/899k [00:06&lt;00:00, 133kB/s]","style":"IPY_MODEL_e3866d1d10c74297abd8fe945bfa574e","placeholder":"â€‹","_view_count":null,"_model_module_version":"1.5.0","description":""},"model_module_version":"1.5.0"},"4c2a3270ee274517b12c173e548dc141":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_module_version":"1.5.0","description_tooltip":null,"_model_name":"FloatProgressModel","_model_module":"@jupyter-widgets/controls","max":657434796,"bar_style":"success","_view_name":"ProgressView","_view_module":"@jupyter-widgets/controls","_dom_classes":[],"layout":"IPY_MODEL_4ba64be214f04a4cbb9817725389e99d","orientation":"horizontal","value":657434796,"style":"IPY_MODEL_739d8fb0cc4a4c80bc00dd3402ea2c43","min":0,"_view_count":null,"_model_module_version":"1.5.0","description":"Downloading: 100%"},"model_module_version":"1.5.0"},"5bdca68c26394bc8857c14ca792c8e7d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_module_version":"1.5.0","description_tooltip":null,"_model_name":"FloatProgressModel","_model_module":"@jupyter-widgets/controls","max":456318,"bar_style":"success","_view_name":"ProgressView","_view_module":"@jupyter-widgets/controls","_dom_classes":[],"layout":"IPY_MODEL_bba854c507044daf8136a9b3368317fa","orientation":"horizontal","value":456318,"style":"IPY_MODEL_e81d493c5510490da6655865f859d82f","min":0,"_view_count":null,"_model_module_version":"1.5.0","description":"Downloading: 100%"},"model_module_version":"1.5.0"},"a7b6bc5963af4756ad490e86305f5e24":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_module_version":"1.5.0","description_tooltip":null,"_model_name":"FloatProgressModel","_model_module":"@jupyter-widgets/controls","max":898823,"bar_style":"success","_view_name":"ProgressView","_view_module":"@jupyter-widgets/controls","_dom_classes":[],"layout":"IPY_MODEL_943998b3cb204d8489ae0c71081e0390","orientation":"horizontal","value":898823,"style":"IPY_MODEL_0ab09f97b5114624b03cda86be5814a8","min":0,"_view_count":null,"_model_module_version":"1.5.0","description":"Downloading: 100%"},"model_module_version":"1.5.0"},"be5a115938c04631a834020b4426fd11":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_module_version":"1.5.0","description_tooltip":null,"_model_name":"HTMLModel","_model_module":"@jupyter-widgets/controls","_view_name":"HTMLView","_view_module":"@jupyter-widgets/controls","_dom_classes":[],"layout":"IPY_MODEL_a646ecf1a46b4d92a03c417fa44bd517","value":" 456k/456k [00:04&lt;00:00, 95.9kB/s]","style":"IPY_MODEL_9240418ef66b42f4b0e4a4b78520bc9f","placeholder":"â€‹","_view_count":null,"_model_module_version":"1.5.0","description":""},"model_module_version":"1.5.0"},"9240418ef66b42f4b0e4a4b78520bc9f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""},"model_module_version":"1.5.0"},"788e3ef4ec61409caf40cc45e23f2f1f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_module_version":"1.2.0","_model_name":"LayoutModel","grid_row":null,"_model_module":"@jupyter-widgets/base","overflow":null,"max_height":null,"display":null,"grid_auto_flow":null,"grid_template_rows":null,"align_self":null,"grid_auto_columns":null,"width":null,"grid_area":null,"align_items":null,"_view_name":"LayoutView","left":null,"height":null,"_view_module":"@jupyter-widgets/base","object_position":null,"justify_content":null,"bottom":null,"max_width":null,"border":null,"margin":null,"order":null,"grid_column":null,"grid_auto_rows":null,"padding":null,"grid_template_columns":null,"justify_items":null,"object_fit":null,"visibility":null,"_view_count":null,"flex_flow":null,"min_height":null,"top":null,"min_width":null,"flex":null,"_model_module_version":"1.2.0","grid_template_areas":null,"overflow_x":null,"right":null,"overflow_y":null,"grid_gap":null,"align_content":null},"model_module_version":"1.2.0"},"9d5d2c73362543ea8f75959a36dbef31":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_module_version":"1.2.0","_model_name":"ProgressStyleModel","_model_module":"@jupyter-widgets/controls","description_width":"initial","_view_name":"StyleView","_view_module":"@jupyter-widgets/base","_view_count":null,"bar_color":null,"_model_module_version":"1.5.0"},"model_module_version":"1.5.0"},"dd386f5a79b848458aab9b34179e9351":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_module_version":"1.2.0","_model_name":"ProgressStyleModel","_model_module":"@jupyter-widgets/controls","description_width":"initial","_view_name":"StyleView","_view_module":"@jupyter-widgets/base","_view_count":null,"bar_color":null,"_model_module_version":"1.5.0"},"model_module_version":"1.5.0"},"0ab09f97b5114624b03cda86be5814a8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_module_version":"1.2.0","_model_name":"ProgressStyleModel","_model_module":"@jupyter-widgets/controls","description_width":"initial","_view_name":"StyleView","_view_module":"@jupyter-widgets/base","_view_count":null,"bar_color":null,"_model_module_version":"1.5.0"},"model_module_version":"1.5.0"},"d530a358eb484cbd90d36842abf80728":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""},"model_module_version":"1.5.0"},"39e24155d4de40cfb9ba3c3d678d9b3b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_module_version":"1.5.0","description_tooltip":null,"_model_name":"HTMLModel","_model_module":"@jupyter-widgets/controls","_view_name":"HTMLView","_view_module":"@jupyter-widgets/controls","_dom_classes":[],"layout":"IPY_MODEL_649ffc91bd8d4c85b3d6eb82f065b094","value":" 481/481 [00:00&lt;00:00, 551B/s]","style":"IPY_MODEL_d530a358eb484cbd90d36842abf80728","placeholder":"â€‹","_view_count":null,"_model_module_version":"1.5.0","description":""},"model_module_version":"1.5.0"},"ef61a20839a84bb29f4877120eda6b95":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_module_version":"1.5.0","_model_name":"HBoxModel","_model_module":"@jupyter-widgets/controls","_view_name":"HBoxView","_view_module":"@jupyter-widgets/controls","_dom_classes":[],"layout":"IPY_MODEL_1f6af1f0db45462da210f0153d092036","_view_count":null,"_model_module_version":"1.5.0","box_style":"","children":["IPY_MODEL_4c2a3270ee274517b12c173e548dc141","IPY_MODEL_71e93f1ef31344998fd0e3382dd71956"]},"model_module_version":"1.5.0"},"39c01f1f92ce4ecb89e7bafba714ecb3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_module_version":"1.5.0","_model_name":"HBoxModel","_model_module":"@jupyter-widgets/controls","_view_name":"HBoxView","_view_module":"@jupyter-widgets/controls","_dom_classes":[],"layout":"IPY_MODEL_97e54be966dc4aeebadf2d77161296a8","_view_count":null,"_model_module_version":"1.5.0","box_style":"","children":["IPY_MODEL_5bdca68c26394bc8857c14ca792c8e7d","IPY_MODEL_be5a115938c04631a834020b4426fd11"]},"model_module_version":"1.5.0"},"44387ff2654445c1b304e9ad0ebdda2b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_module_version":"1.2.0","_model_name":"LayoutModel","grid_row":null,"_model_module":"@jupyter-widgets/base","overflow":null,"max_height":null,"display":null,"grid_auto_flow":null,"grid_template_rows":null,"align_self":null,"grid_auto_columns":null,"width":null,"grid_area":null,"align_items":null,"_view_name":"LayoutView","left":null,"height":null,"_view_module":"@jupyter-widgets/base","object_position":null,"justify_content":null,"bottom":null,"max_width":null,"border":null,"margin":null,"order":null,"grid_column":null,"grid_auto_rows":null,"padding":null,"grid_template_columns":null,"justify_items":null,"object_fit":null,"visibility":null,"_view_count":null,"flex_flow":null,"min_height":null,"top":null,"min_width":null,"flex":null,"_model_module_version":"1.2.0","grid_template_areas":null,"overflow_x":null,"right":null,"overflow_y":null,"grid_gap":null,"align_content":null},"model_module_version":"1.2.0"},"71e93f1ef31344998fd0e3382dd71956":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_module_version":"1.5.0","description_tooltip":null,"_model_name":"HTMLModel","_model_module":"@jupyter-widgets/controls","_view_name":"HTMLView","_view_module":"@jupyter-widgets/controls","_dom_classes":[],"layout":"IPY_MODEL_154919ace6a24a9c836627d45af4832d","value":" 657M/657M [00:21&lt;00:00, 31.0MB/s]","style":"IPY_MODEL_990b1223d2ca4d15b2b528039646a450","placeholder":"â€‹","_view_count":null,"_model_module_version":"1.5.0","description":""},"model_module_version":"1.5.0"}}},"nteract":{"version":"0.28.0"}},"nbformat":4,"nbformat_minor":0}