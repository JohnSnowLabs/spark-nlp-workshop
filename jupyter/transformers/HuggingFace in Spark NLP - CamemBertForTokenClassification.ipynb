{"cells":[{"cell_type":"markdown","metadata":{"id":"2vXYNX2lQROB"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/transformers/HuggingFace%20in%20Spark%20NLP%20-%20CamemBertForTokenClassification.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"Zva6MvJyLeWi"},"source":["## Import CamemBertForTokenClassification models from HuggingFace ðŸ¤—  into Spark NLP ðŸš€ \n","\n","Let's keep in mind a few things before we start ðŸ˜Š \n","\n","- This feature is only in `Spark NLP 4.2.0` and after. So please make sure you have upgraded to the latest Spark NLP release\n","- You can import CamemBERT models trained/fine-tuned for token classification via `CamembertForTokenClassification` or `TFCamembertForTokenClassification`. These models are usually under `Token Classification` category and have `camembert` in their labels\n","- Reference: [TFCamembertForTokenClassification](https://huggingface.co/docs/transformers/model_doc/camembert#transformers.TFCamembertForTokenClassification)\n","- Some [example models](https://huggingface.co/models?other=camembert&pipeline_tag=token-classification)"]},{"cell_type":"markdown","metadata":{"id":"MzxB-Nq6cxOA"},"source":["## Export and Save HuggingFace model"]},{"cell_type":"markdown","metadata":{"id":"yNQkhyMHMgkE"},"source":["- Let's install `HuggingFace` and `TensorFlow`. You don't need `TensorFlow` to be installed for Spark NLP, however, we need it to load and save models from HuggingFace.\n","- We lock TensorFlow on `2.7.1` version and Transformers on `4.21.2`. This doesn't mean it won't work with the future releases, but we wanted you to know which versions have been tested successfully.\n","- CamembertTokenizer requires the `SentencePiece` library, so we install that as well"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":95771,"status":"ok","timestamp":1640707909485,"user":{"displayName":"Maziyar Panahi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTmm4Srbdy-IOOALumHToD8y9PvjupF566HEz1zA=s64","userId":"06037986691777662786"},"user_tz":-60},"id":"hHXgqiWpMfCY","outputId":"3134cc48-78bc-4e03-a79f-748292f7d0a1"},"outputs":[],"source":["!pip install -q transformers==4.21.2 tensorflow==2.7.1 sentencepiece"]},{"cell_type":"markdown","metadata":{"id":"Y3AM6bj4P3NS"},"source":["- HuggingFace comes with a native `saved_model` feature inside `save_pretrained` function for TensorFlow based models. We will use that to save it as TF `SavedModel`.\n","- We'll use [Jean-Baptiste/camembert-ner](https://huggingface.co/Jean-Baptiste/camembert-ner) model from HuggingFace as an example\n","- In addition to `TFCamembertForTokenClassification` we also need to save the `CamembertTokenizer`. This is the same for every model, these are assets needed for tokenization inside Spark NLP."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":352,"status":"ok","timestamp":1640708841457,"user":{"displayName":"Maziyar Panahi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTmm4Srbdy-IOOALumHToD8y9PvjupF566HEz1zA=s64","userId":"06037986691777662786"},"user_tz":-60},"id":"ZaiirlSKNhVD"},"outputs":[],"source":["from transformers import TFCamembertForTokenClassification, CamembertTokenizer \n","\n","MODEL_NAME = 'Jean-Baptiste/camembert-ner'\n","\n","tokenizer = CamembertTokenizer.from_pretrained(MODEL_NAME)\n","tokenizer.save_pretrained('./{}_tokenizer/'.format(MODEL_NAME))\n","\n","# just in case if there is no TF/Keras file provided in the model\n","# we can just use `from_pt` and convert PyTorch to TensorFlow\n","try:\n","  print('try downloading TF weights')\n","  model = TFCamembertForTokenClassification.from_pretrained(MODEL_NAME)\n","except:\n","  print('try downloading PyTorch weights')\n","  model = TFCamembertForTokenClassification.from_pretrained(MODEL_NAME, from_pt=True)\n","\n","model.save_pretrained(\"./{}\".format(MODEL_NAME), saved_model=True)"]},{"cell_type":"markdown","metadata":{"id":"nlgyZuJfS5IB"},"source":["Let's have a look inside these two directories and see what we are dealing with:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":494,"status":"ok","timestamp":1640708154100,"user":{"displayName":"Maziyar Panahi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTmm4Srbdy-IOOALumHToD8y9PvjupF566HEz1zA=s64","userId":"06037986691777662786"},"user_tz":-60},"id":"p2XCole7TTef","outputId":"7bd16979-4e59-4f6e-d685-4b0f882b5bcc"},"outputs":[],"source":["!ls -l {MODEL_NAME}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":511,"status":"ok","timestamp":1640708154608,"user":{"displayName":"Maziyar Panahi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTmm4Srbdy-IOOALumHToD8y9PvjupF566HEz1zA=s64","userId":"06037986691777662786"},"user_tz":-60},"id":"r0DOGz8VUR-r","outputId":"49b86052-ec5c-4a97-959d-c2aa5c3b8df5"},"outputs":[],"source":["!ls -l {MODEL_NAME}/saved_model/1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1640708154609,"user":{"displayName":"Maziyar Panahi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTmm4Srbdy-IOOALumHToD8y9PvjupF566HEz1zA=s64","userId":"06037986691777662786"},"user_tz":-60},"id":"Mcm2UpNxUUQN","outputId":"5068af51-5a09-4a60-866b-96b4f4bdd083"},"outputs":[],"source":["!ls -l {MODEL_NAME}_tokenizer"]},{"cell_type":"markdown","metadata":{"id":"gZegMvuGTmHt"},"source":["- as you can see, we need the SavedModel from `saved_model/1/` path\n","- we also be needing `sentencepiece.bpe.model` file from the tokenizer\n","- all we need is to copy `sentencepiece.bpe.model` file into `saved_model/1/assets` which Spark NLP will look for\n","- in addition to vocabs, we also need `labels` and their `ids` which is saved inside the model's config. We will save this inside `labels.txt`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ez6MT-RTT7ss"},"outputs":[],"source":["asset_path = '{}/saved_model/1/assets'.format(MODEL_NAME)\n","\n","# let's copy sentencepiece.bpe.model file to saved_model/1/assets\n","!cp {MODEL_NAME}_tokenizer/sentencepiece.bpe.model {asset_path}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vcg_5YP1-vfC"},"outputs":[],"source":["# get label2id dictionary \n","labels = model.config.label2id\n","# sort the dictionary based on the id\n","labels = sorted(labels, key=labels.get)\n","\n","with open(asset_path+'/labels.txt', 'w') as f:\n","    f.write('\\n'.join(labels))"]},{"cell_type":"markdown","metadata":{"id":"mBq7ztzlACYO"},"source":["Voila! We have our `vocab.txt` and `labels.txt` inside assets directory"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":228,"status":"ok","timestamp":1640708155273,"user":{"displayName":"Maziyar Panahi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTmm4Srbdy-IOOALumHToD8y9PvjupF566HEz1zA=s64","userId":"06037986691777662786"},"user_tz":-60},"id":"OYnT5U8N9dxT","outputId":"89764651-6a64-4b11-aaaa-f031a4284e1a"},"outputs":[],"source":["! ls -l {asset_path}"]},{"cell_type":"markdown","metadata":{"id":"NlJKd2tIU0PD"},"source":["## Import and Save CamemBertForTokenClassification in Spark NLP\n"]},{"cell_type":"markdown","metadata":{"id":"A0FXoxHJc5CU"},"source":["- Let's install and setup Spark NLP in Google Colab\n","- This part is pretty easy via our simple script"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7553,"status":"ok","timestamp":1640708780913,"user":{"displayName":"Maziyar Panahi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTmm4Srbdy-IOOALumHToD8y9PvjupF566HEz1zA=s64","userId":"06037986691777662786"},"user_tz":-60},"id":"8tpW5nkMc53m","outputId":"2677b2fd-477a-4530-c98b-a8a1ccbd2baa"},"outputs":[],"source":["! wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"]},{"cell_type":"markdown","metadata":{"id":"m_NAgx4hdCGP"},"source":["Let's start Spark with Spark NLP included via our simple `start()` function"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":33750,"status":"ok","timestamp":1640708814657,"user":{"displayName":"Maziyar Panahi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTmm4Srbdy-IOOALumHToD8y9PvjupF566HEz1zA=s64","userId":"06037986691777662786"},"user_tz":-60},"id":"cbNneAVCLU1y"},"outputs":[],"source":["import sparknlp\n","# let's start Spark with Spark NLP\n","spark = sparknlp.start()"]},{"cell_type":"markdown","metadata":{"id":"ABTu9MrdVafM"},"source":["- Let's use `loadSavedModel` functon in `CamemBertForTokenClassification` which allows us to load TensorFlow model in SavedModel format\n","- Most params can be set later when you are loading this model in `CamemBertForTokenClassification` in runtime like `setMaxSentenceLength`, so don't worry what you are setting them now\n","- `loadSavedModel` accepts two params, first is the path to the TF SavedModel. The second is the SparkSession that is `spark` variable we previously started via `sparknlp.start()`\n","- NOTE: `loadSavedModel` accepts local paths in addition to distributed file systems such as `HDFS`, `S3`, `DBFS`, etc. This feature was introduced in Spark NLP 4.2.2 release. Keep in mind the best and recommended way to move/share/reuse Spark NLP models is to use `write.save` so you can use `.load()` from any file systems natively.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1640708858933,"user":{"displayName":"Maziyar Panahi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTmm4Srbdy-IOOALumHToD8y9PvjupF566HEz1zA=s64","userId":"06037986691777662786"},"user_tz":-60},"id":"8W_almibVRTj"},"outputs":[],"source":["from sparknlp.annotator import *\n","from sparknlp.base import *\n","\n","tokenClassifier = CamemBertForTokenClassification\\\n","  .loadSavedModel('{}/saved_model/1'.format(MODEL_NAME), spark)\\\n","  .setInputCols([\"document\",'token'])\\\n","  .setOutputCol(\"ner\")\\\n","  .setCaseSensitive(True)\\\n","  .setMaxSentenceLength(128)"]},{"cell_type":"markdown","metadata":{"id":"PjGiq4KnXWuy"},"source":["- Let's save it on disk so it is easier to be moved around and also be used later via `.load` function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iWu5HfbnXAlM"},"outputs":[],"source":["tokenClassifier.write().overwrite().save(\"./{}_spark_nlp\".format(MODEL_NAME))"]},{"cell_type":"markdown","metadata":{"id":"QCrjxPhzDplN"},"source":["Let's clean up stuff we don't need anymore"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZgkVIJshDtLx"},"outputs":[],"source":["! rm -rf {MODEL_NAME}_tokenizer {MODEL_NAME}"]},{"cell_type":"markdown","metadata":{"id":"-TSeTRZpXqWO"},"source":["Awesome ðŸ˜Ž  !\n","\n","This is your CamemBertForTokenClassification model from HuggingFace ðŸ¤—  loaded and saved by Spark NLP ðŸš€ "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1640708814658,"user":{"displayName":"Maziyar Panahi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTmm4Srbdy-IOOALumHToD8y9PvjupF566HEz1zA=s64","userId":"06037986691777662786"},"user_tz":-60},"id":"ogpxSWxOXj3W","outputId":"7fc4e69f-3ab2-4ddc-a3b0-6de95f018c91"},"outputs":[],"source":["! ls -l {MODEL_NAME}_spark_nlp"]},{"cell_type":"markdown","metadata":{"id":"Fbehje7fYTDj"},"source":["Now let's see how we can use it on other machines, clusters, or any place you wish to use your new and shiny CamemBertForTokenClassification model ðŸ˜Š "]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":88864,"status":"ok","timestamp":1640708950792,"user":{"displayName":"Maziyar Panahi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTmm4Srbdy-IOOALumHToD8y9PvjupF566HEz1zA=s64","userId":"06037986691777662786"},"user_tz":-60},"id":"1mm3CvkwYRgs"},"outputs":[],"source":["tokenClassifier_loaded = CamemBertForTokenClassification.load(\"./{}_spark_nlp\".format(MODEL_NAME))\\\n","  .setInputCols([\"document\",'token'])\\\n","  .setOutputCol(\"ner\")"]},{"cell_type":"markdown","metadata":{"id":"BDWNWdBlBpHi"},"source":["You can see what labels were used to train this model via `getClasses` function:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pGRTNISyYlnO"},"outputs":[],"source":["# .getClasses was introduced in spark-nlp==3.4.0\n","tokenClassifier_loaded.getClasses()"]},{"cell_type":"markdown","metadata":{"id":"UvRBsP2SBpHi"},"source":["This is how you can use your loaded classifier model in Spark NLP ðŸš€ pipeline:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15729,"status":"ok","timestamp":1640708966516,"user":{"displayName":"Maziyar Panahi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTmm4Srbdy-IOOALumHToD8y9PvjupF566HEz1zA=s64","userId":"06037986691777662786"},"user_tz":-60},"id":"MysnSyi8BpHi","outputId":"c13a1827-770f-48a6-bba6-eda25077f8ef"},"outputs":[],"source":["document_assembler = DocumentAssembler() \\\n","    .setInputCol('text') \\\n","    .setOutputCol('document')\n","\n","tokenizer = Tokenizer() \\\n","    .setInputCols(['document']) \\\n","    .setOutputCol('token')\n","\n","pipeline = Pipeline(stages=[\n","    document_assembler, \n","    tokenizer,\n","    tokenClassifier_loaded    \n","])\n","\n","# couple of simple examples\n","example = spark.createDataFrame([[\"Je m'appelle jean-baptiste et je vis Ã  montrÃ©al\"], ['george washington est allÃ© Ã  washington']]).toDF(\"text\")\n","\n","result = pipeline.fit(example).transform(example)\n","\n","# result is a DataFrame\n","result.select(\"text\", \"ner.result\").show()"]},{"cell_type":"markdown","metadata":{"id":"_he2LDtBYo1h"},"source":["That's it! You can now go wild and use hundreds of `CamemBertForTokenClassification` models from HuggingFace ðŸ¤— in Spark NLP ðŸš€ \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yZ8UTMGx4K16"},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"HuggingFace in Spark NLP - XlmRoBertaForTokenClassification.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.8.13 ('sparknlp')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"vscode":{"interpreter":{"hash":"b892d92fcc857cff1611a1b388f1d54f8b5970543d5ec3d14e16974e3049534d"}}},"nbformat":4,"nbformat_minor":0}
