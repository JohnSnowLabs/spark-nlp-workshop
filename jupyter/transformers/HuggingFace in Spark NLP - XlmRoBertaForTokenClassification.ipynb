{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HuggingFace in Spark NLP - XlmRoBertaForTokenClassification.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"2vXYNX2lQROB"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/transformers/HuggingFace%20in%20Spark%20NLP%20-%20XlmRoBertaForTokenClassification.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"Zva6MvJyLeWi"},"source":["## Import XlmRoBertaForTokenClassification models from HuggingFace ðŸ¤—  into Spark NLP ðŸš€ \n","\n","Let's keep in mind a few things before we start ðŸ˜Š \n","\n","- This feature is only in `Spark NLP 3.3.x` and after. So please make sure you have upgraded to the latest Spark NLP release\n","- You can import XLM-RoBERTa models trained/fine-tuned for token classification via `XLMRobertaForTokenClassification` or `TFXLMRobertaForTokenClassification`. These models are usually under `Token Classification` category and have `xlm-roberta` in their labels\n","- Reference: [TFXLMRobertaForTokenClassification](https://huggingface.co/transformers/model_doc/xlmroberta.html#tfxlmrobertafortokenclassification)\n","- Some [example models](https://huggingface.co/models?filter=xlm-roberta&pipeline_tag=token-classification)"]},{"cell_type":"markdown","metadata":{"id":"MzxB-Nq6cxOA"},"source":["## Export and Save HuggingFace model"]},{"cell_type":"markdown","metadata":{"id":"yNQkhyMHMgkE"},"source":["- Let's install `HuggingFace` and `TensorFlow`. You don't need `TensorFlow` to be installed for Spark NLP, however, we need it to load and save models from HuggingFace.\n","- We lock TensorFlow on `2.4.4` version and Transformers on `4.15.0`. This doesn't mean it won't work with the future releases, but we wanted you to know which versions have been tested successfully.\n","- XLMRobertaTokenizer requires the `SentencePiece` library, so we install that as well"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hHXgqiWpMfCY","executionInfo":{"status":"ok","timestamp":1640707909485,"user_tz":-60,"elapsed":95771,"user":{"displayName":"Maziyar Panahi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTmm4Srbdy-IOOALumHToD8y9PvjupF566HEz1zA=s64","userId":"06037986691777662786"}},"outputId":"3134cc48-78bc-4e03-a79f-748292f7d0a1"},"source":["!pip install -q transformers==4.15.0 tensorflow==2.4.4 sentencepiece"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.4 MB 5.1 MB/s \n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 394.5 MB 33 kB/s \n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.2 MB 62.5 MB/s \n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61 kB 347 kB/s \n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895 kB 61.6 MB/s \n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.3 MB 41.7 MB/s \n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 596 kB 48.6 MB/s \n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.8 MB 47.5 MB/s \n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.9 MB 37.3 MB/s \n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 462 kB 46.9 MB/s \n","\u001b[?25h  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"markdown","metadata":{"id":"Y3AM6bj4P3NS"},"source":["- HuggingFace comes with a native `saved_model` feature inside `save_pretrained` function for TensorFlow based models. We will use that to save it as TF `SavedModel`.\n","- We'll use [xlm-roberta-large-finetuned-conll03-english](https://huggingface.co/xlm-roberta-large-finetuned-conll03-english) model from HuggingFace as an example\n","- In addition to `TFXLMRobertaForTokenClassification` we also need to save the `XLMRobertaTokenizer`. This is the same for every model, these are assets needed for tokenization inside Spark NLP."]},{"cell_type":"code","metadata":{"id":"ZaiirlSKNhVD","executionInfo":{"status":"ok","timestamp":1640708841457,"user_tz":-60,"elapsed":352,"user":{"displayName":"Maziyar Panahi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTmm4Srbdy-IOOALumHToD8y9PvjupF566HEz1zA=s64","userId":"06037986691777662786"}}},"source":["from transformers import TFXLMRobertaForTokenClassification, XLMRobertaTokenizer \n","\n","MODEL_NAME = 'xlm-roberta-large-finetuned-conll03-english'\n","\n","tokenizer = XLMRobertaTokenizer.from_pretrained(MODEL_NAME)\n","tokenizer.save_pretrained('./{}_tokenizer/'.format(MODEL_NAME))\n","\n","# just in case if there is no TF/Keras file provided in the model\n","# we can just use `from_pt` and convert PyTorch to TensorFlow\n","try:\n","  print('try downloading TF weights')\n","  model = TFXLMRobertaForTokenClassification.from_pretrained(MODEL_NAME)\n","except:\n","  print('try downloading PyTorch weights')\n","  model = TFXLMRobertaForTokenClassification.from_pretrained(MODEL_NAME, from_pt=True)\n","\n","model.save_pretrained(\"./{}\".format(MODEL_NAME), saved_model=True)"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nlgyZuJfS5IB"},"source":["Let's have a look inside these two directories and see what we are dealing with:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p2XCole7TTef","executionInfo":{"status":"ok","timestamp":1640708154100,"user_tz":-60,"elapsed":494,"user":{"displayName":"Maziyar Panahi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTmm4Srbdy-IOOALumHToD8y9PvjupF566HEz1zA=s64","userId":"06037986691777662786"}},"outputId":"7bd16979-4e59-4f6e-d685-4b0f882b5bcc"},"source":["!ls -l {MODEL_NAME}"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["total 2183524\n","-rw-r--r-- 1 root root       1046 Dec 28 16:15 config.json\n","drwxr-xr-x 3 root root       4096 Dec 28 16:14 saved_model\n","-rw-r--r-- 1 root root 2235915144 Dec 28 16:15 tf_model.h5\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r0DOGz8VUR-r","executionInfo":{"status":"ok","timestamp":1640708154608,"user_tz":-60,"elapsed":511,"user":{"displayName":"Maziyar Panahi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTmm4Srbdy-IOOALumHToD8y9PvjupF566HEz1zA=s64","userId":"06037986691777662786"}},"outputId":"49b86052-ec5c-4a97-959d-c2aa5c3b8df5"},"source":["!ls -l {MODEL_NAME}/saved_model/1"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["total 16068\n","drwxr-xr-x 2 root root     4096 Dec 28 16:14 assets\n","-rw-r--r-- 1 root root 16444767 Dec 28 16:14 saved_model.pb\n","drwxr-xr-x 2 root root     4096 Dec 28 16:14 variables\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mcm2UpNxUUQN","executionInfo":{"status":"ok","timestamp":1640708154609,"user_tz":-60,"elapsed":8,"user":{"displayName":"Maziyar Panahi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTmm4Srbdy-IOOALumHToD8y9PvjupF566HEz1zA=s64","userId":"06037986691777662786"}},"outputId":"5068af51-5a09-4a60-866b-96b4f4bdd083"},"source":["!ls -l {MODEL_NAME}_tokenizer"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["total 4960\n","-rw-r--r-- 1 root root 5069051 Dec 28 16:12 sentencepiece.bpe.model\n","-rw-r--r-- 1 root root     238 Dec 28 16:12 special_tokens_map.json\n","-rw-r--r-- 1 root root     637 Dec 28 16:12 tokenizer_config.json\n"]}]},{"cell_type":"markdown","metadata":{"id":"gZegMvuGTmHt"},"source":["- as you can see, we need the SavedModel from `saved_model/1/` path\n","- we also be needing `sentencepiece.bpe.model` file from the tokenizer\n","- all we need is to copy `sentencepiece.bpe.model` file into `saved_model/1/assets` which Spark NLP will look for\n","- in addition to vocabs, we also need `labels` and their `ids` which is saved inside the model's config. We will save this inside `labels.txt`"]},{"cell_type":"code","metadata":{"id":"ez6MT-RTT7ss"},"source":["asset_path = '{}/saved_model/1/assets'.format(MODEL_NAME)\n","\n","# let's copy sentencepiece.bpe.model file to saved_model/1/assets\n","!cp {MODEL_NAME}_tokenizer/sentencepiece.bpe.model {asset_path}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vcg_5YP1-vfC"},"source":["# get label2id dictionary \n","labels = model.config.label2id\n","# sort the dictionary based on the id\n","labels = sorted(labels, key=labels.get)\n","\n","with open(asset_path+'/labels.txt', 'w') as f:\n","    f.write('\\n'.join(labels))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mBq7ztzlACYO"},"source":["Voila! We have our `vocab.txt` and `labels.txt` inside assets directory"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OYnT5U8N9dxT","executionInfo":{"status":"ok","timestamp":1640708155273,"user_tz":-60,"elapsed":228,"user":{"displayName":"Maziyar Panahi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTmm4Srbdy-IOOALumHToD8y9PvjupF566HEz1zA=s64","userId":"06037986691777662786"}},"outputId":"89764651-6a64-4b11-aaaa-f031a4284e1a"},"source":["! ls -l {asset_path}"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["total 4956\n","-rw-r--r-- 1 root root      45 Dec 28 16:15 labels.txt\n","-rw-r--r-- 1 root root 5069051 Dec 28 16:15 sentencepiece.bpe.model\n"]}]},{"cell_type":"markdown","metadata":{"id":"NlJKd2tIU0PD"},"source":["## Import and Save XlmRoBertaForTokenClassification in Spark NLP\n"]},{"cell_type":"markdown","metadata":{"id":"A0FXoxHJc5CU"},"source":["- Let's install and setup Spark NLP in Google Colab\n","- This part is pretty easy via our simple script"]},{"cell_type":"code","metadata":{"id":"8tpW5nkMc53m","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1640708780913,"user_tz":-60,"elapsed":7553,"user":{"displayName":"Maziyar Panahi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTmm4Srbdy-IOOALumHToD8y9PvjupF566HEz1zA=s64","userId":"06037986691777662786"}},"outputId":"2677b2fd-477a-4530-c98b-a8a1ccbd2baa"},"source":["! wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["--2021-12-28 16:26:13--  http://setup.johnsnowlabs.com/colab.sh\n","Resolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 51.158.130.125\n","Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:80... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://setup.johnsnowlabs.com/colab.sh [following]\n","--2021-12-28 16:26:13--  https://setup.johnsnowlabs.com/colab.sh\n","Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:443... connected.\n","HTTP request sent, awaiting response... 302 Moved Temporarily\n","Location: https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh [following]\n","--2021-12-28 16:26:13--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1275 (1.2K) [text/plain]\n","Saving to: â€˜STDOUTâ€™\n","\n","-                   100%[===================>]   1.25K  --.-KB/s    in 0s      \n","\n","2021-12-28 16:26:13 (49.9 MB/s) - written to stdout [1275/1275]\n","\n","setup Colab for PySpark 3.0.3 and Spark NLP 3.3.4\n","Installing PySpark 3.0.3 and Spark NLP 3.3.4\n"]}]},{"cell_type":"markdown","metadata":{"id":"m_NAgx4hdCGP"},"source":["Let's start Spark with Spark NLP included via our simple `start()` function"]},{"cell_type":"code","metadata":{"id":"cbNneAVCLU1y","executionInfo":{"status":"ok","timestamp":1640708814657,"user_tz":-60,"elapsed":33750,"user":{"displayName":"Maziyar Panahi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTmm4Srbdy-IOOALumHToD8y9PvjupF566HEz1zA=s64","userId":"06037986691777662786"}}},"source":["import sparknlp\n","# let's start Spark with Spark NLP\n","spark = sparknlp.start()"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ABTu9MrdVafM"},"source":["- Let's use `loadSavedModel` functon in `XlmRoBertaForTokenClassification` which allows us to load TensorFlow model in SavedModel format\n","- Most params can be set later when you are loading this model in `XlmRoBertaForTokenClassification` in runtime like `setMaxSentenceLength`, so don't worry what you are setting them now\n","- `loadSavedModel` accepts two params, first is the path to the TF SavedModel. The second is the SparkSession that is `spark` variable we previously started via `sparknlp.start()`\n","- NOTE: `loadSavedModel` accepts local paths in addition to distributed file systems such as `HDFS`, `S3`, `DBFS`, etc. This feature was introduced in Spark NLP 4.2.2 release. Keep in mind the best and recommended way to move/share/reuse Spark NLP models is to use `write.save` so you can use `.load()` from any file systems natively.\n","\n"]},{"cell_type":"code","metadata":{"id":"8W_almibVRTj","executionInfo":{"status":"ok","timestamp":1640708858933,"user_tz":-60,"elapsed":2,"user":{"displayName":"Maziyar Panahi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTmm4Srbdy-IOOALumHToD8y9PvjupF566HEz1zA=s64","userId":"06037986691777662786"}}},"source":["from sparknlp.annotator import *\n","from sparknlp.base import *\n","\n","tokenClassifier = XlmRoBertaForTokenClassification\\\n","  .loadSavedModel('{}/saved_model/1'.format(MODEL_NAME), spark)\\\n","  .setInputCols([\"document\",'token'])\\\n","  .setOutputCol(\"ner\")\\\n","  .setCaseSensitive(True)\\\n","  .setMaxSentenceLength(128)"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PjGiq4KnXWuy"},"source":["- Let's save it on disk so it is easier to be moved around and also be used later via `.load` function"]},{"cell_type":"code","metadata":{"id":"iWu5HfbnXAlM"},"source":["tokenClassifier.write().overwrite().save(\"./{}_spark_nlp\".format(MODEL_NAME))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QCrjxPhzDplN"},"source":["Let's clean up stuff we don't need anymore"]},{"cell_type":"code","metadata":{"id":"ZgkVIJshDtLx"},"source":["! rm -rf {MODEL_NAME}_tokenizer {MODEL_NAME}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-TSeTRZpXqWO"},"source":["Awesome ðŸ˜Ž  !\n","\n","This is your XlmRoBertaForTokenClassification model from HuggingFace ðŸ¤—  loaded and saved by Spark NLP ðŸš€ "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ogpxSWxOXj3W","executionInfo":{"status":"ok","timestamp":1640708814658,"user_tz":-60,"elapsed":16,"user":{"displayName":"Maziyar Panahi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTmm4Srbdy-IOOALumHToD8y9PvjupF566HEz1zA=s64","userId":"06037986691777662786"}},"outputId":"7fc4e69f-3ab2-4ddc-a3b0-6de95f018c91"},"source":["! ls -l {MODEL_NAME}_spark_nlp"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["ls: cannot access '{MODEL_NAME}_spark_nlp': No such file or directory\n"]}]},{"cell_type":"markdown","metadata":{"id":"Fbehje7fYTDj"},"source":["Now let's see how we can use it on other machines, clusters, or any place you wish to use your new and shiny XlmRoBertaForTokenClassification model ðŸ˜Š "]},{"cell_type":"code","metadata":{"id":"1mm3CvkwYRgs","executionInfo":{"status":"ok","timestamp":1640708950792,"user_tz":-60,"elapsed":88864,"user":{"displayName":"Maziyar Panahi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTmm4Srbdy-IOOALumHToD8y9PvjupF566HEz1zA=s64","userId":"06037986691777662786"}}},"source":["tokenClassifier_loaded = XlmRoBertaForTokenClassification.load(\"./{}_spark_nlp\".format(MODEL_NAME))\\\n","  .setInputCols([\"document\",'token'])\\\n","  .setOutputCol(\"ner\")"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BDWNWdBlBpHi"},"source":["You can see what labels were used to train this model via `getClasses` function:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pGRTNISyYlnO"},"outputs":[],"source":["# .getClasses was introduced in spark-nlp==3.4.0\n","tokenClassifier_loaded.getClasses()"]},{"cell_type":"markdown","metadata":{"id":"UvRBsP2SBpHi"},"source":["This is how you can use your loaded classifier model in Spark NLP ðŸš€ pipeline:"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"MysnSyi8BpHi","executionInfo":{"status":"ok","timestamp":1640708966516,"user_tz":-60,"elapsed":15729,"user":{"displayName":"Maziyar Panahi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhTmm4Srbdy-IOOALumHToD8y9PvjupF566HEz1zA=s64","userId":"06037986691777662786"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c13a1827-770f-48a6-bba6-eda25077f8ef"},"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------+--------------------+\n","|                text|              result|\n","+--------------------+--------------------+\n","|My name is Sarah ...|[O, O, O, I-PER, ...|\n","|My name is Clara ...|[O, O, O, I-PER, ...|\n","+--------------------+--------------------+\n","\n"]}],"source":["document_assembler = DocumentAssembler() \\\n","    .setInputCol('text') \\\n","    .setOutputCol('document')\n","\n","tokenizer = Tokenizer() \\\n","    .setInputCols(['document']) \\\n","    .setOutputCol('token')\n","\n","pipeline = Pipeline(stages=[\n","    document_assembler, \n","    tokenizer,\n","    tokenClassifier_loaded    \n","])\n","\n","# couple of simple examples\n","example = spark.createDataFrame([[\"My name is Sarah and I live in London\"], ['My name is Clara and I live in Berkeley, California.']]).toDF(\"text\")\n","\n","result = pipeline.fit(example).transform(example)\n","\n","# result is a DataFrame\n","result.select(\"text\", \"ner.result\").show()"]},{"cell_type":"markdown","metadata":{"id":"_he2LDtBYo1h"},"source":["That's it! You can now go wild and use hundreds of `XlmRoBertaForTokenClassification` models from HuggingFace ðŸ¤— in Spark NLP ðŸš€ \n"]},{"cell_type":"code","source":[""],"metadata":{"id":"yZ8UTMGx4K16"},"execution_count":null,"outputs":[]}]}