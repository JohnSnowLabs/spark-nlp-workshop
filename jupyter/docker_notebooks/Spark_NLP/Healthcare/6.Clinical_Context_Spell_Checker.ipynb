{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2muvLzlqdcva"
   },
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A2A9se0Bdcvb"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/6.Clinical_Context_Spell_Checker.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "orznscn3dcvc"
   },
   "source": [
    "<H1> 6. Context Spell Checker - Medical </H1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZXEqkSp9RFkN"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "jsl_secret = os.getenv('SECRET')\n",
    "\n",
    "import sparknlp\n",
    "sparknlp_version = sparknlp.version()\n",
    "import sparknlp_jsl\n",
    "jsl_version = sparknlp_jsl.version()\n",
    "\n",
    "print (jsl_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 123783,
     "status": "ok",
     "timestamp": 1618327462984,
     "user": {
      "displayName": "muhammet şantaş",
      "photoUrl": "",
      "userId": "01037434825541536598"
     },
     "user_tz": -180
    },
    "id": "H2EWnyIOQZPI",
    "outputId": "93c72f92-d859-4427-cad2-852574d98a8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP Version : 3.0.1\n",
      "Spark NLP_JSL Version : 3.0.0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp_jsl.annotator import *\n",
    "from sparknlp.base import *\n",
    "import sparknlp_jsl\n",
    "import sparknlp\n",
    "\n",
    "\n",
    "params = {\"spark.driver.memory\":\"16G\",\n",
    "\"spark.kryoserializer.buffer.max\":\"2000M\",\n",
    "\"spark.driver.maxResultSize\":\"2000M\"}\n",
    "\n",
    "spark = sparknlp_jsl.start(jsl_secret, params=params)\n",
    "\n",
    "print (\"Spark NLP Version :\", sparknlp.version())\n",
    "print (\"Spark NLP_JSL Version :\", sparknlp_jsl.version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 183587,
     "status": "ok",
     "timestamp": 1618327522800,
     "user": {
      "displayName": "muhammet şantaş",
      "photoUrl": "",
      "userId": "01037434825541536598"
     },
     "user_tz": -180
    },
    "id": "l70_9DOgdcvz",
    "outputId": "f669ef0c-859a-479d-b850-e22c4b4dc012",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spellcheck_clinical download started this may take some time.\n",
      "Approximate size to download 142.2 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "documentAssembler = DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "tokenizer = RecursiveTokenizer()\\\n",
    "    .setInputCols([\"document\"])\\\n",
    "    .setOutputCol(\"token\")\\\n",
    "    .setPrefixes([\"\\\"\", \"(\", \"[\", \"\\n\"])\\\n",
    "    .setSuffixes([\".\", \",\", \"?\", \")\",\"!\", \"'s\"])\n",
    "\n",
    "spellModel = ContextSpellCheckerModel\\\n",
    "    .pretrained('spellcheck_clinical', 'en', 'clinical/models')\\\n",
    "    .setInputCols(\"token\")\\\n",
    "    .setOutputCol(\"checked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XyqbEdoPdcv-",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    stages = [\n",
    "    documentAssembler,\n",
    "    tokenizer,\n",
    "    spellModel\n",
    "  ])\n",
    "\n",
    "empty_ds = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "lp = LightPipeline(pipeline.fit(empty_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "49DMo2sQdcwC"
   },
   "source": [
    "Ok!, at this point we have our spell checking pipeline as expected. Let's see what we can do with it, see these errors,\n",
    "\n",
    "_\n",
    "__Witth__ the __hell__ of __phisical__ __terapy__ the patient was __imbulated__ and on posoperative, the __impatient__ tolerating a post __curgical__ soft diet._\n",
    "\n",
    "_With __paint__ __wel__ controlled on __orall__ pain medications, she was discharged __too__ __reihabilitation__ __facilitay__._\n",
    "\n",
    "_She is to also call the __ofice__ if she has any __ever__ greater than 101, or __leeding__ __form__ the surgical wounds._\n",
    "\n",
    "_Abdomen is __sort__, nontender, and __nonintended__._\n",
    "            \n",
    "_No __cute__ distress_\n",
    "\n",
    "Check that some of the errors are valid English words, only by considering the context the right choice can be made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 191255,
     "status": "ok",
     "timestamp": 1618327530480,
     "user": {
      "displayName": "muhammet şantaş",
      "photoUrl": "",
      "userId": "01037434825541536598"
     },
     "user_tz": -180
    },
    "id": "K2BuhiZNHGhH",
    "outputId": "db4515bd-4518-4475-fb56-94e865128db7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Witth', 'With'), ('the', 'the'), ('hell', 'cell'), ('of', 'of'), ('phisical', 'physical'), ('terapy', 'therapy'), ('the', 'the'), ('patient', 'patient'), ('was', 'was'), ('imbulated', 'ambulated'), ('and', 'and'), ('on', 'on'), ('posoperative', 'postoperative'), (',', ','), ('the', 'the'), ('impatient', 'inpatient'), ('tolerating', 'tolerating'), ('a', 'a'), ('post', 'post'), ('curgical', 'surgical'), ('soft', 'soft'), ('diet', 'diet'), ('.', '.')]\n",
      "[('With', 'With'), ('paint', 'paint'), ('wel', 'well'), ('controlled', 'controlled'), ('on', 'on'), ('orall', 'oral'), ('pain', 'pain'), ('medications', 'medications'), (',', ','), ('she', 'she'), ('was', 'was'), ('discharged', 'discharged'), ('too', 'too'), ('reihabilitation', 'rehabilitation'), ('facilitay', 'facility'), ('.', '.')]\n",
      "[('She', 'She'), ('is', 'is'), ('to', 'to'), ('also', 'also'), ('call', 'call'), ('the', 'the'), ('ofice', 'office'), ('if', 'if'), ('she', 'she'), ('has', 'has'), ('any', 'any'), ('ever', 'ever'), ('greater', 'greater'), ('than', 'than'), ('101', '101'), (',', ','), ('or', 'or'), ('leeding', 'leading'), ('form', 'form'), ('the', 'the'), ('surgical', 'surgical'), ('wounds', 'wounds'), ('.', '.')]\n",
      "[('Abdomen', 'Abdomen'), ('is', 'is'), ('sort', 'sort'), (',', ','), ('nontender', 'nontender'), (',', ','), ('and', 'and'), ('nonintended', 'unintended'), ('.', '.')]\n",
      "[('Patient', 'Patient'), ('not', 'not'), ('showing', 'showing'), ('pain', 'pain'), ('or', 'or'), ('any', 'any'), ('wealth', 'wealth'), ('problems', 'problems'), ('.', '.')]\n",
      "[('No', 'No'), ('cute', 'acute'), ('distress', 'distress')]\n"
     ]
    }
   ],
   "source": [
    "example = [\"Witth the hell of phisical terapy the patient was imbulated and on posoperative, the impatient tolerating a post curgical soft diet.\",\n",
    "            \"With paint wel controlled on orall pain medications, she was discharged too reihabilitation facilitay.\",\n",
    "            \"She is to also call the ofice if she has any ever greater than 101, or leeding form the surgical wounds.\",\n",
    "            \"Abdomen is sort, nontender, and nonintended.\",\n",
    "            \"Patient not showing pain or any wealth problems.\",\n",
    "            \"No cute distress\"\n",
    "            \n",
    "]\n",
    "\n",
    "for pairs in lp.annotate(example):\n",
    "\n",
    "  print (list(zip(pairs['token'],pairs['checked'])))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "6.Clinical_Context_Spell_Checker.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/6.Clinical_Context_Spell_Checker.ipynb",
     "timestamp": 1617780944966
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
