{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c469c9ee-3832-4f99-96ee-679bf24df825",
     "showTitle": false,
     "title": ""
    },
    "id": "QJOsfqRGI_3n"
   },
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a104cee-cb11-4845-86f6-17fbe57a4840",
     "showTitle": false,
     "title": ""
    },
    "id": "sI93AChbI_3v"
   },
   "source": [
    "<H1>Context Based Clinical Spell Checker</H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "daf19bd8-d6fa-4bd7-ac3a-3db6c7a82c5c",
     "showTitle": false,
     "title": ""
    },
    "id": "wdUI6jnVI_3w",
    "outputId": "69563866-9a6a-402b-bf03-20b89f5370d0"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP Version : 5.1.0\nSpark NLP_JSL Version : 5.1.0\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"/?o=7956323724731612#setting/sparkui/0725-092232-stftp6wi/driver-1173520004306045065\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://10.139.64.12:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Databricks Shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fc539705ff0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sparknlp\n",
    "import sparknlp_jsl\n",
    "from sparknlp.util import *\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp_jsl.annotator import *\n",
    "from sparknlp.pretrained import ResourceDownloader\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "\n",
    "\n",
    "pd.set_option('max_colwidth', 100)\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "print(\"Spark NLP Version :\", sparknlp.version())\n",
    "print(\"Spark NLP_JSL Version :\", sparknlp_jsl.version())\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "781885b0-6fe4-42ee-8b41-2a73a37fd7bf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## spellcheck_clinical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d260ffe0-e641-4035-a530-0f100eae8e12",
     "showTitle": false,
     "title": ""
    },
    "id": "-KEqAocbI_3y",
    "outputId": "c20fae82-4fe1-4624-ebc3-2e1672a2bb28"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spellcheck_clinical download started this may take some time.\nApproximate size to download 134.7 MB\n\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[ \\ ]\r[ | ]\r[ / ]\r[ — ]\r[OK!]\n"
     ]
    }
   ],
   "source": [
    "documentAssembler = DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "tokenizer = RecursiveTokenizer()\\\n",
    "    .setInputCols([\"document\"])\\\n",
    "    .setOutputCol(\"token\")\\\n",
    "    .setPrefixes([\"\\\"\", \"(\", \"[\", \"\\n\"])\\\n",
    "    .setSuffixes([\".\", \",\", \"?\", \")\",\"!\", \"'s\"])\n",
    "\n",
    "spellModel = ContextSpellCheckerModel.pretrained('spellcheck_clinical', 'en', 'clinical/models')\\\n",
    "    .setInputCols(\"token\")\\\n",
    "    .setOutputCol(\"checked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "833444d3-5a30-47dc-a00d-19061e93f585",
     "showTitle": false,
     "title": ""
    },
    "id": "L8pETwfiI_31",
    "outputId": "144fefed-0690-44d5-a8dd-8e3735a228b6"
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    stages = [\n",
    "    documentAssembler,\n",
    "    tokenizer,\n",
    "    spellModel\n",
    "  ])\n",
    "\n",
    "empty_ds = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "lp = LightPipeline(pipeline.fit(empty_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8466d0a-cd9c-4829-a383-157fe8562838",
     "showTitle": false,
     "title": ""
    },
    "id": "o-wXCw6mI_33"
   },
   "source": [
    "Ok!, at this point we have our spell checking pipeline as expected. Let's see what we can do with it, see these errors,\n",
    "\n",
    "\n",
    "\n",
    "_She was **treathed** with a five day course of **amoxicilin** for a **resperatory** **truct** infection._\n",
    "\n",
    "_With pain well controlled on **orall** **meditation**, she was discharged to **reihabilitation** **facilitay**._\n",
    "\n",
    "\n",
    "_Her **adominal** examination is soft, nontender, and **nonintended**_\n",
    "\n",
    "_The patient was seen by the **entocrinology** service and she was discharged on 40 units of **unsilin** glargine at night_\n",
    "      \n",
    "_No __cute__ distress_\n",
    "\n",
    "\n",
    "Check that some of the errors are valid English words, only by considering the context the right choice can be made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47569d82-239e-43e0-a485-2e685951045c",
     "showTitle": false,
     "title": ""
    },
    "id": "zjHnqUteI_33",
    "outputId": "b8e18c61-c76b-476e-f650-245e9c678ded"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('She', 'She'), ('was', 'was'), ('treathed', 'treated'), ('with', 'with'), ('a', 'a'), ('five', 'five'), ('day', 'day'), ('course', 'course'), ('of', 'of'), ('amoxicilin', 'amoxicillin'), ('for', 'for'), ('a', 'a'), ('resperatory', 'respiratory'), ('truct', 'tract'), ('infection', 'infection'), ('.', '.')]\n[('With', 'With'), ('pain', 'pain'), ('well', 'well'), ('controlled', 'controlled'), ('on', 'on'), ('orall', 'oral'), ('meditation', 'medication'), (',', ','), ('she', 'she'), ('was', 'was'), ('discharged', 'discharged'), ('to', 'to'), ('reihabilitation', 'rehabilitation'), ('facilitay', 'facility'), ('.', '.')]\n[('Her', 'Her'), ('adominal', 'abdominal'), ('examination', 'examination'), ('is', 'is'), ('soft', 'soft'), (',', ','), ('nontender', 'nontender'), (',', ','), ('and', 'and'), ('nonintended', 'nondistended'), ('.', '.')]\n[('The', 'The'), ('patient', 'patient'), ('was', 'was'), ('seen', 'seen'), ('by', 'by'), ('the', 'the'), ('entocrinology', 'endocrinology'), ('service', 'service'), ('and', 'and'), ('she', 'she'), ('was', 'was'), ('discharged', 'discharged'), ('on', 'on'), ('40', '40'), ('units', 'units'), ('of', 'of'), ('unsilin', 'insulin'), ('glargine', 'glargine'), ('at', 'at'), ('night', 'night')]\n[('No', 'No'), ('cute', 'acute'), ('distress', 'distress')]\n"
     ]
    }
   ],
   "source": [
    "example = [\"She was treathed with a five day course of amoxicilin for a resperatory truct infection . \",\n",
    "           \"With pain well controlled on orall meditation, she was discharged to reihabilitation facilitay.\",\n",
    "           \"Her adominal examination is soft, nontender, and nonintended.\",\n",
    "           \"The patient was seen by the entocrinology service and she was discharged on 40 units of unsilin glargine at night\",\n",
    "           \"No cute distress\",\n",
    "          ]\n",
    "\n",
    "for pairs in lp.annotate(example):\n",
    "\n",
    "  print (list(zip(pairs['token'],pairs['checked'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebe212a6-a9ca-4ef3-b195-e4c9332c441c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrected tokens:\n\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('treathed', 'treated'),\n",
       " ('amoxicilin', 'amoxicillin'),\n",
       " ('resperatory', 'respiratory'),\n",
       " ('truct', 'tract'),\n",
       " ('orall', 'oral'),\n",
       " ('meditation', 'medication'),\n",
       " ('reihabilitation', 'rehabilitation'),\n",
       " ('facilitay', 'facility'),\n",
       " ('adominal', 'abdominal'),\n",
       " ('nonintended', 'nondistended'),\n",
       " ('entocrinology', 'endocrinology'),\n",
       " ('unsilin', 'insulin'),\n",
       " ('cute', 'acute')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Corrected tokens:\\n\")\n",
    "\n",
    "pair_list = [list(zip(pairs['token'],pairs['checked'])) for pairs in lp.annotate(example)]\n",
    "corrected_list = [i for pair in pair_list for i in pair if i[0] != i[1]]\n",
    "corrected_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3efe0157-b8a8-4951-8667-53e2f694a035",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## spellcheck_drug_norvig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c595427-9efa-4571-9f6a-9e0e5d01bc9a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spellcheck_drug_norvig download started this may take some time.\nApproximate size to download 4.3 MB\n\r[ | ]\r[ / ]\r[OK!]\n"
     ]
    }
   ],
   "source": [
    "documentAssembler = DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "tokenizer = Tokenizer()\\\n",
    "    .setInputCols(\"document\")\\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "spell = NorvigSweetingModel.pretrained(\"spellcheck_drug_norvig\", \"en\", \"clinical/models\")\\\n",
    "    .setInputCols(\"token\")\\\n",
    "    .setOutputCol(\"corrected_token\")\\\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    stages = [\n",
    "        documentAssembler,\n",
    "        tokenizer,\n",
    "        spell\n",
    "        ])\n",
    "\n",
    "empty_ds = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "lp = LightPipeline(pipeline.fit(empty_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "905c2ecd-4c51-44ff-9381-fa8939a9d01e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('You', 'You'), ('have', 'have'), ('to', 'to'), ('take', 'take'), ('Amrosia', 'Ambrosia'), ('artemisiifoli', 'artemisiifolia'), (',', ','), ('Oactra', 'Odactra'), ('and', 'and'), ('a', 'a'), ('bit', 'bit'), ('of', 'of'), ('Grastk', 'Grastek'), ('and', 'and'), ('lastacaf', 'lastacaft')]\n"
     ]
    }
   ],
   "source": [
    "example = [\"You have to take Amrosia artemisiifoli , Oactra and a bit of Grastk and lastacaf \",\n",
    "          ]\n",
    "\n",
    "for pairs in lp.annotate(example):\n",
    "    print(list(zip(pairs['token'],pairs['corrected_token'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb2eb7c1-5886-447c-ba1c-9d80fb554535",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrected tokens:\n\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('Amrosia', 'Ambrosia'),\n",
       " ('artemisiifoli', 'artemisiifolia'),\n",
       " ('Oactra', 'Odactra'),\n",
       " ('Grastk', 'Grastek'),\n",
       " ('lastacaf', 'lastacaft')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Corrected tokens:\\n\")\n",
    "\n",
    "pair_list = [list(zip(pairs['token'],pairs['corrected_token'])) for pairs in lp.annotate(example)]\n",
    "corrected_list = [i for pair in pair_list for i in pair if i[0] != i[1]]\n",
    "corrected_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97ac90f2-d3fb-4c3d-a2e5-c5226fc0535a",
     "showTitle": false,
     "title": ""
    },
    "id": "jTs-UhZzI_35"
   },
   "source": [
    "End of Notebook #"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "12. Context Based Clinical Spell Checker",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
