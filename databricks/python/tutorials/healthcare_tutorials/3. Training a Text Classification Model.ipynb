{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c6768fe1-ddbb-4799-8eb0-76d53107d1fa",
     "showTitle": false,
     "title": ""
    },
    "id": "_gMgspigI3rV"
   },
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "198ee648-32d9-4be7-8e38-c78189521b15",
     "showTitle": false,
     "title": ""
    },
    "id": "-g9xwuFPI3rc"
   },
   "source": [
    "# Trainining a Text Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebdd9c48-6750-4fb8-a0e8-ef004acbba94",
     "showTitle": false,
     "title": ""
    },
    "id": "PiTWKkEeI3rd",
    "outputId": "33ccc125-d425-4e3a-e27e-797b090be897"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparknlp.version :  5.1.0\nsparknlp_jsl.version :  5.1.0\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"/?o=7956323724731612#setting/sparkui/0725-092232-stftp6wi/driver-8491851082581706788\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://10.139.64.11:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Databricks Shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fca7c43dff0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import sparknlp\n",
    "import sparknlp_jsl\n",
    "from sparknlp.base import *\n",
    "from sparknlp.util import *\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp_jsl.annotator import *\n",
    "from sparknlp.pretrained import ResourceDownloader\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "\n",
    "pd.set_option('max_colwidth', 100)\n",
    "pd.set_option('display.max_columns', 100)  \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "\n",
    "print('sparknlp.version : ',sparknlp.version())\n",
    "print('sparknlp_jsl.version : ',sparknlp_jsl.version())\n",
    "\n",
    "spark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cfe0436c-8f68-4ecd-8394-415fd204ea77",
     "showTitle": false,
     "title": ""
    },
    "id": "HnG9SuyiI3rh"
   },
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1dd7f21a-7e8c-4938-ba6b-b6699234f6e3",
     "showTitle": false,
     "title": ""
    },
    "id": "v0pw1cCrI3ri",
    "outputId": "2ea04500-17d8-442d-fa5c-90400adaee70"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " !wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Healthcare/data/petfinder-mini.csv\n",
    " \n",
    " dbutils.fs.cp(\"file:/databricks/driver/petfinder-mini.csv\", \"dbfs:/\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5cee9236-adaf-4f58-90fa-bf4a4a9894de",
     "showTitle": false,
     "title": ""
    },
    "id": "5BmKKdIGI3ri",
    "outputId": "a8db8ac1-e2a7-4759-f08a-d8db6f0b0468"
   },
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv('petfinder-mini.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13b0b443-7e66-40ad-9bef-fc24ee654c07",
     "showTitle": false,
     "title": ""
    },
    "id": "INhq5BaLI3rj",
    "outputId": "d3bf83f2-6a27-41c5-cb19-7c4092484516"
   },
   "outputs": [],
   "source": [
    "# In the original dataset \"4\" indicates the pet was not adopted.\n",
    "\n",
    "dataframe['target'] = np.where(dataframe['AdoptionSpeed']==4, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03ff7ad3-261e-411c-be1d-d67f88d3963a",
     "showTitle": false,
     "title": ""
    },
    "id": "IQkbFQtXI3rk",
    "outputId": "f9620837-14f4-4d7b-e5f9-42ecd2c76fb1"
   },
   "outputs": [],
   "source": [
    "dataframe = dataframe.drop(['AdoptionSpeed'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "344e780f-efb7-4975-b838-a1bdda44d4a8",
     "showTitle": false,
     "title": ""
    },
    "id": "_jKwqL_DI3rk",
    "outputId": "90136778-7129-4304-9959-29e66daaeee8"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>FurLength</th>\n",
       "      <th>Vaccinated</th>\n",
       "      <th>Sterilized</th>\n",
       "      <th>Health</th>\n",
       "      <th>Fee</th>\n",
       "      <th>Description</th>\n",
       "      <th>PhotoAmt</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cat</td>\n",
       "      <td>3</td>\n",
       "      <td>Tabby</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>White</td>\n",
       "      <td>Small</td>\n",
       "      <td>Short</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>100</td>\n",
       "      <td>Nibble is a 3+ month old ball of cuteness. He is energetic and playful. I rescued a couple of ca...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cat</td>\n",
       "      <td>1</td>\n",
       "      <td>Domestic Medium Hair</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Not Sure</td>\n",
       "      <td>Not Sure</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>0</td>\n",
       "      <td>I just found it alone yesterday near my apartment. It was shaking so I had to bring it home to p...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dog</td>\n",
       "      <td>1</td>\n",
       "      <td>Mixed Breed</td>\n",
       "      <td>Male</td>\n",
       "      <td>Brown</td>\n",
       "      <td>White</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>0</td>\n",
       "      <td>Their pregnant mother was dumped by her irresponsible owner at the roadside near some shops in S...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dog</td>\n",
       "      <td>4</td>\n",
       "      <td>Mixed Breed</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Short</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>150</td>\n",
       "      <td>Good guard dog, very alert, active, obedience waiting for her good master, plz call or sms for m...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dog</td>\n",
       "      <td>1</td>\n",
       "      <td>Mixed Breed</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>No Color</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Short</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>0</td>\n",
       "      <td>This handsome yet cute boy is up for adoption. He is the most playful pal we've seen in our pupp...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Type  Age                Breed1  Gender Color1    Color2 MaturitySize FurLength Vaccinated Sterilized   Health  Fee                                                                                          Description  PhotoAmt  target\n",
       "0  Cat    3                 Tabby    Male  Black     White        Small     Short         No         No  Healthy  100  Nibble is a 3+ month old ball of cuteness. He is energetic and playful. I rescued a couple of ca...         1       1\n",
       "1  Cat    1  Domestic Medium Hair    Male  Black     Brown       Medium    Medium   Not Sure   Not Sure  Healthy    0  I just found it alone yesterday near my apartment. It was shaking so I had to bring it home to p...         2       1\n",
       "2  Dog    1           Mixed Breed    Male  Brown     White       Medium    Medium        Yes         No  Healthy    0  Their pregnant mother was dumped by her irresponsible owner at the roadside near some shops in S...         7       1\n",
       "3  Dog    4           Mixed Breed  Female  Black     Brown       Medium     Short        Yes         No  Healthy  150  Good guard dog, very alert, active, obedience waiting for her good master, plz call or sms for m...         8       1\n",
       "4  Dog    1           Mixed Breed    Male  Black  No Color       Medium     Short         No         No  Healthy    0  This handsome yet cute boy is up for adoption. He is the most playful pal we've seen in our pupp...         3       1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f7282fa-b75f-4224-be5a-7c688fa5e47e",
     "showTitle": false,
     "title": ""
    },
    "id": "TLYZ9l3II3rl",
    "outputId": "45a1986b-0d7a-4aaf-b9e3-93d947dd1ef3"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['Type', 'Age', 'Breed1', 'Gender', 'Color1', 'Color2', 'MaturitySize',\n",
       "       'FurLength', 'Vaccinated', 'Sterilized', 'Health', 'Fee', 'Description',\n",
       "       'PhotoAmt', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37a3dcd5-44ef-419a-8ec0-481cc9c8cc60",
     "showTitle": false,
     "title": ""
    },
    "id": "0-O6OG5UI3rm",
    "outputId": "206763d8-07e3-4a26-cace-e40936003f59"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 11537 entries, 0 to 11536\nData columns (total 15 columns):\n #   Column        Non-Null Count  Dtype \n---  ------        --------------  ----- \n 0   Type          11537 non-null  object\n 1   Age           11537 non-null  int64 \n 2   Breed1        11537 non-null  object\n 3   Gender        11537 non-null  object\n 4   Color1        11537 non-null  object\n 5   Color2        11537 non-null  object\n 6   MaturitySize  11537 non-null  object\n 7   FurLength     11537 non-null  object\n 8   Vaccinated    11537 non-null  object\n 9   Sterilized    11537 non-null  object\n 10  Health        11537 non-null  object\n 11  Fee           11537 non-null  int64 \n 12  Description   11528 non-null  object\n 13  PhotoAmt      11537 non-null  int64 \n 14  target        11537 non-null  int64 \ndtypes: int64(4), object(11)\nmemory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80617500-a7c0-49b1-9483-90da4427f457",
     "showTitle": false,
     "title": ""
    },
    "id": "5-VqF2eTI3rn",
    "outputId": "6dfa1984-3f42-4a66-a123-36db96b18835"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1    8457\n",
       "0    3080\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d0783d0-4d90-4fe7-9806-f84292d08fcb",
     "showTitle": false,
     "title": ""
    },
    "id": "cf_BEot1I3ro",
    "outputId": "32678e2a-1c6b-47cb-bda1-2e86371b95a7"
   },
   "outputs": [],
   "source": [
    "dataframe.Description = dataframe.Description.fillna('- no description -')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8c0422d4-27cf-4cf6-90a6-61028d2425f6",
     "showTitle": false,
     "title": ""
    },
    "id": "yJpJUD8EI3rp"
   },
   "source": [
    "## Featurize with Sklearn Column Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "642f557d-6706-49a8-ab79-37fcb2ff0fa0",
     "showTitle": false,
     "title": ""
    },
    "id": "ABGU1TwII3rp",
    "outputId": "bbacc5be-ddb7-4c4b-c597-4fa19399ab8e"
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "column_trans = make_column_transformer(\n",
    "     (OneHotEncoder(handle_unknown='ignore', categories='auto'), ['Type', 'Breed1', 'Gender', 'Color1', 'Color2', 'MaturitySize',\n",
    "       'FurLength', 'Vaccinated', 'Sterilized', 'Health']),\n",
    "     (TfidfVectorizer(max_features=100,  norm='l2', ngram_range=(1, 3)), 'Description'),\n",
    "     remainder=StandardScaler())\n",
    "\n",
    "X = column_trans.fit_transform(dataframe.drop(['target'], axis=1))\n",
    "\n",
    "y = dataframe.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9ec05ef-bb43-4ea9-9b27-db9356fade58",
     "showTitle": false,
     "title": ""
    },
    "id": "IYPAwe2OI3rs",
    "outputId": "68c65e58-27b8-48f0-c160-2628c1011447"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3102e9f4-541e-43a6-9cb4-432377593e10",
     "showTitle": false,
     "title": ""
    },
    "id": "z3ekjejkI3rs",
    "outputId": "016c7e17-1286-4657-d141-6cfdd0b4552b"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(11537, 302)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bef2eae5-c018-46f0-88d7-42e6387343f6",
     "showTitle": false,
     "title": ""
    },
    "id": "8mPUXd7sI3rt",
    "outputId": "5c3000c9-5b93-4da7-fe49-7aa00411b2af"
   },
   "outputs": [],
   "source": [
    "input_dim = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0db83aa5-580e-4611-be66-a9c6078fff86",
     "showTitle": false,
     "title": ""
    },
    "id": "DpSlH5TEI3ru",
    "outputId": "b37a797d-2de9-4ea8-a36a-4e2b282570f6"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "302"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7da8187-a1bc-4ed5-bcb5-d979d879f138",
     "showTitle": false,
     "title": ""
    },
    "id": "ILUEOF78I3ru",
    "outputId": "ffb082aa-2314-4a0d-c5c3-5cded5fce1a3"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "      <th>col_5</th>\n",
       "      <th>col_6</th>\n",
       "      <th>col_7</th>\n",
       "      <th>col_8</th>\n",
       "      <th>col_9</th>\n",
       "      <th>col_10</th>\n",
       "      <th>col_11</th>\n",
       "      <th>col_12</th>\n",
       "      <th>col_13</th>\n",
       "      <th>col_14</th>\n",
       "      <th>col_15</th>\n",
       "      <th>col_16</th>\n",
       "      <th>col_17</th>\n",
       "      <th>col_18</th>\n",
       "      <th>col_19</th>\n",
       "      <th>col_20</th>\n",
       "      <th>col_21</th>\n",
       "      <th>col_22</th>\n",
       "      <th>col_23</th>\n",
       "      <th>col_24</th>\n",
       "      <th>col_25</th>\n",
       "      <th>col_26</th>\n",
       "      <th>col_27</th>\n",
       "      <th>col_28</th>\n",
       "      <th>col_29</th>\n",
       "      <th>col_30</th>\n",
       "      <th>col_31</th>\n",
       "      <th>col_32</th>\n",
       "      <th>col_33</th>\n",
       "      <th>col_34</th>\n",
       "      <th>col_35</th>\n",
       "      <th>col_36</th>\n",
       "      <th>col_37</th>\n",
       "      <th>col_38</th>\n",
       "      <th>col_39</th>\n",
       "      <th>col_40</th>\n",
       "      <th>col_41</th>\n",
       "      <th>col_42</th>\n",
       "      <th>col_43</th>\n",
       "      <th>col_44</th>\n",
       "      <th>col_45</th>\n",
       "      <th>col_46</th>\n",
       "      <th>col_47</th>\n",
       "      <th>col_48</th>\n",
       "      <th>col_49</th>\n",
       "      <th>...</th>\n",
       "      <th>col_253</th>\n",
       "      <th>col_254</th>\n",
       "      <th>col_255</th>\n",
       "      <th>col_256</th>\n",
       "      <th>col_257</th>\n",
       "      <th>col_258</th>\n",
       "      <th>col_259</th>\n",
       "      <th>col_260</th>\n",
       "      <th>col_261</th>\n",
       "      <th>col_262</th>\n",
       "      <th>col_263</th>\n",
       "      <th>col_264</th>\n",
       "      <th>col_265</th>\n",
       "      <th>col_266</th>\n",
       "      <th>col_267</th>\n",
       "      <th>col_268</th>\n",
       "      <th>col_269</th>\n",
       "      <th>col_270</th>\n",
       "      <th>col_271</th>\n",
       "      <th>col_272</th>\n",
       "      <th>col_273</th>\n",
       "      <th>col_274</th>\n",
       "      <th>col_275</th>\n",
       "      <th>col_276</th>\n",
       "      <th>col_277</th>\n",
       "      <th>col_278</th>\n",
       "      <th>col_279</th>\n",
       "      <th>col_280</th>\n",
       "      <th>col_281</th>\n",
       "      <th>col_282</th>\n",
       "      <th>col_283</th>\n",
       "      <th>col_284</th>\n",
       "      <th>col_285</th>\n",
       "      <th>col_286</th>\n",
       "      <th>col_287</th>\n",
       "      <th>col_288</th>\n",
       "      <th>col_289</th>\n",
       "      <th>col_290</th>\n",
       "      <th>col_291</th>\n",
       "      <th>col_292</th>\n",
       "      <th>col_293</th>\n",
       "      <th>col_294</th>\n",
       "      <th>col_295</th>\n",
       "      <th>col_296</th>\n",
       "      <th>col_297</th>\n",
       "      <th>col_298</th>\n",
       "      <th>col_299</th>\n",
       "      <th>col_300</th>\n",
       "      <th>col_301</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.171825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.283609</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.220992</td>\n",
       "      <td>0.151594</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.144907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.158869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.170202</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.192465</td>\n",
       "      <td>0.190783</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132427</td>\n",
       "      <td>0.176639</td>\n",
       "      <td>0.151246</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.257843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.452479</td>\n",
       "      <td>0.950288</td>\n",
       "      <td>-0.829762</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.228484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.256152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.213817</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.555981</td>\n",
       "      <td>-0.299388</td>\n",
       "      <td>-0.511871</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.141649</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.172449</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.307225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.178193</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.210999</td>\n",
       "      <td>0.209155</td>\n",
       "      <td>0.209619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.414527</td>\n",
       "      <td>0.179294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.141336</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.555981</td>\n",
       "      <td>-0.299388</td>\n",
       "      <td>1.077583</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.257886</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.198538</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.226480</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.400729</td>\n",
       "      <td>1.575125</td>\n",
       "      <td>1.395473</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126763</td>\n",
       "      <td>0.113263</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.081638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105362</td>\n",
       "      <td>0.128186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.107062</td>\n",
       "      <td>0.086649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125751</td>\n",
       "      <td>0.218471</td>\n",
       "      <td>0.142200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.195683</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111746</td>\n",
       "      <td>0.120832</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.120993</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.223069</td>\n",
       "      <td>0.117846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.198113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133816</td>\n",
       "      <td>0.181835</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.555981</td>\n",
       "      <td>-0.299388</td>\n",
       "      <td>-0.193980</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 303 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   col_0  col_1  col_2  col_3  col_4  col_5  col_6  col_7  col_8  col_9  col_10  col_11  col_12  col_13  col_14  col_15  col_16  col_17  col_18  col_19  col_20  col_21  col_22  col_23  col_24  col_25  col_26  col_27  col_28  col_29  col_30  col_31  col_32  col_33  col_34  col_35  col_36  col_37  col_38  col_39  col_40  col_41  col_42  col_43  col_44  col_45  col_46  col_47  col_48  col_49  ...   col_253   col_254   col_255   col_256  col_257   col_258  col_259   col_260   col_261  col_262   col_263   col_264   col_265   col_266  col_267   col_268  col_269   col_270   col_271   col_272  col_273   col_274  col_275  col_276   col_277   col_278   col_279   col_280   col_281   col_282   col_283   col_284   col_285   col_286  col_287   col_288   col_289   col_290   col_291   col_292  col_293   col_294  col_295   col_296   col_297  col_298   col_299   col_300   col_301  target\n",
       "0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  ...  0.000000  0.000000  0.000000  0.171825      0.0  0.137765      0.0  0.000000  0.283609      0.0  0.220992  0.151594  0.000000  0.000000      0.0  0.000000      0.0  0.000000  0.144907  0.000000      0.0  0.158869      0.0      0.0  0.000000  0.170202  0.000000  0.192465  0.190783  0.000000  0.132427  0.176639  0.151246  0.000000      0.0  0.000000  0.000000  0.257843  0.000000  0.000000      0.0  0.000000      0.0  0.000000  0.000000      0.0 -0.452479  0.950288 -0.829762       1\n",
       "1    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  ...  0.000000  0.000000  0.000000  0.000000      0.0  0.228484      0.0  0.000000  0.000000      0.0  0.000000  0.000000  0.000000  0.000000      0.0  0.000000      0.0  0.000000  0.000000  0.000000      0.0  0.000000      0.0      0.0  0.256152  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.250843  0.000000      0.0  0.000000  0.000000  0.213817  0.000000  0.000000      0.0  0.000000      0.0  0.000000  0.000000      0.0 -0.555981 -0.299388 -0.511871       1\n",
       "2    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  ...  0.000000  0.000000  0.141649  0.000000      0.0  0.000000      0.0  0.172449  0.000000      0.0  0.000000  0.000000  0.000000  0.000000      0.0  0.307225      0.0  0.178193  0.000000  0.000000      0.0  0.000000      0.0      0.0  0.000000  0.000000  0.000000  0.210999  0.209155  0.209619  0.000000  0.000000  0.414527  0.179294      0.0  0.000000  0.000000  0.141336  0.000000  0.000000      0.0  0.000000      0.0  0.000000  0.000000      0.0 -0.555981 -0.299388  1.077583       1\n",
       "3    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  ...  0.000000  0.000000  0.000000  0.000000      0.0  0.000000      0.0  0.000000  0.000000      0.0  0.000000  0.000000  0.000000  0.000000      0.0  0.257886      0.0  0.000000  0.000000  0.000000      0.0  0.000000      0.0      0.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000      0.0  0.000000  0.198538  0.000000  0.000000  0.000000      0.0  0.000000      0.0  0.000000  0.226480      0.0 -0.400729  1.575125  1.395473       1\n",
       "4    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  ...  0.126763  0.113263  0.000000  0.000000      0.0  0.000000      0.0  0.000000  0.000000      0.0  0.081638  0.000000  0.105362  0.128186      0.0  0.000000      0.0  0.000000  0.107062  0.086649      0.0  0.000000      0.0      0.0  0.000000  0.125751  0.218471  0.142200  0.000000  0.000000  0.195683  0.000000  0.111746  0.120832      0.0  0.120993  0.000000  0.000000  0.223069  0.117846      0.0  0.198113      0.0  0.133816  0.181835      0.0 -0.555981 -0.299388 -0.193980       1\n",
       "\n",
       "[5 rows x 303 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.sparse\n",
    "\n",
    "df = pd.DataFrame.sparse.from_spmatrix(X)\n",
    "\n",
    "df.columns = ['col_{}'.format(i) for i in range(input_dim)]\n",
    "\n",
    "df = df.fillna(0)\n",
    "\n",
    "df['target']= y\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e0391099-cff7-4139-9be6-2ce4d3e6e94c",
     "showTitle": false,
     "title": ""
    },
    "id": "7Hca9pLmI3ru"
   },
   "source": [
    "## Train with Spark NLP Generic Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fc2fd4cc-f6a1-4315-a4cb-f9861d1339a0",
     "showTitle": false,
     "title": ""
    },
    "id": "B6aaf2dGI3ru"
   },
   "source": [
    "**Building a pipeline**\n",
    "\n",
    "The FeaturesAssembler is used to collect features from different columns. It can collect features from single value columns (anything which can be cast to a float, if casts fails then the value is set to 0), array columns or SparkNLP annotations (if the annotation is an embedding, it takes the embedding, otherwise tries to cast the 'result' field). The output of the transformer is a FEATURE_VECTOR annotation (the numeric vector is in the 'embeddings' field).\n",
    "\n",
    "The GenericClassifierApproach takes FEATURE_VECTOR annotations as input, classifies them and outputs CATEGORY annotations. The operation of the classifier is controled by the following methods:\n",
    "\n",
    "*setEpochsNumber(int)* - Determines how many epochs the model is trained.\n",
    "\n",
    "*setBatchSize(int)* - Sets the batch size during training.\n",
    "\n",
    "*setLearningRate(float)* - Sets the learning rate.\n",
    "\n",
    "*setValidationSplit(float)* - Sets the proportion of examples in the training set used for validation.\n",
    "\n",
    "*setModelFile(string)* - Loads a model from the specified location and uses it instead of the default model.\n",
    "\n",
    "*setFixImbalance(boolean)* - If set to true, it tries to balance the training set by weighting the classes according to the inverse of the examples they have.\n",
    "\n",
    "*setFeatureScaling(string)* - Normalizes the feature factors using the specified method (\"zscore\", \"minmax\" or empty for no normalization).\n",
    "\n",
    "*setOutputLogsPath(string)* - Sets the path to a folder where logs of training progress will be saved. No logs are generated if no path is specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "206a4ba2-c7c0-4c65-b413-f199a17ca386",
     "showTitle": false,
     "title": ""
    },
    "id": "GA2ixcW1I3rv",
    "outputId": "79fae49b-e5f0-4bc7-bc13-2b7bf3754590"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/spark/python/pyspark/sql/pandas/conversion.py:401: UserWarning: createDataFrame attempted Arrow optimization because 'spark.sql.execution.arrow.pyspark.enabled' is set to true; however, failed by the reason below:\n  Sparse pandas data (column col_0) not supported.\nAttempting non-optimization as 'spark.sql.execution.arrow.pyspark.fallback.enabled' is set to true.\n  warn(msg)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+-------+-------------------+--------------------+-------------------+------+\n|col_293|col_294|col_295|col_296|col_297|col_298|            col_299|             col_300|            col_301|target|\n+-------+-------+-------+-------+-------+-------+-------------------+--------------------+-------------------+------+\n|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|-0.4524794726808656|  0.9502875792756131|-0.8297616989552165|     1|\n|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0| -0.555981017719065|-0.29938816657135553|-0.5118709929431844|     1|\n+-------+-------+-------+-------+-------+-------+-------------------+--------------------+-------------------+------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "spark_df = spark.createDataFrame(df)\n",
    "spark_df.select(spark_df.columns[-10:]).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34869e9d-de62-4dc5-a7d0-5ada9c2d2f83",
     "showTitle": false,
     "title": ""
    },
    "id": "wHQkfrcBI3rv",
    "outputId": "b11ee4c7-f924-4b43-aa21-b4bb7be0ec6d"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 9169\nTest Dataset Count: 2368\n"
     ]
    }
   ],
   "source": [
    "(training_data, test_data) = spark_df.randomSplit([0.8, 0.2], seed = 100)\n",
    "\n",
    "print(\"Training Dataset Count: \" + str(training_data.count()))\n",
    "print(\"Test Dataset Count: \" + str(test_data.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f059d942-31f0-4e39-83f6-15e47842e264",
     "showTitle": false,
     "title": ""
    },
    "id": "D0zmFqzwI3rv"
   },
   "source": [
    "Training with a custom graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6aba9495-ff96-4e92-9c5e-913b41d75416",
     "showTitle": false,
     "title": ""
    },
    "id": "CTtxRBfoI3rw"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\n!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Healthcare/generic_classifier_graph/pet.in1202D.out2.pb -P /databricks/driver/gc_graph\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#or just use the one we already have in the repo\n",
    "'''\n",
    "!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Healthcare/generic_classifier_graph/pet.in1202D.out2.pb -P /databricks/driver/gc_graph\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c32371b-86f8-492f-9c8a-a0536961c310",
     "showTitle": false,
     "title": ""
    },
    "id": "RwkA_ugpI3rw",
    "outputId": "39c873a5-2aed-4295-b98b-5a7da9faaf8e"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">res0: Boolean = true\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">res0: Boolean = true\n</div>",
       "datasetInfos": [],
       "metadata": {
        "isDbfsCommandResult": false
       },
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs mkdirs file:/dbfs/gc_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31f1efeb-65a1-4ed6-8208-d169e0e76c6d",
     "showTitle": false,
     "title": ""
    },
    "id": "BEfjQZV9I3rw",
    "outputId": "140459f0-e6cf-4b37-cb77-23f73461b999"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">res1: Boolean = true\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">res1: Boolean = true\n</div>",
       "datasetInfos": [],
       "metadata": {
        "isDbfsCommandResult": false
       },
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs mkdirs file:/dbfs/generic_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ebbcb949-ed47-4b03-9e2d-999e429f5bab",
     "showTitle": false,
     "title": ""
    },
    "id": "wihiDXVqI3rw"
   },
   "source": [
    "Graph and log folder has been created. <br/>\n",
    "We will create a custom graph and train the model. <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "994df1e9-2222-47c7-8773-2fac82663a94",
     "showTitle": false,
     "title": ""
    },
    "id": "IFf7bzxRI3rw",
    "outputId": "fc4f88f3-52f2-4006-b4c6-beff0bf1fc8c"
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from sparknlp_jsl.training import tf_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "977ca63b-79b6-4416-be3e-55e9ed868234",
     "showTitle": false,
     "title": ""
    },
    "id": "la3mw2oEI3rx",
    "outputId": "351708b7-94cd-48dd-be92-021b18644627"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n\nTensorFlow Addons (TFA) has ended development and introduction of new features.\nTFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\nPlease modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n\nFor more information see: https://github.com/tensorflow/addons/issues/2807 \n\n  warnings.warn(\nWARNING:tensorflow:From /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.10/site-packages/keras/layers/normalization/batch_normalization.py:581: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generic_classifier graph exported to file:/dbfs/gc_graph/gcl.302.2.pb\n"
     ]
    }
   ],
   "source": [
    "DL_params = {\"input_dim\": input_dim, \n",
    "             \"output_dim\": y.nunique(), \n",
    "             \"hidden_layers\": [300, 200, 100], \n",
    "             \"hidden_act\": \"tanh\",\n",
    "             'hidden_act_l2':1,\n",
    "             'batch_norm':1}\n",
    "\n",
    "\n",
    "tf_graph.build(\"generic_classifier\",\n",
    "               build_params=DL_params, \n",
    "               model_location=\"file:/dbfs/gc_graph\",\n",
    "               model_filename=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3b8145d-a749-445e-830e-620a479ab6b2",
     "showTitle": false,
     "title": ""
    },
    "id": "kWQ9rUToI3rx",
    "outputId": "e4895998-e4a5-4fc9-c120-b5957dbb16b7"
   },
   "outputs": [],
   "source": [
    "from sparknlp_jsl.base import *\n",
    "\n",
    "\n",
    "features_asm = FeaturesAssembler()\\\n",
    "      .setInputCols(['col_{}'.format(i) for i in range(X.shape[1])])\\\n",
    "      .setOutputCol(\"features\")\n",
    "\n",
    "gen_clf = GenericClassifierApproach()\\\n",
    "    .setLabelColumn(\"target\")\\\n",
    "    .setInputCols([\"features\"])\\\n",
    "    .setOutputCol(\"prediction\")\\\n",
    "    .setModelFile('file:/dbfs/gc_graph/gcl.302.2.pb')\\\n",
    "    .setEpochsNumber(50)\\\n",
    "    .setBatchSize(100)\\\n",
    "    .setFeatureScaling(\"zscore\")\\\n",
    "    .setFixImbalance(True)\\\n",
    "    .setLearningRate(0.001)\\\n",
    "    .setOutputLogsPath(\"dbfs:/generic_logs\")\\\n",
    "    .setValidationSplit(0.2) # keep 20% of the data for validation purposes\n",
    "\n",
    "clf_Pipeline = Pipeline(stages=[\n",
    "    features_asm, \n",
    "    gen_clf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dff22e0a-e39e-4cc6-8138-6580cf78629d",
     "showTitle": false,
     "title": ""
    },
    "id": "RbD3kxGHI3ry",
    "outputId": "30ef9b78-b3c0-4853-ca41-d96e9103f0a3"
   },
   "outputs": [],
   "source": [
    "clf_model = clf_Pipeline.fit(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "48691c93-125b-4d8e-97ee-d28877ce35a6",
     "showTitle": false,
     "title": ""
    },
    "id": "avkdhKr6I3rz"
   },
   "source": [
    "Getting predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de530d22-8dc0-4c66-9c60-818a72880514",
     "showTitle": false,
     "title": ""
    },
    "id": "HdAh0aS1I3rz",
    "outputId": "91f8aa2d-29a0-474a-c693-121ec9d3371d"
   },
   "outputs": [],
   "source": [
    "pred_df = clf_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ddaddad-bcb8-43a5-b74f-ae0895180ccb",
     "showTitle": false,
     "title": ""
    },
    "id": "JW-ZCgSLI3rz",
    "outputId": "4225ec53-ae27-4798-f29a-11a845640969"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n|target|result|\n+------+------+\n|     0|   [0]|\n|     1|   [1]|\n|     1|   [1]|\n|     1|   [1]|\n|     1|   [1]|\n|     1|   [1]|\n|     0|   [1]|\n|     1|   [1]|\n|     1|   [1]|\n|     1|   [1]|\n|     1|   [1]|\n|     1|   [1]|\n|     0|   [1]|\n|     1|   [1]|\n|     0|   [1]|\n|     1|   [1]|\n|     1|   [1]|\n|     1|   [1]|\n|     0|   [0]|\n|     1|   [1]|\n+------+------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "pred_df.select('target','prediction.result').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6304e396-c975-4153-a95c-6bbffc240938",
     "showTitle": false,
     "title": ""
    },
    "id": "_klzhdcDI3rz",
    "outputId": "0a17eb11-d0d5-4dff-dfe5-4a513b7a1936"
   },
   "outputs": [],
   "source": [
    "preds_df = pred_df.select('target','prediction.result').toPandas()\n",
    "\n",
    "# Let's explode the array and get the item(s) inside of result column out\n",
    "preds_df['result'] = preds_df['result'].apply(lambda x : int(x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e35c94c-e76d-42b0-91af-6186d91a4856",
     "showTitle": false,
     "title": ""
    },
    "id": "OWLMFkLGI3r0",
    "outputId": "fd76a9b5-a251-49ae-de89-2f008b1bc6ae"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n\n           0     0.4834    0.5323    0.5066       573\n           1     0.8457    0.8184    0.8318      1795\n\n    accuracy                         0.7492      2368\n   macro avg     0.6645    0.6753    0.6692      2368\nweighted avg     0.7580    0.7492    0.7531      2368\n\n0.7491554054054054\n"
     ]
    }
   ],
   "source": [
    "# We are going to use sklearn to evalute the results on test dataset\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "print (classification_report(preds_df['result'], preds_df['target'], digits=4))\n",
    "\n",
    "print (accuracy_score(preds_df['result'], preds_df['target']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6216c6a2-0262-46c9-8019-39f47e98fbb2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Create a custom DL architecture with TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1736a838-ba7f-47f1-a83f-f1ce99bfb41d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# !pip install -q tensorflow==2.12.0 tensorflow_addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "973d9a46-6efa-4537-b0a2-4695730e3914",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sparknlp_jsl.annotator import TFGraphBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06ba203e-7954-4aef-8a91-d88696aff3ba",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "graph_folder = \"file:/dbfs/gc_graph\"\n",
    "\n",
    "gc_graph_builder = TFGraphBuilder()\\\n",
    "    .setModelName(\"generic_classifier\")\\\n",
    "    .setInputCols([\"features\"])\\\n",
    "    .setLabelColumn(\"target\")\\\n",
    "    .setHiddenLayers([300, 200, 100])\\\n",
    "    .setHiddenAct(\"tanh\")\\\n",
    "    .setHiddenActL2(True)\\\n",
    "    .setBatchNorm(True)\\\n",
    "    .setGraphFolder(graph_folder)\\\n",
    "    .setGraphFile(\"gcf_graph.pb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc9f1732-4904-450c-a8f6-fd73bcb3ad48",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\n# or just use the one we already have in the repo\\n\\n!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Healthcare/generic_classifier_graph/pet.in1202D.out2.pb -P /content/gc_graph\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Create custom graph\n",
    "\n",
    "# If this method is used, graph folder should be added to training\n",
    "# model as `.setGraphFolder(graph_folder_path)`\n",
    "\n",
    "from sparknlp_jsl.training import tf_graph\n",
    "\n",
    "!mkdir gc_graph\n",
    "\n",
    "tf_graph.print_model_params(\"generic_classifier\")\n",
    "\n",
    "DL_params = {\"input_dim\": input_dim,\n",
    "             \"output_dim\": y.nunique(),\n",
    "             \"hidden_layers\": [300, 200, 100],\n",
    "             \"hidden_act\": \"tanh\",\n",
    "             'hidden_act_l2':1,\n",
    "             'batch_norm':1}\n",
    "\n",
    "\n",
    "tf_graph.build(\"generic_classifier\",\n",
    "               build_params=DL_params,\n",
    "               model_location=\"/content/gc_graph\",\n",
    "               model_filename=\"auto\")\n",
    "'''\n",
    "\n",
    "'''\n",
    "# or just use the one we already have in the repo\n",
    "\n",
    "!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Healthcare/generic_classifier_graph/pet.in1202D.out2.pb -P /content/gc_graph\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eea0df6d-4e59-4212-bd6f-83b42077e077",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory â€˜logsâ€™: File exists\r\n"
     ]
    }
   ],
   "source": [
    "from sparknlp_jsl.base import *\n",
    "\n",
    "!mkdir logs\n",
    "\n",
    "features_asm = FeaturesAssembler()\\\n",
    "    .setInputCols(['col_{}'.format(i) for i in range(X.shape[1])])\\\n",
    "    .setOutputCol(\"features\")\n",
    "\n",
    "gen_clf = GenericClassifierApproach()\\\n",
    "    .setLabelColumn(\"target\")\\\n",
    "    .setInputCols(\"features\")\\\n",
    "    .setOutputCol(\"prediction\")\\\n",
    "    .setModelFile(f\"{graph_folder}/gcf_graph.pb\")\\\n",
    "    .setEpochsNumber(50)\\\n",
    "    .setBatchSize(100)\\\n",
    "    .setFeatureScaling(\"zscore\")\\\n",
    "    .setFixImbalance(True)\\\n",
    "    .setLearningRate(0.002)\\\n",
    "    .setOutputLogsPath(\"logs\")\\\n",
    "    .setValidationSplit(0.2) # keep 20% of the data for validation purposes\n",
    "\n",
    "clf_Pipeline = Pipeline(stages=[\n",
    "    features_asm,\n",
    "    gc_graph_builder,\n",
    "    gen_clf])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0da2b711-02fa-482c-87fe-5b32edb28f80",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Graph Builder configuration:\nModel name: generic_classifier\nGraph folder: file:/dbfs/gc_graph\nGraph file name: gcf_graph.pb\nBuild params: {'input_dim': 302, 'output_dim': 2, 'hidden_layers': [300, 200, 100], 'hidden_act': 'tanh', 'hidden_act_l2': True, 'batch_norm': True}\ngeneric_classifier graph exported to file:/dbfs/gc_graph/gcf_graph.pb\nCPU times: user 1.03 s, sys: 40.1 ms, total: 1.07 s\nWall time: 18.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# train 50 epochs (takes around 1 min)\n",
    "\n",
    "clf_model = clf_Pipeline.fit(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a13aa5a6-fc6d-437c-8614-7f00dcab6d02",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONF_DRIVER_JAVA_OPTS = -Djava.io.tmpdir=/local_disk0/tmp -XX:-OmitStackTraceInFastThrow -Djava.security.properties=/databricks/spark/dbconf/java/extra.security -XX:-UseContainerSupport -XX:+PrintFlagsFinal -XX:+PrintGCDateStamps -XX:+PrintGCDetails -verbose:gc -Xss4m -Djava.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni -Djavax.xml.datatype.DatatypeFactory=com.sun.org.apache.xerces.internal.jaxp.datatype.DatatypeFactoryImpl -Djavax.xml.parsers.DocumentBuilderFactory=com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderFactoryImpl -Djavax.xml.parsers.SAXParserFactory=com.sun.org.apache.xerces.internal.jaxp.SAXParserFactoryImpl -Djavax.xml.validation.SchemaFactory:http://www.w3.org/2001/XMLSchema=com.sun.org.apache.xerces.internal.jaxp.validation.XMLSchemaFactory -Dorg.xml.sax.driver=com.sun.org.apache.xerces.internal.parsers.SAXParser -Dorg.w3c.dom.DOMImplementationSourceList=com.sun.org.apache.xerces.internal.dom.DOMXSImplementationSourceImpl -Djavax.net.ssl.sessionCacheSize=10000 -Dscala.reflect.runtime.disable.typetag.cache=true -Dcom.google.cloud.spark.bigquery.repackaged.io.netty.tryReflectionSetAccessible=true -Dlog4j2.formatMsgNoLookups=true -Dspark.jsl.settings.pretrained.credentials.secret_access_key=REDACTED_POSSIBLE_SECRET_ACCESS_KEY -Dspark.jsl.settings.pretrained.credentials.access_key_id=REDACTED_ACCESS_KEY(9e0d55b1)  -Ddatabricks.serviceName=driver-1 -Xms17385m -Xmx17385m -Dspark.ui.port=40001 -Dspark.driver.extraJavaOptions=\"-Dspark.jsl.settings.pretrained.credentials.secret_access_key=REDACTED_POSSIBLE_SECRET_ACCESS_KEY -Dspark.jsl.settings.pretrained.credentials.access_key_id=REDACTED_ACCESS_KEY(9e0d55b1)\"\nCONF_EXECUTOR_JAVA_OPTS = -Dspark.executor.extraJavaOptions=\"-Djava.io.tmpdir=/local_disk0/tmp -XX:ReservedCodeCacheSize=512m -XX:+UseCodeCacheFlushing -XX:PerMethodRecompilationCutoff=-1 -XX:PerBytecodeRecompilationCutoff=-1 -Djava.security.properties=/databricks/spark/dbconf/java/extra.security -XX:-UseContainerSupport -XX:+PrintFlagsFinal -XX:+PrintGCDateStamps -XX:+PrintGCDetails -verbose:gc -Xss4m -Djava.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni -Djavax.xml.datatype.DatatypeFactory=com.sun.org.apache.xerces.internal.jaxp.datatype.DatatypeFactoryImpl -Djavax.xml.parsers.DocumentBuilderFactory=com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderFactoryImpl -Djavax.xml.parsers.SAXParserFactory=com.sun.org.apache.xerces.internal.jaxp.SAXParserFactoryImpl -Djavax.xml.validation.SchemaFactory:http://www.w3.org/2001/XMLSchema=com.sun.org.apache.xerces.internal.jaxp.validation.XMLSchemaFactory -Dorg.xml.sax.driver=com.sun.org.apache.xerces.internal.parsers.SAXParser -Dorg.w3c.dom.DOMImplementationSourceList=com.sun.org.apache.xerces.internal.dom.DOMXSImplementationSourceImpl -Djavax.net.ssl.sessionCacheSize=10000 -Dscala.reflect.runtime.disable.typetag.cache=true -Dcom.google.cloud.spark.bigquery.repackaged.io.netty.tryReflectionSetAccessible=true -Dlog4j2.formatMsgNoLookups=true -verbose:gc -Xloggc:/dev/stdout -verbose:class -XX:+UnlockDiagnosticVMOptions -XX:+LogVMOutput -XX:-DisplayVMOutput -XX:LogFile=/databricks/databricks_vm_pipe -Ddatabricks.vmLog.pipe=/databricks/databricks_vm_pipe   -Ddatabricks.serviceName=spark-executor-1\" -Dspark.executor.memory=18409m\nJAVA_OPTS = -verbose:gc -Xloggc:/dev/stdout -verbose:class -XX:+UnlockDiagnosticVMOptions -XX:+LogVMOutput -XX:-DisplayVMOutput -XX:LogFile=/databricks/databricks_vm_pipe -Ddatabricks.vmLog.pipe=/databricks/databricks_vm_pipe  -Djava.io.tmpdir=/local_disk0/tmp -XX:-OmitStackTraceInFastThrow -Djava.security.properties=/databricks/spark/dbconf/java/extra.security -XX:-UseContainerSupport -XX:+PrintFlagsFinal -XX:+PrintGCDateStamps -XX:+PrintGCDetails -verbose:gc -Xss4m -Djava.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni -Djavax.xml.datatype.DatatypeFactory=com.sun.org.apache.xerces.internal.jaxp.datatype.DatatypeFactoryImpl -Djavax.xml.parsers.DocumentBuilderFactory=com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderFactoryImpl -Djavax.xml.parsers.SAXParserFactory=com.sun.org.apache.xerces.internal.jaxp.SAXParserFactoryImpl -Djavax.xml.validation.SchemaFactory:http://www.w3.org/2001/XMLSchema=com.sun.org.apache.xerces.internal.jaxp.validation.XMLSchemaFactory -Dorg.xml.sax.driver=com.sun.org.apache.xerces.internal.parsers.SAXParser -Dorg.w3c.dom.DOMImplementationSourceList=com.sun.org.apache.xerces.internal.dom.DOMXSImplementationSourceImpl -Djavax.net.ssl.sessionCacheSize=10000 -Dscala.reflect.runtime.disable.typetag.cache=true -Dcom.google.cloud.spark.bigquery.repackaged.io.netty.tryReflectionSetAccessible=true -Dlog4j2.formatMsgNoLookups=true -Dspark.jsl.settings.pretrained.credentials.secret_access_key=REDACTED_POSSIBLE_SECRET_ACCESS_KEY -Dspark.jsl.settings.pretrained.credentials.access_key_id=REDACTED_ACCESS_KEY(9e0d55b1)  -Ddatabricks.serviceName=driver-1 -Xms17385m -Xmx17385m -Dspark.ui.port=40001 -Dspark.driver.extraJavaOptions=\"-Dspark.jsl.settings.pretrained.credentials.secret_access_key=REDACTED_POSSIBLE_SECRET_ACCESS_KEY -Dspark.jsl.settings.pretrained.credentials.access_key_id=REDACTED_ACCESS_KEY(9e0d55b1)\" -Dspark.executor.extraJavaOptions=\"-Djava.io.tmpdir=/local_disk0/tmp -XX:ReservedCodeCacheSize=512m -XX:+UseCodeCacheFlushing -XX:PerMethodRecompilationCutoff=-1 -XX:PerBytecodeRecompilationCutoff=-1 -Djava.security.properties=/databricks/spark/dbconf/java/extra.security -XX:-UseContainerSupport -XX:+PrintFlagsFinal -XX:+PrintGCDateStamps -XX:+PrintGCDetails -verbose:gc -Xss4m -Djava.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni -Djavax.xml.datatype.DatatypeFactory=com.sun.org.apache.xerces.internal.jaxp.datatype.DatatypeFactoryImpl -Djavax.xml.parsers.DocumentBuilderFactory=com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderFactoryImpl -Djavax.xml.parsers.SAXParserFactory=com.sun.org.apache.xerces.internal.jaxp.SAXParserFactoryImpl -Djavax.xml.validation.SchemaFactory:http://www.w3.org/2001/XMLSchema=com.sun.org.apache.xerces.internal.jaxp.validation.XMLSchemaFactory -Dorg.xml.sax.driver=com.sun.org.apache.xerces.internal.parsers.SAXParser -Dorg.w3c.dom.DOMImplementationSourceList=com.sun.org.apache.xerces.internal.dom.DOMXSImplementationSourceImpl -Djavax.net.ssl.sessionCacheSize=10000 -Dscala.reflect.runtime.disable.typetag.cache=true -Dcom.google.cloud.spark.bigquery.repackaged.io.netty.tryReflectionSetAccessible=true -Dlog4j2.formatMsgNoLookups=true -verbose:gc -Xloggc:/dev/stdout -verbose:class -XX:+UnlockDiagnosticVMOptions -XX:+LogVMOutput -XX:-DisplayVMOutput -XX:LogFile=/databricks/databricks_vm_pipe -Ddatabricks.vmLog.pipe=/databricks/databricks_vm_pipe   -Ddatabricks.serviceName=spark-executor-1\" -Dspark.executor.memory=18409m -Dspark.executor.extraClassPath=/databricks/spark/dbconf/log4j/executor:/databricks/spark/dbconf/jets3t/:/databricks/spark/dbconf/hadoop:/databricks/hive/conf:/databricks/jars/*\nUsing Spark master spark://10.139.64.11:7077\nSat Sep 23 18:24:57 UTC 2023\nStarting driver\nDriver command is /usr/lib/jvm/zulu8-ca-amd64/jre//bin/java -verbose:gc -Xloggc:/dev/stdout -verbose:class -XX:+UnlockDiagnosticVMOptions -XX:+LogVMOutput -XX:-DisplayVMOutput -XX:LogFile=/databricks/databricks_vm_pipe -Ddatabricks.vmLog.pipe=/databricks/databricks_vm_pipe  -Djava.io.tmpdir=/local_disk0/tmp -XX:-OmitStackTraceInFastThrow -Djava.security.properties=/databricks/spark/dbconf/java/extra.security -XX:-UseContainerSupport -XX:+PrintFlagsFinal -XX:+PrintGCDateStamps -XX:+PrintGCDetails -verbose:gc -Xss4m -Djava.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni -Djavax.xml.datatype.DatatypeFactory=com.sun.org.apache.xerces.internal.jaxp.datatype.DatatypeFactoryImpl -Djavax.xml.parsers.DocumentBuilderFactory=com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderFactoryImpl -Djavax.xml.parsers.SAXParserFactory=com.sun.org.apache.xerces.internal.jaxp.SAXParserFactoryImpl -Djavax.xml.validation.SchemaFactory:http://www.w3.org/2001/XMLSchema=com.sun.org.apache.xerces.internal.jaxp.validation.XMLSchemaFactory -Dorg.xml.sax.driver=com.sun.org.apache.xerces.internal.parsers.SAXParser -Dorg.w3c.dom.DOMImplementationSourceList=com.sun.org.apache.xerces.internal.dom.DOMXSImplementationSourceImpl -Djavax.net.ssl.sessionCacheSize=10000 -Dscala.reflect.runtime.disable.typetag.cache=true -Dcom.google.cloud.spark.bigquery.repackaged.io.netty.tryReflectionSetAccessible=true -Dlog4j2.formatMsgNoLookups=true -Dspark.jsl.settings.pretrained.credentials.secret_access_key=REDACTED_POSSIBLE_SECRET_ACCESS_KEY -Dspark.jsl.settings.pretrained.credentials.access_key_id=REDACTED_ACCESS_KEY(9e0d55b1)  -Ddatabricks.serviceName=driver-1 -Xms17385m -Xmx17385m -Dspark.ui.port=40001 -Dspark.driver.extraJavaOptions=\"-Dspark.jsl.settings.pretrained.credentials.secret_access_key=REDACTED_POSSIBLE_SECRET_ACCESS_KEY -Dspark.jsl.settings.pretrained.credentials.access_key_id=REDACTED_ACCESS_KEY(9e0d55b1)\" -Dspark.executor.extraJavaOptions=\"-Djava.io.tmpdir=/local_disk0/tmp -XX:ReservedCodeCacheSize=512m -XX:+UseCodeCacheFlushing -XX:PerMethodRecompilationCutoff=-1 -XX:PerBytecodeRecompilationCutoff=-1 -Djava.security.properties=/databricks/spark/dbconf/java/extra.security -XX:-UseContainerSupport -XX:+PrintFlagsFinal -XX:+PrintGCDateStamps -XX:+PrintGCDetails -verbose:gc -Xss4m -Djava.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni -Djavax.xml.datatype.DatatypeFactory=com.sun.org.apache.xerces.internal.jaxp.datatype.DatatypeFactoryImpl -Djavax.xml.parsers.DocumentBuilderFactory=com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderFactoryImpl -Djavax.xml.parsers.SAXParserFactory=com.sun.org.apache.xerces.internal.jaxp.SAXParserFactoryImpl -Djavax.xml.validation.SchemaFactory:http://www.w3.org/2001/XMLSchema=com.sun.org.apache.xerces.internal.jaxp.validation.XMLSchemaFactory -Dorg.xml.sax.driver=com.sun.org.apache.xerces.internal.parsers.SAXParser -Dorg.w3c.dom.DOMImplementationSourceList=com.sun.org.apache.xerces.internal.dom.DOMXSImplementationSourceImpl -Djavax.net.ssl.sessionCacheSize=10000 -Dscala.reflect.runtime.disable.typetag.cache=true -Dcom.google.cloud.spark.bigquery.repackaged.io.netty.tryReflectionSetAccessible=true -Dlog4j2.formatMsgNoLookups=true -verbose:gc -Xloggc:/dev/stdout -verbose:class -XX:+UnlockDiagnosticVMOptions -XX:+LogVMOutput -XX:-DisplayVMOutput -XX:LogFile=/databricks/databricks_vm_pipe -Ddatabricks.vmLog.pipe=/databricks/databricks_vm_pipe   -Ddatabricks.serviceName=spark-executor-1\" -Dspark.executor.memory=18409m -Dspark.executor.extraClassPath=/databricks/spark/dbconf/log4j/executor:/databricks/spark/dbconf/jets3t/:/databricks/spark/dbconf/hadoop:/databricks/hive/conf:/databricks/jars/* -cp /databricks/spark/dbconf/jets3t/:/databricks/spark/dbconf/log4j/driver:/databricks/hive/conf:/databricks/spark/dbconf/hadoop:/databricks/jars/* com.databricks.backend.daemon.driver.DriverDaemon &\nWorking directory is /databricks/driver\nOpenJDK 64-Bit Server VM (25.372-b07) for linux-amd64 JRE (Zulu 8.70.0.23-CA-linux64) (1.8.0_372-b07), built on Apr 18 2023 08:39:33 by \"zulu_re\" with gcc 7.3.0\nMemory: 4k page, physical 28736088k(11775368k free), swap 10485756k(10485756k free)\nCommandLine flags: -XX:-DisplayVMOutput -XX:InitialHeapSize=18229493760 -XX:LogFile=/databricks/databricks_vm_pipe -XX:+LogVMOutput -XX:MaxHeapSize=18229493760 -XX:-OmitStackTraceInFastThrow -XX:+PrintFlagsFinal -XX:+PrintGC -XX:+PrintGCDateStamps -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:ThreadStackSize=4096 -XX:+TraceClassLoading -XX:+TraceClassUnloading -XX:+UnlockDiagnosticVMOptions -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:-UseContainerSupport -XX:+UseParallelGC \n2023-09-23T18:25:01.456+0000: 3.917: [GC (Metadata GC Threshold) [PSYoungGen: 801239K->23017K(5192704K)] 801239K->23105K(17061888K), 0.0183526 secs] [Times: user=0.04 sys=0.01, real=0.01 secs] \n2023-09-23T18:25:01.474+0000: 3.936: [Full GC (Metadata GC Threshold) [PSYoungGen: 23017K->0K(5192704K)] [ParOldGen: 88K->22184K(11869184K)] 23105K->22184K(17061888K), [Metaspace: 20678K->20665K(1069056K)], 0.0377229 secs] [Times: user=0.14 sys=0.01, real=0.04 secs] \n2023-09-23T18:25:01.854+0000: 4.315: [GC (Metadata GC Threshold) [PSYoungGen: 178053K->8543K(5192704K)] 200237K->30735K(17061888K), 0.0118339 secs] [Times: user=0.03 sys=0.00, real=0.01 secs] \n2023-09-23T18:25:01.866+0000: 4.327: [Full GC (Metadata GC Threshold) [PSYoungGen: 8543K->0K(5192704K)] [ParOldGen: 22192K->18781K(11869184K)] 30735K->18781K(17061888K), [Metaspace: 34739K->34739K(1081344K)], 0.0257403 secs] [Times: user=0.07 sys=0.01, real=0.03 secs] \n2023-09-23T18:25:03.450+0000: 5.911: [GC (Metadata GC Threshold) [PSYoungGen: 623186K->23877K(5192704K)] 641968K->42666K(17061888K), 0.0088402 secs] [Times: user=0.04 sys=0.00, real=0.01 secs] \n2023-09-23T18:25:03.459+0000: 5.920: [Full GC (Metadata GC Threshold) [PSYoungGen: 23877K->0K(5192704K)] [ParOldGen: 18789K->33036K(11869184K)] 42666K->33036K(17061888K), [Metaspace: 58452K->58452K(1101824K)], 0.0763735 secs] [Times: user=0.41 sys=0.00, real=0.08 secs] \n2023-09-23 18:25:07,284 main WARN RollingFileAppender 'publicFile.rolling': The bufferSize is set to 8192 but bufferedIO is not true\n2023-09-23 18:25:07,298 main WARN RollingFileAppender 'privateFile.rolling': The bufferSize is set to 8192 but bufferedIO is not true\n2023-09-23 18:25:07,309 main WARN RollingFileAppender 'com.databricks.UsageLogging.appender': The bufferSize is set to 8192 but bufferedIO is not true\n2023-09-23 18:25:07,313 main WARN RollingFileAppender 'com.databricks.EventLoggingStats.appender': The bufferSize is set to 8192 but bufferedIO is not true\n2023-09-23 18:25:07,316 main WARN RollingFileAppender 'com.databricks.ProductLogging.appender': The bufferSize is set to 8192 but bufferedIO is not true\n2023-09-23 18:25:07,318 main WARN RollingFileAppender 'com.databricks.LineageLogging.appender': The bufferSize is set to 8192 but bufferedIO is not true\n2023-09-23 18:25:07,321 main WARN RollingFileAppender 'com.databricks.MetricsLogging.appender': The bufferSize is set to 8192 but bufferedIO is not true\n2023-09-23 18:25:07,322 main WARN RollingFileAppender 'dltExecution.rolling': The bufferSize is set to 8192 but bufferedIO is not true\n2023-09-23 18:25:07,429 main WARN RollingFileAppender 'com.databricks.logging.structured.FlowLog.appender': The bufferSize is set to 128000 but bufferedIO is not true\n2023-09-23 18:25:07,431 main WARN RollingFileAppender 'com.databricks.logging.structured.SettingsLog.appender': The bufferSize is set to 128000 but bufferedIO is not true\n2023-09-23 18:25:07,433 main WARN RollingFileAppender 'com.databricks.logging.structured.KubernetesEventLog.appender': The bufferSize is set to 128000 but bufferedIO is not true\n2023-09-23 18:25:07,434 main WARN RollingFileAppender 'com.databricks.logging.structured.QueryProfileLog.appender': The bufferSize is set to 128000 but bufferedIO is not true\n2023-09-23 18:25:07,435 main WARN RollingFileAppender 'com.databricks.logging.structured.KubernetesAuditLog.appender': The bufferSize is set to 128000 but bufferedIO is not true\n2023-09-23 18:25:07,437 main WARN RollingFileAppender 'com.databricks.logging.structured.KubernetesObjectLog.appender': The bufferSize is set to 128000 but bufferedIO is not true\n2023-09-23 18:25:07,439 main WARN RollingFileAppender 'com.databricks.logging.structured.ServiceRequestLog.appender': The bufferSize is set to 128000 but bufferedIO is not true\n2023-09-23 18:25:07,440 main WARN RollingFileAppender 'com.databricks.logging.structured.IntegrationTestLog.appender': The bufferSize is set to 128000 but bufferedIO is not true\n2023-09-23 18:25:07,441 main WARN RollingFileAppender 'com.databricks.logging.structured.RequestActivityLog.appender': The bufferSize is set to 128000 but bufferedIO is not true\n2023-09-23 18:25:07,443 main WARN RollingFileAppender 'com.databricks.logging.structured.ServiceHealthEvent.appender': The bufferSize is set to 128000 but bufferedIO is not true\n2023-09-23 18:25:07,444 main WARN RollingFileAppender 'com.databricks.logging.structured.ShadowedServiceRequestLogPipelinedExecution.appender': The bufferSize is set to 128000 but bufferedIO is not true\n2023-09-23 18:25:07,445 main WARN RollingFileAppender 'com.databricks.logging.structured.AppStateLog.appender': The bufferSize is set to 128000 but bufferedIO is not true\n2023-09-23 18:25:07,446 main WARN RollingFileAppender 'com.databricks.logging.structured.BackgroundActivityLog.appender': The bufferSize is set to 128000 but bufferedIO is not true\nDB_HOME: /databricks\n2023-09-23T18:25:09.561+0000: 12.022: [GC (Metadata GC Threshold) [PSYoungGen: 2492748K->45847K(5192704K)] 2525785K->78892K(17061888K), 0.0385703 secs] [Times: user=0.05 sys=0.01, real=0.04 secs] \n2023-09-23T18:25:09.599+0000: 12.061: [Full GC (Metadata GC Threshold) [PSYoungGen: 45847K->0K(5192704K)] [ParOldGen: 33044K->58349K(11869184K)] 78892K->58349K(17061888K), [Metaspace: 97513K->97511K(1138688K)], 0.0475896 secs] [Times: user=0.15 sys=0.01, real=0.05 secs] \n2023-09-23 18:25:11,653 UptimeLogger:driver WARN RollingFileAppender 'com.databricks.UsageLogging.appender': The bufferSize is set to 128000 but bufferedIO is not true\n2023-09-23 18:25:14,062 main WARN RollingFileAppender 'spark_usage': The bufferSize is set to 128000 but bufferedIO is not true\n2023-09-23T18:25:16.505+0000: 18.967: [GC (GCLocker Initiated GC) [PSYoungGen: 4450287K->284036K(5192704K)] 4508636K->342410K(17061888K), 0.1262575 secs] [Times: user=0.46 sys=0.18, real=0.13 secs] \n2023-09-23T18:25:16.645+0000: 19.107: [GC (Metadata GC Threshold) [PSYoungGen: 493314K->221181K(5544960K)] 551688K->324823K(17414144K), 0.0819885 secs] [Times: user=0.44 sys=0.18, real=0.09 secs] \n2023-09-23T18:25:16.727+0000: 19.189: [Full GC (Metadata GC Threshold) [PSYoungGen: 221181K->0K(5544960K)] [ParOldGen: 103641K->288029K(11869184K)] 324823K->288029K(17414144K), [Metaspace: 159059K->159040K(1196032K)], 0.3039776 secs] [Times: user=1.67 sys=0.11, real=0.30 secs] \n2023-09-23T18:25:33.486+0000: 35.948: [GC (Allocation Failure) [PSYoungGen: 5323776K->109887K(5628928K)] 5611805K->397932K(17498112K), 0.0912004 secs] [Times: user=0.21 sys=0.06, real=0.09 secs] \n2023-09-23T18:25:38.127+0000: 40.589: [GC (Metadata GC Threshold) [PSYoungGen: 1112111K->46103K(5663744K)] 1400156K->334164K(17532928K), 0.0266847 secs] [Times: user=0.11 sys=0.02, real=0.02 secs] \n2023-09-23T18:25:38.154+0000: 40.615: [Full GC (Metadata GC Threshold) [PSYoungGen: 46103K->0K(5663744K)] [ParOldGen: 288061K->308446K(11869184K)] 334164K->308446K(17532928K), [Metaspace: 259568K->259146K(1292288K)], 0.4760966 secs] [Times: user=2.25 sys=0.05, real=0.48 secs] \nSat Sep 23 18:25:50 UTC 2023 Starting R processing from BASH\nSat Sep 23 18:25:50 UTC 2023 R script: /local_disk0/tmp/_rServeScript.r8578953705390073049resource.r\nSat Sep 23 18:25:50 UTC 2023 Port number: 1100\nSat Sep 23 18:25:50 UTC 2023 cgroup: None\n2023-09-23 18:25:50 R process started with pid 1118 \n-- running Rserve in this R session (pid=1118), 1 server(s) --\n(This session will block until Rserve is shut down)\nSpark package found in SPARK_HOME: /databricks/spark\nDATABRICKS_STDOUT_END-9929c4b0-c606-4ee6-8869-8b783b1ac38d-1695493552488\n:: loading settings :: url = jar:file:/databricks/jars/----ws_3_4--mvn--hadoop3--org.apache.ivy--ivy--org.apache.ivy__ivy__2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n:: resolving dependencies :: com.databricks#dbc-parent;1.0\n\tconfs: [default]\n\tfound com.johnsnowlabs.nlp#spark-nlp_2.12;5.1.0 in preferred-maven-central-mirror\n\tfound com.typesafe#config;1.4.2 in preferred-maven-central-mirror\n\tfound org.rocksdb#rocksdbjni;6.29.5 in preferred-maven-central-mirror\n\tfound com.amazonaws#aws-java-sdk-bundle;1.11.828 in preferred-maven-central-mirror\n\tfound com.github.universal-automata#liblevenshtein;3.0.0 in preferred-maven-central-mirror\n\tfound com.google.protobuf#protobuf-java-util;3.0.0-beta-3 in preferred-maven-central-mirror\n\tfound com.google.protobuf#protobuf-java;3.0.0-beta-3 in preferred-maven-central-mirror\n\tfound com.google.code.gson#gson;2.3 in preferred-maven-central-mirror\n\tfound it.unimi.dsi#fastutil;7.0.12 in preferred-maven-central-mirror\n\tfound org.projectlombok#lombok;1.16.8 in preferred-maven-central-mirror\n\tfound com.google.cloud#google-cloud-storage;2.20.1 in preferred-maven-central-mirror\n\tfound com.google.guava#guava;31.1-jre in preferred-maven-central-mirror\n\tfound com.google.guava#failureaccess;1.0.1 in preferred-maven-central-mirror\n\tfound com.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava in preferred-maven-central-mirror\n\tfound com.google.errorprone#error_prone_annotations;2.18.0 in preferred-maven-central-mirror\n\tfound com.google.j2objc#j2objc-annotations;1.3 in preferred-maven-central-mirror\n\tfound com.google.http-client#google-http-client;1.43.0 in preferred-maven-central-mirror\n\tfound io.opencensus#opencensus-contrib-http-util;0.31.1 in preferred-maven-central-mirror\n\tfound com.google.http-client#google-http-client-jackson2;1.43.0 in preferred-maven-central-mirror\n\tfound com.google.http-client#google-http-client-gson;1.43.0 in preferred-maven-central-mirror\n\tfound com.google.api-client#google-api-client;2.2.0 in preferred-maven-central-mirror\n\tfound commons-codec#commons-codec;1.15 in preferred-maven-central-mirror\n\tfound com.google.oauth-client#google-oauth-client;1.34.1 in preferred-maven-central-mirror\n\tfound com.google.http-client#google-http-client-apache-v2;1.43.0 in preferred-maven-central-mirror\n\tfound com.google.apis#google-api-services-storage;v1-rev20220705-2.0.0 in preferred-maven-central-mirror\n\tfound com.google.code.gson#gson;2.10.1 in preferred-maven-central-mirror\n\tfound com.google.cloud#google-cloud-core;2.12.0 in preferred-maven-central-mirror\n\tfound io.grpc#grpc-context;1.53.0 in preferred-maven-central-mirror\n\tfound com.google.auto.value#auto-value-annotations;1.10.1 in preferred-maven-central-mirror\n\tfound com.google.auto.value#auto-value;1.10.1 in preferred-maven-central-mirror\n\tfound javax.annotation#javax.annotation-api;1.3.2 in preferred-maven-central-mirror\n\tfound commons-logging#commons-logging;1.2 in preferred-maven-central-mirror\n\tfound com.google.cloud#google-cloud-core-http;2.12.0 in preferred-maven-central-mirror\n\tfound com.google.http-client#google-http-client-appengine;1.43.0 in preferred-maven-central-mirror\n\tfound com.google.api#gax-httpjson;0.108.2 in preferred-maven-central-mirror\n\tfound com.google.cloud#google-cloud-core-grpc;2.12.0 in preferred-maven-central-mirror\n\tfound io.grpc#grpc-alts;1.53.0 in preferred-maven-central-mirror\n\tfound io.grpc#grpc-grpclb;1.53.0 in preferred-maven-central-mirror\n\tfound org.conscrypt#conscrypt-openjdk-uber;2.5.2 in preferred-maven-central-mirror\n\tfound io.grpc#grpc-auth;1.53.0 in preferred-maven-central-mirror\n\tfound io.grpc#grpc-protobuf;1.53.0 in preferred-maven-central-mirror\n\tfound io.grpc#grpc-protobuf-lite;1.53.0 in preferred-maven-central-mirror\n\tfound io.grpc#grpc-core;1.53.0 in preferred-maven-central-mirror\n\tfound com.google.api#gax;2.23.2 in preferred-maven-central-mirror\n\tfound com.google.api#gax-grpc;2.23.2 in preferred-maven-central-mirror\n\tfound com.google.auth#google-auth-library-credentials;1.16.0 in preferred-maven-central-mirror\n\tfound com.google.auth#google-auth-library-oauth2-http;1.16.0 in preferred-maven-central-mirror\n\tfound com.google.api#api-common;2.6.2 in preferred-maven-central-mirror\n\tfound io.opencensus#opencensus-api;0.31.1 in preferred-maven-central-mirror\n\tfound com.google.api.grpc#proto-google-iam-v1;1.9.2 in preferred-maven-central-mirror\n\tfound com.google.protobuf#protobuf-java;3.21.12 in preferred-maven-central-mirror\n\tfound com.google.protobuf#protobuf-java-util;3.21.12 in preferred-maven-central-mirror\n\tfound com.google.api.grpc#proto-google-common-protos;2.14.2 in preferred-maven-central-mirror\n\tfound org.threeten#threetenbp;1.6.5 in preferred-maven-central-mirror\n\tfound com.google.api.grpc#proto-google-cloud-storage-v2;2.20.1-alpha in preferred-maven-central-mirror\n\tfound com.google.api.grpc#grpc-google-cloud-storage-v2;2.20.1-alpha in preferred-maven-central-mirror\n\tfound com.google.api.grpc#gapic-google-cloud-storage-v2;2.20.1-alpha in preferred-maven-central-mirror\n\tfound com.fasterxml.jackson.core#jackson-core;2.14.2 in preferred-maven-central-mirror\n\tfound com.google.code.findbugs#jsr305\n\n*** WARNING: max output size exceeded, skipping output. ***\n\n10 secs] \n2023-09-23T18:48:00.491+0000: 1382.953: [GC (Allocation Failure) [PSYoungGen: 4474396K->377727K(5117952K)] 6177612K->2080950K(16987136K), 0.0509468 secs] [Times: user=0.20 sys=0.00, real=0.05 secs] \n â€” ]\n[ \\ ]\n[ | ]\n[ / ]\n[ â€” ]\n[ \\ ]\n[ | ]\n[ / ]\n[ â€” ]\n[ \\ ]\n[ | ]\n[ / ]\n[ â€” ]\n[ \\ ]\n[ | ]\n[ / ]\n[ â€” ]\n[ \\ ]\n[ | ]\n[ / ]2023-09-23T18:48:25.612+0000: 1408.074: [GC (Allocation Failure) [PSYoungGen: 4652415K->353460K(5090816K)] 6355638K->2056684K(16960000K), 0.0444775 secs] [Times: user=0.21 sys=0.00, real=0.05 secs] \n\n[ â€” ]\n[ \\ ]\n[ | ]\n[ / ]\n[ â€” ]\n[ \\ ]\n[ | ]\n[OK!]\n2023-09-23T18:49:15.063+0000: 1457.525: [GC (Allocation Failure) [PSYoungGen: 4628148K->454413K(5144064K)] 6331372K->2157645K(17013248K), 0.0492323 secs] [Times: user=0.36 sys=0.00, real=0.05 secs] \n2023-09-23T18:50:00.562+0000: 1503.023: [GC (Allocation Failure) [PSYoungGen: 4817677K->739752K(5044736K)] 6520909K->2442992K(16913920K), 0.0403269 secs] [Times: user=0.30 sys=0.00, real=0.04 secs] \n2023-09-23T18:50:43.659+0000: 1546.120: [GC (Allocation Failure) [PSYoungGen: 5044648K->830972K(4266496K)] 6747888K->3182032K(16135680K), 0.2359735 secs] [Times: user=0.76 sys=0.87, real=0.24 secs] \n2023-09-23T18:51:20.810+0000: 1583.271: [GC (Allocation Failure) [PSYoungGen: 4262925K->1019590K(4417024K)] 6613984K->3401009K(16286208K), 0.0620902 secs] [Times: user=0.43 sys=0.02, real=0.06 secs] \n2023-09-23T18:51:46.879+0000: 1609.340: [GC (Allocation Failure) [PSYoungGen: 4416710K->1107171K(4306944K)] 6798129K->3488598K(16176128K), 0.0567380 secs] [Times: user=0.41 sys=0.00, real=0.06 secs] \n2023-09-23T18:51:54.962+0000: 1617.423: [GC (Allocation Failure) [PSYoungGen: 4042979K->1106499K(4014080K)] 6424406K->3487934K(15883264K), 0.0535991 secs] [Times: user=0.38 sys=0.00, real=0.06 secs] \n2023-09-23T18:52:03.294+0000: 1625.756: [GC (Allocation Failure) [PSYoungGen: 4013635K->1106853K(4184064K)] 6395070K->3488288K(16053248K), 0.0586023 secs] [Times: user=0.41 sys=0.00, real=0.05 secs] \n2023-09-23T18:52:10.579+0000: 1633.040: [GC (Allocation Failure) [PSYoungGen: 3692453K->1106857K(3669504K)] 6073888K->3488291K(15538688K), 0.0546747 secs] [Times: user=0.39 sys=0.01, real=0.05 secs] \n2023-09-23T18:52:18.123+0000: 1640.584: [GC (Allocation Failure) [PSYoungGen: 3669417K->1107291K(4125696K)] 6050851K->3488734K(15994880K), 0.0580215 secs] [Times: user=0.42 sys=0.01, real=0.06 secs] \n2023-09-23T18:52:24.950+0000: 1647.412: [GC (Allocation Failure) [PSYoungGen: 3503451K->1107522K(3484160K)] 5884894K->3488973K(15353344K), 0.0557681 secs] [Times: user=0.41 sys=0.01, real=0.06 secs] \nsentence_detector_dl_healthcare download started this may take some time.\nApproximate size to download 367.3 KB\n\n[ | ]sentence_detector_dl_healthcare download started this may take some time.\nApproximate size to download 367.3 KB\nDownload done! Loading the resource.\n\n[OK!]\nembeddings_clinical download started this may take some time.\nApproximate size to download 1.6 GB\n\n[ | ]embeddings_clinical download started this may take some time.\nApproximate size to download 1.6 GB\nDownload done! Loading the resource.\n\n[OK!]\nner_jsl download started this may take some time.\n\n[ | ]ner_jsl download started this may take some time.\nApproximate size to download 14.5 MB\nDownload done! Loading the resource.\n\n[ / ]\n[OK!]\n2023-09-23T18:54:20.913+0000: 1763.375: [GC (Allocation Failure) [PSYoungGen: 3483714K->1152392K(4080128K)] 5865165K->3533851K(15949312K), 0.0629954 secs] [Times: user=0.40 sys=0.00, real=0.07 secs] \n2023-09-23T18:55:18.999+0000: 1821.460: [GC (System.gc()) [PSYoungGen: 1673006K->1151578K(3438592K)] 4054465K->3533037K(15307776K), 0.0619918 secs] [Times: user=0.43 sys=0.00, real=0.06 secs] \n2023-09-23T18:55:19.061+0000: 1821.522: [Full GC (System.gc()) [PSYoungGen: 1151578K->0K(3438592K)] [ParOldGen: 2381458K->1864978K(11869184K)] 3533037K->1864978K(15307776K), [Metaspace: 389453K->386699K(1423360K)], 0.8198526 secs] [Times: user=2.92 sys=0.12, real=0.82 secs] \nsentence_detector_dl_healthcare download started this may take some time.\nApproximate size to download 367.3 KB\n\n[ | ]\n[OK!]\nembeddings_clinical download started this may take some time.\nApproximate size to download 1.6 GB\n\n[ | ]\n[OK!]\nner_clinical_large download started this may take some time.\n\n[ | ]ner_clinical_large download started this may take some time.\nApproximate size to download 13.9 MB\nDownload done! Loading the resource.\n\n[ / ]\n[OK!]\nroot\n |-- index: long (nullable = true)\n |-- text: string (nullable = true)\n\n+-----+--------------------+\n|index|                text|\n+-----+--------------------+\n|    0|Sample Type / Med...|\n|    1|Sample Type / Med...|\n|    2|Sample Type / Med...|\n|    3|Sample Type / Med...|\n|    4|Sample Type / Med...|\n|    5|Sample Type / Med...|\n|    6|Sample Type / Med...|\n|    7|Sample Type / Med...|\n|    8|Sample Type / Med...|\n|    9|Sample Type / Med...|\n+-----+--------------------+\n\nSample Type / Medical Specialty:\nHematology - Oncology\nSample Name:\nDischarge Summary - Mesothelioma - 1\nDescription:\nMesothelioma, pleural effusion, atrial fibrillation, anemia, ascites, esophageal reflux, and history of deep venous thrombosis.\n(Medical Transcription Sample Report)\nPRINCIPAL DIAGNOSIS:\nMesothelioma.\nSECONDARY DIAGNOSES:\nPleural effusion, atrial fibrillation, anemia, ascites, esophageal reflux, and history of deep venous thrombosis.\nPROCEDURES\n1. On August 24, 2007, decortication of the lung with pleural biopsy and transpleural fluoroscopy.\n2. On August 20, 2007, thoracentesis.\n3. On August 31, 2007, Port-A-Cath placement.\nHISTORY AND PHYSICAL:\nThe patient is a 41-year-old Vietnamese female with a nonproductive cough that started last week. She has had right-sided chest pain radiating to her back with fever starting yesterday. She has a history of pericarditis and pericardectomy in May 2006 and developed cough with right-sided chest pain, and went to an urgent care center. Chest x-ray revealed right-sided pleural effusion.\nPAST MEDICAL HISTORY\n1. Pericardectomy.\n2. Pericarditis.\n2. Atrial fibrillation.\n4. RNCA with intracranial thrombolytic treatment.\n5 PTA of MCA.\n6. Mesenteric venous thrombosis.\n7. Pericardial window.\n8. Cholecystectomy.\n9. Left thoracentesis.\nFAMILY HISTORY:\nNo family history of coronary artery disease, CVA, diabetes, CHF or MI. The patient has one family member, a sister, with history of cancer.\nSOCIAL HISTORY:\nShe is married. Employed with the US Post Office. She is a mother of three. Denies tobacco, alcohol or illicit drug use.\nMEDICATIONS\n1. Coumadin 1 mg daily. Last INR was on Tuesday, August 14, 2007, and her INR was 2.3.\n2. Amiodarone 100 mg p.o. daily.\nREVIEW OF SYSTEMS:\nComplete review of systems negative except as in pulmonary as noted above. The patient also reports occasional numbness and tingling of her left arm.\nPHYSICAL EXAMINATION\nVITAL SIGNS: Blood pressure 123/95, heart rate 83, respirations 20, temperature 97, and oxygen saturation 97%.\nGENERAL: Positive nonproductive cough and pain with coughing.\nHEENT: Pupils are equal and reactive to light and accommodation. Tympanic membranes are clear.\nNECK: Supple. No lymphadenopathy. No masses.\nRESPIRATORY: Pleural friction rub is noted.\nGI: Soft, nondistended, and nontender. Positive bowel sounds. No organomegaly.\nEXTREMITIES: No edema, no clubbing, no cyanosis, no tenderness. Full range of motion. Normal pulses in all extremities.\nSKIN: No breakdown or lesions. No ulcers.\nNEUROLOGIC: Grossly intact. No focal deficits. Awake, alert, and oriented to person, place, and time.\nLABORATORY DATA:\nLabs are pending.\nHOSPITAL COURSE:\nThe patient was admitted for a right-sided pleural effusion for thoracentesis on Monday by Dr. X. Her Coumadin was placed on hold. A repeat echocardiogram was checked. She was started on prophylaxis for DVT with Lovenox 40 mg subcutaneously. Her history dated back to March 2005 when she first sought medical attention for evidence of pericarditis, which was treated with pericardial window in an outside hospital, at that time she was also found to have mesenteric pain and thrombosis, is now anticoagulated. Her pericardial fluid was accumulated and she was seen by Dr. Y. At that time, she was recommended for pericardectomy, which was performed by Dr. Z. Review of her CT scan from March 2006 prior to her pericardectomy, already shows bilateral plural effusions. The patient improved clinically after the pericardectomy with resolution of her symptoms. Recently, she was readmitted to the hospital with chest pain and found to have bilateral pleural effusion, the right greater than the left. CT of the chest also revealed a large mediastinal lymph node. We reviewed the pathology obtained from the pericardectomy in March 2006, which was diagnostic of mesothelioma. At this time, chest tube placement for drainage of the fluid occurred and thoracoscopy with fluid biopsies, which were performed, which revealed epithelioid malignant mesothelioma. The patient was then stained with a PET CT, which showed extensive uptake in the chest, bilateral pleural pericardial effusions, and lymphadenopathy. She also had acidic fluid, pectoral and intramammary lymph nodes and uptake in L4 with SUV of 4. This was consistent with stage III disease. Her repeat echocardiogram showed an ejection fraction of 45% to 49%. She was transferred to Oncology service and started on chemotherapy on September 1, 2007 with cisplatin 75 mg/centimeter squared equaling 109 mg IV piggyback over 2 hours on September 1, 2007, Alimta 500 mg/ centimeter squared equaling 730 mg IV piggyback over 10 minutes. This was all initiated after a Port-A-Cath was placed. The chemotherapy was well tolerated and the patient was discharged the following day after discontinuing IV fluid and IV. Her Port-A-Cath was packed with heparin according to protocol.\nDISCHARGE MEDICATIONS:\nZofran, Phenergan, Coumadin, and Lovenox, and Vicodin\nDISCHARGE INSTRUCTIONS:\nShe was instructed to followup with Dr. XYZ in the office to check her INR on Tuesday. She was instructed to call if she had any other questions or concerns in the interim.\nKeywords:\nhematology - oncology, mesothelioma, pleural effusion, atrial fibrillation, anemia, ascites, esophageal reflux, deep venous thrombosis, port-a-cath placement, port a cath, iv piggyback, venous thrombosis, atrial, thrombosis, pericardial, lymphadenopathy, fluid, pericardectomy, chest, pleural,\n2023-09-23T18:55:49.923+0000: 1852.384: [GC (Allocation Failure) [PSYoungGen: 2286592K->45246K(4006912K)] 4151570K->1910233K(15876096K), 0.0176612 secs] [Times: user=0.09 sys=0.01, real=0.02 secs] \n+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n|index|                text|            document|            sentence|               token|          embeddings|                 ner|           ner_chunk|\n+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n|    0|Sample Type / Med...|[{document, 0, 54...|[{document, 0, 53...|[{token, 0, 5, Sa...|[{word_embeddings...|[{named_entity, 0...|[{chunk, 118, 129...|\n|    1|Sample Type / Med...|[{document, 0, 32...|[{document, 0, 53...|[{token, 0, 5, Sa...|[{word_embeddings...|[{named_entity, 0...|[{chunk, 68, 92, ...|\n|    2|Sample Type / Med...|[{document, 0, 42...|[{document, 0, 53...|[{token, 0, 5, Sa...|[{word_embeddings...|[{named_entity, 0...|[{chunk, 68, 73, ...|\n|    3|Sample Type / Med...|[{document, 0, 20...|[{document, 0, 53...|[{token, 0, 5, Sa...|[{word_embeddings...|[{named_entity, 0...|[{chunk, 119, 155...|\n|    4|Sample Type / Med...|[{document, 0, 34...|[{document, 0, 53...|[{token, 0, 5, Sa...|[{word_embeddings...|[{named_entity, 0...|[{chunk, 97, 116,...|\n|    5|Sample Type / Med...|[{document, 0, 15...|[{document, 0, 53...|[{token, 0, 5, Sa...|[{word_embeddings...|[{named_entity, 0...|[{chunk, 68, 84, ...|\n|    6|Sample Type / Med...|[{document, 0, 25...|[{document, 0, 53...|[{token, 0, 5, Sa...|[{word_embeddings...|[{named_entity, 0...|[{chunk, 68, 73, ...|\n|    7|Sample Type / Med...|[{document, 0, 93...|[{document, 0, 53...|[{token, 0, 5, Sa...|[{word_embeddings...|[{named_entity, 0...|[{chunk, 68, 92, ...|\n|    8|Sample Type / Med...|[{document, 0, 20...|[{document, 0, 53...|[{token, 0, 5, Sa...|[{word_embeddings...|[{named_entity, 0...|[{chunk, 155, 189...|\n|    9|Sample Type / Med...|[{document, 0, 19...|[{document, 0, 53...|[{token, 0, 5, Sa...|[{word_embeddings...|[{named_entity, 0...|[{chunk, 68, 95, ...|\n+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n\n+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+\n|                                                                                              result|                                                                                              result|\n+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+\n|[Sample, Type, /, Medical, Specialty, :, Hematology, -, Oncology, Sample, Name, :, Discharge, Sum...|[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-PROBLEM, O, B-PROBLEM, I-PROBLEM, ...|\n|[Sample, Type, /, Medical, Specialty, :, Hematology, -, Oncology, Sample, Name, :, BCCa, Excision...|[O, O, O, O, O, O, O, O, O, O, O, O, B-TREATMENT, I-TREATMENT, I-TREATMENT, I-TREATMENT, I-TREATM...|\n|[Sample, Type, /, Medical, Specialty, :, Hematology, -, Oncology, Sample, Name, :, Anemia, -, Con...|[O, O, O, O, O, O, O, O, O, O, O, O, B-PROBLEM, O, O, O, O, B-PROBLEM, I-PROBLEM, O, O, B-PROBLEM...|\n|[Sample, Type, /, Medical, Specialty, :, Hematology, -, Oncology, Sample, Name, :, Intensity-Modu...|[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-TREATMENT, I-TREATMENT, I-TREATMENT, O, O, ...|\n|[Sample, Type, /, Medical, Specialty, :, Hematology, -, Oncology, Sample, Name, :, Neck, Dissecti...|[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-PROBLEM, I-PROBLEM, I-PROBLEM, O, B-PROBLEM, I...|\n|[Sample, Type, /, Medical, Specialty, :, Hematology, -, Oncology, Sample, Name, :, HDR, Brachythe...|[O, O, O, O, O, O, O, O, O, O, O, O, B-TREATMENT, I-TREATMENT, O, O, B-TREATMENT, I-TREATMENT, O,...|\n|[Sample, Type, /, Medical, Specialty, :, Hematology, -, Oncology, Sample, Name, :, Biopsy, -, Cer...|[O, O, O, O, O, O, O, O, O, O, O, O, B-TEST, O, O, O, O, O, O, B-TEST, I-TEST, I-TEST, I-TEST, I-...|\n|[Sample, Type, /, Medical, Specialty, :, Hematology, -, Oncology, Sample, Name, :, Metastatic, Ov...|[O, O, O, O, O, O, O, O, O, O, O, O, B-PROBLEM, I-PROBLEM, I-PROBLEM, O, O, O, O, O, O, O, O, O, ...|\n|[Sample, Type, /, Medical, Specialty, :, Hematology, -, Oncology, Sample, Name, :, Breast, Radiat...|[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-PROBLEM, I-PROBLEM, I-...|\n|[Sample, Type, /, Medical, Specialty, :, Hematology, -, Oncology, Sample, Name, :, Lymph, Node, E...|[O, O, O, O, O, O, O, O, O, O, O, O, B-TEST, I-TEST, I-TEST, I-TEST, O, O, B-TEST, I-TEST, I-TEST...|\n+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+\n\nCPU times: user 4.67 ms, sys: 177 Âµs, total: 4.85 ms\nWall time: 479 ms\n+-------------+---------+----------+\n|        token|ner_label|confidence|\n+-------------+---------+----------+\n|       Sample|        O|    0.9996|\n|         Type|        O|    0.9926|\n|            /|        O|    0.9755|\n|      Medical|        O|    0.9824|\n|    Specialty|        O|    0.9993|\n|            :|        O|       1.0|\n|   Hematology|        O|    0.9971|\n|            -|        O|    0.9908|\n|     Oncology|        O|    0.9796|\n|       Sample|        O|    0.9999|\n|         Name|        O|    0.9994|\n|            :|        O|       1.0|\n|    Discharge|        O|    0.9998|\n|      Summary|        O|    0.9926|\n|            -|        O|    0.9959|\n| Mesothelioma|        O|    0.8117|\n|            -|        O|    0.9934|\n|            1|        O|    0.7394|\n|  Description|        O|    0.9995|\n|            :|        O|    0.9999|\n| Mesothelioma|B-PROBLEM|    0.9991|\n|            ,|        O|    0.9999|\n|      pleural|B-PROBLEM|    0.9911|\n|     effusion|I-PROBLEM|    0.9982|\n|            ,|        O|    0.9999|\n|       atrial|B-PROBLEM|    0.9976|\n| fibrillation|I-PROBLEM|    0.9982|\n|            ,|        O|    0.9999|\n|       anemia|B-PROBLEM|     0.999|\n|            ,|        O|    0.9999|\n|      ascites|B-PROBLEM|    0.9996|\n|            ,|        O|       1.0|\n|   esophageal|B-PROBLEM|    0.9982|\n|       reflux|I-PROBLEM|    0.9976|\n|            ,|        O|       1.0|\n|          and|        O|    0.9996|\n|      history|        O|    0.9892|\n|           of|        O|    0.9769|\n|         deep|B-PROBLEM|    0.9421|\n|       venous|I-PROBLEM|    0.9624|\n|   thrombosis|I-PROBLEM|    0.9983|\n|            .|        O|       1.0|\n|            (|        O|    0.9999|\n|      Medical|        O|     0.986|\n|Transcription|        O|    0.9214|\n|       Sample|        O|     0.993|\n|       Report|        O|    0.9536|\n|            )|        O|    0.9802|\n|    PRINCIPAL|        O|    0.9981|\n|    DIAGNOSIS|        O|    0.4728|\n+-------------+---------+----------+\nonly showing top 50 rows\n\n+-----------+-----+\n|ner_label  |count|\n+-----------+-----+\n|O          |4721 |\n|I-PROBLEM  |526  |\n|B-PROBLEM  |399  |\n|I-TREATMENT|326  |\n|B-TREATMENT|265  |\n|I-TEST     |173  |\n|B-TEST     |142  |\n+-----------+-----+\n\n+-------------------------+---------+----------+\n|chunk                    |ner_label|confidence|\n+-------------------------+---------+----------+\n|Mesothelioma             |PROBLEM  |0.9991    |\n|pleural effusion         |PROBLEM  |0.99465   |\n|atrial fibrillation      |PROBLEM  |0.9979    |\n|anemia                   |PROBLEM  |0.999     |\n|ascites                  |PROBLEM  |0.9996    |\n|esophageal reflux        |PROBLEM  |0.9979    |\n|deep venous thrombosis   |PROBLEM  |0.96760005|\n|Mesothelioma             |PROBLEM  |0.987     |\n|Pleural effusion         |PROBLEM  |0.97895   |\n|atrial fibrillation      |PROBLEM  |0.99475   |\n|anemia                   |PROBLEM  |0.9984    |\n|ascites                  |PROBLEM  |0.9994    |\n|esophageal reflux        |PROBLEM  |0.99724996|\n|deep venous thrombosis   |PROBLEM  |0.9550001 |\n|decortication of the lung|TREATMENT|0.756325  |\n|pleural biopsy           |TEST     |0.87715   |\n|transpleural fluoroscopy |TEST     |0.9527    |\n|thoracentesis            |TREATMENT|0.9075    |\n|Port-A-Cath placement    |TREATMENT|0.98075   |\n|a nonproductive cough    |PROBLEM  |0.96173334|\n+-------------------------+---------+----------+\nonly showing top 20 rows\n\n2023-09-23T18:56:27.828+0000: 1890.289: [GC (Allocation Failure) [PSYoungGen: 2211006K->84031K(2250240K)] 4075993K->1949026K(14119424K), 0.0223457 secs] [Times: user=0.11 sys=0.01, real=0.02 secs] \n\nA 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to presentation and subsequent type two diabetes mellitus (T2DM), one prior episode of HTG-induced pancreatitis three years prior to presentation, and associated with an acute hepatitis, presented with a one-week history of polyuria, poor appetite, and vomiting. \nShe was on metformin, glipizide, and dapagliflozin for T2DM and atorvastatin and gemfibrozil for HTG. She had been on dapagliflozin for six months at the time of presentation. \nPhysical examination on presentation was significant for dry oral mucosa ; significantly , her abdominal examination was benign with no tenderness, guarding, or rigidity. Pertinent laboratory findings on admission were: serum glucose 111 mg/dl,  creatinine 0.4 mg/dL, triglycerides 508 mg/dL, total cholesterol 122 mg/dL, and venous pH 7.27. \n\n2023-09-23T18:56:33.932+0000: 1896.393: [GC (Allocation Failure) [PSYoungGen: 2249791K->72252K(4047872K)] 4114786K->1937255K(15917056K), 0.0196871 secs] [Times: user=0.11 sys=0.00, real=0.02 secs] \n2023-09-23T18:56:39.097+0000: 1901.558: [GC (Allocation Failure) [PSYoungGen: 2226236K->71629K(4040192K)] 4091239K->1936640K(15909376K), 0.0212904 secs] [Times: user=0.12 sys=0.00, real=0.02 secs] \n2023-09-23T18:56:44.259+0000: 1906.720: [GC (Allocation Failure) [PSYoungGen: 2225613K->71701K(4110336K)] 4090624K->1936712K(15979520K), 0.0187776 secs] [Times: user=0.10 sys=0.00, real=0.02 secs] \n2023-09-23T18:56:49.645+0000: 1912.107: [GC (Allocation Failure) [PSYoungGen: 2320405K->71734K(4072448K)] 4185416K->1936753K(15941632K), 0.0202034 secs] [Times: user=0.10 sys=0.00, real=0.02 secs] \n2023-09-23T18:56:55.083+0000: 1917.544: [GC (Allocation Failure) [PSYoungGen: 2320438K->71720K(4214784K)] 4185457K->1936739K(16083968K), 0.0188157 secs] [Times: user=0.11 sys=0.01, real=0.02 secs] \n2023-09-23T18:57:00.698+0000: 1923.159: [GC (Allocation Failure) [PSYoungGen: 2510888K->71730K(4158464K)] 4375907K->1936749K(16027648K), 0.0188278 secs] [Times: user=0.12 sys=0.00, real=0.02 secs] \n2023-09-23T18:57:06.537+0000: 1928.999: [GC (Allocation Failure) [PSYoungGen: 2510898K->71633K(4342272K)] 4375917K->1936652K(16211456K), 0.0202018 secs] [Times: user=0.13 sys=0.00, real=0.02 secs] \n2023-09-23T18:57:12.866+0000: 1935.328: [GC (Allocation Failure) [PSYoungGen: 2756049K->72433K(4276224K)] 4621068K->1937452K(16145408K), 0.0188576 secs] [Times: user=0.12 sys=0.00, real=0.02 secs] \n2023-09-23T18:57:19.805+0000: 1942.267: [GC (Allocation Failure) [PSYoungGen: 2756849K->72392K(4481536K)] 4621868K->1937411K(16350720K), 0.0197654 secs] [Times: user=0.12 sys=0.00, real=0.02 secs] \n2023-09-23T18:57:27.263+0000: 1949.725: [GC (Allocation Failure) [PSYoungGen: 3031240K->72483K(4411392K)] 4896259K->1937502K(16280576K), 0.0200595 secs] [Times: user=0.12 sys=0.00, real=0.02 secs] \n2023-09-23T18:57:34.455+0000: 1956.916: [GC (Allocation Failure) [PSYoungGen: 3031331K->72289K(4622336K)] 4896350K->1937308K(16491520K), 0.0192162 secs] [Times: user=0.12 sys=0.00, real=0.01 secs] \n2023-09-23T18:57:42.323+0000: 1964.784: [GC (Allocation Failure) [PSYoungGen: 3312737K->72529K(4552192K)] 5177756K->1937556K(16421376K), 0.0189217 secs] [Times: user=0.12 sys=0.00, real=0.02 secs] \n2023-09-23T18:57:50.464+0000: 1972.925: [GC (Allocation Failure) [PSYoungGen: 3312977K->72496K(4759552K)] 5178004K->1937531K(16628736K), 0.0183950 secs] [Times: user=0.11 sys=0.00, real=0.02 secs] \n2023-09-23T18:57:58.917+0000: 1981.378: [GC (Allocation Failure) [PSYoungGen: 3589424K->36710K(4691456K)] 5454459K->1938667K(16560640K), 0.0193325 secs] [Times: user=0.12 sys=0.00, real=0.02 secs] \n--2023-09-23 18:58:06--  https://setup.johnsnowlabs.com/nlu/colab.sh\nResolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 51.158.130.125\nConnecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:443... connected.\nHTTP request sent, awaiting response... 302 Moved Temporarily\nLocation: https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/scripts/colab_setup.sh [following]\n--2023-09-23 18:58:07--  https://raw.githubusercontent.com/JohnSnowLabs/nlu/master/scripts/colab_setup.sh\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1212 (1.2K) [text/plain]\nSaving to: â€˜STDOUTâ€™\n\n\n-                     0%[                    ]       0  --.-KB/s               \n-                   100%[===================>]   1.18K  --.-KB/s    in 0s      \n\n2023-09-23 18:58:07 (77.1 MB/s) - written to stdout [1212/1212]\n\nInstalling PySpark 3.2.1 and Spark NLP 4.0.0\nsetup Colab for PySpark 3.2.1 and Spark NLP 4.0.0\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nspark-ocr 5.0.0 requires spark-nlp==5.0.2, but you have spark-nlp 4.0.0 which is incompatible.\nspark-nlp-jsl 5.1.0 requires spark-nlp==5.1.0, but you have spark-nlp 4.0.0 which is incompatible.\n\n[notice] A new release of pip available: 22.2.2 -> 23.2.1\n[notice] To update, run: pip install --upgrade pip\nWarning::Spark Session already created, some configs may not take.\nWarning::Spark Session already created, some configs may not take.\nWarning::Spark Session already created, some configs may not take.\nWarning::Spark Session already created, some configs may not take.\nWarning::Spark Session already created, some configs may not take.\nWarning::Spark Session already created, some configs may not take.\n\n"
     ]
    }
   ],
   "source": [
    "log_file_name = os.listdir(\"logs\")[0]\n",
    "\n",
    "with open(\"logs/\" + log_file_name, \"r\") as log_file:\n",
    "    print(log_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15991221-e2b1-462b-9834-cb69057c1c84",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pred_df = clf_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5764bcd-1dcb-4e56-bdd2-14ad9bd67c2a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n|target|result|\n+------+------+\n|0     |[0]   |\n|1     |[0]   |\n|1     |[1]   |\n|1     |[1]   |\n|1     |[1]   |\n|1     |[1]   |\n|0     |[1]   |\n|1     |[1]   |\n|1     |[1]   |\n|1     |[1]   |\n|1     |[1]   |\n|1     |[1]   |\n|0     |[0]   |\n|1     |[0]   |\n|0     |[1]   |\n|1     |[1]   |\n|1     |[1]   |\n|1     |[1]   |\n|0     |[1]   |\n|1     |[1]   |\n+------+------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "pred_df.select('target','prediction.result').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66dfd6a5-f6e0-4e1a-95ba-68ad9b594e73",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "preds_df = pred_df.select('target','prediction.result').toPandas()\n",
    "\n",
    "# Let's explode the array and get the item(s) inside of result column out\n",
    "preds_df['result'] = preds_df['result'].apply(lambda x : int(x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b53361c4-dbf8-49d4-b8cc-fd0f6aba6789",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feedback</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feedback  result\n",
       "72          1       1\n",
       "94          1       1\n",
       "383         1       1\n",
       "278         0       1\n",
       "481         1       0\n",
       "300         1       1\n",
       "174         0       1\n",
       "640         1       1\n",
       "419         1       1\n",
       "249         1       1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "089cf30a-d0fe-4ad7-a9f9-7fbd79577c29",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n\n           0     0.5338    0.4754    0.5029       631\n           1     0.8167    0.8492    0.8326      1737\n\n    accuracy                         0.7496      2368\n   macro avg     0.6753    0.6623    0.6678      2368\nweighted avg     0.7413    0.7496    0.7448      2368\n\n0.7495777027027027\n"
     ]
    }
   ],
   "source": [
    "# We are going to use sklearn to evalute the results on test dataset\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "print (classification_report(preds_df['target'], preds_df['result'], digits=4))\n",
    "\n",
    "print (accuracy_score(preds_df['target'], preds_df['result']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b45ee2a4-a5d4-48bc-8276-1cf7d212302b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## get prediction for random input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b6e4c24-255d-4b18-8798-7e0cfef29cba",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>FurLength</th>\n",
       "      <th>Vaccinated</th>\n",
       "      <th>Sterilized</th>\n",
       "      <th>Health</th>\n",
       "      <th>Fee</th>\n",
       "      <th>Description</th>\n",
       "      <th>PhotoAmt</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dog</td>\n",
       "      <td>2</td>\n",
       "      <td>Mixed Breed</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>10</td>\n",
       "      <td>Friendly and pampered female puppy looking for a beautiful home</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Type  Age       Breed1  Gender Color1 Color2 MaturitySize FurLength Vaccinated Sterilized   Health  Fee                                                      Description  PhotoAmt  target\n",
       "0  Dog    2  Mixed Breed  Female  Black  Brown       Medium    Medium        Yes        Yes  Healthy   10  Friendly and pampered female puppy looking for a beautiful home         2       1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([dataframe.loc[5191].to_dict()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1723bfd7-5d4a-4e09-b0c0-de9e56277656",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "input_X = column_trans.transform(pd.DataFrame([dataframe.loc[0].to_dict()]).drop(['target'], axis=1))\n",
    "\n",
    "input_y = dataframe.target[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e044be33-597a-498e-902e-2089d3b055f3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "      <th>col_5</th>\n",
       "      <th>col_6</th>\n",
       "      <th>col_7</th>\n",
       "      <th>col_8</th>\n",
       "      <th>col_9</th>\n",
       "      <th>col_10</th>\n",
       "      <th>col_11</th>\n",
       "      <th>col_12</th>\n",
       "      <th>col_13</th>\n",
       "      <th>col_14</th>\n",
       "      <th>col_15</th>\n",
       "      <th>col_16</th>\n",
       "      <th>col_17</th>\n",
       "      <th>col_18</th>\n",
       "      <th>col_19</th>\n",
       "      <th>col_20</th>\n",
       "      <th>col_21</th>\n",
       "      <th>col_22</th>\n",
       "      <th>col_23</th>\n",
       "      <th>col_24</th>\n",
       "      <th>col_25</th>\n",
       "      <th>col_26</th>\n",
       "      <th>col_27</th>\n",
       "      <th>col_28</th>\n",
       "      <th>col_29</th>\n",
       "      <th>col_30</th>\n",
       "      <th>col_31</th>\n",
       "      <th>col_32</th>\n",
       "      <th>col_33</th>\n",
       "      <th>col_34</th>\n",
       "      <th>col_35</th>\n",
       "      <th>col_36</th>\n",
       "      <th>col_37</th>\n",
       "      <th>col_38</th>\n",
       "      <th>col_39</th>\n",
       "      <th>col_40</th>\n",
       "      <th>col_41</th>\n",
       "      <th>col_42</th>\n",
       "      <th>col_43</th>\n",
       "      <th>col_44</th>\n",
       "      <th>col_45</th>\n",
       "      <th>col_46</th>\n",
       "      <th>col_47</th>\n",
       "      <th>col_48</th>\n",
       "      <th>col_49</th>\n",
       "      <th>...</th>\n",
       "      <th>col_253</th>\n",
       "      <th>col_254</th>\n",
       "      <th>col_255</th>\n",
       "      <th>col_256</th>\n",
       "      <th>col_257</th>\n",
       "      <th>col_258</th>\n",
       "      <th>col_259</th>\n",
       "      <th>col_260</th>\n",
       "      <th>col_261</th>\n",
       "      <th>col_262</th>\n",
       "      <th>col_263</th>\n",
       "      <th>col_264</th>\n",
       "      <th>col_265</th>\n",
       "      <th>col_266</th>\n",
       "      <th>col_267</th>\n",
       "      <th>col_268</th>\n",
       "      <th>col_269</th>\n",
       "      <th>col_270</th>\n",
       "      <th>col_271</th>\n",
       "      <th>col_272</th>\n",
       "      <th>col_273</th>\n",
       "      <th>col_274</th>\n",
       "      <th>col_275</th>\n",
       "      <th>col_276</th>\n",
       "      <th>col_277</th>\n",
       "      <th>col_278</th>\n",
       "      <th>col_279</th>\n",
       "      <th>col_280</th>\n",
       "      <th>col_281</th>\n",
       "      <th>col_282</th>\n",
       "      <th>col_283</th>\n",
       "      <th>col_284</th>\n",
       "      <th>col_285</th>\n",
       "      <th>col_286</th>\n",
       "      <th>col_287</th>\n",
       "      <th>col_288</th>\n",
       "      <th>col_289</th>\n",
       "      <th>col_290</th>\n",
       "      <th>col_291</th>\n",
       "      <th>col_292</th>\n",
       "      <th>col_293</th>\n",
       "      <th>col_294</th>\n",
       "      <th>col_295</th>\n",
       "      <th>col_296</th>\n",
       "      <th>col_297</th>\n",
       "      <th>col_298</th>\n",
       "      <th>col_299</th>\n",
       "      <th>col_300</th>\n",
       "      <th>col_301</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.171825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.283609</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.220992</td>\n",
       "      <td>0.151594</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.144907</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.158869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.170202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.192465</td>\n",
       "      <td>0.190783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132427</td>\n",
       "      <td>0.176639</td>\n",
       "      <td>0.151246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.257843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.452479</td>\n",
       "      <td>0.950288</td>\n",
       "      <td>-0.829762</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 303 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   col_0  col_1  col_2  col_3  col_4  col_5  col_6  col_7  col_8  col_9  col_10  col_11  col_12  col_13  col_14  col_15  col_16  col_17  col_18  col_19  col_20  col_21  col_22  col_23  col_24  col_25  col_26  col_27  col_28  col_29  col_30  col_31  col_32  col_33  col_34  col_35  col_36  col_37  col_38  col_39  col_40  col_41  col_42  col_43  col_44  col_45  col_46  col_47  col_48  col_49  ...  col_253  col_254  col_255   col_256  col_257   col_258  col_259  col_260   col_261  col_262   col_263   col_264  col_265  col_266  col_267  col_268  col_269  col_270   col_271  col_272  col_273   col_274  col_275  col_276  col_277   col_278  col_279   col_280   col_281  col_282   col_283   col_284   col_285  col_286  col_287  col_288  col_289   col_290  col_291  col_292  col_293  col_294  col_295  col_296  col_297  col_298   col_299   col_300   col_301  target\n",
       "0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  ...      0.0      0.0      0.0  0.171825      0.0  0.137765      0.0      0.0  0.283609      0.0  0.220992  0.151594      0.0      0.0      0.0      0.0      0.0      0.0  0.144907      0.0      0.0  0.158869      0.0      0.0      0.0  0.170202      0.0  0.192465  0.190783      0.0  0.132427  0.176639  0.151246      0.0      0.0      0.0      0.0  0.257843      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0 -0.452479  0.950288 -0.829762       1\n",
       "\n",
       "[1 rows x 303 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_df = pd.DataFrame.sparse.from_spmatrix(input_X)\n",
    "\n",
    "input_df.columns = ['col_{}'.format(i) for i in range(input_X.shape[1])]\n",
    "\n",
    "input_df['target']= input_y\n",
    "\n",
    "input_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb52dad1-2596-4719-9d15-839b7fa14153",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/spark/python/pyspark/sql/pandas/conversion.py:401: UserWarning: createDataFrame attempted Arrow optimization because 'spark.sql.execution.arrow.pyspark.enabled' is set to true; however, failed by the reason below:\n  Sparse pandas data (column col_0) not supported.\nAttempting non-optimization as 'spark.sql.execution.arrow.pyspark.fallback.enabled' is set to true.\n  warn(msg)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------------------+-------+-----------------+-------+-------+-------+------------------+-------+-------+-------+------------------+-------+------------------+-------+-------+-------+-------+-------+-------+------------------+-------+-------+-------+-------+-------+-------+-------+-------------------+------------------+-------------------+-------+-------+-------+-------+-------+-------+-------+-------+-------------------+-------+-------------------+-------+-------+-------+-------+-------------------+-------------------+-------+-------+-------+-------+-------------------+-------+------------------+-------+-------+-------------------+-------+------------------+-------------------+-------+-------+-------+-------+-------+-------+-------------------+-------+-------+------------------+-------+-------+-------+-------------------+-------+-------------------+-------------------+-------+-------------------+-------------------+-------------------+-------+-------+-------+-------+------------------+-------+-------+-------+-------+-------+-------+-------+-------+-------------------+------------------+-------------------+------+\n|col_0|col_1|col_2|col_3|col_4|col_5|col_6|col_7|col_8|col_9|col_10|col_11|col_12|col_13|col_14|col_15|col_16|col_17|col_18|col_19|col_20|col_21|col_22|col_23|col_24|col_25|col_26|col_27|col_28|col_29|col_30|col_31|col_32|col_33|col_34|col_35|col_36|col_37|col_38|col_39|col_40|col_41|col_42|col_43|col_44|col_45|col_46|col_47|col_48|col_49|col_50|col_51|col_52|col_53|col_54|col_55|col_56|col_57|col_58|col_59|col_60|col_61|col_62|col_63|col_64|col_65|col_66|col_67|col_68|col_69|col_70|col_71|col_72|col_73|col_74|col_75|col_76|col_77|col_78|col_79|col_80|col_81|col_82|col_83|col_84|col_85|col_86|col_87|col_88|col_89|col_90|col_91|col_92|col_93|col_94|col_95|col_96|col_97|col_98|col_99|col_100|col_101|col_102|col_103|col_104|col_105|col_106|col_107|col_108|col_109|col_110|col_111|col_112|col_113|col_114|col_115|col_116|col_117|col_118|col_119|col_120|col_121|col_122|col_123|col_124|col_125|col_126|col_127|col_128|col_129|col_130|col_131|col_132|col_133|col_134|col_135|col_136|col_137|col_138|col_139|col_140|col_141|col_142|col_143|col_144|col_145|col_146|col_147|col_148|col_149|col_150|col_151|col_152|col_153|col_154|col_155|col_156|col_157|col_158|col_159|col_160|col_161|col_162|col_163|col_164|col_165|col_166|col_167|col_168|col_169|col_170|col_171|col_172|col_173|col_174|col_175|col_176|col_177|col_178|col_179|col_180|col_181|col_182|col_183|col_184|col_185|col_186|col_187|col_188|col_189|col_190|col_191|col_192|col_193|col_194|col_195|col_196|col_197|col_198|col_199|col_200|col_201|col_202|col_203|col_204|            col_205|col_206|          col_207|col_208|col_209|col_210|           col_211|col_212|col_213|col_214|           col_215|col_216|           col_217|col_218|col_219|col_220|col_221|col_222|col_223|           col_224|col_225|col_226|col_227|col_228|col_229|col_230|col_231|            col_232|           col_233|            col_234|col_235|col_236|col_237|col_238|col_239|col_240|col_241|col_242|            col_243|col_244|            col_245|col_246|col_247|col_248|col_249|            col_250|            col_251|col_252|col_253|col_254|col_255|            col_256|col_257|           col_258|col_259|col_260|            col_261|col_262|           col_263|            col_264|col_265|col_266|col_267|col_268|col_269|col_270|            col_271|col_272|col_273|           col_274|col_275|col_276|col_277|            col_278|col_279|            col_280|            col_281|col_282|            col_283|            col_284|            col_285|col_286|col_287|col_288|col_289|           col_290|col_291|col_292|col_293|col_294|col_295|col_296|col_297|col_298|            col_299|           col_300|            col_301|target|\n+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------------------+-------+-----------------+-------+-------+-------+------------------+-------+-------+-------+------------------+-------+------------------+-------+-------+-------+-------+-------+-------+------------------+-------+-------+-------+-------+-------+-------+-------+-------------------+------------------+-------------------+-------+-------+-------+-------+-------+-------+-------+-------+-------------------+-------+-------------------+-------+-------+-------+-------+-------------------+-------------------+-------+-------+-------+-------+-------------------+-------+------------------+-------+-------+-------------------+-------+------------------+-------------------+-------+-------+-------+-------+-------+-------+-------------------+-------+-------+------------------+-------+-------+-------+-------------------+-------+-------------------+-------------------+-------+-------------------+-------------------+-------------------+-------+-------+-------+-------+------------------+-------+-------+-------+-------+-------+-------+-------+-------+-------------------+------------------+-------------------+------+\n|  1.0|  0.0|  0.0|  0.0|  0.0|  0.0|  0.0|  0.0|  0.0|  0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|   0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    1.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    1.0|    1.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    1.0|    0.0|    0.0|    0.0|    1.0|    0.0|    0.0|    1.0|    1.0|    0.0|    0.0|    1.0|    0.0|    0.0|    1.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|0.14790666983217132|    0.0|0.141901216032228|    0.0|    0.0|    0.0|0.1394459499679825|    0.0|    0.0|    0.0|0.3265838806573452|    0.0|0.3634497454343939|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|0.1745124543418815|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|0.13723100321630188|0.1315239445466759|0.15807938231468016|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|0.22228965749451582|    0.0|0.16411338759316998|    0.0|    0.0|    0.0|    0.0|0.14625259628872841|0.15159355410175562|    0.0|    0.0|    0.0|    0.0|0.17182477736803128|    0.0|0.1377650292351999|    0.0|    0.0|0.28360934353718825|    0.0|0.2209915956836379|0.15159355410175562|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|0.14490710928857287|    0.0|    0.0|0.1588694335049109|    0.0|    0.0|    0.0|0.17020231643621128|    0.0|0.19246519270780896|0.19078292304252878|    0.0|0.13242713485040372|0.17663873912979314|0.15124611730800605|    0.0|    0.0|    0.0|    0.0|0.2578425424693542|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|    0.0|-0.4524794726808656|0.9502875792756131|-0.8297616989552165|     1|\n+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------------------+-------+-----------------+-------+-------+-------+------------------+-------+-------+-------+------------------+-------+------------------+-------+-------+-------+-------+-------+-------+------------------+-------+-------+-------+-------+-------+-------+-------+-------------------+------------------+-------------------+-------+-------+-------+-------+-------+-------+-------+-------+-------------------+-------+-------------------+-------+-------+-------+-------+-------------------+-------------------+-------+-------+-------+-------+-------------------+-------+------------------+-------+-------+-------------------+-------+------------------+-------------------+-------+-------+-------+-------+-------+-------+-------------------+-------+-------+------------------+-------+-------+-------+-------------------+-------+-------------------+-------------------+-------+-------------------+-------------------+-------------------+-------+-------+-------+-------+------------------+-------+-------+-------+-------+-------+-------+-------+-------+-------------------+------------------+-------------------+------+\n\n"
     ]
    }
   ],
   "source": [
    "input_spark_df = spark.createDataFrame(input_df)\n",
    "input_spark_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c689a525-3f4e-4273-b738-b4af2cfc2fb0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n|target|result|\n+------+------+\n|     1|   [1]|\n+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "clf_model.transform(input_spark_df).select('target','prediction.result').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "900cd3de-5f8f-4c0c-a93f-2b9b13f9680f",
     "showTitle": false,
     "title": ""
    },
    "id": "_Tgo746qI3r0"
   },
   "source": [
    "# Case Study: Alexa Review Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d999214b-2e14-4521-a39e-2276e2d84f5b",
     "showTitle": false,
     "title": ""
    },
    "id": "cx_hs3OdI3r0",
    "outputId": "5569ab92-4419-49d0-977f-b256fc9fdee0"
   },
   "outputs": [],
   "source": [
    "! wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/data/amazon_alexa.tsv -P /dbfs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b980d10-4e25-4538-b2f3-66b6ee8d4598",
     "showTitle": false,
     "title": ""
    },
    "id": "ImoUa6FoI3r1",
    "outputId": "e303e254-81c1-4da3-83d8-44194f7331bb"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>variation</th>\n",
       "      <th>verified_reviews</th>\n",
       "      <th>feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>Love my Echo!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>Loved it!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Walnut Finish</td>\n",
       "      <td>Sometimes while playing a game, you can answer a question correctly but Alexa says you got it wr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>I have had a lot of fun with this thing. My 4 yr old learns about dinosaurs, i control the light...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>Music</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3145</th>\n",
       "      <td>5</td>\n",
       "      <td>30-Jul-18</td>\n",
       "      <td>Black  Dot</td>\n",
       "      <td>Perfect for kids, adults and everyone in between!!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3146</th>\n",
       "      <td>5</td>\n",
       "      <td>30-Jul-18</td>\n",
       "      <td>Black  Dot</td>\n",
       "      <td>Listening to music, searching locations, checking time, looking up weather. There are many more ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3147</th>\n",
       "      <td>5</td>\n",
       "      <td>30-Jul-18</td>\n",
       "      <td>Black  Dot</td>\n",
       "      <td>I do love these things, i have them running my entire home, TV, all my lights, my thermostat, my...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3148</th>\n",
       "      <td>5</td>\n",
       "      <td>30-Jul-18</td>\n",
       "      <td>White  Dot</td>\n",
       "      <td>Only complaint I have is that the sound quality isn't great. I mostly use it for commands though...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3149</th>\n",
       "      <td>4</td>\n",
       "      <td>29-Jul-18</td>\n",
       "      <td>Black  Dot</td>\n",
       "      <td>Good</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rating       date         variation                                                                                     verified_reviews  feedback\n",
       "0          5  31-Jul-18  Charcoal Fabric                                                                                         Love my Echo!         1\n",
       "1          5  31-Jul-18  Charcoal Fabric                                                                                             Loved it!         1\n",
       "2          4  31-Jul-18    Walnut Finish   Sometimes while playing a game, you can answer a question correctly but Alexa says you got it wr...         1\n",
       "3          5  31-Jul-18  Charcoal Fabric   I have had a lot of fun with this thing. My 4 yr old learns about dinosaurs, i control the light...         1\n",
       "4          5  31-Jul-18  Charcoal Fabric                                                                                                 Music         1\n",
       "...      ...        ...               ...                                                                                                  ...       ...\n",
       "3145       5  30-Jul-18        Black  Dot                                                   Perfect for kids, adults and everyone in between!!         1\n",
       "3146       5  30-Jul-18        Black  Dot  Listening to music, searching locations, checking time, looking up weather. There are many more ...         1\n",
       "3147       5  30-Jul-18        Black  Dot  I do love these things, i have them running my entire home, TV, all my lights, my thermostat, my...         1\n",
       "3148       5  30-Jul-18        White  Dot  Only complaint I have is that the sound quality isn't great. I mostly use it for commands though...         1\n",
       "3149       4  29-Jul-18        Black  Dot                                                                                                 Good         1\n",
       "\n",
       "[3150 rows x 5 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/dbfs/amazon_alexa.tsv', sep='\\t')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a86afcb-dab8-4b11-b998-60ac8a704a2a",
     "showTitle": false,
     "title": ""
    },
    "id": "rm1eLJV3I3r1",
    "outputId": "4858d14e-1e58-47ef-bcf1-15b4a85114c0"
   },
   "outputs": [],
   "source": [
    "df.verified_reviews = df.verified_reviews.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93570891-5f04-4bfa-bc8e-1c13345760ef",
     "showTitle": false,
     "title": ""
    },
    "id": "II1HfCMoI3r2",
    "outputId": "2d0a43f1-939f-4a52-a164-5a1a944674f1"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1    2893\n",
       "0     257\n",
       "Name: feedback, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.feedback.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5744ec9-86e4-4293-ae11-84de563ad925",
     "showTitle": false,
     "title": ""
    },
    "id": "gfMH_ZbII3r3",
    "outputId": "8c0496c4-4d2d-4566-bc66-67f84fb8c39b"
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "column_trans = make_column_transformer(\n",
    "     (TfidfVectorizer(max_features=1000,  norm='l2', ngram_range=(1, 3)), 'verified_reviews'))\n",
    "\n",
    "X = column_trans.fit_transform(df.drop(['feedback'], axis=1))\n",
    "\n",
    "y = df.feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2de95387-38ed-427c-9a91-2dacbc970a48",
     "showTitle": false,
     "title": ""
    },
    "id": "TcswqkkMI3r3",
    "outputId": "101c9ae1-d0b6-4879-b6f3-01cc6e6f7c57"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "      <th>col_5</th>\n",
       "      <th>col_6</th>\n",
       "      <th>col_7</th>\n",
       "      <th>col_8</th>\n",
       "      <th>col_9</th>\n",
       "      <th>col_10</th>\n",
       "      <th>col_11</th>\n",
       "      <th>col_12</th>\n",
       "      <th>col_13</th>\n",
       "      <th>col_14</th>\n",
       "      <th>col_15</th>\n",
       "      <th>col_16</th>\n",
       "      <th>col_17</th>\n",
       "      <th>col_18</th>\n",
       "      <th>col_19</th>\n",
       "      <th>col_20</th>\n",
       "      <th>col_21</th>\n",
       "      <th>col_22</th>\n",
       "      <th>col_23</th>\n",
       "      <th>col_24</th>\n",
       "      <th>col_25</th>\n",
       "      <th>col_26</th>\n",
       "      <th>col_27</th>\n",
       "      <th>col_28</th>\n",
       "      <th>col_29</th>\n",
       "      <th>col_30</th>\n",
       "      <th>col_31</th>\n",
       "      <th>col_32</th>\n",
       "      <th>col_33</th>\n",
       "      <th>col_34</th>\n",
       "      <th>col_35</th>\n",
       "      <th>col_36</th>\n",
       "      <th>col_37</th>\n",
       "      <th>col_38</th>\n",
       "      <th>col_39</th>\n",
       "      <th>col_40</th>\n",
       "      <th>col_41</th>\n",
       "      <th>col_42</th>\n",
       "      <th>col_43</th>\n",
       "      <th>col_44</th>\n",
       "      <th>col_45</th>\n",
       "      <th>col_46</th>\n",
       "      <th>col_47</th>\n",
       "      <th>col_48</th>\n",
       "      <th>col_49</th>\n",
       "      <th>...</th>\n",
       "      <th>col_951</th>\n",
       "      <th>col_952</th>\n",
       "      <th>col_953</th>\n",
       "      <th>col_954</th>\n",
       "      <th>col_955</th>\n",
       "      <th>col_956</th>\n",
       "      <th>col_957</th>\n",
       "      <th>col_958</th>\n",
       "      <th>col_959</th>\n",
       "      <th>col_960</th>\n",
       "      <th>col_961</th>\n",
       "      <th>col_962</th>\n",
       "      <th>col_963</th>\n",
       "      <th>col_964</th>\n",
       "      <th>col_965</th>\n",
       "      <th>col_966</th>\n",
       "      <th>col_967</th>\n",
       "      <th>col_968</th>\n",
       "      <th>col_969</th>\n",
       "      <th>col_970</th>\n",
       "      <th>col_971</th>\n",
       "      <th>col_972</th>\n",
       "      <th>col_973</th>\n",
       "      <th>col_974</th>\n",
       "      <th>col_975</th>\n",
       "      <th>col_976</th>\n",
       "      <th>col_977</th>\n",
       "      <th>col_978</th>\n",
       "      <th>col_979</th>\n",
       "      <th>col_980</th>\n",
       "      <th>col_981</th>\n",
       "      <th>col_982</th>\n",
       "      <th>col_983</th>\n",
       "      <th>col_984</th>\n",
       "      <th>col_985</th>\n",
       "      <th>col_986</th>\n",
       "      <th>col_987</th>\n",
       "      <th>col_988</th>\n",
       "      <th>col_989</th>\n",
       "      <th>col_990</th>\n",
       "      <th>col_991</th>\n",
       "      <th>col_992</th>\n",
       "      <th>col_993</th>\n",
       "      <th>col_994</th>\n",
       "      <th>col_995</th>\n",
       "      <th>col_996</th>\n",
       "      <th>col_997</th>\n",
       "      <th>col_998</th>\n",
       "      <th>col_999</th>\n",
       "      <th>feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.145963</td>\n",
       "      <td>0.146283</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.094944</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.327234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.324472</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.149662</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.16371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.210616</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   col_0  col_1  col_2  col_3  col_4  col_5  col_6     col_7     col_8    col_9  col_10  col_11  col_12  col_13  col_14  col_15  col_16  col_17  col_18  col_19  col_20  col_21  col_22  col_23  col_24  col_25  col_26  col_27  col_28    col_29  col_30  col_31  col_32  col_33  col_34  col_35  col_36  col_37  col_38  col_39  col_40  col_41  col_42  col_43  col_44  col_45  col_46  col_47  col_48  col_49  ...  col_951  col_952   col_953  col_954  col_955  col_956  col_957  col_958  col_959  col_960  col_961  col_962  col_963   col_964  col_965  col_966  col_967  col_968  col_969   col_970  col_971  col_972  col_973  col_974  col_975  col_976  col_977  col_978  col_979  col_980  col_981  col_982  col_983  col_984  col_985  col_986  col_987  col_988  col_989  col_990  col_991   col_992  col_993   col_994  col_995  col_996  col_997  col_998  col_999  feedback\n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.000000  0.000000  0.00000     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  0.000000     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  ...      0.0      0.0  0.000000      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  0.000000      0.0      0.0      0.0      0.0      0.0  0.000000      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  0.000000      0.0  0.000000      0.0      0.0      0.0      0.0      0.0         1\n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.000000  0.000000  0.00000     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  0.000000     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  ...      0.0      0.0  0.000000      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  0.000000      0.0      0.0      0.0      0.0      0.0  0.000000      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  0.000000      0.0  0.000000      0.0      0.0      0.0      0.0      0.0         1\n",
       "2    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.145963  0.146283  0.00000     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  0.094944     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  ...      0.0      0.0  0.327234      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  0.000000      0.0      0.0      0.0      0.0      0.0  0.000000      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  0.324472      0.0  0.149662      0.0      0.0      0.0      0.0      0.0         1\n",
       "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.000000  0.000000  0.16371     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  0.000000     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  ...      0.0      0.0  0.000000      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  0.104466      0.0      0.0      0.0      0.0      0.0  0.210616      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  0.000000      0.0  0.000000      0.0      0.0      0.0      0.0      0.0         1\n",
       "4    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.000000  0.000000  0.00000     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  0.000000     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0  ...      0.0      0.0  0.000000      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  0.000000      0.0      0.0      0.0      0.0      0.0  0.000000      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  0.000000      0.0  0.000000      0.0      0.0      0.0      0.0      0.0         1\n",
       "\n",
       "[5 rows x 1001 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.sparse\n",
    "\n",
    "sdf = pd.DataFrame.sparse.from_spmatrix(X)\n",
    "\n",
    "sdf.columns = ['col_{}'.format(i) for i in range(X.shape[1])]\n",
    "\n",
    "sdf = sdf.fillna(0)\n",
    "\n",
    "sdf['feedback']= y\n",
    "\n",
    "sdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "853040ea-6b10-4fb8-9918-bb902b5c8f29",
     "showTitle": false,
     "title": ""
    },
    "id": "-ps3PB3LI3r4",
    "outputId": "351cb0b3-e4c8-4b87-c75b-4ae0821539a1"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/spark/python/pyspark/sql/pandas/conversion.py:401: UserWarning: createDataFrame attempted Arrow optimization because 'spark.sql.execution.arrow.pyspark.enabled' is set to true; however, failed by the reason below:\n  Sparse pandas data (column col_0) not supported.\nAttempting non-optimization as 'spark.sql.execution.arrow.pyspark.fallback.enabled' is set to true.\n  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "input_spark_df = spark.createDataFrame(sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4cc2bcd6-125c-471c-af85-eb4b5c66ee48",
     "showTitle": false,
     "title": ""
    },
    "id": "0RuXso9XI3r4",
    "outputId": "595c9c0c-dc9b-4412-818d-d9d26446b184"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 2475\nTest Dataset Count: 675\n"
     ]
    }
   ],
   "source": [
    "(training_data, test_data) = input_spark_df.randomSplit([0.8, 0.2], seed = 100)\n",
    "\n",
    "print(\"Training Dataset Count: \" + str(training_data.count()))\n",
    "print(\"Test Dataset Count: \" + str(test_data.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c60e2d0-40de-49f6-912b-4981b0d092c4",
     "showTitle": false,
     "title": ""
    },
    "id": "ZlzC2GeDI3r5",
    "outputId": "043969b7-4be7-4421-93b6-2045e2a7bd22"
   },
   "outputs": [],
   "source": [
    "from sparknlp_jsl.base import *\n",
    "\n",
    "features_asm = FeaturesAssembler()\\\n",
    "    .setInputCols(['col_{}'.format(i) for i in range(X.shape[1])])\\\n",
    "    .setOutputCol(\"features\")\n",
    "        \n",
    "gen_clf = GenericClassifierApproach()\\\n",
    "    .setLabelColumn(\"feedback\")\\\n",
    "    .setInputCols([\"features\"])\\\n",
    "    .setOutputCol(\"prediction\")\\\n",
    "    .setEpochsNumber(50)\\\n",
    "    .setBatchSize(100)\\\n",
    "    .setFeatureScaling(\"zscore\")\\\n",
    "    .setFixImbalance(True)\\\n",
    "    .setLearningRate(0.001)\\\n",
    "    .setOutputLogsPath(\"file:/databricks/driver/generic_logs\")\\\n",
    "   #.setModelFile(\"/databricks/driver/gc_graph/pet_in1202D_out2.pb\")\n",
    "    \n",
    "clf_Pipeline = Pipeline(stages=[\n",
    "    features_asm, \n",
    "    gen_clf])\n",
    "\n",
    "clf_model = clf_Pipeline.fit(training_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2028c4f7-1bef-42bb-b0ff-8d4843bc6d75",
     "showTitle": false,
     "title": ""
    },
    "id": "dZN30blzI3r6",
    "outputId": "53679d19-01ef-495c-af24-bfd9fdc6a644"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n\n           0     0.5556    0.4110    0.4724        73\n           1     0.9308    0.9601    0.9452       602\n\n    accuracy                         0.9007       675\n   macro avg     0.7432    0.6855    0.7088       675\nweighted avg     0.8902    0.9007    0.8941       675\n\n0.9007407407407407\n"
     ]
    }
   ],
   "source": [
    "pred_df = clf_model.transform(test_data)\n",
    "\n",
    "preds_df = pred_df.select('feedback','prediction.result').toPandas()\n",
    "\n",
    "# Let's explode the array and get the item(s) inside of result column out\n",
    "preds_df['result'] = preds_df['result'].apply(lambda x : int(x[0]))\n",
    "\n",
    "# We are going to use sklearn to evalute the results on test dataset\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "print (classification_report(preds_df['result'], preds_df['feedback'], digits=4))\n",
    "\n",
    "print (accuracy_score(preds_df['result'], preds_df['feedback']))\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2198454510639858,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "3. Training a Text Classification Model",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
