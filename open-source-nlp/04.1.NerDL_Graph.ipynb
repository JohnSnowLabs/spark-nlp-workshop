{"cells":[{"cell_type":"markdown","metadata":{"id":"whTyBPfVKYDv"},"source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"]},{"cell_type":"markdown","metadata":{"id":"6v9klEY_nSoK"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/open-source-nlp/04.1.NerDL_Graph.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"88IkXOy8nUC3"},"source":["# Graph Generation for NerDL Model\n","\n","---\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ojGSbUnTLtXr"},"outputs":[],"source":["!pip install -q pyspark==3.4.1  spark-nlp==5.1.2\n","!pip install -q tensorflow==2.12.0\n","!pip install -q tensorflow_addons"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":254},"executionInfo":{"elapsed":36016,"status":"ok","timestamp":1696397187286,"user":{"displayName":"Vildan Sarıkaya","userId":"07789644790967768983"},"user_tz":240},"id":"IJbM-mJVLvtb","outputId":"08192879-9e22-480f-902f-186ff50f0f37"},"outputs":[{"output_type":"stream","name":"stdout","text":["Spark NLP version:  5.1.2\n","Apache Spark version:  3.4.1\n"]},{"output_type":"execute_result","data":{"text/plain":["<pyspark.sql.session.SparkSession at 0x7c3b2f57b5e0>"],"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://a49f93d6161d:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.4.1</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>Spark NLP</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "]},"metadata":{},"execution_count":2}],"source":["import sparknlp\n","from sparknlp.base import *\n","from sparknlp.annotator import *\n","\n","spark = sparknlp.start()\n","\n","print(\"Spark NLP version: \", sparknlp.version())\n","print(\"Apache Spark version: \", spark.version)\n","\n","spark"]},{"cell_type":"markdown","metadata":{"id":"hz4wBSTcL8Pm"},"source":["# TF Graph Builder\n","\n","`TFNerDLGraphBuilder` annotator can be used to create graph in the model training pipeline. This annotator inspects the data and creates the proper graph if a suitable version of TensorFlow (<= 2.7 ) is available. The graph is stored in the defined folder and loaded by the approach.\n","\n","**NOTE:** This annotator is avaliable on `sparknlp` version `v4.1.0` and after.\n","\n","**ATTENTION:** **Do not forget to play with the parameters of this annotator, it may affect the model performance that you want to train.**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"attFUE8ZMBfX"},"outputs":[],"source":["!mkdir ner_logs\n","!mkdir ner_graphs\n","\n","graph_folder = \"/content/ner_graphs\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cBzu52eAMFBT"},"outputs":[],"source":["graph_builder = TFNerDLGraphBuilder()\\\n","                      .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n","                      .setLabelColumn(\"label\")\\\n","                      .setGraphFile(\"auto\")\\\n","                      .setGraphFolder(graph_folder)\\\n","                      .setHiddenUnitsNumber(20)"]},{"cell_type":"markdown","metadata":{"id":"ACevCCpMMKpN"},"source":["*Train the model with `NerDLApproach` and let it use the graph generated by the builder.*\n","\n","You can find an example in [NERDL Training Notebook](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/4.NERDL_Training.ipynb).\n","\n","```python\n","# You can use any word embeddings you want (Glove, Elmo, Bert, custom etc.)\n","glove_embeddings = WordEmbeddingsModel.pretrained('glove_100d')\\\n","              .setInputCols([\"document\", \"token\"])\\\n","              .setOutputCol(\"embeddings\")\n","\n","nerTagger = NerDLApproach()\\\n","              .setInputCols([\"sentence\", \"token\", \"embeddings\"])\\\n","              .setLabelColumn(\"label\")\\\n","              .setOutputCol(\"ner\")\\\n","              .setMaxEpochs(3)\\\n","              .setLr(0.003)\\\n","              .setBatchSize(32)\\\n","              .setRandomSeed(0)\\\n","              .setVerbose(1)\\\n","              .setValidationSplit(0.2)\\\n","              .setEvaluationLogExtended(True) \\\n","              .setEnableOutputLogs(True)\\\n","              .setIncludeConfidence(True)\\\n","              .setGraphFolder(graph_folder)\\\n","              .setOutputLogsPath('ner_logs') # if not set, logs will be written to ~/annotator_logs\n","          \n","ner_pipeline = Pipeline(stages=[glove_embeddings,\n","                                graph_builder,\n","                                nerTagger])\n","```\n"]},{"cell_type":"markdown","metadata":{"id":"gn4Mfh26MN2M"},"source":["# Custom Graph"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lXEaePmbnRq-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696397188455,"user_tz":240,"elapsed":985,"user":{"displayName":"Vildan Sarıkaya","userId":"07789644790967768983"}},"outputId":"ea322a15-0a94-471a-9a31-84c403b02393"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-10-04 05:26:27--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/utils/graph_utils/nerdl/nerdl-graph/create_graph.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1545 (1.5K) [text/plain]\n","Saving to: ‘create_graph.py’\n","\n","\rcreate_graph.py       0%[                    ]       0  --.-KB/s               \rcreate_graph.py     100%[===================>]   1.51K  --.-KB/s    in 0s      \n","\n","2023-10-04 05:26:27 (30.5 MB/s) - ‘create_graph.py’ saved [1545/1545]\n","\n","--2023-10-04 05:26:27--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/utils/graph_utils/nerdl/nerdl-graph/dataset_encoder.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2543 (2.5K) [text/plain]\n","Saving to: ‘dataset_encoder.py’\n","\n","dataset_encoder.py  100%[===================>]   2.48K  --.-KB/s    in 0s      \n","\n","2023-10-04 05:26:28 (50.9 MB/s) - ‘dataset_encoder.py’ saved [2543/2543]\n","\n","--2023-10-04 05:26:28--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/utils/graph_utils/nerdl/nerdl-graph/ner_model.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 21853 (21K) [text/plain]\n","Saving to: ‘ner_model.py’\n","\n","ner_model.py        100%[===================>]  21.34K  --.-KB/s    in 0.001s  \n","\n","2023-10-04 05:26:28 (13.9 MB/s) - ‘ner_model.py’ saved [21853/21853]\n","\n","--2023-10-04 05:26:28--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/utils/graph_utils/nerdl/nerdl-graph/ner_model_saver.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2484 (2.4K) [text/plain]\n","Saving to: ‘ner_model_saver.py’\n","\n","ner_model_saver.py  100%[===================>]   2.43K  --.-KB/s    in 0s      \n","\n","2023-10-04 05:26:28 (48.3 MB/s) - ‘ner_model_saver.py’ saved [2484/2484]\n","\n","--2023-10-04 05:26:28--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/utils/graph_utils/nerdl/nerdl-graph/sentence_grouper.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 953 [text/plain]\n","Saving to: ‘sentence_grouper.py’\n","\n","sentence_grouper.py 100%[===================>]     953  --.-KB/s    in 0s      \n","\n","2023-10-04 05:26:28 (70.8 MB/s) - ‘sentence_grouper.py’ saved [953/953]\n","\n"]}],"source":["!wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/utils/graph_utils/nerdl/nerdl-graph/create_graph.py\n","!wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/utils/graph_utils/nerdl/nerdl-graph/dataset_encoder.py\n","!wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/utils/graph_utils/nerdl/nerdl-graph/ner_model.py\n","!wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/utils/graph_utils/nerdl/nerdl-graph/ner_model_saver.py\n","!wget https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/utils/graph_utils/nerdl/nerdl-graph/sentence_grouper.py"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ypu-r4GZj8r0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1696397194299,"user_tz":240,"elapsed":5850,"user":{"displayName":"Vildan Sarıkaya","userId":"07789644790967768983"}},"outputId":"d32fff80-a14a-4234-ab1c-abfb17890d72"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.12.0\n","Spark NLP is compiled with TensorFlow 1.15.0, Please use such version.\n","Current TensorFlow version:  2.12.0\n"]},{"output_type":"stream","name":"stderr","text":["/content/ner_model.py:217: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n","  assert(self._word_embeddings_added or self._char_cnn_added or self._char_bilstm_added,\n","/content/ner_model.py:249: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n","  assert(self._context_added,\n","/content/ner_model.py:295: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n","  assert(self._inference_added,\n","/content/ner_model.py:391: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n","  assert(self._training_added, \"Add training layer by method add_training_op before running training\")\n"]}],"source":["import create_graph\n","\n","ntags = 19 # number of labels\n","embeddings_dim = 100\n","nchars = 100\n","\n","create_graph.create_graph(ntags, embeddings_dim, nchars)\n","\n","# then put your graph file (pb) under a folder and set it with .setGraphFolder('folder') in NerDLApproach"]}],"metadata":{"accelerator":"TPU","colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"tf-gpu","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"vscode":{"interpreter":{"hash":"3f47d918ae832c68584484921185f5c85a1760864bf927a683dc6fb56366cc77"}}},"nbformat":4,"nbformat_minor":0}