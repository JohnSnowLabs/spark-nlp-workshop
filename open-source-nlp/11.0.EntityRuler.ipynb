{"cells":[{"cell_type":"markdown","metadata":{"id":"V2rdmvrPDlZA"},"source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"6KvNW4MU5rrF","outputId":"4f640fd8-41e8-4f35-c6d6-ed98ab926127"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/open-source-nlp/11.0.EntityRuler.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"GZx3ReWigu_W"},"source":["# Rule-based Entity Recognition with EntityRuler"]},{"cell_type":"markdown","metadata":{"id":"3JKV2top7095"},"source":["This notebook will cover the different parameter and usage of **EntityRuler**. There are 2 annotators to perform this task in Spark NLP; `EntityRulerApproach` and `EntityRulerModel`. <br/>\n","\n","- `EntityRulerApproach` fits an Annotator to match exact strings or regex patterns provided in a file against a Document and assigns them an named entity. The definitions can contain any number of named entities. \n","- `EntityRulerModel` is instantiated model of the `EntityRulerApproach`"]},{"cell_type":"markdown","metadata":{"id":"SSgvnsj_Etcq"},"source":["## Install Spark NLP"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q0HMq9H5Wdb3"},"outputs":[],"source":["!pip install -q pyspark==3.3.0 spark-nlp==4.3.2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":219},"id":"1DRf_M0KlMV7","outputId":"296a89ad-da1d-429c-c8bc-c759c96bbfe4"},"outputs":[{"data":{"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://b9f8d542b77a:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.3.0</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>Spark NLP</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "],"text/plain":["<pyspark.sql.session.SparkSession at 0x7f49d188bf40>"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["import sparknlp\n","from sparknlp.base import *\n","from sparknlp.annotator import *\n","from pyspark.sql import functions as F\n","from pyspark.sql import SparkSession\n","\n","spark = sparknlp.start()\n","spark"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_eB72Yzg8_Jx"},"outputs":[],"source":["data = spark.createDataFrame([[\"Lord Eddard Stark was the head of House Stark. John Snow lives in Winterfell.\"]]).toDF(\"text\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mi7ENdn0MTvt","outputId":"42c39e16-0736-45b3-8b51-7e2c57231264"},"outputs":[{"name":"stdout","output_type":"stream","text":["+-----------------------------------------------------------------------------+\n","|text                                                                         |\n","+-----------------------------------------------------------------------------+\n","|Lord Eddard Stark was the head of House Stark. John Snow lives in Winterfell.|\n","+-----------------------------------------------------------------------------+\n","\n"]}],"source":["data.show(truncate=False)"]},{"cell_type":"markdown","metadata":{"id":"1o6BJQba7qT8"},"source":["# EntityRulerApproach"]},{"cell_type":"markdown","metadata":{"id":"69UzeVcXCcNc"},"source":["## Keywords Patterns"]},{"cell_type":"markdown","metadata":{"id":"6YTnzWsW5veU"},"source":["EntityRuler will handle the chunks output based on the patterns defined, as shown in the example below."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-qPpbCxYIyHy"},"outputs":[],"source":["import json\n","\n","keywords = [\n","          {\n","            \"label\": \"PERSON\",\n","            \"patterns\": [\"Jon\", \"John\", \"John Snow\", \"Jon Snow\"]\n","          },\n","          {\n","            \"label\": \"PERSON\",\n","            \"patterns\": [\"Eddard\", \"Eddard Stark\"]\n","          },\n","          {\n","            \"label\": \"LOCATION\",\n","            \"patterns\": [\"Winterfell\"]\n","          },\n","         ]\n","\n","with open('./keywords.json', 'w') as jsonfile:\n","    json.dump(keywords, jsonfile)"]},{"cell_type":"markdown","metadata":{"id":"Rdrsm2rfrACF"},"source":["We are going to use a JSON file with the following format:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FbP7UtSrLnQ3","outputId":"e2e40ae2-598f-43d9-cb71-5abb8fd66072"},"outputs":[{"name":"stdout","output_type":"stream","text":["cat: ./person.json: No such file or directory\n"]}],"source":["! cat ./person.json"]},{"cell_type":"markdown","metadata":{"id":"dgSHiRHc8eM2"},"source":["When working with keywords, we DON'T need a pipeline with Tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tRyju8D-6XJ1"},"outputs":[],"source":["document_assembler = DocumentAssembler().setInputCol(\"text\").setOutputCol(\"document\")\n","sentence_detector = SentenceDetector().setInputCols(\"document\").setOutputCol(\"sentence\")\n","\n","entity_ruler = EntityRulerApproach() \\\n","    .setInputCols([\"sentence\"]) \\\n","    .setOutputCol(\"entity\") \\\n","    .setPatternsResource(\"./keywords.json\") \\\n","    .setUseStorage(True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FhKPEMb09w6a"},"outputs":[],"source":["pipeline = Pipeline(stages=[document_assembler, sentence_detector, entity_ruler])\n","pipeline_model = pipeline.fit(data)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D7mjcA2E_ehu","outputId":"f4217999-7b50-4dca-db28-27787b71924c"},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|entity                                                                                                                                                                                                        |\n","+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|[{chunk, 5, 16, Eddard Stark, {entity -> PERSON, sentence -> 0}, []}, {chunk, 47, 55, John Snow, {entity -> PERSON, sentence -> 1}, []}, {chunk, 66, 75, Winterfell, {entity -> LOCATION, sentence -> 1}, []}]|\n","+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","\n"]}],"source":["pipeline_model.transform(data).select(\"entity\").show(truncate=False)"]},{"cell_type":"markdown","metadata":{"id":"9LAxooiQNYVv"},"source":["We can define an id field to identify entities and it supports JSON Lines format as the example below."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V8_KVQvdBDm8"},"outputs":[],"source":["keywords = [\n","            {\n","              \"id\": \"names-with-j\",\n","              \"label\": \"PERSON\",\n","              \"patterns\": [\"Jon\", \"John\", \"John Snow\", \"Jon Snow\"]\n","            },\n","            {\n","              \"id\": \"names-with-e\",\n","              \"label\": \"PERSON\",\n","              \"patterns\": [\"Eddard\", \"Eddard Stark\"]\n","            },\n","            {\n","              \"id\": \"locations\",\n","              \"label\": \"LOCATION\",\n","              \"patterns\": [\"Winterfell\"]\n","            },\n","         ]\n","\n","with open('./keywords.jsonl', 'w') as jsonlfile:\n","    for keyword in keywords:\n","      json.dump(keyword, jsonlfile)\n","      jsonlfile.write('\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OWakfKMlB3Th","outputId":"3bd96015-923c-45c0-86b9-6fe648a10609"},"outputs":[{"name":"stdout","output_type":"stream","text":["{\"id\": \"names-with-j\", \"label\": \"PERSON\", \"patterns\": [\"Jon\", \"John\", \"John Snow\", \"Jon Snow\"]}\n","{\"id\": \"names-with-e\", \"label\": \"PERSON\", \"patterns\": [\"Eddard\", \"Eddard Stark\"]}\n","{\"id\": \"locations\", \"label\": \"LOCATION\", \"patterns\": [\"Winterfell\"]}\n"]}],"source":["! cat ./keywords.jsonl"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-_4a1QYaNPfr"},"outputs":[],"source":["entity_ruler = EntityRulerApproach() \\\n","    .setInputCols([\"sentence\"]) \\\n","    .setOutputCol(\"entity\") \\\n","    .setPatternsResource(\"./keywords.jsonl\", ReadAs.TEXT, options={\"format\": \"JSONL\"}) \\\n","    .setUseStorage(True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cd0sNKNeOcUg","outputId":"1692f5f3-ad08-4ff4-a4b7-2b1c3fd2619e"},"outputs":[{"name":"stdout","output_type":"stream","text":["+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|entity                                                                                                                                                                                                                                                                 |\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|[{chunk, 5, 16, Eddard Stark, {entity -> PERSON, sentence -> 0, id -> names-with-e}, []}, {chunk, 47, 55, John Snow, {entity -> PERSON, sentence -> 1, id -> names-with-j}, []}, {chunk, 66, 75, Winterfell, {entity -> LOCATION, sentence -> 1, id -> locations}, []}]|\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","\n"]}],"source":["pipeline = Pipeline(stages=[document_assembler, sentence_detector, entity_ruler])\n","model = pipeline.fit(data)\n","model.transform(data).select(\"entity\").show(truncate=False)"]},{"cell_type":"markdown","metadata":{"id":"lDZ21hp3rOHV"},"source":["For the CSV file we use the following configuration:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_MLFqq-ICy56"},"outputs":[],"source":["with open('./keywords.csv', 'w') as csvfile:\n","    csvfile.write('PERSON|Jon\\n')\n","    csvfile.write('PERSON|John\\n')\n","    csvfile.write('PERSON|John Snow\\n')\n","    csvfile.write('LOCATION|Winterfell')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bz4129WyDNwd","outputId":"b3f6cd9c-ad42-4fc2-e63c-84430db5c753"},"outputs":[{"name":"stdout","output_type":"stream","text":["PERSON|Jon\n","PERSON|John\n","PERSON|John Snow\n","LOCATION|Winterfell"]}],"source":["! cat ./keywords.csv"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0HLcNfrdoAmP"},"outputs":[],"source":["entity_ruler_csv = EntityRulerApproach() \\\n","    .setInputCols([\"sentence\"]) \\\n","    .setOutputCol(\"entity\") \\\n","    .setPatternsResource(\"./keywords.csv\", options={\"format\": \"csv\", \"delimiter\": \"\\\\|\"}) \\\n","    .setUseStorage(True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NYTuwztwoHIK"},"outputs":[],"source":["pipeline_csv = Pipeline(stages=[document_assembler, sentence_detector, entity_ruler_csv])\n","model_csv = pipeline_csv.fit(data)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qEN-zRNQoLu5","outputId":"c923acd1-4b12-4f29-9727-06ad02e91595"},"outputs":[{"name":"stdout","output_type":"stream","text":["+-----------------------------------------------------------------------------------------------------------------------------------------+\n","|entity                                                                                                                                   |\n","+-----------------------------------------------------------------------------------------------------------------------------------------+\n","|[{chunk, 47, 55, John Snow, {entity -> PERSON, sentence -> 1}, []}, {chunk, 66, 75, Winterfell, {entity -> LOCATION, sentence -> 1}, []}]|\n","+-----------------------------------------------------------------------------------------------------------------------------------------+\n","\n"]}],"source":["model_csv.transform(data).select(\"entity\").show(truncate=False)"]},{"cell_type":"markdown","metadata":{"id":"FmLiqAYhn5DT"},"source":["## Regex Patterns"]},{"cell_type":"markdown","metadata":{"id":"V4h5Ulxyn-rE"},"source":["Starting with Spark NLP 4.2.0 regex patterns must be defined at a more granular level, with each label. For example we can have the JSON file below"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1QQvXA4Zqelm"},"outputs":[],"source":["data = spark.createDataFrame([[\"The address is 123456 in Winterfell\"]]).toDF(\"text\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oZZWlpFknvn1"},"outputs":[],"source":["patterns_string = \"\"\"\n","[\n","  {\n","    \"id\": \"id-regex\",\n","    \"label\": \"ID\",\n","    \"patterns\": [\"[0-9]+\"],\n","    \"regex\": true\n","  },\n","  {\n","    \"id\": \"locations-words\",\n","    \"label\": \"LOCATION\",\n","    \"patterns\": [\"Winterfell\"],\n","    \"regex\": false\n","  }\n","]\n","\"\"\"\n","patterns_obj = json.loads(patterns_string)\n","with open('./patterns.json', 'w') as jsonfile:\n","    json.dump(patterns_obj, jsonfile)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xnp0zMqpogVU","outputId":"bcf7b9c2-c421-4c85-aad7-5212c859c055"},"outputs":[{"name":"stdout","output_type":"stream","text":["[{\"id\": \"id-regex\", \"label\": \"ID\", \"patterns\": [\"[0-9]+\"], \"regex\": true}, {\"id\": \"locations-words\", \"label\": \"LOCATION\", \"patterns\": [\"Winterfell\"], \"regex\": false}]"]}],"source":["!cat ./patterns.json"]},{"cell_type":"markdown","metadata":{"id":"9RcZIelWorQ9"},"source":["When defining a regex pattern, we need to define Tokenizer annotator in the pipeline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rCUYCM56oq-e"},"outputs":[],"source":["tokenizer = Tokenizer().setInputCols(\"sentence\").setOutputCol(\"token\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TJvrwk18pGqk"},"outputs":[],"source":["regex_entity_ruler = EntityRulerApproach() \\\n","    .setInputCols([\"sentence\", \"token\"]) \\\n","    .setOutputCol(\"entity\") \\\n","    .setPatternsResource(\"./patterns.json\") \\\n","    .setUseStorage(True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7v8TbKbo0Izg"},"outputs":[],"source":["regex_pipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, regex_entity_ruler])\n","regex_model = regex_pipeline.fit(data)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pl63WAaq0TKa","outputId":"70bd9e49-5c72-4933-92db-6fb30afa5f31"},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|entity                                                                                                                                                                   |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|[{chunk, 15, 20, 123456, {entity -> ID, id -> id-regex, sentence -> 0}, []}, {chunk, 25, 34, Winterfell, {entity -> LOCATION, sentence -> 0, id -> locations-words}, []}]|\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","\n"]}],"source":["regex_model.transform(data).select(\"entity\").show(truncate=False)"]},{"cell_type":"markdown","metadata":{"id":"BMZ8eyXR1ELB"},"source":["# `EntityRulerModel`"]},{"cell_type":"markdown","metadata":{"id":"4-50Tixl2WLt"},"source":["This annotator is an instantiated model of the `EntityRulerApproach`. Once you build an `EntityRulerApproach()`, you can save it and use it with `EntityRulerModel()` via `load()` function. <br/>\n","\n","Let's re-build one of examples that we have done before and save it. "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WDZqgtLu1MsY","outputId":"33869aab-84b7-47d9-e06f-d1845534d0c8"},"outputs":[{"name":"stdout","output_type":"stream","text":["+-----------------------------------------------------------------------------+\n","|text                                                                         |\n","+-----------------------------------------------------------------------------+\n","|Lord Eddard Stark was the head of House Stark. John Snow lives in Winterfell.|\n","+-----------------------------------------------------------------------------+\n","\n"]}],"source":["data = spark.createDataFrame([[\"Lord Eddard Stark was the head of House Stark. John Snow lives in Winterfell.\"]]).toDF(\"text\")\n","data.show(truncate=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4zd_7q134dCv"},"outputs":[],"source":["#Defining the source JSON file and saving\n","import json\n","\n","keywords = [\n","          {\n","            \"label\": \"PERSON\",\n","            \"patterns\": [\"Jon\", \"John\", \"John Snow\", \"Jon Snow\"]\n","          },\n","          {\n","            \"label\": \"PERSON\",\n","            \"patterns\": [\"Eddard\", \"Eddard Stark\"]\n","          },\n","          {\n","            \"label\": \"LOCATION\",\n","            \"patterns\": [\"Winterfell\"]\n","          },\n","         ]\n","\n","with open('keywords.json', 'w') as jsonfile:\n","    json.dump(keywords, jsonfile)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qaBRAtop0zyl"},"outputs":[],"source":["entity_ruler = EntityRulerApproach() \\\n","    .setInputCols([\"sentence\"]) \\\n","    .setOutputCol(\"entity\") \\\n","    .setPatternsResource(\"keywords.json\") \n","    \n","pipeline = Pipeline(stages=[document_assembler, \n","                            sentence_detector, \n","                            entity_ruler])\n","\n","pipeline_model = pipeline.fit(data)\n","result= pipeline_model.transform(data)"]},{"cell_type":"markdown","metadata":{"id":"kRjiiW_I2_m9"},"source":["Saving the approach to disk"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FaGeCIj5YVYC"},"outputs":[],"source":["pipeline_model.stages[2].write().overwrite().save('models/ruler_approach_model')"]},{"cell_type":"markdown","metadata":{"id":"2I7E0wkV3C5u"},"source":["Loading the saved model and using it with the `EntityRulerModel()` via `load`. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RHdhw2t-6pmL"},"outputs":[],"source":["entity_ruler = EntityRulerModel.load('/content/models/ruler_approach_model') \\\n","    .setInputCols([\"sentence\"]) \\\n","    .setOutputCol(\"entity\") \n","\n","pipeline = Pipeline(stages=[document_assembler, \n","                            sentence_detector, \n","                            entity_ruler])\n","\n","pipeline_model = pipeline.fit(data)\n","result = pipeline_model.transform(data)"]},{"cell_type":"markdown","metadata":{"id":"kT6h7Hoy3Qkw"},"source":["Checking the result"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z_Qr9g_y1uaN","outputId":"08074404-8067-48ee-90aa-030f96847169"},"outputs":[{"name":"stdout","output_type":"stream","text":["+------------+--------+\n","|     keyword|   label|\n","+------------+--------+\n","|Eddard Stark|  PERSON|\n","|   John Snow|  PERSON|\n","|  Winterfell|LOCATION|\n","+------------+--------+\n","\n"]}],"source":["result.select(F.explode(F.arrays_zip(result.entity.result, result.entity.metadata)).alias('col'))\\\n","      .select(F.expr(\"col['0']\").alias(\"keyword\"),\n","              F.expr(\"col['1']['entity']\").alias(\"label\")).show()"]},{"cell_type":"markdown","metadata":{"id":"D9nSEExz3STL"},"source":["As seen above, we built an `EntityRuler`, saved it and used the saved model with `EntityRulerModel`. "]},{"cell_type":"markdown","metadata":{"id":"uuN7dw05_AlD"},"source":["### Using LightPipeline"]},{"cell_type":"markdown","metadata":{"id":"f3IXo3vO_H0s"},"source":["The EntityRuler annotator can also be applied by using LightPipeline:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IS8fN6lh_AlD"},"outputs":[],"source":["light_pipeline = LightPipeline(pipeline_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qpM8ed-G_AlD","outputId":"6482c8f1-19d0-4ac4-f7aa-3d7e9e3b8421"},"outputs":[{"data":{"text/plain":["dict_keys(['document', 'sentence', 'entity'])"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["annotations = light_pipeline.fullAnnotate(\"Doctor John Snow lives in London, whereas Lord Commander Jon Snow lives in Castle Black\")[0]\n","annotations.keys()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BuvodYEI_AlE","outputId":"7c076183-aa8f-446f-c460-71531f3d89b0"},"outputs":[{"data":{"text/plain":["[Annotation(chunk, 7, 15, John Snow, {'entity': 'PERSON', 'sentence': '0'}, []),\n"," Annotation(chunk, 57, 64, Jon Snow, {'entity': 'PERSON', 'sentence': '0'}, [])]"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["annotations.get('entity')"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}