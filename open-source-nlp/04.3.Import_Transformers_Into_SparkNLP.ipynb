{"cells":[{"cell_type":"markdown","metadata":{"id":"Jjblr56uRTJf"},"source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"]},{"cell_type":"markdown","metadata":{"id":"2vXYNX2lQROB"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/open-source-nlp/04.3.Import_Transformers_Into_SparkNLP.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"nkays-Ij-wI9"},"source":["## Import Transformers from HuggingFace ðŸ¤—  into Spark NLP ðŸš€\n","Let's keep in mind that this feature is only in Spark NLP 3.2.x and after. So please make sure you have upgraded to the latest Spark NLP release\n"]},{"cell_type":"markdown","metadata":{"id":"MzxB-Nq6cxOA"},"source":["## Export and Save HuggingFace model"]},{"cell_type":"markdown","metadata":{"id":"yNQkhyMHMgkE"},"source":["- Let's install `HuggingFace` and `TensorFlow`. You don't need `TensorFlow` to be installed for Spark NLP, however, we need it to load and save models from HuggingFace.\n","- We lock TensorFlow on `2.4.4` version and Transformers on `4.25.0`. This doesn't mean it won't work with the future releases, but we wanted you to know which versions have been tested successfully."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hHXgqiWpMfCY"},"outputs":[],"source":["!pip install -q transformers==4.25.1 tensorflow==2.11.0"]},{"cell_type":"markdown","metadata":{"id":"Y3AM6bj4P3NS"},"source":["- HuggingFace comes with a native `saved_model` feature inside `save_pretrained` function for TensorFlow based models. We will use that to save it as TF `SavedModel`.\n","- We'll use [dslim/bert-base-NER](https://huggingface.co/dslim/bert-base-NER) model from HuggingFace as an example\n","- In addition to `TFBertForTokenClassification` we also need to save the `BertTokenizer`. This is the same for every model, these are assets needed for tokenization inside Spark NLP."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZaiirlSKNhVD"},"outputs":[],"source":["from transformers import TFBertForTokenClassification, BertTokenizer\n","import tensorflow as tf\n","\n","MODEL_NAME = 'dslim/bert-base-NER'\n","\n","tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n","tokenizer.save_pretrained('./{}_tokenizer/'.format(MODEL_NAME))\n","\n","# just in case if there is no TF/Keras file provided in the model\n","# we can just use `from_pt` and convert PyTorch to TensorFlow\n","try:\n","  print('try downloading TF weights')\n","  model = TFBertForTokenClassification.from_pretrained(MODEL_NAME)\n","except:\n","  print('try downloading PyTorch weights')\n","  model = TFBertForTokenClassification.from_pretrained(MODEL_NAME, from_pt=True)\n","\n","# Define TF Signature\n","@tf.function(\n","  input_signature=[\n","      {\n","          \"input_ids\": tf.TensorSpec((None, None), tf.int32, name=\"input_ids\"),\n","          \"attention_mask\": tf.TensorSpec((None, None), tf.int32, name=\"attention_mask\"),\n","          \"token_type_ids\": tf.TensorSpec((None, None), tf.int32, name=\"token_type_ids\"),\n","      }\n","  ]\n",")\n","def serving_fn(input):\n","    return model(input)\n","\n","model.save_pretrained(\"./{}\".format(MODEL_NAME), saved_model=True, signatures={\"serving_default\": serving_fn})\n"]},{"cell_type":"markdown","metadata":{"id":"nlgyZuJfS5IB"},"source":["Let's have a look inside these two directories and see what we are dealing with:"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1688973244904,"user":{"displayName":"Damla","userId":"03285166568766987047"},"user_tz":-120},"id":"p2XCole7TTef","outputId":"2664533c-6866-47e9-d400-055f9f344ab7"},"outputs":[{"output_type":"stream","name":"stdout","text":["total 421084\n","-rw-r--r-- 1 root root       999 Jul 10 07:13 config.json\n","drwxr-xr-x 3 root root      4096 Jul 10 07:12 saved_model\n","-rw-r--r-- 1 root root 431179756 Jul 10 07:13 tf_model.h5\n"]}],"source":["!ls -l {MODEL_NAME}"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1688973246125,"user":{"displayName":"Damla","userId":"03285166568766987047"},"user_tz":-120},"id":"r0DOGz8VUR-r","outputId":"54c144e5-e4f3-454a-e587-019fcdc328d8"},"outputs":[{"output_type":"stream","name":"stdout","text":["total 9152\n","drwxr-xr-x 2 root root    4096 Jul 10 07:13 assets\n","-rw-r--r-- 1 root root      55 Jul 10 07:13 fingerprint.pb\n","-rw-r--r-- 1 root root  165837 Jul 10 07:13 keras_metadata.pb\n","-rw-r--r-- 1 root root 9190258 Jul 10 07:13 saved_model.pb\n","drwxr-xr-x 2 root root    4096 Jul 10 07:13 variables\n"]}],"source":["!ls -l {MODEL_NAME}/saved_model/1"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1688973247471,"user":{"displayName":"Damla","userId":"03285166568766987047"},"user_tz":-120},"id":"Mcm2UpNxUUQN","outputId":"2f461561-542d-4ae1-a7ca-a7eefb9f6da0"},"outputs":[{"output_type":"stream","name":"stdout","text":["total 220\n","-rw-r--r-- 1 root root    125 Jul 10 07:12 special_tokens_map.json\n","-rw-r--r-- 1 root root    551 Jul 10 07:12 tokenizer_config.json\n","-rw-r--r-- 1 root root 213450 Jul 10 07:12 vocab.txt\n"]}],"source":["!ls -l {MODEL_NAME}_tokenizer"]},{"cell_type":"markdown","metadata":{"id":"gZegMvuGTmHt"},"source":["- As you can see, we need the SavedModel from `saved_model/1/` path\n","- We also be needing `vocab.txt` from the tokenizer\n","- All we need is to just copy the `vocab.txt` to `saved_model/1/assets` which Spark NLP will look for\n","- In addition to vocabs, we also need `labels` and their `ids` which is saved inside the model's config. We will save this inside `labels.txt`"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":438,"status":"ok","timestamp":1688973250941,"user":{"displayName":"Damla","userId":"03285166568766987047"},"user_tz":-120},"id":"ez6MT-RTT7ss"},"outputs":[],"source":["asset_path = '{}/saved_model/1/assets'.format(MODEL_NAME)\n","\n","!cp {MODEL_NAME}_tokenizer/vocab.txt {asset_path}"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1688973251919,"user":{"displayName":"Damla","userId":"03285166568766987047"},"user_tz":-120},"id":"vcg_5YP1-vfC"},"outputs":[],"source":["# get label2id dictionary\n","labels = model.config.label2id\n","# sort the dictionary based on the id\n","labels = sorted(labels, key=labels.get)\n","\n","with open(asset_path+'/labels.txt', 'w') as f:\n","    f.write('\\n'.join(labels))"]},{"cell_type":"markdown","metadata":{"id":"mBq7ztzlACYO"},"source":["Voila! We have our `vocab.txt` and `labels.txt` inside assets directory"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":427,"status":"ok","timestamp":1688973253904,"user":{"displayName":"Damla","userId":"03285166568766987047"},"user_tz":-120},"id":"OYnT5U8N9dxT","outputId":"aef901a7-762b-4dc9-ae35-e72003682a58"},"outputs":[{"output_type":"stream","name":"stdout","text":["total 216\n","-rw-r--r-- 1 root root     51 Jul 10 07:14 labels.txt\n","-rw-r--r-- 1 root root 213450 Jul 10 07:14 vocab.txt\n"]}],"source":["! ls -l {MODEL_NAME}/saved_model/1/assets"]},{"cell_type":"markdown","metadata":{"id":"NlJKd2tIU0PD"},"source":["## Import and Save BertForTokenClassification in Spark NLP\n"]},{"cell_type":"markdown","metadata":{"id":"A0FXoxHJc5CU"},"source":["- Let's install and setup Spark NLP in Google Colab"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZEaBzzZ5jQ4u"},"outputs":[],"source":["! pip install -q pyspark==3.3.0 spark-nlp==5.0.0"]},{"cell_type":"markdown","metadata":{"id":"m_NAgx4hdCGP"},"source":["Let's start Spark with Spark NLP included via our simple `start()` function"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":151648,"status":"ok","timestamp":1688973443688,"user":{"displayName":"Damla","userId":"03285166568766987047"},"user_tz":-120},"id":"cbNneAVCLU1y"},"outputs":[],"source":["import sparknlp\n","\n","spark = sparknlp.start()"]},{"cell_type":"markdown","metadata":{"id":"ABTu9MrdVafM"},"source":["- Let's use `loadSavedModel` functon in `BertForTokenClassification` which allows us to load TensorFlow model in SavedModel format\n","- Most params can be set later when you are loading this model in `BertForTokenClassification` in runtime like `setMaxSentenceLength`, so don't worry what you are setting them now\n","- `loadSavedModel` accepts two params, first is the path to the TF SavedModel. The second is the SparkSession that is `spark` variable we previously started via `sparknlp.start()`\n","- NOTE: `loadSavedModel` only accepts local paths and not distributed file systems such as `HDFS`, `S3`, `DBFS`, etc. That is why we use `write.save` so we can use `.load()` from any file systems\n","\n"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":11838,"status":"ok","timestamp":1688973455517,"user":{"displayName":"Damla","userId":"03285166568766987047"},"user_tz":-120},"id":"8W_almibVRTj"},"outputs":[],"source":["from sparknlp.annotator import *\n","from sparknlp.base import *\n","\n","tokenClassifier = BertForTokenClassification.loadSavedModel(\n","     '{}/saved_model/1'.format(MODEL_NAME),\n","     spark\n"," )\\\n"," .setInputCols([\"document\",'token'])\\\n"," .setOutputCol(\"ner\")\\\n"," .setCaseSensitive(True)\\\n"," .setMaxSentenceLength(128)"]},{"cell_type":"markdown","metadata":{"id":"PjGiq4KnXWuy"},"source":["- Let's save it on disk so it is easier to be moved around and also be used later via `.load` function"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":11055,"status":"ok","timestamp":1688973466565,"user":{"displayName":"Damla","userId":"03285166568766987047"},"user_tz":-120},"id":"iWu5HfbnXAlM"},"outputs":[],"source":["tokenClassifier.write().overwrite().save(\"./{}_spark_nlp\".format(MODEL_NAME))"]},{"cell_type":"markdown","metadata":{"id":"QCrjxPhzDplN"},"source":["Let's clean up stuff we don't need anymore"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":594,"status":"ok","timestamp":1688973467151,"user":{"displayName":"Damla","userId":"03285166568766987047"},"user_tz":-120},"id":"ZgkVIJshDtLx"},"outputs":[],"source":["! rm -rf {MODEL_NAME}_tokenizer {MODEL_NAME}"]},{"cell_type":"markdown","metadata":{"id":"zeQt3UFv3vVb"},"source":["Awesome!\n","\n","This is your BertForTokenClassification model from HuggingFace ðŸ¤—  loaded and saved by Spark NLP ðŸš€"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1688973467151,"user":{"displayName":"Damla","userId":"03285166568766987047"},"user_tz":-120},"id":"ogpxSWxOXj3W","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e2842958-b15d-46f8-8c4e-4db3889979dd"},"outputs":[{"output_type":"stream","name":"stdout","text":["total 429708\n","-rw-r--r-- 1 root root 440007243 Jul 10 07:17 bert_classification_tensorflow\n","drwxr-xr-x 5 root root      4096 Jul 10 07:17 fields\n","drwxr-xr-x 2 root root      4096 Jul 10 07:17 metadata\n"]}],"source":["! ls -l {MODEL_NAME}_spark_nlp"]},{"cell_type":"markdown","metadata":{"id":"Fbehje7fYTDj"},"source":["Now let's see how we can use it on other machines, clusters, or any place you wish to use your new and shiny BertForTokenClassification model"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":8776,"status":"ok","timestamp":1688973475924,"user":{"displayName":"Damla","userId":"03285166568766987047"},"user_tz":-120},"id":"1mm3CvkwYRgs"},"outputs":[],"source":["tokenClassifier_loaded = BertForTokenClassification.load(\"./{}_spark_nlp\".format(MODEL_NAME))\\\n","  .setInputCols([\"document\",'token'])\\\n","  .setOutputCol(\"ner\")"]},{"cell_type":"markdown","metadata":{"id":"_he2LDtBYo1h"},"source":["That's it! You can now go wild and use hundreds of `BertForTokenClassification` models from HuggingFace ðŸ¤— in Spark NLP ðŸš€\n"]},{"cell_type":"markdown","metadata":{"id":"BDWNWdBlBpHi"},"source":["You can see what labels were used to train this model via `getClasses` function:"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1688973475926,"user":{"displayName":"Damla","userId":"03285166568766987047"},"user_tz":-120},"id":"pGRTNISyYlnO","colab":{"base_uri":"https://localhost:8080/"},"outputId":"96f0771b-9271-4e68-dc69-9bf9ddea0ca3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['B-LOC', 'I-ORG', 'I-MISC', 'I-LOC', 'I-PER', 'B-MISC', 'B-ORG', 'O', 'B-PER']"]},"metadata":{},"execution_count":16}],"source":["tokenClassifier_loaded.getClasses()"]},{"cell_type":"markdown","metadata":{"id":"UvRBsP2SBpHi"},"source":["This is how you can use your loaded classifier model in Spark NLP ðŸš€ pipeline:"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":10273,"status":"ok","timestamp":1688973486191,"user":{"displayName":"Damla","userId":"03285166568766987047"},"user_tz":-120},"id":"MysnSyi8BpHi","colab":{"base_uri":"https://localhost:8080/"},"outputId":"961f565d-5dcb-4840-c317-9eacaa26aad1"},"outputs":[{"output_type":"stream","name":"stdout","text":["+----------------------------------------------------+------------------------------------------------+\n","|text                                                |result                                          |\n","+----------------------------------------------------+------------------------------------------------+\n","|My name is Sarah and I live in London               |[O, O, O, B-PER, O, O, O, O, B-LOC]             |\n","|My name is Clara and I live in Berkeley, California.|[O, O, O, B-PER, O, O, O, O, B-LOC, O, B-LOC, O]|\n","+----------------------------------------------------+------------------------------------------------+\n","\n"]}],"source":["document_assembler = DocumentAssembler() \\\n","    .setInputCol('text') \\\n","    .setOutputCol('document')\n","\n","tokenizer = Tokenizer() \\\n","    .setInputCols(['document']) \\\n","    .setOutputCol('token')\n","\n","pipeline = Pipeline(stages=[\n","    document_assembler,\n","    tokenizer,\n","    tokenClassifier_loaded\n","])\n","\n","# couple of simple examples\n","example = spark.createDataFrame([[\"My name is Sarah and I live in London\"],\n","                                 [\"My name is Clara and I live in Berkeley, California.\"]]).toDF(\"text\")\n","\n","result = pipeline.fit(example).transform(example)\n","\n","# result is a DataFrame\n","result.select(\"text\", \"ner.result\").show(truncate=False)"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","toc_visible":true,"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"tf-gpu","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.9.7"},"vscode":{"interpreter":{"hash":"3f47d918ae832c68584484921185f5c85a1760864bf927a683dc6fb56366cc77"}}},"nbformat":4,"nbformat_minor":0}