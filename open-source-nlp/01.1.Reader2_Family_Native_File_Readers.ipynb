{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"collapsed_sections":["JAyS6KUQNwYz","iBRoCjkT_NSC"],"authorship_tag":"ABX9TyP8c6l+krVClo6YNnc0xK6s"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"JblJe8DTlGpl"},"source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"]},{"cell_type":"markdown","metadata":{"id":"_Hmv_AJA1rnu"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/open-source-nlp/01.1.Reader2_Family_Native_File_Readers.ipynb)"]},{"cell_type":"markdown","source":["# 01.1 Reader2 Family: Native File Readers in Spark NLP"],"metadata":{"id":"xKVLe0DWD24Q"}},{"cell_type":"markdown","source":["This notebook introduces the **Reader2 family of annotators**, a powerful set of components that bring native document ingestion directly into Spark NLP pipelines.\n","\n","With these readers, you can extract text, tables, and images from a wide range of file formats without external preprocessing, making large-scale document workflows simpler, faster, and more reproducible.\n","\n","## Overview\n","\n","The Reader2 annotators allow you to load and structure multi-format content directly as Spark NLP annotations:\n","\n","- **`Reader2Doc`**: extracts and structures textual content into `Document` annotations.  \n","- **`Reader2Image`**: extracts and structures images from standalone files or embedded media in documents.  \n","- **`Reader2Table`**: extracts and structures tabular data into machine-readable formats for downstream NLP or analytics tasks.\n","\n","Together, these annotators enable fully integrated **Document AI pipelines**, capable of reading, parsing, and analyzing complex documents end-to-end inside Spark NLP without needing external file readers, Pandas, or OCR preprocessing.\n","\n","## Supported File Formats\n","\n","| Reader | Supported File Types |\n","|:-------|:----------------------|\n","| **Reader2Doc** | TXT, HTML, DOC, DOCX, XLS, XLSX, PPT, PPTX, EML, MSG, PDF |\n","| **Reader2Image** | PNG, JPG, BMP, GIF, PDF, DOCX, PPTX, XLSX, HTML, EML |\n","| **Reader2Table** | HTML, DOCX, XLSX, PPTX, CSV |"],"metadata":{"id":"-YMzeACn_Vmj"}},{"cell_type":"markdown","metadata":{"id":"MfkkKkbVF309"},"source":["### **Colab Setup**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MS62MFbPfPRC"},"outputs":[],"source":["!wget -q http://setup.johnsnowlabs.com/colab.sh -O - | bash"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mc9eI8XqA7VY","colab":{"base_uri":"https://localhost:8080/","height":258},"executionInfo":{"status":"ok","timestamp":1761702799162,"user_tz":-300,"elapsed":202630,"user":{"displayName":"Abdullah Mubeen","userId":"17886490017623663394"}},"outputId":"ad59a6e9-e26e-4be0-f1aa-0e038ec08a37"},"outputs":[{"output_type":"stream","name":"stdout","text":["Spark NLP version 6.2.0\n","Apache Spark version: 3.5.1\n"]},{"output_type":"execute_result","data":{"text/plain":["<pyspark.sql.session.SparkSession at 0x7a5881447d70>"],"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://734845536a2f:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.5.1</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>Spark NLP</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "]},"metadata":{},"execution_count":3}],"source":["import sparknlp\n","from sparknlp.base import *\n","from sparknlp.annotator import *\n","from pyspark.ml import Pipeline\n","\n","spark = sparknlp.start(gpu=True)\n","\n","print(\"Spark NLP version\", sparknlp.version())\n","print(\"Apache Spark version:\", spark.version)\n","\n","spark"]},{"cell_type":"markdown","source":["### **Prepare data**"],"metadata":{"id":"rHFOQBfoIev9"}},{"cell_type":"code","source":["%%bash\n","set -e\n","git clone -q --no-checkout https://github.com/JohnSnowLabs/spark-nlp-workshop.git tmp\n","cd tmp\n","git sparse-checkout set reader2doc reader2table reader2image\n","git checkout -q\n","mkdir -p /content/files\n","mv reader2doc reader2table reader2image /content/files/\n","cd ..\n","rm -rf tmp\n"],"metadata":{"id":"GKw_flWkmiCD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls files"],"metadata":{"id":"eOW4T04vXKj6","executionInfo":{"status":"ok","timestamp":1761702802023,"user_tz":-300,"elapsed":116,"user":{"displayName":"Abdullah Mubeen","userId":"17886490017623663394"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a02f82ef-04be-4458-db61-9ff4f3fb89e2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["reader2doc  reader2image  reader2table\n"]}]},{"cell_type":"markdown","source":["## Reader2Doc\n","\n","\n"],"metadata":{"id":"Uio9UogXFOoX"}},{"cell_type":"markdown","source":["Instead of handling each file format separately (like PDFs, Word files, or emails), `Reader2Doc` abstracts away the complexity and outputs clean, unified text for every document into structured `Document` annotations. This makes it ideal for large-scale ingestion pipelines where documents come from mixed sources.\n","\n","*Supported File Formats:*\n","- Text: `.txt`  \n","- HTML: `.html`, `.htm`  \n","- Microsoft Word: `.doc`, `.docx`  \n","- Microsoft Excel: `.xls`, `.xlsx`  \n","- Microsoft PowerPoint: `.ppt`, `.pptx`  \n","- Email files: `.eml`, `.msg`  \n","- PDF documents: `.pdf`\n"],"metadata":{"id":"b577bCIQFV48"}},{"cell_type":"markdown","source":["> This annotator is usually the **first stage** of a document-based pipeline, preparing structured text for tokenization, sentence segmentation, or downstream NLP tasks."],"metadata":{"id":"MyhlajNaIW7Z"}},{"cell_type":"markdown","source":["### Basic usage"],"metadata":{"id":"N7wPvcnjN2qa"}},{"cell_type":"markdown","source":["Lets define our Pipeline"],"metadata":{"id":"cZmQsu_dM3Lz"}},{"cell_type":"code","source":["from sparknlp.reader.reader2doc import Reader2Doc\n","\n","reader2doc = Reader2Doc().setContentPath(\"files/reader2doc\")\n","pipeline = Pipeline(stages=[reader2doc])\n"],"metadata":{"id":"tliEn1SMDEtF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Unlike traditional Spark NLP annotators, Reader2Doc reads files directly from the specified `contentPath` rather than from an input column.\n","\n","Because of this, it does not require a `.setInputCols()` parameter. Instead, we initialize the pipeline with an **empty DataFrame**, since the reader itself handles file ingestion."],"metadata":{"id":"U_UAiGMDM7yE"}},{"cell_type":"code","source":["empty_df = spark.createDataFrame([], \"string\").toDF(\"text\")\n","\n","model = pipeline.fit(empty_df)\n","result_df = model.transform(empty_df)\n"],"metadata":{"id":"8rMJ_-I-MzWH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result_df.show(truncate=False)"],"metadata":{"id":"ZIMegeTsMvoE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761700755015,"user_tz":-300,"elapsed":7118,"user":{"displayName":"Abdullah Mubeen","userId":"17886490017623663394"}},"outputId":"8561bd93-69f8-421d-b879-5fbf07179ce3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+\n","|fileName                             |document                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |exception|\n","+-------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+\n","|financial_impact_analysis.xlsx       |[{document, 0, 17, Metric\\tValue\\tNotes, {location -> (0, 2), SheetName -> Financials, elementType -> NarrativeText}, []}, {document, 18, 62, Model training cost\\t$12,500\\tIncludes GPU time, {location -> (1, 2), SheetName -> Financials, elementType -> NarrativeText}, []}, {document, 63, 126, Expected annual savings\\t$85,000\\tBased on reduced delivery delays, {location -> (2, 2), SheetName -> Financials, elementType -> NarrativeText}, []}, {document, 127, 160, ROI\\t580%\\tCalculated over 12 months, {location -> (3, 2), SheetName -> Financials, elementType -> NarrativeText}, []}]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |NULL     |\n","|SparkNLP_New_Notebooks_Proposals.xlsx|[{document, 0, 75, Notebook Topic\\tAnnotators/Transformers\\tRelated Existing Notebook\\tDescription, {location -> (0, 3), SheetName -> Sheet1, elementType -> Title}, []}, {document, 76, 402, Native File Readers\\tSparkNLPReader, Partition, PartitionTransformer, PDFReader, ExcelReader, PowerPointReader, TextReader, XMLReader\\t2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb\\tDemonstrate how to natively ingest .pdf, .xlsx, .pptx, .xml, and .txt files directly into Spark pipelines without external tools., {location -> (1, 3), SheetName -> Sheet1, elementType -> NarrativeText}, []}, {document, 403, 714, Information Extraction & Cleaning\\tIPExtractor, EmailExtractor, DateExtractor, Cleane\\t2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb; 8.Keyword_Extraction_YAKE.ipynb\\tShowcase how to extract structured fields like emails, IPs, and dates from unstructured text, highlighting built-in capabilities., {location -> (2, 3), SheetName -> Sheet1, elementType -> NarrativeText}, []}, {document, 715, 896, Vision-Language Models\\tInternVLForMultiModal, Florence2Transforme\\t19.Image_Classification.ipynb\\tExpand vision tutorials by introducing image captioning and visual question answering., {location -> (3, 3), SheetName -> Sheet1, elementType -> NarrativeText}, []}, {document, 897, 1082, Vision-Language Transformers\\tGemma3ForVisionLanguage, PaliGemmaForMultiModal, SmolVLMForMultiModal\\tNone\\tShowcase lightweight models for vision-language tasks that run even on local CPUs., {location -> (4, 3), SheetName -> Sheet1, elementType -> NarrativeText}, []}, {document, 1083, 1300, On-Prem Multimodal Inference (GGUF + LLaMA.cpp)\\tAutoGGUFVisionModel, AutoGGUFMode\\t22.0_Llama2_Transformer_In_SparkNLP.ipynb\\tDemonstrate multimodal inference with GGUF models running locally using LLaMA.cpp integration., {location -> (5, 3), SheetName -> Sheet1, elementType -> NarrativeText}, []}, {document, 1301, 1546, Multimodal E5 Embeddings in addition to Bert\\tE5VEmbeddings\\t11.Text_Similarities_and_dimension_reduction_visualizations_for_Embeddings.ipynb\\tExtend embeddings tutorial with cross-modal embeddings to find images matching text queries or vice versa., {location -> (6, 3), SheetName -> Sheet1, elementType -> NarrativeText}, []}]|NULL     |\n","|dataset_inventory.xls                |[{document, 0, 35, Dataset\\tRows\\tFeatures\\tTarget\\tComment, {location -> (0, 4), SheetName -> Datasets, elementType -> NarrativeText}, []}, {document, 36, 109, deliveries.csv\\t100,000\\t45\\tdelivery_time\\tHigh variance, needs normalization, {location -> (1, 4), SheetName -> Datasets, elementType -> NarrativeText}, []}, {document, 110, 154, weather.csv\\t365\\t12\\tN/A\\tGood seasonal coverage, {location -> (2, 4), SheetName -> Datasets, elementType -> NarrativeText}, []}, {document, 155, 197, routes.csv\\t12,000\\t20\\tcost\\tMissing 5% values, {location -> (3, 4), SheetName -> Datasets, elementType -> NarrativeText}, []}]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |NULL     |\n","|data_centric_ai_whitepaper.pdf       |[{document, 0, 41, Data-Centric AI for Real-World Reliability, {pageNumber -> 1, elementType -> Title}, []}, {document, 42, 122, Most AI systems fail not due to algorithmic limits, but due to data misalignment., {pageNumber -> 1, elementType -> NarrativeText}, []}, {document, 123, 217, This paper presents a framework for iterative dataset refinement — using human feedback, active, {pageNumber -> 1, elementType -> NarrativeText}, []}, {document, 218, 317, learning, and distributional shift monitoring — to close the gap between lab accuracy and production, {pageNumber -> 1, elementType -> NarrativeText}, []}, {document, 318, 329, reliability., {pageNumber -> 1, elementType -> NarrativeText}, []}]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |NULL     |\n","|predictive_analytics_future.pptx     |[{document, 0, 33, The Future of Predictive Analytics, {elementType -> NarrativeText}, []}, {document, 34, 78, Problem: Businesses react instead of predict., {elementType -> NarrativeText}, []}, {document, 79, 127, Solution: Unified ML platform for streaming data., {elementType -> NarrativeText}, []}, {document, 128, 170, Results: 20% cost reduction across clients., {elementType -> NarrativeText}, []}, {document, 171, 216, Roadmap: Multimodal learning and federated AI., {elementType -> NarrativeText}, []}]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |NULL     |\n","|enterprise_ai_strategy.ppt           |[{document, 0, 29, Scaling AI at Enterprise Level, {elementType -> NarrativeText}, []}, {document, 30, 51, 1. Data Infrastructure, {elementType -> NarrativeText}, []}, {document, 52, 70, 2. Model Governance, {elementType -> NarrativeText}, []}, {document, 71, 83, 3. Case Study, {elementType -> NarrativeText}, []}, {document, 84, 96, 4. Next Steps, {elementType -> NarrativeText}, []}]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |NULL     |\n","|predictive_maintenance_report.doc    |[{document, 0, 28, Predictive Maintenance System, {elementType -> NarrativeText}, []}, {document, 29, 110, Our team trained an ensemble of gradient boosting models on equipment sensor data., {elementType -> NarrativeText}, []}, {document, 111, 177, Preliminary results indicate a 35% reduction in unplanned downtime., {elementType -> NarrativeText}, []}, {document, 178, 263, Further work will focus on real-time anomaly detection using streaming data pipelines., {elementType -> NarrativeText}, []}]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |NULL     |\n","|labeling_insights_note.txt           |[{document, 0, 184, Today I realized that most of our predictive errors come not from the model, but from inconsistent data labeling.\\nBefore tuning hyperparameters, we should probably tune our definitions., {paragraph -> 0, sentence -> 0, elementType -> NarrativeText}, []}]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |NULL     |\n","|openai_reply_to_nvidia.msg           |[{document, 0, 28, Re: Next-Gen AI Collaboration, {sent_to -> jensen@nvidia.com, sent_from -> sam@openai.com, cc_to -> , elementType -> Title}, []}, {document, 29, 329, Hey Jensen,\\n\\nAppreciate the note â and the GPUs. Weâd love to explore tighter integration between your hardware stack and our scaling pipelines.\\nIf youâre open to it, maybe we can test a few experimental runs on the next cluster revision.\\n\\nLetâs coordinate next week.\\n\\nCheers,\\nSam\\nCEO, OpenAI\\n, {sent_to -> jensen@nvidia.com, sent_from -> sam@openai.com, cc_to -> , elementType -> NarrativeText}, []}]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |NULL     |\n","|ai_logistics_executive_summary.docx  |[{document, 0, 34, Executive Summary — AI in Logistics, {elementType -> NarrativeText}, []}, {document, 35, 130, We deployed a machine learning model to optimize delivery routes using traffic and weather data., {elementType -> NarrativeText}, []}, {document, 131, 203, This reduced fuel consumption by 12% and improved on-time delivery rates., {elementType -> NarrativeText}, []}, {document, 204, 269, Next phase: integrate reinforcement learning for adaptive routing., {elementType -> NarrativeText}, []}]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |NULL     |\n","|model_performance_dashboard.html     |[{document, 0, 29, Data Science Metrics Dashboard, {element_id -> 3441a7c0-cf38-40c9-81ed-b242d3209760, pageNumber -> 1, sentence -> 0, elementType -> Title}, []}, {document, 30, 54, Latest model performance:, {element_id -> 114cd0f2-09b0-4d31-a811-07538df2bffa, parent_id -> 3441a7c0-cf38-40c9-81ed-b242d3209760, pageNumber -> 1, elementType -> NarrativeText, sentence -> 1}, []}, {document, 55, 69, Accuracy: 92.4%, {element_id -> f370c670-b497-4614-9f70-c9d004eecf3b, parent_id -> 3441a7c0-cf38-40c9-81ed-b242d3209760, pageNumber -> 1, elementType -> ListItem, sentence -> 2}, []}, {document, 70, 83, F1 Score: 0.88, {element_id -> 18507ca7-52f1-41ab-ab99-49c9b6da4017, parent_id -> 3441a7c0-cf38-40c9-81ed-b242d3209760, pageNumber -> 1, elementType -> ListItem, sentence -> 3}, []}, {document, 84, 96, ROC-AUC: 0.94, {element_id -> 61b5c2eb-bc54-4ef3-8cc2-0a9996015c3a, parent_id -> 3441a7c0-cf38-40c9-81ed-b242d3209760, pageNumber -> 1, elementType -> ListItem, sentence -> 4}, []}, {document, 97, 148, Deployed on: October 2025 — Monitoring drift weekly., {element_id -> f87d1905-b809-4371-bcb0-711f9fe7acba, parent_id -> 3441a7c0-cf38-40c9-81ed-b242d3209760, pageNumber -> 1, elementType -> NarrativeText, sentence -> 5}, []}]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |NULL     |\n","|nvidia_to_openai_ai_collaboration.eml|[{document, 0, 24, Next-Gen AI Collaboration, {sent_to -> sam@openai.com, sent_from -> jensen@nvidia.com, cc_to -> , elementType -> Title}, []}, {document, 25, 390, Hey Sam,\\n\\nCongrats on the new model launch â itâs incredible to see how fast generative systems are evolving.\\nWeâve been prototyping a distributed GPU fabric specifically for large transformer workloads, and I think it could double your training throughput.\\nLetâs schedule a quick sync next week to discuss joint optimization work.\\n\\nBest,\\nJensen\\nCEO, NVIDIA\\n, {sent_to -> sam@openai.com, sent_from -> jensen@nvidia.com, cc_to -> , elementType -> NarrativeText}, []}]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |NULL     |\n","+-------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+\n","\n"]}]},{"cell_type":"code","source":["result_df.printSchema()"],"metadata":{"id":"_kAKzTyhNlm3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761324083879,"user_tz":-300,"elapsed":69,"user":{"displayName":"Abdullah Mubeen","userId":"17886490017623663394"}},"outputId":"20f694f2-43af-4b4d-cbfe-c3d892de96e5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- fileName: string (nullable = true)\n"," |-- document: array (nullable = true)\n"," |    |-- element: struct (containsNull = true)\n"," |    |    |-- annotatorType: string (nullable = true)\n"," |    |    |-- begin: integer (nullable = false)\n"," |    |    |-- end: integer (nullable = false)\n"," |    |    |-- result: string (nullable = true)\n"," |    |    |-- metadata: map (nullable = true)\n"," |    |    |    |-- key: string\n"," |    |    |    |-- value: string (valueContainsNull = true)\n"," |    |    |-- embeddings: array (nullable = true)\n"," |    |    |    |-- element: float (containsNull = false)\n"," |-- exception: void (nullable = true)\n","\n"]}]},{"cell_type":"markdown","source":["let's summarize these extracted documents using `AutoGGUFModel`, which allows native integration of **Llama.cpp** compatible models (such as **Phi-4,** **LLaMA**, or **Mistral**) directly within Spark NLP."],"metadata":{"id":"Gryb_-Sad5-L"}},{"cell_type":"code","source":["from sparknlp.annotator import AutoGGUFModel\n","\n","auto_gguf_model = (\n","    AutoGGUFModel.pretrained(\"phi_4_mini_instruct_bf16_gguf\", \"en\")\n","    .setInputCols([\"document\"])\n","    .setOutputCol(\"completions\")\n","    .setSystemPrompt(\"You are a helpful assistant. Read the text below and write a clear, concise summary capturing the key ideas, facts, and tone.\")\n","    .setCachePrompt(True)\n","    .setNPredict(200)\n","    .setTemperature(0.3)\n","    .setTopK(30)\n","    .setTopP(0.9)\n","    .setNCtx(4096)\n","    .setNThreads(8)\n","    .setNThreadsBatch(8)\n","    .setIgnoreEos(False)\n","    .setLogVerbosity(1)\n",")\n","\n","pipeline = Pipeline().setStages([\n","    reader2doc,\n","    auto_gguf_model\n","])\n","\n","model = pipeline.fit(empty_df)\n","result = model.transform(empty_df)\n"],"metadata":{"id":"GnYWgI9ER4x9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761324741247,"user_tz":-300,"elapsed":657363,"user":{"displayName":"Abdullah Mubeen","userId":"17886490017623663394"}},"outputId":"124702a4-a6c9-45e0-b221-9635a09a2498"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["phi_4_mini_instruct_bf16_gguf download started this may take some time.\n","Approximate size to download 5.7 GB\n","[OK!]\n"]}]},{"cell_type":"code","source":["result.select(\"fileName\", \"completions.result\").show(truncate=False)"],"metadata":{"id":"GOCUaDbXcTKL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761324813345,"user_tz":-300,"elapsed":72099,"user":{"displayName":"Abdullah Mubeen","userId":"17886490017623663394"}},"outputId":"43196c15-2051-47a2-99d9-546e4340710a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|fileName                             |result                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n","+-------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|SparkNLP_New_Notebooks_Proposals.xlsx|[Notebook Topic: Exploring the Impact of Climate Change on Global Biodiversity\\nAnnotators/Transformers: Dr. Jane Goodall, Dr. David Attenborough, Dr. E.O. Wilson\\nRelated Existing Notebook: \"Climate Change and Biodiversity: A Comprehensive Analysis\" by Dr. Sarah Johnson\\nSummary: This notebook focuses on the effects of climate change on global biodiversity, with insights from renowned experts Dr. Jane Goodall, Dr. David Attenborough, and Dr. E.O. Wilson. It builds upon Dr. Sarah Johnson's comprehensive analysis, aiming to deepen understanding and explore potential solutions to mitigate these impacts.]                                                      |\n","|financial_impact_analysis.xlsx       |[The SparkNLPReader package provides native file readers for various file formats including .pdf, .xlsx, .pptx, .xml, and .txt. It allows direct ingestion of these files into Spark pipelines without the need for external tools. The package includes readers such as SparkNLPReader, Partition, PartitionTransformer, PDFReader, ExcelReader, PowerPointReader, TextReader, and XMLReader. A demonstration of this process can be found in the \"Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb\" notebook.]                                                                                                                                                         |\n","|dataset_inventory.xls                |[The dataset has an unspecified number of rows and features, with a single target variable. The comment section is available for additional information or notes.]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n","|data_centric_ai_whitepaper.pdf       |[The text discusses the importance of data-centric AI in enhancing real-world reliability. It emphasizes the need for robust, high-quality data to train AI systems effectively. The tone is informative and persuasive, advocating for the adoption of data-centric approaches in AI development.]                                                                                                                                                                                                                                                                                                                                                                                    |\n","|predictive_analytics_future.pptx     |[Predictive analytics is set to revolutionize various industries by harnessing the power of data, machine learning, and artificial intelligence. The technology is poised to provide unprecedented insights, allowing businesses to anticipate trends, improve decision-making, and gain a competitive edge. As the field continues to evolve, it will undoubtedly shape the future of business and technology.]                                                                                                                                                                                                                                                                       |\n","|enterprise_ai_strategy.ppt           |[The text discusses the challenges and strategies involved in scaling artificial intelligence (AI) at an enterprise level. It highlights the need for large datasets, computational power, and skilled personnel. The tone is informative and analytical, providing insights into the complexities of implementing AI solutions in a large-scale business environment.]                                                                                                                                                                                                                                                                                                                |\n","|predictive_maintenance_report.doc    |[A Predictive Maintenance System is an advanced technique that uses data analysis and machine learning to predict when equipment maintenance is required. This approach helps in preventing unexpected equipment failures, reducing downtime, and saving costs. The system analyzes historical and real-time data to identify patterns and anomalies that could indicate potential issues. By predicting maintenance needs, organizations can schedule repairs during non-peak hours, thereby increasing efficiency and productivity. The tone of the summary is informative and straightforward, focusing on the key benefits and functionality of the Predictive Maintenance System.]|\n","|labeling_insights_note.txt           |[The author suggests that predictive errors in models are often due to inconsistent data labeling rather than the model itself. They recommend that before tuning hyperparameters, the definitions used for data labeling should be refined.]                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n","|openai_reply_to_nvidia.msg           |[The sender is seeking a collaboration to develop a next-generation artificial intelligence. The tone is professional and forward-thinking.]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n","|ai_logistics_executive_summary.docx  |[Artificial Intelligence (AI) is revolutionizing the logistics industry by enhancing efficiency, accuracy, and decision-making. Key applications include predictive analytics for demand forecasting, autonomous vehicles for transportation, and intelligent robotics for warehouse management. These innovations result in reduced costs, improved customer satisfaction, and a competitive edge for businesses embracing AI in their logistics operations. The tone of the summary is informative and optimistic about the potential of AI in logistics.]                                                                                                                           |\n","|model_performance_dashboard.html     |[The Data Science Metrics Dashboard is a tool designed to track and visualize key performance indicators (KPIs) in data science projects. It provides real-time insights into various metrics such as model accuracy, data quality, and processing speed, enabling data scientists to monitor their progress and make informed decisions. The dashboard's user-friendly interface allows for easy interpretation of complex data, fostering a more efficient and effective data science workflow. The tone of the text is informative and professional, focusing on the practical benefits of the dashboard.]                                                                          |\n","|nvidia_to_openai_ai_collaboration.eml|[The text refers to the emergence of advanced AI technologies that are designed to work collaboratively with humans. These next-generation AI systems are expected to enhance productivity, foster innovation, and streamline complex tasks. The tone suggests a positive outlook on the potential benefits of human-AI partnerships.]                                                                                                                                                                                                                                                                                                                                                 |\n","+-------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","\n"]}]},{"cell_type":"markdown","source":["### Exploring Parameters"],"metadata":{"id":"JAyS6KUQNwYz"}},{"cell_type":"markdown","source":["| Parameter | Description | Default |\n","|:-----------|:-------------|:----------|\n","| **contentPath** | Path to the input documents (local directory, file, or URL). | Required |\n","| **contentType** | MIME type of the document (e.g., `text/html`, `application/pdf`). Usually inferred automatically. | Optional |\n","| **explodeDocs** | Whether to output one document per row. Set to `False` to combine all content into a single record per file. | `False` |\n","| **flattenOutput** | If `True`, returns plain text with minimal metadata instead of full annotation structures. | `False` |\n","| **outputAsDocument** | Whether to output all content as a single combined `Document`. | `False` |\n","| **excludeNonText** | Exclude non-textual data like tables or images from the output. | `False` |\n","| **storeContent** | Include the raw file content in the DataFrame (useful for debugging or serialization). | `False` |\n","| **ignoreExceptions** | Continue processing even if some documents fail to parse. | `True` |\n","| **includeSlideNotes** | Include speaker notes when reading PowerPoint files. | `False` |\n","| **addAttachmentContent** | Extract plain-text attachments from emails (`.eml`, `.msg`). | `False` |\n"],"metadata":{"id":"j5J8YBRGIV1J"}},{"cell_type":"markdown","source":["Let's use `SparkNLP_New_Notebooks_Proposals.xlsx` for this"],"metadata":{"id":"3dUOgqwBkc3F"}},{"cell_type":"code","source":["!mkdir -p single-file & cp files/reader2doc/SparkNLP_New_Notebooks_Proposals.xlsx single-file/"],"metadata":{"id":"rxsjxId1gJeQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**explodeDocs**\n","\n","Whether to explode the documents into separate rows."],"metadata":{"id":"m_7581KRhliN"}},{"cell_type":"code","source":["reader2doc = Reader2Doc() \\\n","    .setContentPath(\"./single-file\") \\\n","    .setExplodeDocs(True)\n","\n","pipeline = Pipeline(stages=[reader2doc])\n","empty_df = spark.createDataFrame([], \"string\").toDF(\"text\")\n","\n","model = pipeline.fit(empty_df)\n","result_df = model.transform(empty_df)\n","\n","result_df.show(truncate=False)\n"],"metadata":{"id":"W58f5qSbfgAY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761324890607,"user_tz":-300,"elapsed":466,"user":{"displayName":"Abdullah Mubeen","userId":"17886490017623663394"}},"outputId":"84b0e7a9-13be-4897-d59c-e6d910bfa6ed"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+\n","|fileName                             |document                                                                                                                                                                                                                                                                                                                                                                                                                                      |exception|\n","+-------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+\n","|SparkNLP_New_Notebooks_Proposals.xlsx|[{document, 0, 75, Notebook Topic\\tAnnotators/Transformers\\tRelated Existing Notebook\\tDescription, {location -> (0, 3), SheetName -> Sheet1, elementType -> Title}, []}]                                                                                                                                                                                                                                                                     |NULL     |\n","|SparkNLP_New_Notebooks_Proposals.xlsx|[{document, 76, 402, Native File Readers\\tSparkNLPReader, Partition, PartitionTransformer, PDFReader, ExcelReader, PowerPointReader, TextReader, XMLReader\\t2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb\\tDemonstrate how to natively ingest .pdf, .xlsx, .pptx, .xml, and .txt files directly into Spark pipelines without external tools., {location -> (1, 3), SheetName -> Sheet1, elementType -> NarrativeText}, []}]|NULL     |\n","|SparkNLP_New_Notebooks_Proposals.xlsx|[{document, 403, 714, Information Extraction & Cleaning\\tIPExtractor, EmailExtractor, DateExtractor, Cleane\\t2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb; 8.Keyword_Extraction_YAKE.ipynb\\tShowcase how to extract structured fields like emails, IPs, and dates from unstructured text, highlighting built-in capabilities., {location -> (2, 3), SheetName -> Sheet1, elementType -> NarrativeText}, []}]              |NULL     |\n","|SparkNLP_New_Notebooks_Proposals.xlsx|[{document, 715, 896, Vision-Language Models\\tInternVLForMultiModal, Florence2Transforme\\t19.Image_Classification.ipynb\\tExpand vision tutorials by introducing image captioning and visual question answering., {location -> (3, 3), SheetName -> Sheet1, elementType -> NarrativeText}, []}]                                                                                                                                                |NULL     |\n","|SparkNLP_New_Notebooks_Proposals.xlsx|[{document, 897, 1082, Vision-Language Transformers\\tGemma3ForVisionLanguage, PaliGemmaForMultiModal, SmolVLMForMultiModal\\tNone\\tShowcase lightweight models for vision-language tasks that run even on local CPUs., {location -> (4, 3), SheetName -> Sheet1, elementType -> NarrativeText}, []}]                                                                                                                                           |NULL     |\n","|SparkNLP_New_Notebooks_Proposals.xlsx|[{document, 1083, 1300, On-Prem Multimodal Inference (GGUF + LLaMA.cpp)\\tAutoGGUFVisionModel, AutoGGUFMode\\t22.0_Llama2_Transformer_In_SparkNLP.ipynb\\tDemonstrate multimodal inference with GGUF models running locally using LLaMA.cpp integration., {location -> (5, 3), SheetName -> Sheet1, elementType -> NarrativeText}, []}]                                                                                                          |NULL     |\n","|SparkNLP_New_Notebooks_Proposals.xlsx|[{document, 1301, 1546, Multimodal E5 Embeddings in addition to Bert\\tE5VEmbeddings\\t11.Text_Similarities_and_dimension_reduction_visualizations_for_Embeddings.ipynb\\tExtend embeddings tutorial with cross-modal embeddings to find images matching text queries or vice versa., {location -> (6, 3), SheetName -> Sheet1, elementType -> NarrativeText}, []}]                                                                              |NULL     |\n","+-------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+\n","\n"]}]},{"cell_type":"code","source":["reader2doc = Reader2Doc() \\\n","    .setContentPath(\"./single-file\") \\\n","    .setExplodeDocs(False)\n","\n","pipeline = Pipeline(stages=[reader2doc])\n","empty_df = spark.createDataFrame([], \"string\").toDF(\"text\")\n","\n","model = pipeline.fit(empty_df)\n","result_df = model.transform(empty_df)\n","\n","result_df.show(truncate=False)"],"metadata":{"id":"gUv-AcZPgIm6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761324898541,"user_tz":-300,"elapsed":401,"user":{"displayName":"Abdullah Mubeen","userId":"17886490017623663394"}},"outputId":"28fad609-f711-4052-ba58-d074ca68518e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+\n","|fileName                             |document                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |exception|\n","+-------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+\n","|SparkNLP_New_Notebooks_Proposals.xlsx|[{document, 0, 75, Notebook Topic\\tAnnotators/Transformers\\tRelated Existing Notebook\\tDescription, {location -> (0, 3), SheetName -> Sheet1, elementType -> Title}, []}, {document, 76, 402, Native File Readers\\tSparkNLPReader, Partition, PartitionTransformer, PDFReader, ExcelReader, PowerPointReader, TextReader, XMLReader\\t2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb\\tDemonstrate how to natively ingest .pdf, .xlsx, .pptx, .xml, and .txt files directly into Spark pipelines without external tools., {location -> (1, 3), SheetName -> Sheet1, elementType -> NarrativeText}, []}, {document, 403, 714, Information Extraction & Cleaning\\tIPExtractor, EmailExtractor, DateExtractor, Cleane\\t2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb; 8.Keyword_Extraction_YAKE.ipynb\\tShowcase how to extract structured fields like emails, IPs, and dates from unstructured text, highlighting built-in capabilities., {location -> (2, 3), SheetName -> Sheet1, elementType -> NarrativeText}, []}, {document, 715, 896, Vision-Language Models\\tInternVLForMultiModal, Florence2Transforme\\t19.Image_Classification.ipynb\\tExpand vision tutorials by introducing image captioning and visual question answering., {location -> (3, 3), SheetName -> Sheet1, elementType -> NarrativeText}, []}, {document, 897, 1082, Vision-Language Transformers\\tGemma3ForVisionLanguage, PaliGemmaForMultiModal, SmolVLMForMultiModal\\tNone\\tShowcase lightweight models for vision-language tasks that run even on local CPUs., {location -> (4, 3), SheetName -> Sheet1, elementType -> NarrativeText}, []}, {document, 1083, 1300, On-Prem Multimodal Inference (GGUF + LLaMA.cpp)\\tAutoGGUFVisionModel, AutoGGUFMode\\t22.0_Llama2_Transformer_In_SparkNLP.ipynb\\tDemonstrate multimodal inference with GGUF models running locally using LLaMA.cpp integration., {location -> (5, 3), SheetName -> Sheet1, elementType -> NarrativeText}, []}, {document, 1301, 1546, Multimodal E5 Embeddings in addition to Bert\\tE5VEmbeddings\\t11.Text_Similarities_and_dimension_reduction_visualizations_for_Embeddings.ipynb\\tExtend embeddings tutorial with cross-modal embeddings to find images matching text queries or vice versa., {location -> (6, 3), SheetName -> Sheet1, elementType -> NarrativeText}, []}]|NULL     |\n","+-------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+\n","\n"]}]},{"cell_type":"markdown","source":["**flattenOutput**\n","\n","If true, output is flattened to plain text with minimal metadata"],"metadata":{"id":"ycaft3mBh5or"}},{"cell_type":"code","source":["reader2doc = Reader2Doc() \\\n","    .setContentPath(\"./single-file\") \\\n","    .setFlattenOutput(True)\n","\n","pipeline = Pipeline(stages=[reader2doc])\n","empty_df = spark.createDataFrame([], \"string\").toDF(\"text\")\n","\n","model = pipeline.fit(empty_df)\n","result_df = model.transform(empty_df)\n","\n","result_df.select(\"document.metadata\").show(truncate=False)\n"],"metadata":{"id":"AR_Hi1-RhwDG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761324904577,"user_tz":-300,"elapsed":374,"user":{"displayName":"Abdullah Mubeen","userId":"17886490017623663394"}},"outputId":"a86f1314-80e4-4bfd-d564-62a1daf556b9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------------------------+\n","|metadata                    |\n","+----------------------------+\n","|[{}, {}, {}, {}, {}, {}, {}]|\n","+----------------------------+\n","\n"]}]},{"cell_type":"code","source":["reader2doc = Reader2Doc() \\\n","    .setContentPath(\"./single-file\") \\\n","    .setFlattenOutput(False)\n","\n","pipeline = Pipeline(stages=[reader2doc])\n","empty_df = spark.createDataFrame([], \"string\").toDF(\"text\")\n","\n","model = pipeline.fit(empty_df)\n","result_df = model.transform(empty_df)\n","\n","result_df.select(\"document.metadata\").show(truncate=False)\n"],"metadata":{"id":"zXRmLjkKijHB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761324909610,"user_tz":-300,"elapsed":265,"user":{"displayName":"Abdullah Mubeen","userId":"17886490017623663394"}},"outputId":"b7230d3b-037d-4ea5-b241-8c7946adce99"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|metadata                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|[{location -> (0, 3), SheetName -> Sheet1, elementType -> Title}, {location -> (1, 3), SheetName -> Sheet1, elementType -> NarrativeText}, {location -> (2, 3), SheetName -> Sheet1, elementType -> NarrativeText}, {location -> (3, 3), SheetName -> Sheet1, elementType -> NarrativeText}, {location -> (4, 3), SheetName -> Sheet1, elementType -> NarrativeText}, {location -> (5, 3), SheetName -> Sheet1, elementType -> NarrativeText}, {location -> (6, 3), SheetName -> Sheet1, elementType -> NarrativeText}]|\n","+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","\n"]}]},{"cell_type":"markdown","source":["**outputAsDocument**\n","\n","Whether to return all sentences joined into a single document"],"metadata":{"id":"d046mH_Ri6Cy"}},{"cell_type":"code","source":["reader2doc = Reader2Doc() \\\n","    .setContentPath(\"./single-file\") \\\n","    .setOutputAsDocument(True)\n","\n","pipeline = Pipeline(stages=[reader2doc])\n","empty_df = spark.createDataFrame([], \"string\").toDF(\"text\")\n","\n","model = pipeline.fit(empty_df)\n","result_df = model.transform(empty_df)\n","\n","result_df.select(\"document\").show(truncate=False)\n"],"metadata":{"id":"Odt_prXHjCLp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761324914225,"user_tz":-300,"elapsed":465,"user":{"displayName":"Abdullah Mubeen","userId":"17886490017623663394"}},"outputId":"3038b56f-1bb4-4317-de40-0e6e6a1dcbf6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|document                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n","+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|[{document, 0, 1552, Notebook Topic\\tAnnotators/Transformers\\tRelated Existing Notebook\\tDescription Native File Readers\\tSparkNLPReader, Partition, PartitionTransformer, PDFReader, ExcelReader, PowerPointReader, TextReader, XMLReader\\t2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb\\tDemonstrate how to natively ingest .pdf, .xlsx, .pptx, .xml, and .txt files directly into Spark pipelines without external tools. Information Extraction & Cleaning\\tIPExtractor, EmailExtractor, DateExtractor, Cleane\\t2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb; 8.Keyword_Extraction_YAKE.ipynb\\tShowcase how to extract structured fields like emails, IPs, and dates from unstructured text, highlighting built-in capabilities. Vision-Language Models\\tInternVLForMultiModal, Florence2Transforme\\t19.Image_Classification.ipynb\\tExpand vision tutorials by introducing image captioning and visual question answering. Vision-Language Transformers\\tGemma3ForVisionLanguage, PaliGemmaForMultiModal, SmolVLMForMultiModal\\tNone\\tShowcase lightweight models for vision-language tasks that run even on local CPUs. On-Prem Multimodal Inference (GGUF + LLaMA.cpp)\\tAutoGGUFVisionModel, AutoGGUFMode\\t22.0_Llama2_Transformer_In_SparkNLP.ipynb\\tDemonstrate multimodal inference with GGUF models running locally using LLaMA.cpp integration. Multimodal E5 Embeddings in addition to Bert\\tE5VEmbeddings\\t11.Text_Similarities_and_dimension_reduction_visualizations_for_Embeddings.ipynb\\tExtend embeddings tutorial with cross-modal embeddings to find images matching text queries or vice versa., {sentence -> 0}, []}]|\n","+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","\n"]}]},{"cell_type":"code","source":["reader2doc = Reader2Doc() \\\n","    .setContentPath(\"./single-file\") \\\n","    .setOutputAsDocument(False)\n","\n","pipeline = Pipeline(stages=[reader2doc])\n","empty_df = spark.createDataFrame([], \"string\").toDF(\"text\")\n","\n","model = pipeline.fit(empty_df)\n","result_df = model.transform(empty_df)\n","\n","result_df.select(\"document\").show(truncate=False)\n"],"metadata":{"id":"A-XsxQjVjDK6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761324919444,"user_tz":-300,"elapsed":375,"user":{"displayName":"Abdullah Mubeen","userId":"17886490017623663394"}},"outputId":"82d13766-5520-46de-f23a-f3bd011dce4d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|document                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\n","+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|[{document, 0, 75, Notebook Topic\\tAnnotators/Transformers\\tRelated Existing Notebook\\tDescription, {location -> (0, 3), SheetName -> Sheet1, elementType -> Title}, []}, {document, 76, 402, Native File Readers\\tSparkNLPReader, Partition, PartitionTransformer, PDFReader, ExcelReader, PowerPointReader, TextReader, XMLReader\\t2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb\\tDemonstrate how to natively ingest .pdf, .xlsx, .pptx, .xml, and .txt files directly into Spark pipelines without external tools., {location -> (1, 3), SheetName -> Sheet1, elementType -> NarrativeText}, []}, {document, 403, 714, Information Extraction & Cleaning\\tIPExtractor, EmailExtractor, DateExtractor, Cleane\\t2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb; 8.Keyword_Extraction_YAKE.ipynb\\tShowcase how to extract structured fields like emails, IPs, and dates from unstructured text, highlighting built-in capabilities., {location -> (2, 3), SheetName -> Sheet1, elementType -> NarrativeText}, []}, {document, 715, 896, Vision-Language Models\\tInternVLForMultiModal, Florence2Transforme\\t19.Image_Classification.ipynb\\tExpand vision tutorials by introducing image captioning and visual question answering., {location -> (3, 3), SheetName -> Sheet1, elementType -> NarrativeText}, []}, {document, 897, 1082, Vision-Language Transformers\\tGemma3ForVisionLanguage, PaliGemmaForMultiModal, SmolVLMForMultiModal\\tNone\\tShowcase lightweight models for vision-language tasks that run even on local CPUs., {location -> (4, 3), SheetName -> Sheet1, elementType -> NarrativeText}, []}, {document, 1083, 1300, On-Prem Multimodal Inference (GGUF + LLaMA.cpp)\\tAutoGGUFVisionModel, AutoGGUFMode\\t22.0_Llama2_Transformer_In_SparkNLP.ipynb\\tDemonstrate multimodal inference with GGUF models running locally using LLaMA.cpp integration., {location -> (5, 3), SheetName -> Sheet1, elementType -> NarrativeText}, []}, {document, 1301, 1546, Multimodal E5 Embeddings in addition to Bert\\tE5VEmbeddings\\t11.Text_Similarities_and_dimension_reduction_visualizations_for_Embeddings.ipynb\\tExtend embeddings tutorial with cross-modal embeddings to find images matching text queries or vice versa., {location -> (6, 3), SheetName -> Sheet1, elementType -> NarrativeText}, []}]|\n","+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","\n"]}]},{"cell_type":"markdown","source":["## Reader2Table\n"],"metadata":{"id":"qzLLeeYsqqsV"}},{"cell_type":"markdown","source":["The Reader2Table annotator enables seamless extraction of tabular content from documents within existing Spark NLP workflows. It allows you to efficiently parse tables from a wide variety of file types and return them as structured Spark DataFrames with metadata, ready for downstream processing or analysis.\n","\n","*Supported File Formats:*\n","- HTML: `.html`, `.htm`  \n","- Word documents: `.doc`, `.docx`  \n","- Excel spreadsheets: `.xls`, `.xlsx`  \n","- PowerPoint presentations: `.ppt`, `.pptx`  \n","- CSV files: `.csv`  "],"metadata":{"id":"Fs6y1VtoqxS5"}},{"cell_type":"markdown","source":["### Basic usage"],"metadata":{"id":"EBc6Fvt5q61L"}},{"cell_type":"markdown","source":["Lets define our Pipeline"],"metadata":{"id":"XtYHs3Loq61L"}},{"cell_type":"code","source":["from sparknlp.reader.reader2table import Reader2Table\n","\n","reader2table = Reader2Table().setContentPath(\"files/reader2table\")\n","pipeline = Pipeline(stages=[reader2table])\n"],"metadata":{"id":"_Kd9ZxbQq61L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["empty_df = spark.createDataFrame([], \"string\").toDF(\"text\")\n","\n","model = pipeline.fit(empty_df)\n","result_df = model.transform(empty_df)\n"],"metadata":{"id":"KJHr3kbqq61L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result_df.show(truncate=False)"],"metadata":{"id":"eXN8cLm8q61L","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761702829435,"user_tz":-300,"elapsed":7273,"user":{"displayName":"Abdullah Mubeen","userId":"17886490017623663394"}},"outputId":"728c484c-a886-45e5-90a8-123528f3b0ee"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+\n","|fileName                    |document                                                                                                                                                                                                                                                                                                                                                                                                                                                |exception|\n","+----------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+\n","|ai_budget.xlsx              |[{document, 0, 221, {\"caption\":\"\",\"header\":[],\"rows\":[[\"Department\",\"2023 ($M)\",\"2024 ($M)\",\"% Growth\"],[\"Research\",\"25.0\",\"35.0\",\"40%\"],[\"Infrastructure\",\"15.0\",\"18.0\",\"20%\"],[\"Product\",\"10.0\",\"16.0\",\"60%\"],[\"Governance\",\"5.0\",\"6.0\",\"20%\"]]}, {SheetName -> AI Budget, elementType -> JSON}, []}]                                                                                                                                                 |NULL     |\n","|data_sources.xls            |[{document, 0, 287, {\"caption\":\"\",\"header\":[],\"rows\":[[\"Dataset\",\"Domain\",\"Records\",\"License\"],[\"ImageNet\",\"Computer Vision\",\"14,000,000\",\"Custom\"],[\"Common Crawl\",\"NLP\",\"100,000,000,000\",\"Public Domain\"],[\"COCO\",\"Object Detection\",\"330,000\",\"CC BY 4.0\"],[\"MIMIC-IV\",\"Healthcare\",\"380,000\",\"Research Only\"]]}, {SheetName -> Data Sources, elementType -> JSON}, []}]                                                                            |NULL     |\n","|training_times.csv          |[{document, 0, 210, {\"caption\":\"\",\"header\":[],\"rows\":[[\"Model\",\"Dataset\",\"Epochs\",\"Time (hrs)\"],[\"CNN\",\"CIFAR-10\",\"50\",\"3.2\"],[\"ResNet-50\",\"ImageNet\",\"90\",\"14.5\"],[\"BERT\",\"WikiText\",\"3\",\"10.8\"],[\"GPT-3\",\"OpenWebText\",\"1\",\"480.0\"]]}, {elementType -> Table}, []}]                                                                                                                                                                                   |NULL     |\n","|nlp_trends.pptx             |[{document, 0, 172, {\"caption\":\"\",\"header\":[],\"rows\":[[\"Model\",\"Parameters (B)\",\"Release Year\"],[\"GPT-2\",\"1.5\",\"2019\"],[\"GPT-3\",\"175\",\"2020\"],[\"PaLM 2\",\"340\",\"2023\"],[\"Claude 3\",\"860\",\"2024\"]]}, {element -> table, elementType -> JSON}, []}]                                                                                                                                                                                                        |NULL     |\n","|presentation_results.ppt    |[{document, 0, 110, {\"caption\":\"\",\"header\":[],\"rows\":[[\"Dataset\",\"Accuracy\"],[\"CIFAR-10\",\"0.93\"],[\"MNIST\",\"0.99\"],[\"IMDB\",\"0.88\"]]}, {element -> table, elementType -> JSON}, []}]                                                                                                                                                                                                                                                                      |NULL     |\n","|ai_research_publications.doc|[{document, 0, 372, {\"caption\":\"\",\"header\":[\"Title\",\"Author(s)\",\"Year\",\"Venue\"],\"rows\":[[\"Attention Is All You Need\",\"Vaswani et al.\",\"2017\",\"NeurIPS\"],[\"BERT: Pre-training of Deep Bidirectional Transformers\",\"Devlin et al.\",\"2018\",\"NAACL\"],[\"AlphaFold: Protein Structure Prediction\",\"Jumper et al.\",\"2021\",\"Nature\"],[\"DALL·E: Creating Images from Text\",\"Ramesh et al.\",\"2021\",\"OpenAI Blog\"]]}, {elementType -> JSON}, []}]                  |NULL     |\n","|hardware_benchmarks.docx    |[{document, 0, 227, {\"caption\":\"\",\"header\":[\"GPU\",\"Memory (GB)\",\"TFLOPs\",\"Power (W)\",\"Price ($)\"],\"rows\":[[\"RTX 4090\",\"24\",\"83\",\"450\",\"1599\"],[\"A100\",\"80\",\"312\",\"400\",\"9999\"],[\"H100\",\"80\",\"730\",\"700\",\"29999\"],[\"MI300X\",\"192\",\"1230\",\"750\",\"29999\"]]}, {elementType -> JSON}, []}]                                                                                                                                                                   |NULL     |\n","|model_performance.html      |[{document, 0, 254, {\"caption\":\"\",\"header\":[\"Model\",\"Accuracy\",\"Precision\",\"Recall\",\"F1 Score\"],\"rows\":[[\"Naive Bayes\",\"0.84\",\"0.81\",\"0.83\",\"0.82\"],[\"SVM\",\"0.89\",\"0.88\",\"0.87\",\"0.87\"],[\"Random Forest\",\"0.92\",\"0.91\",\"0.90\",\"0.91\"],[\"Transformer\",\"0.96\",\"0.95\",\"0.94\",\"0.95\"]]}, {element_id -> 7b890d40-6e13-4413-8f22-f463e24d5951, parent_id -> 51644df0-da31-4e2c-a22e-6b625fcf9982, pageNumber -> 1, elementType -> Table, sentence -> 1}, []}]|NULL     |\n","+----------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+\n","\n"]}]},{"cell_type":"code","source":["result_df.printSchema()"],"metadata":{"id":"PGEC8Lb3q61M","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761702829468,"user_tz":-300,"elapsed":25,"user":{"displayName":"Abdullah Mubeen","userId":"17886490017623663394"}},"outputId":"01afd404-18e3-4f49-aa18-95c735d710dd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- fileName: string (nullable = true)\n"," |-- document: array (nullable = true)\n"," |    |-- element: struct (containsNull = true)\n"," |    |    |-- annotatorType: string (nullable = true)\n"," |    |    |-- begin: integer (nullable = false)\n"," |    |    |-- end: integer (nullable = false)\n"," |    |    |-- result: string (nullable = true)\n"," |    |    |-- metadata: map (nullable = true)\n"," |    |    |    |-- key: string\n"," |    |    |    |-- value: string (valueContainsNull = true)\n"," |    |    |-- embeddings: array (nullable = true)\n"," |    |    |    |-- element: float (containsNull = false)\n"," |-- exception: void (nullable = true)\n","\n"]}]},{"cell_type":"code","source":["result_df.select(\"document.result\").collect()[0].result[0]"],"metadata":{"id":"dYC6x13M18wY","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1761702831688,"user_tz":-300,"elapsed":2217,"user":{"displayName":"Abdullah Mubeen","userId":"17886490017623663394"}},"outputId":"3b14274a-bee1-446f-a3bb-c6ff889fe591"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'{\"caption\":\"\",\"header\":[],\"rows\":[[\"Department\",\"2023 ($M)\",\"2024 ($M)\",\"% Growth\"],[\"Research\",\"25.0\",\"35.0\",\"40%\"],[\"Infrastructure\",\"15.0\",\"18.0\",\"20%\"],[\"Product\",\"10.0\",\"16.0\",\"60%\"],[\"Governance\",\"5.0\",\"6.0\",\"20%\"]]}'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["As you see the table is in a json format, we can use pandas to display it as a DataFrame"],"metadata":{"id":"IdBrjIPm2wzL"}},{"cell_type":"code","source":["import json\n","import pandas as pd\n","\n","# Extract Result\n","hardware_row = result_df.filter(result_df.fileName == \"hardware_benchmarks.docx\").first().document[0]['result']\n","\n","# Build Pandas DataFrame\n","data = json.loads(hardware_row)\n","table = pd.DataFrame(data[\"rows\"], columns=data[\"header\"])\n","\n","table\n"],"metadata":{"id":"LpruHOZHyhRF","colab":{"base_uri":"https://localhost:8080/","height":175},"executionInfo":{"status":"ok","timestamp":1761702834935,"user_tz":-300,"elapsed":3246,"user":{"displayName":"Abdullah Mubeen","userId":"17886490017623663394"}},"outputId":"cbc8e6cc-9d68-49f3-c4e7-f4d52e92141a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["        GPU Memory (GB) TFLOPs Power (W) Price ($)\n","0  RTX 4090          24     83       450      1599\n","1      A100          80    312       400      9999\n","2      H100          80    730       700     29999\n","3    MI300X         192   1230       750     29999"],"text/html":["\n","  <div id=\"df-8141f416-d98b-474f-9882-6ca0b9ef73f1\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>GPU</th>\n","      <th>Memory (GB)</th>\n","      <th>TFLOPs</th>\n","      <th>Power (W)</th>\n","      <th>Price ($)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>RTX 4090</td>\n","      <td>24</td>\n","      <td>83</td>\n","      <td>450</td>\n","      <td>1599</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A100</td>\n","      <td>80</td>\n","      <td>312</td>\n","      <td>400</td>\n","      <td>9999</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>H100</td>\n","      <td>80</td>\n","      <td>730</td>\n","      <td>700</td>\n","      <td>29999</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>MI300X</td>\n","      <td>192</td>\n","      <td>1230</td>\n","      <td>750</td>\n","      <td>29999</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8141f416-d98b-474f-9882-6ca0b9ef73f1')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-8141f416-d98b-474f-9882-6ca0b9ef73f1 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-8141f416-d98b-474f-9882-6ca0b9ef73f1');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-1a75c0b0-1d95-4985-a770-e783350d4eff\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1a75c0b0-1d95-4985-a770-e783350d4eff')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-1a75c0b0-1d95-4985-a770-e783350d4eff button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_1fa28661-d318-45eb-8fc2-9f2917a5050f\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('table')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_1fa28661-d318-45eb-8fc2-9f2917a5050f button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('table');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"table","summary":"{\n  \"name\": \"table\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"GPU\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"A100\",\n          \"MI300X\",\n          \"RTX 4090\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Memory (GB)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"24\",\n          \"80\",\n          \"192\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TFLOPs\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"312\",\n          \"1230\",\n          \"83\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Power (W)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"400\",\n          \"750\",\n          \"450\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Price ($)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"1599\",\n          \"9999\",\n          \"29999\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["Let's Run A Table Question Answering Pipeline with TAPAS"],"metadata":{"id":"aAWU5XrWpNiI"}},{"cell_type":"markdown","source":["Let's use `hardware_benchmarks.docx` for this"],"metadata":{"id":"dte0nF8n_NSC"}},{"cell_type":"code","source":["!mkdir -p single-table-file & cp files/reader2table/hardware_benchmarks.docx single-table-file/\n"],"metadata":{"id":"zXcUbhTNjTQQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["reader = Reader2Table() \\\n","    .setContentPath(\"./single-table-file\") \\\n","    .setOutputCol(\"document_table\")\n","\n","document_assembler = DocumentAssembler()\\\n","    .setInputCol(\"questions\")\\\n","    .setOutputCol(\"document_questions\")\n","\n","sentence_detector = SentenceDetector()\\\n","    .setInputCols([\"document_questions\"])\\\n","    .setOutputCol(\"questions_detected\")\n","\n","table_assembler = TableAssembler()\\\n","    .setInputCols([\"document_table\"])\\\n","    .setOutputCol(\"table\")\n","\n","tapas = TapasForQuestionAnswering\\\n","    .pretrained(\"table_qa_tapas_base_finetuned_wikisql_supervised\", \"en\")\\\n","    .setInputCols([\"questions_detected\", \"table\"])\\\n","    .setOutputCol(\"answers\")\n","\n","pipeline = Pipeline(stages=[\n","    document_assembler,\n","    sentence_detector,\n","    table_assembler,\n","    tapas\n","])\n","\n","questions_df = spark.createDataFrame([\n","    [\"Which GPU has the highest memory?\"],\n","    [\"What is the TFLOPs of the RTX 4090?\"],\n","    [\"How much power does the H100 consume?\"],\n","    [\"Which GPU costs $9999?\"],\n","    [\"What is the price of the MI300X?\"],\n","    [\"Which GPU has the highest TFLOPs?\"],\n","    [\"How many gigabytes of memory does the A100 have?\"],\n","    [\"What is the power consumption of the RTX 4090?\"],\n","    [\"Which GPU has 192 GB of memory?\"],\n","    [\"Compare the price of the H100 and MI300X.\"]\n","], [\"questions\"])\n","\n","# attach table to every question row\n","table_df = reader.transform(empty_df).select(\"document_table\")\n","combined_df = (questions_df.crossJoin(table_df))\n","\n","model = pipeline.fit(combined_df)\n","result_df = model.transform(combined_df)\n","\n","result_df.select(\"questions\", \"answers.result\").show(truncate=False)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7JTkBWi9mgZo","executionInfo":{"status":"ok","timestamp":1761702930965,"user_tz":-300,"elapsed":95987,"user":{"displayName":"Abdullah Mubeen","userId":"17886490017623663394"}},"outputId":"a69aad04-956b-4518-fbe4-d2538dae6189"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["table_qa_tapas_base_finetuned_wikisql_supervised download started this may take some time.\n","Approximate size to download 394.7 MB\n","[OK!]\n","+------------------------------------------------+--------+\n","|questions                                       |result  |\n","+------------------------------------------------+--------+\n","|Which GPU has the highest memory?               |[MI300X]|\n","|What is the TFLOPs of the RTX 4090?             |[83]    |\n","|How much power does the H100 consume?           |[700]   |\n","|Which GPU costs $9999?                          |[A100]  |\n","|What is the price of the MI300X?                |[29999] |\n","|Which GPU has the highest TFLOPs?               |[MI300X]|\n","|How many gigabytes of memory does the A100 have?|[80]    |\n","|What is the power consumption of the RTX 4090?  |[450]   |\n","|Which GPU has 192 GB of memory?                 |[MI300X]|\n","|Compare the price of the H100 and MI300X.       |[29999] |\n","+------------------------------------------------+--------+\n","\n"]}]},{"cell_type":"markdown","source":["### Exploring Parameters"],"metadata":{"id":"iBRoCjkT_NSC"}},{"cell_type":"markdown","source":["| **Parameter**             | **Description**                                                                                                              | **Default**        |\n","|----------------------------|------------------------------------------------------------------------------------------------------------------------------|-------------------|\n","| **contentPath**           | `Path` to the content source.                                                                                                 |                   |\n","| **inputCol**              | `Input column name` in the DataFrame.                                                                                         |                   |\n","| **outputCol**             | `Output column name` in the DataFrame.                                                                                        |                   |\n","| **outputFormat**          | Output format for the table content. Options: `json-table`, `html-table`.                            | `json-table`      |\n","| **appendCells**           | Whether to append all rows into a single content block instead of creating separate elements per row.                           | `false`           |\n","| **cellSeparator**         | String used to join cell values in a row when assembling textual output.                                                      | `\" \"`             |\n","| **explodeDocs**           | Whether to explode the documents into separate rows.                                                                          | `false`           |\n","| **flattenOutput**         | If `true`, output is flattened to plain text with minimal metadata.                                                           | `false`           |\n","| **groupBrokenParagraphs** | Whether to merge fragmented lines into coherent paragraphs using heuristics based on line length and structure.               | `true`            |\n","| **paragraphSplit**        | Regex pattern used to detect paragraph boundaries when grouping broken paragraphs.                                             | `\"\\n\\n\"`          |\n","| **shortLineWordThreshold**| Maximum word count for a line to be considered \"short\" during broken paragraph grouping.                                       | `10`              |\n","| **includePageBreaks**     | Whether to detect and tag content with page break metadata.                                                                  | `false`           |\n","| **includeSlideNotes**     | Whether to extract speaker notes from slides. When enabled, notes are included as narrative text elements.                    | `false`           |\n","| **addAttachmentContent**  | Whether to extract and include the textual content of plain-text attachments in the output.                                   | `false`           |\n","| **storeContent**          | Whether to include the raw file content in the output DataFrame as a separate `content` column.                               | `false`           |\n","| **ignoreExceptions**      | Whether to ignore exceptions during processing.                                                                              | `false`           |\n","| **inferTableStructure**   | Whether to generate an HTML `<table>` representation from structured table content.                                           | `false`           |\n","| **outputAsDocument**      | Whether to return all sentences joined into a single document.                                                               | `false`           |\n","| **timeout**               | Timeout value in seconds for reading remote HTML resources. Applied when fetching content from URLs.                           | `30`              |\n"],"metadata":{"id":"cRqJqudq_NSC"}},{"cell_type":"markdown","source":["**outputFormat**\n","\n","Output format for the table content. Options are `html-table` or `json-table`."],"metadata":{"id":"lPCT8Rq3_NSC"}},{"cell_type":"code","source":["reader2table = Reader2Table() \\\n","    .setContentPath(\"./single-table-file\") \\\n","    .setOutputFormat(\"html-table\")\n","\n","pipeline = Pipeline(stages=[reader2table])\n","empty_df = spark.createDataFrame([], \"string\").toDF(\"text\")\n","\n","model = pipeline.fit(empty_df)\n","result_df = model.transform(empty_df)\n","\n","result_df.select(\"document.result\").show(truncate=False)\n"],"metadata":{"id":"ZeiYBEsK_NSC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761324926842,"user_tz":-300,"elapsed":268,"user":{"displayName":"Abdullah Mubeen","userId":"17886490017623663394"}},"outputId":"fb39a17f-5c69-448b-e6ce-8f560c2a262b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|result                                                                                                                                                                                                                                                                                                                                                                                                        |\n","+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|[<table><tr><th>GPU</th><th>Memory (GB)</th><th>TFLOPs</th><th>Power (W)</th><th>Price ($)</th></tr><tr><td>RTX 4090</td><td>24</td><td>83</td><td>450</td><td>1599</td></tr><tr><td>A100</td><td>80</td><td>312</td><td>400</td><td>9999</td></tr><tr><td>H100</td><td>80</td><td>730</td><td>700</td><td>29999</td></tr><tr><td>MI300X</td><td>192</td><td>1230</td><td>750</td><td>29999</td></tr></table>]|\n","+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","\n"]}]},{"cell_type":"code","source":["reader2table = Reader2Table() \\\n","    .setContentPath(\"./single-table-file\") \\\n","    .setOutputFormat(\"json-table\")\n","\n","pipeline = Pipeline(stages=[reader2table])\n","empty_df = spark.createDataFrame([], \"string\").toDF(\"text\")\n","\n","model = pipeline.fit(empty_df)\n","result_df = model.transform(empty_df)\n","\n","result_df.select(\"document.result\").show(truncate=False)\n"],"metadata":{"id":"DNSvK1e7_NSD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761324927118,"user_tz":-300,"elapsed":231,"user":{"displayName":"Abdullah Mubeen","userId":"17886490017623663394"}},"outputId":"df4a125e-44c9-47a2-9529-0c93435a6d5b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|result                                                                                                                                                                                                                                |\n","+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|[{\"caption\":\"\",\"header\":[\"GPU\",\"Memory (GB)\",\"TFLOPs\",\"Power (W)\",\"Price ($)\"],\"rows\":[[\"RTX 4090\",\"24\",\"83\",\"450\",\"1599\"],[\"A100\",\"80\",\"312\",\"400\",\"9999\"],[\"H100\",\"80\",\"730\",\"700\",\"29999\"],[\"MI300X\",\"192\",\"1230\",\"750\",\"29999\"]]}]|\n","+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","\n"]}]},{"cell_type":"markdown","source":["## Reader2Image"],"metadata":{"id":"aoxO1u-8VfaZ"}},{"cell_type":"markdown","source":["The Reader2Image annotator enables seamless integration of image reading capabilities into existing Spark NLP workflows. It allows you to efficiently extract and structure image content from both individual image files and documents with embedded images.\n","\n","With this, you can read image files or extract images from documents. All extracted images are returned as structured Spark DataFrames with associated metadata, ready for downstream processing in Spark NLP pipelines.\n","\n","Supported File Formats:\n","- Image files: `.png`, `.jpg`, `.jpeg`, `.bmp`, `.gif`  \n","- Documents with embedded images: `.pdf`, `.doc`, `.docx`, `.ppt`, `.pptx`, `.xls`, `.xlsx`, `.eml`, `.msg`, `.html`, `.htm`, `.md`\n"],"metadata":{"id":"o06tdwIwV0TX"}},{"cell_type":"markdown","source":["### Basic usage"],"metadata":{"id":"dITxWUrIVlSF"}},{"cell_type":"code","source":["from sparknlp.reader.reader2image import Reader2Image\n","\n","reader2image = Reader2Image()\\\n","    .setContentPath(\"files/reader2image\")\\\n","    .setOutputCol(\"image\")\n","\n","pipeline = Pipeline(stages=[reader2image])\n"],"metadata":{"id":"Uj13Ko-jVlSF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["empty_df = spark.createDataFrame([], \"string\").toDF(\"text\")\n","\n","model = pipeline.fit(empty_df)\n","result_df = model.transform(empty_df)\n"],"metadata":{"id":"RDyCgUplVlSF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result_df.show()"],"metadata":{"id":"MqpPRkE7VlSG","executionInfo":{"status":"ok","timestamp":1761320225159,"user_tz":-300,"elapsed":16939,"user":{"displayName":"Abdullah Mubeen","userId":"17886490017623663394"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"dd01c42b-b756-4f80-d7e0-75b61b7fc363"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------+--------------------+---------+\n","|            fileName|               image|exception|\n","+--------------------+--------------------+---------+\n","|      line_chart.jpg|[{image, line_cha...|     NULL|\n","|johnsnowlabs_logo...|[{image, johnsnow...|     NULL|\n","|   Venn_diagram.jpeg|[{image, Venn_dia...|     NULL|\n","|windows_wallpaper...|[{image, windows_...|     NULL|\n","|              67.gif|[{image, 67.gif, ...|     NULL|\n","| embedded_image.docx|[{image, embedded...|     NULL|\n","+--------------------+--------------------+---------+\n","\n"]}]},{"cell_type":"code","source":["result_df.printSchema()"],"metadata":{"id":"qLgsmI2uVlSG","executionInfo":{"status":"ok","timestamp":1761320225159,"user_tz":-300,"elapsed":14,"user":{"displayName":"Abdullah Mubeen","userId":"17886490017623663394"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"201bac10-6911-4888-9fb6-ce880139f34e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- fileName: string (nullable = true)\n"," |-- image: array (nullable = false)\n"," |    |-- element: struct (containsNull = true)\n"," |    |    |-- annotatorType: string (nullable = true)\n"," |    |    |-- origin: string (nullable = true)\n"," |    |    |-- height: integer (nullable = false)\n"," |    |    |-- width: integer (nullable = false)\n"," |    |    |-- nChannels: integer (nullable = false)\n"," |    |    |-- mode: integer (nullable = false)\n"," |    |    |-- result: binary (nullable = true)\n"," |    |    |-- metadata: map (nullable = true)\n"," |    |    |    |-- key: string\n"," |    |    |    |-- value: string (valueContainsNull = true)\n"," |    |    |-- text: string (nullable = true)\n"," |-- exception: string (nullable = true)\n","\n"]}]},{"cell_type":"markdown","source":["Let's use `Qwen2VLTransformer` to describe these images. We will use the existing `image` column obtained from `Reader2Image` and add another column, `text`, which will contain the prompt for the VLM."],"metadata":{"id":"N_pkqvxAEwsC"}},{"cell_type":"code","source":["from pyspark.sql.functions import lit\n","\n","prompt_df = result_df.withColumn(\n","    \"text\",\n","    lit(\n","        \"<|im_start|>system\"\n","        \"You are a helpful assistant that describes images clearly and accurately.\"\n","        \"<|im_end|>\"\n","        \"<|im_start|>user\"\n","        \"<|vision_start|><|image_pad|><|vision_end|>\"\n","        \"Describe this image in detail.\"\n","        \"<|im_end|>\"\n","        \"<|im_start|>assistant\"\n","    )\n",")\n","\n","prompt_df.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hSN7k7f9pJqB","executionInfo":{"status":"ok","timestamp":1761320240044,"user_tz":-300,"elapsed":14889,"user":{"displayName":"Abdullah Mubeen","userId":"17886490017623663394"}},"outputId":"bad6d20e-09b1-4f5d-ea8e-8570dff7c8e6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------+--------------------+---------+--------------------+\n","|            fileName|               image|exception|                text|\n","+--------------------+--------------------+---------+--------------------+\n","|      line_chart.jpg|[{image, line_cha...|     NULL|<|im_start|>syste...|\n","|johnsnowlabs_logo...|[{image, johnsnow...|     NULL|<|im_start|>syste...|\n","|   Venn_diagram.jpeg|[{image, Venn_dia...|     NULL|<|im_start|>syste...|\n","|windows_wallpaper...|[{image, windows_...|     NULL|<|im_start|>syste...|\n","|              67.gif|[{image, 67.gif, ...|     NULL|<|im_start|>syste...|\n","| embedded_image.docx|[{image, embedded...|     NULL|<|im_start|>syste...|\n","+--------------------+--------------------+---------+--------------------+\n","\n"]}]},{"cell_type":"code","source":["from sparknlp.annotator import Qwen2VLTransformer\n","\n","multiModel = (\n","    Qwen2VLTransformer.pretrained(\"qwen2_vl_2b_instruct_int4\")\n","    .setInputCols(\"image\")\n","    .setOutputCol(\"answer\")\n",")\n","\n","pipeline = Pipeline().setStages([multiModel])\n","\n","model = pipeline.fit(prompt_df)\n","result = model.transform(prompt_df)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gqwXu9dn1ri_","executionInfo":{"status":"ok","timestamp":1761320394574,"user_tz":-300,"elapsed":129728,"user":{"displayName":"Abdullah Mubeen","userId":"17886490017623663394"}},"outputId":"85c49b5e-e1b7-46bc-b5dc-ffd8a908e08d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["qwen2_vl_2b_instruct_int4 download started this may take some time.\n","Approximate size to download 1.4 GB\n","[OK!]\n"]}]},{"cell_type":"code","source":["result.select(\"fileName\", \"answer.result\").show(truncate=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0c4u1PGB2Tx5","executionInfo":{"status":"ok","timestamp":1761321214136,"user_tz":-300,"elapsed":797102,"user":{"displayName":"Abdullah Mubeen","userId":"17886490017623663394"}},"outputId":"420306ac-cac1-46ba-bc7e-48205e529fcd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+---------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|fileName             |result                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n","+---------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|line_chart.jpg       |[The image is a line graph titled \"School Enrollment by Year.\" The x-axis represents the years from 1989 to 2020, and the y-axis represents the number of school enrollments. The graph shows a general trend of decreasing enrollments over the years, with some fluctuations.]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n","|johnsnowlabs_logo.png|[The image features a logo consisting of a stylized \"U\" shape. The \"U\" is divided into two parts: the top part is blue and the bottom part is purple. Inside the blue part of the \"U\", there is a blue liquid or substance. The background of the image is a light gray color. The text \"John Snow Labs\" is written in purple on the right side of the image.]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n","|Venn_diagram.jpeg    |[The image is a Venn diagram comparing two sets of categories: \"Dolphins\" and \"Fish.\" The diagram is divided into three overlapping circles, each representing a category:\\n\\n1. The leftmost circle is labeled \"Dolphins\" and contains the following categories:\\n   - Breathe air\\n Live birth\\n times\\n   - Warm blooded\\n   - Warm blooded\\n   - Warm blooded\\n   - Warm blooded\\n   - Warm blooded\\n   - Warm blooded\\n   - Warm blooded\\n   - Warm blooded\\n   - Warm blooded\\n   - Warm blooded\\n   - Warm blooded\\n   - Warm blooded\\n   - Warm blooded\\n   - Warm blooded\\n   - Warm blooded\\n   - Warm blooded\\n   - Warm blooded\\n   - Warm blooded\\n   - Warm blooded\\n   - Warm blooded\\n\\n   - Warm blooded\\n   - Warm blooded\\n]                                                                                                                                                                                                                 |\n","|windows_wallpaper.bmp|[The image depicts a large, rocky formation resembling a natural arch or bridge in a desert landscape. The rock formation is characterized by its jagged edges and layered structure, typical of geological formations formed by erosion over time. The sky above is clear, suggesting a dry, arid environment, likely a desert or semi-arid region. The sand dunes in the background further emphasize the arid environment. The overall scene conveys a sense of image depicts a large, rocky formation resembling a natural arch or bridge in a desert landscape. The rock formation is characterized by its jagged edges and layered structure, typical of geological formations formed by erosion over time. The sky above is clear, suggesting a dry, arid environment, likely a desert or semi-arid region. The sand dunes in the background further emphasize the arid environment. The overall scene conveys a sense of desolation and natural beauty.]|\n","|67.gif               |[The image shows a group of people sitting in a locker room. The individuals are wearing athletic clothing, including jerseys and shorts. The locker room has wooden walls and a wooden floor. There are two men sitting side by side, and another person is partially visible on the right side of the image. The setting appears to be a sports facility, likely a locker room, given the attire and the presence of sports equipment.]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n","|embedded_image.docx  |[The image features a logo consisting of a stylized \"U\" shape. The \"U\" is divided into two parts: the top part is blue and the bottom part is purple. Inside the blue part of the \"U\", there is a blue liquid or substance. The background of the image is a light gray color. The text \"John Snow Labs\" is written in purple on the right side of the image.]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n","+---------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","\n"]}]},{"cell_type":"markdown","source":["### Exploring Parameters"],"metadata":{"id":"6pcULb28AG7O"}},{"cell_type":"markdown","source":["| **Parameter**          | **Why it’s useful / Notes**                                                                                           | **Default** |\n","| ---------------------- | --------------------------------------------------------------------------------------------------------------------- | ----------- |\n","| **contentPath**        | Core input: the source of the file(s). Can be a local path or a URL.                                                 |             |\n","| **outputCol**          | Where the extracted results go.                                                                                      |             |\n","| **readAsImage**        | Key for PDFs: whether to process pages as images. Necessary for scanned PDFs where text extraction directly won't work. | `false`     |\n","| **splitPage**          | Splits the document per page. Improves performance and enables page-specific operations.                               | `true`      |\n","| **onlyPageNum**        | Extracts only page numbers if you don’t need full text content.                                                      | `false`     |\n","| **storeContent**       | Retains raw file bytes alongside structured output, useful if you want to save or process the original file later.    | `false`     |\n","| **flattenOutput**      | Outputs clean, concatenated text with minimal metadata. Good for quick analysis or NLP tasks.                         | `false`     |\n","| **normalizeLigatures** | Converts ligatures like `ﬂ` into standard characters (`fl`). Helps avoid text artifacts, especially in scanned PDFs. | `true`      |\n","| **timeout**            | Maximum seconds to wait when fetching remote resources (URLs). Helps prevent notebook hangs.                          | `30`        |\n","\n","**Tips for Usage:**   \n","- Use `readAsImage` and `splitPage` for scanned PDFs or large documents to improve extraction quality and performance.  \n","- `flattenOutput` is optional but make it easier to handle the output in downstream analysis or NLP pipelines.  \n","- `storeContent` is useful if you want to archive the original file alongside extracted text for auditing or reuse.  \n","- `normalizeLigatures` is usually recommended for PDFs to prevent weird characters from breaking your text processing.  \n","- `timeout` is important when fetching from URLs to avoid long delays in a session.  "],"metadata":{"id":"awazNu9lAG7O"}}]}