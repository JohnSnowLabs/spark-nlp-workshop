{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zsWWqAa7XFSb"
   },
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u0bx1JcGXFA-"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/open-source-nlp/05.2.Transformers_for_Sequence_Classification_in_SparkNLP.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0QdDYGXqXY_D"
   },
   "source": [
    "# BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LYEJ-H_pXqCQ"
   },
   "source": [
    "BertForSequenceClassification can load Bert Models with sequence classification/regression head on top (a linear layer on top of the pooled output) e.g. for multi-class document classification tasks.\n",
    "\n",
    "Pretrained models can be loaded with `pretrained()` of the companion object.\n",
    "<br/><br/>\n",
    "\n",
    "### **Here are Bert Based Sequence Classification models available in Spark NLP**\n",
    "<br/>\n",
    "\n",
    "\n",
    "| title                                                                                                        | name                                                 | language   |\n",
    "|:-------------------------------------------------------------------------------------------------------------|:-----------------------------------------------------|:-----------|\n",
    "| BERT Sequence Classification Base - DBpedia14 (bert_base_sequence_classifier_dbpedia_14)                     | bert_base_sequence_classifier_dbpedia_14             | en         |\n",
    "| BERT Sequence Classification Base - IMDB (bert_base_sequence_classifier_imdb)                                | bert_base_sequence_classifier_imdb                   | en         |\n",
    "| BERT Sequence Classification Large - IMDB (bert_large_sequence_classifier_imdb)                              | bert_large_sequence_classifier_imdb                  | en         |\n",
    "| BERT Sequence Classification Multilingual - AlloCine (bert_multilingual_sequence_classifier_allocine)        | bert_multilingual_sequence_classifier_allocine       | fr         |\n",
    "| BERT Sequence Classification Base - AG News (bert_base_sequence_classifier_ag_news)                          | bert_base_sequence_classifier_ag_news                | en         |\n",
    "| BERT Sequence Classification - Spanish Emotion Analysis (bert_sequence_classifier_beto_emotion_analysis)     | bert_sequence_classifier_beto_emotion_analysis       | es         |\n",
    "| BERT Sequence Classification - Spanish Sentiment Analysis (bert_sequence_classifier_beto_sentiment_analysis) | bert_sequence_classifier_beto_sentiment_analysis     | es         |\n",
    "| BERT Sequence Classification - Detecting Hate Speech (bert_sequence_classifier_dehatebert_mono)              | bert_sequence_classifier_dehatebert_mono             | en         |\n",
    "| BERT Sequence Classification - Financial Sentiment Analysis (bert_sequence_classifier_finbert)               | bert_sequence_classifier_finbert                     | en         |\n",
    "| BERT Sequence Classification - Japanese Sentiment (bert_sequence_classifier_japanese_sentiment)              | bert_sequence_classifier_japanese_sentiment          | ja         |\n",
    "| BERT Sequence Classification Multilingual Sentiment                                                          | bert_sequence_classifier_multilingual_sentiment      | xx         |\n",
    "| BERT Sequence Classification - Russian Sentiment Analysis (bert_sequence_classifier_rubert_sentiment)        | bert_sequence_classifier_rubert_sentiment            | ru         |\n",
    "| BERT Sequence Classification - German Sentiment Analysis (bert_sequence_classifier_sentiment)                | bert_sequence_classifier_sentiment                   | de         |\n",
    "| BERT Sequence Classification - Turkish Sentiment (bert_sequence_classifier_turkish_sentiment)                | bert_sequence_classifier_turkish_sentiment           | tr         |\n",
    "| Bert for Sequence Classification (Question vs Statement)                                                     | bert_sequence_classifier_question_statement          | en         |\n",
    "| Bert for Sequence Classification (Clinical Question vs Statement)                                            | bert_sequence_classifier_question_statement_clinical | en         |\n",
    "| BERT Sequence Classification - Identify Antisemitic texts                                                    | bert_sequence_classifier_antisemitism                | en         |\n",
    "| BERT Sequence Classification - Detecting Hate Speech (bert_sequence_classifier_hatexplain)                   | bert_sequence_classifier_hatexplain                  | en         |\n",
    "| BERT Sequence Classification - Identify Trec Data Classes                                                    | bert_sequence_classifier_trec_coarse                 | en         |\n",
    "| BERT Sequence Classification - Classify into News Categories                                                 | bert_sequence_classifier_age_news                    | en         |\n",
    "| BERT Sequence Classification - Classify Banking-Related texts                                                | bert_sequence_classifier_banking77                   | en         |\n",
    "| BERT Sequence Classification - Detect Spam SMS                                                               | bert_sequence_classifier_sms_spam                    | en         |\n",
    "| BERT Sequence Classifier - Classify the Music Genre                                                          | bert_sequence_classifier_song_lyrics                 | en         |\n",
    "| DistilBERT Sequence Classification Base - AG News (distilbert_base_sequence_classifier_ag_news)              | distilbert_base_sequence_classifier_ag_news          | en         |\n",
    "| DistilBERT Sequence Classification - Amazon Polarity (distilbert_base_sequence_classifier_amazon_polarity)   | distilbert_base_sequence_classifier_amazon_polarity  | en         |\n",
    "| DistilBERT Sequence Classification - IMDB (distilbert_base_sequence_classifier_imdb)                         | distilbert_base_sequence_classifier_imdb             | en         |\n",
    "| DistilBERT Sequence Classification - Urdu IMDB (distilbert_base_sequence_classifier_imdb)                    | distilbert_base_sequence_classifier_imdb             | ur         |\n",
    "| DistilBERT Sequence Classification French - AlloCine (distilbert_multilingual_sequence_classifier_allocine)  | distilbert_multilingual_sequence_classifier_allocine | fr         |\n",
    "| DistilBERT Sequence Classification - Banking77 (distilbert_sequence_classifier_banking77)                    | distilbert_sequence_classifier_banking77             | en         |\n",
    "| DistilBERT Sequence Classification - Emotion (distilbert_sequence_classifier_emotion)                        | distilbert_sequence_classifier_emotion               | en         |\n",
    "| DistilBERT Sequence Classification - Industry (distilbert_sequence_classifier_industry)                      | distilbert_sequence_classifier_industry              | en         |\n",
    "| DistilBERT Sequence Classification - Policy (distilbert_sequence_classifier_policy)                          | distilbert_sequence_classifier_policy                | en         |\n",
    "| DistilBERT Sequence Classification - SST-2 (distilbert_sequence_classifier_sst2)                             | distilbert_sequence_classifier_sst2                  | en         |\n",
    "| ALBERT Sequence Classification Base - AG News (albert_base_sequence_classifier_ag_news)                      | albert_base_sequence_classifier_ag_news              | en         |\n",
    "| ALBERT Sequence Classification Base - IMDB (albert_base_sequence_classifier_imdb)                            | albert_base_sequence_classifier_imdb                 | en         |\n",
    "| Longformer Sequence Classification Base - AG News (longformer_base_sequence_classifier_ag_news)              | longformer_base_sequence_classifier_ag_news          | en         |\n",
    "| Longformer Sequence Classification Base - IMDB (longformer_base_sequence_classifier_imdb)                    | longformer_base_sequence_classifier_imdb             | en         |\n",
    "| RoBERTa Sequence Classification Base - AG News (roberta_base_sequence_classifier_ag_news)                    | roberta_base_sequence_classifier_ag_news             | en         |\n",
    "| RoBERTa Sequence Classification Base - IMDB (roberta_base_sequence_classifier_imdb)                          | roberta_base_sequence_classifier_imdb                | en         |\n",
    "| XLM-RoBERTa Sequence Classification Base - AG News (xlm_roberta_base_sequence_classifier_ag_news)            | xlm_roberta_base_sequence_classifier_ag_news         | en         |\n",
    "| XLM-RoBERTa Sequence Classification Multilingual - AlloCine (xlm_roberta_base_sequence_classifier_allocine)  | xlm_roberta_base_sequence_classifier_allocine        | fr         |\n",
    "| XLM-RoBERTa Sequence Classification Base - IMDB (xlm_roberta_base_sequence_classifier_imdb)                  | xlm_roberta_base_sequence_classifier_imdb            | en         |\n",
    "| XLNet Sequence Classification Base - AG News (xlnet_base_sequence_classifier_ag_news)                        | xlnet_base_sequence_classifier_ag_news               | en         |\n",
    "| XLNet Sequence Classification Base - IMDB (xlnet_base_sequence_classifier_imdb)                              | xlnet_base_sequence_classifier_imdb                  | en         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8XifA40IPzv9"
   },
   "source": [
    "You can also import any models trained with the transformers library into Spark NLP for greater inference speed & scalability. Access our tutorials to do so in [this discussion thread](https://github.com/JohnSnowLabs/spark-nlp/discussions/5669). You will find notebooks like [this one](https://github.com/JohnSnowLabs/spark-nlp/blob/74b8f230bc1547ee1b1152fbd19c111e8610f13c/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20BertForSequenceClassification.ipynb) to import BertForSequenceClassification models. The process is very straightforward and can be done in a few lines of code. Once you've downloaded the model and extracted its contents as described in the notebooks, it's as simple as running the following snippet:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3-DfWltyR2S6"
   },
   "source": [
    "```\n",
    "sequenceClassifier = BertForSequenceClassification.loadSavedModel(\n",
    "     '{}/saved_model/1'.format(MODEL_NAME), spark)\\\n",
    "  .setInputCols([\"document\",'token'])\\\n",
    "  .setOutputCol(\"class\")\\\n",
    "  .setCaseSensitive(True)\\\n",
    "  .setMaxSentenceLength(128)\n",
    "\n",
    "sequenceClassifier.write().overwrite().save(\"./{}_spark_nlp\".format(MODEL_NAME))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HY7Kv9CaXvj6"
   },
   "source": [
    "## Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7-6DPN1DXDF5"
   },
   "outputs": [],
   "source": [
    "!wget -q http://setup.johnsnowlabs.com/colab.sh -O - | bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "executionInfo": {
     "elapsed": 87453,
     "status": "ok",
     "timestamp": 1761764867990,
     "user": {
      "displayName": "Jay Gil",
      "userId": "13872230983498128557"
     },
     "user_tz": 180
    },
    "id": "SDasO3DbKu2Z",
    "outputId": "71a4ac04-b3ac-4111-f25c-c4e0cf9acf4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version:  6.2.0\n",
      "Apache Spark version:  3.5.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://4c306040331f:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark NLP</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7b05589d0560>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sparknlp\n",
    "\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "\n",
    "from pyspark.ml import Pipeline,PipelineModel\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "import pandas as pd\n",
    "\n",
    "spark = sparknlp.start()\n",
    "\n",
    "print(\"Spark NLP version: \", sparknlp.version())\n",
    "print(\"Apache Spark version: \", spark.version)\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4m50AicQYFVa"
   },
   "source": [
    "## BertForSequenceClassification Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hB9gxXRWk9hx"
   },
   "source": [
    "Now, let's create a Spark NLP Pipeline with `bert_base_sequence_classifier_imdb` model and check the results.\n",
    "\n",
    "This model is a fine-tuned BERT model that is ready to be used for Sequence Classification tasks such as sentiment analysis or multi-class text classification and it achieves state-of-the-art performance.\n",
    "\n",
    "This model has been trained to recognize two types of entities: negative (neg), positive (pos)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54854,
     "status": "ok",
     "timestamp": 1761764922846,
     "user": {
      "displayName": "Jay Gil",
      "userId": "13872230983498128557"
     },
     "user_tz": 180
    },
    "id": "kt3wsl0cXC_2",
    "outputId": "030389af-30d6-44c4-db35-d539e32937eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_base_sequence_classifier_imdb download started this may take some time.\n",
      "Approximate size to download 387.6 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol('text') \\\n",
    "    .setOutputCol('document')\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols(['document']) \\\n",
    "    .setOutputCol('token')\n",
    "\n",
    "sequenceClassifier = BertForSequenceClassification \\\n",
    "    .pretrained('bert_base_sequence_classifier_imdb', 'en') \\\n",
    "    .setInputCols(['token', 'document']) \\\n",
    "    .setOutputCol('pred_class') \\\n",
    "    .setCaseSensitive(True) \\\n",
    "    .setMaxSentenceLength(512)\\\n",
    "    .setMultilabel(True)\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    stages=[\n",
    "        document_assembler,\n",
    "        tokenizer,\n",
    "        sequenceClassifier\n",
    "])\n",
    "\n",
    "sample_text= [[\"I really liked that movie!\"], [\"The last movie I watched was awful!\"]]\n",
    "sample_df= spark.createDataFrame(sample_text).toDF(\"text\")\n",
    "model = pipeline.fit(sample_df)\n",
    "result= model.transform(sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1761764922853,
     "user": {
      "displayName": "Jay Gil",
      "userId": "13872230983498128557"
     },
     "user_tz": 180
    },
    "id": "4Ko9vP95XXA1",
    "outputId": "81194e24-bd56-43ae-ec58-ae20cc6727bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DocumentAssembler_c1060a6cc4d4,\n",
       " REGEX_TOKENIZER_f12a8bf81778,\n",
       " BERT_FOR_SEQUENCE_CLASSIFICATION_41f87e548530]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.stages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zmBD_hKlRzs-"
   },
   "source": [
    "We can check the classes of `bert_base_sequence_classifier_imdb` model by using `getClasses()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1761764922859,
     "user": {
      "displayName": "Jay Gil",
      "userId": "13872230983498128557"
     },
     "user_tz": 180
    },
    "id": "K7-P1FL3XCvL",
    "outputId": "4a22eeb3-987e-446d-96d3-399ac4e27075"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequenceClassifier.getClasses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1761764922865,
     "user": {
      "displayName": "Jay Gil",
      "userId": "13872230983498128557"
     },
     "user_tz": 180
    },
    "id": "alaqz-0PXW82",
    "outputId": "0ba9736a-1631-430d-d359-4ab04169228a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text', 'document', 'token', 'pred_class']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1761764922871,
     "user": {
      "displayName": "Jay Gil",
      "userId": "13872230983498128557"
     },
     "user_tz": 180
    },
    "id": "pr5Meq-6XW50",
    "outputId": "9bb0cf9c-3894-40ba-e110-13e032ce7b76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- document: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      " |    |    |-- embeddings: array (nullable = true)\n",
      " |    |    |    |-- element: float (containsNull = false)\n",
      " |-- token: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      " |    |    |-- embeddings: array (nullable = true)\n",
      " |    |    |    |-- element: float (containsNull = false)\n",
      " |-- pred_class: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      " |    |    |-- embeddings: array (nullable = true)\n",
      " |    |    |    |-- element: float (containsNull = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2848,
     "status": "ok",
     "timestamp": 1761764925720,
     "user": {
      "displayName": "Jay Gil",
      "userId": "13872230983498128557"
     },
     "user_tz": 180
    },
    "id": "Ev6irQHEtEcW",
    "outputId": "1b894983-c322-4af6-b6c6-17e47b0b831f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+----------+-----------------------------------------------------+\n",
      "|sentence                           |prediction|metadata                                             |\n",
      "+-----------------------------------+----------+-----------------------------------------------------+\n",
      "|I really liked that movie!         |pos       |{sentence -> 0, neg -> 0.009402122, pos -> 0.9905979}|\n",
      "|The last movie I watched was awful!|neg       |{sentence -> 0, neg -> 0.9916872, pos -> 0.008312822}|\n",
      "+-----------------------------------+----------+-----------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_df= result.select(F.explode(F.arrays_zip(result.document.result,\n",
    "                                                result.pred_class.result,\n",
    "                                                result.pred_class.metadata)).alias(\"col\"))\\\n",
    "                 .select(F.expr(\"col['0']\").alias(\"sentence\"),\n",
    "                         F.expr(\"col['1']\").alias(\"prediction\"),\n",
    "                         F.expr(\"col['2']\").alias(\"metadata\"))\n",
    "\n",
    "result_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aCIru-7Rgazw"
   },
   "source": [
    "## DistilBertForSequenceClassification By Using LightPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZo_X6SHgoeM"
   },
   "source": [
    "Now, we will use `distilbert_base_sequence_classifier_ag_news` model with LightPipeline and fullAnnotate it with sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31590,
     "status": "ok",
     "timestamp": 1761764957312,
     "user": {
      "displayName": "Jay Gil",
      "userId": "13872230983498128557"
     },
     "user_tz": 180
    },
    "id": "NAPdh0bjgUGi",
    "outputId": "b55d84d3-e4b0-421d-a777-9ce5f5c8d59d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distilbert_base_sequence_classifier_ag_news download started this may take some time.\n",
      "Approximate size to download 234.9 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol('text') \\\n",
    "    .setOutputCol('document')\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols(['document']) \\\n",
    "    .setOutputCol('token')\n",
    "\n",
    "sequenceClassifier = DistilBertForSequenceClassification \\\n",
    "    .pretrained('distilbert_base_sequence_classifier_ag_news', 'en') \\\n",
    "    .setInputCols(['token', 'document']) \\\n",
    "    .setOutputCol('class') \\\n",
    "    .setCaseSensitive(True) \\\n",
    "    .setMaxSentenceLength(512)\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    stages=[\n",
    "        document_assembler,\n",
    "        tokenizer,\n",
    "        sequenceClassifier\n",
    "])\n",
    "\n",
    "empty_data= spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "model = pipeline.fit(empty_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 1260,
     "status": "ok",
     "timestamp": 1761764958575,
     "user": {
      "displayName": "Jay Gil",
      "userId": "13872230983498128557"
     },
     "user_tz": 180
    },
    "id": "Nulge_OAgh0o"
   },
   "outputs": [],
   "source": [
    "light_model= LightPipeline(model)\n",
    "light_result= light_model.fullAnnotate(\"Manchester United forward Cristiano Ronaldo on Saturday made his 181st appearance for Portugal.\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 903,
     "status": "ok",
     "timestamp": 1761764959480,
     "user": {
      "displayName": "Jay Gil",
      "userId": "13872230983498128557"
     },
     "user_tz": 180
    },
    "id": "GLNRAc5agxHm",
    "outputId": "5bd194aa-ec74-4abe-e8a9-d16237142cc4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'document': [Annotation(document, 0, 94, Manchester United forward Cristiano Ronaldo on Saturday made his 181st appearance for Portugal., {}, [])],\n",
       " 'token': [Annotation(token, 0, 9, Manchester, {'sentence': '0'}, []),\n",
       "  Annotation(token, 11, 16, United, {'sentence': '0'}, []),\n",
       "  Annotation(token, 18, 24, forward, {'sentence': '0'}, []),\n",
       "  Annotation(token, 26, 34, Cristiano, {'sentence': '0'}, []),\n",
       "  Annotation(token, 36, 42, Ronaldo, {'sentence': '0'}, []),\n",
       "  Annotation(token, 44, 45, on, {'sentence': '0'}, []),\n",
       "  Annotation(token, 47, 54, Saturday, {'sentence': '0'}, []),\n",
       "  Annotation(token, 56, 59, made, {'sentence': '0'}, []),\n",
       "  Annotation(token, 61, 63, his, {'sentence': '0'}, []),\n",
       "  Annotation(token, 65, 69, 181st, {'sentence': '0'}, []),\n",
       "  Annotation(token, 71, 80, appearance, {'sentence': '0'}, []),\n",
       "  Annotation(token, 82, 84, for, {'sentence': '0'}, []),\n",
       "  Annotation(token, 86, 93, Portugal, {'sentence': '0'}, []),\n",
       "  Annotation(token, 94, 94, ., {'sentence': '0'}, [])],\n",
       " 'class': [Annotation(category, 0, 94, Sports, {'Sports': '0.57992303', 'Business': '0.0029063805', 'World': '0.41659665', 'Sci/Tech': '5.739416E-4', 'sentence': '0'}, [])]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "light_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uVmQLNg0hsQK"
   },
   "source": [
    "Let's check the classes that `distilbert_base_sequence_classifier_ag_news` model can predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1761764959497,
     "user": {
      "displayName": "Jay Gil",
      "userId": "13872230983498128557"
     },
     "user_tz": 180
    },
    "id": "OVSQbncUhxNc",
    "outputId": "2d11ead2-14da-4543-f63e-2951bc790d98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sports', 'World', 'Sci/Tech', 'Business']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequenceClassifier.getClasses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1761764959504,
     "user": {
      "displayName": "Jay Gil",
      "userId": "13872230983498128557"
     },
     "user_tz": 180
    },
    "id": "qK8KspWwgxDk",
    "outputId": "44d357b6-f157-44c6-821b-51be323e81e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['document', 'token', 'class'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "light_result.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zPAXXvCQkYU4"
   },
   "source": [
    "Let's check the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "executionInfo": {
     "elapsed": 38,
     "status": "ok",
     "timestamp": 1761764959550,
     "user": {
      "displayName": "Jay Gil",
      "userId": "13872230983498128557"
     },
     "user_tz": 180
    },
    "id": "zqCTHdXAhKW-",
    "outputId": "3d984c0a-810d-42fb-fac0-6df7afaa7f3f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"result_df\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Manchester United forward Cristiano Ronaldo on Saturday made his 181st appearance for Portugal.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prediction\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Sports\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "result_df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-9441ca7e-162e-4cfa-a332-64dcff94a4ca\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Manchester United forward Cristiano Ronaldo on Saturday made his 181st appearance for Portugal.</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9441ca7e-162e-4cfa-a332-64dcff94a4ca')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-9441ca7e-162e-4cfa-a332-64dcff94a4ca button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-9441ca7e-162e-4cfa-a332-64dcff94a4ca');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                                                                                              text  \\\n",
       "0  Manchester United forward Cristiano Ronaldo on Saturday made his 181st appearance for Portugal.   \n",
       "\n",
       "  prediction  \n",
       "0     Sports  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "text= []\n",
    "pred= []\n",
    "\n",
    "for i, k in list(zip(light_result[\"document\"], light_result[\"class\"])):\n",
    "  text.append(i.result)\n",
    "  pred.append(k.result)\n",
    "\n",
    "result_df= pd.DataFrame({\"text\": text, \"prediction\": pred})\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8WpM19MIJwxs"
   },
   "source": [
    "## CamemBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41750,
     "status": "ok",
     "timestamp": 1761765001302,
     "user": {
      "displayName": "Jay Gil",
      "userId": "13872230983498128557"
     },
     "user_tz": 180
    },
    "id": "ME2xOX8wJyI2",
    "outputId": "604df57f-e1fb-46d3-ad9c-df62cfdd89c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "camembert_base_sequence_classifier_allocine download started this may take some time.\n",
      "Approximate size to download 396.1 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "document_assembler = DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "tokenizer = Tokenizer()\\\n",
    "    .setInputCols(['document'])\\\n",
    "    .setOutputCol('token')\n",
    "\n",
    "sequenceClassifier = CamemBertForSequenceClassification.pretrained(\"camembert_base_sequence_classifier_allocine\", \"fr\")\\\n",
    "    .setInputCols([\"document\", \"token\"])\\\n",
    "    .setOutputCol(\"pred_class\")\\\n",
    "    .setCaseSensitive(True)\\\n",
    "    .setMaxSentenceLength(512)\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    stages=[\n",
    "        document_assembler,\n",
    "        tokenizer,\n",
    "        sequenceClassifier\n",
    "])\n",
    "\n",
    "data = spark.createDataFrame([['On retrouve avec plaisir nos deux ripoux pr√©f√©r√©s pour une super histoire encore. Cette suite est tr√®s bien r√©ussie!'], [\"Film trop lent comme ses dialogues.Je n'ai pas du tout accroch√©.\"]]).toDF(\"text\")\n",
    "result = pipeline.fit(data).transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4152,
     "status": "ok",
     "timestamp": 1761765005456,
     "user": {
      "displayName": "Jay Gil",
      "userId": "13872230983498128557"
     },
     "user_tz": 180
    },
    "id": "u4VmjhY4M_yJ",
    "outputId": "d7788f42-83fe-463d-f60a-2bc27983aa64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------+----------+\n",
      "|sentence                                                                                                            |prediction|\n",
      "+--------------------------------------------------------------------------------------------------------------------+----------+\n",
      "|On retrouve avec plaisir nos deux ripoux pr√©f√©r√©s pour une super histoire encore. Cette suite est tr√®s bien r√©ussie!|pos       |\n",
      "|Film trop lent comme ses dialogues.Je n'ai pas du tout accroch√©.                                                    |neg       |\n",
      "+--------------------------------------------------------------------------------------------------------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_df= result.select(F.explode(F.arrays_zip(result.document.result,\n",
    "                                                result.pred_class.result)).alias(\"col\"))\\\n",
    "                 .select(F.expr(\"col['0']\").alias(\"sentence\"),\n",
    "                         F.expr(\"col['1']\").alias(\"prediction\"))\n",
    "\n",
    "result_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3f1eX3LDKEjy"
   },
   "source": [
    "## MPNetForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36304,
     "status": "ok",
     "timestamp": 1761765041763,
     "user": {
      "displayName": "Jay Gil",
      "userId": "13872230983498128557"
     },
     "user_tz": 180
    },
    "id": "9MtN87qDKFHS",
    "outputId": "3ef231ed-3cc7-428d-e7bf-794f674361cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mpnet_sequence_classifier_ukr_message download started this may take some time.\n",
      "Approximate size to download 384.5 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "document = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "sequenceClassifier = MPNetForSequenceClassification.pretrained() \\\n",
    "    .setInputCols([\"document\", \"token\"]) \\\n",
    "    .setOutputCol(\"label\")\n",
    "\n",
    "pipeline = Pipeline().setStages([\n",
    "    document,\n",
    "    tokenizer,\n",
    "    sequenceClassifier\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2532,
     "status": "ok",
     "timestamp": 1761765044298,
     "user": {
      "displayName": "Jay Gil",
      "userId": "13872230983498128557"
     },
     "user_tz": 180
    },
    "id": "y1kF-MUrKUGP",
    "outputId": "1b870ce4-651f-4ede-9e84-54b29d3e846b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------+--------------------+\n",
      "|text                                   |result              |\n",
      "+---------------------------------------+--------------------+\n",
      "|I love driving my car.                 |[TRANSPORT/CAR]     |\n",
      "|The next bus will arrive in 20 minutes.|[TRANSPORT/MOVEMENT]|\n",
      "|pineapple on pizza is the worst ü§Æ     |[FOOD]              |\n",
      "+---------------------------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark.createDataFrame([\n",
    "     [\"I love driving my car.\"],\n",
    "     [\"The next bus will arrive in 20 minutes.\"],\n",
    "     [\"pineapple on pizza is the worst ü§Æ\"]]).toDF(\"text\")\n",
    "\n",
    "result = pipeline.fit(data).transform(data)\n",
    "result.select(\"text\", \"label.result\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hzksfZkITrFZ"
   },
   "source": [
    "## RoBertaForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 480417,
     "status": "ok",
     "timestamp": 1761765524717,
     "user": {
      "displayName": "Jay Gil",
      "userId": "13872230983498128557"
     },
     "user_tz": 180
    },
    "id": "VkAenpKqTw5u",
    "outputId": "b13c8781-3c4a-4c49-c7bd-9e780596f843"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta_classifier_autotrain_neurips_chanllenge_1287149282 download started this may take some time.\n",
      "Approximate size to download 1.2 GB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "documentAssembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols(\"document\") \\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "roberta_classifier = RoBertaForSequenceClassification.pretrained(\"roberta_classifier_autotrain_neurips_chanllenge_1287149282\",\"en\") \\\n",
    "    .setInputCols([\"document\", \"token\"]) \\\n",
    "    .setOutputCol(\"class\")\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    stages=[\n",
    "        documentAssembler,\n",
    "        tokenizer,\n",
    "        roberta_classifier])\n",
    "\n",
    "data = spark.createDataFrame([[\"I love you!\"], [\"I feel lucky to be here.\"]]).toDF(\"text\")\n",
    "\n",
    "result = pipeline.fit(data).transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1761765524751,
     "user": {
      "displayName": "Jay Gil",
      "userId": "13872230983498128557"
     },
     "user_tz": 180
    },
    "id": "B1yCMwI9UsDQ",
    "outputId": "b118c750-a195-4676-b597-e7b848853dbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+------+\n",
      "|text                    |result|\n",
      "+------------------------+------+\n",
      "|I love you!             |[1]   |\n",
      "|I feel lucky to be here.|[1]   |\n",
      "+------------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.select(\"text\", \"class.result\").show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
