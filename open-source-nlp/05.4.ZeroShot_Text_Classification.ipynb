{"cells":[{"cell_type":"markdown","metadata":{"id":"I08sFJYCxR0Z"},"source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"]},{"cell_type":"markdown","metadata":{"id":"FwJ-P56kq6FU"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/open-source-nlp/05.4.ZeroShot_Text_Classification.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"Niy3mZAjoayg"},"source":["# Zero-Shot Text Classification\n","**State-of-the-art NLP models for text classification without annotated data**\n","\n","Natural language processing is a very exciting field right now. In recent years, the community has begun to figure out some pretty effective methods of learning from the enormous amounts of unlabeled data available on the internet. The success of transfer learning from unsupervised models has allowed us to surpass virtually all existing benchmarks on downstream supervised learning tasks. As we continue to develop new model architectures and unsupervised learning objectives, \"state of the art\" continues to be a rapidly moving target for many tasks where large amounts of labeled data are available.\n","\n","## Zero-Shot Learning (ZSL)\n","Traditionally, zero-shot learning (ZSL) most often referred to a fairly specific type of task: learn a classifier on one set of labels and then evaluate on a different set of labels that the classifier has never seen before. Recently, especially in NLP, it's been used much more broadly to mean get a model to do something that it wasn't explicitly trained to do. A well-known example of this is in the [GPT-2 paper](https://pdfs.semanticscholar.org/9405/cc0d6169988371b2755e573cc28650d14dfe.pdf) where the authors evaluate a language model on downstream tasks like machine translation without fine-tuning on these tasks directly.\n"]},{"cell_type":"markdown","metadata":{"id":"okhT7AcXxben"},"source":["## Colab Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n9luR-MGuUb4"},"outputs":[],"source":["! pip install -q pyspark==3.4.1 spark-nlp==5.1.2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a-nbXT3euZoS","colab":{"base_uri":"https://localhost:8080/","height":254},"executionInfo":{"status":"ok","timestamp":1696398057510,"user_tz":240,"elapsed":50742,"user":{"displayName":"Vildan SarÄ±kaya","userId":"07789644790967768983"}},"outputId":"e1746e79-2aa1-4128-a9a9-b85c3f0a83d2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Spark NLP version:  5.1.2\n","Apache Spark version:  3.4.1\n"]},{"output_type":"execute_result","data":{"text/plain":["<pyspark.sql.session.SparkSession at 0x787ee43ca0e0>"],"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://3a7d8ef24ab3:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.4.1</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>Spark NLP</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "]},"metadata":{},"execution_count":2}],"source":["import sparknlp\n","\n","from sparknlp.base import *\n","from sparknlp.annotator import *\n","\n","from pyspark.ml import Pipeline,PipelineModel\n","from pyspark.sql import SparkSession\n","from pyspark.sql import functions as F\n","import pandas as pd\n","\n","spark = sparknlp.start()\n","\n","print(\"Spark NLP version: \", sparknlp.version())\n","print(\"Apache Spark version: \", spark.version)\n","\n","spark"]},{"cell_type":"markdown","metadata":{"id":"AMU4sAJQ0Rhs"},"source":["## Bert Zero-Shot Classification\n","\n","This model is intended to be used for zero-shot text classification, especially in English. It is fine-tuned on XNLI by using BERT Base Case model.\n","\n","BertForZeroShotClassification using a ModelForSequenceClassification trained on NLI (natural language inference) tasks. Equivalent of BertForSequenceClassification models, but these models don't require a hardcoded number of potential classes, they can be chosen at runtime. It usually means it's slower but it is much more flexible.\n","\n","We used `TFBertForSequenceClassification` to train this model and used `BertForZeroShotClassification` annotator in Spark NLP for prediction at scale!"]},{"cell_type":"markdown","source":["### Zero-Shot Pipeline\n","\n","\n","Let's see how easy it is to just use any set of lables our trained model has never seen via `setCandidateLabels()` param:"],"metadata":{"id":"z0Fmc9r-0Pq_"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":59528,"status":"ok","timestamp":1696398117028,"user":{"displayName":"Vildan SarÄ±kaya","userId":"07789644790967768983"},"user_tz":240},"id":"NAztF-lb2eh8","outputId":"e242b262-deb1-4569-c284-7de36c3ee5b1"},"outputs":[{"output_type":"stream","name":"stdout","text":["bert_base_cased_zero_shot_classifier_xnli download started this may take some time.\n","Approximate size to download 387.7 MB\n","[OK!]\n"]}],"source":["document_assembler = DocumentAssembler() \\\n","    .setInputCol(\"text\") \\\n","    .setOutputCol(\"document\")\n","\n","tokenizer = Tokenizer()\\\n","    .setInputCols(\"document\")\\\n","    .setOutputCol(\"token\")\n","\n","zero_shot_classifier = BertForZeroShotClassification.pretrained(\"bert_base_cased_zero_shot_classifier_xnli\", \"en\")\\\n","    .setInputCols([\"document\", \"token\"]) \\\n","    .setOutputCol(\"class\") \\\n","    .setCandidateLabels([\"urgent\", \"mobile\", \"travel\", \"movie\", \"music\", \"sport\", \"weather\", \"technology\"])\n","\n","pipeline = Pipeline(stages=[\n","    document_assembler,\n","    tokenizer,\n","    zero_shot_classifier\n","])\n","\n","zero_shot_bert = pipeline.fit(spark.createDataFrame([[\"\"]]).toDF(\"text\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1696398117029,"user":{"displayName":"Vildan SarÄ±kaya","userId":"07789644790967768983"},"user_tz":240},"id":"7xto0Lf83Ilu","outputId":"f2e4bf16-7865-4431-a093-7e1feafa1ad7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{Param(parent='BERT_FOR_ZERO_SHOT_CLASSIFICATION_e4205e7cf10f', name='activation', doc='Whether to calculate logits via Softmax or Sigmoid. Default is Softmax'): 'softmax',\n"," Param(parent='BERT_FOR_ZERO_SHOT_CLASSIFICATION_e4205e7cf10f', name='batchSize', doc='Size of every batch'): 8,\n"," Param(parent='BERT_FOR_ZERO_SHOT_CLASSIFICATION_e4205e7cf10f', name='coalesceSentences', doc=\"Instead of 1 class per sentence (if inputCols is '''sentence''') output 1 class per document by averaging probabilities in all sentences.\"): False,\n"," Param(parent='BERT_FOR_ZERO_SHOT_CLASSIFICATION_e4205e7cf10f', name='lazyAnnotator', doc='Whether this AnnotatorModel acts as lazy in RecursivePipelines'): False,\n"," Param(parent='BERT_FOR_ZERO_SHOT_CLASSIFICATION_e4205e7cf10f', name='multilabel', doc='Whether to calculate logits via Multiclass(softmax) or Multilabel(sigmoid). Default is False i.e. Multiclass'): False,\n"," Param(parent='BERT_FOR_ZERO_SHOT_CLASSIFICATION_e4205e7cf10f', name='threshold', doc='Choose the threshold to determine which logits are considered to be positive or negative'): 0.5,\n"," Param(parent='BERT_FOR_ZERO_SHOT_CLASSIFICATION_e4205e7cf10f', name='maxSentenceLength', doc='Max sentence length to process'): 512,\n"," Param(parent='BERT_FOR_ZERO_SHOT_CLASSIFICATION_e4205e7cf10f', name='caseSensitive', doc='whether to ignore case in tokens for embeddings matching'): True,\n"," Param(parent='BERT_FOR_ZERO_SHOT_CLASSIFICATION_e4205e7cf10f', name='candidateLabels', doc='Deep Learning engine used for this model'): ['urgent',\n","  'mobile',\n","  'travel',\n","  'movie',\n","  'music',\n","  'sport',\n","  'weather',\n","  'technology'],\n"," Param(parent='BERT_FOR_ZERO_SHOT_CLASSIFICATION_e4205e7cf10f', name='contradictionIdParam', doc='contradictionIdParam'): 2,\n"," Param(parent='BERT_FOR_ZERO_SHOT_CLASSIFICATION_e4205e7cf10f', name='engine', doc='Deep Learning engine used for this model'): 'tensorflow',\n"," Param(parent='BERT_FOR_ZERO_SHOT_CLASSIFICATION_e4205e7cf10f', name='entailmentIdParam', doc='contradictionIdParam'): 0,\n"," Param(parent='BERT_FOR_ZERO_SHOT_CLASSIFICATION_e4205e7cf10f', name='inputCols', doc='previous annotations columns, if renamed'): ['document',\n","  'token'],\n"," Param(parent='BERT_FOR_ZERO_SHOT_CLASSIFICATION_e4205e7cf10f', name='outputCol', doc='output annotation column. can be left default.'): 'class'}"]},"metadata":{},"execution_count":4}],"source":["zero_shot_classifier.extractParamMap()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wvlVe9yQ3N14"},"outputs":[],"source":["text = [[\"I have a problem with my iphone that needs to be resolved asap!!\"],\n","        [\"Last week I upgraded my iOS version and ever since then my phone has been overheating whenever I use your app.\"],\n","        [\"I have a phone and I love it!\"],\n","        [\"I really want to visit Germany and I am planning to go there next year.\"],\n","        [\"Let's watch some movies tonight! I am in the mood for a horror movie.\"],\n","        [\"Have you watched the match yesterday? It was a great game!\"],\n","        [\"We need to harry up and get to the airport. We are going to miss our flight!\"]]\n","\n","# create a DataFrame in PySpark\n","inputDataset = spark.createDataFrame(text, [\"text\"])\n","predictionDF = zero_shot_bert.transform(inputDataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12935,"status":"ok","timestamp":1696398130571,"user":{"displayName":"Vildan SarÄ±kaya","userId":"07789644790967768983"},"user_tz":240},"id":"C_P--bdK3uHu","outputId":"25bd8b57-27c3-42be-adec-216717e0d375"},"outputs":[{"output_type":"stream","name":"stdout","text":["+----------------------------------------------------------------------------------------------------------------+--------+\n","|result                                                                                                          |result  |\n","+----------------------------------------------------------------------------------------------------------------+--------+\n","|[I have a problem with my iphone that needs to be resolved asap!!]                                              |[mobile]|\n","|[Last week I upgraded my iOS version and ever since then my phone has been overheating whenever I use your app.]|[mobile]|\n","|[I have a phone and I love it!]                                                                                 |[mobile]|\n","|[I really want to visit Germany and I am planning to go there next year.]                                       |[travel]|\n","|[Let's watch some movies tonight! I am in the mood for a horror movie.]                                         |[movie] |\n","|[Have you watched the match yesterday? It was a great game!]                                                    |[sport] |\n","|[We need to harry up and get to the airport. We are going to miss our flight!]                                  |[urgent]|\n","+----------------------------------------------------------------------------------------------------------------+--------+\n","\n"]}],"source":["predictionDF.select(\"document.result\", \"class.result\").show(10, False)"]},{"cell_type":"markdown","source":["### Using Light Pipeline"],"metadata":{"id":"nTqvyQLI0WCj"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":660,"status":"ok","timestamp":1696398131216,"user":{"displayName":"Vildan SarÄ±kaya","userId":"07789644790967768983"},"user_tz":240},"id":"MU0ViO0I3159","outputId":"46f8f267-1c36-45de-cd6e-96b3b09df330"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'document': ['Last week I upgraded my iOS version and ever since then my phone has been overheating whenever I use your app.'],\n"," 'token': ['Last',\n","  'week',\n","  'I',\n","  'upgraded',\n","  'my',\n","  'iOS',\n","  'version',\n","  'and',\n","  'ever',\n","  'since',\n","  'then',\n","  'my',\n","  'phone',\n","  'has',\n","  'been',\n","  'overheating',\n","  'whenever',\n","  'I',\n","  'use',\n","  'your',\n","  'app',\n","  '.'],\n"," 'class': ['mobile']}"]},"metadata":{},"execution_count":7}],"source":["sample_text = \"Last week I upgraded my iOS version and ever since then my phone has been overheating whenever I use your app.\"\n","\n","light_pipeline = LightPipeline(zero_shot_bert)\n","\n","results = light_pipeline.annotate(sample_text)\n","\n","results"]},{"cell_type":"code","source":["results[\"class\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tDAQK5v5nS63","executionInfo":{"status":"ok","timestamp":1696398131217,"user_tz":240,"elapsed":8,"user":{"displayName":"Vildan SarÄ±kaya","userId":"07789644790967768983"}},"outputId":"9b9d10ec-5775-4b3c-b93b-5385e72168b3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['mobile']"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"RfQrLMxATYyY"},"source":["### Multi Label vs. Multi Class\n","\n","We can use `activation` parameter to set whether or not the result should be multi-class (the sum of all probabilities is `1.0`) or multi-label (each label has a probability between `0.0` to `1.0`)\n","\n","- multi-class: `softmax` (default)\n","- multi-label: `sigmoid`"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JnVfw4T9PWyb","outputId":"f1ac33da-e186-4ff3-8d3c-ec8b4f597c57","executionInfo":{"status":"ok","timestamp":1696398133345,"user_tz":240,"elapsed":2132,"user":{"displayName":"Vildan SarÄ±kaya","userId":"07789644790967768983"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["+---------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------+\n","|result                                                                                                                                             |result                                |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------+\n","|[Learn about the presidential election process, including the Electoral College, caucuses and primaries, and the national conventions.]            |[politics]                            |\n","|[In a new book, Sean Carroll brings together physics and philosophy while advocating for \"poetic naturalism.\" Ramin Skibba, Contributor. Space ...]|[space & cosmos, scientific discovery]|\n","|[Who are you voting for in 2024?]                                                                                                                  |[politics]                            |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------+\n","\n"]}],"source":["zero_shot_classifier\\\n","    .setCandidateLabels([\"space & cosmos\", \"scientific discovery\", \"microbiology\", \"robots\", \"archeology\", \"politics\"])\\\n","    .setActivation(\"sigmoid\") # multi-label\n","\n","pipeline = Pipeline(stages=[\n","    document_assembler,\n","    tokenizer,\n","    zero_shot_classifier\n","])\n","\n","input_text3 = [\n","    [\"\"\"Learn about the presidential election process, including the Electoral College, caucuses and primaries, and the national conventions.\"\"\"],\n","    [\"\"\"In a new book, Sean Carroll brings together physics and philosophy while advocating for \"poetic naturalism.\" Ramin Skibba, Contributor. Space ...\"\"\"],\n","    [\"\"\"Who are you voting for in 2024?\"\"\"]]\n","\n","# create a DataFrame in PySpark\n","inputDataset = spark.createDataFrame(input_text3, [\"text\"])\n","model = pipeline.fit(inputDataset)\n","predictionDF = model.transform(inputDataset)\n","\n","predictionDF.select(\"document.result\", \"class.result\").show(3, False)"]},{"cell_type":"markdown","source":["Let's see our other zero-shot classification models"],"metadata":{"id":"J8YliYBzxZX4"}},{"cell_type":"markdown","metadata":{"id":"Rky40cUX4fjj"},"source":["## RoBerta Zero-Shot Classification\n","\n","This model is intended to be used for zero-shot text classification, especially in English. It is fine-tuned on NLI by using Roberta Base model.\n","\n","`RoBertaForZeroShotClassificationusing` a `ModelForSequenceClassification` trained on NLI (natural language inference) tasks. Equivalent of `RoBertaForZeroShotClassification` models, but these models don't require a hardcoded number of potential classes, they can be chosen at runtime. It usually means it's slower but it is much more flexible.\n","\n","We used `TFRobertaForSequenceClassification` to train this model and used `RoBertaForZeroShotClassification` annotator in Spark NLP for prediction at scale!"]},{"cell_type":"code","source":["zero_shot_classifier = RoBertaForZeroShotClassification.pretrained(\"roberta_base_zero_shot_classifier_nli\", \"en\")\\\n","  .setInputCols([\"document\",'token'])\\\n","  .setOutputCol(\"class\")\\\n","  .setCaseSensitive(True)\\\n","  .setMaxSentenceLength(512)\\\n","  .setCandidateLabels([\"movie\",\"mobile\", \"music\", \"travel\", \"sport\", \"computer\"])\n","\n","pipeline = Pipeline(stages=[\n","    document_assembler,\n","    tokenizer,\n","    zero_shot_classifier\n","])\n","\n","zero_shot_roberta = pipeline.fit(spark.createDataFrame([[\"\"]]).toDF(\"text\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fF9euj8EGjth","executionInfo":{"status":"ok","timestamp":1696398185343,"user_tz":240,"elapsed":52003,"user":{"displayName":"Vildan SarÄ±kaya","userId":"07789644790967768983"}},"outputId":"3342f2b5-f5a0-4c4d-8110-a6f26e34a2c1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["roberta_base_zero_shot_classifier_nli download started this may take some time.\n","Approximate size to download 444.8 MB\n","[OK!]\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ldt1VbzJ4f43"},"outputs":[],"source":["text = [[\"I have a problem with my iphone that needs to be resolved asap!!\"],\n","        [\"We need to harry up and get to the airport. We are going to miss our flight!\"]]\n","\n","# create a DataFrame in PySpark\n","inputDataset = spark.createDataFrame(text, [\"text\"])\n","predictionDF = zero_shot_roberta.transform(inputDataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4803,"status":"ok","timestamp":1696398190430,"user":{"displayName":"Vildan SarÄ±kaya","userId":"07789644790967768983"},"user_tz":240},"id":"s2vffQEf4hLc","outputId":"68b883ff-80e2-41a2-d26f-c6dc3850e131"},"outputs":[{"output_type":"stream","name":"stdout","text":["+------------------------------------------------------------------------------+--------+\n","|result                                                                        |result  |\n","+------------------------------------------------------------------------------+--------+\n","|[I have a problem with my iphone that needs to be resolved asap!!]            |[mobile]|\n","|[We need to harry up and get to the airport. We are going to miss our flight!]|[travel]|\n","+------------------------------------------------------------------------------+--------+\n","\n"]}],"source":["predictionDF.select(\"document.result\", \"class.result\").show(10, False)"]},{"cell_type":"markdown","source":["## DistilBert Zero-Shot Classification\n","\n","This model is intended to be used for zero-shot text classification, especially in English. It is fine-tuned on MNLI by using DistilBERT Base Uncased model.\n","\n","`DistilBertForZeroShotClassification` using a `ModelForSequenceClassification` trained on NLI (natural language inference) tasks. Equivalent of `DistilBertForSequenceClassification` models, but these models don't require a hardcoded number of potential classes, they can be chosen at runtime. It usually means it's slower but it is much more flexible.\n","\n","We used `TFDistilBertForSequenceClassification` to train this model and used `DistilBertForZeroShotClassification` annotator in Spark NLP for prediction at scale!"],"metadata":{"id":"yNykk3t9ZTOp"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29380,"status":"ok","timestamp":1696398219805,"user":{"displayName":"Vildan SarÄ±kaya","userId":"07789644790967768983"},"user_tz":240},"id":"9NqwHYxJ4kiQ","outputId":"d53c0828-876f-4f2c-9353-b42fa0e33c01"},"outputs":[{"output_type":"stream","name":"stdout","text":["distilbert_base_zero_shot_classifier_uncased_mnli download started this may take some time.\n","Approximate size to download 238.1 MB\n","[OK!]\n"]}],"source":["zero_shot_classifier = DistilBertForZeroShotClassification.pretrained(\"distilbert_base_zero_shot_classifier_uncased_mnli\", \"en\")\\\n","    .setInputCols([\"document\", \"token\"]) \\\n","    .setOutputCol(\"class\") \\\n","    .setCandidateLabels([\"urgent\", \"mobile\", \"travel\", \"movie\", \"music\", \"sport\", \"technology\"])\n","\n","pipeline = Pipeline(stages=[\n","    document_assembler,\n","    tokenizer,\n","    zero_shot_classifier\n","])\n","\n","zero_shot_distilbert = pipeline.fit(spark.createDataFrame([[\"\"]]).toDF(\"text\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5594,"status":"ok","timestamp":1696398225394,"user":{"displayName":"Vildan SarÄ±kaya","userId":"07789644790967768983"},"user_tz":240},"id":"0WqeUFwf4vix","outputId":"0e81dc61-dfa6-43d7-dff6-e8358ed9695b"},"outputs":[{"output_type":"stream","name":"stdout","text":["+------------+\n","|      result|\n","+------------+\n","|    [mobile]|\n","|[technology]|\n","|    [mobile]|\n","|    [travel]|\n","|     [sport]|\n","|    [urgent]|\n","+------------+\n","\n"]}],"source":["text = [[\"I have a problem with my iphone that needs to be resolved asap!!\"],\n","        [\"Last week I upgraded my iOS version and ever since then my phone has been overheating whenever I use your app.\"],\n","        [\"I have a phone and I love it!\"],\n","        [\"I really want to visit Germany and I am planning to go there next year.\"],\n","        [\"Have you watched the match yesterday? It was a great game!\"],\n","        [\"We need to harry up and get to the airport. We are going to miss our flight!\"]]\n","\n","# create a DataFrame in PySpark\n","inputDataset = spark.createDataFrame(text, [\"text\"])\n","\n","zero_shot_distilbert.transform(inputDataset).select(\"class.result\").show()"]},{"cell_type":"markdown","source":["## Bart Zero-Shot Classification"],"metadata":{"id":"0PqZLVO_Nmnm"}},{"cell_type":"markdown","source":["This model is intended to be used for zero-shot text classification, especially in English. It is fine-tuned on MNLI by using large BART model.\n","\n","BartForZeroShotClassification using a ModelForSequenceClassification trained on MNLI tasks. Equivalent of BartForSequenceClassification models, but these models donâ€™t require a hardcoded number of potential classes, they can be chosen at runtime. It usually means itâ€™s slower but it is much more flexible.\n","\n","We used TFBartForSequenceClassification to train this model and used BartForZeroShotClassification annotator in Spark NLP ðŸš€ for prediction at scale!"],"metadata":{"id":"JsF8TfaHOh_f"}},{"cell_type":"code","source":["document_assembler = DocumentAssembler() \\\n",".setInputCol('text') \\\n",".setOutputCol('document')\n","\n","tokenizer = Tokenizer() \\\n",".setInputCols(['document']) \\\n",".setOutputCol('token')\n","\n","zeroShotClassifier = BartForZeroShotClassification \\\n",".pretrained('bart_large_zero_shot_classifier_mnli', 'en') \\\n",".setInputCols(['token', 'document']) \\\n",".setOutputCol('class') \\\n",".setCaseSensitive(True) \\\n",".setMaxSentenceLength(512) \\\n",".setCandidateLabels([\"urgent\", \"mobile\", \"travel\", \"movie\", \"music\", \"sport\", \"weather\", \"technology\"])\n","\n","pipeline = Pipeline(stages=[\n","document_assembler,\n","tokenizer,\n","zeroShotClassifier\n","])\n","\n","zero_shot_bart = pipeline.fit(spark.createDataFrame([[\"\"]]).toDF(\"text\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FDzI5G6ZN0-w","executionInfo":{"status":"ok","timestamp":1696398274581,"user_tz":240,"elapsed":49203,"user":{"displayName":"Vildan SarÄ±kaya","userId":"07789644790967768983"}},"outputId":"43c1989c-ade1-4c07-ce06-4e699ca25b5f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["bart_large_zero_shot_classifier_mnli download started this may take some time.\n","Approximate size to download 445.4 MB\n","[OK!]\n"]}]},{"cell_type":"code","source":["text = [[\"Last summer, I embarked on an unforgettable journey to explore the ancient ruins of Machu Picchu, surrounded by breathtaking landscapes and rich cultural history.\"]]\n","\n","# create a DataFrame in PySpark\n","inputDataset = spark.createDataFrame(text, [\"text\"])\n","predictionDF = zero_shot_bart.transform(inputDataset)"],"metadata":{"id":"7uSHTIATOA8q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predictionDF.select(\"document.result\", \"class.result\").show(10, False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XRSLm_nsOFUj","executionInfo":{"status":"ok","timestamp":1696398279817,"user_tz":240,"elapsed":4986,"user":{"displayName":"Vildan SarÄ±kaya","userId":"07789644790967768983"}},"outputId":"f0969d3f-4bef-4c4e-c2c6-208feaff1981"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+\n","|result                                                                                                                                                              |result  |\n","+--------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+\n","|[Last summer, I embarked on an unforgettable journey to explore the ancient ruins of Machu Picchu, surrounded by breathtaking landscapes and rich cultural history.]|[travel]|\n","+--------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------+\n","\n"]}]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[{"file_id":"https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/open-source-nlp/04.4.ZeroShot_NER.ipynb","timestamp":1688503818196}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.1"}},"nbformat":4,"nbformat_minor":0}