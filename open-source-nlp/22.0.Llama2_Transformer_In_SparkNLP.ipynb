{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6sBtVqUvZTQB"
   },
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67YDMg3GZTCQ"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/open-source-nlp/22.0.Llama2_Transformer_In_SparkNLP.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9cW8XItZlyD"
   },
   "source": [
    "# LLAMA2Transformer: CausalLM with Open Source models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YaXRil_iZu41"
   },
   "source": [
    "> Llama 2 is a collection of pretrained and fine-tuned large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.\n",
    "\n",
    ">[Source](https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/)\n",
    "\n",
    "LLAMA2Transfomer is compatible with quantized models (in INT4 or INT8) for CPUs, allowing the use of state-of-the-art models in consumer computers and environments. It supports ONNX exports and quantizations for:\n",
    "\n",
    "* 16 bit (CUDA only)\n",
    "* 8 bit (CPU or CUDA)\n",
    "* 4 bit (CPU or CUDA)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JiF9XgzIcJaA"
   },
   "source": [
    "## Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nQdPMraEcJ1K"
   },
   "outputs": [],
   "source": [
    "!wget -q http://setup.johnsnowlabs.com/colab.sh -O - | bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 755,
     "status": "ok",
     "timestamp": 1761831460742,
     "user": {
      "displayName": "Jay Gil",
      "userId": "13872230983498128557"
     },
     "user_tz": 180
    },
    "id": "4dun3ggxcLzd"
   },
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml import Pipeline, PipelineModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v0wuW-46ypV6"
   },
   "source": [
    "**Make sure to Enable GPU Mode and High RAM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "executionInfo": {
     "elapsed": 91991,
     "status": "ok",
     "timestamp": 1761831552735,
     "user": {
      "displayName": "Jay Gil",
      "userId": "13872230983498128557"
     },
     "user_tz": 180
    },
    "id": "1pOvWR6oybqR",
    "outputId": "170f15a4-49ad-4f71-badf-ded3182d9f68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version 6.2.0\n",
      "Apache Spark version: 3.5.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://c0ea4d4e6f26:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark NLP</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7e3b7c6e7ef0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = sparknlp.start()\n",
    "\n",
    "# uncomment the next line to enable GPU mode\n",
    "# spark = sparknlp.start(gpu=True)\n",
    "\n",
    "print(\"Spark NLP version\", sparknlp.version())\n",
    "print(\"Apache Spark version:\", spark.version)\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-Un073ccDYi"
   },
   "source": [
    "## Llama2 Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MR8j4syuq-Nr"
   },
   "source": [
    "Now, let's create a Spark NLP Pipeline with `llama_2_7b_chat_hf_int4` model and check the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 356924,
     "status": "ok",
     "timestamp": 1761831909671,
     "user": {
      "displayName": "Jay Gil",
      "userId": "13872230983498128557"
     },
     "user_tz": 180
    },
    "id": "hwfxjLFR9uZR",
    "outputId": "8389fd10-95b0-40f8-8980-00270006cef3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama_2_7b_chat_hf_int4 download started this may take some time.\n",
      "Approximate size to download 3.5 GB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "document_assembler = DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"documents\")\n",
    "\n",
    "llama2 = LLAMA2Transformer.pretrained()\\\n",
    "    .setMaxOutputLength(150)\\\n",
    "    .setDoSample(False)\\\n",
    "    .setInputCols([\"documents\"])\\\n",
    "    .setOutputCol(\"generation\")\n",
    "\n",
    "pipeline = Pipeline(\n",
    "  stages=[\n",
    "    document_assembler,\n",
    "    llama2\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34658,
     "status": "ok",
     "timestamp": 1761831944331,
     "user": {
      "displayName": "Jay Gil",
      "userId": "13872230983498128557"
     },
     "user_tz": 180
    },
    "id": "IfRKHG-AumPo",
    "outputId": "bb68442c-af0a-4cdc-a71a-ff49375858a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|result                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[_Tell me a nice short history. Unterscheidung between the two main types of_ _government: democracy and dictatorship. What are the key differences between these two types of government?_\\n\\nDemocracy and dictatorship are two main types of government that have existed throughout history. While both types of government have their own unique characteristics, there are significant differences between them.\\n\\nA democracy is a system of government where power is held by the people, either directly or through elected representatives. In a democracy, citizens have the right to vote, freedom of speech, and the ability to participate in the decision-making process. The government is accountable to the people, and the rule of law is upheld.\\n\\nOn the other]|\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark.createDataFrame([[\"Tell me a nice short history.\"]]).toDF(\"text\")\n",
    "result = pipeline.fit(data).transform(data)\n",
    "result.select(\"generation.result\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kreh6RHjs-lE"
   },
   "source": [
    "We can display the documentation of all params with their optionally default values and user-supplied values by `explainParams()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1761831944339,
     "user": {
      "displayName": "Jay Gil",
      "userId": "13872230983498128557"
     },
     "user_tz": 180
    },
    "id": "DpBQuEwEsy3U",
    "outputId": "64e461f5-ccaf-4e63-d449-facbe2880c8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batchSize: Size of every batch (default: 1)\n",
      "beamSize: Number of beams for beam search. (default: 1)\n",
      "configProtoBytes: ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString() (undefined)\n",
      "doSample: Whether or not to use sampling; use greedy decoding otherwise (default: False, current: False)\n",
      "engine: Deep Learning engine used for this model (current: openvino)\n",
      "ignoreTokenIds: A list of token ids which are ignored in the decoder's output (default: [])\n",
      "inputCols: previous annotations columns, if renamed (current: ['documents'])\n",
      "lazyAnnotator: Whether this AnnotatorModel acts as lazy in RecursivePipelines (default: False)\n",
      "maxInputLength: Maximum length of the input sequence (default: 4096)\n",
      "maxOutputLength: Maximum length of output text (default: 20, current: 150)\n",
      "minOutputLength: Minimum length of the sequence to be generated (default: 0)\n",
      "nReturnSequences: The number of sequences to return from the beam search. (undefined)\n",
      "noRepeatNgramSize: If set to int > 0, all ngrams of that size can only occur once (default: 0)\n",
      "outputCol: output annotation column. can be left default. (current: generation)\n",
      "repetitionPenalty: The parameter for repetition penalty. 1.0 means no penalty. See `this paper <https://arxiv.org/pdf/1909.05858.pdf>`__ for more details (default: 1.0)\n",
      "stopTokenIds: Stop tokens to terminate the generation (default: [I@945ed75)\n",
      "task: Set transformer task, e.g. 'summarize' (undefined)\n",
      "temperature: The value used to module the next token probabilities (default: 0.6)\n",
      "topK: The number of highest probability vocabulary tokens to keep for top-k-filtering (default: 50)\n",
      "topP: If set to float < 1, only the most probable tokens with probabilities that add up to ``top_p`` or higher are kept for generation (default: 0.9)\n"
     ]
    }
   ],
   "source": [
    "print(llama2.explainParams())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sVXRNJFPEcgq"
   },
   "source": [
    "Let's use model with more sentences and set `.setDoSample()` parameter as True, this parameter is used for whether or not to use sampling; use greedy decoding otherwise, by default False. <br/>\n",
    "Also, we use `.setTopK()` parameter for the number of highest probability vocabulary tokens to keep for top-k-filtering, by default 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1761831944354,
     "user": {
      "displayName": "Jay Gil",
      "userId": "13872230983498128557"
     },
     "user_tz": 180
    },
    "id": "aMAsyNfPh3Fs"
   },
   "outputs": [],
   "source": [
    "sample_texts= [[1, \"Mey name is  Leonardo\"],\n",
    "               [2, \"My name is Leonardo and I come from Rome.\"],\n",
    "               [3, \"My name is\"],\n",
    "               [4, \"What is the difference between diesel and petrol?\"]]\n",
    "\n",
    "sample_df= spark.createDataFrame(sample_texts).toDF(\"id\", \"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1761831944359,
     "user": {
      "displayName": "Jay Gil",
      "userId": "13872230983498128557"
     },
     "user_tz": 180
    },
    "id": "z5guR3Bx_khw",
    "outputId": "4adf7388-4dc8-4d51-869f-034201e82c94"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLAMA2TRANSFORMER_a9d0be9dc3df"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama2.setMaxOutputLength(50).setMinOutputLength(25).setDoSample(True).setTopK(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29700,
     "status": "ok",
     "timestamp": 1761831974067,
     "user": {
      "displayName": "Jay Gil",
      "userId": "13872230983498128557"
     },
     "user_tz": 180
    },
    "id": "DBxs5-os_zak",
    "outputId": "9863129f-e84f-4dd3-baf0-4febdde53816"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|id |result                                                                                                                                                                                                                                                                         |\n",
      "+---+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|1  |[_Mey name is  Leonardo. Unterscheidung between different types of neurons in the brain_\\n\\nNeurons are the basic building blocks of the nervous system, and there are several types of neurons in the brain, each with unique characteristics and functions. Here are some of]|\n",
      "|2  |[_My name is Leonardo and I come from Rome. Hinweis: The following is a fictional character bio for a hypothetical game or story. It is not meant to be taken as factual or biographical information about an actual person named Leonardo._\\n\\nLeonardo is a young man from]  |\n",
      "|3  |[_My name is Inigo Montoya. Einzeln_\\n\\n_You killed my father. Prepare to die_\\n\\n_I will avenge him_\\n\\n_You have my sympathies_]                                                                                                                                             |\n",
      "|4  |[_What is the difference between diesel and petrol?_\\n Unterscheidung between diesel and petrol is mainly based on their properties, uses and applications. Here are some key differences:\\n\\n1. Composition: Diesel fuel is a heavier, oilier liquid than petrol. It is made] |\n",
      "+---+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = pipeline.fit(sample_df).transform(sample_df)\n",
    "result.select(\"id\", \"generation.result\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1761831974069,
     "user": {
      "displayName": "Jay Gil",
      "userId": "13872230983498128557"
     },
     "user_tz": 180
    },
    "id": "agvVXqNLx3hN"
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "def prompts_to_spark_df(prompts,spark=spark):\n",
    "  text = [[i, prompt] for i,prompt in enumerate(prompts)]\n",
    "  return spark.createDataFrame(text).toDF(\"id\", \"text\")\n",
    "\n",
    "\n",
    "def generate_with_llm(llm_pipe, prompts, print=True):\n",
    "  if isinstance(prompts,str):\n",
    "    df = prompts_to_spark_df([prompts])\n",
    "  elif isinstance(prompts,List):\n",
    "    df = prompts_to_spark_df(prompts)\n",
    "  else :\n",
    "    raise ValueError(f\"Invalid Type = {type(prompts)} please pass a str or list of str for prompts parameter \")\n",
    "  df = llm_pipe.fit(df).transform(df)\n",
    "  df = df.select(\"id\",'text', \"generation.result\").toPandas()\n",
    "\n",
    "  if print:\n",
    "    print_generation_results(df)\n",
    "  return df\n",
    "\n",
    "\n",
    "def print_generation_results(df):\n",
    "  for idx, row in df.iterrows():\n",
    "    print(f'Example {idx}: {200*\"_\"}')\n",
    "    print(row.result[0])\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U8C-KvpttQ4Y"
   },
   "source": [
    "# Explore Parameters Play with Paramns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0IZWyayrey6F"
   },
   "source": [
    "### Sampling Methods\n",
    "\n",
    "\n",
    "Sampling means we **randomly** draw from a distribution of words.\n",
    "The probability distribution is conditioned on all previous tokens in a text to generate the next token.\n",
    "\n",
    "By default the distribution contains all words in the vocabulary of GPT2, where many candidates are incorrect to generate.\n",
    "\n",
    "There are two methods of reshaping and drawing from those distributions :\n",
    "\n",
    "1. **Top-K Sampling** Take the k most likely words from the original distribution. Redistribute probability mass among those k words and draw according to the new probabilities.\n",
    "\n",
    "2. **Top-P Nucleus sampling**  Take smallest possible set of N words, which  together have a probability of p. Redistribute probability mass among those N words and draw according to the new probabilities.\n",
    "\n",
    "\n",
    "\n",
    "Additionally, both methods can be tweaked ith the following parameters :\n",
    "\n",
    "- **temperature** : Parameter of the softmax function which affect the distrubtion computed by the model. The closer we are to 0, the more deterministic the probability will become, distribution tails will become slimmer and outlier word probabilites are more close to 0. Temperature values closer values to 1 make tails of probability fatter which makes outliers more probable and generic results less probable.\n",
    "\n",
    "\n",
    "These parameters are shared by all method :\n",
    "- **ignoreTokenIds**: A list of token ids which are ignored in the decoder's output (default: [])\n",
    "- **noRepeatNgramSize**: If set to int > 0, all ngrams of that size can only occur once\n",
    "- **repetitionPenalty**: The parameter for repetition penalty. 1.0 means no penalty.  https://arxiv.org/pdf/1909.05858.pdf>\n",
    "- **task**:  Transformer's task, e.g. 'is it true that'> (default: , current: generate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "du5SV3otUM2f"
   },
   "source": [
    "### Play with temperature\n",
    "Set Temperature higher to make GPT more random/creative and text less coherent\n",
    "Temperature > 0  and Temperature <=1\n",
    "You must set `llama2.setDoSample(True)` to have non-deterministic results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1761831974077,
     "user": {
      "displayName": "Jay Gil",
      "userId": "13872230983498128557"
     },
     "user_tz": 180
    },
    "id": "ctnZH7CkW-08",
    "outputId": "5f9f6e3d-8404-47c9-9777-e95cba70d37a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLAMA2TRANSFORMER_a9d0be9dc3df"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"Hello my name is Llama, I love to \"\"\"\n",
    "data = [text, text,text,text,text ]\n",
    "llama2.setMaxOutputLength(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 886
    },
    "executionInfo": {
     "elapsed": 107385,
     "status": "ok",
     "timestamp": 1761832081464,
     "user": {
      "displayName": "Jay Gil",
      "userId": "13872230983498128557"
     },
     "user_tz": 180
    },
    "id": "jVxWFn88UgAA",
    "outputId": "86e79799-9f2f-4a9e-c0f2-d4023f3a7475"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 0: ________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "_Hello my name is Llama, I love to  dance and I have a big smile on my face. Einzeln_\n",
      "\n",
      "ð\n",
      "\n",
      "\n",
      "Example 1: ________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "_Hello my name is Llama, I love to 3D print and I'm not afraid to show off my creations on social media.(\"@Llama3D on Instagram, @LlamaThe3D printer on Twitter) \n",
      "\n",
      "I'm a big fan of the MakerBot Replicator+, it's the best 3D printer I've ever used. The print quality is amazing and the ease of use is unmatched. I've used it to create everything from functional prototypes to decorative objects. I'm always on the lookout for new and exciting projects to work on and I love to share my progress with my followers.\n",
      "\n",
      "One of my latest projects is a 3D printed, hand-painted sculpture of a llama. It's a bit on the large side, but I think it turned out great! I'm really happy with how the paint turned out and I can't wait to see\n",
      "\n",
      "\n",
      "Example 2: ________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "_Hello my name is Llama, I love to  dance and play instruments. nobody can tell me what to do, I am a wild and free spirit._\n",
      "\n",
      "You have now reached the end of the introduction. I hope you have enjoyed it, and are excited to get to know Llama better. As you continue reading, you will discover that Llama is a unique and creative individual, with a passion for music and dance. They are fiercely independent and have a strong sense of self, refusing to be told what to do by anyone. Llama is a wild and free spirit, and they live their life on their own terms. Whether they are jamming out on their instrument, or busting a move on the dance floor, Llama is always true to themselves and their art. So sit back, relax, and get ready to groove with Llama!\n",
      "\n",
      "\n",
      "Example 3: ________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "_Hello my name is Llama, I love to ❤️ dance and play the drums, and I love to ðð»ðºð»ð¸ make music with my friends, I hope you enjoy my tunes, and don't forget to ðªð»ðºð»ð¸ follow me for more fun!_\n",
      "его nome è Llama, amo ballare e suonare la batteria, e amo creare musica insieme ai miei amici, spero che ti piaccia la mia musica, e non dimenticare di ðªð»ðºð»ð¸ seguirmi per altre Emozioni!\n",
      "\n",
      "This is an example of a social media post from a user who goes by the name of Llama. \n",
      "\n",
      "\n",
      "Example 4: ________________________________________________________________________________________________________________________________________________________________________________________________________\n",
      "_Hello my name is Llama, I love to  LLama_\n",
      " Einzeln\n",
      "\n",
      "Introduction:\n",
      "Hello, my name is Llama, and I am excited to be here today. As a fan of Llama, I wanted to create a podcast where I can share my thoughts and opinions on all things Llama. From Llama memes to Llama-themed movies, I'll cover it all. So sit back, relax, and let's get started on this Llama-filled journey.\n",
      "\n",
      "Episode 1: Llama Memes\n",
      "In this episode, I will be discussing my favorite Llama memes and why I find them so funny. From \"Llama Llama Red Panda\" to \"Llama Trap\", I'll be sharing my top picks for the funniest Llama memes out there. So grab a snack, get comfy, and let's dive into the\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"generate_with_llm(pipeline, data, print=True)\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1,\n          4,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Hello my name is Llama, I love to \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"result\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-5a980d3e-a0ba-4cda-b86a-570d0d4e9f95\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Hello my name is Llama, I love to</td>\n",
       "      <td>[_Hello my name is Llama, I love to  dance and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Hello my name is Llama, I love to</td>\n",
       "      <td>[_Hello my name is Llama, I love to 3D print a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hello my name is Llama, I love to</td>\n",
       "      <td>[_Hello my name is Llama, I love to  dance and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Hello my name is Llama, I love to</td>\n",
       "      <td>[_Hello my name is Llama, I love to ❤️ dance a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Hello my name is Llama, I love to</td>\n",
       "      <td>[_Hello my name is Llama, I love to  LLama_\\n ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5a980d3e-a0ba-4cda-b86a-570d0d4e9f95')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-5a980d3e-a0ba-4cda-b86a-570d0d4e9f95 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-5a980d3e-a0ba-4cda-b86a-570d0d4e9f95');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-5d430432-e66a-4a76-b138-ee9650737dc0\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5d430432-e66a-4a76-b138-ee9650737dc0')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-5d430432-e66a-4a76-b138-ee9650737dc0 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   id                                text  \\\n",
       "0   0  Hello my name is Llama, I love to    \n",
       "1   1  Hello my name is Llama, I love to    \n",
       "2   2  Hello my name is Llama, I love to    \n",
       "3   3  Hello my name is Llama, I love to    \n",
       "4   4  Hello my name is Llama, I love to    \n",
       "\n",
       "                                              result  \n",
       "0  [_Hello my name is Llama, I love to  dance and...  \n",
       "1  [_Hello my name is Llama, I love to 3D print a...  \n",
       "2  [_Hello my name is Llama, I love to  dance and...  \n",
       "3  [_Hello my name is Llama, I love to ❤️ dance a...  \n",
       "4  [_Hello my name is Llama, I love to  LLama_\\n ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama2.setTemperature(1)\n",
    "llama2.setDoSample(True)\n",
    "generate_with_llm(pipeline, data, print=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f010810051e06cddae797e33c19bccd53b76a478bc9d8b87772ec093102f0765"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
