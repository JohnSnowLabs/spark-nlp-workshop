{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"ezjSmtiVZn76"},"source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Open_Source/35.07.Chunk2Doc.ipynb)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"RDUqXp-bHOL7"},"source":["# **Chunk2Doc**"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"1l5Z-juMZytA"},"source":["This notebook will cover the different parameters and usages of `Chunk2Doc`. This annotator converts a CHUNK type column back into DOCUMENT. Useful when trying to re-tokenize or do further analysis on a CHUNK result. \n","\n","**📖 Learning Objectives:**\n","\n","1. Understand the usage of the annotator.\n","\n","2. Become comfortable using the different parameters of the annotator.\n","\n","\n","**🔗 Helpful Links:**\n","\n","- Documentation : [Chunk2Doc](https://nlp.johnsnowlabs.com/docs/en/annotators#chunk2doc)\n","\n","- Python Docs : [Chunk2Doc](https://nlp.johnsnowlabs.com/api/python/reference/autosummary/sparknlp/base/chunk2_doc/index.html#sparknlp.base.chunk2_doc.Chunk2Doc)\n","\n","- Scala Docs : [Chunk2Doc](https://nlp.johnsnowlabs.com/api/com/johnsnowlabs/nlp/Chunk2Doc)\n","\n","- For extended examples of usage, see the [Spark NLP Workshop repository](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb)."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"72SLebVgdtiY"},"source":["## **📜 Background**"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"TZkxfvNEHaMq"},"source":["In Spark ML, the machine learning algorithms are grouped in two classes: Estimators and Transformers. An Estimator is an algorithm which can be fit on a DataFrame to produce a Transformer. A Transformer is an algorithm which can transform one DataFrame into another DataFrame.\n","\n","Similarily, in Spark NLP, there are two types of annotators: AnnotatorApproach and AnnotatorModel. \n","The AnnotatorApproach extends the Estimator from Spark ML, and is meant to be trained through fit(). The AnnotatorModel extends the Transformer and is meant to transform data frames through transform().\n","\n","Each annotator accepts certain types of columns and outputs new columns in another type (we call this AnnotatorType).\n","\n","In Spark NLP, we have five different transformers that are mainly used for getting the data in or transforming the data from one AnnotatorType to another. `Chunk2Doc` is one of them, it transforms the `CHUNK` type into `DOCUMENT` type.\n","\n","\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"xvHkquq42_6P"},"source":["## **🎬 Colab Setup**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gydvaTGVHZhK"},"outputs":[],"source":["!pip install -q pyspark==3.2.1 spark-nlp==4.2.4"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R4jPfDMg2Qt4"},"outputs":[],"source":["import sparknlp\n","from sparknlp.base import *\n","from sparknlp.annotator import *\n","from pyspark.ml import Pipeline\n","from sparknlp.pretrained import PretrainedPipeline\n","\n","spark = sparknlp.start()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"gDEf2qEqfhBT"},"source":["## **🖨️ Input/Output Annotation Types**"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ulzuFRzPfopd"},"source":["- Input: `CHUNK`\n","\n","- Output: `DOCUMENT`"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"SZ379WTWgbG2"},"source":["## **🔎 Parameters**\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"oWtHTN-ef5ye"},"source":["- `inputCols`: (Array) Previous annotations columns, if renamed (Default  ['entities']).\n","\n","- `outputCol`: (String) Output annotation column, can be left default (Default 'chunkConverted'). "]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"PGiVraQvgvYv"},"source":["## `Use Chunk2Doc with a Pretrained Pipeline`"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"5eYd6aN37Rxu"},"source":["Relevant entities are extracted with [Explain Document DL Pipeline](https://nlp.johnsnowlabs.com/2021/03/23/explain_document_dl_en.html), a pretrained pipeline in Spark NLP."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9cpGYdTe7ri4"},"outputs":[],"source":["data = spark.createDataFrame([[1, \"New York and New Jersey aren't that far apart actually.\"]]).toDF(\"id\", \"text\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":57521,"status":"ok","timestamp":1673638170423,"user":{"displayName":"Silvia Onofrei","userId":"08518681359279549405"},"user_tz":360},"id":"baVXu7HX7z3B","outputId":"2b25d15f-a569-4057-8af7-c099a452efcd"},"outputs":[{"name":"stdout","output_type":"stream","text":["explain_document_dl download started this may take some time.\n","Approx size to download 169.4 MB\n","[OK!]\n"]}],"source":["pipeline = PretrainedPipeline(\"explain_document_dl\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9859,"status":"ok","timestamp":1673638180267,"user":{"displayName":"Silvia Onofrei","userId":"08518681359279549405"},"user_tz":360},"id":"SAjaD2ar8KQ8","outputId":"739cbf93-db9e-4822-ce1a-723d355e87ba"},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+-------------------------------------------------------+-------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+\n","| id|                                                   text|                                                                                         document|                                                                                         sentence|                                                                                               token|                                                                                             checked|                                                                                               lemma|                                                                                                stem|                                                                                                 pos|                                                                                          embeddings|                                                                                                 ner|                                                                                            entities|\n","+---+-------------------------------------------------------+-------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+\n","|  1|New York and New Jersey aren't that far apart actually.|[{document, 0, 54, New York and New Jersey aren't that far apart actually., {sentence -> 0}, []}]|[{document, 0, 54, New York and New Jersey aren't that far apart actually., {sentence -> 0}, []}]|[{token, 0, 2, New, {sentence -> 0}, []}, {token, 4, 7, York, {sentence -> 0}, []}, {token, 9, 11...|[{token, 0, 2, New, {confidence -> 1.0, sentence -> 0}, []}, {token, 4, 7, York, {confidence -> 1...|[{token, 0, 2, New, {confidence -> 1.0, sentence -> 0}, []}, {token, 4, 7, York, {confidence -> 1...|[{token, 0, 2, new, {confidence -> 1.0, sentence -> 0}, []}, {token, 4, 7, york, {confidence -> 1...|[{pos, 0, 2, NNP, {word -> New, sentence -> 0}, []}, {pos, 4, 7, NNP, {word -> York, sentence -> ...|[{word_embeddings, 0, 2, New, {isOOV -> false, pieceId -> -1, isWordStart -> true, token -> New, ...|[{named_entity, 0, 2, B-LOC, {word -> New, sentence -> 0}, []}, {named_entity, 4, 7, I-LOC, {word...|[{chunk, 0, 7, New York, {entity -> LOC, sentence -> 0, chunk -> 0}, []}, {chunk, 13, 22, New Jer...|\n","+---+-------------------------------------------------------+-------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+\n","\n"]}],"source":["pipelineResult = pipeline.transform(data)\n","pipelineResult.show(2, 100)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"eMhw_TWkhKKh"},"source":[" The relevant chunks of text are converted back into DOCUMENT type with Chunk2Doc for further processing."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yAQFMcWv-aFg"},"outputs":[],"source":["chunkToDoc = Chunk2Doc() \\\n","    .setInputCols(\"entities\") \\\n","    .setOutputCol(\"chunkConverted\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2730,"status":"ok","timestamp":1673638182955,"user":{"displayName":"Silvia Onofrei","userId":"08518681359279549405"},"user_tz":360},"id":"PaStaIkA-gSY","outputId":"163603a6-992f-4f3d-ef30-ee1ad78580c9"},"outputs":[{"name":"stdout","output_type":"stream","text":["+------------------------------------------------------------------------------+\n","|chunkConverted                                                                |\n","+------------------------------------------------------------------------------+\n","|{document, 0, 7, New York, {entity -> LOC, sentence -> 0, chunk -> 0}, []}    |\n","|{document, 13, 22, New Jersey, {entity -> LOC, sentence -> 0, chunk -> 1}, []}|\n","+------------------------------------------------------------------------------+\n","\n"]}],"source":["result = chunkToDoc.transform(pipelineResult)\n","result.selectExpr(\"explode(chunkConverted) as chunkConverted\").show(truncate=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"PIkXcUBbFAyD"},"source":["## Use `Chunk2Doc with a NER Pipeline`"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42777,"status":"ok","timestamp":1673638225711,"user":{"displayName":"Silvia Onofrei","userId":"08518681359279549405"},"user_tz":360},"id":"vIJLp_EE_dLr","outputId":"a8a255c2-5557-4cb4-f284-dec9305a2dd8"},"outputs":[{"name":"stdout","output_type":"stream","text":["glove_100d download started this may take some time.\n","Approximate size to download 145.3 MB\n","[OK!]\n","pos_anc download started this may take some time.\n","Approximate size to download 3.9 MB\n","[OK!]\n","ner_crf download started this may take some time.\n","Approximate size to download 10.2 MB\n","[OK!]\n"]}],"source":["documentAssembler = DocumentAssembler() \\\n","    .setInputCol(\"text\") \\\n","    .setOutputCol(\"document\")\n","\n","sentenceDetector = SentenceDetector() \\\n","    .setInputCols([\"document\"]) \\\n","    .setOutputCol(\"sentence\")\n","\n","tokenizer = Tokenizer() \\\n","    .setInputCols([\"sentence\"]) \\\n","    .setOutputCol(\"token\")\n","\n","wordEmbeddings = WordEmbeddingsModel.pretrained() \\\n","    .setInputCols([\"sentence\", \"token\"]) \\\n","    .setOutputCol(\"word_embeddings\") \\\n","    .setCaseSensitive(False)\n","\n","posTagger = PerceptronModel.pretrained() \\\n","    .setInputCols([\"sentence\", \"token\"]) \\\n","    .setOutputCol(\"pos\")\n","\n","nerModel = NerCrfModel.pretrained() \\\n","    .setInputCols([\"pos\", \"token\", \"document\", \"word_embeddings\"]) \\\n","    .setOutputCol(\"ner\")\n","\n","nerConverter = NerConverter() \\\n","    .setInputCols([\"sentence\", \"token\", \"ner\"]) \\\n","    .setOutputCol(\"entities\") \n","\n","chunkToDoc = Chunk2Doc() \\\n","    .setInputCols(\"entities\") \\\n","    .setOutputCol(\"chunkConverted\")\n","\n","pipeline = Pipeline().setStages([\n","      documentAssembler,\n","      sentenceDetector,\n","      tokenizer,\n","      posTagger,\n","      wordEmbeddings,\n","      nerModel,\n","      nerConverter,\n","      chunkToDoc\n","    ])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"50zpQAhpAJ78"},"outputs":[],"source":["data = spark.createDataFrame([[\"Short sellers, Wall Street's dwindling band of ultra cynics, are seeing green again.\"]]).toDF(\"text\")\n","result = pipeline.fit(data).transform(data)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6850,"status":"ok","timestamp":1673638233382,"user":{"displayName":"Silvia Onofrei","userId":"08518681359279549405"},"user_tz":360},"id":"BHO3rjqKAJ-4","outputId":"521ad7ea-e16a-4ca4-c125-04c344115238"},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------------+-----+---+-------------+------------------------------------------+----------+\n","|annotatorType|begin|end|result       |metadata                                  |embeddings|\n","+-------------+-----+---+-------------+------------------------------------------+----------+\n","|document     |15   |27 |Wall Street's|{entity -> ORG, sentence -> 0, chunk -> 0}|[]        |\n","+-------------+-----+---+-------------+------------------------------------------+----------+\n","\n"]}],"source":["result.selectExpr(\"explode(chunkConverted) as result\") \\\n","    .select(\"result.annotatorType\", \"result.begin\", \"result.end\", \"result.result\", \"result.metadata\", \"result.embeddings\") \\\n","    .show(truncate=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Lh729p8JEeHg"},"source":["## `Use Chunk2Doc with a NER-DL Pipeline`"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32198,"status":"ok","timestamp":1673638265566,"user":{"displayName":"Silvia Onofrei","userId":"08518681359279549405"},"user_tz":360},"id":"hVZhFamA8nKm","outputId":"68443b84-df4b-40bb-9f09-40e43e26f18c"},"outputs":[{"name":"stdout","output_type":"stream","text":["bert_base_cased download started this may take some time.\n","Approximate size to download 389.1 MB\n","[OK!]\n","ner_dl_bert download started this may take some time.\n","Approximate size to download 15.4 MB\n","[OK!]\n"]}],"source":["documentAssembler = DocumentAssembler() \\\n","    .setInputCol(\"text\") \\\n","    .setOutputCol(\"document\")\n","    \n","tokenizer = Tokenizer() \\\n","    .setInputCols([\"document\"]) \\\n","    .setOutputCol(\"token\")\n","\n","wordEmbeddings = BertEmbeddings().pretrained('bert_base_cased') \\\n","      .setInputCols([\"document\",'token'])\\\n","      .setOutputCol(\"word_embeddings\")\\\n","      .setCaseSensitive(False)\n","\n","nerModel = NerDLModel.pretrained(\"ner_dl_bert\", \"en\") \\\n","        .setInputCols([\"document\", \"token\", \"word_embeddings\"]) \\\n","        .setOutputCol(\"ner\")\n","\n","nerConverter = NerConverter() \\\n","    .setInputCols([\"document\", \"token\", \"ner\"]) \\\n","    .setOutputCol(\"entities\")\n","\n","chunkToDoc = Chunk2Doc() \\\n","    .setInputCols(\"entities\") \\\n","    .setOutputCol(\"chunkConverted\")\n","\n","pipeline = Pipeline().setStages([\n","      documentAssembler,\n","      tokenizer,\n","      wordEmbeddings,\n","      nerModel,\n","      nerConverter,\n","      chunkToDoc\n","    ])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HBMUIRXj8nTc"},"outputs":[],"source":["data = spark.createDataFrame([[\"Stocks ended slightly higher on Friday but stayed near lows for the year as oil prices surged past $36;46 a barrel, offsetting a positive outlook from computer maker Dell Inc.\"]]).toDF(\"text\")\n","result = pipeline.fit(data).transform(data)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2663,"status":"ok","timestamp":1673638268879,"user":{"displayName":"Silvia Onofrei","userId":"08518681359279549405"},"user_tz":360},"id":"1ZEVazv88nfM","outputId":"b51dc203-535e-4b5c-e58b-3b1bb2b84cf7"},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------------+-----+---+------+------------------------------------------+\n","|annotatorType|begin|end|result|metadata                                  |\n","+-------------+-----+---+------+------------------------------------------+\n","|document     |166  |169|Dell  |{entity -> ORG, sentence -> 0, chunk -> 0}|\n","+-------------+-----+---+------+------------------------------------------+\n","\n"]}],"source":["result.selectExpr(\"explode(chunkConverted) as result\") \\\n","    .select(\"result.annotatorType\", \"result.begin\", \"result.end\", \"result.result\", \"result.metadata\") \\\n","    .show(truncate=False)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPbIAaXf6HUHSNzgjapP9Mt","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
