{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"D0qeroSZw4vv"},"source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Open_Source/35.01.LightPipeline.ipynb)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"-UHbE9sww3By"},"source":["# 🔎 What is `LightPipeline`?\n","\n","`LightPipelines` are Spark NLP specific pipelines, equivalent to *Spark ML Pipeline*. The difference is that it’s execution does not hold to Spark principles, instead it computes everything locally (but in parallel) in order to achieve fast results when dealing with small amounts of data. \n","\n","They’re useful while working with small datasets, experimentation, and debugging results.\n","\n","They're especially useful while building real-time APIs for serving real-time requets.\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"G5v4yF-Q9Lu6"},"source":["# 🔎 How `LightPipeline` work?\n","\n","Spark NLP `LightPipelines` are Spark ML pipelines converted into a single machine.\n","\n","**They do not leverage full Spark cluster, and run in local mode (on driver) only.**\n","\n","**10x times faster for smaller amounts of data (small is relative, but 50k sentences are roughly a good maximum)**.\n","\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"5InSWPOq9Nhu"},"source":["# 🔎 How `LightPipeline` can be used?\n","\n","Full pipelines are casted to `LightPipelines` to remove spark overhead. In this process, two new functions are introduced:\n","\n","- `annotate()`\n","- `fullAnnotate()`\n","\n","**Difference in input**:\n","While full pipelines require pyspark dataframes as inputs, the light pipeline requires a single example of a list of examples.\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"BstdsVkz-ZxY"},"source":["# 📚 Documentation\n","\n","```\n","LightPipeline(pipelineModel: PipelineModel, parse_embeddings: Boolean = false)\n","```\n","\n","\n","You can check our [Python API](https://nlp.johnsnowlabs.com/api/python/reference/autosummary/sparknlp/base/light_pipeline/index.html#sparknlp.base.light_pipeline.LightPipeline) and [ScalaDoc](https://nlp.johnsnowlabs.com/api/com/johnsnowlabs/nlp/LightPipeline.html) for more details about `LightPipeline`."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"P9BgOdf_yan8"},"source":["## Colab Setup"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":51800,"status":"ok","timestamp":1679243277044,"user":{"displayName":"Hasham Ul Haq","userId":"10508284328555930330"},"user_tz":300},"id":"V3b4Flg_tz5C","outputId":"b921efef-ffad-42cb-b2cb-8cce0d337ee8"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.3/281.3 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m448.4/448.4 KB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install -q pyspark==3.3.0 spark-nlp==4.2.4"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":256},"executionInfo":{"elapsed":43052,"status":"ok","timestamp":1679243320091,"user":{"displayName":"Hasham Ul Haq","userId":"10508284328555930330"},"user_tz":300},"id":"atQWxlEit36h","outputId":"75dde0b4-8346-441d-85a8-fd6b0284fede"},"outputs":[{"name":"stdout","output_type":"stream","text":["Spark NLP version 4.2.4\n","Apache Spark version: 3.3.0\n"]},{"data":{"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://d2d933c46618:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.3.0</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>Spark NLP</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "],"text/plain":["<pyspark.sql.session.SparkSession at 0x7f3bb8dca340>"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["import sparknlp\n","from sparknlp.base import *\n","from sparknlp.annotator import *\n","from pyspark.ml import Pipeline\n","\n","spark = sparknlp.start()\n","\n","print(\"Spark NLP version\", sparknlp.version())\n","print(\"Apache Spark version:\", spark.version)\n","\n","spark"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"whCNXlabCqp9"},"source":["# LightPipeline\n","\n","Now, let's create a Spark NLP Pipeline that can tokenize the text and get the embeddings of lemmas by using `LightPipeline`."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25810,"status":"ok","timestamp":1679243345895,"user":{"displayName":"Hasham Ul Haq","userId":"10508284328555930330"},"user_tz":300},"id":"Zwqmcwu9KSMs","outputId":"07b6477c-a1a3-4d5f-fa79-768b894df42a"},"outputs":[{"name":"stdout","output_type":"stream","text":["glove_100d download started this may take some time.\n","Approximate size to download 145.3 MB\n","[OK!]\n"]}],"source":["documentAssembler = DocumentAssembler() \\\n","    .setInputCol(\"text\") \\\n","    .setOutputCol(\"document\")\n","\n","sentenceDetector = SentenceDetector() \\\n","    .setInputCols([\"document\"]) \\\n","    .setOutputCol(\"sentence\")\n","\n","tokenizer = Tokenizer() \\\n","    .setInputCols([\"sentence\"]) \\\n","    .setOutputCol(\"token\")\n","\n","glove_embeddings = WordEmbeddingsModel.pretrained() \\\n","    .setInputCols([\"sentence\",'token'])\\\n","    .setOutputCol(\"embeddings\")\n","\n","pipeline = Pipeline(stages = [\n","      documentAssembler,\n","      sentenceDetector,\n","      tokenizer,\n","      glove_embeddings\n","    ])"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"4b7VJOIO7KlK"},"source":["➤ We will fit our pipeline with a Spark DataFrame and have a model.\n","\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":5561,"status":"ok","timestamp":1679243351454,"user":{"displayName":"Hasham Ul Haq","userId":"10508284328555930330"},"user_tz":300},"id":"Kntkz15Tt32K"},"outputs":[],"source":["sample_text = \"Peter Pipers employees are picking pecks of pickled peppers. He had a good income last year.\"\n","sample_list = [\"Peter Pipers employees are picking pecks of pickled peppers.\", \"He had a good income last year.\"]\n","\n","data = spark.createDataFrame([[sample_text]]).toDF(\"text\")\n","\n","model = pipeline.fit(data)"]},{"cell_type":"code","execution_count":75,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":660,"status":"ok","timestamp":1679247717534,"user":{"displayName":"Hasham Ul Haq","userId":"10508284328555930330"},"user_tz":300},"id":"muj-t2X0tkve","outputId":"f64eedf5-5cfc-451f-cbd4-086d91eece8d"},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------------------+--------------------+--------------------+--------------------+--------------------+\n","|                text|            document|            sentence|               token|          embeddings|\n","+--------------------+--------------------+--------------------+--------------------+--------------------+\n","|Peter Pipers empl...|[{document, 0, 91...|[{document, 0, 59...|[{token, 0, 4, Pe...|[{word_embeddings...|\n","+--------------------+--------------------+--------------------+--------------------+--------------------+\n","\n","CPU times: user 18.8 ms, sys: 6.03 ms, total: 24.9 ms\n","Wall time: 503 ms\n"]}],"source":["%%time\n","res = model.transform(data)\n","res.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"QOzq1W64IVTJ"},"source":["➤ Now we will convert the fitted model to a `LightPipeline`."]},{"cell_type":"code","execution_count":82,"metadata":{"executionInfo":{"elapsed":111,"status":"ok","timestamp":1679248731281,"user":{"displayName":"Hasham Ul Haq","userId":"10508284328555930330"},"user_tz":300},"id":"GG_msy1YTqfx"},"outputs":[],"source":["light_model = LightPipeline(pipelineModel = model, parse_embeddings = False)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"fK-CXajuIt0C"},"source":["## 📌 `LightPipeline` Methods"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"oG2P32Vz1TDc"},"source":["### 💡 `transform` Method\n","\n","➤ The transform method expects pyspark dataframe as input (for consistency with full piplines)."]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":640,"status":"ok","timestamp":1679246655382,"user":{"displayName":"Hasham Ul Haq","userId":"10508284328555930330"},"user_tz":300},"id":"7KHYojVv1SA5","outputId":"26b2915a-e02f-4bbc-fda7-684ae03c86a6"},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------------------+--------------------+--------------------+--------------------+--------------------+\n","|                text|            document|            sentence|               token|          embeddings|\n","+--------------------+--------------------+--------------------+--------------------+--------------------+\n","|Peter Pipers empl...|[{document, 0, 91...|[{document, 0, 59...|[{token, 0, 4, Pe...|[{word_embeddings...|\n","+--------------------+--------------------+--------------------+--------------------+--------------------+\n","\n","CPU times: user 20.6 ms, sys: 7.12 ms, total: 27.7 ms\n","Wall time: 485 ms\n"]}],"source":["%%time\n","res = light_model.transform(data)\n","res.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"GqR_1cPnNBnv"},"source":["### 💡 `fullAnnotate` Method\n","\n","➤ When you use `.fullAnnotate` method of `LightPipeline`, it annotates the data provided into *Annotation type* results. It will return a list of dictionaries that contain the output columns of annotators as keys and their results as values. \n","\n","➤ `.fullAnnotate` results contain `begin`, `end`, `result`, `metadata` information which is good for checking the results deeply or using these results for the downstream tasks.\n","\n","Let's show an example using our `sample_text`."]},{"cell_type":"code","execution_count":59,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":150,"status":"ok","timestamp":1679246842001,"user":{"displayName":"Hasham Ul Haq","userId":"10508284328555930330"},"user_tz":300},"id":"UuJx4Fuv6Up_","outputId":"6eae4a95-3b08-49bf-d125-49a9690c9748"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Peter Pipers employees are picking pecks of pickled peppers. He had a good income last year.'"]},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"source":["sample_text"]},{"cell_type":"code","execution_count":56,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":137,"status":"ok","timestamp":1679246719023,"user":{"displayName":"Hasham Ul Haq","userId":"10508284328555930330"},"user_tz":300},"id":"foahONgL2c9o","outputId":"20ccfd6d-bd57-46fe-f050-af05e4905cb4"},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 29.1 ms, sys: 9.62 ms, total: 38.7 ms\n","Wall time: 129 ms\n"]},{"data":{"text/plain":["dict_keys(['document', 'sentence', 'token', 'embeddings'])"]},"execution_count":56,"metadata":{},"output_type":"execute_result"}],"source":["%%time\n","fullAnnotate_result = light_model.fullAnnotate(sample_text)\n","fullAnnotate_result[0].keys()"]},{"cell_type":"code","execution_count":58,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":562,"status":"ok","timestamp":1679246793144,"user":{"displayName":"Hasham Ul Haq","userId":"10508284328555930330"},"user_tz":300},"id":"YbrSZ_7Y6JJr","outputId":"a18230ba-0031-42e8-b0d9-4231517aacd2"},"outputs":[{"data":{"text/plain":["{'document': [Annotation(document, 0, 59, Peter Pipers employees are picking pecks of pickled peppers., {})],\n"," 'sentence': [Annotation(document, 0, 59, Peter Pipers employees are picking pecks of pickled peppers., {'sentence': '0'})],\n"," 'token': [Annotation(token, 0, 4, Peter, {'sentence': '0'}),\n","  Annotation(token, 6, 11, Pipers, {'sentence': '0'}),\n","  Annotation(token, 13, 21, employees, {'sentence': '0'}),\n","  Annotation(token, 23, 25, are, {'sentence': '0'}),\n","  Annotation(token, 27, 33, picking, {'sentence': '0'}),\n","  Annotation(token, 35, 39, pecks, {'sentence': '0'}),\n","  Annotation(token, 41, 42, of, {'sentence': '0'}),\n","  Annotation(token, 44, 50, pickled, {'sentence': '0'}),\n","  Annotation(token, 52, 58, peppers, {'sentence': '0'}),\n","  Annotation(token, 59, 59, ., {'sentence': '0'})],\n"," 'embeddings': [Annotation(word_embeddings, 0, 4, Peter, {'isOOV': 'false', 'pieceId': '-1', 'isWordStart': 'true', 'token': 'Peter', 'sentence': '0'}),\n","  Annotation(word_embeddings, 6, 11, Pipers, {'isOOV': 'false', 'pieceId': '-1', 'isWordStart': 'true', 'token': 'Pipers', 'sentence': '0'}),\n","  Annotation(word_embeddings, 13, 21, employees, {'isOOV': 'false', 'pieceId': '-1', 'isWordStart': 'true', 'token': 'employees', 'sentence': '0'}),\n","  Annotation(word_embeddings, 23, 25, are, {'isOOV': 'false', 'pieceId': '-1', 'isWordStart': 'true', 'token': 'are', 'sentence': '0'}),\n","  Annotation(word_embeddings, 27, 33, picking, {'isOOV': 'false', 'pieceId': '-1', 'isWordStart': 'true', 'token': 'picking', 'sentence': '0'}),\n","  Annotation(word_embeddings, 35, 39, pecks, {'isOOV': 'false', 'pieceId': '-1', 'isWordStart': 'true', 'token': 'pecks', 'sentence': '0'}),\n","  Annotation(word_embeddings, 41, 42, of, {'isOOV': 'false', 'pieceId': '-1', 'isWordStart': 'true', 'token': 'of', 'sentence': '0'}),\n","  Annotation(word_embeddings, 44, 50, pickled, {'isOOV': 'false', 'pieceId': '-1', 'isWordStart': 'true', 'token': 'pickled', 'sentence': '0'}),\n","  Annotation(word_embeddings, 52, 58, peppers, {'isOOV': 'false', 'pieceId': '-1', 'isWordStart': 'true', 'token': 'peppers', 'sentence': '0'}),\n","  Annotation(word_embeddings, 59, 59, ., {'isOOV': 'false', 'pieceId': '-1', 'isWordStart': 'true', 'token': '.', 'sentence': '0'})]}"]},"execution_count":58,"metadata":{},"output_type":"execute_result"}],"source":["fullAnnotate_result[0]"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"nVj9iyBF6hkS"},"source":["➤ We can also use `.fullAnnotate` method with an Array of strings. In this case, `.fullAnnotate` method returns a list of dictionaries which contain the results of each item of the list."]},{"cell_type":"code","execution_count":76,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":137,"status":"ok","timestamp":1679248538031,"user":{"displayName":"Hasham Ul Haq","userId":"10508284328555930330"},"user_tz":300},"id":"NbdbMVuBAzRn","outputId":"6d16709e-f5f1-4976-be4a-96cb7a7fd5fe"},"outputs":[{"data":{"text/plain":["['Peter Pipers employees are picking pecks of pickled peppers.',\n"," 'He had a good income last year.']"]},"execution_count":76,"metadata":{},"output_type":"execute_result"}],"source":["sample_list"]},{"cell_type":"code","execution_count":77,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":155,"status":"ok","timestamp":1679248542454,"user":{"displayName":"Hasham Ul Haq","userId":"10508284328555930330"},"user_tz":300},"id":"xwxvlYO85mGq","outputId":"86aaa5d2-d9ed-44f8-bc82-c626cb1780d8"},"outputs":[{"name":"stdout","output_type":"stream","text":["2\n"]},{"data":{"text/plain":["dict_keys(['document', 'sentence', 'token', 'embeddings'])"]},"execution_count":77,"metadata":{},"output_type":"execute_result"}],"source":["fullAnnotate_result = light_model.fullAnnotate(sample_list)\n","print (len(fullAnnotate_result))\n","fullAnnotate_result[0].keys()"]},{"cell_type":"code","execution_count":79,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":915,"status":"ok","timestamp":1679248554228,"user":{"displayName":"Hasham Ul Haq","userId":"10508284328555930330"},"user_tz":300},"id":"lJ8fJuni6clv","outputId":"b0bb5898-2a4e-4d4f-9f05-b035513fcd24"},"outputs":[{"data":{"text/plain":["{'document': [Annotation(document, 0, 59, Peter Pipers employees are picking pecks of pickled peppers., {})],\n"," 'sentence': [Annotation(document, 0, 59, Peter Pipers employees are picking pecks of pickled peppers., {'sentence': '0'})],\n"," 'token': [Annotation(token, 0, 4, Peter, {'sentence': '0'}),\n","  Annotation(token, 6, 11, Pipers, {'sentence': '0'}),\n","  Annotation(token, 13, 21, employees, {'sentence': '0'}),\n","  Annotation(token, 23, 25, are, {'sentence': '0'}),\n","  Annotation(token, 27, 33, picking, {'sentence': '0'}),\n","  Annotation(token, 35, 39, pecks, {'sentence': '0'}),\n","  Annotation(token, 41, 42, of, {'sentence': '0'}),\n","  Annotation(token, 44, 50, pickled, {'sentence': '0'}),\n","  Annotation(token, 52, 58, peppers, {'sentence': '0'}),\n","  Annotation(token, 59, 59, ., {'sentence': '0'})],\n"," 'embeddings': [Annotation(word_embeddings, 0, 4, Peter, {'isOOV': 'false', 'pieceId': '-1', 'isWordStart': 'true', 'token': 'Peter', 'sentence': '0'}),\n","  Annotation(word_embeddings, 6, 11, Pipers, {'isOOV': 'false', 'pieceId': '-1', 'isWordStart': 'true', 'token': 'Pipers', 'sentence': '0'}),\n","  Annotation(word_embeddings, 13, 21, employees, {'isOOV': 'false', 'pieceId': '-1', 'isWordStart': 'true', 'token': 'employees', 'sentence': '0'}),\n","  Annotation(word_embeddings, 23, 25, are, {'isOOV': 'false', 'pieceId': '-1', 'isWordStart': 'true', 'token': 'are', 'sentence': '0'}),\n","  Annotation(word_embeddings, 27, 33, picking, {'isOOV': 'false', 'pieceId': '-1', 'isWordStart': 'true', 'token': 'picking', 'sentence': '0'}),\n","  Annotation(word_embeddings, 35, 39, pecks, {'isOOV': 'false', 'pieceId': '-1', 'isWordStart': 'true', 'token': 'pecks', 'sentence': '0'}),\n","  Annotation(word_embeddings, 41, 42, of, {'isOOV': 'false', 'pieceId': '-1', 'isWordStart': 'true', 'token': 'of', 'sentence': '0'}),\n","  Annotation(word_embeddings, 44, 50, pickled, {'isOOV': 'false', 'pieceId': '-1', 'isWordStart': 'true', 'token': 'pickled', 'sentence': '0'}),\n","  Annotation(word_embeddings, 52, 58, peppers, {'isOOV': 'false', 'pieceId': '-1', 'isWordStart': 'true', 'token': 'peppers', 'sentence': '0'}),\n","  Annotation(word_embeddings, 59, 59, ., {'isOOV': 'false', 'pieceId': '-1', 'isWordStart': 'true', 'token': '.', 'sentence': '0'})]}"]},"execution_count":79,"metadata":{},"output_type":"execute_result"}],"source":["fullAnnotate_result[0]"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"VujiS39wKCMl"},"source":["### 💡 `annotate` Method\n","\n","➤ When you use `.annotate` method of `LightPipeline`, it will return a dictionary which contains output columns of the annotators as keys and the results as values. \n","\n","➤ `.annotate` results contain only the results, they don't contain `begin`, `end`, `metadata` information which is easy to check the results.\n","\n","Let's show an example using our `sample_text`."]},{"cell_type":"code","execution_count":83,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":532,"status":"ok","timestamp":1679248737215,"user":{"displayName":"Hasham Ul Haq","userId":"10508284328555930330"},"user_tz":300},"id":"0lc-cPkYSvXg","outputId":"0ada7468-8a22-4fa7-e41e-065c3d7f82be"},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 17.6 ms, sys: 2.1 ms, total: 19.7 ms\n","Wall time: 177 ms\n"]},{"data":{"text/plain":["dict_keys(['document', 'sentence', 'token', 'embeddings'])"]},"execution_count":83,"metadata":{},"output_type":"execute_result"}],"source":["%%time\n","annotate_result = light_model.annotate(sample_text)\n","annotate_result.keys()"]},{"cell_type":"code","execution_count":85,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":380,"status":"ok","timestamp":1679248760050,"user":{"displayName":"Hasham Ul Haq","userId":"10508284328555930330"},"user_tz":300},"id":"n93vA6toG4WK","outputId":"3d746763-4a8f-4a63-d038-f1d9262b6795"},"outputs":[{"data":{"text/plain":["{'document': ['Peter Pipers employees are picking pecks of pickled peppers. He had a good income last year.'],\n"," 'sentence': ['Peter Pipers employees are picking pecks of pickled peppers.',\n","  'He had a good income last year.'],\n"," 'token': ['Peter',\n","  'Pipers',\n","  'employees',\n","  'are',\n","  'picking',\n","  'pecks',\n","  'of',\n","  'pickled',\n","  'peppers',\n","  '.',\n","  'He',\n","  'had',\n","  'a',\n","  'good',\n","  'income',\n","  'last',\n","  'year',\n","  '.'],\n"," 'embeddings': ['Peter',\n","  'Pipers',\n","  'employees',\n","  'are',\n","  'picking',\n","  'pecks',\n","  'of',\n","  'pickled',\n","  'peppers',\n","  '.',\n","  'He',\n","  'had',\n","  'a',\n","  'good',\n","  'income',\n","  'last',\n","  'year',\n","  '.']}"]},"execution_count":85,"metadata":{},"output_type":"execute_result"}],"source":["annotate_result"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"9TewQlooPFMi"},"source":["➤ We can also use `.annotate` method with an Array of strings. In this case, `.annotate` method returns a list of dictionaries which contain the results of each item of the list."]},{"cell_type":"code","execution_count":86,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":105,"status":"ok","timestamp":1679248800441,"user":{"displayName":"Hasham Ul Haq","userId":"10508284328555930330"},"user_tz":300},"id":"_IBzMZ_LPOf_","outputId":"2baaff52-56eb-4c9c-9ba5-cfaca697b475"},"outputs":[{"data":{"text/plain":["['Peter Pipers employees are picking pecks of pickled peppers.',\n"," 'He had a good income last year.']"]},"execution_count":86,"metadata":{},"output_type":"execute_result"}],"source":["sample_list"]},{"cell_type":"code","execution_count":87,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":302,"status":"ok","timestamp":1679248803605,"user":{"displayName":"Hasham Ul Haq","userId":"10508284328555930330"},"user_tz":300},"id":"Z5MO0UwtS1Aj","outputId":"085fbd77-040b-4626-e709-641d9a09d2ab"},"outputs":[{"data":{"text/plain":["dict_keys(['document', 'sentence', 'token', 'embeddings'])"]},"execution_count":87,"metadata":{},"output_type":"execute_result"}],"source":["annotate_list_result = light_model.annotate(sample_list)\n","annotate_list_result[0].keys()"]},{"cell_type":"code","execution_count":88,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":109,"status":"ok","timestamp":1679248808016,"user":{"displayName":"Hasham Ul Haq","userId":"10508284328555930330"},"user_tz":300},"id":"TVKv1mi0Rquj","outputId":"5e5cbd56-a174-4612-be73-52821b449af5"},"outputs":[{"data":{"text/plain":["2"]},"execution_count":88,"metadata":{},"output_type":"execute_result"}],"source":["# length of results and the list of strings are in the same\n","\n","len(annotate_list_result)"]},{"cell_type":"code","execution_count":89,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":110,"status":"ok","timestamp":1679248817037,"user":{"displayName":"Hasham Ul Haq","userId":"10508284328555930330"},"user_tz":300},"id":"1qk2gJOUO72g","outputId":"026f74b5-cc25-4df3-cb03-ce08af7cc444"},"outputs":[{"data":{"text/plain":["[{'document': ['Peter Pipers employees are picking pecks of pickled peppers.'],\n","  'sentence': ['Peter Pipers employees are picking pecks of pickled peppers.'],\n","  'token': ['Peter',\n","   'Pipers',\n","   'employees',\n","   'are',\n","   'picking',\n","   'pecks',\n","   'of',\n","   'pickled',\n","   'peppers',\n","   '.'],\n","  'embeddings': ['Peter',\n","   'Pipers',\n","   'employees',\n","   'are',\n","   'picking',\n","   'pecks',\n","   'of',\n","   'pickled',\n","   'peppers',\n","   '.']},\n"," {'document': ['He had a good income last year.'],\n","  'sentence': ['He had a good income last year.'],\n","  'token': ['He', 'had', 'a', 'good', 'income', 'last', 'year', '.'],\n","  'embeddings': ['He', 'had', 'a', 'good', 'income', 'last', 'year', '.']}]"]},"execution_count":89,"metadata":{},"output_type":"execute_result"}],"source":["annotate_list_result"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"kmyjglNGPkXw"},"source":["➤ Lets show the `token` result of second text in the list."]},{"cell_type":"code","execution_count":90,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":124,"status":"ok","timestamp":1679248831394,"user":{"displayName":"Hasham Ul Haq","userId":"10508284328555930330"},"user_tz":300},"id":"oiYZWrphPjwr","outputId":"7afffdf8-4c17-43ad-d0e7-7d75239a29b0"},"outputs":[{"data":{"text/plain":["['He', 'had', 'a', 'good', 'income', 'last', 'year', '.']"]},"execution_count":90,"metadata":{},"output_type":"execute_result"}],"source":["annotate_list_result[1][\"token\"]"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":317,"status":"ok","timestamp":1679245292644,"user":{"displayName":"Hasham Ul Haq","userId":"10508284328555930330"},"user_tz":300},"id":"KJnGFhjHS9tp","outputId":"b4d55b84-99a9-40a4-a30a-b82299b0c363"},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 32.6 ms, sys: 13.3 ms, total: 45.8 ms\n","Wall time: 174 ms\n"]},{"data":{"text/plain":["dict_keys(['document', 'sentence', 'token', 'embeddings'])"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":[]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"P7VXafxy8fAK"},"source":["### Get Embeddings Using `LightPipeline`\n","\n","As you can see in the results, the embeddings of the tokens are not shown in the metadata. To get the embeddings, we need to call `parse_embeddings = True` while creating the `LightPipeline`."]},{"cell_type":"code","execution_count":93,"metadata":{"executionInfo":{"elapsed":130,"status":"ok","timestamp":1679249205382,"user":{"displayName":"Hasham Ul Haq","userId":"10508284328555930330"},"user_tz":300},"id":"ltjKRFi_E-8V"},"outputs":[],"source":["light_model_emb = LightPipeline(pipelineModel = model, parse_embeddings=True)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"wRWHlDvUOI6I"},"source":["➤ Let's use `annotate` method to get the embeddings."]},{"cell_type":"code","execution_count":94,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":132,"status":"ok","timestamp":1679249212188,"user":{"displayName":"Hasham Ul Haq","userId":"10508284328555930330"},"user_tz":300},"id":"8FUenhESVelB","outputId":"1ac9d7b6-440e-4c6e-8994-7f3c48dc8e58"},"outputs":[{"data":{"text/plain":["{'document': ['Peter Pipers employees are picking pecks of pickled peppers. He had a good income last year.'],\n"," 'sentence': ['Peter Pipers employees are picking pecks of pickled peppers.',\n","  'He had a good income last year.'],\n"," 'token': ['Peter',\n","  'Pipers',\n","  'employees',\n","  'are',\n","  'picking',\n","  'pecks',\n","  'of',\n","  'pickled',\n","  'peppers',\n","  '.',\n","  'He',\n","  'had',\n","  'a',\n","  'good',\n","  'income',\n","  'last',\n","  'year',\n","  '.'],\n"," 'embeddings': ['-0.12434 0.27086 -0.25726 -0.92575 0.28346 -0.21944 -0.25647 -0.3976 -0.57385 -0.68947 -0.013447 0.1228 0.026195 0.61443 0.27363 -0.76713 0.24401 0.11872 -0.95617 0.5759 -0.26431 0.27444 0.50889 0.075364 0.4246 -0.071953 0.35437 -0.20185 0.38063 0.58091 -0.47259 0.16159 -0.017361 -0.2855 -0.49036 -0.5123 -0.045206 0.47847 0.30254 -0.27687 -0.27672 0.095084 0.29336 0.25971 -0.14715 -0.23236 -0.91433 -0.87662 0.048327 0.32749 1.0647 -0.61005 0.1543 0.38154 -0.16749 -3.0263 -1.0712 0.44597 0.052224 -0.50453 0.38656 0.20731 -0.1338 0.1269 0.18352 -0.56448 -0.1121 1.4906 0.6329 0.51403 0.011779 -0.23554 -0.29482 -0.63349 0.065235 -0.92042 -0.34364 -0.13913 0.076305 0.79587 0.27538 -0.18788 0.11315 -0.13842 -0.76616 -0.72023 -0.69237 -0.83988 -0.15289 -0.14292 0.26925 -0.79049 0.52366 0.46049 0.16114 -0.25888 0.06052 -0.029555 -0.086427 -0.37297',\n","  '0.50033 0.072487 0.4071 -0.78272 -0.3137 0.92802 -0.13052 -0.16564 -0.65964 -0.74321 -0.23527 -0.14712 0.12395 0.086565 -0.1342 -0.181 0.33023 -0.34229 0.42381 -0.2326 -0.57685 -0.066354 -0.31997 -0.72414 0.08131 -0.38289 0.05658 -0.25225 0.81431 0.22373 -0.18376 -0.16366 0.099785 -0.11763 -0.20793 -0.31055 -0.69135 0.54878 0.44869 0.1112 0.31927 -0.045907 -0.55461 0.19433 -0.17863 0.30522 -0.1481 0.28145 0.26152 0.15387 -1.6514 0.31548 -0.67455 0.53849 -0.53427 0.72408 0.64724 -0.55363 -0.56437 0.41743 0.0070583 -0.12772 7.962E-4 0.75213 0.1498 -0.74423 -0.027502 -0.86733 -0.016421 -0.5091 -0.5892 0.1118 -0.43179 0.39337 -0.75308 -0.49154 0.37764 -0.021259 0.35066 -0.28028 0.0023227 -0.22818 0.090611 1.025 0.095825 0.093931 0.45583 -0.12986 0.20001 0.69488 -0.63328 -0.30865 -1.4222 -0.53573 -0.7265 0.13607 -0.34067 -0.072907 -0.21878 0.32025',\n","  '0.7206 -0.18073 -0.47621 -0.11763 -0.65444 0.19243 -0.34281 0.57096 -0.20443 0.14316 0.5499 -0.20605 1.0076 -0.0074096 -0.71318 -0.96216 0.46232 0.29057 -0.38639 0.33338 0.50552 0.22608 -0.18231 -0.013688 -0.53922 -1.0093 0.0090689 0.16949 -0.12536 -0.41273 0.87526 1.1016 -0.5859 -0.68899 -0.25819 0.080917 0.016448 0.18208 0.33626 0.23472 -0.057365 -0.46495 -0.21835 0.28313 0.061164 0.37927 -0.51267 -0.10541 -0.068109 -0.56569 -0.026374 -1.1114 -1.1146 0.95196 -0.39138 -0.80733 0.4674 -1.1257 2.4514 0.099297 0.086096 0.32104 0.18617 -0.28801 0.37865 -0.45019 0.69389 0.42161 0.95187 0.13064 -0.24932 0.05208 -0.93184 -0.69027 0.64072 0.064489 0.92491 -0.15351 -0.8551 0.078052 0.75868 -0.46968 -0.04895 -0.26187 -1.9927 -0.48627 0.35927 0.29179 -0.20821 0.033251 0.41392 -0.32014 0.42173 -0.65427 -0.46362 0.4277 0.090491 0.59082 0.70458 0.032847',\n","  '-0.51533 0.83186 0.22457 -0.73865 0.18718 0.26021 -0.42564 0.67121 -0.31084 -0.61275 0.089526 -0.24011 1.1878 0.67609 -0.022885 -0.92533 0.071174 0.38837 -0.42924 0.37144 0.32671 0.43141 0.87495 0.34009 -0.23189 -0.41144 0.49061 -0.32906 -0.49109 -0.18988 0.33408 -0.21245 -0.38386 -0.080547 1.1161 0.23617 0.31333 0.49286 0.1 -0.15131 -0.14176 -0.2802 -0.2388 -0.35486 0.18282 -0.19134 0.60544 0.074573 -0.20731 -0.60965 0.19908 -0.57024 -0.17427 1.4419 -0.25019 -1.8648 0.41671 -0.24607 1.501 0.87415 -0.67135 1.2762 -0.2721 0.17583 1.2242 0.28242 0.62375 0.63951 0.36914 -0.84677 -0.3227 -0.67152 -0.19635 -0.40789 -0.20966 -0.19623 0.041885 0.53967 -1.1105 -0.39515 0.6659 -0.233 -1.082 0.046465 -2.0993 -0.28493 0.080025 -0.12963 -0.30011 -0.46764 -0.81831 -0.048509 -0.32233 -0.32013 -1.1207 -0.056788 -0.73004 -1.2024 1.1304 0.3479',\n","  '-0.0036618 0.22974 0.29882 -0.56806 0.42334 0.063595 0.010886 0.034923 0.029709 -0.51931 0.066931 -0.09084 0.0050487 -0.25149 0.39328 -0.34966 0.0080375 -0.046751 0.75312 0.32056 -0.3119 0.31801 0.2727 -0.49709 -0.25946 0.218 -0.39087 -0.25213 -0.12246 -0.1474 -0.30322 -0.16788 0.23095 -0.46637 0.043081 -0.69707 -0.62142 -0.58567 0.12999 -0.099603 -0.51347 -0.4648 0.70888 -0.34531 -0.48233 0.057247 -0.33344 -0.27999 -0.49173 -1.0357 0.074744 -0.35792 -0.55793 1.0123 -0.32618 -1.1572 0.049583 0.37225 0.65029 0.33603 -0.15939 1.045 0.061484 0.77098 -0.066843 0.23938 0.528 -0.16948 0.11667 -0.098056 -0.58239 0.22326 -0.047084 -0.50194 -0.12098 0.58614 -0.72017 0.12435 0.44493 0.081355 0.38825 0.19443 -0.89857 -0.31516 -0.57526 -0.86676 0.053313 -0.083532 -0.57143 -0.079064 -0.51858 0.15813 0.0065564 -0.13155 -0.66449 -0.23702 -0.017022 0.33848 0.83477 0.35158',\n","  '0.2249 0.21727 -0.39846 0.021821 0.56639 0.17647 0.29679 -0.48319 0.60535 -0.1522 -0.087211 0.94772 -0.40136 0.21808 0.16334 0.7447 -0.89337 -0.20695 -0.20845 -0.28663 -0.48562 0.36786 -0.072757 -0.69117 1.2429 -0.075452 -0.37337 0.3697 -0.33159 -0.069872 -0.46043 -0.31981 -0.090884 0.74428 -0.51915 0.15767 0.15646 -0.43391 -0.31216 0.21965 -0.31498 -0.18205 -0.13765 -0.082912 -0.41473 0.15502 -0.67673 -0.13082 -0.11471 0.67207 -0.35008 -0.38488 -0.0067339 -0.26964 -0.43623 0.93383 -0.083333 -0.02871 -0.23768 -0.54266 0.288 0.36221 0.2276 0.50409 -0.17752 0.11016 0.11801 0.039851 -0.37032 0.047588 -0.1442 0.085161 -0.045787 -0.42023 -0.090433 0.39139 -0.29866 -0.46675 0.57089 -0.013388 -0.54677 0.31051 -0.63216 -0.62434 0.056642 0.18436 0.13495 0.69944 0.27255 0.037849 -0.81561 0.42655 0.23611 0.1354 0.062156 -0.084071 -0.46727 -0.039551 -0.38656 0.31916',\n","  '-0.1529 -0.24279 0.89837 0.16996 0.53516 0.48784 -0.58826 -0.17982 -1.3581 0.42541 0.15377 0.24215 0.13474 0.41193 0.67043 -0.56418 0.42985 -0.012183 -0.11677 0.31781 0.054177 -0.054273 0.35516 -0.30241 0.31434 -0.33846 0.71715 -0.26855 -0.15837 -0.47467 0.051581 -0.33252 0.15003 -0.1299 -0.54617 -0.37843 0.64261 0.82187 -0.080006 0.078479 -0.96976 -0.57741 0.56491 -0.39873 -0.057099 0.19743 0.065706 -0.48092 -0.20125 -0.40834 0.39456 -0.02642 -0.11838 1.012 -0.53171 -2.7474 -0.042981 -0.74849 1.7574 0.59085 0.04885 0.78267 0.38497 0.42097 0.67882 0.10337 0.6328 -0.026595 0.58647 -0.44332 0.33057 -0.12022 -0.55645 0.073611 0.20915 0.43395 -0.012761 0.089874 -1.7991 0.084808 0.77112 0.63105 -0.90685 0.60326 -1.7515 0.18596 -0.50687 -0.70203 0.66578 -0.81304 0.18712 -0.018488 -0.26757 0.727 -0.59363 -0.34839 -0.56094 -0.591 1.0039 0.20664',\n","  '-1.05 0.5338 0.020072 -0.34029 -0.38199 -0.21586 0.31519 -0.77298 0.50663 0.04273 0.11982 0.72543 0.39441 1.3374 0.80225 0.32331 0.14645 0.037314 0.2541 0.066851 -0.20769 -0.12443 0.31041 -0.12712 -0.17627 1.0001 -0.97159 -0.11259 -0.22403 0.46884 -0.32289 0.14366 0.0048271 0.12526 -0.15476 0.74851 -0.52632 0.39074 0.13152 -0.30755 0.91804 -1.2203 -0.34127 -0.50266 0.5837 -0.023186 0.14705 0.42887 -0.63661 0.063788 0.033288 -0.35904 -0.085728 -0.20493 -1.2328 0.1922 -0.59451 0.10165 -1.0365 -0.43699 -0.041209 1.0104 0.046454 0.47414 -0.071508 -0.74275 0.035981 -0.75861 0.13618 -0.23629 0.080248 0.19262 0.13967 0.49687 -0.74057 1.0303 -0.66569 0.27123 0.77984 -0.20417 0.7496 -0.50025 -0.0279 1.2473 -0.67111 0.39955 -0.23311 0.52268 0.49917 0.12368 -0.075896 -0.088006 -0.4112 -0.83482 -0.31519 -0.62055 -0.51626 -0.48444 0.12858 0.43396',\n","  '-0.7199 0.43062 -0.38727 -0.95503 -0.26449 0.11582 0.60068 -0.19748 0.37874 0.35588 -0.076802 0.42356 -0.19344 0.76623 0.28132 0.11129 0.037713 0.1491 0.062745 0.1332 -1.1632 0.033333 0.46174 0.44118 0.26025 0.98465 0.72668 0.021245 0.13797 -0.030895 -0.3684 0.49006 -0.04411 0.34411 -0.44798 0.39974 0.037205 -0.028705 0.89356 -0.80244 1.0103 -0.89817 -0.15263 -0.42638 0.26874 -0.23711 -0.41208 0.076044 0.22515 -0.63154 -0.34838 0.12607 -0.84193 0.18925 -1.5501 -0.60126 -0.27824 -0.027498 -0.84017 0.37299 -0.081033 1.2111 0.65772 -0.26722 0.65631 -1.0572 0.34407 -0.35383 0.25141 -0.066453 0.2102 0.39376 -0.37418 0.68083 -0.43531 0.71879 -0.93903 0.18838 1.0401 0.28523 1.3577 -0.85704 -0.9611 0.30858 -0.17546 -0.18474 0.061607 0.67931 0.17479 0.64741 -0.73547 -0.12097 -1.0578 -0.43043 -1.1111 -0.39086 -0.74064 0.029951 -0.033792 0.48291',\n","  '-0.33979 0.20941 0.46348 -0.64792 -0.38377 0.038034 0.17127 0.15978 0.46619 -0.019169 0.41479 -0.34349 0.26872 0.04464 0.42131 -0.41032 0.15459 0.022239 -0.64653 0.25256 0.043136 -0.19445 0.46516 0.45651 0.68588 0.091295 0.21875 -0.70351 0.16785 -0.35079 -0.12634 0.66384 -0.2582 0.036542 -0.13605 0.40253 0.14289 0.38132 -0.12283 -0.45886 -0.25282 -0.30432 -0.11215 -0.26182 -0.22482 -0.44554 0.2991 -0.85612 -0.14503 -0.49086 0.0082973 -0.17491 0.27524 1.4401 -0.21239 -2.8435 -0.27958 -0.45722 1.6386 0.78808 -0.55262 0.65 0.086426 0.39012 1.0632 -0.35379 0.48328 0.346 0.84174 0.098707 -0.24213 -0.27053 0.045287 -0.40147 0.11395 0.0062226 0.036673 0.018518 -1.0213 -0.20806 0.64072 -0.068763 -0.58635 0.33476 -1.1432 -0.1148 -0.25091 -0.45907 -0.096819 -0.17946 -0.063351 -0.67412 -0.068895 0.53604 -0.87773 0.31802 -0.39242 -0.23394 0.47298 -0.028803',\n","  '0.1225 -0.058833 0.23658 -0.28877 -0.028181 0.31524 0.070229 0.16447 -0.027623 0.25214 0.21174 -0.059674 0.36133 0.13607 0.18755 -0.1487 0.31315 0.13368 -0.59703 -0.030161 0.080656 0.26162 -0.055924 -0.35351 0.34722 -0.0055801 -0.57935 -0.88007 0.42931 -0.15695 -0.51256 1.2684 -0.25228 0.35265 -0.46419 0.55648 -0.57556 0.32574 -0.21893 -0.13178 -1.1027 -0.039591 0.89643 -0.9845 -0.47393 -0.12855 0.63506 -0.94888 0.40088 -0.77542 -0.35153 -0.27788 0.68747 1.458 -0.38474 -2.8937 -0.29523 -0.38836 0.94881 1.3891 0.054591 0.70486 -0.65699 0.075648 0.7655 -0.63365 0.86556 0.42441 0.14796 0.4156 0.29354 -0.51295 0.19635 -0.45568 0.0080246 0.14528 -0.15395 0.11406 -1.2167 -0.1111 0.8264 0.21738 -0.63776 -0.074874 -1.713 -0.8827 -0.0073058 -0.37623 -0.50209 -0.58844 -0.24943 -1.0425 0.27678 0.64142 -0.64605 0.43559 -0.37276 -0.0032068 0.18744 0.30702',\n","  '0.63256 -0.12718 -0.084182 -0.30718 -0.2526 -0.16172 0.47123 0.46553 -0.051526 0.17231 0.42743 0.57854 0.64548 0.31367 0.32752 -0.47608 0.25888 0.035845 -0.95154 -0.20671 0.65171 0.010712 0.3894 0.069552 0.061198 -0.72152 -0.22334 -0.34747 -0.1434 -0.32482 0.79539 0.84708 -0.046052 0.74384 0.18185 0.18666 0.17123 0.93485 -0.1299 0.39219 -1.016 -0.27859 0.79293 -0.40433 0.41505 0.017283 0.2936 -0.72944 0.98233 -0.96504 -0.19016 -0.010012 0.26765 1.3316 -0.19376 -2.4401 -0.39477 -0.36232 0.88315 1.5974 0.31113 0.72201 -0.55023 0.54995 0.6846 -0.40378 0.52677 0.23314 -0.12764 0.12305 -0.12489 -0.25052 0.11632 -0.41648 -0.19738 0.093786 -0.24532 0.29676 -1.6156 0.38933 0.68466 0.048371 -0.4177 0.10663 -2.0738 -0.81679 0.56651 -0.32536 -0.76685 -0.27123 -0.10798 -0.61763 -0.27098 0.077119 -0.89352 0.17811 -0.50156 -0.30966 0.22378 0.038183',\n","  '-0.27086 0.044006 -0.02026 -0.17395 0.6444 0.71213 0.3551 0.47138 -0.29637 0.54427 -0.72294 -0.0047612 0.040611 0.043236 0.29729 0.10725 0.40156 -0.53662 0.033382 0.067396 0.64556 -0.085523 0.14103 0.094539 0.74947 -0.194 -0.68739 -0.41741 -0.22807 0.12 -0.48999 0.80945 0.045138 -0.11898 0.20161 0.39276 -0.20121 0.31354 0.75304 0.25907 -0.11566 -0.029319 0.93499 -0.36067 0.5242 0.23706 0.52715 0.22869 -0.51958 -0.79349 -0.20368 -0.50187 0.18748 0.94282 -0.44834 -3.6792 0.044183 -0.26751 2.1997 0.241 -0.033425 0.69553 -0.64472 -0.0072277 0.89575 0.20015 0.46493 0.61933 -0.1066 0.08691 -0.4623 0.18262 -0.15849 0.020791 0.19373 0.063426 -0.31673 -0.48177 -1.3848 0.13669 0.96859 0.049965 -0.2738 -0.035686 -1.0577 -0.24467 0.90366 -0.12442 0.080776 -0.83401 0.57201 0.088945 -0.42532 -0.018253 -0.079995 -0.28581 -0.01089 -0.4923 0.63687 0.23642',\n","  '-0.030769 0.11993 0.53909 -0.43696 -0.73937 -0.15345 0.081126 -0.38559 -0.68797 -0.41632 -0.13183 -0.24922 0.441 0.085919 0.20871 -0.063582 0.062228 -0.051234 -0.13398 1.1418 0.036526 0.49029 -0.24567 -0.412 0.12349 0.41336 -0.48397 -0.54243 -0.27787 -0.26015 -0.38485 0.78656 0.1023 -0.20712 0.40751 0.32026 -0.51052 0.48362 -0.0099498 -0.38685 0.034975 -0.167 0.4237 -0.54164 -0.30323 -0.36983 0.082836 -0.52538 -0.064531 -1.398 -0.14873 -0.35327 -0.1118 1.0912 0.095864 -2.8129 0.45238 0.46213 1.6012 -0.20837 -0.27377 0.71197 -1.0754 -0.046974 0.67479 -0.065839 0.75824 0.39405 0.15507 -0.64719 0.32796 -0.031748 0.52899 -0.43886 0.67405 0.42136 -0.11981 -0.21777 -0.29756 -0.1351 0.59898 0.46529 -0.58258 -0.02323 -1.5442 0.01901 -0.015877 0.024499 -0.58017 -0.67659 -0.040379 -0.44043 0.083292 0.20035 -0.75499 0.16918 -0.26573 -0.52878 0.17584 1.065',\n","  '0.15541 0.38608 0.34359 0.0097512 0.27924 -0.054375 -0.43069 0.3813 0.23443 0.34265 -0.16119 -0.17161 -0.29524 -0.35995 0.83795 -1.1666 0.24115 -0.038695 0.424 0.79087 0.25585 0.0088783 0.035978 1.1443 -0.87749 -1.0095 0.21284 -1.0325 -1.0476 -0.67332 0.71657 0.84415 0.13099 -0.63803 0.074175 0.25513 0.18213 0.80384 0.16256 -0.17716 0.039664 -0.96388 -0.47882 0.40761 -0.12361 -0.32895 -0.0090602 -0.30753 -0.77032 -1.3028 -0.51525 -0.53606 -0.0087068 0.83454 0.052746 -1.329 0.6281 -1.3599 2.0209 0.23077 0.51271 -0.97311 -0.57712 -0.30825 0.70207 -0.36143 0.29529 -0.57122 1.3864 -0.64602 0.11111 -0.071344 -0.23003 -0.019121 0.16027 0.0049144 -0.035267 -0.33258 -0.84458 0.2186 0.77075 1.1133 0.036489 -0.89003 -0.91214 -0.44888 -0.61923 -1.3474 9.1482E-5 -0.18369 -0.46682 -0.17937 0.46453 -0.91704 -1.0289 -0.203 0.70534 0.36188 0.78783 -0.66761',\n","  '0.23745 0.1241 0.6252 -0.46639 0.12238 -0.03638 0.63611 0.59247 -0.51344 0.06342 0.13814 0.15193 0.094313 -0.20548 0.023568 0.091028 -0.089488 -0.29624 -0.52466 -0.028628 0.87168 -0.16307 -0.06663 1.022 0.44789 -0.48008 -0.17092 -0.30576 -0.061999 -0.23902 0.25188 -0.018878 0.084057 -0.045508 -0.38034 0.45911 -0.4122 0.39722 -0.33249 0.031747 -0.54668 -0.093553 0.67786 0.006941 0.20718 0.075996 0.49682 -0.92707 0.3506 -1.0986 -0.074723 -0.62458 0.31857 1.2155 -0.47096 -2.9422 -0.76529 -0.11556 1.9006 1.0152 -0.49471 0.61459 -0.25465 -0.0065357 0.17702 0.14239 0.18148 0.69493 -0.028739 -0.083564 0.009709 -0.18764 -0.72949 -0.26976 -0.47262 0.23738 -0.38301 -0.017983 -1.4596 0.34242 0.83223 -0.1178 -0.28637 0.35349 -1.2153 -0.37696 0.36761 0.16653 -0.22993 -0.25607 0.19118 0.055805 -0.40315 0.43574 -0.82909 0.3665 -0.14267 0.30254 0.42477 -0.2106',\n","  '0.44234 0.48431 0.37284 -0.52861 0.21558 -0.4629 0.60307 0.71816 -0.41382 0.15157 -0.02936 -0.012905 0.24569 -0.02638 2.8137E-4 -0.41139 0.16784 -0.094465 -0.39723 0.25608 0.39144 -0.14293 0.1543 1.1509 0.51744 -0.4226 -0.07987 -0.77108 0.078489 -0.49301 -0.14824 0.16366 0.23525 -0.32219 -0.50613 0.68354 -0.39673 0.48081 -0.59104 -0.19323 -0.28618 -0.16291 0.48853 0.037437 0.039265 0.02585 0.47258 -1.3542 0.026895 -1.2436 -0.13284 -0.9807 0.39823 1.1715 -0.49008 -2.8411 -0.1709 -0.2184 2.0011 0.59575 -0.36505 0.7859 -0.45694 0.070966 0.18904 0.22404 0.060091 0.050271 0.82711 -0.24997 0.46051 -0.11298 -1.0912 0.14487 -0.83451 0.12452 -0.26793 0.02768 -1.4872 -0.1812 0.8862 -0.053061 -0.49827 0.31571 -1.1596 -0.18781 0.15968 -0.57221 -0.047602 -0.32081 -0.070405 0.36944 -0.42656 -0.080083 -0.87588 0.28568 0.099353 0.38253 0.47456 -0.6505',\n","  '-0.33979 0.20941 0.46348 -0.64792 -0.38377 0.038034 0.17127 0.15978 0.46619 -0.019169 0.41479 -0.34349 0.26872 0.04464 0.42131 -0.41032 0.15459 0.022239 -0.64653 0.25256 0.043136 -0.19445 0.46516 0.45651 0.68588 0.091295 0.21875 -0.70351 0.16785 -0.35079 -0.12634 0.66384 -0.2582 0.036542 -0.13605 0.40253 0.14289 0.38132 -0.12283 -0.45886 -0.25282 -0.30432 -0.11215 -0.26182 -0.22482 -0.44554 0.2991 -0.85612 -0.14503 -0.49086 0.0082973 -0.17491 0.27524 1.4401 -0.21239 -2.8435 -0.27958 -0.45722 1.6386 0.78808 -0.55262 0.65 0.086426 0.39012 1.0632 -0.35379 0.48328 0.346 0.84174 0.098707 -0.24213 -0.27053 0.045287 -0.40147 0.11395 0.0062226 0.036673 0.018518 -1.0213 -0.20806 0.64072 -0.068763 -0.58635 0.33476 -1.1432 -0.1148 -0.25091 -0.45907 -0.096819 -0.17946 -0.063351 -0.67412 -0.068895 0.53604 -0.87773 0.31802 -0.39242 -0.23394 0.47298 -0.028803']}"]},"execution_count":94,"metadata":{},"output_type":"execute_result"}],"source":["annotate_results_emb = light_model_emb.annotate(sample_text)\n","annotate_results_emb"]}],"metadata":{"colab":{"provenance":[{"file_id":"1iNYzzoUpnKq4LromhNrZCVrs9A8xxlX0","timestamp":1672216149968},{"file_id":"https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/14.Transformers_for_Token_Classification_in_Spark_NLP.ipynb","timestamp":1672124045161}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
