{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNDCwuF0Ug8mbHBSiHCumTp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"],"metadata":{"id":"IpA6M_eNO9Xx"}},{"cell_type":"markdown","source":["# **TokenAssembler**"],"metadata":{"id":"NJwoqjEcO-Yk"}},{"cell_type":"markdown","source":["This notebook will cover the different parameters and usages of `TokenAssembler`. \n","\n","**📖 Learning Objectives:**\n","\n","1. Understand how it reconstructs a DOCUMENT type annotation from tokens.\n","\n","3. Become comfortable using the different parameters of the annotator.\n","\n","\n","**🔗 Helpful Links:**\n","\n","- Documentation : [TokenAssembler](https://nlp.johnsnowlabs.com/docs/en/annotators#tokenassembler)\n","\n","- Scala Docs : [TokenAssembler](https://nlp.johnsnowlabs.com/api/com/johnsnowlabs/nlp/TokenAssembler)\n","\n","- For extended examples of usage, see the [Spark NLP Workshop repository](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb)."],"metadata":{"id":"iRr-KJTzPGhe"}},{"cell_type":"markdown","source":["## **📜 Background**"],"metadata":{"id":"2gf9CBG-PH2o"}},{"cell_type":"markdown","source":["This transformer reconstructs a DOCUMENT type annotation from tokens, usually after these have been normalized, lemmatized, normalized, spell checked, etc, in order to use this document annotation in further annotators."],"metadata":{"id":"BT0mICDNPMbF"}},{"cell_type":"markdown","source":["## **🎬 Colab Setup**"],"metadata":{"id":"iT-Y2ujXPNQT"}},{"cell_type":"code","source":["!pip install -q pyspark==3.1.2  spark-nlp==4.2.4"],"metadata":{"id":"Iqhc7IyfDIYM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673448427598,"user_tz":-330,"elapsed":33606,"user":{"displayName":"Arshaan","userId":"17964254249366085303"}},"outputId":"5f5e0a5a-43cd-4d0c-e637-a43ed01e1a8b"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.4/212.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m448.4/448.4 KB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.6/198.6 KB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["import sparknlp\n","from sparknlp.base import *\n","from sparknlp.annotator import *\n","from pyspark.sql import functions as F\n","\n","spark = sparknlp.start()\n","spark"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":219},"id":"RRH_zjV9DOZD","executionInfo":{"status":"ok","timestamp":1673448473634,"user_tz":-330,"elapsed":46049,"user":{"displayName":"Arshaan","userId":"17964254249366085303"}},"outputId":"db3b7b4b-01be-4248-a61e-a41fa0f9d28a"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<pyspark.sql.session.SparkSession at 0x7fb93c98d220>"],"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://ebd9b536d197:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.1.2</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>Spark NLP</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","source":["## **🖨️ Input/Output Annotation Types**"],"metadata":{"id":"lOMlMeNgPTLS"}},{"cell_type":"markdown","source":["- Input: `DOCUMENT`,`TOKEN`\n","\n","- Output: `DOCUMENT`"],"metadata":{"id":"lLymcMYCPZlc"}},{"cell_type":"markdown","source":["## **🔎 Parameters**"],"metadata":{"id":"K4K7EZA_PgxG"}},{"cell_type":"markdown","source":["*  `PreservePosition` (*Boolean*) : Whether to preserve the actual position of the tokens or reduce them to one space (Default: false).\n","\n"],"metadata":{"id":"YLhaWRtlDmZk"}},{"cell_type":"code","source":["# First, the text is tokenized and cleaned\n","documentAssembler = DocumentAssembler() \\\n","    .setInputCol(\"text\") \\\n","    .setOutputCol(\"document\")\n","\n","sentenceDetector = SentenceDetector() \\\n","    .setInputCols([\"document\"]) \\\n","    .setOutputCol(\"sentences\")\n","\n","tokenizer = Tokenizer() \\\n","    .setInputCols([\"sentences\"]) \\\n","    .setOutputCol(\"token\")\n","\n","normalizer = Normalizer() \\\n","    .setInputCols([\"token\"]) \\\n","    .setOutputCol(\"normalized\") \\\n","    .setLowercase(False)\n","\n","stopwordsCleaner = StopWordsCleaner() \\\n","    .setInputCols([\"normalized\"]) \\\n","    .setOutputCol(\"cleanTokens\") \\\n","    .setCaseSensitive(False)\n","\n","# Then the TokenAssembler turns the cleaned tokens into a `DOCUMENT` type structure.\n","tokenAssembler = TokenAssembler() \\\n","    .setInputCols([\"sentences\", \"cleanTokens\"]) \\\n","    .setOutputCol(\"cleanText\")\n","\n","data = spark.createDataFrame([[\"Spark NLP is an open-source text processing library for advanced natural language processing.\"]]) \\\n","    .toDF(\"text\")\n","\n","pipeline = Pipeline().setStages([\n","    documentAssembler,\n","    sentenceDetector,\n","    tokenizer,\n","    normalizer,\n","    stopwordsCleaner,\n","    tokenAssembler\n","]).fit(data)\n","\n","result = pipeline.transform(data)\n","result.select(\"cleanText\").take(1)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3zspSOAdEz1P","executionInfo":{"status":"ok","timestamp":1673448485247,"user_tz":-330,"elapsed":11633,"user":{"displayName":"Arshaan","userId":"17964254249366085303"}},"outputId":"710785b6-a3f4-49de-f443-82e3b7a6c063"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Row(cleanText=[Row(annotatorType='document', begin=0, end=80, result='Spark NLP opensource text processing library advanced natural language processing', metadata={'sentence': '0'}, embeddings=[])])]"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["result.select('text', F.explode(result.cleanText.result).alias('cleanText')).show(truncate=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pvkuY6wf1NTB","executionInfo":{"status":"ok","timestamp":1673448487211,"user_tz":-330,"elapsed":1966,"user":{"displayName":"Arshaan","userId":"17964254249366085303"}},"outputId":"b33f26cf-18d6-4070-e78e-486f94e63e66"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["+---------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------+\n","|text                                                                                         |cleanText                                                                        |\n","+---------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------+\n","|Spark NLP is an open-source text processing library for advanced natural language processing.|Spark NLP opensource text processing library advanced natural language processing|\n","+---------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------+\n","\n"]}]},{"cell_type":"markdown","source":["By default *`PreservePosition = False`*, so the actual position of tokens is not preserved. So it just reconstructs a DOCUMENT type annotation from these tokens after they have been normalized and stopwords being removed."],"metadata":{"id":"UdbEcBqwJFDe"}},{"cell_type":"markdown","source":["\n","➤  PreservePosition : True\n"],"metadata":{"id":"CHH4P64HI2AH"}},{"cell_type":"code","source":["# Setting PreservePosition as True\n","tokenAssembler = TokenAssembler() \\\n","    .setInputCols([\"sentences\", \"cleanTokens\"]) \\\n","    .setOutputCol(\"cleanText\")\\\n","    .setPreservePosition(True)\n","\n","data = spark.createDataFrame([[\"Spark NLP is an open-source text processing library for advanced natural language processing.\"]]) \\\n","    .toDF(\"text\")\n","\n","pipeline = Pipeline().setStages([\n","    documentAssembler,\n","    sentenceDetector,\n","    tokenizer,\n","    normalizer,\n","    stopwordsCleaner,\n","    tokenAssembler\n","]).fit(data)\n","\n","result = pipeline.transform(data)\n","result.select(\"cleanText\").take(1)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I9nMr-W6HkE3","executionInfo":{"status":"ok","timestamp":1673448489697,"user_tz":-330,"elapsed":2491,"user":{"displayName":"Arshaan","userId":"17964254249366085303"}},"outputId":"d833a248-f97d-4fe0-e555-7fbb43d0b658"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Row(cleanText=[Row(annotatorType='document', begin=0, end=83, result='Spark NLP   opensource text processing library  advanced natural language processing', metadata={'sentence': '0'}, embeddings=[])])]"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["result.select('text', F.explode(result.cleanText.result).alias('cleanText')).show(truncate=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kA162Cij2Gn6","executionInfo":{"status":"ok","timestamp":1673448490406,"user_tz":-330,"elapsed":714,"user":{"displayName":"Arshaan","userId":"17964254249366085303"}},"outputId":"71f02ff0-0e47-4bdb-ff92-4cb1caf27685"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["+---------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------+\n","|text                                                                                         |cleanText                                                                           |\n","+---------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------+\n","|Spark NLP is an open-source text processing library for advanced natural language processing.|Spark NLP   opensource text processing library  advanced natural language processing|\n","+---------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------+\n","\n"]}]},{"cell_type":"markdown","source":["Here as *`PreservePosition = True`*, we can see in the result that the actual position of the tokens has been preserved."],"metadata":{"id":"QpfQZ-a4J0GM"}},{"cell_type":"markdown","source":["### Checking for multiple sentences \n"],"metadata":{"id":"a2XziPaCmN4Y"}},{"cell_type":"code","source":["!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/jupyter/annotation/english/spark-nlp-basics/sample-sentences-en.txt"],"metadata":{"id":"j1ek1rrXgM0K","executionInfo":{"status":"ok","timestamp":1673448491629,"user_tz":-330,"elapsed":1229,"user":{"displayName":"Arshaan","userId":"17964254249366085303"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["with open('./sample-sentences-en.txt') as f:\n","  print (f.read())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DtvNKIyXheYq","executionInfo":{"status":"ok","timestamp":1673448491630,"user_tz":-330,"elapsed":8,"user":{"displayName":"Arshaan","userId":"17964254249366085303"}},"outputId":"0070c7c7-02e8-485d-ed4b-d53eb4e958d6"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Peter is a very good person.\n","My life in Russia is very interesting.\n","John and Peter are brothers. However they don't support each other that much.\n","Lucas Nogal Dunbercker is no longer happy. He has a good car though.\n","Europe is very culture rich. There are huge churches! and big houses!\n"]}]},{"cell_type":"code","source":["#Loading data\n","spark_df = spark.read.text('./sample-sentences-en.txt').toDF('text')\n","\n","spark_df.show(truncate=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"stTgs7J3hgwj","executionInfo":{"status":"ok","timestamp":1673448492529,"user_tz":-330,"elapsed":904,"user":{"displayName":"Arshaan","userId":"17964254249366085303"}},"outputId":"09afe30a-1f00-4485-c38f-643dbdf8cc01"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------------------------------------------------------------------------+\n","|text                                                                         |\n","+-----------------------------------------------------------------------------+\n","|Peter is a very good person.                                                 |\n","|My life in Russia is very interesting.                                       |\n","|John and Peter are brothers. However they don't support each other that much.|\n","|Lucas Nogal Dunbercker is no longer happy. He has a good car though.         |\n","|Europe is very culture rich. There are huge churches! and big houses!        |\n","+-----------------------------------------------------------------------------+\n","\n"]}]},{"cell_type":"markdown","source":["\n","\n","➤  With Sentence Detector"],"metadata":{"id":"_XZ9K2i4oXre"}},{"cell_type":"code","source":["sentenceDetector = SentenceDetector() \\\n","    .setInputCols([\"document\"]) \\\n","    .setOutputCol(\"sentences\")\n","\n","\n","# Setting PreservePosition as True\n","tokenAssembler = TokenAssembler() \\\n","    .setInputCols([\"sentences\", \"cleanTokens\"]) \\\n","    .setOutputCol(\"cleanText\")\\\n","    .setPreservePosition(True)\n","\n","\n","pipeline = Pipeline().setStages([\n","    documentAssembler,\n","    sentenceDetector,\n","    tokenizer,\n","    normalizer,\n","    stopwordsCleaner,\n","    tokenAssembler\n","]).fit(spark_df)\n","\n","result = pipeline.transform(spark_df)\n","result.select(\"cleanText\").take(5)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2TqDZhXxhtz0","executionInfo":{"status":"ok","timestamp":1673448493892,"user_tz":-330,"elapsed":1369,"user":{"displayName":"Arshaan","userId":"17964254249366085303"}},"outputId":"00273c4f-5496-4796-94f2-ccd6191e5c2c"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Row(cleanText=[Row(annotatorType='document', begin=0, end=19, result='Peter    good person', metadata={'sentence': '0'}, embeddings=[])]),\n"," Row(cleanText=[Row(annotatorType='document', begin=0, end=25, result='life  Russia   interesting', metadata={'sentence': '0'}, embeddings=[])]),\n"," Row(cleanText=[Row(annotatorType='document', begin=0, end=20, result='John  Peter  brothers', metadata={'sentence': '0'}, embeddings=[]), Row(annotatorType='document', begin=29, end=57, result='However  dont support    much', metadata={'sentence': '1'}, embeddings=[])]),\n"," Row(cleanText=[Row(annotatorType='document', begin=0, end=36, result='Lucas Nogal Dunbercker   longer happy', metadata={'sentence': '0'}, embeddings=[]), Row(annotatorType='document', begin=43, end=57, result='good car though', metadata={'sentence': '1'}, embeddings=[])]),\n"," Row(cleanText=[Row(annotatorType='document', begin=0, end=20, result='Europe   culture rich', metadata={'sentence': '0'}, embeddings=[]), Row(annotatorType='document', begin=29, end=41, result='huge churches', metadata={'sentence': '1'}, embeddings=[]), Row(annotatorType='document', begin=54, end=63, result='big houses', metadata={'sentence': '2'}, embeddings=[])])]"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["result.select('text', F.explode(result.cleanText.result).alias('cleanText')).show(truncate=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3wPJPt2Yh5mp","executionInfo":{"status":"ok","timestamp":1673448494307,"user_tz":-330,"elapsed":420,"user":{"displayName":"Arshaan","userId":"17964254249366085303"}},"outputId":"fd53c90b-0d68-4d4c-89db-0d1247ff5ab5"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------------------------------------------------------------------------+-------------------------------------+\n","|text                                                                         |cleanText                            |\n","+-----------------------------------------------------------------------------+-------------------------------------+\n","|Peter is a very good person.                                                 |Peter    good person                 |\n","|My life in Russia is very interesting.                                       |life  Russia   interesting           |\n","|John and Peter are brothers. However they don't support each other that much.|John  Peter  brothers                |\n","|John and Peter are brothers. However they don't support each other that much.|However  dont support    much        |\n","|Lucas Nogal Dunbercker is no longer happy. He has a good car though.         |Lucas Nogal Dunbercker   longer happy|\n","|Lucas Nogal Dunbercker is no longer happy. He has a good car though.         |good car though                      |\n","|Europe is very culture rich. There are huge churches! and big houses!        |Europe   culture rich                |\n","|Europe is very culture rich. There are huge churches! and big houses!        |huge churches                        |\n","|Europe is very culture rich. There are huge churches! and big houses!        |big houses                           |\n","+-----------------------------------------------------------------------------+-------------------------------------+\n","\n"]}]},{"cell_type":"markdown","source":["As we have used *`Sentence Detector`* in our pipleine, it detects the sentence boundaries and we get cleanText for each of them separately. In the metadata we can see that after detecting sentences, it assigns a sentence number to it, with first sentence being initialized as 0. Also as the PreservePosition is set as True, the actual position of tokens has been preserved."],"metadata":{"id":"5NpPdOL2mkQ1"}},{"cell_type":"code","source":["import pyspark.sql.functions as F\n","\n","result.select(\"text\").show(truncate=False)\n","\n","result.withColumn(\n","    \"tmp\", \n","    F.explode(\"cleanText\")) \\\n","    .select(\"tmp.*\").select(\"begin\",\"end\",\"result\",\"metadata.sentence\").show(truncate = False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ua6jdo8mpZtJ","executionInfo":{"status":"ok","timestamp":1673448496304,"user_tz":-330,"elapsed":2006,"user":{"displayName":"Arshaan","userId":"17964254249366085303"}},"outputId":"dc6ec8c3-948f-491c-aa06-bf1a25907d5d"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------------------------------------------------------------------------+\n","|text                                                                         |\n","+-----------------------------------------------------------------------------+\n","|Peter is a very good person.                                                 |\n","|My life in Russia is very interesting.                                       |\n","|John and Peter are brothers. However they don't support each other that much.|\n","|Lucas Nogal Dunbercker is no longer happy. He has a good car though.         |\n","|Europe is very culture rich. There are huge churches! and big houses!        |\n","+-----------------------------------------------------------------------------+\n","\n","+-----+---+-------------------------------------+--------+\n","|begin|end|result                               |sentence|\n","+-----+---+-------------------------------------+--------+\n","|0    |19 |Peter    good person                 |0       |\n","|0    |25 |life  Russia   interesting           |0       |\n","|0    |20 |John  Peter  brothers                |0       |\n","|29   |57 |However  dont support    much        |1       |\n","|0    |36 |Lucas Nogal Dunbercker   longer happy|0       |\n","|43   |57 |good car though                      |1       |\n","|0    |20 |Europe   culture rich                |0       |\n","|29   |41 |huge churches                        |1       |\n","|54   |63 |big houses                           |2       |\n","+-----+---+-------------------------------------+--------+\n","\n"]}]},{"cell_type":"markdown","source":["Sentence boundaries within the text were detected.\n","\n","For Example, we had the following text: \n","\n","*John and Peter are brothers. However they don't support each other that much.*\n","\n","John  Peter  brothers  ▶  metadata={'sentence': '0'}\n","\n","However  dont support    much ▶ metadata={'sentence': '1'}\n","\n"],"metadata":{"id":"7na0H1femUsm"}},{"cell_type":"markdown","source":["\n","➤  Without Sentence Detector"],"metadata":{"id":"tFEduvRiogiv"}},{"cell_type":"code","source":["# if we hadn't used Sentence Detector, this would be what we got. (tokenizer gets document instead of sentences column)\n","tokenizer = Tokenizer() \\\n","    .setInputCols([\"document\"]) \\\n","    .setOutputCol(\"token\")\n","\n","tokenassembler = TokenAssembler()\\\n","    .setInputCols([\"document\", \"cleanTokens\"]) \\\n","    .setOutputCol(\"cleanText\")\\\n","    .setPreservePosition(True)\n","\n","nlpPipeline = Pipeline(stages=[documentAssembler,\n","                               tokenizer,\n","                               normalizer,\n","                               stopwordsCleaner,\n","                               tokenassembler])\n","\n","result = nlpPipeline.fit(spark_df).transform(spark_df)\n","result.select(\"cleanText\").take(5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OiQk_w_OiHu9","executionInfo":{"status":"ok","timestamp":1673448496304,"user_tz":-330,"elapsed":8,"user":{"displayName":"Arshaan","userId":"17964254249366085303"}},"outputId":"e072a4b1-90c3-4545-eaf4-6a36f1990081"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Row(cleanText=[Row(annotatorType='document', begin=0, end=19, result='Peter    good person', metadata={'sentence': '0'}, embeddings=[])]),\n"," Row(cleanText=[Row(annotatorType='document', begin=0, end=25, result='life  Russia   interesting', metadata={'sentence': '0'}, embeddings=[])]),\n"," Row(cleanText=[Row(annotatorType='document', begin=0, end=50, result='John  Peter  brothers However  dont support    much', metadata={'sentence': '0'}, embeddings=[])]),\n"," Row(cleanText=[Row(annotatorType='document', begin=0, end=55, result='Lucas Nogal Dunbercker   longer happy    good car though', metadata={'sentence': '0'}, embeddings=[])]),\n"," Row(cleanText=[Row(annotatorType='document', begin=0, end=48, result='Europe   culture rich   huge churches  big houses', metadata={'sentence': '0'}, embeddings=[])])]"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["result.select('text', F.explode(result.cleanText.result).alias('cleanText')).show(truncate=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mvVG6f6oiTQz","executionInfo":{"status":"ok","timestamp":1673448496989,"user_tz":-330,"elapsed":690,"user":{"displayName":"Arshaan","userId":"17964254249366085303"}},"outputId":"7ead193c-0afb-4c02-cc8f-a134ce452845"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------------------------------------------------------------------------+--------------------------------------------------------+\n","|text                                                                         |cleanText                                               |\n","+-----------------------------------------------------------------------------+--------------------------------------------------------+\n","|Peter is a very good person.                                                 |Peter    good person                                    |\n","|My life in Russia is very interesting.                                       |life  Russia   interesting                              |\n","|John and Peter are brothers. However they don't support each other that much.|John  Peter  brothers However  dont support    much     |\n","|Lucas Nogal Dunbercker is no longer happy. He has a good car though.         |Lucas Nogal Dunbercker   longer happy    good car though|\n","|Europe is very culture rich. There are huge churches! and big houses!        |Europe   culture rich   huge churches  big houses       |\n","+-----------------------------------------------------------------------------+--------------------------------------------------------+\n","\n"]}]},{"cell_type":"markdown","source":["Without using a *`Sentence Detector`* in our pipleine, sentence boundaries are not detected. It treats it as a single sentence. Also as the PreservePosition is set as True, the actual position of tokens has been preserved."],"metadata":{"id":"0cVHFwJKrEos"}},{"cell_type":"code","source":["import pyspark.sql.functions as F\n","\n","result.select(\"text\").show(truncate=False)\n","\n","result.withColumn(\n","    \"tmp\", \n","    F.explode(\"cleanText\")) \\\n","    .select(\"tmp.*\").select(\"begin\",\"end\",\"result\",\"metadata.sentence\").show(truncate = False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5Wa4quD_prqS","executionInfo":{"status":"ok","timestamp":1673448497411,"user_tz":-330,"elapsed":427,"user":{"displayName":"Arshaan","userId":"17964254249366085303"}},"outputId":"36f825f9-d2a1-4c14-f45d-f4e79efb4c50"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------------------------------------------------------------------------+\n","|text                                                                         |\n","+-----------------------------------------------------------------------------+\n","|Peter is a very good person.                                                 |\n","|My life in Russia is very interesting.                                       |\n","|John and Peter are brothers. However they don't support each other that much.|\n","|Lucas Nogal Dunbercker is no longer happy. He has a good car though.         |\n","|Europe is very culture rich. There are huge churches! and big houses!        |\n","+-----------------------------------------------------------------------------+\n","\n","+-----+---+--------------------------------------------------------+--------+\n","|begin|end|result                                                  |sentence|\n","+-----+---+--------------------------------------------------------+--------+\n","|0    |19 |Peter    good person                                    |0       |\n","|0    |25 |life  Russia   interesting                              |0       |\n","|0    |50 |John  Peter  brothers However  dont support    much     |0       |\n","|0    |55 |Lucas Nogal Dunbercker   longer happy    good car though|0       |\n","|0    |48 |Europe   culture rich   huge churches  big houses       |0       |\n","+-----+---+--------------------------------------------------------+--------+\n","\n"]}]},{"cell_type":"markdown","source":["Sentence boundaries within the text were not detected and considered as a single sentence."],"metadata":{"id":"L3QQv8lel5Rq"}},{"cell_type":"markdown","source":["`IMPORTANT NOTE`:\n","\n","If you have some other steps & annotators in your pipeline that will need to use the tokens from cleaned text (assembled tokens), you will need to tokenize the processed text again as the original text is probably changed completely."],"metadata":{"id":"8TgjbBq-1vG3"}}]}