{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"sXatvRX899i0"},"source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Open_Source/02.05.NorvigSweetingSpellchecker.ipynb.ipynb)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"AOn8d1tcBkK3"},"source":["# **NorvigSweetingApproach** and **NorvigSweetingModel**"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"WimihSwD3vtH"},"source":["This notebook will cover the different parameters and usages of `NorvigSweetingApproach` and `NorvigSweetingModel`. These annotators are used to make corrections to tokens automatically if they are not found in an English dictionary.\n","\n","**üìñ Learning Objectives:**\n","\n","1. Understand how to check spelling using NorvigSweeting annotators.\n","\n","2. Understand the difference between `NorvigSweetingApproach` and `NorvigSweetingModel`.\n","\n","3. Customize the use of these annotators by setting their parameters.\n","\n","\n","**üîó Helpful Links:**\n","\n","- Documentation : [NorvigSweeting Spellchecker](https://nlp.johnsnowlabs.com/docs/en/annotators#norvigsweeting-spellchecker)\n","\n","- Python Docs : [NorvigSweetingApproach](https://nlp.johnsnowlabs.com/api/python/reference/autosummary/python/sparknlp/annotator/spell_check/norvig_sweeting/index.html#sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach), [NorvigSweetingModel](https://nlp.johnsnowlabs.com/api/python/reference/autosummary/python/sparknlp/annotator/spell_check/norvig_sweeting/index.html#sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingModel)\n","\n","- Scala Docs : [NorvigSweetingApproach](https://nlp.johnsnowlabs.com/api/com/johnsnowlabs/nlp/annotators/spell/norvig/NorvigSweetingApproach), [NorvigSweetingModel](https://nlp.johnsnowlabs.com/api/com/johnsnowlabs/nlp/annotators/spell/norvig/NorvigSweetingModel)\n","\n","- For extended examples of usage, see the [Spark NLP Workshop repository](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/training/english/vivekn-sentiment/VivekNarayanSentimentApproach.ipynb)."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"qL9lcISyFSLv"},"source":["## **üìú Background**\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"TjDKOoZ4Fc8G"},"source":["These annotators retrieve tokens and make corrections automatically if they are not found in an external dictionary. They are inspired by Norvig model and [SymSpell](https://github.com/wolfgarbe/SymSpell).\n","\n","The Symmetric Delete spelling correction algorithm reduces the complexity of edit candidate generation and dictionary lookup for a given Damerau-Levenshtein distance. It is six orders of magnitude faster (than the standard approach with deletes + transposes + replaces + inserts) and language independent.\n","\n","- `NorvigSweetingApproach` is used to train your own spellchecker model. A dictionary of correct spellings must be provided as a text file, and each word is then parsed by a regex pattern.\n","- `NorvigSweetingModel` is the instantiated model of the `NorvigSweetingApproach`. Pretrained models can be loaded using this annotator. If no pretrained model name is provided, the `spellcheck_norvig` is used by default. For available pretrained models please see the [Models Hub](https://nlp.johnsnowlabs.com/models?task=Spell+Check).\n","\n","For alternative approaches to spellchecking, refer to [SymmetricDelete annotator](https://nlp.johnsnowlabs.com/docs/en/annotators#symmetricdelete) or [ContextSpellChecker annotator](https://nlp.johnsnowlabs.com/docs/en/annotators#contextspellchecker)."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"MfkkKkbVF309"},"source":["## **üé¨ Colab Setup**"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24843,"status":"ok","timestamp":1673294605354,"user":{"displayName":"Mauro Nievas Offidani","userId":"07990177195800485445"},"user_tz":180},"id":"iMkMQtZNF2n-","outputId":"aa84e52e-e21a-4880-e8c0-3b6259221aa0"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m212.4/212.4 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m448.4/448.4 KB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m198.6/198.6 KB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install -q pyspark==3.1.2  spark-nlp==4.2.4"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":46170,"status":"ok","timestamp":1673294651512,"user":{"displayName":"Mauro Nievas Offidani","userId":"07990177195800485445"},"user_tz":180},"id":"NulWi4_f4GN5"},"outputs":[],"source":["import sparknlp\n","from sparknlp.base import *\n","from sparknlp.annotator import *\n","from pyspark.ml import Pipeline\n","from pyspark.sql.functions import col\n","\n","spark = sparknlp.start()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"9Fbbk1bqcuA5"},"source":["## **üñ®Ô∏è Input/Output Annotation Types**"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"0yFIrr5acsiU"},"source":["- Input: `TOKEN`\n","\n","- Output: `TOKEN` (misspelled words are replaced by their correct form and the metadata includes the confidence score of the spelling correction)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"b2YJehUKMhb0"},"source":["## **üîé Parameters**\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"oidLDoS94asU"},"source":["- `caseSensitive`: (Boolean) Sensitivity on spell checking (Default: True). Might affect accuracy.\n","\n","- `dictionary`: (String) Path to .txt file with external dictionary. External dictionary to be used needs \"tokenPattern\" (Default: \\S+) for parsing the resource. This parameter only applies to `NorvigSweetingApproach`.\n","\n","  Example:\n","\n","\n","```\n","...\n","gummy\n","gummic\n","gummier\n","gummiest\n","gummiferous\n","...\n","```\n","- `doubleVariants`: (Boolean) Increase search at cost of performance (Default: false). Enables extra check for word combinations. More accuracy at performance.\n","\n","- `dupsLimit`: (Int) Maximum duplicate of characters in a word to consider (Default: 2).\n","\n","- `frequencyPriority`: (Boolean) Applies frequency over hamming in intersections (Default: true). When false hamming takes priority.\n","\n","- `intersections`: (Int) Hamming intersections to attempt (Default: 10).\n","\n","- `reductLimit`: (Int) Word reduction limit (Default: 3).\n","\n","- `shortCircuit`: (Boolean) Increase performance at cost of accuracy (Default: false). Faster but less accurate mode.\n","\n","- `vowelSwapLimit`: (Int) Vowel swap attempts (Default: 6).\n","\n","- `wordSizeIgnore`: (Int) Minimum size of word before ignoring (Default: 3)."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"vSMTsrBfinOc"},"source":["## **Examples**"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"sVcaX9eBO1x6"},"source":["### Using a pretrained spellchecker with `NorvigSweetingModel`"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21094,"status":"ok","timestamp":1673294672582,"user":{"displayName":"Mauro Nievas Offidani","userId":"07990177195800485445"},"user_tz":180},"id":"C5IbTr6pO6LM","outputId":"70e17dd6-33cd-4c84-db82-bb36f1873d46"},"outputs":[{"name":"stdout","output_type":"stream","text":["spellcheck_norvig download started this may take some time.\n","Approximate size to download 4.2 MB\n","[OK!]\n","+--------------------------------------+--------------------------------------+\n","|before_spellchecker                   |after_spellchecker                    |\n","+--------------------------------------+--------------------------------------+\n","|[somtimes, i, wrrite, wordz, erong, .]|[sometimes, i, write, words, wrong, .]|\n","+--------------------------------------+--------------------------------------+\n","\n"]}],"source":["documentAssembler = DocumentAssembler() \\\n",".setInputCol(\"text\") \\\n",".setOutputCol(\"document\")\n","\n","tokenizer = Tokenizer() \\\n",".setInputCols([\"document\"]) \\\n",".setOutputCol(\"token\")\n","\n","# \"spellcheck_norvig\" can be omitted, as it is the default value\n","spellChecker = NorvigSweetingModel.pretrained(\"spellcheck_norvig\")\\\n",".setInputCols([\"token\"]) \\\n",".setOutputCol(\"spell\")\n","\n","pipeline = Pipeline().setStages([\n","documentAssembler,\n","tokenizer,\n","spellChecker\n","])\n","\n","data = spark.createDataFrame([[\"somtimes i wrrite wordz erong.\"]]).toDF(\"text\")\n","result = pipeline.fit(data).transform(data)\n","result.select(col('token.result').alias(\"before_spellchecker\"), col('spell.result').alias(\"after_spellchecker\")).show(truncate = False)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Sf4k15g8jxgs"},"source":["### Training a spellchecker using `NorvigSweetingApproach`"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":23,"status":"ok","timestamp":1673294672583,"user":{"displayName":"Mauro Nievas Offidani","userId":"07990177195800485445"},"user_tz":180},"id":"HkQhdR4YHICg"},"outputs":[],"source":["# Dictionary creation\n","\n","external_dict = '''\n","dog\n","fish\n","horse\n","'''\n","\n","with open('external_dict.txt', 'w') as f:\n","  f.write(external_dict)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3121,"status":"ok","timestamp":1673294675683,"user":{"displayName":"Mauro Nievas Offidani","userId":"07990177195800485445"},"user_tz":180},"id":"L3P8k9e5imHR","outputId":"a63b4352-e4ac-42ee-8d0f-6ff97f080ff8"},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------------------------+-------------------------+\n","|before_spellchecker       |after_spellchecker       |\n","+--------------------------+-------------------------+\n","|[The, dogh, is, eating, .]|[The, dog, is, eating, .]|\n","+--------------------------+-------------------------+\n","\n"]}],"source":["documentAssembler = DocumentAssembler() \\\n","    .setInputCol(\"text\") \\\n","    .setOutputCol(\"document\")\n","\n","tokenizer = Tokenizer() \\\n","    .setInputCols([\"document\"]) \\\n","    .setOutputCol(\"token\")\n","\n","spellChecker = NorvigSweetingApproach() \\\n","    .setInputCols([\"token\"]) \\\n","    .setOutputCol(\"spell\") \\\n","    .setDictionary(\"external_dict.txt\")\n","\n","pipeline = Pipeline().setStages([\n","    documentAssembler,\n","    tokenizer,\n","    spellChecker\n","])\n","\n","empty_df = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n","\n","spellcheck_model = pipeline.fit(empty_df)\n","\n","text_df = spark.createDataFrame([[\"The dogh is eating.\"]]).toDF(\"text\")\n","\n","corrected_text = spellcheck_model.transform(text_df)\n","\n","corrected_text.select(col('token.result').alias(\"before_spellchecker\"), col('spell.result').alias(\"after_spellchecker\")).show(truncate = False)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"o-1Jp-MT1ysY"},"source":["Based on the external dictionary, the spellchecker identified the misspelled word \"dogh\" and replaced it by \"dog\"."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"cFX52oPxuKBZ"},"source":["### setCaseSensitive"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1673294675684,"user":{"displayName":"Mauro Nievas Offidani","userId":"07990177195800485445"},"user_tz":180},"id":"YfME9V7OHS4_"},"outputs":[],"source":["capital_external_dict = '''\n","Dog\n","Fish\n","Horse\n","'''\n","\n","with open('capital_external_dict.txt', 'w') as f:\n","  f.write(capital_external_dict)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3084,"status":"ok","timestamp":1673294678758,"user":{"displayName":"Mauro Nievas Offidani","userId":"07990177195800485445"},"user_tz":180},"id":"6Y2Llz63vttb","outputId":"61ea952d-0a93-4a60-9917-343e00d5dbf4"},"outputs":[{"name":"stdout","output_type":"stream","text":["+---------------------------------------+--------------------------------------+--------------------------------------+\n","|before_spellchecker                    |case_sensitive_false                  |case_sensitive_true                   |\n","+---------------------------------------+--------------------------------------+--------------------------------------+\n","|[The, name, of, the, dogh, is, Dogh, .]|[The, name, of, the, dog, is, Dogh, .]|[The, name, of, the, dogh, is, Dog, .]|\n","+---------------------------------------+--------------------------------------+--------------------------------------+\n","\n"]}],"source":["documentAssembler = DocumentAssembler() \\\n","    .setInputCol(\"text\") \\\n","    .setOutputCol(\"document\")\n","\n","tokenizer = Tokenizer() \\\n","    .setInputCols([\"document\"]) \\\n","    .setOutputCol(\"token\")\n","\n","spellChecker_1 = NorvigSweetingApproach() \\\n","    .setInputCols([\"token\"]) \\\n","    .setOutputCol(\"spell_1\") \\\n","    .setDictionary(\"capital_external_dict.txt\") \\\n","    .setCaseSensitive(False)\n","\n","spellChecker_2 = NorvigSweetingApproach() \\\n","    .setInputCols([\"token\"]) \\\n","    .setOutputCol(\"spell_2\") \\\n","    .setDictionary(\"capital_external_dict.txt\") \\\n","    .setCaseSensitive(True)\n","\n","pipeline = Pipeline().setStages([\n","    documentAssembler,\n","    tokenizer,\n","    spellChecker_1,\n","    spellChecker_2\n","])\n","\n","empty_df = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n","\n","spellcheck_model = pipeline.fit(empty_df)\n","\n","text_df = spark.createDataFrame([[\"The name of the dogh is Dogh.\"]]).toDF(\"text\")\n","\n","corrected_text = spellcheck_model.transform(text_df)\n","\n","corrected_text.select(col('token.result').alias(\"before_spellchecker\"), col('spell_1.result').alias(\"case_sensitive_false\"), col('spell_2.result').alias(\"case_sensitive_true\")).show(truncate = False)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"jy7_zFgj1_Vi"},"source":["When caseSensitive is False (default value), the spellchecker ignores the uppercase included in the external dictionary. When it is set to True, only the uppercased version of the word is corrected."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"3RJ361Srv-Tj"},"source":["### setDupsLimit"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2561,"status":"ok","timestamp":1673294681300,"user":{"displayName":"Mauro Nievas Offidani","userId":"07990177195800485445"},"user_tz":180},"id":"Qt_pAJgNwF2y","outputId":"6f554703-c57d-4314-d321-af147d84e9c4"},"outputs":[{"name":"stdout","output_type":"stream","text":["+----------------------------+--------------------------+-------------------------+\n","|before_spellchecker         |dups_limit_1              |dups_limit_0             |\n","+----------------------------+--------------------------+-------------------------+\n","|[It, was, a, goood, dogh, .]|[It, was, a, good, dog, .]|[It, was, a, god, dog, .]|\n","+----------------------------+--------------------------+-------------------------+\n","\n"]}],"source":["documentAssembler = DocumentAssembler() \\\n","    .setInputCol(\"text\") \\\n","    .setOutputCol(\"document\")\n","\n","tokenizer = Tokenizer() \\\n","    .setInputCols([\"document\"]) \\\n","    .setOutputCol(\"token\")\n","\n","spellChecker_1 = NorvigSweetingApproach() \\\n","    .setInputCols([\"token\"]) \\\n","    .setOutputCol(\"spell_1\") \\\n","    .setDictionary(\"external_dict.txt\") \\\n","    .setDupsLimit(1)\n","\n","spellChecker_2 = NorvigSweetingApproach() \\\n","    .setInputCols([\"token\"]) \\\n","    .setOutputCol(\"spell_2\") \\\n","    .setDictionary(\"external_dict.txt\") \\\n","    .setDupsLimit(0)\n","\n","pipeline = Pipeline().setStages([\n","    documentAssembler,\n","    tokenizer,\n","    spellChecker_1,\n","    spellChecker_2\n","])\n","\n","empty_df = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n","\n","spellcheck_model = pipeline.fit(empty_df)\n","\n","text_df = spark.createDataFrame([[\"It was a goood dogh.\"]]).toDF(\"text\")\n","\n","corrected_text = spellcheck_model.transform(text_df)\n","\n","corrected_text.select(col('token.result').alias(\"before_spellchecker\"), col('spell_1.result').alias(\"dups_limit_1\"), col('spell_2.result').alias(\"dups_limit_0\")).show(truncate = False)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"GuZQiVag2Zrp"},"source":["When dupsLimit is 1, the same letter cannot be repeated more than once. When dupsLimit is set to 0, no letter can be repeated (this is why \"goood\" was turned to \"god\")."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"_0aVl_wBwS_x"},"source":["### setWordSizeIgnore"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2323,"status":"ok","timestamp":1673294683616,"user":{"displayName":"Mauro Nievas Offidani","userId":"07990177195800485445"},"user_tz":180},"id":"ProUftZ6wU7G","outputId":"e178cc4b-42ca-452c-901b-dd808895bc49"},"outputs":[{"name":"stdout","output_type":"stream","text":["+---------------------------+--------------------------+---------------------------+\n","|before_spellchecker        |word_size_ignore_3        |word_size_ignore_4         |\n","+---------------------------+--------------------------+---------------------------+\n","|[It, was, a, good, dogh, .]|[It, was, a, good, dog, .]|[It, was, a, good, dogh, .]|\n","+---------------------------+--------------------------+---------------------------+\n","\n"]}],"source":["documentAssembler = DocumentAssembler() \\\n","    .setInputCol(\"text\") \\\n","    .setOutputCol(\"document\")\n","\n","tokenizer = Tokenizer() \\\n","    .setInputCols([\"document\"]) \\\n","    .setOutputCol(\"token\")\n","\n","spellChecker_1 = NorvigSweetingApproach() \\\n","    .setInputCols([\"token\"]) \\\n","    .setOutputCol(\"spell_1\") \\\n","    .setDictionary(\"external_dict.txt\") \\\n","    .setWordSizeIgnore(3)\n","\n","spellChecker_2 = NorvigSweetingApproach() \\\n","    .setInputCols([\"token\"]) \\\n","    .setOutputCol(\"spell_2\") \\\n","    .setDictionary(\"external_dict.txt\") \\\n","    .setWordSizeIgnore(4)\n","\n","pipeline = Pipeline().setStages([\n","    documentAssembler,\n","    tokenizer,\n","    spellChecker_1,\n","    spellChecker_2\n","])\n","\n","empty_df = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n","\n","spellcheck_model = pipeline.fit(empty_df)\n","\n","text_df = spark.createDataFrame([[\"It was a good dogh.\"]]).toDF(\"text\")\n","\n","corrected_text = spellcheck_model.transform(text_df)\n","\n","corrected_text.select(col('token.result').alias(\"before_spellchecker\"), col('spell_1.result').alias(\"word_size_ignore_3\"), col('spell_2.result').alias(\"word_size_ignore_4\")).show(truncate = False)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"H86mS5w02yqG"},"source":["In this example, the misspelled word has 4 characters. The spellchecker with a value for wordSizeIgnore of 4 ignored this token and did not correct its spelling. "]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[{"file_id":"1L8GdQ-yorjVk_V8Um6Rw6aEzFVT31OCO","timestamp":1672941527684},{"file_id":"1VVV4jTagH47UZiKFqXoP-Abq5ozZM1BV","timestamp":1672918708428},{"file_id":"https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb","timestamp":1671914287039}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":0}
