{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"IpA6M_eNO9Xx"},"source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Open_Source/08.04.TokenAssembler.ipynb)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"NJwoqjEcO-Yk"},"source":["# **TokenAssembler**"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"iRr-KJTzPGhe"},"source":["This notebook will cover the different parameters and usages of `TokenAssembler`. \n","\n","**📖 Learning Objectives:**\n","\n","1. Understand how it reconstructs a DOCUMENT type annotation from tokens.\n","\n","3. Become comfortable using the different parameters of the annotator.\n","\n","\n","**🔗 Helpful Links:**\n","\n","- Documentation : [TokenAssembler](https://nlp.johnsnowlabs.com/docs/en/annotators#tokenassembler)\n","\n","- Scala Docs : [TokenAssembler](https://nlp.johnsnowlabs.com/api/com/johnsnowlabs/nlp/TokenAssembler)\n","\n","- For extended examples of usage, see the [Spark NLP Workshop repository](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb)."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"2gf9CBG-PH2o"},"source":["## **📜 Background**"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"BT0mICDNPMbF"},"source":["This transformer reconstructs a DOCUMENT type annotation from tokens, usually after these have been normalized, lemmatized, normalized, spell checked, etc, in order to use this document annotation in further annotators."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"iT-Y2ujXPNQT"},"source":["## **🎬 Colab Setup**"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33606,"status":"ok","timestamp":1673448427598,"user":{"displayName":"Arshaan","userId":"17964254249366085303"},"user_tz":-330},"id":"Iqhc7IyfDIYM","outputId":"5f5e0a5a-43cd-4d0c-e637-a43ed01e1a8b"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.4/212.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m448.4/448.4 KB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.6/198.6 KB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install -q pyspark==3.1.2  spark-nlp==4.2.4"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":219},"executionInfo":{"elapsed":46049,"status":"ok","timestamp":1673448473634,"user":{"displayName":"Arshaan","userId":"17964254249366085303"},"user_tz":-330},"id":"RRH_zjV9DOZD","outputId":"db3b7b4b-01be-4248-a61e-a41fa0f9d28a"},"outputs":[{"data":{"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://ebd9b536d197:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.1.2</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>Spark NLP</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "],"text/plain":["<pyspark.sql.session.SparkSession at 0x7fb93c98d220>"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["import sparknlp\n","from sparknlp.base import *\n","from sparknlp.annotator import *\n","from pyspark.sql import functions as F\n","\n","spark = sparknlp.start()\n","spark"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"lOMlMeNgPTLS"},"source":["## **🖨️ Input/Output Annotation Types**"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"lLymcMYCPZlc"},"source":["- Input: `DOCUMENT`,`TOKEN`\n","\n","- Output: `DOCUMENT`"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"K4K7EZA_PgxG"},"source":["## **🔎 Parameters**"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"YLhaWRtlDmZk"},"source":["*  `PreservePosition` (*Boolean*) : Whether to preserve the actual position of the tokens or reduce them to one space (Default: false).\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11633,"status":"ok","timestamp":1673448485247,"user":{"displayName":"Arshaan","userId":"17964254249366085303"},"user_tz":-330},"id":"3zspSOAdEz1P","outputId":"710785b6-a3f4-49de-f443-82e3b7a6c063"},"outputs":[{"data":{"text/plain":["[Row(cleanText=[Row(annotatorType='document', begin=0, end=80, result='Spark NLP opensource text processing library advanced natural language processing', metadata={'sentence': '0'}, embeddings=[])])]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# First, the text is tokenized and cleaned\n","documentAssembler = DocumentAssembler() \\\n","    .setInputCol(\"text\") \\\n","    .setOutputCol(\"document\")\n","\n","sentenceDetector = SentenceDetector() \\\n","    .setInputCols([\"document\"]) \\\n","    .setOutputCol(\"sentences\")\n","\n","tokenizer = Tokenizer() \\\n","    .setInputCols([\"sentences\"]) \\\n","    .setOutputCol(\"token\")\n","\n","normalizer = Normalizer() \\\n","    .setInputCols([\"token\"]) \\\n","    .setOutputCol(\"normalized\") \\\n","    .setLowercase(False)\n","\n","stopwordsCleaner = StopWordsCleaner() \\\n","    .setInputCols([\"normalized\"]) \\\n","    .setOutputCol(\"cleanTokens\") \\\n","    .setCaseSensitive(False)\n","\n","# Then the TokenAssembler turns the cleaned tokens into a `DOCUMENT` type structure.\n","tokenAssembler = TokenAssembler() \\\n","    .setInputCols([\"sentences\", \"cleanTokens\"]) \\\n","    .setOutputCol(\"cleanText\")\n","\n","data = spark.createDataFrame([[\"Spark NLP is an open-source text processing library for advanced natural language processing.\"]]) \\\n","    .toDF(\"text\")\n","\n","pipeline = Pipeline().setStages([\n","    documentAssembler,\n","    sentenceDetector,\n","    tokenizer,\n","    normalizer,\n","    stopwordsCleaner,\n","    tokenAssembler\n","]).fit(data)\n","\n","result = pipeline.transform(data)\n","result.select(\"cleanText\").take(1)\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1966,"status":"ok","timestamp":1673448487211,"user":{"displayName":"Arshaan","userId":"17964254249366085303"},"user_tz":-330},"id":"pvkuY6wf1NTB","outputId":"b33f26cf-18d6-4070-e78e-486f94e63e66"},"outputs":[{"name":"stdout","output_type":"stream","text":["+---------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------+\n","|text                                                                                         |cleanText                                                                        |\n","+---------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------+\n","|Spark NLP is an open-source text processing library for advanced natural language processing.|Spark NLP opensource text processing library advanced natural language processing|\n","+---------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------+\n","\n"]}],"source":["result.select('text', F.explode(result.cleanText.result).alias('cleanText')).show(truncate=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"UdbEcBqwJFDe"},"source":["By default *`PreservePosition = False`*, so the actual position of tokens is not preserved. So it just reconstructs a DOCUMENT type annotation from these tokens after they have been normalized and stopwords being removed."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"CHH4P64HI2AH"},"source":["\n","➤  PreservePosition : True\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2491,"status":"ok","timestamp":1673448489697,"user":{"displayName":"Arshaan","userId":"17964254249366085303"},"user_tz":-330},"id":"I9nMr-W6HkE3","outputId":"d833a248-f97d-4fe0-e555-7fbb43d0b658"},"outputs":[{"data":{"text/plain":["[Row(cleanText=[Row(annotatorType='document', begin=0, end=83, result='Spark NLP   opensource text processing library  advanced natural language processing', metadata={'sentence': '0'}, embeddings=[])])]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# Setting PreservePosition as True\n","tokenAssembler = TokenAssembler() \\\n","    .setInputCols([\"sentences\", \"cleanTokens\"]) \\\n","    .setOutputCol(\"cleanText\")\\\n","    .setPreservePosition(True)\n","\n","data = spark.createDataFrame([[\"Spark NLP is an open-source text processing library for advanced natural language processing.\"]]) \\\n","    .toDF(\"text\")\n","\n","pipeline = Pipeline().setStages([\n","    documentAssembler,\n","    sentenceDetector,\n","    tokenizer,\n","    normalizer,\n","    stopwordsCleaner,\n","    tokenAssembler\n","]).fit(data)\n","\n","result = pipeline.transform(data)\n","result.select(\"cleanText\").take(1)\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":714,"status":"ok","timestamp":1673448490406,"user":{"displayName":"Arshaan","userId":"17964254249366085303"},"user_tz":-330},"id":"kA162Cij2Gn6","outputId":"71f02ff0-0e47-4bdb-ff92-4cb1caf27685"},"outputs":[{"name":"stdout","output_type":"stream","text":["+---------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------+\n","|text                                                                                         |cleanText                                                                           |\n","+---------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------+\n","|Spark NLP is an open-source text processing library for advanced natural language processing.|Spark NLP   opensource text processing library  advanced natural language processing|\n","+---------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------+\n","\n"]}],"source":["result.select('text', F.explode(result.cleanText.result).alias('cleanText')).show(truncate=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"QpfQZ-a4J0GM"},"source":["Here as *`PreservePosition = True`*, we can see in the result that the actual position of the tokens has been preserved."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"a2XziPaCmN4Y"},"source":["### Checking for multiple sentences \n"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":1229,"status":"ok","timestamp":1673448491629,"user":{"displayName":"Arshaan","userId":"17964254249366085303"},"user_tz":-330},"id":"j1ek1rrXgM0K"},"outputs":[],"source":["!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/jupyter/annotation/english/spark-nlp-basics/sample-sentences-en.txt"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1673448491630,"user":{"displayName":"Arshaan","userId":"17964254249366085303"},"user_tz":-330},"id":"DtvNKIyXheYq","outputId":"0070c7c7-02e8-485d-ed4b-d53eb4e958d6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Peter is a very good person.\n","My life in Russia is very interesting.\n","John and Peter are brothers. However they don't support each other that much.\n","Lucas Nogal Dunbercker is no longer happy. He has a good car though.\n","Europe is very culture rich. There are huge churches! and big houses!\n"]}],"source":["with open('./sample-sentences-en.txt') as f:\n","  print (f.read())"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":904,"status":"ok","timestamp":1673448492529,"user":{"displayName":"Arshaan","userId":"17964254249366085303"},"user_tz":-330},"id":"stTgs7J3hgwj","outputId":"09afe30a-1f00-4485-c38f-643dbdf8cc01"},"outputs":[{"name":"stdout","output_type":"stream","text":["+-----------------------------------------------------------------------------+\n","|text                                                                         |\n","+-----------------------------------------------------------------------------+\n","|Peter is a very good person.                                                 |\n","|My life in Russia is very interesting.                                       |\n","|John and Peter are brothers. However they don't support each other that much.|\n","|Lucas Nogal Dunbercker is no longer happy. He has a good car though.         |\n","|Europe is very culture rich. There are huge churches! and big houses!        |\n","+-----------------------------------------------------------------------------+\n","\n"]}],"source":["#Loading data\n","spark_df = spark.read.text('./sample-sentences-en.txt').toDF('text')\n","\n","spark_df.show(truncate=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"_XZ9K2i4oXre"},"source":["\n","\n","➤  With Sentence Detector"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1369,"status":"ok","timestamp":1673448493892,"user":{"displayName":"Arshaan","userId":"17964254249366085303"},"user_tz":-330},"id":"2TqDZhXxhtz0","outputId":"00273c4f-5496-4796-94f2-ccd6191e5c2c"},"outputs":[{"data":{"text/plain":["[Row(cleanText=[Row(annotatorType='document', begin=0, end=19, result='Peter    good person', metadata={'sentence': '0'}, embeddings=[])]),\n"," Row(cleanText=[Row(annotatorType='document', begin=0, end=25, result='life  Russia   interesting', metadata={'sentence': '0'}, embeddings=[])]),\n"," Row(cleanText=[Row(annotatorType='document', begin=0, end=20, result='John  Peter  brothers', metadata={'sentence': '0'}, embeddings=[]), Row(annotatorType='document', begin=29, end=57, result='However  dont support    much', metadata={'sentence': '1'}, embeddings=[])]),\n"," Row(cleanText=[Row(annotatorType='document', begin=0, end=36, result='Lucas Nogal Dunbercker   longer happy', metadata={'sentence': '0'}, embeddings=[]), Row(annotatorType='document', begin=43, end=57, result='good car though', metadata={'sentence': '1'}, embeddings=[])]),\n"," Row(cleanText=[Row(annotatorType='document', begin=0, end=20, result='Europe   culture rich', metadata={'sentence': '0'}, embeddings=[]), Row(annotatorType='document', begin=29, end=41, result='huge churches', metadata={'sentence': '1'}, embeddings=[]), Row(annotatorType='document', begin=54, end=63, result='big houses', metadata={'sentence': '2'}, embeddings=[])])]"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["sentenceDetector = SentenceDetector() \\\n","    .setInputCols([\"document\"]) \\\n","    .setOutputCol(\"sentences\")\n","\n","\n","# Setting PreservePosition as True\n","tokenAssembler = TokenAssembler() \\\n","    .setInputCols([\"sentences\", \"cleanTokens\"]) \\\n","    .setOutputCol(\"cleanText\")\\\n","    .setPreservePosition(True)\n","\n","\n","pipeline = Pipeline().setStages([\n","    documentAssembler,\n","    sentenceDetector,\n","    tokenizer,\n","    normalizer,\n","    stopwordsCleaner,\n","    tokenAssembler\n","]).fit(spark_df)\n","\n","result = pipeline.transform(spark_df)\n","result.select(\"cleanText\").take(5)\n"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":420,"status":"ok","timestamp":1673448494307,"user":{"displayName":"Arshaan","userId":"17964254249366085303"},"user_tz":-330},"id":"3wPJPt2Yh5mp","outputId":"fd53c90b-0d68-4d4c-89db-0d1247ff5ab5"},"outputs":[{"name":"stdout","output_type":"stream","text":["+-----------------------------------------------------------------------------+-------------------------------------+\n","|text                                                                         |cleanText                            |\n","+-----------------------------------------------------------------------------+-------------------------------------+\n","|Peter is a very good person.                                                 |Peter    good person                 |\n","|My life in Russia is very interesting.                                       |life  Russia   interesting           |\n","|John and Peter are brothers. However they don't support each other that much.|John  Peter  brothers                |\n","|John and Peter are brothers. However they don't support each other that much.|However  dont support    much        |\n","|Lucas Nogal Dunbercker is no longer happy. He has a good car though.         |Lucas Nogal Dunbercker   longer happy|\n","|Lucas Nogal Dunbercker is no longer happy. He has a good car though.         |good car though                      |\n","|Europe is very culture rich. There are huge churches! and big houses!        |Europe   culture rich                |\n","|Europe is very culture rich. There are huge churches! and big houses!        |huge churches                        |\n","|Europe is very culture rich. There are huge churches! and big houses!        |big houses                           |\n","+-----------------------------------------------------------------------------+-------------------------------------+\n","\n"]}],"source":["result.select('text', F.explode(result.cleanText.result).alias('cleanText')).show(truncate=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"5NpPdOL2mkQ1"},"source":["As we have used *`Sentence Detector`* in our pipleine, it detects the sentence boundaries and we get cleanText for each of them separately. In the metadata we can see that after detecting sentences, it assigns a sentence number to it, with first sentence being initialized as 0. Also as the PreservePosition is set as True, the actual position of tokens has been preserved."]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2006,"status":"ok","timestamp":1673448496304,"user":{"displayName":"Arshaan","userId":"17964254249366085303"},"user_tz":-330},"id":"ua6jdo8mpZtJ","outputId":"dc6ec8c3-948f-491c-aa06-bf1a25907d5d"},"outputs":[{"name":"stdout","output_type":"stream","text":["+-----------------------------------------------------------------------------+\n","|text                                                                         |\n","+-----------------------------------------------------------------------------+\n","|Peter is a very good person.                                                 |\n","|My life in Russia is very interesting.                                       |\n","|John and Peter are brothers. However they don't support each other that much.|\n","|Lucas Nogal Dunbercker is no longer happy. He has a good car though.         |\n","|Europe is very culture rich. There are huge churches! and big houses!        |\n","+-----------------------------------------------------------------------------+\n","\n","+-----+---+-------------------------------------+--------+\n","|begin|end|result                               |sentence|\n","+-----+---+-------------------------------------+--------+\n","|0    |19 |Peter    good person                 |0       |\n","|0    |25 |life  Russia   interesting           |0       |\n","|0    |20 |John  Peter  brothers                |0       |\n","|29   |57 |However  dont support    much        |1       |\n","|0    |36 |Lucas Nogal Dunbercker   longer happy|0       |\n","|43   |57 |good car though                      |1       |\n","|0    |20 |Europe   culture rich                |0       |\n","|29   |41 |huge churches                        |1       |\n","|54   |63 |big houses                           |2       |\n","+-----+---+-------------------------------------+--------+\n","\n"]}],"source":["import pyspark.sql.functions as F\n","\n","result.select(\"text\").show(truncate=False)\n","\n","result.withColumn(\n","    \"tmp\", \n","    F.explode(\"cleanText\")) \\\n","    .select(\"tmp.*\").select(\"begin\",\"end\",\"result\",\"metadata.sentence\").show(truncate = False)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"7na0H1femUsm"},"source":["Sentence boundaries within the text were detected.\n","\n","For Example, we had the following text: \n","\n","*John and Peter are brothers. However they don't support each other that much.*\n","\n","John  Peter  brothers  ▶  metadata={'sentence': '0'}\n","\n","However  dont support    much ▶ metadata={'sentence': '1'}\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"tFEduvRiogiv"},"source":["\n","➤  Without Sentence Detector"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1673448496304,"user":{"displayName":"Arshaan","userId":"17964254249366085303"},"user_tz":-330},"id":"OiQk_w_OiHu9","outputId":"e072a4b1-90c3-4545-eaf4-6a36f1990081"},"outputs":[{"data":{"text/plain":["[Row(cleanText=[Row(annotatorType='document', begin=0, end=19, result='Peter    good person', metadata={'sentence': '0'}, embeddings=[])]),\n"," Row(cleanText=[Row(annotatorType='document', begin=0, end=25, result='life  Russia   interesting', metadata={'sentence': '0'}, embeddings=[])]),\n"," Row(cleanText=[Row(annotatorType='document', begin=0, end=50, result='John  Peter  brothers However  dont support    much', metadata={'sentence': '0'}, embeddings=[])]),\n"," Row(cleanText=[Row(annotatorType='document', begin=0, end=55, result='Lucas Nogal Dunbercker   longer happy    good car though', metadata={'sentence': '0'}, embeddings=[])]),\n"," Row(cleanText=[Row(annotatorType='document', begin=0, end=48, result='Europe   culture rich   huge churches  big houses', metadata={'sentence': '0'}, embeddings=[])])]"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["# if we hadn't used Sentence Detector, this would be what we got. (tokenizer gets document instead of sentences column)\n","tokenizer = Tokenizer() \\\n","    .setInputCols([\"document\"]) \\\n","    .setOutputCol(\"token\")\n","\n","tokenassembler = TokenAssembler()\\\n","    .setInputCols([\"document\", \"cleanTokens\"]) \\\n","    .setOutputCol(\"cleanText\")\\\n","    .setPreservePosition(True)\n","\n","nlpPipeline = Pipeline(stages=[documentAssembler,\n","                               tokenizer,\n","                               normalizer,\n","                               stopwordsCleaner,\n","                               tokenassembler])\n","\n","result = nlpPipeline.fit(spark_df).transform(spark_df)\n","result.select(\"cleanText\").take(5)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":690,"status":"ok","timestamp":1673448496989,"user":{"displayName":"Arshaan","userId":"17964254249366085303"},"user_tz":-330},"id":"mvVG6f6oiTQz","outputId":"7ead193c-0afb-4c02-cc8f-a134ce452845"},"outputs":[{"name":"stdout","output_type":"stream","text":["+-----------------------------------------------------------------------------+--------------------------------------------------------+\n","|text                                                                         |cleanText                                               |\n","+-----------------------------------------------------------------------------+--------------------------------------------------------+\n","|Peter is a very good person.                                                 |Peter    good person                                    |\n","|My life in Russia is very interesting.                                       |life  Russia   interesting                              |\n","|John and Peter are brothers. However they don't support each other that much.|John  Peter  brothers However  dont support    much     |\n","|Lucas Nogal Dunbercker is no longer happy. He has a good car though.         |Lucas Nogal Dunbercker   longer happy    good car though|\n","|Europe is very culture rich. There are huge churches! and big houses!        |Europe   culture rich   huge churches  big houses       |\n","+-----------------------------------------------------------------------------+--------------------------------------------------------+\n","\n"]}],"source":["result.select('text', F.explode(result.cleanText.result).alias('cleanText')).show(truncate=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"0cVHFwJKrEos"},"source":["Without using a *`Sentence Detector`* in our pipleine, sentence boundaries are not detected. It treats it as a single sentence. Also as the PreservePosition is set as True, the actual position of tokens has been preserved."]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":427,"status":"ok","timestamp":1673448497411,"user":{"displayName":"Arshaan","userId":"17964254249366085303"},"user_tz":-330},"id":"5Wa4quD_prqS","outputId":"36f825f9-d2a1-4c14-f45d-f4e79efb4c50"},"outputs":[{"name":"stdout","output_type":"stream","text":["+-----------------------------------------------------------------------------+\n","|text                                                                         |\n","+-----------------------------------------------------------------------------+\n","|Peter is a very good person.                                                 |\n","|My life in Russia is very interesting.                                       |\n","|John and Peter are brothers. However they don't support each other that much.|\n","|Lucas Nogal Dunbercker is no longer happy. He has a good car though.         |\n","|Europe is very culture rich. There are huge churches! and big houses!        |\n","+-----------------------------------------------------------------------------+\n","\n","+-----+---+--------------------------------------------------------+--------+\n","|begin|end|result                                                  |sentence|\n","+-----+---+--------------------------------------------------------+--------+\n","|0    |19 |Peter    good person                                    |0       |\n","|0    |25 |life  Russia   interesting                              |0       |\n","|0    |50 |John  Peter  brothers However  dont support    much     |0       |\n","|0    |55 |Lucas Nogal Dunbercker   longer happy    good car though|0       |\n","|0    |48 |Europe   culture rich   huge churches  big houses       |0       |\n","+-----+---+--------------------------------------------------------+--------+\n","\n"]}],"source":["import pyspark.sql.functions as F\n","\n","result.select(\"text\").show(truncate=False)\n","\n","result.withColumn(\n","    \"tmp\", \n","    F.explode(\"cleanText\")) \\\n","    .select(\"tmp.*\").select(\"begin\",\"end\",\"result\",\"metadata.sentence\").show(truncate = False)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"L3QQv8lel5Rq"},"source":["Sentence boundaries within the text were not detected and considered as a single sentence."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"8TgjbBq-1vG3"},"source":["`IMPORTANT NOTE`:\n","\n","If you have some other steps & annotators in your pipeline that will need to use the tokens from cleaned text (assembled tokens), you will need to tokenize the processed text again as the original text is probably changed completely."]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNDCwuF0Ug8mbHBSiHCumTp","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
