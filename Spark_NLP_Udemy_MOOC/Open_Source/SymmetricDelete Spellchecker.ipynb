{"cells":[{"cell_type":"markdown","metadata":{"id":"sXatvRX899i0"},"source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"]},{"cell_type":"markdown","source":["# **Attention!!** There is a bug in .setDupsLimit(). An issue was opened for this in GH. Please do not include that param setter in the recording until the bug is fixed."],"metadata":{"id":"A-ruJr3ScADD"}},{"cell_type":"markdown","metadata":{"id":"AOn8d1tcBkK3"},"source":["# **SymmetricDeleteApproach** and **SymmetricDeleteModel**"]},{"cell_type":"markdown","source":["This notebook will cover the different parameters and usages of `SymmetricDeleteApproach` and `SymmetricDeleteModel`.\n","\n","**📖 Learning Objectives:**\n","\n","1. Understand how to check spelling using SymmetricDelete annotators.\n","\n","2. Understand the difference between `SymmetricDeleteApproach` and `SymmetricDeleteModel`.\n","\n","3. Customize the use of these annotators by setting their parameters.\n","\n","\n","**🔗 Helpful Links:**\n","\n","- Documentation : [SymmetricDelete Spellchecker](https://nlp.johnsnowlabs.com/docs/en/annotators#symmetricdelete-spellchecker)\n","\n","- Python Docs : [SymmetricDeleteApproach](https://nlp.johnsnowlabs.com/api/python/reference/autosummary/python/sparknlp/annotator/spell_check/symmetric_delete/index.html#sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach), [SymmetricDeleteModel](https://nlp.johnsnowlabs.com/api/python/reference/autosummary/python/sparknlp/annotator/spell_check/symmetric_delete/index.html#sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteModel)\n","\n","- Scala Docs : [SymmetricDeleteApproach](https://nlp.johnsnowlabs.com/api/com/johnsnowlabs/nlp/annotators/spell/symmetric/SymmetricDeleteApproach), [SymmetricDeleteModel](https://nlp.johnsnowlabs.com/api/com/johnsnowlabs/nlp/annotators/spell/symmetric/SymmetricDeleteApproach)"],"metadata":{"id":"WimihSwD3vtH"}},{"cell_type":"markdown","source":["## **📜 Background**\n"],"metadata":{"id":"qL9lcISyFSLv"}},{"cell_type":"markdown","source":["Symmetric Delete spelling correction annotators retrieve tokens and utilize distance metrics to compute possible derived words. They are inspired by [SymSpell](https://github.com/wolfgarbe/SymSpell).\n","\n","The Symmetric Delete spelling correction algorithm reduces the complexity of edit candidate generation and dictionary lookup for a given Damerau-Levenshtein distance. It is six orders of magnitude faster (than the standard approach with deletes + transposes + replaces + inserts) and language independent.\n","\n","- `SymmetricDeleteApproach` is used to train your own spellchecker model based on training data.\n","- `SymmetricDeleteModel` is the instantiated model of the `SymmetricDeleteApproach`. Pretrained models can be loaded using this annotator. The default model is \"spellcheck_sd\", if no name is provided. For available pretrained models please see the [Models Hub](https://nlp.johnsnowlabs.com/models?task=Spell+Check).\n","\n","For alternative approaches to spellchecking, refer to [NorvigSweeting annotator](https://nlp.johnsnowlabs.com/docs/en/annotators#norvigsweeting-spellchecker) or [ContextSpellChecker annotator](https://nlp.johnsnowlabs.com/docs/en/annotators#contextspellchecker)."],"metadata":{"id":"TjDKOoZ4Fc8G"}},{"cell_type":"markdown","metadata":{"id":"MfkkKkbVF309"},"source":["## **🎬 Colab Setup**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iMkMQtZNF2n-","executionInfo":{"status":"ok","timestamp":1673382598401,"user_tz":180,"elapsed":29941,"user":{"displayName":"Mauro Nievas Offidani","userId":"07990177195800485445"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b144a7f9-ac02-4d6a-c8ad-c57636684803"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.4/212.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m448.4/448.4 KB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.6/198.6 KB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install -q pyspark==3.1.2  spark-nlp==4.2.4"]},{"cell_type":"code","source":["import sparknlp\n","from sparknlp.base import *\n","from sparknlp.annotator import *\n","from pyspark.ml import Pipeline\n","from pyspark.sql.functions import col\n","\n","spark = sparknlp.start()"],"metadata":{"id":"NulWi4_f4GN5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **🖨️ Input/Output Annotation Types**"],"metadata":{"id":"9Fbbk1bqcuA5"}},{"cell_type":"markdown","source":["- Input: `TOKEN`\n","\n","- Output: `TOKEN` (misspelled words are replaced by their correct form and the metadata includes the confidence score of the spelling correction)"],"metadata":{"id":"0yFIrr5acsiU"}},{"cell_type":"markdown","source":["## **🔎 Parameters**\n"],"metadata":{"id":"b2YJehUKMhb0"}},{"cell_type":"markdown","source":["- `deletesThreshold`: (Int) Minimum frequency of corrections a word needs to have to be considered from training. Increase if training set is LARGE (Default: 0).\n","\n","- `dictionary`: (String) Path to .txt file with external dictionary. External dictionary to be used needs \"tokenPattern\" (Default: \\S+) for parsing the resource. If provided, significantly boosts spell checking performance. This parameter only applies to `SymmetricDeleteApproach`.\n","\n","  Example:\n","\n","\n","```\n","...\n","gummy\n","gummic\n","gummier\n","gummiest\n","gummiferous\n","...\n","```\n","\n","- `dupsLimit`: (Int) Maximum duplicate of characters in a word to consider (Default: 2).\n","\n","- `frequencyThreshold`: (Int) Minimum frequency of words to be considered from training. Increase if training set is LARGE (Default: 0).\n","\n","- `longestWordLength`: (Int) Length of longest word in corpus.\n","\n","- `maxEditDistance`: (Int) Max edit distance characters to derive strings from a word (Default: 3).\n","\n","- `maxFrequency`: (Int) Maximum frequency of a word in the corpus.\n","\n","- `minFrequency`: (Int) Minimum frequency of a word in the corpus."],"metadata":{"id":"oidLDoS94asU"}},{"cell_type":"markdown","source":["## **Examples**"],"metadata":{"id":"vSMTsrBfinOc"}},{"cell_type":"markdown","source":["### Using a pretrained spellchecker with `SymmetricDeleteModel`"],"metadata":{"id":"sVcaX9eBO1x6"}},{"cell_type":"code","source":["documentAssembler = DocumentAssembler() \\\n",".setInputCol(\"text\") \\\n",".setOutputCol(\"document\")\n","\n","tokenizer = Tokenizer() \\\n",".setInputCols([\"document\"]) \\\n",".setOutputCol(\"token\")\n","\n","# \"spellcheck_sd\" can be omitted, as it is the default value\n","spellChecker = SymmetricDeleteModel.pretrained(\"spellcheck_sd\")\\\n",".setInputCols([\"token\"]) \\\n",".setOutputCol(\"spell\")\n","\n","pipeline = Pipeline().setStages([\n","documentAssembler,\n","tokenizer,\n","spellChecker\n","])\n","\n","data = spark.createDataFrame([[\"somtimes i wrrite wordz erong.\"]]).toDF(\"text\")\n","result = pipeline.fit(data).transform(data)\n","result.select(col('token.result').alias(\"before_spellchecker\"), col('spell.result').alias(\"after_spellchecker\")).show(truncate = False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JcLPCnNFqD0R","executionInfo":{"status":"ok","timestamp":1673296575296,"user_tz":180,"elapsed":528494,"user":{"displayName":"Mauro Nievas Offidani","userId":"07990177195800485445"}},"outputId":"a2573156-1481-4c71-d122-af1c741fff74"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["spellcheck_sd download started this may take some time.\n","Approximate size to download 198.1 MB\n","[OK!]\n","+--------------------------------------+--------------------------------------+\n","|before_spellchecker                   |after_spellchecker                    |\n","+--------------------------------------+--------------------------------------+\n","|[somtimes, i, wrrite, wordz, erong, .]|[sometimes, i, write, words, wrong, .]|\n","+--------------------------------------+--------------------------------------+\n","\n"]}]},{"cell_type":"markdown","source":["### Training a spellchecker using `SymmetricDeleteApproach`"],"metadata":{"id":"Sf4k15g8jxgs"}},{"cell_type":"code","source":["documentAssembler = DocumentAssembler() \\\n","    .setInputCol(\"text\") \\\n","    .setOutputCol(\"document\")\n","\n","tokenizer = Tokenizer() \\\n","    .setInputCols([\"document\"]) \\\n","    .setOutputCol(\"token\")\n","\n","spellChecker = SymmetricDeleteApproach() \\\n","    .setInputCols([\"token\"]) \\\n","    .setOutputCol(\"spell\")\n","\n","pipeline = Pipeline().setStages([\n","    documentAssembler,\n","    tokenizer,\n","    spellChecker\n","])\n","\n","# Corpus of texts used to train the spellchecker. In this example, the corpus consists of only one sentence.\n","training_df = spark.createDataFrame([[\"The dog and the cat play together.\"]]).toDF(\"text\")\n","\n","spellcheck_model = pipeline.fit(training_df)\n","\n","text_df = spark.createDataFrame([[\"Teh dogh is eating.\"]]).toDF(\"text\")\n","\n","corrected_text = spellcheck_model.transform(text_df)\n","\n","corrected_text.select(col('token.result').alias(\"before_spellchecker\"), col('spell.result').alias(\"after_spellchecker\")).show(truncate = False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L3P8k9e5imHR","executionInfo":{"status":"ok","timestamp":1673296581058,"user_tz":180,"elapsed":5782,"user":{"displayName":"Mauro Nievas Offidani","userId":"07990177195800485445"}},"outputId":"40b6e1df-4d3e-4975-f2fa-69dfde7be17e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------------+-------------------------+\n","|before_spellchecker       |after_spellchecker       |\n","+--------------------------+-------------------------+\n","|[Teh, dogh, is, eating, .]|[The, dog, is, eating, .]|\n","+--------------------------+-------------------------+\n","\n"]}]},{"cell_type":"markdown","source":["Based on the training corpus, the spellchecker identified and corrected the misspelled words."],"metadata":{"id":"o-1Jp-MT1ysY"}},{"cell_type":"markdown","source":["### setDictionary"],"metadata":{"id":"vBSbkjVMIKuD"}},{"cell_type":"code","source":["external_dict = '''\n","dogs\n","are\n","'''\n","with open('external_dict.txt', 'w') as f:\n","  f.write(external_dict)\n","\n","documentAssembler = DocumentAssembler() \\\n","    .setInputCol(\"text\") \\\n","    .setOutputCol(\"document\")\n","\n","tokenizer = Tokenizer() \\\n","    .setInputCols([\"document\"]) \\\n","    .setOutputCol(\"token\")\n","\n","spellChecker_1 = SymmetricDeleteApproach() \\\n","    .setInputCols([\"token\"]) \\\n","    .setOutputCol(\"spell_1\")\n","\n","spellChecker_2 = SymmetricDeleteApproach() \\\n","    .setInputCols([\"token\"]) \\\n","    .setOutputCol(\"spell_2\") \\\n","    .setDictionary(\"external_dict.txt\")\n","\n","pipeline = Pipeline().setStages([\n","    documentAssembler,\n","    tokenizer,\n","    spellChecker_1,\n","    spellChecker_2\n","])\n","\n","\n","training_df = spark.createDataFrame([[\"The dog and the cat play together.\"]]).toDF(\"text\")\n","\n","spellcheck_model = pipeline.fit(training_df)\n","\n","text_df = spark.createDataFrame([[\"teh dogs aree eating.\"]]).toDF(\"text\")\n","\n","corrected_text = spellcheck_model.transform(text_df)\n","\n","corrected_text.select(col('token.result').alias(\"before_spellchecker\"), col('spell_1.result').alias(\"spellchecker_without_dict\"), col('spell_2.result').alias(\"spellchecker_with_dict\")).show(truncate = False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qpGYhY0bIJ5Y","executionInfo":{"status":"ok","timestamp":1673211249321,"user_tz":180,"elapsed":2540,"user":{"displayName":"Mauro Nievas Offidani","userId":"07990177195800485445"}},"outputId":"35152111-7891-42a6-a727-3acf1669fa46"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------------------------+--------------------------+---------------------------+\n","|before_spellchecker         |spellchecker_without_dict |spellchecker_with_dict     |\n","+----------------------------+--------------------------+---------------------------+\n","|[teh, dogs, aree, eating, .]|[the, dog, and, eating, .]|[the, dogs, are, eating, .]|\n","+----------------------------+--------------------------+---------------------------+\n","\n"]}]},{"cell_type":"markdown","source":["Using a dictionary apart from training data, better results are achieved. In this case, the spellchecker without a dictionary made two mistakes when dealing with words that were not included in the training data ('dogs' and 'are'). This was solved by including an external dictionary with such words."],"metadata":{"id":"S8MJqMuXKJCh"}},{"cell_type":"markdown","source":["### setDupsLimit"],"metadata":{"id":"3RJ361Srv-Tj"}},{"cell_type":"code","source":["documentAssembler = DocumentAssembler() \\\n","    .setInputCol(\"text\") \\\n","    .setOutputCol(\"document\")\n","\n","tokenizer = Tokenizer() \\\n","    .setInputCols([\"document\"]) \\\n","    .setOutputCol(\"token\")\n","\n","spellChecker_1 = SymmetricDeleteApproach() \\\n","    .setInputCols([\"token\"]) \\\n","    .setOutputCol(\"spell_1\") \\\n","    .setDupsLimit(1)\n","\n","spellChecker_2 = SymmetricDeleteApproach() \\\n","    .setInputCols([\"token\"]) \\\n","    .setOutputCol(\"spell_2\") \\\n","    .setDupsLimit(0)\n","\n","pipeline = Pipeline().setStages([\n","    documentAssembler,\n","    tokenizer,\n","    spellChecker_1,\n","    spellChecker_2\n","])\n","\n","training_df = spark.createDataFrame([[\"it was a good day, and the dog played alone.\"]]).toDF(\"text\")\n","\n","spellcheck_model = pipeline.fit(training_df)\n","\n","text_df = spark.createDataFrame([[\"it was a goood dogg.\"]]).toDF(\"text\")\n","\n","corrected_text = spellcheck_model.transform(text_df)\n","\n","corrected_text.select(col('token.result').alias(\"before_spellchecker\"), col('spell_1.result').alias(\"dups_limit_1\"), col('spell_2.result').alias(\"dups_limit_0\")).show(truncate = False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qt_pAJgNwF2y","executionInfo":{"status":"ok","timestamp":1673383620961,"user_tz":180,"elapsed":4072,"user":{"displayName":"Mauro Nievas Offidani","userId":"07990177195800485445"}},"outputId":"a86b7d5a-a0be-4dda-cc39-b4c9f8fc095a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------------------------+--------------------------+--------------------------+\n","|before_spellchecker         |dups_limit_1              |dups_limit_0              |\n","+----------------------------+--------------------------+--------------------------+\n","|[it, was, a, goood, dogg, .]|[it, was, a, good, dog, .]|[it, was, a, good, dog, .]|\n","+----------------------------+--------------------------+--------------------------+\n","\n"]}]},{"cell_type":"markdown","source":["### setFrequencyThreshold"],"metadata":{"id":"_0aVl_wBwS_x"}},{"cell_type":"code","source":["documentAssembler = DocumentAssembler() \\\n","    .setInputCol(\"text\") \\\n","    .setOutputCol(\"document\")\n","\n","tokenizer = Tokenizer() \\\n","    .setInputCols([\"document\"]) \\\n","    .setOutputCol(\"token\")\n","\n","spellChecker_1 = SymmetricDeleteApproach() \\\n","    .setInputCols([\"token\"]) \\\n","    .setOutputCol(\"spell_1\") \\\n","    .setFrequencyThreshold(0)\n","\n","spellChecker_2 = SymmetricDeleteApproach() \\\n","    .setInputCols([\"token\"]) \\\n","    .setOutputCol(\"spell_2\") \\\n","    .setFrequencyThreshold(2)\n","\n","pipeline = Pipeline().setStages([\n","    documentAssembler,\n","    tokenizer,\n","    spellChecker_1,\n","    spellChecker_2\n","])\n","\n","training_df = spark.createDataFrame([[\"the dog and the cat play together.\"]]).toDF(\"text\")\n","\n","spellcheck_model = pipeline.fit(training_df)\n","\n","text_df = spark.createDataFrame([[\"teh dogh is eating.\"]]).toDF(\"text\")\n","\n","corrected_text = spellcheck_model.transform(text_df)\n","\n","corrected_text.select(col('token.result').alias(\"before_spellchecker\"), col('spell_1.result').alias(\"frequency_threshold_0\"), col('spell_2.result').alias(\"frequency_threshold_2\")).show(truncate = False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ProUftZ6wU7G","executionInfo":{"status":"ok","timestamp":1673211839025,"user_tz":180,"elapsed":2478,"user":{"displayName":"Mauro Nievas Offidani","userId":"07990177195800485445"}},"outputId":"36a08be2-6acd-4776-9357-50301c760734"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------------+-------------------------+--------------------------+\n","|before_spellchecker       |frequency_threshold_0    |frequency_threshold_2     |\n","+--------------------------+-------------------------+--------------------------+\n","|[teh, dogh, is, eating, .]|[the, dog, is, eating, .]|[the, dogh, is, eating, .]|\n","+--------------------------+-------------------------+--------------------------+\n","\n"]}]},{"cell_type":"markdown","source":["In this example, the spellchecker with frequencyThreshold = 2 did not correct the misspelled word \"dogh\", because the correct spelling of that word appears only once in the training data. In contrast to this, the word \"teh\" was corrected, because \"the\" appears at least twice in the training data."],"metadata":{"id":"H86mS5w02yqG"}},{"cell_type":"markdown","source":["### setMaxEditDistance"],"metadata":{"id":"XyF4NHKCNJBW"}},{"cell_type":"code","source":["documentAssembler = DocumentAssembler() \\\n","    .setInputCol(\"text\") \\\n","    .setOutputCol(\"document\")\n","\n","tokenizer = Tokenizer() \\\n","    .setInputCols([\"document\"]) \\\n","    .setOutputCol(\"token\")\n","\n","spellChecker_1 = SymmetricDeleteApproach() \\\n","    .setInputCols([\"token\"]) \\\n","    .setOutputCol(\"spell_1\") \\\n","    .setMaxEditDistance(1)\n","\n","spellChecker_2 = SymmetricDeleteApproach() \\\n","    .setInputCols([\"token\"]) \\\n","    .setOutputCol(\"spell_2\") \\\n","    .setMaxEditDistance(2)\n","\n","pipeline = Pipeline().setStages([\n","    documentAssembler,\n","    tokenizer,\n","    spellChecker_1,\n","    spellChecker_2\n","])\n","\n","training_df = spark.createDataFrame([[\"the dog and the cat play together.\"]]).toDF(\"text\")\n","\n","spellcheck_model = pipeline.fit(training_df)\n","\n","text_df = spark.createDataFrame([[\"teh dogh is eating.\"]]).toDF(\"text\")\n","\n","corrected_text = spellcheck_model.transform(text_df)\n","\n","corrected_text.select(col('token.result').alias(\"before_spellchecker\"), col('spell_1.result').alias(\"max_edit_distance_1\"), col('spell_2.result').alias(\"max_edit_distance_2\")).show(truncate = False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Iv5JAb-LP4Bw","executionInfo":{"status":"ok","timestamp":1673213077320,"user_tz":180,"elapsed":2769,"user":{"displayName":"Mauro Nievas Offidani","userId":"07990177195800485445"}},"outputId":"325c913f-87df-407a-a098-3e2c3ab38c00"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------------+-------------------------+-------------------------+\n","|before_spellchecker       |max_edit_distance_1      |max_edit_distance_2      |\n","+--------------------------+-------------------------+-------------------------+\n","|[teh, dogh, is, eating, .]|[teh, dog, is, eating, .]|[the, dog, is, eating, .]|\n","+--------------------------+-------------------------+-------------------------+\n","\n"]}]},{"cell_type":"markdown","source":["When maxEditDistance is 1, \"teh\" is not corrected to \"the\" because the amount of edits that are needed (2 letters) is higher than the maximum amount of edits that are allowed."],"metadata":{"id":"TN-f6gBjRaL7"}}],"metadata":{"colab":{"machine_shape":"hm","provenance":[{"file_id":"1L8GdQ-yorjVk_V8Um6Rw6aEzFVT31OCO","timestamp":1672941527684},{"file_id":"1VVV4jTagH47UZiKFqXoP-Abq5ozZM1BV","timestamp":1672918708428},{"file_id":"https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb","timestamp":1671914287039}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":0}