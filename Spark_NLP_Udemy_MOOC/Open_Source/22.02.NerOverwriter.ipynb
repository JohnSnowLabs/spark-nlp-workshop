{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"PofWFxUL4r4h"},"source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Open_Source/22.02.NerOverwriter.ipynb)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"cCer9VRZ4zXk"},"source":["# **NerOverwriter**"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"bkj8B-_VXrzg"},"source":["This notebook will cover the different parameters and usages of `NerOverwriter`. This annotator overwrites entities of specified strings.\n","\n","**üìñ Learning Objectives:**\n","\n","1. Understand how different regex patterns split sequences of words in different ways.\n","\n","2. Understand the difference between the regex tokenizer and regular tokenizer.\n","\n","3. Become comfortable using the different parameters of the annotator.\n","\n","\n","**üîó Helpful Links:**\n","\n","- Documentation : [NerOverwriter](https://nlp.johnsnowlabs.com/docs/en/annotators#neroverwriter)\n","\n","- Python Docs : [NerOverwriter](https://nlp.johnsnowlabs.com/api/python/reference/autosummary/sparknlp/annotator/ner/ner_overwriter/index.html#sparknlp.annotator.ner.ner_overwriter.NerOverwriter)\n","\n","- Scala Docs : [NerOverwriter](https://nlp.johnsnowlabs.com/api/com/johnsnowlabs/nlp/annotators/RegexTokenizer.html)\n","\n","- For extended examples of usage, see the [Spark NLP Workshop repository](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/)."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"_JH6irwLZDro"},"source":["## **üìú Background**"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Sxgg5EBLZFkU"},"source":[]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"mHgCpkndZLug"},"source":["## **üé¨ Colab Setup**"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":6434,"status":"ok","timestamp":1676937795300,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":300},"id":"kuQS373YZNbH"},"outputs":[],"source":["!pip install -q pyspark==3.1.2  spark-nlp==4.2.4"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":31,"status":"ok","timestamp":1676937795303,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":300},"id":"XVWBajFEZVd5"},"outputs":[],"source":["import sparknlp\n","from sparknlp.base import *\n","from sparknlp.annotator import *\n","from pyspark.ml import Pipeline\n","\n","spark = sparknlp.start()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"C5jOz7cLZdJL"},"source":["## **üñ®Ô∏è Input/Output Annotation Types**"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"mfTEicqEZexx"},"source":["<table class=\"table\">\n","<thead>\n","<tr class=\"row-odd\"><th class=\"head\"><p>Input Annotation types</p></th>\n","<th class=\"head\"><p>Output Annotation type</p></th>\n","</tr>\n","</thead>\n","<tbody>\n","<tr class=\"row-even\"><td><p><code class=\"docutils literal notranslate\"><span class=\"pre\">NAMED_ENTITY</span></code></p></td>\n","<td><p><code class=\"docutils literal notranslate\"><span class=\"pre\">NAMED_ENTITY</span></code></p></td>\n","</tr>\n","</tbody>\n","</table>"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"2wsFSeH8aIrQ"},"source":["## **üîé Parameters**"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"C80qDHBPbH6G"},"source":["- `setNerWords` : (List[str]) Sets the words to be overwritten.\n","\n","- `setNewNerEntity` : (str)  Sets new NER class to apply to those stopwords, by default I-OVERWRITE.\n","\n","- `setReplaceEntities`: (Dict[str, str]) Sets weights dictionary with the tags that you want to replace.\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"KUKJI4M3ihBA"},"source":["##### First extract the prerequisite Entities\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34821,"status":"ok","timestamp":1676925971084,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":300},"id":"X0PdNvICZ9Da","outputId":"d56dc687-bf45-48ed-c486-20cad1678921"},"outputs":[{"name":"stdout","output_type":"stream","text":["glove_100d download started this may take some time.\n","Approximate size to download 145.3 MB\n","[OK!]\n","ner_dl download started this may take some time.\n","Approximate size to download 13.6 MB\n","[OK!]\n","+---------------------------------------------------------------------+\n","|col                                                                  |\n","+---------------------------------------------------------------------+\n","|{named_entity, 0, 4, B-ORG, {word -> Spark, sentence -> 0}, []}      |\n","|{named_entity, 6, 8, I-ORG, {word -> NLP, sentence -> 0}, []}        |\n","|{named_entity, 10, 16, O, {word -> Crosses, sentence -> 0}, []}      |\n","|{named_entity, 18, 21, O, {word -> Five, sentence -> 0}, []}         |\n","|{named_entity, 23, 29, O, {word -> Million, sentence -> 0}, []}      |\n","|{named_entity, 31, 39, O, {word -> Downloads, sentence -> 0}, []}    |\n","|{named_entity, 40, 40, O, {word -> ,, sentence -> 0}, []}            |\n","|{named_entity, 42, 45, B-ORG, {word -> John, sentence -> 0}, []}     |\n","|{named_entity, 47, 50, I-ORG, {word -> Snow, sentence -> 0}, []}     |\n","|{named_entity, 52, 55, I-ORG, {word -> Labs, sentence -> 0}, []}     |\n","|{named_entity, 57, 65, I-ORG, {word -> Announces, sentence -> 0}, []}|\n","|{named_entity, 66, 66, O, {word -> ., sentence -> 0}, []}            |\n","+---------------------------------------------------------------------+\n","\n"]}],"source":["documentAssembler = DocumentAssembler() \\\n","    .setInputCol(\"text\") \\\n","    .setOutputCol(\"document\")\n","sentence = SentenceDetector() \\\n","    .setInputCols([\"document\"]) \\\n","    .setOutputCol(\"sentence\")\n","tokenizer = Tokenizer() \\\n","    .setInputCols([\"sentence\"]) \\\n","    .setOutputCol(\"token\")\n","embeddings = WordEmbeddingsModel.pretrained() \\\n","    .setInputCols([\"sentence\", \"token\"]) \\\n","    .setOutputCol(\"bert\")\n","nerTagger = NerDLModel.pretrained() \\\n","    .setInputCols([\"sentence\", \"token\", \"bert\"]) \\\n","    .setOutputCol(\"ner\")\n","pipeline = Pipeline().setStages([\n","    documentAssembler,\n","    sentence,\n","    tokenizer,\n","    embeddings,\n","    nerTagger\n","])\n","data = spark.createDataFrame([[\"Spark NLP Crosses Five Million Downloads, John Snow Labs Announces.\"]]).toDF(\"text\")\n","result = pipeline.fit(data).transform(data)\n","result.selectExpr(\"explode(ner)\").show(truncate=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"VFcolinLgn80"},"source":["### `setNerWords()` , `setNewNerEntity()`\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"m4tE31nli2aV"},"source":["##### The recognized entities can then be overwritten"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1678,"status":"ok","timestamp":1673367995563,"user":{"displayName":"G√∂khan T√úRER","userId":"17886843627290606834"},"user_tz":-180},"id":"jmohv6Kjd3-z","outputId":"3f882076-2429-48b6-8daa-068825e3fd7b"},"outputs":[{"name":"stdout","output_type":"stream","text":["+------------------------------------------------------------------------+\n","|col                                                                     |\n","+------------------------------------------------------------------------+\n","|{named_entity, 0, 4, B-ORG, {word -> Spark, sentence -> 0}, []}         |\n","|{named_entity, 6, 8, I-ORG, {word -> NLP, sentence -> 0}, []}           |\n","|{named_entity, 10, 16, O, {word -> Crosses, sentence -> 0}, []}         |\n","|{named_entity, 18, 21, O, {word -> Five, sentence -> 0}, []}            |\n","|{named_entity, 23, 29, B-CARDINAL, {word -> Million, sentence -> 0}, []}|\n","|{named_entity, 31, 39, O, {word -> Downloads, sentence -> 0}, []}       |\n","|{named_entity, 40, 40, O, {word -> ,, sentence -> 0}, []}               |\n","|{named_entity, 42, 45, B-ORG, {word -> John, sentence -> 0}, []}        |\n","|{named_entity, 47, 50, I-ORG, {word -> Snow, sentence -> 0}, []}        |\n","|{named_entity, 52, 55, I-ORG, {word -> Labs, sentence -> 0}, []}        |\n","|{named_entity, 57, 65, I-ORG, {word -> Announces, sentence -> 0}, []}   |\n","|{named_entity, 66, 66, O, {word -> ., sentence -> 0}, []}               |\n","+------------------------------------------------------------------------+\n","\n"]}],"source":["nerOverwriter = NerOverwriter() \\\n","    .setInputCols([\"ner\"]) \\\n","    .setOutputCol(\"ner_overwritten\") \\\n","    .setNerWords([\"Million\"]) \\\n","    .setNewNerEntity(\"B-CARDINAL\")\n","nerOverwriter.transform(result).selectExpr(\"explode(ner_overwritten)\").show(truncate=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"QJNz9XHrlOEH"},"source":["### `setReplaceEntities()`\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LuK3bSgfgZyE"},"outputs":[],"source":["new_dict = {\"B-ORG\":\"B-PLACE\", \"I-ORG\":\"I-PLACE\"}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1342,"status":"ok","timestamp":1673370574107,"user":{"displayName":"G√∂khan T√úRER","userId":"17886843627290606834"},"user_tz":-180},"id":"KsIFuDmkotuB","outputId":"dd682d4a-7501-401d-9759-f14c3d96d0d3"},"outputs":[{"name":"stdout","output_type":"stream","text":["+-----------------------------------------------------------------------+\n","|col                                                                    |\n","+-----------------------------------------------------------------------+\n","|{named_entity, 0, 4, B-PLACE, {word -> Spark, sentence -> 0}, []}      |\n","|{named_entity, 6, 8, I-PLACE, {word -> NLP, sentence -> 0}, []}        |\n","|{named_entity, 10, 16, O, {word -> Crosses, sentence -> 0}, []}        |\n","|{named_entity, 18, 21, O, {word -> Five, sentence -> 0}, []}           |\n","|{named_entity, 23, 29, O, {word -> Million, sentence -> 0}, []}        |\n","|{named_entity, 31, 39, O, {word -> Downloads, sentence -> 0}, []}      |\n","|{named_entity, 40, 40, O, {word -> ,, sentence -> 0}, []}              |\n","|{named_entity, 42, 45, B-PLACE, {word -> John, sentence -> 0}, []}     |\n","|{named_entity, 47, 50, I-PLACE, {word -> Snow, sentence -> 0}, []}     |\n","|{named_entity, 52, 55, I-PLACE, {word -> Labs, sentence -> 0}, []}     |\n","|{named_entity, 57, 65, I-PLACE, {word -> Announces, sentence -> 0}, []}|\n","|{named_entity, 66, 66, O, {word -> ., sentence -> 0}, []}              |\n","+-----------------------------------------------------------------------+\n","\n"]}],"source":["nerOverwriter = NerOverwriter() \\\n","    .setInputCols([\"ner\"]) \\\n","    .setOutputCol(\"ner_overwritten\") \\\n","    .setReplaceEntities(new_dict)\n","nerOverwriter.transform(result).selectExpr(\"explode(ner_overwritten)\").show(truncate=False)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
