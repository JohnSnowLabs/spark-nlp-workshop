{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"sXatvRX899i0"},"source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Open_Source/15.01.Word2Vec.ipynb)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"AOn8d1tcBkK3"},"source":["# **Word2Vec**"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"WimihSwD3vtH"},"source":["This notebook will cover the different parameters and usages of the `Word2Vec` annotator. There are two versions of this annotator: approach and model. The `Word2Vec` annotator approach trains a model that creates vector representations of words in a text corpus. \n","\n","**ðŸ“– Learning Objectives:**\n","\n","1. Understand how .\n","\n","2. Understand \n","\n","3. Become comfortable using the different parameters of the annotator.\n","\n","\n","**ðŸ”— Helpful Links:**\n","\n","- Documentation : [Word2Vec](https://nlp.johnsnowlabs.com/docs/en/annotators#word2vec)\n","\n","- Python Docs : [Word2VecApproach](https://nlp.johnsnowlabs.com/api/python/reference/autosummary/sparknlp/annotator/embeddings/word2vec/index.html#sparknlp.annotator.embeddings.word2vec.Word2VecApproach) and [Word2VecModel](https://nlp.johnsnowlabs.com/api/python/reference/autosummary/sparknlp/annotator/embeddings/word2vec/index.html#sparknlp.annotator.embeddings.word2vec.Word2VecModel)\n","\n","- Scala Docs : [Word2VecApproach](https://nlp.johnsnowlabs.com/api/com/johnsnowlabs/nlp/embeddings/Word2VecApproach) and [Word2VecModel](https://nlp.johnsnowlabs.com/api/com/johnsnowlabs/nlp/embeddings/Word2VecModel)\n","\n","- Original C Implementation: [Word2Vec](https://code.google.com/archive/p/word2vec/)\n","\n","- Research Papers: [Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/abs/1301.3781) and [Distributed Representations of Words and Phrases and their Compositionality](https://arxiv.org/pdf/1310.4546v1.pdf)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"qL9lcISyFSLv"},"source":["## **ðŸ“œ Background**\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"TjDKOoZ4Fc8G"},"source":["The algorithm first constructs a vocabulary from the corpus and then learns vector representation of words in the vocabulary. The vector representation can be used as features in natural language processing and machine learning algorithms.\n","\n","The anotator uses Word2Vec implemented in Spark ML. It uses skip-gram model in Spark NLP implementation and a hierarchical softmax method to train the model. The variable names in the implementation match the original C implementation.\n","\n","The Word2VecApproach can be used to train your own model. The Word2VecModel is the instantiated model of the Word2VecApproach. \n","\n","Pretrained models can be loaded with `Word2VecModel.pretrained()`. The default model is `word2vec_gigaword_300`, if no name is provided.\n","\n","For available pretrained models, for several languages and various dimensions, see the [Models Hub](https://nlp.johnsnowlabs.com/models?q=Word2Vec)."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"MfkkKkbVF309"},"source":["## **ðŸŽ¬ Colab Setup**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24597,"status":"ok","timestamp":1672910250382,"user":{"displayName":"Luca Martial","userId":"17305191879319411410"},"user_tz":-420},"id":"iMkMQtZNF2n-","outputId":"c56e46bc-72d9-4f7c-ec1d-f6c756991f91"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m212.4/212.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m453.4/453.4 KB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m198.6/198.6 KB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install -q pyspark==3.1.2  spark-nlp==4.2.4"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NulWi4_f4GN5"},"outputs":[],"source":["import sparknlp\n","from sparknlp.base import *\n","from sparknlp.annotator import *\n","from pyspark.ml import Pipeline\n","\n","spark = sparknlp.start()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"9Fbbk1bqcuA5"},"source":["## **ðŸ–¨ï¸ Input/Output Annotation Types**"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"0yFIrr5acsiU"},"source":["- Input: `TOKEN`\n","\n","- Output: `WORD_EMBEDDINGS`"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"b2YJehUKMhb0"},"source":["## **ðŸ”Ž Parameters Word2VecApproach**\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"oidLDoS94asU"},"source":["- `enableCaching`: (BooleanParam) --> Whether to enable caching DataFrames or RDDs during the training.\n","\n","- `maxIter`: (IntParam) --> Param for maximum number of iterations (>= 0) (Default: 1).\n","\n","- `maxSentenceLength`: (IntParam) --> Sets the maximum length (in words) of each sentence in the input data (Default: 1000).\n","\n","- `minCount`: (IntParam) --> The minimum number of times a token must appear to be included in the word2vec model's vocabulary (Default: 5).\n","\n","- `numPartitions`: (IntParam)\n","Number of partitions for sentences of words (Default: 1).\n","\n","- `seed`: (IntParam) --> Random seed for shuffling the dataset (Default: 44).\n","\n","- `stepSize`: (DoubleParam) --> \n","Param for Step size to be used for each iteration of optimization (> 0) (Default: 0.025).\n","\n","- `storageRef`: (Param[String]) --> Unique identifier for storage (Default: this.uid).\n","\n","- `vectorSize`: (IntParam) --> The dimension of the code that you want to transform from words (Default: 100).\n","\n","- `windowSize`: (IntParam) --> Window size (context words from [-window, window]) (Default: 5)."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"_8kwQs-GFMsI"},"source":["## **Word2VecApproach Example Pipeline**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g1ih0SkmFbSc"},"outputs":[],"source":["documentAssembler = DocumentAssembler() \\\n","    .setInputCol(\"text\") \\\n","    .setOutputCol(\"document\")\n","tokenizer = Tokenizer() \\\n","    .setInputCols([\"document\"]) \\\n","    .setOutputCol(\"token\")\n","embeddings = Word2VecApproach() \\\n","    .setInputCols([\"token\"]) \\\n","    .setOutputCol(\"embeddings\")\n","pipeline = Pipeline() \\\n","    .setStages([\n","      documentAssembler,\n","      tokenizer,\n","      embeddings\n","    ])\n","path = \"src/test/resources/spell/sherlockholmes.txt\"\n","dataset = spark.read.text(path).toDF(\"text\")\n","pipelineModel = pipeline.fit(dataset)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"sVcaX9eBO1x6"},"source":["### `setVectorSize()`"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"tvxWsNEbHoQG"},"source":["### `setWindowSize()`"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"TCJtf-99HwCH"},"source":["### `setStepSize`"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"vtGicyOJH2Fb"},"source":["### `setNumPartitions()`"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"vFLlDMWgBjqx"},"source":["### `setMaxIter()`"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"08mk6KARFZHY"},"source":["### `setMinCount()`"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"jpNpy9dDII8s"},"source":["### `setMaxSentenceLength()`"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"o4kv9pGhAcBZ"},"source":["## **ðŸ”Ž Parameters Word2VecModel**"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"DilroyvWAcH2"},"source":["- `dimension`: (IntParam) --> Number of embedding dimensions (Default depends on model).\n","\n","- `storageRef`: (Param[String]) --> Unique identifier for storage (Default: this.uid).\n","\n","- `vectorSize`: (IntParam) --> The dimension of codes after transforming from words (> 0) (Default: 100).\n","\n","- `wordVectors`: (MapFeature(String, Array[Float]) --> Dictionary of words with their vectors.\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"M4Oj8LNUGjrM"},"source":["## **Word2VecModel Example Pipeline**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XFqrdkyvGoqM"},"outputs":[],"source":["documentAssembler = DocumentAssembler() \\\n","    .setInputCol(\"text\") \\\n","    .setOutputCol(\"document\")\n","\n","tokenizer = Tokenizer() \\\n","    .setInputCols([\"document\"]) \\\n","    .setOutputCol(\"token\")\n","\n","embeddings = Word2VecModel.pretrained() \\\n","    .setInputCols([\"token\"]) \\\n","    .setOutputCol(\"embeddings\")\n","\n","embeddingsFinisher = EmbeddingsFinisher() \\\n","    .setInputCols([\"embeddings\"]) \\\n","    .setOutputCols(\"finished_embeddings\") \\\n","    .setOutputAsVector(True)\n","\n","pipeline = Pipeline().setStages([\n","    documentAssembler,\n","    tokenizer,\n","    embeddings,\n","    embeddingsFinisher\n","])\n","data = spark.createDataFrame([[\"This is a sentence.\"]]).toDF(\"text\")\n","result = pipeline.fit(data).transform(data)\n","result.selectExpr(\"explode(finished_embeddings) as result\").show(1, 80)"]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[{"file_id":"1L8GdQ-yorjVk_V8Um6Rw6aEzFVT31OCO","timestamp":1673032420252},{"file_id":"1VVV4jTagH47UZiKFqXoP-Abq5ozZM1BV","timestamp":1672918708428},{"file_id":"https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb","timestamp":1671914287039}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":0}
