{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "klIak_Gb_OPJ"
      },
      "source": [
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Open_Source/05.01.Lemmatizer_LemmatizerModel.ipynb)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bewC1SWN-6jB"
      },
      "source": [
        "#  **Lemmatizer** and **LemmatizerModel**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SdotCsxH2try"
      },
      "source": [
        "This notebook will cover the different parameters and usages of `Lemmatizer` and `LemmatizerModel` annotators.\n",
        "\n",
        "**📖 Learning Objectives:**\n",
        "\n",
        "1. Understand the process of reducing inflected words to their base forms to obtain the lemmas.\n",
        "\n",
        "2. Be able to train custom `LemmatizerModel` annotators.\n",
        "\n",
        "3. Become confortable with creating pipelines to preprocess texts with `Lemmatizer` and `LemmatizerModel`. \n",
        "\n",
        "\n",
        "**🔗 Helpful Links:**\n",
        "\n",
        "- Documentation : [Lemmatizer](https://nlp.johnsnowlabs.com/docs/en/annotators#lemmatizer), [LemmatizerModel](https://nlp.johnsnowlabs.com/docs/en/annotators#lemmatizer)\n",
        "\n",
        "- Python Docs : [Lemmatizer](https://nlp.johnsnowlabs.com/api/python/reference/autosummary/sparknlp/annotator/lemmatizer/index.html), [LemmatizerModel](https://sparknlp.org/api/python/reference/autosummary/sparknlp/annotator/lemmatizer/index.html#sparknlp.annotator.lemmatizer.LemmatizerModel)\n",
        "\n",
        "- Scala Docs : [Lemmatizer](https://nlp.johnsnowlabs.com/api/com/johnsnowlabs/nlp/annotators/Lemmatizer.html), [LemmatizerModel](https://nlp.johnsnowlabs.com/api/com/johnsnowlabs/nlp/annotators/LemmatizerModel.html)\n",
        "\n",
        "- For extended examples of usage, see the [Spark NLP Workshop repository](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/)."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "A4hMnkhd_ik9"
      },
      "source": [
        "## **🎬 Colab Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "xrdvNxjD_yQI"
      },
      "outputs": [],
      "source": [
        "# Install PySpark and Spark NLP\n",
        "!pip install -q pyspark==3.1.2  spark-nlp==4.2.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "W5D63vBo_0u0"
      },
      "outputs": [],
      "source": [
        "import sparknlp\n",
        "from sparknlp.base import DocumentAssembler, Pipeline\n",
        "from sparknlp.annotator import Lemmatizer, LemmatizerModel, Tokenizer\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "\n",
        "spark = sparknlp.start()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "efnXX29f39ac"
      },
      "source": [
        "## **🖨️ Input/Output Annotation Types**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nfVChrHh4A6z"
      },
      "source": [
        "- Input: `TOKEN`\n",
        "\n",
        "- Output: `TOKEN`"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ggx0d3iZYen"
      },
      "source": [
        "## **Training a Lemmatizer model**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8Lh3V_Qz4QRk"
      },
      "source": [
        "### **🔎 Parameters**\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gknV3dE-4UCs"
      },
      "source": [
        "- `dictionary`: Path to external dictionary for the lemmatizer.\n",
        "\n",
        "- `formCol`: Name of the column containing the word form information, following the [CoNLLU](https://universaldependencies.org/format.html) format.\n",
        "\n",
        "- `lemmaCol`: Name of the column containing the lemma information, following the [CoNLLU](https://universaldependencies.org/format.html) format.\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YN8m-ZBnYo3Y"
      },
      "source": [
        "### `.setDictionary()`"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9k2T3c5RY8I4"
      },
      "source": [
        "External dictionary to be used by the lemmatizer, which needs `keyDelimiter` (separates lemmas from the word forms) and `valueDelimiter` (separator between different word forms of the same lemma) for parsing the resource."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ye7zaTgJYoQG"
      },
      "outputs": [],
      "source": [
        "!wget -q https://raw.githubusercontent.com/mahavivo/vocabulary/master/lemmas/AntBNC_lemmas_ver_001.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pr4TW56AVPPs",
        "outputId": "22b1159b-2c25-4865-f9ca-983894570dec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "aaah\t->\taaahed\taaah\n",
            "aac\t->\taac\taacs\n",
            "aah\t->\taah\taahs\taahing\taahed\taahhing\n",
            "aam\t->\taams\taam\n",
            "aardvark\t->\taardvark\taardvarks\n"
          ]
        }
      ],
      "source": [
        "!head -5 AntBNC_lemmas_ver_001.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "sJ_3GRF8YWk4"
      },
      "outputs": [],
      "source": [
        "lemmatizer = Lemmatizer() \\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"lemma\") \\\n",
        "    .setDictionary(\"./AntBNC_lemmas_ver_001.txt\", value_delimiter =\"\\t\", key_delimiter = \"->\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNlpC06KZ37F",
        "outputId": "e22292f5-0a74-43ab-e7c8-be56ac426e92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------------------------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
            "|                         text|                                document|                                   token|                                   lemma|\n",
            "+-----------------------------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
            "|I love working with SparkNLP.|[{document, 0, 28, I love working wit...|[{token, 0, 0, I, {sentence -> 0}, []...|[{token, 0, 0, I, {sentence -> 0}, []...|\n",
            "|       I am living in Canada.|[{document, 0, 21, I am living in Can...|[{token, 0, 0, I, {sentence -> 0}, []...|[{token, 0, 0, I, {sentence -> 0}, []...|\n",
            "+-----------------------------+----------------------------------------+----------------------------------------+----------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "documentAssembler = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "tokenizer = Tokenizer() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "nlpPipeline = Pipeline(stages=[documentAssembler, \n",
        "                               tokenizer,\n",
        "                               lemmatizer])\n",
        "\n",
        "sample_texts = [\n",
        "    [\"I love working with SparkNLP.\"], \n",
        "    [\"I am living in Canada.\"]\n",
        "]\n",
        "\n",
        "data = spark.createDataFrame(sample_texts).toDF(\"text\")\n",
        "\n",
        "result = nlpPipeline.fit(data).transform(data)\n",
        "\n",
        "result.show(truncate=40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kN2-Z7GYU6B",
        "outputId": "98e5aa83-e9d1-4f16-9eb7-4fd7733d40de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------------------------------+\n",
            "|result                            |\n",
            "+----------------------------------+\n",
            "|[I, love, work, with, SparkNLP, .]|\n",
            "|[I, be, live, in, Canada, .]      |\n",
            "+----------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result.select('lemma.result').show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "e579F_D_YVUa",
        "outputId": "58d1ad65-a58f-4244-db5d-dbde56e6857d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-59faafa5-ba3b-4d7d-8cf8-b6e7fbb4586a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "      <th>lemma</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I</td>\n",
              "      <td>I</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>love</td>\n",
              "      <td>love</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>working</td>\n",
              "      <td>work</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>with</td>\n",
              "      <td>with</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SparkNLP</td>\n",
              "      <td>SparkNLP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>I</td>\n",
              "      <td>I</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>am</td>\n",
              "      <td>be</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>living</td>\n",
              "      <td>live</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>in</td>\n",
              "      <td>in</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-59faafa5-ba3b-4d7d-8cf8-b6e7fbb4586a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-59faafa5-ba3b-4d7d-8cf8-b6e7fbb4586a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-59faafa5-ba3b-4d7d-8cf8-b6e7fbb4586a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      token     lemma\n",
              "0         I         I\n",
              "1      love      love\n",
              "2   working      work\n",
              "3      with      with\n",
              "4  SparkNLP  SparkNLP\n",
              "5         .         .\n",
              "6         I         I\n",
              "7        am        be\n",
              "8    living      live\n",
              "9        in        in"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result_df = result.select(F.explode(F.arrays_zip(result.token.result, \n",
        "                                                 result.lemma.result)).alias(\"cols\")) \\\n",
        "                  .select(F.expr(\"cols['0']\").alias(\"token\"),\n",
        "                          F.expr(\"cols['1']\").alias(\"lemma\")).toPandas()\n",
        "\n",
        "result_df.head(10)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4M_lgQwHbSWY"
      },
      "source": [
        "# **Using pretrained models**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MDiLlng4bOMD"
      },
      "source": [
        "The `LemmatizerModel` annotator can automatically download pretrained models with the `.pretrained()` method. For available pretrained models, check the [NLP Models Hub](https://nlp.johnsnowlabs.com/models?task=Lemmatization)."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1CfCbbMt6OMK"
      },
      "source": [
        "## **🔎 Example Pipeline**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Fy_2J2ncgLks"
      },
      "outputs": [],
      "source": [
        "!wget -q -O news_category_test.csv https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/classifier-dl/news_Category/news_category_test.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAd2Ig1cWde_",
        "outputId": "29d5c5dc-fa7b-4260-ed22-55b29471ca1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "category,description\n",
            "Business,Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.\n",
            "Sci/Tech,\" TORONTO, Canada    A second team of rocketeers competing for the  #36;10 million Ansari X Prize, a contest for privately funded suborbital space flight, has officially announced the first launch date for its manned rocket.\"\n",
            "Sci/Tech,\" A company founded by a chemistry researcher at the University of Louisville won a grant to develop a method of producing better peptides, which are short chains of amino acids, the building blocks of proteins.\"\n",
            "Sci/Tech,\" It's barely dawn when Mike Fitzpatrick starts his shift with a blur of colorful maps, figures and endless charts, but already he knows what the day will bring. Lightning will strike in places he expects. Winds will pick up, moist places will dry and flames will roar.\"\n"
          ]
        }
      ],
      "source": [
        "!head -5 news_category_test.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ka4QJqV7gPg5",
        "outputId": "571c2c17-6c5d-40ca-c4a2-3579dce5a21b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+--------------------------------------------------+\n",
            "|category|                                              text|\n",
            "+--------+--------------------------------------------------+\n",
            "|Business|Unions representing workers at Turner   Newall ...|\n",
            "|Sci/Tech| TORONTO, Canada    A second team of rocketeers...|\n",
            "|Sci/Tech| A company founded by a chemistry researcher at...|\n",
            "|Sci/Tech| It's barely dawn when Mike Fitzpatrick starts ...|\n",
            "|Sci/Tech| Southern California's smog fighting agency wen...|\n",
            "|Sci/Tech|\"The British Department for Education and Skill...|\n",
            "|Sci/Tech|\"confessed author of the Netsky and Sasser viru...|\n",
            "|Sci/Tech|\\\\FOAF/LOAF  and bloom filters have a lot of in...|\n",
            "|Sci/Tech|\"Wiltshire Police warns about \"\"phishing\"\" afte...|\n",
            "|Sci/Tech|In its first two years, the UK's dedicated card...|\n",
            "|Sci/Tech| A group of technology companies  including Tex...|\n",
            "|Sci/Tech| Apple Computer Inc.&lt;AAPL.O&gt; on  Tuesday ...|\n",
            "|Sci/Tech| Free Record Shop, a Dutch music  retail chain,...|\n",
            "|Sci/Tech|A giant 100km colony of ants  which has been di...|\n",
            "|Sci/Tech|                      \"Dolphin groups, or \"\"pods\"\"|\n",
            "|Sci/Tech|Tyrannosaurus rex achieved its massive size due...|\n",
            "|Sci/Tech|  Scientists have discovered irregular lumps be...|\n",
            "|Sci/Tech|  ESAs Mars Express has relayed pictures from o...|\n",
            "|Sci/Tech|When did life begin? One evidential clue stems ...|\n",
            "|Sci/Tech|update Earnings per share rise compared with a ...|\n",
            "+--------+--------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pyspark.sql.functions as F\n",
        "\n",
        "news_df = spark.read\\\n",
        "                .option(\"header\", \"true\")\\\n",
        "                .csv(\"news_category_test.csv\")\\\n",
        "                .withColumnRenamed(\"description\", \"text\")\n",
        "\n",
        "news_df.show(truncate=50)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "63MBKTTLdHZ5"
      },
      "source": [
        "Let's use the model `lemma_antbnc`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3pJIbvpbO_c",
        "outputId": "34e15bba-a771-4f21-b997-f404defd1836"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lemma_antbnc download started this may take some time.\n",
            "Approximate size to download 907.6 KB\n",
            "[OK!]\n"
          ]
        }
      ],
      "source": [
        "lemmatizer = LemmatizerModel.pretrained('lemma_antbnc', 'en') \\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"lemma\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "F6aWoxH8gdB5"
      },
      "outputs": [],
      "source": [
        "documentAssembler = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "tokenizer = Tokenizer() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "nlpPipeline = Pipeline(stages=[documentAssembler, \n",
        "                               tokenizer,\n",
        "                               lemmatizer])\n",
        "\n",
        "empty_df = spark.createDataFrame([['']]).toDF(\"text\")\n",
        "\n",
        "pipelineModel = nlpPipeline.fit(empty_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUSVidT4gg5m",
        "outputId": "5c7fdccb-a5ed-4965-93ec-f45b7082df27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+--------------------+--------------------+--------------------+--------------------+\n",
            "|category|                text|            document|               token|               lemma|\n",
            "+--------+--------------------+--------------------+--------------------+--------------------+\n",
            "|Business|Unions representi...|[{document, 0, 12...|[{token, 0, 5, Un...|[{token, 0, 5, Un...|\n",
            "|Sci/Tech| TORONTO, Canada ...|[{document, 0, 22...|[{token, 1, 7, TO...|[{token, 1, 7, TO...|\n",
            "|Sci/Tech| A company founde...|[{document, 0, 20...|[{token, 1, 1, A,...|[{token, 1, 1, A,...|\n",
            "|Sci/Tech| It's barely dawn...|[{document, 0, 26...|[{token, 1, 4, It...|[{token, 1, 4, It...|\n",
            "|Sci/Tech| Southern Califor...|[{document, 0, 17...|[{token, 1, 8, So...|[{token, 1, 8, So...|\n",
            "+--------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result = pipelineModel.transform(news_df)\n",
        "\n",
        "result.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBGCMNI7gl9r",
        "outputId": "83dfe804-a09d-4da0-b2b0-3dce43f59fc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+\n",
            "|                                                                                              result|                                                                                              result|\n",
            "+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+\n",
            "|[Unions, representing, workers, at, Turner, Newall, say, they, are, ', disappointed, ', after, ta...|[Unions, represent, worker, at, Turner, Newall, say, they, be, ', disappointed, ', after, talk, w...|\n",
            "|[TORONTO, ,, Canada, A, second, team, of, rocketeers, competing, for, the, #36;10, million, Ansar...|[TORONTO, ,, Canada, A, second, team, of, rocketeer, compete, for, the, #36;10, million, Ansari, ...|\n",
            "|[A, company, founded, by, a, chemistry, researcher, at, the, University, of, Louisville, won, a, ...|[A, company, founded, by, a, chemistry, researcher, at, the, University, of, Louisville, win, a, ...|\n",
            "|[It's, barely, dawn, when, Mike, Fitzpatrick, starts, his, shift, with, a, blur, of, colorful, ma...|[It's, barely, dawn, when, Mike, Fitzpatrick, start, he, shift, with, a, blur, of, colorful, map,...|\n",
            "|[Southern, California's, smog, fighting, agency, went, after, emissions, of, the, bovine, variety...|[Southern, California's, smog, fight, agency, go, after, emission, of, the, bovine, variety, Frid...|\n",
            "+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result.select('token.result','lemma.result').show(5, truncate=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "q4dI4P6gdPZ8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
