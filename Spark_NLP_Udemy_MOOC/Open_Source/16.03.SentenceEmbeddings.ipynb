{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"sXatvRX899i0"},"source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Open_Source/16.03.SentenceEmbeddings.ipynb)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"AOn8d1tcBkK3"},"source":["# **SentenceEmbeddings**"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"WimihSwD3vtH"},"source":["This notebook will cover the different parameters and usages of `SentenceEmbeddings`, an annotator used to convert word embeddings into sentence embeddings.\n","\n","**ðŸ“– Learning Objectives:**\n","\n","1. Use `SentenceEmbeddings` to turn word embeddings into sentence embeddings.\n","\n","2. Become comfortable using the different parameters of the annotator.\n","\n","3. Convert sentence embeddings into features that can be used to Spark ML regression or clustering functions.\n","\n","\n","**ðŸ”— Helpful Links:**\n","\n","- Documentation : [SentenceEmbeddings](https://nlp.johnsnowlabs.com/docs/en/annotators#sentenceembeddings)\n","\n","- Python Docs : [SentenceEmbeddings](https://nlp.johnsnowlabs.com/api/python/reference/autosummary/python/sparknlp/annotator/embeddings/sentence_embeddings/index.html#sparknlp.annotator.embeddings.sentence_embeddings.SentenceEmbeddings)\n","\n","- Scala Docs : [SentenceEmbeddings](https://nlp.johnsnowlabs.com/api/com/johnsnowlabs/nlp/embeddings/SentenceEmbeddings)\n","\n","- For extended examples of usage, see the [Spark NLP Workshop repository](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/5.1_Text_classification_examples_in_SparkML_SparkNLP.ipynb)."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"qL9lcISyFSLv"},"source":["## **ðŸ“œ Background**\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"TjDKOoZ4Fc8G"},"source":["Text embedding is one of the main steps before building any Deep Learning model in Natural Language Processing (NLP). This step of the pipeline consists in encoding words and sentences into high-dimensional numerical vectors in order to drastically improve the processing of textual data.\n","\n","Sentence embeddings can be used for text classification, semantic similarity, clustering, and other natural language tasks. Apart from `SentenceEmbeddings`, other annotators such as `UniversalSentenceEncoder`and `BERTSentenceEmbeddings` can be used for these tasks. You can find some examples of the use of sentence embeddings in the following blog posts about [text classification](https://towardsdatascience.com/text-classification-in-spark-nlp-with-bert-and-universal-sentence-encoders-e644d618ca32) and [sentence similarity](https://medium.com/spark-nlp/easy-sentence-similarity-with-bert-sentence-embeddings-using-john-snow-labs-nlu-ea078deb6ebf)."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"MfkkKkbVF309"},"source":["## **ðŸŽ¬ Colab Setup**"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30701,"status":"ok","timestamp":1674485767770,"user":{"displayName":"Mauro Nievas Offidani","userId":"07990177195800485445"},"user_tz":180},"id":"iMkMQtZNF2n-","outputId":"f4a03f1b-4935-41cc-a5ba-1a0b9e232512"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m212.4/212.4 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m448.4/448.4 KB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m198.6/198.6 KB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install -q pyspark==3.1.2  spark-nlp==4.2.4"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":39715,"status":"ok","timestamp":1674485807472,"user":{"displayName":"Mauro Nievas Offidani","userId":"07990177195800485445"},"user_tz":180},"id":"NulWi4_f4GN5"},"outputs":[],"source":["import sparknlp\n","from sparknlp.base import *\n","from sparknlp.annotator import *\n","from pyspark.ml import Pipeline\n","from pyspark.sql.functions import col, size\n","\n","spark = sparknlp.start()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"9Fbbk1bqcuA5"},"source":["## **ðŸ–¨ï¸ Input/Output Annotation Types**"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"0yFIrr5acsiU"},"source":["- Input: `DOCUMENT`, `WORD_EMBEDDINGS`\n","\n","- Output: `SENTENCE_EMBEDDINGS`"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"b2YJehUKMhb0"},"source":["## **ðŸ”Ž Parameters**\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"oidLDoS94asU"},"source":["- `dimension`: (Int) Number of embedding dimensions (Default: 100).\n","\n","- `poolingStrategy`: (String) Choose how you would like to aggregate Word Embeddings to Sentence Embeddings (Default: \"AVERAGE\"). Can either be \"AVERAGE\" or \"SUM\".\n","\n","- `storageRef`: (String) Unique identifier for storage (Default: this.uid)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"QtSTfa5TmNmQ"},"source":["## **Examples**"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"q-aqWpV0mnk3"},"source":["`SentenceEmbeddings` converts the word embeddings which result from annotators such as `WordEmbeddings` or `BertEmbeddings` into sentence or document embeddings by either summing up or averaging all the word embeddings in a sentence or a document. If you use the output of `DocumentAssembler` as the input for `Tokenizer` (as in the example below), SentenceEmbeddings will return an array of embeddings. On the other hand, if you use the output of `SentenceDetector`, `SentenceEmbeddings` will return one array of embeddings per sentence.\n","\n","By using `EmbeddingsFinisher` you can easily transform your embeddings into a more easily usable form."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20631,"status":"ok","timestamp":1674485828081,"user":{"displayName":"Mauro Nievas Offidani","userId":"07990177195800485445"},"user_tz":180},"id":"3hi17OkZmoQ2","outputId":"bb188c92-26e5-481b-aaa8-a9b8e67d6532"},"outputs":[{"name":"stdout","output_type":"stream","text":["glove_100d download started this may take some time.\n","Approximate size to download 145.3 MB\n","[OK!]\n"]}],"source":["document_assembler = DocumentAssembler() \\\n","      .setInputCol(\"text\") \\\n","      .setOutputCol(\"document\")\n","    \n","tokenizer = Tokenizer() \\\n","      .setInputCols([\"document\"]) \\\n","      .setOutputCol(\"token\")\n","\n","glove_embeddings = WordEmbeddingsModel().pretrained() \\\n","      .setInputCols([\"document\",'token'])\\\n","      .setOutputCol(\"embeddings\")\\\n","      .setCaseSensitive(False)\n","\n","sentence_embeddings = SentenceEmbeddings() \\\n","      .setInputCols([\"document\", \"embeddings\"]) \\\n","      .setOutputCol(\"sentence_embeddings\")\n","    \n","embeddings_finisher = EmbeddingsFinisher() \\\n","      .setInputCols([\"sentence_embeddings\"]) \\\n","      .setOutputCols([\"finished_sentence_embeddings\"])\n","\n","nlp_pipeline = Pipeline(\n","    stages=[document_assembler, \n","            tokenizer,\n","            glove_embeddings,\n","            sentence_embeddings,\n","            embeddings_finisher])\n","\n","text_df = spark.createDataFrame([[\"Sentence embeddings can be used for text classification, semantic similarity, clustering, and other natural language tasks.\"]]).toDF(\"text\")\n","\n","nlp_model = nlp_pipeline.fit(text_df)\n","\n","results = nlp_model.transform(text_df)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2494,"status":"ok","timestamp":1674485830558,"user":{"displayName":"Mauro Nievas Offidani","userId":"07990177195800485445"},"user_tz":180},"id":"uytEs559olUW","outputId":"85600725-1378-4d3c-8585-b941f5066946"},"outputs":[{"name":"stdout","output_type":"stream","text":["+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|sentence_embeddings                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n","+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|[{sentence_embeddings, 0, 122, Sentence embeddings can be used for text classification, semantic similarity, clustering, and other natural language tasks., {sentence -> 0, token -> Sentence embeddings can be used for text classification, semantic similarity, clustering, and other natural language tasks., pieceId -> -1, isWordStart -> true}, [-0.12791464, 0.42698997, 0.23708983, -0.10287435, 0.21044841, 0.108422115, -0.15264691, 0.05551195, -0.09587891, 0.13683523, -0.045580357, -0.26128367, 0.18115294, 0.07203667, 0.3771641, -0.005159448, 0.30595842, 0.093556605, -0.28294563, 0.228062, -0.07328449, -0.20441934, 0.36461097, 0.25488788, 0.11517898, -0.1613116, 0.032625556, -0.17831266, -0.18313715, -0.118618205, -0.14995119, 0.30124414, -0.38840234, -0.19265306, 0.26580945, 0.21583292, 0.17575458, 0.14103584, 0.055819236, -0.21481952, -0.24850014, -0.2731791, 0.0037935176, -0.19180886, -0.195809, 0.066877104, 0.20016941, -0.3136445, -0.23710851, -0.3129894, 0.22292271, -0.13626441, 0.19329114, 1.0013162, -0.08933382, -1.5649455, 0.038891356, -0.23150817, 1.2152109, 0.5186803, -0.24488933, 0.47831148, -0.11456923, -0.033168845, 0.8212805, -0.08892574, 0.4014867, 0.07526895, 0.3690719, -0.2343363, -0.32152992, -0.14876547, 0.30185807, -0.29125825, 0.18998763, 0.072837085, -0.13999684, -0.02471565, -0.682374, -0.12240086, 0.33664995, -0.2684685, -0.55078256, 0.050746154, -1.301523, 0.17680426, 0.13992937, -0.2645202, -0.03832919, -0.25311002, -0.25999936, -0.15318301, -0.084904306, 0.22642164, -0.17249343, 0.0568384, -0.32607296, -0.6217123, 0.41408092, 0.21118245]}]|\n","+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","\n"]}],"source":["results.select('sentence_embeddings').show(truncate = False)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1674485830559,"user":{"displayName":"Mauro Nievas Offidani","userId":"07990177195800485445"},"user_tz":180},"id":"FpfsACc-ny5f","outputId":"bec0fa06-9f10-46ec-8e67-6fcd61d6eea4"},"outputs":[{"name":"stdout","output_type":"stream","text":["+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|finished_sentence_embeddings                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|[[-0.12791464, 0.42698997, 0.23708983, -0.10287435, 0.21044841, 0.108422115, -0.15264691, 0.05551195, -0.09587891, 0.13683523, -0.045580357, -0.26128367, 0.18115294, 0.07203667, 0.3771641, -0.005159448, 0.30595842, 0.093556605, -0.28294563, 0.228062, -0.07328449, -0.20441934, 0.36461097, 0.25488788, 0.11517898, -0.1613116, 0.032625556, -0.17831266, -0.18313715, -0.118618205, -0.14995119, 0.30124414, -0.38840234, -0.19265306, 0.26580945, 0.21583292, 0.17575458, 0.14103584, 0.055819236, -0.21481952, -0.24850014, -0.2731791, 0.0037935176, -0.19180886, -0.195809, 0.066877104, 0.20016941, -0.3136445, -0.23710851, -0.3129894, 0.22292271, -0.13626441, 0.19329114, 1.0013162, -0.08933382, -1.5649455, 0.038891356, -0.23150817, 1.2152109, 0.5186803, -0.24488933, 0.47831148, -0.11456923, -0.033168845, 0.8212805, -0.08892574, 0.4014867, 0.07526895, 0.3690719, -0.2343363, -0.32152992, -0.14876547, 0.30185807, -0.29125825, 0.18998763, 0.072837085, -0.13999684, -0.02471565, -0.682374, -0.12240086, 0.33664995, -0.2684685, -0.55078256, 0.050746154, -1.301523, 0.17680426, 0.13992937, -0.2645202, -0.03832919, -0.25311002, -0.25999936, -0.15318301, -0.084904306, 0.22642164, -0.17249343, 0.0568384, -0.32607296, -0.6217123, 0.41408092, 0.21118245]]|\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","\n"]}],"source":["results.select('finished_sentence_embeddings').show(truncate = False)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"DQ88eDCxTsD3"},"source":["### `setPoolingStrategy()`"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"8EFZsxV1HxXb"},"source":["Sentence embeddings can be calculated either by summing up or by averaging all the word embeddings. The `setPoolingStrategy` method is used to select between these two options (by default, the pooling strategy is average)."]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4906,"status":"ok","timestamp":1674485835455,"user":{"displayName":"Mauro Nievas Offidani","userId":"07990177195800485445"},"user_tz":180},"id":"0hWNC0Y_RS27","outputId":"48053958-1368-49fa-c8d1-9bc56d4e70d9"},"outputs":[{"name":"stdout","output_type":"stream","text":["glove_100d download started this may take some time.\n","Approximate size to download 145.3 MB\n","[OK!]\n"]}],"source":["document_assembler = DocumentAssembler() \\\n","      .setInputCol(\"text\") \\\n","      .setOutputCol(\"document\")\n","    \n","tokenizer = Tokenizer() \\\n","      .setInputCols([\"document\"]) \\\n","      .setOutputCol(\"token\")\n","\n","glove_embeddings = WordEmbeddingsModel().pretrained() \\\n","      .setInputCols([\"document\",'token'])\\\n","      .setOutputCol(\"embeddings\")\\\n","      .setCaseSensitive(False)\n","\n","sentence_embeddings_1 = SentenceEmbeddings() \\\n","      .setInputCols([\"document\", \"embeddings\"]) \\\n","      .setOutputCol(\"average_sentence_embeddings\")\\\n","      .setPoolingStrategy('AVERAGE')\n","    \n","embeddings_finisher_1 = EmbeddingsFinisher() \\\n","      .setInputCols([\"average_sentence_embeddings\"]) \\\n","      .setOutputCols([\"average_pooling_strategy\"])\n","\n","sentence_embeddings_2 = SentenceEmbeddings() \\\n","      .setInputCols([\"document\", \"embeddings\"]) \\\n","      .setOutputCol(\"sum_sentence_embeddings\")\\\n","      .setPoolingStrategy('SUM')\n","    \n","embeddings_finisher_2 = EmbeddingsFinisher() \\\n","      .setInputCols([\"sum_sentence_embeddings\"]) \\\n","      .setOutputCols([\"sum_pooling_strategy\"])\n","\n","nlp_pipeline = Pipeline(\n","    stages=[document_assembler, \n","            tokenizer,\n","            glove_embeddings,\n","            sentence_embeddings_1,\n","            embeddings_finisher_1,\n","            sentence_embeddings_2,\n","            embeddings_finisher_2])\n","\n","text_df = spark.createDataFrame([[\"Sentence embeddings can be used for text classification, semantic similarity, clustering, and other natural language tasks.\"]]).toDF(\"text\")\n","\n","nlp_model = nlp_pipeline.fit(text_df)\n","\n","results = nlp_model.transform(text_df)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1674485835456,"user":{"displayName":"Mauro Nievas Offidani","userId":"07990177195800485445"},"user_tz":180},"id":"b24Zqpqg2G2Q","outputId":"e4d68a27-a6e2-4e80-edf2-7dee2b1b3c94"},"outputs":[{"name":"stdout","output_type":"stream","text":["+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|average_pooling_strategy                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|[[-0.12791464, 0.42698997, 0.23708983, -0.10287435, 0.21044841, 0.108422115, -0.15264691, 0.05551195, -0.09587891, 0.13683523, -0.045580357, -0.26128367, 0.18115294, 0.07203667, 0.3771641, -0.005159448, 0.30595842, 0.093556605, -0.28294563, 0.228062, -0.07328449, -0.20441934, 0.36461097, 0.25488788, 0.11517898, -0.1613116, 0.032625556, -0.17831266, -0.18313715, -0.118618205, -0.14995119, 0.30124414, -0.38840234, -0.19265306, 0.26580945, 0.21583292, 0.17575458, 0.14103584, 0.055819236, -0.21481952, -0.24850014, -0.2731791, 0.0037935176, -0.19180886, -0.195809, 0.066877104, 0.20016941, -0.3136445, -0.23710851, -0.3129894, 0.22292271, -0.13626441, 0.19329114, 1.0013162, -0.08933382, -1.5649455, 0.038891356, -0.23150817, 1.2152109, 0.5186803, -0.24488933, 0.47831148, -0.11456923, -0.033168845, 0.8212805, -0.08892574, 0.4014867, 0.07526895, 0.3690719, -0.2343363, -0.32152992, -0.14876547, 0.30185807, -0.29125825, 0.18998763, 0.072837085, -0.13999684, -0.02471565, -0.682374, -0.12240086, 0.33664995, -0.2684685, -0.55078256, 0.050746154, -1.301523, 0.17680426, 0.13992937, -0.2645202, -0.03832919, -0.25311002, -0.25999936, -0.15318301, -0.084904306, 0.22642164, -0.17249343, 0.0568384, -0.32607296, -0.6217123, 0.41408092, 0.21118245]]|\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","\n"]}],"source":["results.select('average_pooling_strategy').show(truncate = False)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1674485835457,"user":{"displayName":"Mauro Nievas Offidani","userId":"07990177195800485445"},"user_tz":180},"id":"y3gvm9HP2Lok","outputId":"4ed44a14-47d0-43fb-f361-31d13fcbbe18"},"outputs":[{"name":"stdout","output_type":"stream","text":["+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|sum_pooling_strategy                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|[[-2.5582929, 8.5398, 4.7417965, -2.057487, 4.208968, 2.1684422, -3.0529382, 1.110239, -1.9175781, 2.7367046, -0.91160715, -5.225673, 3.6230588, 1.4407333, 7.543282, -0.10318896, 6.1191683, 1.8711321, -5.6589127, 4.56124, -1.4656898, -4.088387, 7.2922196, 5.0977573, 2.3035796, -3.2262318, 0.6525111, -3.5662532, -3.6627429, -2.372364, -2.9990237, 6.024883, -7.768047, -3.8530612, 5.316189, 4.3166585, 3.5150914, 2.8207169, 1.1163847, -4.2963905, -4.9700027, -5.4635825, 0.07587035, -3.8361773, -3.9161801, 1.337542, 4.0033884, -6.27289, -4.7421703, -6.2597885, 4.458454, -2.7252882, 3.8658228, 20.026323, -1.7866764, -31.298908, 0.77782714, -4.630163, 24.304218, 10.373606, -4.8977866, 9.56623, -2.2913847, -0.6633769, 16.42561, -1.7785149, 8.029734, 1.505379, 7.3814383, -4.686726, -6.4305987, -2.9753096, 6.0371614, -5.825165, 3.7997527, 1.4567417, -2.7999368, -0.49431303, -13.64748, -2.4480171, 6.7329993, -5.36937, -11.015651, 1.0149231, -26.030458, 3.5360851, 2.7985873, -5.290404, -0.76658386, -5.0622005, -5.1999874, -3.0636601, -1.6980861, 4.528433, -3.4498687, 1.136768, -6.521459, -12.434246, 8.281618, 4.223649]]|\n","+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","\n"]}],"source":["results.select('sum_pooling_strategy').show(truncate = False)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":509,"status":"ok","timestamp":1674485835946,"user":{"displayName":"Mauro Nievas Offidani","userId":"07990177195800485445"},"user_tz":180},"id":"LcLdIIw6DJIP","outputId":"e0a07a0b-1073-4b28-9fae-65c47637a1fb"},"outputs":[{"name":"stdout","output_type":"stream","text":["+---------------------+-----------------+\n","|average_strategy_size|sum_strategy_size|\n","+---------------------+-----------------+\n","|                  100|              100|\n","+---------------------+-----------------+\n","\n"]}],"source":["results.withColumn('average_strategy_size', size(col('average_pooling_strategy')[0]))\\\n","       .withColumn('sum_strategy_size', size(col('sum_pooling_strategy')[0]))\\\n","       .select('average_strategy_size', 'sum_strategy_size').show()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"NjWJaUcxJRXu"},"source":["The pooling strategy affects the way in which sentence embeddings are calculated, but it does not affect the their dimensions."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ot_m-0yithqJ"},"source":["### Converting embeddings into feature vectors"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"zqDDUzLJuDJP"},"source":["In order to be able to use sentence embeddings in Spark ML regression or clustering functions, the vector needs to be exploded. This can be done inside or outside the NLP pipeline."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"If-p1xSBEuEK"},"source":["- Exploding inside the NLP pipeline:"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1674485835947,"user":{"displayName":"Mauro Nievas Offidani","userId":"07990177195800485445"},"user_tz":180},"id":"lx6OLTpD3kL6"},"outputs":[],"source":["from pyspark.ml.feature import SQLTransformer"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4599,"status":"ok","timestamp":1674485840538,"user":{"displayName":"Mauro Nievas Offidani","userId":"07990177195800485445"},"user_tz":180},"id":"q-2Y-Zj6uDYg","outputId":"9aaaf563-9fc2-49e7-8722-d49da3e914b0"},"outputs":[{"name":"stdout","output_type":"stream","text":["glove_100d download started this may take some time.\n","Approximate size to download 145.3 MB\n","[OK!]\n"]}],"source":["document_assembler = DocumentAssembler() \\\n","      .setInputCol(\"text\") \\\n","      .setOutputCol(\"document\")\n","    \n","tokenizer = Tokenizer() \\\n","      .setInputCols([\"document\"]) \\\n","      .setOutputCol(\"token\")\n","\n","glove_embeddings = WordEmbeddingsModel().pretrained() \\\n","      .setInputCols([\"document\",'token'])\\\n","      .setOutputCol(\"embeddings\")\\\n","      .setCaseSensitive(False)\n","\n","sentence_embeddings = SentenceEmbeddings() \\\n","      .setInputCols([\"document\", \"embeddings\"]) \\\n","      .setOutputCol(\"sentence_embeddings\")\n","    \n","embeddings_finisher = EmbeddingsFinisher() \\\n","      .setInputCols([\"sentence_embeddings\"]) \\\n","      .setOutputCols([\"finished_sentence_embeddings\"])\\\n","      .setOutputAsVector(True)\\\n","      .setCleanAnnotations(False)\n","\n","explodeVectors = SQLTransformer(statement=\n","      \"SELECT EXPLODE(finished_sentence_embeddings) AS features, * FROM __THIS__\")\n","\n","nlp_pipeline = Pipeline(\n","    stages=[document_assembler, \n","            tokenizer,\n","            glove_embeddings,\n","            sentence_embeddings,\n","            embeddings_finisher,\n","            explodeVectors])\n","\n","text_df = spark.createDataFrame([[\"Sentence embeddings can be used for text classification, semantic similarity, clustering, and other natural language tasks.\"]]).toDF(\"text\")\n","\n","nlp_model = nlp_pipeline.fit(text_df)\n","\n","results = nlp_model.transform(text_df)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1779,"status":"ok","timestamp":1674485842311,"user":{"displayName":"Mauro Nievas Offidani","userId":"07990177195800485445"},"user_tz":180},"id":"b30m_FefFCgU","outputId":"a39ba695-cd03-400f-a9a8-03b02b3a0b19"},"outputs":[{"data":{"text/plain":["[Row(features=DenseVector([-0.1279, 0.427, 0.2371, -0.1029, 0.2104, 0.1084, -0.1526, 0.0555, -0.0959, 0.1368, -0.0456, -0.2613, 0.1812, 0.072, 0.3772, -0.0052, 0.306, 0.0936, -0.2829, 0.2281, -0.0733, -0.2044, 0.3646, 0.2549, 0.1152, -0.1613, 0.0326, -0.1783, -0.1831, -0.1186, -0.15, 0.3012, -0.3884, -0.1927, 0.2658, 0.2158, 0.1758, 0.141, 0.0558, -0.2148, -0.2485, -0.2732, 0.0038, -0.1918, -0.1958, 0.0669, 0.2002, -0.3136, -0.2371, -0.313, 0.2229, -0.1363, 0.1933, 1.0013, -0.0893, -1.5649, 0.0389, -0.2315, 1.2152, 0.5187, -0.2449, 0.4783, -0.1146, -0.0332, 0.8213, -0.0889, 0.4015, 0.0753, 0.3691, -0.2343, -0.3215, -0.1488, 0.3019, -0.2913, 0.19, 0.0728, -0.14, -0.0247, -0.6824, -0.1224, 0.3366, -0.2685, -0.5508, 0.0507, -1.3015, 0.1768, 0.1399, -0.2645, -0.0383, -0.2531, -0.26, -0.1532, -0.0849, 0.2264, -0.1725, 0.0568, -0.3261, -0.6217, 0.4141, 0.2112]))]"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["results.select('features').take(1)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"qaTILw5LE3Vo"},"source":["- Exploding outside the NLP pipeline:"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":395,"status":"ok","timestamp":1674485842700,"user":{"displayName":"Mauro Nievas Offidani","userId":"07990177195800485445"},"user_tz":180},"id":"dHq5O2z5E6P4","outputId":"6a1dfda2-b0b6-426c-9118-9c4775db7e1a"},"outputs":[{"data":{"text/plain":["[Row(exploded_features=DenseVector([-0.1279, 0.427, 0.2371, -0.1029, 0.2104, 0.1084, -0.1526, 0.0555, -0.0959, 0.1368, -0.0456, -0.2613, 0.1812, 0.072, 0.3772, -0.0052, 0.306, 0.0936, -0.2829, 0.2281, -0.0733, -0.2044, 0.3646, 0.2549, 0.1152, -0.1613, 0.0326, -0.1783, -0.1831, -0.1186, -0.15, 0.3012, -0.3884, -0.1927, 0.2658, 0.2158, 0.1758, 0.141, 0.0558, -0.2148, -0.2485, -0.2732, 0.0038, -0.1918, -0.1958, 0.0669, 0.2002, -0.3136, -0.2371, -0.313, 0.2229, -0.1363, 0.1933, 1.0013, -0.0893, -1.5649, 0.0389, -0.2315, 1.2152, 0.5187, -0.2449, 0.4783, -0.1146, -0.0332, 0.8213, -0.0889, 0.4015, 0.0753, 0.3691, -0.2343, -0.3215, -0.1488, 0.3019, -0.2913, 0.19, 0.0728, -0.14, -0.0247, -0.6824, -0.1224, 0.3366, -0.2685, -0.5508, 0.0507, -1.3015, 0.1768, 0.1399, -0.2645, -0.0383, -0.2531, -0.26, -0.1532, -0.0849, 0.2264, -0.1725, 0.0568, -0.3261, -0.6217, 0.4141, 0.2112]))]"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["from pyspark.sql.functions import explode\n","\n","results = results.withColumn(\"exploded_features\", explode(results.finished_sentence_embeddings))\n","\n","results.select(\"exploded_features\").take(1)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"kYnVPX5hRx5_"},"source":["## Training a ClassifierDL Model with Sentence Embeddings"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"lqVZNMqYJOpD"},"source":["Now we are going to use our sentence embeddings to train a ClassifierDL Model. First, we need to download our dataset."]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":730,"status":"ok","timestamp":1674485843425,"user":{"displayName":"Mauro Nievas Offidani","userId":"07990177195800485445"},"user_tz":180},"id":"5mPIFjPdSgtv"},"outputs":[],"source":["! wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/data/news_category_train.csv"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2002,"status":"ok","timestamp":1674485845421,"user":{"displayName":"Mauro Nievas Offidani","userId":"07990177195800485445"},"user_tz":180},"id":"nW0ZAbC7ShFE","outputId":"0d971703-8713-4d7e-f3cf-a2a0a8f03f71"},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------+--------------------------------------------------+\n","|category|                                       description|\n","+--------+--------------------------------------------------+\n","|Business| Short sellers, Wall Street's dwindling band of...|\n","|Business| Private investment firm Carlyle Group, which h...|\n","|Business| Soaring crude prices plus worries about the ec...|\n","|Business| Authorities have halted oil export flows from ...|\n","|Business| Tearaway world oil prices, toppling records an...|\n","|Business| Stocks ended slightly higher on Friday but sta...|\n","|Business| Assets of the nation's retail money market mut...|\n","|Business| Retail sales bounced back a bit in July, and n...|\n","|Business|\" After earning a PH.D. in Sociology, Danny Baz...|\n","|Business| Short sellers, Wall Street's dwindling  band o...|\n","+--------+--------------------------------------------------+\n","only showing top 10 rows\n","\n"]}],"source":["trainDataset = spark.read \\\n","      .option(\"header\", True) \\\n","      .csv(\"news_category_train.csv\")\n","\n","trainDataset.show(10, truncate=50)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Ozd5KKKGJ0pD"},"source":["In this dataset, news are classified into 4 categories:"]},{"cell_type":"code","execution_count":69,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":993,"status":"ok","timestamp":1674488109635,"user":{"displayName":"Mauro Nievas Offidani","userId":"07990177195800485445"},"user_tz":180},"id":"WFlLyyyLJkn_","outputId":"6dffcd74-19e2-447a-f822-72be6a34417f"},"outputs":[{"data":{"text/plain":["[Row(category='World'),\n"," Row(category='Sci/Tech'),\n"," Row(category='Sports'),\n"," Row(category='Business')]"]},"execution_count":69,"metadata":{},"output_type":"execute_result"}],"source":["trainDataset.select('category').distinct().collect()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"OEROwFTaJ7Ti"},"source":["Let's create our pipeline and fit our training data."]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2746,"status":"ok","timestamp":1674485848157,"user":{"displayName":"Mauro Nievas Offidani","userId":"07990177195800485445"},"user_tz":180},"id":"QElwkX1VS6nq","outputId":"a48fa348-cdaf-497f-b52c-f8d3d3570b3c"},"outputs":[{"name":"stdout","output_type":"stream","text":["glove_100d download started this may take some time.\n","Approximate size to download 145.3 MB\n","[OK!]\n"]}],"source":["document_assembler = DocumentAssembler() \\\n","      .setInputCol(\"description\") \\\n","      .setOutputCol(\"document\")\n","    \n","tokenizer = Tokenizer() \\\n","      .setInputCols([\"document\"]) \\\n","      .setOutputCol(\"token\")\n","\n","glove_embeddings = WordEmbeddingsModel().pretrained() \\\n","      .setInputCols([\"document\",'token'])\\\n","      .setOutputCol(\"embeddings\")\\\n","      .setCaseSensitive(False)\n","\n","sentence_embeddings = SentenceEmbeddings() \\\n","      .setInputCols([\"document\", \"embeddings\"]) \\\n","      .setOutputCol(\"sentence_embeddings\")\n","\n","classifier_dl = ClassifierDLApproach()\\\n","      .setInputCols([\"sentence_embeddings\"])\\\n","      .setOutputCol(\"class\")\\\n","      .setLabelColumn(\"category\")\\\n","      .setMaxEpochs(3)\n","\n","nlp_pipeline = Pipeline(\n","    stages=[document_assembler, \n","            tokenizer,\n","            glove_embeddings,\n","            sentence_embeddings,\n","            classifier_dl])"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":137729,"status":"ok","timestamp":1674485985880,"user":{"displayName":"Mauro Nievas Offidani","userId":"07990177195800485445"},"user_tz":180},"id":"0nYD3XlBUbhZ"},"outputs":[],"source":["clf_model = nlp_pipeline.fit(trainDataset)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"VyIF2wpmUyhn"},"source":["You can look at further examples in our [GitHub repo](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/5.Text_Classification_with_ClassifierDL.ipynb) or in this [Blog post](https://towardsdatascience.com/text-classification-in-spark-nlp-with-bert-and-universal-sentence-encoders-e644d618ca32)."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Q6rfsmOlU28Y"},"source":["## Use Sentence Embeddings to Calculate Sentence Similarity"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"oez5G4wlOnkx"},"source":["Sentence embeddings can be used to calculate similarity between sentences. For this, we need to import scipy and numpy, create a pipeline, and then use it to get embeddings from some sample sentences."]},{"cell_type":"code","execution_count":60,"metadata":{"executionInfo":{"elapsed":294,"status":"ok","timestamp":1674487893849,"user":{"displayName":"Mauro Nievas Offidani","userId":"07990177195800485445"},"user_tz":180},"id":"c6NDllGAPgH-"},"outputs":[],"source":["from scipy.spatial import distance\n","import numpy as np"]},{"cell_type":"code","execution_count":61,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4643,"status":"ok","timestamp":1674487900924,"user":{"displayName":"Mauro Nievas Offidani","userId":"07990177195800485445"},"user_tz":180},"id":"bwBnlryheodK","outputId":"8a1d937f-bebb-45be-ecc9-b74f10f567ba"},"outputs":[{"name":"stdout","output_type":"stream","text":["glove_100d download started this may take some time.\n","Approximate size to download 145.3 MB\n","[OK!]\n"]}],"source":["document_assembler = DocumentAssembler() \\\n","      .setInputCol(\"text\") \\\n","      .setOutputCol(\"document\")\n","    \n","tokenizer = Tokenizer() \\\n","      .setInputCols([\"document\"]) \\\n","      .setOutputCol(\"token\")\n","\n","glove_embeddings = WordEmbeddingsModel().pretrained() \\\n","      .setInputCols([\"document\",'token'])\\\n","      .setOutputCol(\"embeddings\")\\\n","      .setCaseSensitive(False)\n","\n","sentence_embeddings = SentenceEmbeddings() \\\n","      .setInputCols([\"document\", \"embeddings\"]) \\\n","      .setOutputCol(\"sentence_embeddings\")\n","\n","nlp_pipeline = Pipeline(\n","    stages=[document_assembler, \n","            tokenizer,\n","            glove_embeddings,\n","            sentence_embeddings])\n","\n","empty_df = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n","\n","nlp_model = nlp_pipeline.fit(empty_df)"]},{"cell_type":"code","execution_count":62,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1674487900925,"user":{"displayName":"Mauro Nievas Offidani","userId":"07990177195800485445"},"user_tz":180},"id":"X27E0qd-exrI"},"outputs":[],"source":["sentence_0 = \"The patient was diagnosed with diabetes.\"\n","sentence_1 = \"A diabetic foot is any pathology that results directly from peripheral arterial disease.\"\n","sentence_2 = \"She does physical activity every day.\"\n","\n","sentence_df = spark.createDataFrame([[sentence_0], [sentence_1], [sentence_2]]).toDF(\"text\")"]},{"cell_type":"code","execution_count":63,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1674487900925,"user":{"displayName":"Mauro Nievas Offidani","userId":"07990177195800485445"},"user_tz":180},"id":"tVoTcJrlNDF_","outputId":"0444366a-733a-4cc1-ffb1-7cf841ffe3cd"},"outputs":[{"name":"stdout","output_type":"stream","text":["+----------------------------------------------------------------------------------------+\n","|text                                                                                    |\n","+----------------------------------------------------------------------------------------+\n","|The patient was diagnosed with diabetes.                                                |\n","|A diabetic foot is any pathology that results directly from peripheral arterial disease.|\n","|She does physical activity every day.                                                   |\n","+----------------------------------------------------------------------------------------+\n","\n"]}],"source":["sentence_df.show(truncate = False)"]},{"cell_type":"code","execution_count":64,"metadata":{"executionInfo":{"elapsed":422,"status":"ok","timestamp":1674487901985,"user":{"displayName":"Mauro Nievas Offidani","userId":"07990177195800485445"},"user_tz":180},"id":"ri0mSt3VMejH"},"outputs":[],"source":["embeddings = nlp_model.transform(sentence_df).select('sentence_embeddings.embeddings').collect()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Fg00AQPtP0U7"},"source":["Once we have the embeddings, we need to turn them into arrays in order to use them to calculate cosine distances."]},{"cell_type":"code","execution_count":65,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1674487903652,"user":{"displayName":"Mauro Nievas Offidani","userId":"07990177195800485445"},"user_tz":180},"id":"bYrnamjsPx_z"},"outputs":[],"source":["v0 = np.array(embeddings[0]['embeddings'])\n","v1 = np.array(embeddings[1]['embeddings'])\n","v2 = np.array(embeddings[2]['embeddings'])"]},{"cell_type":"code","execution_count":66,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1674487904019,"user":{"displayName":"Mauro Nievas Offidani","userId":"07990177195800485445"},"user_tz":180},"id":"1QKJGxiNOMr0"},"outputs":[],"source":["similarity_a = 1 - distance.cosine(v0, v1)\n","similarity_b = 1 - distance.cosine(v1, v2)\n","similarity_c = 1 - distance.cosine(v2, v0)"]},{"cell_type":"code","execution_count":67,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1674487905730,"user":{"displayName":"Mauro Nievas Offidani","userId":"07990177195800485445"},"user_tz":180},"id":"bAQSUTInOUVs","outputId":"4e95f26c-de41-4715-c677-36f1ba38ab79"},"outputs":[{"data":{"text/plain":["(0.9166266555913121, 0.8655254538729918, 0.8406160060116418)"]},"execution_count":67,"metadata":{},"output_type":"execute_result"}],"source":["similarity_a, similarity_b, similarity_c"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"rU7fOqUIQJPt"},"source":["The pair of sentences with higher similarity are sentence_0 and sentence_1, which makes sense considering that they both refer to patients with diabetes.\n","\n","You can find another example of sentence similarity in [this blog post](https://medium.com/spark-nlp/easy-sentence-similarity-with-bert-sentence-embeddings-using-john-snow-labs-nlu-ea078deb6ebf)."]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[{"file_id":"1L8GdQ-yorjVk_V8Um6Rw6aEzFVT31OCO","timestamp":1672941527684},{"file_id":"1VVV4jTagH47UZiKFqXoP-Abq5ozZM1BV","timestamp":1672918708428},{"file_id":"https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb","timestamp":1671914287039}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":0}
