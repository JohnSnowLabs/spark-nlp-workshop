{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ISkb1pTfKDSp"
      },
      "source": [
        "\n",
        "\n",
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Open_Source/10.01.RegexMatcher.ipynb)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "S_Yeia5H8gMd"
      },
      "source": [
        "# **RegexMatcher**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qjDkn9GwQ6P3"
      },
      "source": [
        "This notebook will cover the different parameters and usages of the `RegexMatcher` annotator. This annotator provides the ability to tag occurrences of regex patterns in raw text.\n",
        "\n",
        "**üìñ Learning Objectives:**\n",
        "\n",
        "1. Find occurrences of *regular expression (regex)* patterns in text\n",
        "2. Set one or more regex rules and assign an `identifier` for each regex rule\n",
        "3. Create and use external regex rules file\n",
        "4. Change the matching strategy of `RegexMatcher`\n",
        "\n",
        "**üîó Helpful Links:**\n",
        "\n",
        "- Documentation : [RegexMatcher](https://nlp.johnsnowlabs.com/docs/en/annotators#regexmatcher)\n",
        "\n",
        "- Python Docs :  [RegexMatcher](https://nlp.johnsnowlabs.com/api/python/reference/autosummary/sparknlp/annotator/matcher/regex_matcher/index.html)\n",
        "\n",
        "\n",
        "- Scala Docs :  [RegexMatcher](https://nlp.johnsnowlabs.com/api/com/johnsnowlabs/nlp/annotators/RegexMatcher.html)\n",
        "\n",
        "- For extended examples of usage, see the [Spark NLP Workshop repository](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/)."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "yEtEexu3RCJ2"
      },
      "source": [
        "## **üìú Background**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "l6IsWbZn9Psl"
      },
      "source": [
        "`RegexMatcher` uses rules to match a set of regular expressions and associate them with a provided `identifier`. It can be thought of as the regex-based version of the `TextMatcher` and can provide lots of flexibility when implementing rule-based captures.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "a7DUtZC_pTY4"
      },
      "source": [
        "## **üé¨ Colab Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6o8-g0tEqNz",
        "outputId": "b2f21c10-db16-4422-ffd3-35621bd0d73d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m469.5/469.5 KB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Install PySpark and Spark NLP\n",
        "! pip install -q pyspark==3.3.1 spark-nlp==4.3.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "yMmT9S6mE0ad",
        "outputId": "f40cf246-7caa-4d02-e553-ade0102f15e0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://785f341a7de9:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.3.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark NLP</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f82cdff6310>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import sparknlp\n",
        "from sparknlp.annotator import DocumentAssembler, RegexMatcher\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.types import StringType\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "spark = sparknlp.start()\n",
        "spark"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "EZ1Zyu-VRiBF"
      },
      "source": [
        "## **üñ®Ô∏è Inputs/Output Annotation Types:**\n",
        "\n",
        "- Input Annotation types: `DOCUMENT`\n",
        "\n",
        "- Output Annotation type: `CHUNK`"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xMsu4JlOmvRM"
      },
      "source": [
        "## **üîé Parameters**\n",
        "\n",
        "- `rules`: (StringArrayParam) Rules with regex pattern and identifiers for matching.\n",
        "\n",
        "- `externalRules`: (StringArrayParam) External resource to rules, needs 'delimiter' in options.\n",
        "\n",
        "- `delimiter`: (String) Delimiter for rules provided with setRules.\n",
        "\n",
        "- `strategy`: (String)  Strategy for which to match the expressions. (Default: \"MATCH_ALL\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "uzYt3Mcp_Dq-"
      },
      "source": [
        "### `setRules`"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NCmVgWzV_WP0"
      },
      "source": [
        "Here `\\d{4}\\/\\d\\d\\/\\d\\d,date` is a `date` rule. In this rule, `regex_pattern` and the `identifier` is separated with delimeter `,`.\n",
        "\n",
        "We need to add this rule to `setRules()` and provide the delimeter by `setDelimiter()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9WYB2E8_TZI",
        "outputId": "14a6dcf9-e876-42b9-ae8c-424d060a5736"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------------------------------------------------+----------------------+\n",
            "|                                                  text|                result|\n",
            "+------------------------------------------------------+----------------------+\n",
            "|                                  Today is 2010/10/10.|          [2010/10/10]|\n",
            "|                           She was born on 1966/02/03.|          [1966/02/03]|\n",
            "|The project started on 89/01/01 and ended on 89/04/25.|[ 89/01/01,  89/04/25]|\n",
            "+------------------------------------------------------+----------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "documentAssembler = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "regex_matcher = RegexMatcher()\\\n",
        "    .setRules([\"\\d{4}\\/\\d\\d\\/\\d\\d,date\", \"\\s\\d{2}\\/\\d\\d\\/\\d\\d,short_date\"]) \\\n",
        "    .setDelimiter(\",\") \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"matched_text\") \\\n",
        "    .setStrategy(\"MATCH_ALL\")\n",
        "\n",
        "\n",
        "nlpPipeline = Pipeline(stages=[documentAssembler,regex_matcher])\n",
        "\n",
        "text_list = [\"Today is 2010/10/10.\",  \"She was born on 1966/02/03.\", \"The project started on 89/01/01 and ended on 89/04/25.\"]\n",
        "spark_df = spark.createDataFrame(text_list, StringType()).toDF(\"text\")\n",
        "\n",
        "result = nlpPipeline.fit(spark_df).transform(spark_df)\n",
        "result.select('text','matched_text.result').show(truncate=120)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_B7NBy3DBn1",
        "outputId": "acfedacf-3835-4437-90a5-df4aef571f17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|matched_text                                                                                                                                                                  |\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|[{chunk, 9, 18, 2010/10/10, {identifier -> date, sentence -> 0, chunk -> 0}, []}]                                                                                             |\n",
            "|[{chunk, 16, 25, 1966/02/03, {identifier -> date, sentence -> 0, chunk -> 0}, []}]                                                                                            |\n",
            "|[{chunk, 22, 30,  89/01/01, {identifier -> short_date, sentence -> 0, chunk -> 0}, []}, {chunk, 44, 52,  89/04/25, {identifier -> short_date, sentence -> 0, chunk -> 1}, []}]|\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result.select('matched_text').show(truncate=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "v7o8nYmVDH_i"
      },
      "source": [
        "Showing the results with its `identifier`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_PQ0OpO_TVO",
        "outputId": "01b2bf1f-c5dd-4f4a-a828-0eb7e2263574"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+----------+\n",
            "|Matches Found|identifier|\n",
            "+-------------+----------+\n",
            "|   2010/10/10|      date|\n",
            "|   1966/02/03|      date|\n",
            "|     89/01/01|short_date|\n",
            "|     89/04/25|short_date|\n",
            "+-------------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result.select(F.explode(F.arrays_zip(result.matched_text.result,\n",
        "                                     result.matched_text.metadata)).alias(\"cols\")) \\\n",
        "       .select(F.expr(\"cols['0']\").alias(\"Matches Found\"),\n",
        "               F.expr(\"cols['1']['identifier']\").alias(\"identifier\")).show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "n9faZW7HLZfd"
      },
      "source": [
        "### `setExternalRules`"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "U-bQmTPTEtZS"
      },
      "source": [
        "To use an external file that includes a dictionary of predefined regular expressions, we must use `setExternalRules()`. The dictionary can be set in the form of a delimited text file, the same as `setRules()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z83Hk7QHFFXD"
      },
      "outputs": [],
      "source": [
        "rules = '''\n",
        "Quantum\\s\\w+, started with 'Quantum'\n",
        "\\w+\\smillion, followed with 'million'\n",
        "[A-Z]{2}[A-Z]*, all capital words\n",
        "\\w*ly\\b, ending with 'ly'\n",
        "\\S*\\d+\\S*, match any word that contains numbers\n",
        "\\$\\d+, money related numbers\n",
        "'''\n",
        "\n",
        "with open('regex_rules.txt', 'w') as f:\n",
        "    f.write(rules)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJ7GCD0pFDvP"
      },
      "outputs": [],
      "source": [
        "text_list = [\"\"\"Quantum computing is the use of quantum-mechanical phenomena such as superposition and entanglement to perform computation.\n",
        "                Computers that perform quantum computations are known as quantum computers.\n",
        "                Quantum computers are believed to be able to solve certain computational problems, such as integer factorization (which underlies RSA encryption), substantially faster than classical computers.\n",
        "                The study of quantum computing is a subfield of quantum information science. Quantum computing began in the early 1980s, when physicist Paul Benioff proposed a quantum mechanical model of the Turing machine.\n",
        "                Richard Feynman and Yuri Manin later suggested that a quantum computer had the potential to simulate things that a classical computer could not.\n",
        "                In 1994, Peter Shor developed a quantum algorithm for factoring integers that had the potential to decrypt RSA-encrypted communications.\n",
        "                Despite ongoing experimental progress since the late 1990s, most researchers believe that \"fault-tolerant quantum computing is still a rather distant dream.\"\n",
        "                In recent years, investment into quantum computing research has increased in both the public and private sector.\n",
        "                On 23 October 2019, Google AI, in partnership with the U.S. National Aeronautics and Space Administration (NASA), published a paper in which they claimed to have achieved quantum supremacy.\n",
        "                While some have disputed this claim, it is still a significant milestone in the history of quantum computing.\"\"\",\n",
        "\n",
        "             \"\"\"Instacart has raised a new round of financing that makes it one of the most valuable private companies in the U.S., leapfrogging DoorDash, Palantir and Robinhood.\n",
        "                Amid surging demand for grocery delivery due to the coronavirus pandemic, Instacart has raised $225 million in a new funding round led by DST Global and General Catalyst.\n",
        "                The round increases Instacart‚Äôs valuation to $13.7 billion, up from $8 billion when it last raised money in 2018.\"\"\",\n",
        "\n",
        "            \"\"\"Quantum computing\"\"\"\n",
        "            ]\n",
        "\n",
        "spark_df = spark.createDataFrame(text_list, StringType()).toDF(\"text\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "77liqEuQFsR3"
      },
      "source": [
        "Below is the pipeline. We need to define the `path` and `delimiter` parameters in `setExternalRules()` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiYxv0mOFIcX",
        "outputId": "7bd2d17e-b270-4d6c-f2f4-460fa68e358c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+\n",
            "|                                                                                                text|                                                                                              result|\n",
            "+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+\n",
            "|Quantum computing is the use of quantum-mechanical phenomena such as superposition and entangleme...|[Quantum computing, Quantum computers, Quantum computing, RSA, RSA, AI, NASA, substantially, earl...|\n",
            "|Instacart has raised a new round of financing that makes it one of the most valuable private comp...|                                   [225 million, DST, Cataly, $225, $13.7, $8, 2018., $225, $13, $8]|\n",
            "|                                                                                   Quantum computing|                                                                                 [Quantum computing]|\n",
            "+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "documentAssembler = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "regex_matcher = RegexMatcher()\\\n",
        "    .setInputCols('document')\\\n",
        "    .setStrategy(\"MATCH_ALL\")\\\n",
        "    .setOutputCol(\"matched_text\")\\\n",
        "    .setExternalRules(path='regex_rules.txt', delimiter=',')\n",
        "\n",
        "\n",
        "nlpPipeline = Pipeline(stages=[documentAssembler,\n",
        "                                 regex_matcher])\n",
        "\n",
        "result = nlpPipeline.fit(spark_df).transform(spark_df)\n",
        "\n",
        "result.select('text','matched_text.result').show(truncate=100)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sB0OE6uUGdgP"
      },
      "source": [
        "Display the results with identifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4ACcIXqGkfl",
        "outputId": "45405292-437a-4c78-9618-08b2e0af11be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------------+------------------------------------+\n",
            "|Matches Found    |matching_regex/string               |\n",
            "+-----------------+------------------------------------+\n",
            "|Quantum computing|started with 'Quantum'              |\n",
            "|Quantum computers|started with 'Quantum'              |\n",
            "|Quantum computing|started with 'Quantum'              |\n",
            "|RSA              |all capital words                   |\n",
            "|RSA              |all capital words                   |\n",
            "|AI               |all capital words                   |\n",
            "|NASA             |all capital words                   |\n",
            "|substantially    |ending with 'ly'                    |\n",
            "|early            |ending with 'ly'                    |\n",
            "|1980s,           |match any word that contains numbers|\n",
            "|1994,            |match any word that contains numbers|\n",
            "|1990s,           |match any word that contains numbers|\n",
            "|23               |match any word that contains numbers|\n",
            "|2019,            |match any word that contains numbers|\n",
            "|225 million      |followed with 'million'             |\n",
            "|DST              |all capital words                   |\n",
            "|Cataly           |ending with 'ly'                    |\n",
            "|$225             |match any word that contains numbers|\n",
            "|$13.7            |match any word that contains numbers|\n",
            "|$8               |match any word that contains numbers|\n",
            "|2018.            |match any word that contains numbers|\n",
            "|$225             |money related numbers               |\n",
            "|$13              |money related numbers               |\n",
            "|$8               |money related numbers               |\n",
            "|Quantum computing|started with 'Quantum'              |\n",
            "+-----------------+------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result.select(F.explode(F.arrays_zip(result.matched_text.result,\n",
        "                                     result.matched_text.metadata)).alias(\"cols\")) \\\n",
        "       .select(F.expr(\"cols['0']\").alias(\"Matches Found\"),\n",
        "               F.expr(\"cols['1']['identifier']\").alias(\"matching_regex/string\"),).show(25,truncate=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "q_PYQQB4fBgq"
      },
      "source": [
        "### `setStrategy`"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9y9cHztzGxF2"
      },
      "source": [
        "`setStrategy()` sets matching strategy, by default `MATCH_ALL`.\n",
        "\n",
        "It can be either `MATCH_FIRST`|`MATCH_ALL`|`MATCH_COMPLETE`.\n",
        "\n",
        "- `MATCH_FIRST`: gets the first match of each rule\n",
        "- `MATCH_ALL`: gets all matches of each rule\n",
        "- `MATCH_COMPLETE`: gets matches if complete match of input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9E0GiqTfFQx",
        "outputId": "901bfa5a-e434-452e-f040-285f785c7048"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{Param(parent='RegexMatcher_36740a125e6d', name='lazyAnnotator', doc='Whether this AnnotatorModel acts as lazy in RecursivePipelines'): False,\n",
              " Param(parent='RegexMatcher_36740a125e6d', name='strategy', doc='MATCH_FIRST|MATCH_ALL|MATCH_COMPLETE'): 'MATCH_ALL'}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "RegexMatcher().extractParamMap()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zRgCbuW05SoL"
      },
      "source": [
        "Let's compare `MATCH_FIRST` & `MATCH_ALL`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGO1ZKJ2fH7h",
        "outputId": "15137a0e-d37b-466d-b22a-22b05528aba3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------------------------------------------+------------------------------------------------------------------------------------------------------------------------+\n",
            "|                      matched_text_first.result|                                                                                                 matched_text_all.result|\n",
            "+-----------------------------------------------+------------------------------------------------------------------------------------------------------------------------+\n",
            "|[Quantum computing, RSA, substantially, 1980s,]|[Quantum computing, Quantum computers, Quantum computing, RSA, RSA, AI, NASA, substantially, early, 1980s,, 1994,, 19...|\n",
            "|         [225 million, DST, Cataly, $225, $225]|                                                       [225 million, DST, Cataly, $225, $13.7, $8, 2018., $225, $13, $8]|\n",
            "|                            [Quantum computing]|                                                                                                     [Quantum computing]|\n",
            "+-----------------------------------------------+------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "documentAssembler = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "regex_matcher_first = RegexMatcher()\\\n",
        "    .setInputCols('document')\\\n",
        "    .setStrategy(\"MATCH_FIRST\")\\\n",
        "    .setOutputCol(\"matched_text_first\")\\\n",
        "    .setExternalRules(path='regex_rules.txt', delimiter=',')\n",
        "\n",
        "regex_matcher_all = RegexMatcher()\\\n",
        "    .setInputCols('document')\\\n",
        "    .setStrategy(\"MATCH_ALL\")\\\n",
        "    .setOutputCol(\"matched_text_all\")\\\n",
        "    .setExternalRules(path='regex_rules.txt', delimiter=',')\n",
        "\n",
        "nlpPipeline = Pipeline(stages=[documentAssembler,\n",
        "                                 regex_matcher_first,\n",
        "                               regex_matcher_all\n",
        "                               ])\n",
        "\n",
        "result = nlpPipeline.fit(spark_df).transform(spark_df)\n",
        "\n",
        "result.select(result.matched_text_first.result, result.matched_text_all.result).show(truncate=120)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6bhTelDoRDKh"
      },
      "source": [
        "Here in `MATCH_FIRST` only the first match of the rules is shown while in `MATCH_ALL` all matches are returned."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ZndgZIdINBgC"
      },
      "source": [
        "Now use of the `MATCH_COMPLETE`. With `MATCH_COMPLETE`, regex pattern should match to entire input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bT62sv62NHl_",
        "outputId": "f00d76b5-701e-4d02-9eb0-aab3de9e1f9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------------------------+------+------+\n",
            "|                        text|result|result|\n",
            "+----------------------------+------+------+\n",
            "|                        2010|[2010]|[2010]|\n",
            "| She was born on 1966/02/03.|[1966]|    []|\n",
            "|The project started in 2001.|[2001]|    []|\n",
            "+----------------------------+------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "documentAssembler = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "regex_matcher_complete = RegexMatcher()\\\n",
        "    .setInputCols('document')\\\n",
        "    .setStrategy(\"MATCH_COMPLETE\")\\\n",
        "    .setOutputCol(\"matched_text_complete\")\\\n",
        "    .setRules([\"\\d{4},year\"])\\\n",
        "    .setDelimiter(\",\")\n",
        "\n",
        "regex_matcher_all = RegexMatcher()\\\n",
        "    .setInputCols('document')\\\n",
        "    .setStrategy(\"MATCH_ALL\")\\\n",
        "    .setOutputCol(\"matched_text_all\")\\\n",
        "    .setRules([\"\\d{4},year\"])\\\n",
        "    .setDelimiter(\",\")\n",
        "\n",
        "\n",
        "nlpPipeline = Pipeline(stages=[documentAssembler,\n",
        "                            regex_matcher_complete,\n",
        "                               regex_matcher_all\n",
        "                               ])\n",
        "\n",
        "text_list = [\"2010\",  \"She was born on 1966/02/03.\", \"The project started in 2001.\"]\n",
        "\n",
        "spark_df = spark.createDataFrame(text_list, StringType()).toDF(\"text\")\n",
        "\n",
        "result = nlpPipeline.fit(spark_df).transform(spark_df)\n",
        "\n",
        "result.select('text','matched_text_all.result','matched_text_complete.result').show(truncate=120)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WmUlmzpNRsGn"
      },
      "source": [
        "In `MATCH_COMPLETE`, only the first document has a regex match. This is because the first document has only one string which is a `year` and `MATCH_COMPLETE` requires to match the entire input."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "interpreter": {
      "hash": "45150093197569bb3a58481dcd32cd1adb45462fa3448719e8ac38ada6166aca"
    },
    "kernelspec": {
      "display_name": "Python 3.6.10 64-bit ('tensorflow2_p36': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
