{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
      ],
      "metadata": {
        "id": "SmoQbkO5ISF6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MultiDocumentAssembler**"
      ],
      "metadata": {
        "id": "qoeyMWQBIUpc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook will cover the different parameters and usages of `MultiDocumentAssembler`. "
      ],
      "metadata": {
        "id": "lOBV0q8pIrCS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**📖 Learning Objectives:**\n",
        "\n",
        "1. Understand how to prepare data into a format that is processable by SparkNLP\n",
        "\n",
        "2. Become comfortable with how to apply some text pre-processing by using the parameters of `MultiDocumentAssembler` \n",
        "\n",
        "3. Be able to use this annotator in a question answering application\n",
        "\n",
        "\n",
        "**🔗 Helpful Links:**\n",
        "\n",
        "Documentation: [MultiDocumentAssembler](https://nlp.johnsnowlabs.com/docs/en/annotators#multidocumentassembler)\n",
        "\n",
        "Python Docs: [MultiDocumentAssembler](https://nlp.johnsnowlabs.com/api/python/reference/autosummary/sparknlp/base/multi_document_assembler/index.html#sparknlp.base.multi_document_assembler.MultiDocumentAssembler.setIdCol)\n",
        "\n",
        "Scala Docs: [MultiDocumentAssembler](https://nlp.johnsnowlabs.com/api/com/johnsnowlabs/nlp/MultiDocumentAssembler.html)\n",
        "\n",
        "Example Use Case: [Table Question Answering](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/17.Table_Question_Answering.ipynb)"
      ],
      "metadata": {
        "id": "WD79PalbJN2a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **📜 Background**\n",
        "\n",
        "This annotator is used as the first stage of Spark NLP pipelines. It transforms raw texts into `DOCUMENT` type annotations that is used by other annotators.\n",
        "\n",
        "`DocumentAssembler()` is another annotator that does transforms raw texts into `DOCUMENT` annotations, but `MultiDocumentAssembler` can take multiple inputs which is useful in such cases as Table Question Answering. "
      ],
      "metadata": {
        "id": "ZmgQpWpOPvhV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **🎬 Colab Setup**"
      ],
      "metadata": {
        "id": "7y-nrmPJRX-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pyspark==3.3.0  spark-nlp==4.3.1"
      ],
      "metadata": {
        "id": "H8DJ72nJIR8M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b59db70-e991-4935-e841-4ec4efb0e050"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.3/281.3 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.7/471.7 KB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sparknlp\n",
        "\n",
        "\n",
        "spark = sparknlp.start()\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "HdV_P3lfIR5a",
        "outputId": "a44cf7fe-0d71-4e95-d948-7c49d2d41651"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fb341bf4a30>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://f496c36b031b:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.3.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark NLP</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **🖨️ Input/Output Annotation Types**"
      ],
      "metadata": {
        "id": "3gtnsoBbz98t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Input: `None`\n",
        "\n",
        "- Output: `ARRAY[DOCUMENT]`"
      ],
      "metadata": {
        "id": "VP7uyMWO0A2u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **🔎 Parameters**\n"
      ],
      "metadata": {
        "id": "_TpgYnSi1R44"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `cleanupMode` (String): Cleaning up options, (Default: \"disabled\")\n",
        "\n",
        "- `idCol` (String): String type column with id information\n",
        "\n",
        "- `metadataCol` (String): Map type column with metadata information.\n",
        "\n"
      ],
      "metadata": {
        "id": "pEfli5Li15ta"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `setCleanupMode()`\n",
        "\n",
        "\n",
        "This parameter can be used to pre-process the text. It sets how to cleanup the document which has noisy content such as blank lines and tabs. "
      ],
      "metadata": {
        "id": "zSu6zGjG1-ca"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Possible values for the CleanupMode :\n",
        "\n",
        "- **disabled**: Source kept as original. This is a default.\n",
        "- **inplace**: Removes new lines and tabs.\n",
        "- **inplace_full**: Removes new lines and tabs but also those which were converted to strings (i.e. `\"\\n\"`)\n",
        "- **shrink**: Removes new lines and tabs, plus merging multiple spaces and blank lines to a single space (`strip`).\n",
        "- **shrink_full**: Removes new lines and tabs, including stringified values, plus shrinking spaces and blank lines.\n"
      ],
      "metadata": {
        "id": "jD6RXMoa2Y8c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will add blank lines and tabs to our sample text in order to see how pre-processing features work. "
      ],
      "metadata": {
        "id": "H-KoO8QY5EI_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_texts= \"\"\"I love working with  \\n   SparkNLP. \\n\n",
        "\n",
        "It is a perfect \\tlibrary. \n",
        "\"\"\"\n",
        "\n",
        "data = spark.createDataFrame([[sample_texts]]).toDF(\"text\")"
      ],
      "metadata": {
        "id": "UVdrGsp14vyh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`disabled`**"
      ],
      "metadata": {
        "id": "stfl7I_C5wRA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building `MultiDocumentAssembler()` and transforming it with the example data. "
      ],
      "metadata": {
        "id": "0Tkj0AXf5Ve8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sparknlp.base import MultiDocumentAssembler\n",
        "\n",
        "\n",
        "documentAssembler = MultiDocumentAssembler()\\\n",
        "    .setInputCols(\"text\")\\\n",
        "    .setOutputCols(\"document\")\\\n",
        "    .setCleanupMode(\"disabled\")\n",
        "\n",
        "result = documentAssembler.transform(data)\n",
        "\n",
        "result.select(\"document\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAlibOFN4WRF",
        "outputId": "959f05fa-a7d3-46fc-febd-6d8aa3572956"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------------------------------------------------------------------------------------------+\n",
            "|document                                                                                                         |\n",
            "+-----------------------------------------------------------------------------------------------------------------+\n",
            "|[{document, 0, 64, I love working with  \\n   SparkNLP. \\n\\n\\nIt is a perfect \\tlibrary. \\n, {sentence -> 0}, []}]|\n",
            "+-----------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.select(\"document.result\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kTigHs488rj",
        "outputId": "3296238b-6f85-4108-ab00-2fea73f206fe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------------------------------------+\n",
            "|result                                                                   |\n",
            "+-------------------------------------------------------------------------+\n",
            "|[I love working with  \\n   SparkNLP. \\n\\n\\nIt is a perfect \\tlibrary. \\n]|\n",
            "+-------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result.select(\"document.result\").take(1)[0].result[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpZd538T_IIZ",
        "outputId": "31f3a4c0-5bec-4451-f74f-19e972fac55c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I love working with  \n",
            "   SparkNLP. \n",
            "\n",
            "\n",
            "It is a perfect \tlibrary. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As seen above, there is no text pre-processing/cleaning applied. "
      ],
      "metadata": {
        "id": "b4bwAuIF53fB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`inplace`**"
      ],
      "metadata": {
        "id": "rJas5N9Y6Am4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documentAssembler = MultiDocumentAssembler()\\\n",
        "    .setInputCols(\"text\")\\\n",
        "    .setOutputCols(\"document\")\\\n",
        "    .setCleanupMode(\"inplace\")\n",
        "\n",
        "result = documentAssembler.transform(data)\n",
        "\n",
        "result.select(\"document\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgtheSQI4r4d",
        "outputId": "914856b0-64b9-4c50-b0e8-b484748a00a3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------------------------------------------------------------------------------------+\n",
            "|document                                                                                                   |\n",
            "+-----------------------------------------------------------------------------------------------------------+\n",
            "|[{document, 0, 64, I love working with      SparkNLP.    It is a perfect  library.  , {sentence -> 0}, []}]|\n",
            "+-----------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.select(\"document.result\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qc_VhEnu81JU",
        "outputId": "00936384-bb68-49f1-df30-e0b93519f479"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------------------------------+\n",
            "|result                                                             |\n",
            "+-------------------------------------------------------------------+\n",
            "|[I love working with      SparkNLP.    It is a perfect  library.  ]|\n",
            "+-------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result.select(\"document.result\").take(1)[0].result[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxTEGtgg6XdY",
        "outputId": "2de6f819-2421-4ded-898b-9bf2e9a44082"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I love working with      SparkNLP.    It is a perfect  library.  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`shrink`**"
      ],
      "metadata": {
        "id": "LOpZxknH7RYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documentAssembler = MultiDocumentAssembler()\\\n",
        "    .setInputCols(\"text\")\\\n",
        "    .setOutputCols(\"document\")\\\n",
        "    .setCleanupMode(\"shrink\")\n",
        "\n",
        "result = documentAssembler.transform(data)\n",
        "\n",
        "result.select(\"document\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jaed9JL6Sjr",
        "outputId": "31690c73-1307-4ab4-e59a-31fe76184fbf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------------------------------------------------------------------+\n",
            "|document                                                                                        |\n",
            "+------------------------------------------------------------------------------------------------+\n",
            "|[{document, 0, 53, I love working with SparkNLP. It is a perfect library., {sentence -> 0}, []}]|\n",
            "+------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.select(\"document.result\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lbLk2AA7Lwt",
        "outputId": "2c6d9989-a5a2-4e92-b059-b7f46751e82c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------+\n",
            "|result                                                  |\n",
            "+--------------------------------------------------------+\n",
            "|[I love working with SparkNLP. It is a perfect library.]|\n",
            "+--------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result.select(\"document.result\").take(1)[0].result[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IBTxFQH9DsQ",
        "outputId": "b89122af-fff9-44ef-bdc6-5e561af5caca"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I love working with SparkNLP. It is a perfect library.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `setIdCol()`\n",
        "\n",
        "This parameter sets the name of string type column for row id. It is used to specify the id information under the metadata for the target document column. "
      ],
      "metadata": {
        "id": "3jLwzPlvJMuI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating sample data with id column:"
      ],
      "metadata": {
        "id": "dNzVNcmAQBqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define a schema for the dataset\n",
        "schema = \"id INT, text STRING\"\n",
        "\n",
        "data= [{\"id\": 0, \"text\": \"His name is Jack and lives in New York\"},\n",
        "       {\"id\": 1, \"text\": \"She lives in LA\"}]\n",
        "\n",
        "# create a DataFrame from the list of dictionaries\n",
        "df = spark.createDataFrame(data, schema)\n",
        "df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJll3nWHLjEA",
        "outputId": "3ecea8ef-39cf-4c8c-8961-aaeaa493aa1a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------------------------------------+\n",
            "|id |text                                  |\n",
            "+---+--------------------------------------+\n",
            "|0  |His name is Jack and lives in New York|\n",
            "|1  |She lives in LA                       |\n",
            "+---+--------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Firstly, we will define `MultiDocumentAssembler()` with no `setIdCol()` parameter and check the metadata of the \"document\" column. "
      ],
      "metadata": {
        "id": "jbU_JC-AQhew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documentAssembler = MultiDocumentAssembler()\\\n",
        "    .setInputCols(\"text\")\\\n",
        "    .setOutputCols(\"document\")\\\n",
        "    .setCleanupMode(\"shrink\")\n",
        "    \n",
        "result = documentAssembler.transform(df)\n",
        "\n",
        "result.select(\"document\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TmdGMTZM2I0",
        "outputId": "0f2ea41d-9fd4-4efb-d748-0b36cec46979"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------------------------------+\n",
            "|document                                                                        |\n",
            "+--------------------------------------------------------------------------------+\n",
            "|[{document, 0, 37, His name is Jack and lives in New York, {sentence -> 0}, []}]|\n",
            "|[{document, 0, 14, She lives in LA, {sentence -> 0}, []}]                       |\n",
            "+--------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.select(\"document.metadata\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7RqSWOdQvul",
        "outputId": "fc392e07-af02-4c80-ff94-8e196cc15fd1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+\n",
            "|metadata         |\n",
            "+-----------------+\n",
            "|[{sentence -> 0}]|\n",
            "|[{sentence -> 0}]|\n",
            "+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As seen above, we only have sentence number information under the metadata. <br/>\n",
        "\n",
        "Now, let's define `setIdCol(\"id\")` parameter and see the difference. "
      ],
      "metadata": {
        "id": "jMioUTSwQyIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documentAssembler = MultiDocumentAssembler()\\\n",
        "    .setInputCols(\"text\")\\\n",
        "    .setOutputCols(\"document\")\\\n",
        "    .setCleanupMode(\"shrink\")\\\n",
        "    .setIdCol(\"id\")\n",
        "\n",
        "result = documentAssembler.transform(df)\n",
        "\n",
        "result.select(\"document\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HstwzvSxJI2H",
        "outputId": "541cd869-dce2-4974-a658-29836e1a636a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------------------------------------------------------------------+\n",
            "|document                                                                                 |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "|[{document, 0, 37, His name is Jack and lives in New York, {id -> 0, sentence -> 0}, []}]|\n",
            "|[{document, 0, 14, She lives in LA, {id -> 1, sentence -> 0}, []}]                       |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.select(\"document.metadata\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekF66PY6JIzY",
        "outputId": "4c10384c-1e5a-40bf-9ee4-e619732a7b00"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------+\n",
            "|metadata                  |\n",
            "+--------------------------+\n",
            "|[{id -> 0, sentence -> 0}]|\n",
            "|[{id -> 1, sentence -> 0}]|\n",
            "+--------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you see above, we have id information under the metadata since we employed `setIdCol(\"id\")` parameter. "
      ],
      "metadata": {
        "id": "3MAAtjzOREfT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `setMetadataCol()`\n",
        "\n",
        "This parameter sets the name of the column containing metadata information. The information should be a `dict` (`Map` type in Spark).\n",
        "\n",
        "With the `setIdCol()`, we were able to define id information under the metadata while we are able to define any other information under the metadata by using the `setMetadataCol()` parameter. "
      ],
      "metadata": {
        "id": "4hRS_ti0NUCv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating sample data with a MapType column containing metadata information: "
      ],
      "metadata": {
        "id": "hBr89NhgOteW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define a schema for the dataset\n",
        "schema = \"id INT, name STRING, properties MAP<STRING, INT>\"\n",
        "\n",
        "# create a list of dictionaries to represent the data\n",
        "data = [{\"id\": 1, \"name\": \"Alice\", \"properties\": {\"age\": 25, \"height\": 170}},\n",
        "        {\"id\": 2, \"name\": \"Bob\", \"properties\": {\"age\": 30, \"height\": 180}},\n",
        "        {\"id\": 3, \"name\": \"Charlie\", \"properties\": {\"age\": 35, \"height\": 175}}]\n",
        "\n",
        "# create a DataFrame from the list of dictionaries\n",
        "df = spark.createDataFrame(data, schema)\n",
        "\n",
        "# show the resulting DataFrame\n",
        "df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uh5aJr9SNd_d",
        "outputId": "01b7b7cc-418d-494d-b9d5-9d1533830b85"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------+--------------------------+\n",
            "|id |name   |properties                |\n",
            "+---+-------+--------------------------+\n",
            "|1  |Alice  |{age -> 25, height -> 170}|\n",
            "|2  |Bob    |{age -> 30, height -> 180}|\n",
            "|3  |Charlie|{age -> 35, height -> 175}|\n",
            "+---+-------+--------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will use `setMetadataCol(\"properties\")` to specify metadata information for the \"name\" column. "
      ],
      "metadata": {
        "id": "L27UPVikPFzf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documentAssembler = MultiDocumentAssembler()\\\n",
        "    .setInputCols(\"name\")\\\n",
        "    .setOutputCols(\"document\")\\\n",
        "    .setCleanupMode(\"shrink\")\\\n",
        "    .setMetadataCol(\"properties\")\n",
        "\n",
        "result = documentAssembler.transform(df)\n",
        "\n",
        "result.select(\"document\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Al_JU4CuNTcC",
        "outputId": "0a9fe9bf-c729-418b-fdb0-25c094d593bf"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------------------------+\n",
            "|document                                                                  |\n",
            "+--------------------------------------------------------------------------+\n",
            "|[{document, 0, 4, Alice, {age -> 25, height -> 170, sentence -> 0}, []}]  |\n",
            "|[{document, 0, 2, Bob, {age -> 30, height -> 180, sentence -> 0}, []}]    |\n",
            "|[{document, 0, 6, Charlie, {age -> 35, height -> 175, sentence -> 0}, []}]|\n",
            "+--------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.select(\"document.result\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYGW7h7sPZcH",
        "outputId": "56e05f98-05af-4826-9a9a-fdf1bb9aac1b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|result   |\n",
            "+---------+\n",
            "|[Alice]  |\n",
            "|[Bob]    |\n",
            "|[Charlie]|\n",
            "+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the metadata of the \"document\" column. "
      ],
      "metadata": {
        "id": "ai2mBI8mPcYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result.select(\"document.metadata\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yZCO6eTNTZE",
        "outputId": "71352b06-ef52-4854-b3d0-08b1ee62a889"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------+\n",
            "|metadata                                   |\n",
            "+-------------------------------------------+\n",
            "|[{age -> 25, height -> 170, sentence -> 0}]|\n",
            "|[{age -> 30, height -> 180, sentence -> 0}]|\n",
            "|[{age -> 35, height -> 175, sentence -> 0}]|\n",
            "+-------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use Case: TAPAS for Table Question Answering\n",
        "\n",
        "In this section, we will use `MultiDocumentAssembler()` annotator with **TAPAS for Table Question Answering** task. <br/>\n",
        "\n",
        "TAPAS needs the `MultiDocumentAssembler()` annotator to assemble the table and the questions as two `DOCUMENT` type annotations coming from two columns in the data frame."
      ],
      "metadata": {
        "id": "RGCW022K9EuW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating an example table and some questions"
      ],
      "metadata": {
        "id": "GbVsF7o_9Kdv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Table\n",
        "json_data = \"\"\"\n",
        "{\n",
        "  \"header\": [\"name\", \"money\", \"age\"],\n",
        "  \"rows\": [\n",
        "    [\"Donald Trump\", \"$100,000,000\", \"75\"],\n",
        "    [\"Elon Musk\", \"$20,000,000,000,000\", \"55\"]\n",
        "  ]\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Questions\n",
        "queries = [\n",
        "    \"Who earns less than 200,000,000?\",\n",
        "    \"Who earns 100,000,000?\", \n",
        "    \"How much money has Donald Trump?\",\n",
        "    \"How old are they?\",\n",
        "]\n",
        "\n",
        "# Spark data frame with two columns\n",
        "data = spark.createDataFrame([\n",
        "        [json_data, \" \".join(queries)]\n",
        "    ]).toDF(\"table_json\", \"questions\")"
      ],
      "metadata": {
        "id": "dDSVJ-2X82QY"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing extra annotators"
      ],
      "metadata": {
        "id": "H-gIC0E_-YQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sparknlp.base import Pipeline, TableAssembler\n",
        "from sparknlp.annotator import SentenceDetector, TapasForQuestionAnswering"
      ],
      "metadata": {
        "id": "wHrPUgf1-WeO"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a pipeline to perform the task"
      ],
      "metadata": {
        "id": "uvxNkODQ-sTl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Text to `DOCUMENT` annotation\n",
        "document_assembler = MultiDocumentAssembler() \\\n",
        "    .setInputCols(\"table_json\", \"questions\") \\\n",
        "    .setOutputCols(\"document_table\", \"document_questions\")\n",
        "\n",
        "# Split into sentences\n",
        "sentence_detector = SentenceDetector() \\\n",
        "    .setInputCols([\"document_questions\"]) \\\n",
        "    .setOutputCol(\"questions\")\n",
        "\n",
        "# Transform the JSON formatted table into a proper format\n",
        "table_assembler = TableAssembler()\\\n",
        "    .setInputCols([\"document_table\"])\\\n",
        "    .setOutputCol(\"table\")\n",
        "\n",
        "# Last component is `TapasForQuestionAnswering`, which will carry out the inference process\n",
        "tapas = TapasForQuestionAnswering\\\n",
        "    .pretrained(\"table_qa_tapas_base_finetuned_wtq\", \"en\")\\\n",
        "    .setInputCols([\"questions\", \"table\"])\\\n",
        "    .setOutputCol(\"answers\")\n",
        "\n",
        "\n",
        "pipeline = Pipeline(stages=[\n",
        "    document_assembler,\n",
        "    sentence_detector,\n",
        "    table_assembler,\n",
        "    tapas\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDadf_ER82Fq",
        "outputId": "f7cf9e3a-cb64-4f27-aadc-1e373a3899cc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "table_qa_tapas_base_finetuned_wtq download started this may take some time.\n",
            "Approximate size to download 394.7 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the result on fit/transform:"
      ],
      "metadata": {
        "id": "xwYRP9Hd-bHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data frame manipulations\n",
        "import pyspark.sql.functions as F"
      ],
      "metadata": {
        "id": "15jnrw2sAH3F"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = pipeline.fit(data)\n",
        "result = model.transform(data)\n",
        "\n",
        "result.select(F.explode(F.arrays_zip(result.questions.result, result.answers.result)).alias(\"cols\"))\\\n",
        "      .select(F.expr(\"cols['0'] as question\"), F.expr(\"cols['1'] as answer\"))\\\n",
        "      .show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWT7YL-R82By",
        "outputId": "089b6b21-2b95-4035-e3ee-aa11facd62ed"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------+-----------------+\n",
            "|question                        |answer           |\n",
            "+--------------------------------+-----------------+\n",
            "|Who earns less than 200,000,000?|Donald Trump     |\n",
            "|Who earns 100,000,000?          |Donald Trump     |\n",
            "|How much money has Donald Trump?|SUM($100,000,000)|\n",
            "|How old are they?               |AVERAGE(75, 55)  |\n",
            "+--------------------------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MultiDocumentAssembler with LightPipeline\n"
      ],
      "metadata": {
        "id": "kmwcGdPhtXg5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this section, we will cover the usage of `MultiDocumentAssembler` with `LightPipeline`. <br/>\n",
        "\n",
        "We will demonstrate this with an example Question Answering use case by using a `BertForQuestionAnswering` pretrained model. "
      ],
      "metadata": {
        "id": "78WqvW2S5cP6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example data with questions and context to fit our pipeline."
      ],
      "metadata": {
        "id": "xYWfjsaY5wDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example = spark.createDataFrame([[\"What's my name?\", \"My name is Clara and I live in Berkeley.\"]]).toDF(\"question\", \"context\")\n",
        "example.show(truncate=False)"
      ],
      "metadata": {
        "id": "YdjvBTGk00bZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab877388-293b-4b64-ae2c-23e304bcf3c9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+----------------------------------------+\n",
            "|question       |context                                 |\n",
            "+---------------+----------------------------------------+\n",
            "|What's my name?|My name is Clara and I live in Berkeley.|\n",
            "+---------------+----------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating pipeline"
      ],
      "metadata": {
        "id": "xUULy9WV59P-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sparknlp.base import LightPipeline\n",
        "from sparknlp.annotator import BertForQuestionAnswering"
      ],
      "metadata": {
        "id": "Q83yFOPOCs_x"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documentAssembler = MultiDocumentAssembler()\\\n",
        "    .setInputCols([\"question\", \"context\"])\\\n",
        "    .setOutputCols(['document_question', 'document_context'])\n",
        "\n",
        "spanClassifier = BertForQuestionAnswering.pretrained(\"bert_qa_bert_large_cased_whole_word_masking_finetuned_squad\",\"en\") \\\n",
        ".setInputCols([\"document_question\", \"document_context\"]) \\\n",
        ".setOutputCol(\"answer\") \\\n",
        ".setCaseSensitive(True)\n",
        "\n",
        "\n",
        "pipeline = Pipeline().setStages([\n",
        "documentAssembler,\n",
        "spanClassifier\n",
        "])\n",
        "\n",
        "model= pipeline.fit(example)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVSXQYKg0LzW",
        "outputId": "a6c27311-79f7-490d-e6f5-c661e83aaa14"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_qa_bert_large_cased_whole_word_masking_finetuned_squad download started this may take some time.\n",
            "Approximate size to download 1.2 GB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating LightPipeline and `fullAnnotate()` it with sample question and context. "
      ],
      "metadata": {
        "id": "ycQ327iD6EdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lmodel= LightPipeline(model)\n",
        "lresult= lmodel.fullAnnotate(\"Where does he work?\", \"He is data scientist and works at John Snow Labs\")"
      ],
      "metadata": {
        "id": "96bbmWQk0Lvb"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the results"
      ],
      "metadata": {
        "id": "-CnT1er37vNr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lresult"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hDIQ_bF7ucr",
        "outputId": "637456c2-6762-4ae8-bc22-caaa453a5e20"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'document_question': [Annotation(document, 0, 18, Where does he work?, {}, [])],\n",
              "  'document_context': [Annotation(document, 0, 47, He is data scientist and works at John Snow Labs, {}, [])],\n",
              "  'answer': [Annotation(chunk, 0, 13, John Snow Labs, {'chunk': '0', 'start_score': '0.99399257', 'score': '0.9931092', 'end': '16', 'start': '14', 'end_score': '0.99222594', 'sentence': '0'}, [])]}]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "answers= []\n",
        "questions= []\n",
        "\n",
        "for i, j in list(zip(lresult[0][\"document_question\"], lresult[0][\"answer\"])):\n",
        "  questions.append(i.result)\n",
        "  answers.append(j.result)\n",
        "  \n",
        "\n",
        "df= pd.DataFrame({\"question\": questions, \"answer\": answers})\n",
        "df.head()"
      ],
      "metadata": {
        "id": "ZTagAQky2IVI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "40075620-701a-4912-a433-f700fdb6fe12"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              question          answer\n",
              "0  Where does he work?  John Snow Labs"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7ed54fe0-47ed-4399-9ee8-bcbabb98c52a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Where does he work?</td>\n",
              "      <td>John Snow Labs</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ed54fe0-47ed-4399-9ee8-bcbabb98c52a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7ed54fe0-47ed-4399-9ee8-bcbabb98c52a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7ed54fe0-47ed-4399-9ee8-bcbabb98c52a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As seen above, we specified metadata information for the document column. "
      ],
      "metadata": {
        "id": "4dG89JXXSIkz"
      }
    }
  ]
}