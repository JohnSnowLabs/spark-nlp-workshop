{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPI0VYtufj/NwnscNRiAuLI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"],"metadata":{"id":"VIVvNURL-pfj"}},{"cell_type":"markdown","source":["# **Normalizer**"],"metadata":{"id":"IDNY8ZYY-v8L"}},{"cell_type":"markdown","source":["This notebook will cover the different parameters and usages of `Normalizer`. \n","\n","**ğŸ“– Learning Objectives:**\n","\n","1. Understand how to clean tokens by making use of this annotator.\n","\n","2. Become comfortable using the different parameters of the annotator.\n","\n","\n","**ğŸ”— Helpful Links:**\n","\n","- Documentation : [Normalizer](https://nlp.johnsnowlabs.com/docs/en/annotators#normalizer)\n","\n","- Python Docs : [Normalizer](https://nlp.johnsnowlabs.com/api/python/reference/autosummary/sparknlp/annotator/normalizer/index.html)\n","\n","- Scala Docs : [Normalizer](https://nlp.johnsnowlabs.com/api/com/johnsnowlabs/nlp/annotators/Normalizer.html)\n","\n","- For extended examples of usage, see the [Spark NLP Workshop repository](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb)."],"metadata":{"id":"wEzNoDwE-5cv"}},{"cell_type":"markdown","source":["## **ğŸ“œ Background**"],"metadata":{"id":"MX22B4qNBLMW"}},{"cell_type":"markdown","source":["This annotator cleans out tokens. Requires stems, hence tokens. Removes all dirty characters from text following a regex pattern and transforms words based on a provided dictionary"],"metadata":{"id":"Na0FhyctBMK2"}},{"cell_type":"markdown","source":["## **ğŸ¬ Colab Setup**"],"metadata":{"id":"tSGCuXRG83ZY"}},{"cell_type":"code","source":["!pip install -q pyspark==3.1.2  spark-nlp==4.2.4"],"metadata":{"id":"FfkYXKFmhReo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673445243869,"user_tz":-330,"elapsed":30438,"user":{"displayName":"Arshaan","userId":"17964254249366085303"}},"outputId":"742d9030-53e9-4c40-8fc4-b8771f09f320"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m212.4/212.4 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m448.4/448.4 KB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m198.6/198.6 KB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["import sparknlp\n","from sparknlp.base import *\n","from sparknlp.annotator import *\n","from pyspark.sql import functions as F\n","\n","spark = sparknlp.start()\n","spark"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":219},"id":"X5uX26AviN92","executionInfo":{"status":"ok","timestamp":1673445291367,"user_tz":-330,"elapsed":47504,"user":{"displayName":"Arshaan","userId":"17964254249366085303"}},"outputId":"d3c60943-4b23-4952-8597-4bfbf6e54c14"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<pyspark.sql.session.SparkSession at 0x7f8d570f0bb0>"],"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://c826b887836a:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.1.2</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>Spark NLP</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","source":["## **ğŸ–¨ï¸ Input/Output Annotation Types**"],"metadata":{"id":"kwPWcPqU8-oB"}},{"cell_type":"markdown","source":["- Input: `TOKEN`\n","\n","- Output: `TOKEN`"],"metadata":{"id":"AChCHSne9DnI"}},{"cell_type":"markdown","source":["## **ğŸ” Parameters**"],"metadata":{"id":"bu5c_fCQ9OQj"}},{"cell_type":"markdown","source":["\n","*  `CleanupPatterns` (*StringArrayParam*) : Normalization regex patterns which match will be removed from token (Default: [\"[^A-Za-z]\"])\n","\n","*   `Lowercase` ( *Boolean* ) : Whether to convert strings to lowercase (Default: false)\n","\n","\n","\n","*   `MaxLength` ( *Int* ) : Set the maximum allowed length for each token\n","\n","\n","*  `MinLength` ( *Int* ) : Set the minimum allowed length for each token (Default: 0)\n","\n","*  `SlangDictionary` ( *path* ) : Delimited file with list of custom words to be manually corrected\n","\n","\n","*   `SlangMatchCase` ( *Boolean* ) : Whether or not to be case sensitive to match slangs (Default: false)\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"71GSmHOuj0gg"}},{"cell_type":"markdown","source":["### `CleanupPatterns` \n","\n","If we don't set CleanupPatterns, it will only keep alphabet letters ([^A-Za-z])"],"metadata":{"id":"-10Pldi9rInq"}},{"cell_type":"code","source":["documentAssembler = DocumentAssembler() \\\n","    .setInputCol(\"text\") \\\n","    .setOutputCol(\"document\")\n","\n","tokenizer = Tokenizer() \\\n","    .setInputCols([\"document\"]) \\\n","    .setOutputCol(\"token\")\n","\n","normalizer = Normalizer() \\\n","    .setInputCols([\"token\"]) \\\n","    .setOutputCol(\"normalized\")\\\n","\n","pipeline = Pipeline().setStages([\n","    documentAssembler,\n","    tokenizer,\n","    normalizer\n","])\n","\n","data = spark.createDataFrame([[\"John and Peter are brothers. However they don't support each other that much. John is 20 years old and Peter is 26\"]]) \\\n","    .toDF(\"text\")\n","result = pipeline.fit(data).transform(data)\n","result.selectExpr(\"normalized.result\").show(truncate = False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tx5TOAZKnUBW","executionInfo":{"status":"ok","timestamp":1673445300827,"user_tz":-330,"elapsed":9473,"user":{"displayName":"Arshaan","userId":"17964254249366085303"}},"outputId":"8547ac1f-b761-4618-d028-6ed5828747a3"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["+------------------------------------------------------------------------------------------------------------------------------+\n","|result                                                                                                                        |\n","+------------------------------------------------------------------------------------------------------------------------------+\n","|[John, and, Peter, are, brothers, However, they, dont, support, each, other, that, much, John, is, years, old, and, Peter, is]|\n","+------------------------------------------------------------------------------------------------------------------------------+\n","\n"]}]},{"cell_type":"markdown","source":["As CleanupPatterns will take default value, so anything other than the alphabet letters is cleaned. In our case that is why 20 and 26 get removed."],"metadata":{"id":"ZyiVcu_1Q-dk"}},{"cell_type":"markdown","source":["â¤ After specifying CleanupPatterns"],"metadata":{"id":"8RAmkpLrtQ0t"}},{"cell_type":"code","source":["documentAssembler = DocumentAssembler() \\\n","    .setInputCol(\"text\") \\\n","    .setOutputCol(\"document\")\n","\n","tokenizer = Tokenizer() \\\n","    .setInputCols([\"document\"]) \\\n","    .setOutputCol(\"token\")\n","\n","normalizer = Normalizer() \\\n","    .setInputCols([\"token\"]) \\\n","    .setOutputCol(\"normalized\") \\\n","    .setCleanupPatterns([\"\"\"[^\\w\\d\\s]\"\"\"]) \n","\n","pipeline = Pipeline().setStages([\n","    documentAssembler,\n","    tokenizer,\n","    normalizer\n","])\n","\n","data = spark.createDataFrame([[\"John and Peter are brothers. However they don't support each other that much. John is 20 years old and Peter is 26\"]]) \\\n","    .toDF(\"text\")\n","result = pipeline.fit(data).transform(data)\n","result.selectExpr(\"normalized.result\").show(truncate = False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EfRrrGgzragF","executionInfo":{"status":"ok","timestamp":1673445302937,"user_tz":-330,"elapsed":2116,"user":{"displayName":"Arshaan","userId":"17964254249366085303"}},"outputId":"9abfe795-96c6-4f60-f816-0d4dcb1692f8"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------------------------------------------------------------------------------------------------------------------------+\n","|result                                                                                                                                |\n","+--------------------------------------------------------------------------------------------------------------------------------------+\n","|[John, and, Peter, are, brothers, However, they, dont, support, each, other, that, much, John, is, 20, years, old, and, Peter, is, 26]|\n","+--------------------------------------------------------------------------------------------------------------------------------------+\n","\n"]}]},{"cell_type":"markdown","source":["Our CleanupPattern removes all non-word, non-digit and non-space characters. \n","\n","So that is why: *don't -> dont*"],"metadata":{"id":"Fqd5hqDGcZdc"}},{"cell_type":"markdown","source":["### `Lowercase`\n","\n","(Default: false)"],"metadata":{"id":"DH2LZ8rfuFPG"}},{"cell_type":"code","source":["documentAssembler = DocumentAssembler() \\\n","    .setInputCol(\"text\") \\\n","    .setOutputCol(\"document\")\n","\n","tokenizer = Tokenizer() \\\n","    .setInputCols([\"document\"]) \\\n","    .setOutputCol(\"token\")\n","\n","normalizer = Normalizer() \\\n","    .setInputCols([\"token\"]) \\\n","    .setOutputCol(\"normalized\") \\\n","    \n","pipeline = Pipeline().setStages([\n","    documentAssembler,\n","    tokenizer,\n","    normalizer\n","])\n","\n","data = spark.createDataFrame([[\"John and Peter are brothers. However they don't support each other that much. John is 20 years old and Peter is 26\"]]) \\\n","    .toDF(\"text\")\n","result = pipeline.fit(data).transform(data)\n","result.selectExpr(\"normalized.result\").show(truncate = False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rT8o_UVOskX6","executionInfo":{"status":"ok","timestamp":1673445303648,"user_tz":-330,"elapsed":715,"user":{"displayName":"Arshaan","userId":"17964254249366085303"}},"outputId":"536079f9-cd39-4516-f5e8-d5dd39841eaf"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["+------------------------------------------------------------------------------------------------------------------------------+\n","|result                                                                                                                        |\n","+------------------------------------------------------------------------------------------------------------------------------+\n","|[John, and, Peter, are, brothers, However, they, dont, support, each, other, that, much, John, is, years, old, and, Peter, is]|\n","+------------------------------------------------------------------------------------------------------------------------------+\n","\n"]}]},{"cell_type":"markdown","source":["As LowerCase takes its default value which is False, we get non-lowercase tokens as well."],"metadata":{"id":"M8sH6x3ETAay"}},{"cell_type":"markdown","source":["â¤ Lowercase : True"],"metadata":{"id":"kaW2P_3cudpS"}},{"cell_type":"code","source":["documentAssembler = DocumentAssembler() \\\n","    .setInputCol(\"text\") \\\n","    .setOutputCol(\"document\")\n","\n","tokenizer = Tokenizer() \\\n","    .setInputCols([\"document\"]) \\\n","    .setOutputCol(\"token\")\n","\n","normalizer = Normalizer() \\\n","    .setInputCols([\"token\"]) \\\n","    .setOutputCol(\"normalized\") \\\n","    .setLowercase(True)\n","    \n","pipeline = Pipeline().setStages([\n","    documentAssembler,\n","    tokenizer,\n","    normalizer\n","])\n","\n","data = spark.createDataFrame([[\"John and Peter are brothers. However they don't support each other that much. John is 20 years old and Peter is 26\"]]) \\\n","    .toDF(\"text\")\n","result = pipeline.fit(data).transform(data)\n","result.selectExpr(\"normalized.result\").show(truncate = False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YutlgTnBucLk","executionInfo":{"status":"ok","timestamp":1673445305744,"user_tz":-330,"elapsed":2100,"user":{"displayName":"Arshaan","userId":"17964254249366085303"}},"outputId":"e3a90d97-a64c-4b4e-c033-233ba8847980"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["+------------------------------------------------------------------------------------------------------------------------------+\n","|result                                                                                                                        |\n","+------------------------------------------------------------------------------------------------------------------------------+\n","|[john, and, peter, are, brothers, however, they, dont, support, each, other, that, much, john, is, years, old, and, peter, is]|\n","+------------------------------------------------------------------------------------------------------------------------------+\n","\n"]}]},{"cell_type":"markdown","source":["As we set LowerCase as True, we get everything in lowercase."],"metadata":{"id":"MYtUpHC1T10K"}},{"cell_type":"markdown","source":["### `MaxLength and MinLength` \n","\n","Sets the maximum and minimum allowed length for each token."],"metadata":{"id":"2JKdO2THu0xP"}},{"cell_type":"code","source":["documentAssembler = DocumentAssembler() \\\n","    .setInputCol(\"text\") \\\n","    .setOutputCol(\"document\")\n","\n","tokenizer = Tokenizer() \\\n","    .setInputCols([\"document\"]) \\\n","    .setOutputCol(\"token\")\n","\n","normalizer = Normalizer() \\\n","    .setInputCols([\"token\"]) \\\n","    .setOutputCol(\"normalized\") \\\n","    .setLowercase(True)\\\n","    .setMaxLength(4)\\\n","    .setMinLength(3) #Default = 0\n","    \n","pipeline = Pipeline().setStages([\n","    documentAssembler,\n","    tokenizer,\n","    normalizer\n","])\n","\n","data = spark.createDataFrame([[\"John and Peter are brothers. However they don't support each other that much. John is 20 years old and Peter is 26\"]]) \\\n","    .toDF(\"text\")\n","result = pipeline.fit(data).transform(data)\n","result.selectExpr(\"normalized.result\").show(truncate = False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OD7gFRtsvkig","executionInfo":{"status":"ok","timestamp":1673445307163,"user_tz":-330,"elapsed":1424,"user":{"displayName":"Arshaan","userId":"17964254249366085303"}},"outputId":"af9e76cd-87c9-45b7-9a0d-94306995aec7"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------------------------------------------------+\n","|result                                                        |\n","+--------------------------------------------------------------+\n","|[john, and, are, they, dont, each, that, much, john, old, and]|\n","+--------------------------------------------------------------+\n","\n"]}]},{"cell_type":"markdown","source":["As we set the MaxLength=4 and MinLength=3, we get only the tokens having lengths 3 and 4."],"metadata":{"id":"dgAXhUW9UvoW"}},{"cell_type":"markdown","source":["### `SlangDictionary`\n","\n","Give delimited file with list of custom words to be manually corrected"],"metadata":{"id":"2jvcb1yM_cli"}},{"cell_type":"code","source":["#Create a Demo Slang CSV File\n","import csv\n","  \n","field_names = ['Slang', 'Correct_Word']\n","  \n","slangs = [\n","{'Slang': \"bros\", 'Correct_Word': 'brothers'},\n","{'Slang': \"approx\", 'Correct_Word': 'approximately'},\n","{'Slang': \"AFAIK\", 'Correct_Word': 'As far as I know'}\n","]\n","  \n","with open('slangs.csv', 'w') as csvfile:\n","    writer = csv.DictWriter(csvfile, fieldnames = field_names)\n","    writer.writeheader()\n","    writer.writerows(slangs)"],"metadata":{"id":"GhA_gZjz-f4C","executionInfo":{"status":"ok","timestamp":1673445307163,"user_tz":-330,"elapsed":4,"user":{"displayName":"Arshaan","userId":"17964254249366085303"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["documentAssembler = DocumentAssembler() \\\n","    .setInputCol(\"text\") \\\n","    .setOutputCol(\"document\")\n","\n","tokenizer = Tokenizer() \\\n","    .setInputCols([\"document\"]) \\\n","    .setOutputCol(\"token\")\n","\n","normalizer = Normalizer() \\\n","    .setInputCols([\"token\"]) \\\n","    .setOutputCol(\"normalized\") \\\n","    .setSlangDictionary(\"/content/slangs.csv\" ,\",\")\n","\n","    \n","pipeline = Pipeline().setStages([\n","    documentAssembler,\n","    tokenizer,\n","    normalizer\n","])\n","\n","data = spark.createDataFrame([[\"John and Peter are bros. However they don't support each other that much. AFAIK, John is 20 years old and Peter is approx 26\"]]) \\\n","    .toDF(\"text\")\n","result = pipeline.fit(data).transform(data)\n","result.selectExpr(\"normalized.result\").show(truncate = False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"luK9uE3EvsQi","executionInfo":{"status":"ok","timestamp":1673445308797,"user_tz":-330,"elapsed":1638,"user":{"displayName":"Arshaan","userId":"17964254249366085303"}},"outputId":"26fd285e-106b-451c-e845-27f24b05387d"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|result                                                                                                                                                             |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|[John, and, Peter, are, brothers, However, they, dont, support, each, other, that, much, As, far, as, I, know, John, is, years, old, and, Peter, is, approximately]|\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","\n"]}]},{"cell_type":"markdown","source":["The slang words were replaced with their correct words as specified in the file.\n","\n","*   bros -> brothers\n","\n","*   AFAIK -> As far as I know\n","\n","*   approx -> approximately\n","\n","\n"],"metadata":{"id":"BU-62dy8VHYF"}},{"cell_type":"markdown","source":["### `SlangMatchCase` \n","\n","Whether or not to be case sensitive to match slangs (Default: false)"],"metadata":{"id":"nZLAZJxOCWrN"}},{"cell_type":"code","source":["documentAssembler = DocumentAssembler() \\\n","    .setInputCol(\"text\") \\\n","    .setOutputCol(\"document\")\n","\n","tokenizer = Tokenizer() \\\n","    .setInputCols([\"document\"]) \\\n","    .setOutputCol(\"token\")\n","\n","normalizer = Normalizer() \\\n","    .setInputCols([\"token\"]) \\\n","    .setOutputCol(\"normalized\") \\\n","    .setSlangDictionary(\"/content/slangs.csv\" ,\",\")\\\n","    .setSlangMatchCase(False)\n","\n","    \n","pipeline = Pipeline().setStages([\n","    documentAssembler,\n","    tokenizer,\n","    normalizer\n","])\n","\n","data = spark.createDataFrame([[\"John and Peter are bros. However they don't support each other that much. afaik, John is 20 years old and Peter is approx 26\"]]) \\\n","    .toDF(\"text\")\n","result = pipeline.fit(data).transform(data)\n","result.selectExpr(\"normalized.result\").show(truncate = False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y90cjjo3CnVB","executionInfo":{"status":"ok","timestamp":1673445309642,"user_tz":-330,"elapsed":849,"user":{"displayName":"Arshaan","userId":"17964254249366085303"}},"outputId":"725a1e71-79ff-494e-9fad-a66edee4231e"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|result                                                                                                                                                             |\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","|[John, and, Peter, are, brothers, However, they, dont, support, each, other, that, much, As, far, as, I, know, John, is, years, old, and, Peter, is, approximately]|\n","+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","\n"]}]},{"cell_type":"markdown","source":["As SlangMatchCase is False, even non case sensitive slangs were matched.\n","\n","*   afaik -> As far as I know"],"metadata":{"id":"6rbvDuNYWU-b"}},{"cell_type":"markdown","source":["â¤ SlangMatchCase : True"],"metadata":{"id":"bCCEdCH6DZsD"}},{"cell_type":"code","source":["documentAssembler = DocumentAssembler() \\\n","    .setInputCol(\"text\") \\\n","    .setOutputCol(\"document\")\n","\n","tokenizer = Tokenizer() \\\n","    .setInputCols([\"document\"]) \\\n","    .setOutputCol(\"token\")\n","\n","normalizer = Normalizer() \\\n","    .setInputCols([\"token\"]) \\\n","    .setOutputCol(\"normalized\") \\\n","    .setSlangDictionary(\"/content/slangs.csv\" ,\",\")\\\n","    .setSlangMatchCase(True)\n","\n","    \n","pipeline = Pipeline().setStages([\n","    documentAssembler,\n","    tokenizer,\n","    normalizer\n","])\n","\n","data = spark.createDataFrame([[\"John and Peter are bros. However they don't support each other that much. afaik, John is 20 years old and Peter is approx 26\"]]) \\\n","    .toDF(\"text\")\n","result = pipeline.fit(data).transform(data)\n","result.selectExpr(\"normalized.result\").show(truncate = False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v2g2YrO_DP_W","executionInfo":{"status":"ok","timestamp":1673445311870,"user_tz":-330,"elapsed":2235,"user":{"displayName":"Arshaan","userId":"17964254249366085303"}},"outputId":"af24181a-d4ec-4513-9b7a-f5989b61adba"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------------------------------------------------------------------------------------------------------------------------------------------------+\n","|result                                                                                                                                              |\n","+----------------------------------------------------------------------------------------------------------------------------------------------------+\n","|[John, and, Peter, are, brothers, However, they, dont, support, each, other, that, much, afaik, John, is, years, old, and, Peter, is, approximately]|\n","+----------------------------------------------------------------------------------------------------------------------------------------------------+\n","\n"]}]},{"cell_type":"markdown","source":["As SlangMatchCase is True, non case sensitive slangs were not matched.\n","\n","*   afaik -> afaik (Remains Same)"],"metadata":{"id":"Mf0-RtUKXSDZ"}},{"cell_type":"markdown","source":["\n","â–¶ *Token Indicies are preserved* "],"metadata":{"id":"xd0Ja2HLeTjB"}},{"cell_type":"code","source":["documentAssembler = DocumentAssembler() \\\n","    .setInputCol(\"text\") \\\n","    .setOutputCol(\"document\")\n","\n","tokenizer = Tokenizer() \\\n","    .setInputCols([\"document\"]) \\\n","    .setOutputCol(\"token\")\n","\n","normalizer = Normalizer() \\\n","    .setInputCols([\"token\"]) \\\n","    .setOutputCol(\"normalized\")\\\n","\n","pipeline = Pipeline().setStages([\n","    documentAssembler,\n","    tokenizer,\n","    normalizer\n","])\n","\n","data = spark.createDataFrame([[\"John is 20 and Peter is 26 years old.\"]]) \\\n","    .toDF(\"text\")\n","result = pipeline.fit(data).transform(data)\n","\n","result.select(\"token.result\",\"token.begin\",\"token.end\").show(truncate=False)\n","result.select(\"normalized.result\",\"normalized.begin\",\"normalized.end\").withColumnRenamed(\"result\",\"normalized result\").show(truncate=False)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uwok_bX2d2-f","executionInfo":{"status":"ok","timestamp":1673445312716,"user_tz":-330,"elapsed":851,"user":{"displayName":"Arshaan","userId":"17964254249366085303"}},"outputId":"7074dc71-574b-4791-b228-dfb3a25634c1"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------------------------------------------------+-------------------------------------+-------------------------------------+\n","|result                                           |begin                                |end                                  |\n","+-------------------------------------------------+-------------------------------------+-------------------------------------+\n","|[John, is, 20, and, Peter, is, 26, years, old, .]|[0, 5, 8, 11, 15, 21, 24, 27, 33, 36]|[3, 6, 9, 13, 19, 22, 25, 31, 35, 36]|\n","+-------------------------------------------------+-------------------------------------+-------------------------------------+\n","\n","+--------------------------------------+--------------------------+--------------------------+\n","|normalized result                     |begin                     |end                       |\n","+--------------------------------------+--------------------------+--------------------------+\n","|[John, is, and, Peter, is, years, old]|[0, 5, 11, 15, 21, 27, 33]|[3, 6, 13, 19, 22, 31, 35]|\n","+--------------------------------------+--------------------------+--------------------------+\n","\n"]}]},{"cell_type":"markdown","source":["As we can see above, token indicies are preserved after using a Normalizer() "],"metadata":{"id":"HEV_Pkwjgjty"}}]}