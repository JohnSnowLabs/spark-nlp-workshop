{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n"
      ],
      "metadata": {
        "id": "klIak_Gb_OPJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DocumentAssembler**"
      ],
      "metadata": {
        "id": "bewC1SWN-6jB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook will cover the different parameters and usages of `DocumentAssembler`. DocumentAssembler() is a special transformer that does this for us; it creates the first annotation of type Document which may be used by annotators down the road.\n",
        "\n",
        "**ðŸ“– Learning Objectives:**\n",
        "\n",
        "1. Understand how to use `DocumentAssembler`.\n",
        "\n",
        "2. Become comfortable using the different parameters of the `DocumentAssembler`.\n",
        "\n",
        "\n",
        "**ðŸ”— Helpful Links:**\n",
        "\n",
        "- Documentation : [DocumentAssembler](https://nlp.johnsnowlabs.com/docs/en/annotators#documentassembler)\n",
        "\n",
        "- Python Docs : [DocumentAssembler](https://nlp.johnsnowlabs.com/api/python/reference/autosummary/sparknlp/base/document_assembler/index.html)\n",
        "\n",
        "- Scala Docs : [DocumentAssembler](https://nlp.johnsnowlabs.com/api/com/johnsnowlabs/nlp/DocumentAssembler.html)\n",
        "\n",
        "- For extended examples of usage, see the [Spark NLP Workshop repository](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/)."
      ],
      "metadata": {
        "id": "m048uDkB69Rv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ðŸ“œ Background**\n"
      ],
      "metadata": {
        "id": "B9Wo54MT8jKU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Spark NLP, the transformations occur on different stages of `Pipelines`, each containing `annotations` that are input/output of those stages.\n",
        "\n",
        "`DocumentAssembler` is an annotator that is used to transform raw texts into `DOCUMENT` annotations, and is often used as the first stage of the pipelines. "
      ],
      "metadata": {
        "id": "yaDBNKJsAovm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ðŸŽ¬ Colab Setup**"
      ],
      "metadata": {
        "id": "A4hMnkhd_ik9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install PySpark and Spark NLP\n",
        "!pip install -q pyspark==3.3.0  spark-nlp==4.3.2"
      ],
      "metadata": {
        "id": "xrdvNxjD_yQI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a71c3ebf-d47c-4821-8f2b-ee6122200939"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m281.3/281.3 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m473.2/473.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sparknlp\n",
        "from sparknlp.base import DocumentAssembler\n",
        "\n",
        "\n",
        "spark = sparknlp.start()"
      ],
      "metadata": {
        "id": "W5D63vBo_0u0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ðŸ–¨ï¸ Input/Output Annotation Types**"
      ],
      "metadata": {
        "id": "fdTHvykf8wni"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Input: `None` (raw texts)\n",
        "\n",
        "- Output: `DOCUMENT`"
      ],
      "metadata": {
        "id": "ejYVNcX98y5j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ðŸ”Ž Parameters**\n"
      ],
      "metadata": {
        "id": "YVa72oJd9Bk_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `inputCol()`: (String) The name of the column that will be converted. We can specify only one column here. It can read either a String column or an Array.\n",
        "\n",
        "- `outputCol`: (optional) The name of the column in Document type that is generated. We can specify only one column here. Default is '**document**'.\n",
        "\n",
        "- `idCol`: (optional) String type column with id information\n",
        "\n",
        "- `metadataCol`: (optional) Map type column with metadata information.\n",
        "\n",
        "- `cleanupMode`: (optional) Cleaning up options\n"
      ],
      "metadata": {
        "id": "AUbv3YL59D8Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `setInputCol()`\n",
        "\n",
        "\n",
        "setInputCol() is a parameter in the DocumentAssembler component of Spark NLP, which specifies the column name from your input DataFrame that will be converted into the Document format, suitable for further NLP processing. This parameter accepts only one column, and the column can either be of type String or an Array."
      ],
      "metadata": {
        "id": "EpBqGk7oNc3C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suppose you have a DataFrame with two columns: \"id\" and \"text\". The \"text\" column contains the raw text that you want to process using Spark NLP. To convert the \"text\" column into Document format, you need to use the DocumentAssembler and set its InputCol() parameter to \"text\"."
      ],
      "metadata": {
        "id": "wOGfzMDiOAXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    (1, \"I love working with SparkNLP.\"),\n",
        "    (2, \"Today is sunny.\")\n",
        "]\n",
        "\n",
        "# Create a DataFrame\n",
        "columns = [\"id\", \"text\"]\n",
        "df = spark.createDataFrame(data, columns)"
      ],
      "metadata": {
        "id": "5In_YI36OEFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documentAssembler = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "    \n",
        "result = documentAssembler.transform(df)\n",
        "\n",
        "result.select(\"document\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c23AbFZ7OV6B",
        "outputId": "e91697ea-3a3b-437f-a3d4-e5780dd632ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------------------------------------------------+\n",
            "|document                                                               |\n",
            "+-----------------------------------------------------------------------+\n",
            "|[{document, 0, 28, I love working with SparkNLP., {sentence -> 0}, []}]|\n",
            "|[{document, 0, 14, Today is sunny., {sentence -> 0}, []}]              |\n",
            "+-----------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `setOutputCol`\n",
        "\n",
        "\n",
        "The outputCol parameter in the DocumentAssembler determines the name of the output column that will store the processed documents."
      ],
      "metadata": {
        "id": "-OMNdVaJOlWo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For example, suppose you have a dataset with a column named 'text', and you want to use the DocumentAssembler to process the text data."
      ],
      "metadata": {
        "id": "RiuPHAD-PC_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document_assembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"text\") \\\n",
        "    .setOutputCol(\"processed_text\")"
      ],
      "metadata": {
        "id": "LUNW9fH3PFZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = document_assembler.transform(df)\n",
        "\n",
        "result.select(\"processed_text\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXvtIaEKPuVq",
        "outputId": "39e6c1e0-abdf-4766-db23-77a3b39807bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------------------------------------------------+\n",
            "|processed_text                                                         |\n",
            "+-----------------------------------------------------------------------+\n",
            "|[{document, 0, 28, I love working with SparkNLP., {sentence -> 0}, []}]|\n",
            "|[{document, 0, 14, Today is sunny., {sentence -> 0}, []}]              |\n",
            "+-----------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, the resulting DataFrame will have a new column named 'processed_text' containing the processed documents in the Document format, which can be used as input for further NLP tasks."
      ],
      "metadata": {
        "id": "1F5kQvNIP3r_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `setIdCol()`\n",
        "\n",
        "\n",
        "setIdCol() sets name of string type column for row id and provides a unique identifier (ID) for each item in the dataset."
      ],
      "metadata": {
        "id": "7ihCOTebKXwT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating sample data with id column:"
      ],
      "metadata": {
        "id": "DnJfVkGAL6ix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define a schema for the dataset\n",
        "schema = \"id INT, text STRING\"\n",
        "\n",
        "data= [{\"id\": 0, \"text\": \"The playful kittens chased the fluttering butterflies in the garden.\"},\n",
        "       {\"id\": 1, \"text\": \"During her vacation, Emily enjoyed playing tennis\"}]\n",
        "\n",
        "# create a DataFrame from the list of dictionaries\n",
        "df = spark.createDataFrame(data, schema)\n",
        "df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7J454IXuL0le",
        "outputId": "c3fe0e79-61df-47a7-ad7a-d3a0c5453271"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------------------------------------------------------------------+\n",
            "|id |text                                                                |\n",
            "+---+--------------------------------------------------------------------+\n",
            "|0  |The playful kittens chased the fluttering butterflies in the garden.|\n",
            "|1  |During her vacation, Emily enjoyed playing tennis                   |\n",
            "+---+--------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Firstly, we will define `DocumentAssembler()` with no `setIdCol()` parameter and check the metadata of the \"document\" column. "
      ],
      "metadata": {
        "id": "HYBvr1-aMkxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documentAssembler = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\\\n",
        "    .setCleanupMode(\"shrink\")\n",
        "    \n",
        "result = documentAssembler.transform(df)\n",
        "\n",
        "result.select(\"document\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioU8l03GMp0v",
        "outputId": "be27a635-bc64-405d-dc81-d6cebc3f9a62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------------------------------------------------------------+\n",
            "|document                                                                                                      |\n",
            "+--------------------------------------------------------------------------------------------------------------+\n",
            "|[{document, 0, 67, The playful kittens chased the fluttering butterflies in the garden., {sentence -> 0}, []}]|\n",
            "|[{document, 0, 48, During her vacation, Emily enjoyed playing tennis, {sentence -> 0}, []}]                   |\n",
            "+--------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.select(\"document.metadata\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emtB4LDhMuwy",
        "outputId": "87c3f1b6-6fb8-4b72-de1f-f1a959c58855"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+\n",
            "|metadata         |\n",
            "+-----------------+\n",
            "|[{sentence -> 0}]|\n",
            "|[{sentence -> 0}]|\n",
            "+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As seen above, we only have sentence number information under the metadata. <br/>\n",
        "\n",
        "Now, let's define `setIdCol(\"id\")` parameter and see the difference. "
      ],
      "metadata": {
        "id": "JEfivg1HM0HP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documentAssembler = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\\\n",
        "    .setCleanupMode(\"shrink\")\\\n",
        "    .setIdCol(\"id\")\n",
        "\n",
        "result = documentAssembler.transform(df)\n",
        "\n",
        "result.select(\"document\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4XGFwqOMzYt",
        "outputId": "f50b551d-d69d-40d6-db20-da5407fab49e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------------------------------------------------------------------------------------------------+\n",
            "|document                                                                                                               |\n",
            "+-----------------------------------------------------------------------------------------------------------------------+\n",
            "|[{document, 0, 67, The playful kittens chased the fluttering butterflies in the garden., {id -> 0, sentence -> 0}, []}]|\n",
            "|[{document, 0, 48, During her vacation, Emily enjoyed playing tennis, {id -> 1, sentence -> 0}, []}]                   |\n",
            "+-----------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.select(\"document.metadata\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8H5PnCmM6fd",
        "outputId": "ad445de5-a781-4929-feeb-f7cfceeb4fd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------+\n",
            "|metadata                  |\n",
            "+--------------------------+\n",
            "|[{id -> 0, sentence -> 0}]|\n",
            "|[{id -> 1, sentence -> 0}]|\n",
            "+--------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you see above, we have id information under the metadata since we employed `setIdCol(\"id\")` parameter. "
      ],
      "metadata": {
        "id": "FFNL5X7oM9tM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `setMetadataCol()`\n",
        "\n",
        "\n",
        "This parameter establishes the name of a Map type column that holds metadata information. It is employed to generate a column containing metadata details.\n",
        "\n",
        "By using setIdCol(), we can assign ID information within the metadata, while setMetadataCol() enables us to specify any additional details within the metadata."
      ],
      "metadata": {
        "id": "clHF2KiKQPPj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating sample data with a MapType column containing metadata information: "
      ],
      "metadata": {
        "id": "_LLlu6NzQh5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import MapType, StringType, IntegerType\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# define a schema for the dataset\n",
        "schema = \"id INT, name STRING, properties MAP<STRING, INT>\"\n",
        "\n",
        "# create a list of dictionaries to represent the data\n",
        "data = [{\"id\": 1, \"name\": \"Samantha\", \"properties\": {\"age\": 28, \"height\": 165, \"weight\": 60}},\n",
        "        {\"id\": 2, \"name\": \"James\", \"properties\": {\"age\": 32, \"height\": 185, \"weight\": 80}},\n",
        "        {\"id\": 3, \"name\": \"Olivia\", \"properties\": {\"age\": 40, \"height\": 172, \"weight\": 65}}]\n",
        "\n",
        "# create a DataFrame from the list of dictionaries\n",
        "df = spark.createDataFrame(data, schema)\n",
        "\n",
        "# show the resulting DataFrame\n",
        "df.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfQmD5wqQfa2",
        "outputId": "0876f7d0-6743-460e-947a-a3098621014b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------+----------------------------------------+\n",
            "|id |name    |properties                              |\n",
            "+---+--------+----------------------------------------+\n",
            "|1  |Samantha|{weight -> 60, age -> 28, height -> 165}|\n",
            "|2  |James   |{weight -> 80, age -> 32, height -> 185}|\n",
            "|3  |Olivia  |{weight -> 65, age -> 40, height -> 172}|\n",
            "+---+--------+----------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will use `setMetadataCol(\"properties\")` to specify metadata information for the \"name\" column. "
      ],
      "metadata": {
        "id": "iMaMHDGuROR0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documentAssembler = DocumentAssembler()\\\n",
        "    .setInputCol(\"name\")\\\n",
        "    .setOutputCol(\"document\")\\\n",
        "    .setCleanupMode(\"shrink\")\\\n",
        "    .setMetadataCol(\"properties\")\n",
        "\n",
        "result = documentAssembler.transform(df)\n",
        "\n",
        "result.select(\"document\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTs2Xq66RQrE",
        "outputId": "64fe1fa7-c010-4908-b7c1-dbb6aef73961"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------------------------------------------------------------------+\n",
            "|document                                                                                 |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "|[{document, 0, 7, Samantha, {weight -> 60, age -> 28, height -> 165, sentence -> 0}, []}]|\n",
            "|[{document, 0, 4, James, {weight -> 80, age -> 32, height -> 185, sentence -> 0}, []}]   |\n",
            "|[{document, 0, 5, Olivia, {weight -> 65, age -> 40, height -> 172, sentence -> 0}, []}]  |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.select(\"document.result\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9Lv5dRQRVa3",
        "outputId": "ed89fe32-27e0-4e5f-da36-7672c7884764"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+\n",
            "|result    |\n",
            "+----------+\n",
            "|[Samantha]|\n",
            "|[James]   |\n",
            "|[Olivia]  |\n",
            "+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.select(\"document.metadata\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vgx-nNgRYlP",
        "outputId": "6743c101-8cd1-4958-f1d8-6f4a468a6325"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------------+\n",
            "|metadata                                                 |\n",
            "+---------------------------------------------------------+\n",
            "|[{weight -> 60, age -> 28, height -> 165, sentence -> 0}]|\n",
            "|[{weight -> 80, age -> 32, height -> 185, sentence -> 0}]|\n",
            "|[{weight -> 65, age -> 40, height -> 172, sentence -> 0}]|\n",
            "+---------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `setCleanupMode()`\n",
        "\n",
        "\n",
        "setCleanupMode() can be used to pre-process the text (Default: disabled). It sets how to cleanup the document which has noisy content such as blank lines and tabs. "
      ],
      "metadata": {
        "id": "PN0WomRNLvFR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Possible values for setCleanupMode :\n",
        "- **disabled**: Don't change the source text (default).\n",
        "- **inplace**: Removes new lines and tabs.\n",
        "- **inplace_full**: Removes new lines and tabs but also those which were converted to strings (e.g., \\n, \\r, \\t)\n",
        "- **shrink**: removes new lines and tabs, plus merging multiple spaces and blank lines to a single space.\n",
        "- **shrink_full**: remove new lines and tabs, including stringified values, plus shrinking spaces and blank lines."
      ],
      "metadata": {
        "id": "rZYEOAOJ94sV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will add blank lines and tabs to our sample text in order to see how pre-processing features work."
      ],
      "metadata": {
        "id": "OdMNV05CgM6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_texts= \"\"\"I love working with  \\n   SparkNLP. \\n\n",
        "\n",
        "It is a perfect library.     I am living in Canada. \n",
        "\"\"\"\n",
        "\n",
        "data = spark.createDataFrame([[sample_texts]]).toDF(\"text\")"
      ],
      "metadata": {
        "id": "sd94ArHggPWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`disabled`**"
      ],
      "metadata": {
        "id": "KfHvbEx2ISm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documentAssembler = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\\\n",
        "    .setCleanupMode(\"disabled\")\n",
        "\n",
        "result = documentAssembler.transform(data)\n",
        "\n",
        "result.select(\"document\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnbcJJxwITjn",
        "outputId": "9883ae58-df36-4171-82b4-2e2546b3cc11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|document                                                                                                                                  |\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|[{document, 0, 90, I love working with  \\n   SparkNLP. \\n\\n\\nIt is a perfect library.     I am living in Canada. \\n, {sentence -> 0}, []}]|\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.select(\"document.result\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNJi9N3NIZiy",
        "outputId": "1086e51a-bf52-4e2a-8007-b6e114f7db32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------------------------------------------------+\n",
            "|result                                                                                            |\n",
            "+--------------------------------------------------------------------------------------------------+\n",
            "|[I love working with  \\n   SparkNLP. \\n\\n\\nIt is a perfect library.     I am living in Canada. \\n]|\n",
            "+--------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Disabled values for setCleanupMode is a default. As you see th result nothing changed. Disabled option keeps sources as a original."
      ],
      "metadata": {
        "id": "0DgB7IErIhGz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`inplace`**"
      ],
      "metadata": {
        "id": "0tS25j9ZI_Ia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documentAssembler = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\\\n",
        "    .setCleanupMode(\"inplace\")\n",
        "\n",
        "result = documentAssembler.transform(data)\n",
        "\n",
        "result.select(\"document\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eK4Gzp5-JBIW",
        "outputId": "10a334f1-c0dd-47e3-f332-cded1da1971d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|document                                                                                                                             |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|[{document, 0, 90, I love working with      SparkNLP.    It is a perfect library.     I am living in Canada.  , {sentence -> 0}, []}]|\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.select(\"document.result\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_HGT0sGJEZE",
        "outputId": "2bdf4d31-1f05-4946-b6c2-f2d6b95c47c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------------------------------------------------+\n",
            "|result                                                                                       |\n",
            "+---------------------------------------------------------------------------------------------+\n",
            "|[I love working with      SparkNLP.    It is a perfect library.     I am living in Canada.  ]|\n",
            "+---------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inplace option removes new lines and tabs. As you see the result there are no new lines and tabs. Inplace_full option is same as inplace option."
      ],
      "metadata": {
        "id": "UYXFh5RmJHu7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`shrink`**"
      ],
      "metadata": {
        "id": "8VcL3wQEghHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documentAssembler = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\\\n",
        "    .setCleanupMode(\"shrink\")\n",
        "\n",
        "result = documentAssembler.transform(data)\n",
        "\n",
        "result.select(\"document\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvF1ZqLEKtYX",
        "outputId": "e4ad0051-3d93-4a2d-afb6-cc3211d23207"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------------------------------------------------------------------------------------------------+\n",
            "|document                                                                                                               |\n",
            "+-----------------------------------------------------------------------------------------------------------------------+\n",
            "|[{document, 0, 76, I love working with SparkNLP. It is a perfect library. I am living in Canada., {sentence -> 0}, []}]|\n",
            "+-----------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.select(\"document.result\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kc05JcgGgj0r",
        "outputId": "ab7b750d-4d15-4c89-c424-2ac2fc57aa36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------------------------------------------+\n",
            "|result                                                                         |\n",
            "+-------------------------------------------------------------------------------+\n",
            "|[I love working with SparkNLP. It is a perfect library. I am living in Canada.]|\n",
            "+-------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As seen above, there is no new lines and tabs. Merged multiple spaces and blank lines to a single space. shrink_full option is same as shrink option."
      ],
      "metadata": {
        "id": "478-pAkUID2K"
      }
    }
  ]
}