{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1dy4u_2nRQ4P"
      },
      "source": [
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Open_Source/04.01.NGramGenerator.ipynb)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GZx3ReWigu_W"
      },
      "source": [
        "# NGramGenerator"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5LVXb6QRW8F"
      },
      "source": [
        "This notebook will cover the different parameters and usages of `NGramGenerator`.\n",
        "\n",
        "**📖 Learning Objectives:**\n",
        "\n",
        "1. Understand how to use `NGramGenerator`.\n",
        "\n",
        "2. Become familiar with the parameters and options available for the `NGramGenerator`.\n",
        "\n",
        "**🔗 Helpful Links:**\n",
        "\n",
        "- Documentation: [NGramGenerator](https://nlp.johnsnowlabs.com/docs/en/annotators#ngramgenerator)\n",
        "\n",
        "- Python Docs: [NGramGenerator](https://nlp.johnsnowlabs.com/api/python/reference/autosummary/sparknlp/annotator/n_gram_generator/index.html#sparknlp.annotator.n_gram_generator.NGramGenerator)\n",
        "\n",
        "- Scala Docs: [NGramGenerator](https://nlp.johnsnowlabs.com/api/com/johnsnowlabs/nlp/annotators/NGramGenerator)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9z4LO9SmSGFo"
      },
      "source": [
        "## **📜 Background**\n",
        "N-grams are continuous sequences of words or symbols or tokens in a document. In technical terms, they can be defined as the neighbouring sequences of items in a document. They come into play when we deal with text data in NLP(Natural Language Processing) tasks. A feature transformer that converts the input array of strings into an array of n-grams. Null values in the input array are ignored. It returns an array of n-grams where each n-gram is represented by a space-separated string of words.\n",
        "\n",
        "\n",
        "'N' here is used to designate the number of 'grams' or neighbouring sequences of items. Common splits are as follows:\n",
        "\n",
        "- n = 1: Unigram\n",
        "- n = 2: Bigram\n",
        "- n = 3: Trigram"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "yAiy7CI5SLOY"
      },
      "source": [
        "## **🎬 Colab Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0HMq9H5Wdb3",
        "outputId": "3d4ea5e0-60aa-4566-da63-9c1787b5e1ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.4/453.4 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.0/199.0 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q pyspark==3.2.1 spark-nlp==4.2.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "1DRf_M0KlMV7",
        "outputId": "e0946950-03aa-4ec4-b1e1-1c18f9bd8d50"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://3e8828c552fa:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark NLP</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fb7f12cc6d0>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import sparknlp\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.types import StringType\n",
        "\n",
        "spark = sparknlp.start()\n",
        "spark"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "10rTlAX6SNzk"
      },
      "source": [
        "## **🖨️ Input/Output Annotation Types**\n",
        "\n",
        "\n",
        "- Input: `TOKEN`\n",
        "\n",
        "- Output: `CHUNK`"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sdsbIFP5SusQ"
      },
      "source": [
        "## **🔎Parameters**\n",
        "- `n`: (IntParam) Minimum n-gram length, greater than or equal to 1 (Default: 2, bigram features).\n",
        "- `enableCumulative`: (BooleanParam) Whether to calculate just the actual n-grams or all n-grams from 1 through n (Default: false).\n",
        "- `delimiter`: (String) Glue character used to join the tokens (Default: \" \").\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GSQxmQSraJKU"
      },
      "source": [
        "### `setN`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRyju8D-6XJ1"
      },
      "outputs": [],
      "source": [
        "documentAssembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"text\") \\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "tokenizer = Tokenizer() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "bigrams = NGramGenerator() \\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"bigrams\") \\\n",
        "    .setN(2)\n",
        "\n",
        "trigrams = NGramGenerator() \\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"trigrams\") \\\n",
        "    .setN(3)\n",
        "\n",
        "pipeline = Pipeline(stages=[\n",
        "    documentAssembler,\n",
        "    tokenizer,\n",
        "    bigrams,\n",
        "    trigrams\n",
        "])\n",
        "\n",
        "data = spark.createDataFrame([\n",
        "    \"Cloud computing is benefiting major manufacturing companies\",\n",
        "    \"Big data cloud computing cyber security machine learning\"\n",
        "], StringType()).toDF(\"text\")\n",
        "\n",
        "result = pipeline.fit(data).transform(data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CPQRxBXjpHu",
        "outputId": "8d2c7d19-d2ce-408f-d518-3226dc21d5e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------------------------------------------------------------------+\n",
            "|result                                                                                                        |\n",
            "+--------------------------------------------------------------------------------------------------------------+\n",
            "|[Cloud computing, computing is, is benefiting, benefiting major, major manufacturing, manufacturing companies]|\n",
            "|[Big data, data cloud, cloud computing, computing cyber, cyber security, security machine, machine learning]  |\n",
            "+--------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result.select(\"bigrams.result\").show(2, truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fjj1HOiOjuOk",
        "outputId": "a9dc69f3-c840-4415-d9c8-d0e9017aee7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|result                                                                                                                                    |\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|[Cloud computing is, computing is benefiting, is benefiting major, benefiting major manufacturing, major manufacturing companies]         |\n",
            "|[Big data cloud, data cloud computing, cloud computing cyber, computing cyber security, cyber security machine, security machine learning]|\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result.select(\"trigrams.result\").show(2, truncate=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6cks2UP5mC0h"
      },
      "source": [
        "### `setEnableCumulative`\n",
        "If we set EnableCumulative True. Return all n-grams from 1 through n. You can see an example in below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQ6qQwCOlvAq",
        "outputId": "6468b6eb-810b-420f-d030-90760d9fa31b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "NGramGenerator_26fa38408f8a"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trigrams.setEnableCumulative(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDXVUjpZl3Ka"
      },
      "outputs": [],
      "source": [
        "data = spark.createDataFrame([\n",
        "    \"Cloud computing is benefiting major manufacturing companies\",\n",
        "    \"Big data cloud computing cyber security machine learning\"\n",
        "], StringType()).toDF(\"text\")\n",
        "\n",
        "result = pipeline.fit(data).transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-M-xRQwl6yz",
        "outputId": "6f36d9fc-886f-45fb-ff18-3b054ef712fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|result                                                                                                                                                                                                                                                                                                                 |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|[Cloud, computing, is, benefiting, major, manufacturing, companies, Cloud computing, computing is, is benefiting, benefiting major, major manufacturing, manufacturing companies, Cloud computing is, computing is benefiting, is benefiting major, benefiting major manufacturing, major manufacturing companies]     |\n",
            "|[Big, data, cloud, computing, cyber, security, machine, learning, Big data, data cloud, cloud computing, computing cyber, cyber security, security machine, machine learning, Big data cloud, data cloud computing, cloud computing cyber, computing cyber security, cyber security machine, security machine learning]|\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result.select(\"trigrams.result\").show(2, truncate=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tzOsXJK1lDFf"
      },
      "source": [
        "### `setDelimiter`\n",
        "If we set delimiter \"/\", tokens will be joined with \"/\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0k3xBwKoJy3",
        "outputId": "b4c6657c-ec29-4912-92eb-2cb80733d136"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "NGramGenerator_0fd4f0e688c6"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bigrams.setDelimiter(\"/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Agi-l4w-oRjC"
      },
      "outputs": [],
      "source": [
        "data = spark.createDataFrame([\n",
        "    \"Cloud computing is benefiting major manufacturing companies\",\n",
        "], StringType()).toDF(\"text\")\n",
        "\n",
        "result = pipeline.fit(data).transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGg7rJzToU9U",
        "outputId": "4d1bfe02-cf0d-42b7-fde5-d508b0067e22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------------------------------------------------------------------+\n",
            "|result                                                                                                        |\n",
            "+--------------------------------------------------------------------------------------------------------------+\n",
            "|[Cloud/computing, computing/is, is/benefiting, benefiting/major, major/manufacturing, manufacturing/companies]|\n",
            "+--------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result.select(\"bigrams.result\").show(2, truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEh2yCKM_9UO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
