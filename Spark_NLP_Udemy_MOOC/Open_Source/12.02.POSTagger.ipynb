{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"_UPkqyygYK3L"},"source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Open_Source/12.02.POSTagger.ipynb)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"kiOhdfmwYOFQ"},"source":["# **POSTagger(Part of speech tagger)**"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"9xWjzOICY_Qg"},"source":["This notebook will cover the different parameters and usages of `POSTagger`. \n","\n","**📖 Learning Objectives:**\n","\n","1. Understand the basics of `part-of-speech (POS) tagging` and how it can be useful in natural language processing applications.\n","\n","2. Learn about potential use cases for `POS tagging`, such as and named entity recognition, and dependency parser\n","\n","**🔗 Helpful Links:**\n","\n","- Documentation : [PerceptronModel](https://nlp.johnsnowlabs.com/docs/en/annotators#postagger-part-of-speech-tagger)\n","\n","- Python Docs : [PerceptronModel](https://nlp.johnsnowlabs.com/api/python/reference/autosummary/sparknlp/annotator/pos/perceptron/index.html)\n","\n","- Scala Docs : [PerceptronModel](https://nlp.johnsnowlabs.com/api/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronModel)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ESodR3tMrnk5"},"source":["## **📜 Background**\n","`Part-of-speech (POS) tagging` is the process of labeling each word in a text with its corresponding part of speech, such as noun, verb, adjective, etc. `POS tagging` is a fundamental task in natural language processing, and it is used in many downstream applications such as  and named entity recognition, relation extraction, and dependency parser."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"X26HwMdwf-nJ"},"source":["## **🎬 Colab Setup**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WVrizsjCWebQ"},"outputs":[],"source":["! pip install -q pyspark==3.1.2  spark-nlp==4.2.4"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":259},"executionInfo":{"elapsed":309,"status":"ok","timestamp":1677845718453,"user":{"displayName":"Ahmet Mesut BİROL","userId":"04340760882990254267"},"user_tz":-180},"id":"R1AJV_vigF8V","outputId":"c7b8d9c7-659b-4e5c-bd00-1dd36e5f8ff5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Spark NLP version 4.2.4\n","Apache Spark version: 3.1.2\n"]},{"data":{"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://c2ed2c3603ba:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.1.2</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>Spark NLP</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "],"text/plain":["<pyspark.sql.session.SparkSession at 0x7f95216a1cd0>"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["import sparknlp\n","\n","import sys\n","sys.path.append('../../')\n","\n","import sparknlp\n","\n","from sparknlp.base import LightPipeline\n","from pyspark.sql import SparkSession\n","from pyspark.ml import Pipeline\n","from pyspark.sql.functions import array_contains\n","from sparknlp.annotator import *\n","from sparknlp.common import RegexRule\n","from sparknlp.base import DocumentAssembler, Finisher\n","import pandas as pd\n","import pyspark.sql.functions as F\n","\n","spark = sparknlp.start()\n","\n","print(\"Spark NLP version\", sparknlp.version())\n","print(\"Apache Spark version:\", spark.version)\n","\n","spark"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"mX1qzTKNgLkv"},"source":["## **🖨️ Input/Output Annotation Types**"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"lkY8aHzZgQ_J"},"source":["- Input: `TOKEN`  `DOCUMENT`\n","\n","- Output: `POS`"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"1FXE50gejKTd"},"source":["## **🔎Parameters**"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"PCmnL1oMjVaO"},"source":["- `NONE`\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3946,"status":"ok","timestamp":1677845722384,"user":{"displayName":"Ahmet Mesut BİROL","userId":"04340760882990254267"},"user_tz":-180},"id":"rZI62kjZgJuR","outputId":"f564f33d-c14c-4e13-9d25-c142fc27c38e"},"outputs":[{"name":"stdout","output_type":"stream","text":["pos_anc download started this may take some time.\n","Approximate size to download 3.9 MB\n","[OK!]\n"]}],"source":["documentAssembler = DocumentAssembler() \\\n","    .setInputCol(\"text\") \\\n","    .setOutputCol(\"document\")\n","\n","tokenizer = Tokenizer() \\\n","    .setInputCols([\"document\"]) \\\n","    .setOutputCol(\"token\")\n","\n","posTagger = PerceptronModel.pretrained() \\\n","    .setInputCols([\"document\", \"token\"]) \\\n","    .setOutputCol(\"pos\")\n","\n","pipeline = Pipeline().setStages([\n","    documentAssembler,\n","    tokenizer,\n","    posTagger\n","])\n","data = spark.createDataFrame([[\"Peter Pipers employees are picking pecks of pickled peppers\"]]).toDF(\"text\")\n","\n","result = pipeline.fit(data).transform(data)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":589,"status":"ok","timestamp":1677845722961,"user":{"displayName":"Ahmet Mesut BİROL","userId":"04340760882990254267"},"user_tz":-180},"id":"A7NEfnlNofqD","outputId":"e7c16c7d-301d-4e70-b80e-afcbfd1b3e2b"},"outputs":[{"name":"stdout","output_type":"stream","text":["+----------------------------------------------------------+\n","|pos                                                       |\n","+----------------------------------------------------------+\n","|{pos, 0, 4, NNP, {word -> Peter, sentence -> 0}, []}      |\n","|{pos, 6, 11, NNP, {word -> Pipers, sentence -> 0}, []}    |\n","|{pos, 13, 21, NNS, {word -> employees, sentence -> 0}, []}|\n","|{pos, 23, 25, VBP, {word -> are, sentence -> 0}, []}      |\n","|{pos, 27, 33, VBG, {word -> picking, sentence -> 0}, []}  |\n","|{pos, 35, 39, NNS, {word -> pecks, sentence -> 0}, []}    |\n","|{pos, 41, 42, IN, {word -> of, sentence -> 0}, []}        |\n","|{pos, 44, 50, JJ, {word -> pickled, sentence -> 0}, []}   |\n","|{pos, 52, 58, NNS, {word -> peppers, sentence -> 0}, []}  |\n","+----------------------------------------------------------+\n","\n"]}],"source":["result.selectExpr(\"explode(pos) as pos\").show(truncate=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"rK3RjH9NPIs4"},"source":["**When we use `pereptron model`.**"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"12eOmnwHNZhw"},"source":["* For example `NerCRF model` and `Dependency parser` require POS tag as an input column."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11672,"status":"ok","timestamp":1677845734622,"user":{"displayName":"Ahmet Mesut BİROL","userId":"04340760882990254267"},"user_tz":-180},"id":"yqU_V8E9UtnY","outputId":"28cd932c-3a46-4824-e841-3029c31c0666"},"outputs":[{"name":"stdout","output_type":"stream","text":["glove_100d download started this may take some time.\n","Approximate size to download 145.3 MB\n","[OK!]\n","pos_anc download started this may take some time.\n","Approximate size to download 3.9 MB\n","[OK!]\n","ner_crf download started this may take some time.\n","Approximate size to download 10.2 MB\n","[OK!]\n","+------------------------------------+\n","|result                              |\n","+------------------------------------+\n","|[I-ORG, O, O, I-PER, O, O, I-LOC, O]|\n","+------------------------------------+\n","\n"]}],"source":["documentAssembler = DocumentAssembler() \\\n","    .setInputCol(\"text\") \\\n","    .setOutputCol(\"document\")\n","\n","sentence = SentenceDetector() \\\n","    .setInputCols([\"document\"]) \\\n","    .setOutputCol(\"sentence\")\n","\n","tokenizer = Tokenizer() \\\n","    .setInputCols([\"sentence\"]) \\\n","    .setOutputCol(\"token\")\n","\n","embeddings = WordEmbeddingsModel.pretrained() \\\n","    .setInputCols([\"sentence\", \"token\"]) \\\n","    .setOutputCol(\"word_embeddings\")\n","\n","posTagger = PerceptronModel.pretrained() \\\n","    .setInputCols([\"sentence\", \"token\"]) \\\n","    .setOutputCol(\"pos\")\n","\n","dependencyParser = DependencyParserModel() \\\n","    .setInputCols(\"sentence\", \"pos\", \"token\") \\\n","    .setOutputCol(\"dependency\")\n","\n","nerTagger = NerCrfModel.pretrained() \\\n","    .setInputCols([\"sentence\", \"token\", \"word_embeddings\", \"pos\"]) \\\n","    .setOutputCol(\"ner\")\n","\n","pipeline = Pipeline().setStages([\n","    documentAssembler,\n","    sentence,\n","    tokenizer,\n","    embeddings,\n","    posTagger,\n","    dependencyParser,\n","    nerTagger\n","])\n","\n","data = spark.createDataFrame([[\"U.N. official Ekeus heads for Baghdad.\"]]).toDF(\"text\")\n","result = pipeline.fit(data).transform(data)\n","\n","result.select(\"ner.result\").show(truncate=False)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMbrWE9IBoE0MfP76Fqwpu9","provenance":[{"file_id":"1CrvrheKC5BTv5YGgqJtt0spZfEiu0fpO","timestamp":1677785283722}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
