{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"D0qeroSZw4vv"},"source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Open_Source/27.01.QuestionAnswering_with_Transformers.ipynb)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"-UHbE9sww3By"},"source":["# QuestionAnswering with Transformers"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Pyvm-P37Cs0E"},"source":["This notebook will cover the different parameters and usages of Transformers-bases QuestionAnswering annotators.\n","\n","\n","\n","**üìñ Learning Objectives:**\n","\n","1. Be able to create a pipeline for question answering using a Transformers-bases annotator.\n","\n","2. Understand how to use the annotators for predictions.\n","\n","3. Become comfortable using the different parameters of the annotator.\n","\n","4. Import Transformers models from Hugging Face to Spark NLP.\n","\n","\n","\n","**üîó Helpful Links:**\n","\n","- Documentation : [Transformers in Spark NLP](https://nlp.johnsnowlabs.com/docs/en/transformers)\n","\n","\n","\n","- Scala Doc : [BertForQuestionAnswering](https://nlp.johnsnowlabs.com/api/com/johnsnowlabs/nlp/annotators/classifier/dl/BertForQuestionAnswering.html)\n","\n","\n","- For extended examples of usage, see the [Spark NLP Workshop repository.](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/14.Transformers_for_Token_Classification_in_Spark_NLP.ipynb)\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"AXWnSePjQySK"},"source":["## Transformers and Spark NLP"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"-CXZlu3xQ48d"},"source":["Spark NLP has extended support for importing models from `HuggingFace` ü§ó   and `TF Hub` since `3.1.0`. You can easily use the `saved_model` feature in HuggingFace within a few lines of codes and import any of the following types of models into Spark NLP.\n","\n","</br>\n","<div align=\"center\">\n","<style type=\"text/css\">\n",".tg  {border-collapse:collapse;border-spacing:0;}\n",".tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n","  overflow:hidden;padding:10px 5px;word-break:normal;}\n",".tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n","  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",".tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}\n","</style>\n","<table class=\"tg\">\n","<tbody>\n","  <tr>\n","    <td class=\"tg-0pky\"><span style=\"color:#905;background-color:#ddd\">AlbertForQuestionAnswering</span></td>\n","  </tr>\n","  <tr>\n","    <td class=\"tg-0pky\"><span style=\"color:#905;background-color:#ddd\">BertForQuestionAnswering</span></td>\n","  </tr>\n","  <tr>\n","    <td class=\"tg-0pky\"><span style=\"color:#905;background-color:#ddd\">DeBertaForQuestionAnswering</span></td>\n","  </tr>\n","  <tr>\n","    <td class=\"tg-0pky\"><span style=\"color:#905;background-color:#ddd\">DistilBertForQuestionAnswering</span></td>\n","  </tr>\n","  <tr>\n","    <td class=\"tg-0pky\"><span style=\"color:#905;background-color:#ddd\">LongformerForQuestionAnswering</span></td>\n","  </tr>\n","  <tr>\n","    <td class=\"tg-0pky\"><span style=\"color:#905;background-color:#ddd\">RoBertaForQuestionAnswering</span></td>\n","  </tr>\n","  <tr>\n","    <td class=\"tg-0pky\"><span style=\"color:#905;background-color:#ddd\">XlmRoBertaForQuestionAnswering</span></td>\n","  </tr>\n","  <tr>\n","    <td class=\"tg-0pky\"><span style=\"color:#905;background-color:#ddd\">TapasForQuestionAnswering</span></td>\n","  </tr>\n","</tbody>\n","</table>\n","</div>\n","</br>\n","\n","> We will keep working on the remaining annotators and extend this support to aditional Transformers models. To keep updated, visit [this page](https://github.com/JohnSnowLabs/spark-nlp/discussions/5669) on compatibility and development of the adaptations of TF Hub and  HuggingFace to Spark NLP. Keep tuned for the next releases."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"A3u00wg1RRmI"},"source":["### Question Answering"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"yOu1JHUvRQRX"},"source":["As mentioned above, we already have implemented many different Transformers models in Spark NLP, and specifically for question answering we have all the versions of **`ForQuestionAnswering`**, where can be any of:\n","\n","- `BERT` ([BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805), Jacob Devlin et al.): Randomly changes input texts (for example, 15% of them) with _MASKS_ or random tokens in order to learn a language model. Given two sentences, the learning process makes two tasks: \n","    - Predict the sentences by correctly replacing the wrong tokens.\n","    - Predict if the sentences are consecutive or not.\n","- `ALBERT` ([ALBERT: A Lite BERT for Self-supervised Learning of Language Representations](https://arxiv.org/abs/1909.11942), Zhenzhong Lan et al.): Same as Bert, with changes in some hyperparameters that optimizes memomy usage. The training phase instead of predicting if the two sentences are consecutive, now they predict if they were swapped or not (two consecutive sentences are input, model predict if they were given in the correct order or not).\n","- `RoBERTa` ([RoBERTa: A Robustly Optimized BERT Pretraining Approach](https://arxiv.org/abs/1907.11692), Yinhan Liu et al.): Same as Bert, but with some different training methods (e.g., using dynamic masking in each epoch instead).\n","- `CamemBERT` ([CamemBERT: a Tasty French Language Model](https://arxiv.org/abs/1911.03894), Louis Martin et al.): Based on RoBerta model, trained with French dataset.\n","- `DistilBERT` ([DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter](https://arxiv.org/abs/1910.01108),Victor Sanh et al.): Distilled version of Bert (model parameters were reduced by using transfer learning from big model to smaller model). \n","- `Longformer` ([Longformer: The Long-Document Transformer](https://arxiv.org/abs/2004.05150), Iz Beltagy et al.): Allows the use of upt to 4096 tokens instead of the usual limit of 512. To optimize the added computational cost, replace dense matrixes by sparse representations.\n","- `XlmRoBerta` ([Unsupervised Cross-lingual Representation Learning at Scale](https://arxiv.org/abs/1911.02116), Alexis Conneau et al.): Applies the training methods from RoBerta to Xlm model. \n","- `Xlnet` ([XLNet: Generalized Autoregressive Pretraining for Language Understanding](https://arxiv.org/abs/1906.08237), Zhilin Yang et al.): differently than token masking applied in Bert models, it trains the language model by permuting the tokens. \n","\n","\n","For more details on these models and others available on HuggingFace, pelase visit the [HuggingFace documentation](https://huggingface.co/docs/transformers/model_summary)."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"P9BgOdf_yan8"},"source":["## **üé¨ Colab Setup**"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"xlgz0VWj0d32"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32020,"status":"ok","timestamp":1678049440173,"user":{"displayName":"Hasham Ul Haq","userId":"10508284328555930330"},"user_tz":360},"id":"V3b4Flg_tz5C","outputId":"3999e7fb-f67a-4c4b-e703-a69be90acc40"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m212.4/212.4 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m448.4/448.4 KB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m198.6/198.6 KB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install -q pyspark==3.1.2 spark-nlp==4.2.4"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":256},"executionInfo":{"elapsed":40478,"status":"ok","timestamp":1678049480644,"user":{"displayName":"Hasham Ul Haq","userId":"10508284328555930330"},"user_tz":360},"id":"atQWxlEit36h","outputId":"68ef27b5-5ba7-445e-aa55-7013396f197d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Spark NLP version 4.2.4\n","Apache Spark version: 3.1.2\n"]},{"data":{"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://4c14a905d5c9:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.1.2</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>Spark NLP</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "],"text/plain":["<pyspark.sql.session.SparkSession at 0x7f340092b640>"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["import sparknlp\n","\n","from sparknlp.annotator import *\n","from sparknlp.common import *\n","from sparknlp.base import *\n","\n","spark = sparknlp.start()\n","\n","print(\"Spark NLP version\", sparknlp.version())\n","print(\"Apache Spark version:\", spark.version)\n","\n","spark"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"38c-lVAcFKlL"},"source":["## **üñ®Ô∏è Input/Output Annotation Types**"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"kTsgw5lxFOHZ"},"source":["- Input: `DOCUMENT`, `TOKEN`\n","\n","- Output: `CHUNK`"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"PK4swxT0G-3V"},"source":["## **üîéParameters**"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"DCwpJTR-rRtQ"},"source":["- `setCaseSensitive()`:\n","Set whether to ignore case in index lookups with this parameter\n","(Default depends on model)\n","\n","- `setMaxSentenceLength()` : Maximum sentence length to process, limited to 512 for all models except `Longformer` which has a limit of 4096. (Default: 512)\n","\n","- `batchSize` : Large values allows faster processing but requires more memory (Default depends on model)\n","\n","- `configProtoBytes` : ConfigProto from tensorflow, serialized into byte array. Get with `config_proto.SerializeToString()`"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"QScWUezqWcqG"},"source":["## Defining the Spark NLP Pipeline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OelkNPwLWgvV"},"outputs":[],"source":["from sparknlp.base import MultiDocumentAssembler\n","from sparknlp.annotator import Tokenizer, BertForQuestionAnswering, DistilBertForQuestionAnswering, RoBertaForQuestionAnswering\n","from pyspark.ml import Pipeline\n","import pyspark.sql.functions as F"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"IFmSwLdAXUD7"},"source":["‚û§ Let's prepared the pre-requisite columns first, so we can use them in different annotators."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LHc4xXwAXU7L"},"outputs":[],"source":["documentAssembler = MultiDocumentAssembler() \\\n","    .setInputCols([\"question\", \"context\"]) \\\n","    .setOutputCols([\"document_question\", \"document_context\"])\n","\n","pipeline = Pipeline(stages=[documentAssembler])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":406,"status":"ok","timestamp":1678051661009,"user":{"displayName":"Hasham Ul Haq","userId":"10508284328555930330"},"user_tz":360},"id":"Obz2d7ltYOQG","outputId":"1456690a-3673-46b0-b649-864a3a0f9915"},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------------------+--------------------+\n","|            question|             context|\n","+--------------------+--------------------+\n","|Who is founder of...|Alibaba Group fou...|\n","+--------------------+--------------------+\n","\n"]}],"source":["example_df = spark.createDataFrame([[\"Who is founder of Alibaba Group?\", \"Alibaba Group founder Jack Ma has made his first appearance since Chinese regulators cracked down on his business empire.\"]]).toDF(\"question\", \"context\")\n","\n","example_df.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1935,"status":"ok","timestamp":1678051684324,"user":{"displayName":"Hasham Ul Haq","userId":"10508284328555930330"},"user_tz":360},"id":"CNmPrcL4iak1","outputId":"a160a67a-bbb8-4288-ff26-a62cf616afa6"},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------------------+--------------------+--------------------+--------------------+--------------------+\n","|            question|             context|   document_question|    document_context|              answer|\n","+--------------------+--------------------+--------------------+--------------------+--------------------+\n","|Who is founder of...|Alibaba Group fou...|[{document, 0, 31...|[{document, 0, 12...|[{chunk, 0, 6, Ja...|\n","+--------------------+--------------------+--------------------+--------------------+--------------------+\n","\n"]}],"source":["example_df = pipeline.fit(example_df).transform(example_df)\n","example_df.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"u4zQOmoNYMX6"},"source":["### Bert"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43470,"status":"ok","timestamp":1678049690681,"user":{"displayName":"Hasham Ul Haq","userId":"10508284328555930330"},"user_tz":360},"id":"CrvNKyWHYnm9","outputId":"e94b133b-5049-47e2-88cd-916c4407d00b"},"outputs":[{"name":"stdout","output_type":"stream","text":["bert_base_cased_qa_squad2 download started this may take some time.\n","Approximate size to download 385.5 MB\n","[OK!]\n"]}],"source":["question_answering = BertForQuestionAnswering.pretrained(\"bert_base_cased_qa_squad2\") \\\n","    .setInputCols([\"document_question\", \"document_context\"]) \\\n","    .setOutputCol(\"answer\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":121,"status":"ok","timestamp":1678051719130,"user":{"displayName":"Hasham Ul Haq","userId":"10508284328555930330"},"user_tz":360},"id":"_dyiO_JIrSQy","outputId":"d9631f76-9115-43f3-bcdf-e60c590b018b"},"outputs":[{"data":{"text/plain":["True"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["question_answering.getCaseSensitive()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4197,"status":"ok","timestamp":1678049694861,"user":{"displayName":"Hasham Ul Haq","userId":"10508284328555930330"},"user_tz":360},"id":"U-_7S2ThZmeY","outputId":"87d52842-e05a-4507-b362-2e461e3c29f9"},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------------------------------+---------+\n","|Question                        |Answer   |\n","+--------------------------------+---------+\n","|Who is founder of Alibaba Group?|[Jack Ma]|\n","+--------------------------------+---------+\n","\n"]}],"source":["result = question_answering.transform(example_df)\n","result.selectExpr(\"question as Question\", \"answer.result as Answer\").show(truncate=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"5HRMSlCEaHtm"},"source":["### DistilBert"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23282,"status":"ok","timestamp":1678049718128,"user":{"displayName":"Hasham Ul Haq","userId":"10508284328555930330"},"user_tz":360},"id":"oH98lQx5aRWc","outputId":"2ac39c57-ce82-410f-91dd-559c35274015"},"outputs":[{"name":"stdout","output_type":"stream","text":["distilbert_qa_BERT download started this may take some time.\n","Approximate size to download 232.8 MB\n","[OK!]\n","+--------------------------------+---------+\n","|Question                        |Answer   |\n","+--------------------------------+---------+\n","|Who is founder of Alibaba Group?|[Jack Ma]|\n","+--------------------------------+---------+\n","\n"]}],"source":["question_answering = DistilBertForQuestionAnswering \\\n","    .pretrained(\"distilbert_qa_BERT\", \"en\") \\\n","    .setInputCols([\"document_question\", \"document_context\"]) \\\n","    .setOutputCol(\"answer\")\n","\n","\n","result = question_answering.transform(example_df)\n","result.selectExpr(\"question as Question\", \"answer.result as Answer\").show(truncate=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"djiI-wuGAAfx"},"source":["### RoBerta for Spanish\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46670,"status":"ok","timestamp":1678049764780,"user":{"displayName":"Hasham Ul Haq","userId":"10508284328555930330"},"user_tz":360},"id":"9tqxnJfNAvoN","outputId":"0a007e02-105e-4c73-ff7e-72b5b58d153e"},"outputs":[{"name":"stdout","output_type":"stream","text":["roberta_qa_roberta_base_bne_squad_2.0_es_jamarju download started this may take some time.\n","Approximate size to download 435.2 MB\n","[OK!]\n","+-----------------------------+--------+\n","|Question                     |Answer  |\n","+-----------------------------+--------+\n","|¬øEn qu√© ciudad vive su madre?|[Madrid]|\n","+-----------------------------+--------+\n","\n"]}],"source":["example_df = spark.createDataFrame([[\"¬øEn qu√© ciudad vive su madre?\", \"Su madre vive en Madrid y es maestra.\" ]]).toDF(\"question\", \"context\")\n","\n","documentAssembler = MultiDocumentAssembler() \\\n","    .setInputCols([\"question\", \"context\"]) \\\n","    .setOutputCols([\"document_question\", \"document_context\"])\n","\n","question_answering = RoBertaForQuestionAnswering \\\n","    .pretrained(\"roberta_qa_roberta_base_bne_squad_2.0_es_jamarju\", \"es\") \\\n","    .setInputCols([\"document_question\", \"document_context\"]) \\\n","    .setOutputCol(\"answer\")\n","\n","pipeline = Pipeline(stages=[\n","    documentAssembler,\n","    question_answering\n","    ])\n","\n","result = pipeline.fit(example_df).transform(example_df)\n","result.selectExpr(\"question as Question\", \"answer.result as Answer\").show(truncate=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1748,"status":"ok","timestamp":1678049766507,"user":{"displayName":"Hasham Ul Haq","userId":"10508284328555930330"},"user_tz":360},"id":"u0fFNbOzt3lw","outputId":"2c012263-f781-4834-9562-437db0997339"},"outputs":[{"name":"stdout","output_type":"stream","text":["+-----------------------------+-------------------------------------+------+\n","|                     question|                              context|answer|\n","+-----------------------------+-------------------------------------+------+\n","|¬øEn qu√© ciudad vive su madre?|Su madre vive en Madrid y es maestra.|Madrid|\n","+-----------------------------+-------------------------------------+------+\n","\n"]}],"source":["result_df = result.select(F.explode(F.arrays_zip(result.document_question.result,\n","                                                 result.document_context.result, \n","                                                 result.answer.result)).alias(\"cols\"))\\\n","                  .select(F.expr(\"cols['0']\").alias(\"question\"),\n","                          F.expr(\"cols['1']\").alias(\"context\"),\n","                          F.expr(\"cols['2']\").alias(\"answer\"))\n","\n","result_df.show(50, truncate=100)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"nMcRpNcXxZbQ"},"source":["###  Using LightPipeline"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"wrnjKRMsxXLh"},"source":["[LightPipelines](https://nlp.johnsnowlabs.com/docs/en/concepts#using-spark-nlps-lightpipeline) are Spark NLP specific Pipelines, equivalent to Spark ML Pipeline, but meant to deal with smaller amounts of data. They‚Äôre useful working with small datasets, debugging results, or when running either training or prediction from an API that serves one-off requests.\n","\n","Spark NLP LightPipelines are Spark ML pipelines converted into a single machine but the multi-threaded task, **becoming more than 10x times faster** for smaller amounts of data (small is relative, but 50k sentences are roughly a good maximum). To use them, we simply plug in a trained (fitted) pipeline and then annotate a plain text. We don't even need to convert the input text to DataFrame in order to feed it into a pipeline that's accepting DataFrame as an input in the first place. This feature would be quite useful when it comes to getting a prediction for a few lines of text from a trained ML model.\n","\n","For more details, check the following \n","[Medium post](https://medium.com/spark-nlp/spark-nlp-101-lightpipeline-a544e93f20f1).\n","\n","This class accepts strings or list of strings as input, without the need to transform your text into a spark data frame. The [.annotate()](https://nlp.johnsnowlabs.com/api/python/reference/autosummary/sparknlp/base/light_pipeline/index.html#sparknlp.base.light_pipeline.LightPipeline.annotate) method returns a dictionary (or list of dictionary if a list is passed as input) with the results of each step in the pipeline. To retrieve all metadata from the anntoators in the result, use the method [.fullAnnotate()](https://nlp.johnsnowlabs.com/api/python/reference/autosummary/sparknlp/base/light_pipeline/index.html#sparknlp.base.light_pipeline.LightPipeline.fullAnnotate) instead, which always returns a list.\n","\n","To extract the results from the object, you just need to parse the dictionary.\n","\n","Let's use the `distilbert_base_cased_qa_squad2` model with `LightPipeline` and `.fullAnnotate()` it with sample data."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20888,"status":"ok","timestamp":1678049787386,"user":{"displayName":"Hasham Ul Haq","userId":"10508284328555930330"},"user_tz":360},"id":"yGfyD4oWt9uu","outputId":"362b7336-7ae7-4985-fcd5-40781edf41a2"},"outputs":[{"name":"stdout","output_type":"stream","text":["distilbert_base_cased_qa_squad2 download started this may take some time.\n","Approximate size to download 232.8 MB\n","[OK!]\n"]}],"source":["documentAssembler = MultiDocumentAssembler() \\\n","    .setInputCols([\"question\", \"context\"]) \\\n","    .setOutputCols([\"document_question\", \"document_context\"])\n","\n","question_answering = DistilBertForQuestionAnswering \\\n","    .pretrained(\"distilbert_base_cased_qa_squad2\", \"en\") \\\n","    .setInputCols([\"document_question\", \"document_context\"]) \\\n","    .setOutputCol(\"answer\")\\\n","    .setCaseSensitive(True) \\\n","    .setMaxSentenceLength(512)\n","\n","pipeline = Pipeline(stages=[\n","    documentAssembler,\n","    question_answering\n","    ])\n","\n","model = pipeline.fit(spark.createDataFrame([[\"\", \"\"]]).toDF(\"question\", \"context\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-EfgXhE5wOdZ"},"outputs":[],"source":["light_model= LightPipeline(model)\n","light_result= light_model.fullAnnotate(\"What type of flight decks are aircraft carriers equipped with?\" ,\"An aircraft carrier is a warship that serves as a seagoing airbase, equipped with a full-length flight deck and facilities for carrying, arming, deploying, and recovering aircraft.\")[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1678049789717,"user":{"displayName":"Hasham Ul Haq","userId":"10508284328555930330"},"user_tz":360},"id":"avwRoOJGu7cv","outputId":"b14d709f-8a30-4261-ca9d-9514347629fe"},"outputs":[{"data":{"text/plain":["{'document_question': [Annotation(document, 0, 61, What type of flight decks are aircraft carriers equipped with?, {})],\n"," 'document_context': [Annotation(document, 0, 179, An aircraft carrier is a warship that serves as a seagoing airbase, equipped with a full-length flight deck and facilities for carrying, arming, deploying, and recovering aircraft., {})],\n"," 'answer': [Annotation(chunk, 0, 12, full - length, {'chunk': '0', 'start_score': '0.8622168', 'score': '0.81347287', 'end': '33', 'start': '31', 'end_score': '0.7647289', 'sentence': '0'})]}"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["light_result"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1678049789718,"user":{"displayName":"Hasham Ul Haq","userId":"10508284328555930330"},"user_tz":360},"id":"XlQDOeeqwxIW","outputId":"813ac012-e211-4912-da2f-fd0d3fa94a7c"},"outputs":[{"data":{"text/plain":["dict_keys(['document_question', 'document_context', 'answer'])"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["light_result.keys()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ssjec4q3VJAi"},"source":["# From HuggingFace to Spark NLP"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"DO42-jcfVMqu"},"source":["Here you will learn how to export a model from HuggingFace to Spark NLP. \n","\n","For compatibility details and examples, check [this page](https://nlp.johnsnowlabs.com/docs/en/transformers#import-transformers-into-spark-nlp)."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"dgfqI9JvQSxR"},"source":["### Export and Save HuggingFace model"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"PC2CJk2qQbgD"},"source":["- Let's install `HuggingFace` and `TensorFlow`. You don't need `TensorFlow` to be installed for Spark NLP, however, we need it to load and save models from HuggingFace.\n","- We lock TensorFlow on `2.11.0` version and Transformers on `4.25.1`. This doesn't mean it won't work with the future releases, but we wanted you to know which versions have been tested successfully."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10259,"status":"ok","timestamp":1678049799967,"user":{"displayName":"Hasham Ul Haq","userId":"10508284328555930330"},"user_tz":360},"id":"CP_myt7nQTQI","outputId":"d321395e-0e08-4683-a745-bf071388bb7a"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m113.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install -q transformers==4.25.1 tensorflow==2.11.0"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"cSqk1g5rQhzq"},"source":["- HuggingFace comes with a native `saved_model` feature inside `save_pretrained` function for TensorFlow based models. We will use that to save it as TF `SavedModel`.\n","- We'll use [deepset/bert-large-uncased-whole-word-masking-squad2](https://huggingface.co/deepset/bert-large-uncased-whole-word-masking-squad2) model from HuggingFace as an example\n","- In addition to `TFBertForQuestionAnswering` we also need to save the `BertTokenizer`. This is the same for every model, these are assets needed for tokenization inside Spark NLP."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":304,"referenced_widgets":["580a4cd5cc2e4decaf8351f4a0b24ce0","6af7696a06754a1e9092a83c0ee1ff50","3d044728d5f04de3b783b6ef55a97b6d","42d27c1781a947a083d5a6b668229c7e","b15c6805128d47b79b75d15934955aef","536c498e634f4203b8c813fd740a00aa","9de4a72b7ba24dab89c2e68b376a3a90","3eaf8fc4a42a4e958d0cbf87027322f6","0095b93080a147478525f89b9a267dd5","d0e86fe8ec5f455ba0bcd85f249d3a31","acda6ffb68434e779bdc12f8bae21a57","f8c10ac7364f4b70b766bfab0b2205eb","940d3c5f2f2f4107b25478b7ee58425f","0fe4b57a3d1346a5930e77dad2b40e2e","811e28e06ac14e06b5aed876e764b48e","0e51e44a98b74da8ab18396492800d13","c6035c926b4b4a98af4fe4ac3bd7cccf","aa2ff0dde72749859618756931ba6b7e","68deb1fdd86c415baab6cc88521f0ac9","4d8f9fac658944c084a8b6147ef64cdc","aefb71b851144d59994d3b1f4ea18f87","bcefbb47fb61452a8a69c0a1ff0327ae","6f121d822fd9473bb87dd2dae1b0cbf4","9e70e076059f4330a93f4e4480d4ad3f","0295acd6f889415eba0fd1b93676f841","a2611d068b0a484fa8c93a492b2783c0","2f6e4f22e1da489d9c56b5dacff4cca8","e09de2d585f346d7b1842a7444a97a83","13fe244935464a88b24c5bf87e3b9800","dccff12f0b97468aad4e85a3c301bf76","bd3f898cc52f4d08857de21b73e783d7","8578ac6c922549c1a709d1176afffd1f","ecb11079b4d94128918186245fb5170a","eab878f9d72c4a888b0cd334b73261d5","65e8f2f902184c798e3332957567c290","690749e3a1bf4446849ca0197ac50334","57dad291acd6483291d72623af4364c6","449aac08dcf2407e9d9b5eeabb6323d2","98522097b82a417a9e6e64ec4a0d4908","52cfca4f9fbf44b781373f043e3f277c","cbc86c7e150341ee9d6a693fd93a664a","80f5314ed5ea4f51ad34b41c59ff8d2d","810a73f99b6443b98695a89e5f0629f4","f767420ae11546f3959d467c9369d1ff","8e4404276b254412a0ebcaf96444ca36","f03688cd5d8c46179b0a8fcd7800e556","97eeb513e54240d492afa9b31db1632f","70585c0868804348a2486539b8aab197","d9fd08105257473bb4f31eebffe3a50f","94081cd068ed415a9e6667069e26298c","c0feeb43d5124959b1e2d163d9373588","4d9568681cf94696a4ce43310a4a52b2","bc6164f56451497b8cad2d182e981ce7","86b4e135c32f48aaa7c5728ce8535cf2","b7bee70e44534e6db932a8259fa85768"]},"executionInfo":{"elapsed":225398,"status":"ok","timestamp":1678050025353,"user":{"displayName":"Hasham Ul Haq","userId":"10508284328555930330"},"user_tz":360},"id":"m0yh2mB_Qa6U","outputId":"358f0201-310d-4664-e99d-494a7267f551"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"580a4cd5cc2e4decaf8351f4a0b24ce0","version_major":2,"version_minor":0},"text/plain":["Downloading (‚Ä¶)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f8c10ac7364f4b70b766bfab0b2205eb","version_major":2,"version_minor":0},"text/plain":["Downloading (‚Ä¶)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6f121d822fd9473bb87dd2dae1b0cbf4","version_major":2,"version_minor":0},"text/plain":["Downloading (‚Ä¶)okenizer_config.json:   0%|          | 0.00/107 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eab878f9d72c4a888b0cd334b73261d5","version_major":2,"version_minor":0},"text/plain":["Downloading (‚Ä¶)lve/main/config.json:   0%|          | 0.00/477 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8e4404276b254412a0ebcaf96444ca36","version_major":2,"version_minor":0},"text/plain":["Downloading (‚Ä¶)\"pytorch_model.bin\";:   0%|          | 0.00/133M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["All PyTorch model weights were used when initializing TFBertForQuestionAnswering.\n","\n","All the weights of TFBertForQuestionAnswering were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForQuestionAnswering for predictions without further training.\n","WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, LayerNorm_layer_call_fn while saving (showing 5 of 416). These functions will not be directly callable after loading.\n","WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, LayerNorm_layer_call_fn while saving (showing 5 of 416). These functions will not be directly callable after loading.\n"]}],"source":["from transformers import TFBertForQuestionAnswering, BertTokenizer \n","import tensorflow as tf\n","\n","MODEL_NAME = 'deepset/minilm-uncased-squad2'\n","\n","tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n","tokenizer.save_pretrained('./{}_tokenizer/'.format(MODEL_NAME))\n","\n","try:\n","  model = TFBertForQuestionAnswering.from_pretrained(MODEL_NAME)\n","except:\n","  model = TFBertForQuestionAnswering.from_pretrained(MODEL_NAME, from_pt=True)\n","    \n","model.save_pretrained(\"./{}\".format(MODEL_NAME), saved_model=True)\n","\n","# Define TF Signature\n","@tf.function(\n","  input_signature=[\n","      {\n","          \"input_ids\": tf.TensorSpec((None, None), tf.int32, name=\"input_ids\"),\n","          \"attention_mask\": tf.TensorSpec((None, None), tf.int32, name=\"attention_mask\"),\n","          \"token_type_ids\": tf.TensorSpec((None, None), tf.int32, name=\"token_type_ids\"),\n","      }\n","  ]\n",")\n","def serving_fn(input):\n","    return model(input)\n","\n","model.save_pretrained(\"./{}\".format(MODEL_NAME), saved_model=True, signatures={\"serving_default\": serving_fn})\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"yV62Jg8mQnnM"},"source":["‚û§ Let's have a look inside these two directories and see what we are dealing with:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":132,"status":"ok","timestamp":1678050025459,"user":{"displayName":"Hasham Ul Haq","userId":"10508284328555930330"},"user_tz":360},"id":"SYVe5zcwQkzw","outputId":"a73ab888-f620-403b-f8ea-52c90a318f1d"},"outputs":[{"name":"stdout","output_type":"stream","text":["total 130028\n","-rw-r--r-- 1 root root       657 Mar  5 21:00 config.json\n","drwxr-xr-x 3 root root      4096 Mar  5 20:59 saved_model\n","-rw-r--r-- 1 root root 133136696 Mar  5 21:00 tf_model.h5\n"]}],"source":["!ls -l {MODEL_NAME}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":260,"status":"ok","timestamp":1678050025713,"user":{"displayName":"Hasham Ul Haq","userId":"10508284328555930330"},"user_tz":360},"id":"VW_6bu43Qp0d","outputId":"aa7c7524-08b3-49f5-926b-ac753f5675e6"},"outputs":[{"name":"stdout","output_type":"stream","text":["total 9112\n","drwxr-xr-x 2 root root    4096 Mar  5 20:59 assets\n","-rw-r--r-- 1 root root      55 Mar  5 21:00 fingerprint.pb\n","-rw-r--r-- 1 root root  164802 Mar  5 21:00 keras_metadata.pb\n","-rw-r--r-- 1 root root 9150273 Mar  5 21:00 saved_model.pb\n","drwxr-xr-x 2 root root    4096 Mar  5 21:00 variables\n"]}],"source":["!ls -l {MODEL_NAME}/saved_model/1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":157,"status":"ok","timestamp":1678050025868,"user":{"displayName":"Hasham Ul Haq","userId":"10508284328555930330"},"user_tz":360},"id":"mIzaIV9iQriF","outputId":"43be7ae0-c0e1-4dd6-f2f7-cfc05981bd71"},"outputs":[{"name":"stdout","output_type":"stream","text":["total 236\n","-rw-r--r-- 1 root root    125 Mar  5 20:58 special_tokens_map.json\n","-rw-r--r-- 1 root root    492 Mar  5 20:58 tokenizer_config.json\n","-rw-r--r-- 1 root root 231508 Mar  5 20:58 vocab.txt\n"]}],"source":["!ls -l {MODEL_NAME}_tokenizer"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"JovxOyjvQw98"},"source":["- As you can see, we need the SavedModel from `saved_model/1/` path\n","- We also be needing `vocab.txt` from the tokenizer\n","- All we need is to just copy the `vocab.txt` to `saved_model/1/assets` which Spark NLP will look for"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1UULsmgwQs3J"},"outputs":[],"source":["asset_path = '{}/saved_model/1/assets'.format(MODEL_NAME)\n","\n","!cp {MODEL_NAME}_tokenizer/vocab.txt {asset_path}"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"08sVBWCUQ1Sy"},"source":["‚û§ We have our `vocab.txt` inside assets directory"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":197,"status":"ok","timestamp":1678050026306,"user":{"displayName":"Hasham Ul Haq","userId":"10508284328555930330"},"user_tz":360},"id":"7MKj-OgVQzaF","outputId":"8aee064c-7917-4f95-f60b-7f3c8137e95d"},"outputs":[{"name":"stdout","output_type":"stream","text":["total 228\n","-rw-r--r-- 1 root root 231508 Mar  5 21:00 vocab.txt\n"]}],"source":["!ls -l {MODEL_NAME}/saved_model/1/assets"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"otFVMoh4Vf9b"},"source":["## Import and Save BertForQuestionAnswering in Spark NLP"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"YK9U99O4RAjL"},"source":["- Let's use `loadSavedModel` functon in `BertForQuestionAnswering` which allows us to load TensorFlow model in SavedModel format\n","- Most params can be set later when you are loading this model in `BertForQuestionAnswering` in runtime like `setMaxSentenceLength`, so don't worry what you are setting them now\n","- `loadSavedModel` accepts two params, first is the path to the TF SavedModel. The second is the SparkSession that is `spark` variable we previously started via `sparknlp.start()`\n","- NOTE: `loadSavedModel` accepts local paths in addition to distributed file systems such as `HDFS`, `S3`, `DBFS`, etc. This feature was introduced in Spark NLP 4.2.2 release. Keep in mind the best and recommended way to move/share/reuse Spark NLP models is to use `write.save` so you can use `.load()` from any file systems natively."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4OWRDcKkQ3UJ"},"outputs":[],"source":["from sparknlp.annotator import *\n","from sparknlp.base import *\n","\n","spanClassifier = BertForQuestionAnswering.loadSavedModel(\n","     '{}/saved_model/1'.format(MODEL_NAME),spark)\\\n","  .setInputCols([\"document_question\",'document_context'])\\\n","  .setOutputCol(\"answer\")\\\n","  .setCaseSensitive(False)\\\n","  .setMaxSentenceLength(512)\n","\n","  # setCaseSensitive is set to False because the model we imported is `uncased`"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"NOo3_TTPRGBW"},"source":["‚û§ Let's save it on disk so it is easier to be moved around and also be used later via `.load` function"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YYeUAeeERENW"},"outputs":[],"source":["spanClassifier.write().overwrite().save(\"./{}_spark_nlp\".format(MODEL_NAME))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"sMli98iyRNT-"},"source":["‚û§ Let's clean up stuff we don't need anymore"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aSYXyVYcRIuN"},"outputs":[],"source":["!rm -rf {MODEL_NAME}_tokenizer {MODEL_NAME}"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"EzdmgjU6RR0Q"},"source":["\n","\n","\n","Awesome üòé  !\n","\n","‚û§ This is your BertForQuestionAnswering model from HuggingFace ü§ó  loaded and saved by Spark NLP üöÄ"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":270,"status":"ok","timestamp":1678050045746,"user":{"displayName":"Hasham Ul Haq","userId":"10508284328555930330"},"user_tz":360},"id":"dsCbv72iRPhj","outputId":"e9e2efad-dd37-479b-d5ba-d8a08a605b69"},"outputs":[{"name":"stdout","output_type":"stream","text":["total 138552\n","-rw-r--r-- 1 root root 141868303 Mar  5 21:00 bert_classification_tensorflow\n","drwxr-xr-x 4 root root      4096 Mar  5 21:00 fields\n","drwxr-xr-x 2 root root      4096 Mar  5 21:00 metadata\n"]}],"source":["! ls -l {MODEL_NAME}_spark_nlp"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"mOcmg0I7RgfU"},"source":["‚û§ Now let's see how we can use it on other machines, clusters, or any place you wish to use your new and shiny BertForQuestionAnswering model in Spark NLP üöÄ pipeline! "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10597,"status":"ok","timestamp":1678050056340,"user":{"displayName":"Hasham Ul Haq","userId":"10508284328555930330"},"user_tz":360},"id":"yQ_Uwu69RewL","outputId":"ef0fff55-a2e6-4b00-f85a-ed72ab56e16e"},"outputs":[{"name":"stdout","output_type":"stream","text":["+-----------------------------------------------------------+----------+\n","|Question                                                   |Answer    |\n","+-----------------------------------------------------------+----------+\n","|The most populated city in the United States is which city?|[New York]|\n","+-----------------------------------------------------------+----------+\n","\n"]}],"source":["document_assembler = MultiDocumentAssembler() \\\n","    .setInputCols([\"question\", \"context\"]) \\\n","    .setOutputCols([\"document_question\", \"document_context\"])\n","\n","spanClassifier_loaded = BertForQuestionAnswering.load(\"./{}_spark_nlp\".format(MODEL_NAME))\\\n","  .setInputCols([\"document_question\",'document_context'])\\\n","  .setOutputCol(\"answer\")\n","\n","pipeline = Pipeline().setStages([\n","    document_assembler,\n","    spanClassifier_loaded\n","])\n","\n","example = spark.createDataFrame([[\"The most populated city in the United States is which city?\", \"New York is the most populous city in the United States and the center of the New York metropolitan area\"]]).toDF(\"question\", \"context\")\n","result = pipeline.fit(example).transform(example)\n","\n","\n","result.selectExpr(\"question as Question\", \"answer.result as Answer\").show(truncate=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"-JmP-dmVV5e3"},"source":["‚û§ Cool! You can now go wild and use hundreds of BertForQuestionAnswering models from HuggingFace ü§ó in Spark NLP üöÄ"]}],"metadata":{"colab":{"provenance":[{"file_id":"1iNYzzoUpnKq4LromhNrZCVrs9A8xxlX0","timestamp":1672692128509},{"file_id":"https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/14.Transformers_for_Token_Classification_in_Spark_NLP.ipynb","timestamp":1672124045161}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0095b93080a147478525f89b9a267dd5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0295acd6f889415eba0fd1b93676f841":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dccff12f0b97468aad4e85a3c301bf76","max":107,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bd3f898cc52f4d08857de21b73e783d7","value":107}},"0e51e44a98b74da8ab18396492800d13":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0fe4b57a3d1346a5930e77dad2b40e2e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_68deb1fdd86c415baab6cc88521f0ac9","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4d8f9fac658944c084a8b6147ef64cdc","value":112}},"13fe244935464a88b24c5bf87e3b9800":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2f6e4f22e1da489d9c56b5dacff4cca8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d044728d5f04de3b783b6ef55a97b6d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3eaf8fc4a42a4e958d0cbf87027322f6","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0095b93080a147478525f89b9a267dd5","value":231508}},"3eaf8fc4a42a4e958d0cbf87027322f6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42d27c1781a947a083d5a6b668229c7e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d0e86fe8ec5f455ba0bcd85f249d3a31","placeholder":"‚Äã","style":"IPY_MODEL_acda6ffb68434e779bdc12f8bae21a57","value":" 232k/232k [00:00&lt;00:00, 2.55MB/s]"}},"449aac08dcf2407e9d9b5eeabb6323d2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d8f9fac658944c084a8b6147ef64cdc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4d9568681cf94696a4ce43310a4a52b2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52cfca4f9fbf44b781373f043e3f277c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"536c498e634f4203b8c813fd740a00aa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57dad291acd6483291d72623af4364c6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_810a73f99b6443b98695a89e5f0629f4","placeholder":"‚Äã","style":"IPY_MODEL_f767420ae11546f3959d467c9369d1ff","value":" 477/477 [00:00&lt;00:00, 16.9kB/s]"}},"580a4cd5cc2e4decaf8351f4a0b24ce0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6af7696a06754a1e9092a83c0ee1ff50","IPY_MODEL_3d044728d5f04de3b783b6ef55a97b6d","IPY_MODEL_42d27c1781a947a083d5a6b668229c7e"],"layout":"IPY_MODEL_b15c6805128d47b79b75d15934955aef"}},"65e8f2f902184c798e3332957567c290":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_98522097b82a417a9e6e64ec4a0d4908","placeholder":"‚Äã","style":"IPY_MODEL_52cfca4f9fbf44b781373f043e3f277c","value":"Downloading (‚Ä¶)lve/main/config.json: 100%"}},"68deb1fdd86c415baab6cc88521f0ac9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"690749e3a1bf4446849ca0197ac50334":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cbc86c7e150341ee9d6a693fd93a664a","max":477,"min":0,"orientation":"horizontal","style":"IPY_MODEL_80f5314ed5ea4f51ad34b41c59ff8d2d","value":477}},"6af7696a06754a1e9092a83c0ee1ff50":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_536c498e634f4203b8c813fd740a00aa","placeholder":"‚Äã","style":"IPY_MODEL_9de4a72b7ba24dab89c2e68b376a3a90","value":"Downloading (‚Ä¶)solve/main/vocab.txt: 100%"}},"6f121d822fd9473bb87dd2dae1b0cbf4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9e70e076059f4330a93f4e4480d4ad3f","IPY_MODEL_0295acd6f889415eba0fd1b93676f841","IPY_MODEL_a2611d068b0a484fa8c93a492b2783c0"],"layout":"IPY_MODEL_2f6e4f22e1da489d9c56b5dacff4cca8"}},"70585c0868804348a2486539b8aab197":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_86b4e135c32f48aaa7c5728ce8535cf2","placeholder":"‚Äã","style":"IPY_MODEL_b7bee70e44534e6db932a8259fa85768","value":" 133M/133M [00:02&lt;00:00, 74.5MB/s]"}},"80f5314ed5ea4f51ad34b41c59ff8d2d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"810a73f99b6443b98695a89e5f0629f4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"811e28e06ac14e06b5aed876e764b48e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aefb71b851144d59994d3b1f4ea18f87","placeholder":"‚Äã","style":"IPY_MODEL_bcefbb47fb61452a8a69c0a1ff0327ae","value":" 112/112 [00:00&lt;00:00, 6.12kB/s]"}},"8578ac6c922549c1a709d1176afffd1f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86b4e135c32f48aaa7c5728ce8535cf2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e4404276b254412a0ebcaf96444ca36":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f03688cd5d8c46179b0a8fcd7800e556","IPY_MODEL_97eeb513e54240d492afa9b31db1632f","IPY_MODEL_70585c0868804348a2486539b8aab197"],"layout":"IPY_MODEL_d9fd08105257473bb4f31eebffe3a50f"}},"94081cd068ed415a9e6667069e26298c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"940d3c5f2f2f4107b25478b7ee58425f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6035c926b4b4a98af4fe4ac3bd7cccf","placeholder":"‚Äã","style":"IPY_MODEL_aa2ff0dde72749859618756931ba6b7e","value":"Downloading (‚Ä¶)cial_tokens_map.json: 100%"}},"97eeb513e54240d492afa9b31db1632f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d9568681cf94696a4ce43310a4a52b2","max":133490920,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bc6164f56451497b8cad2d182e981ce7","value":133490920}},"98522097b82a417a9e6e64ec4a0d4908":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9de4a72b7ba24dab89c2e68b376a3a90":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9e70e076059f4330a93f4e4480d4ad3f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e09de2d585f346d7b1842a7444a97a83","placeholder":"‚Äã","style":"IPY_MODEL_13fe244935464a88b24c5bf87e3b9800","value":"Downloading (‚Ä¶)okenizer_config.json: 100%"}},"a2611d068b0a484fa8c93a492b2783c0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8578ac6c922549c1a709d1176afffd1f","placeholder":"‚Äã","style":"IPY_MODEL_ecb11079b4d94128918186245fb5170a","value":" 107/107 [00:00&lt;00:00, 4.23kB/s]"}},"aa2ff0dde72749859618756931ba6b7e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"acda6ffb68434e779bdc12f8bae21a57":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aefb71b851144d59994d3b1f4ea18f87":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b15c6805128d47b79b75d15934955aef":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7bee70e44534e6db932a8259fa85768":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bc6164f56451497b8cad2d182e981ce7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bcefbb47fb61452a8a69c0a1ff0327ae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bd3f898cc52f4d08857de21b73e783d7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c0feeb43d5124959b1e2d163d9373588":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c6035c926b4b4a98af4fe4ac3bd7cccf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cbc86c7e150341ee9d6a693fd93a664a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0e86fe8ec5f455ba0bcd85f249d3a31":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9fd08105257473bb4f31eebffe3a50f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dccff12f0b97468aad4e85a3c301bf76":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e09de2d585f346d7b1842a7444a97a83":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eab878f9d72c4a888b0cd334b73261d5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_65e8f2f902184c798e3332957567c290","IPY_MODEL_690749e3a1bf4446849ca0197ac50334","IPY_MODEL_57dad291acd6483291d72623af4364c6"],"layout":"IPY_MODEL_449aac08dcf2407e9d9b5eeabb6323d2"}},"ecb11079b4d94128918186245fb5170a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f03688cd5d8c46179b0a8fcd7800e556":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_94081cd068ed415a9e6667069e26298c","placeholder":"‚Äã","style":"IPY_MODEL_c0feeb43d5124959b1e2d163d9373588","value":"Downloading (‚Ä¶)&quot;pytorch_model.bin&quot;;: 100%"}},"f767420ae11546f3959d467c9369d1ff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f8c10ac7364f4b70b766bfab0b2205eb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_940d3c5f2f2f4107b25478b7ee58425f","IPY_MODEL_0fe4b57a3d1346a5930e77dad2b40e2e","IPY_MODEL_811e28e06ac14e06b5aed876e764b48e"],"layout":"IPY_MODEL_0e51e44a98b74da8ab18396492800d13"}}}}},"nbformat":4,"nbformat_minor":0}
