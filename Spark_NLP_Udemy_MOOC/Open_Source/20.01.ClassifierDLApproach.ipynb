{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"RbV_ePo3cAGl"},"source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Open_Source/20.01.ClassifierDLApproach.ipynb)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Y0fJRpNJBslT"},"source":["# **ClassifierDLApproach**"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"W8H8FoQOOn8D"},"source":["This notebook will cover the different parameters and usages of `ClassifierDLApproach`. \n","\n","`ClassifierDLApproach` annotator provides the ability to train deep learning models that can make text classifications - assign tags or categories to text. \n","\n","\n","**üìñ Learning Objectives:**\n","\n","1. Understand how `ClassifierDLApproach` algorithm works.\n","\n","2. Understand how `ClassifierDLApproach` follows an unsupervised approach which builds upon features extracted from the text.\n","\n","3. Become comfortable using the different parameters of the annotator.\n","\n","\n","**üîó Helpful Links:**\n","\n","- Documentation : [ClassifierDL](https://nlp.johnsnowlabs.com/docs/en/annotators#classifierdl)\n","\n","- Python Docs : [ClassifierDLApproach](https://nlp.johnsnowlabs.com/api/python/reference/autosummary/sparknlp/annotator/classifier_dl/classifier_dl/index.html#sparknlp.annotator.classifier_dl.classifier_dl.ClassifierDLApproach)\n","\n","- Scala Docs : [ClassifierDLApproach](https://nlp.johnsnowlabs.com/api/com/johnsnowlabs/nlp/annotators/classifier/dl/ClassifierDLApproach.html)\n","\n","- For extended examples of usage, see the [Spark NLP Workshop repository](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/5.Text_Classification_with_ClassifierDL.ipynb).\n","\n","- For additional information, see [Text Classification in Spark NLP with Bert and Universal Sentence Encoders](https://towardsdatascience.com/text-classification-in-spark-nlp-with-bert-and-universal-sentence-encoders-e644d618ca32).\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"2smMg5mbF-Pt"},"source":["ClassifierDL architecture is discussed in the [Mining Adverse Drug Reactions from Unstructured Mediums at Scale](https://arxiv.org/abs/2201.01405) research paper.\n","\n","According to the researchers, to be able to process large volume of data, a text classification model needs to be scalable, and accurate, as it is used to filter out documents, reviews, and tweets that do not contain any indication of adverse event. To achieve this, John Snow Labs team used a Fully Connected Neural Network (FCNN) model that does not require hand-crafted features, and relies on a single embedding vector for classification.\n","\n","\n","Given the conversational nature of social media text, it is possible to\n","utilise the entire document to get efficient embeddings (with little text clipping in case of BioBERT embeddings) that are directly fed to the classifier model. Since there is only a single feature vector as input to the model, multiple embedding techniques were tested to analyse performance.\n","  "]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"aWHNYeRqPp0m"},"source":["## **üìú Background**"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"pyklitKiPvQL"},"source":["\n","`ClassifierDLApproach` is a generic multi-class text classifier trainer annotator in Spark NLP and it uses various text embeddings as an input for text classifications. The `ClassifierDL` annotator uses a deep learning model (DNNs) that is built inside TensorFlow and supports up to 100 classes.\n","\n","It is possible to train a text classifier model with Bert, Elmo, Glove and Universal Sentence Encoders in Spark NLP using the `ClassiferDLApproach` annotator.\n","\n","The model is trained and optimized for greater-than-word length text, such as sentences, phrases or short paragraphs. It is trained on a variety of data sources and a variety of tasks with the aim of dynamically accommodating a wide variety of natural language understanding tasks. The input is variable length text and the output vector dimension depends on the type of embeddings that were used during training - typically ranges from 100 to 768 dimensions. \n","\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"MRTod5xEArT2"},"source":["## **üé¨ Colab Setup**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HuLFt0OdBkuo"},"outputs":[],"source":["! pip install -q pyspark==3.1.2  spark-nlp==4.2.4"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":257},"executionInfo":{"elapsed":39641,"status":"ok","timestamp":1678803819128,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":240},"id":"URRyJvTMBtXQ","outputId":"08ed324a-6ea4-488b-91a4-2b52b2620ce2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Spark NLP version 4.2.4\n","Apache Spark version: 3.1.2\n"]},{"data":{"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://161b24ecc1a3:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.1.2</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>Spark NLP</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "],"text/plain":["<pyspark.sql.session.SparkSession at 0x7f46953e5fd0>"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["import sparknlp\n","\n","import sys\n","sys.path.append('../../')\n","\n","import sparknlp\n","\n","from sparknlp.base import LightPipeline\n","from pyspark.sql import SparkSession\n","from pyspark.ml import Pipeline\n","from pyspark.sql.functions import array_contains\n","from sparknlp.annotator import *\n","from sparknlp.common import RegexRule\n","from sparknlp.base import DocumentAssembler, Finisher\n","import pandas as pd\n","import pyspark.sql.functions as F\n","\n","spark = sparknlp.start()\n","\n","print(\"Spark NLP version\", sparknlp.version())\n","print(\"Apache Spark version:\", spark.version)\n","\n","spark"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Qvcg5itgSRrw"},"source":["## **üñ®Ô∏è Input/Output Annotation Types**"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"4OBqaXpaSYQq"},"source":["- Input: `SENTENCE EMBEDDINGS`\n","\n","- Output: `CATEGORY`"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"pJv3-Up3AvQh"},"source":["## **üîé Parameters**\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"t-CtEPIani5w"},"source":["### **`setBatchSize`**\n","\n","In deep learning, batch size refers to the number of training examples used in one iteration of gradient descent. During training, the training data is divided into batches, and each batch is fed through the neural network to compute the loss and update the weights. \n","\n","`setBatchSize` is a hyperparameter that can be tuned to achieve the best performance. Increasing the batch size can reduce the overall training time, but it may also require more memory and computational resources. Conversely, reducing the batch size may increase the training time but it can reduce the memory usage and allow the model to fit into memory.\n","\n","By default, the setBatchSize parameter is set to `64` in `ClassifierDLApproach`. This default value is suitable for small datasets, but larger datasets may require larger batch sizes for optimal performance."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"nffUUfhvno48"},"source":["### **`setLr`**\n","\n","Lr stands for **Learning Rate**. It is a hyperparameter that determines the step size at which the model weights are updated during the optimization process in model training.\n","\n","During training, the model adjusts its weights to minimize the loss function, which measures the difference between the predicted and actual labels for each input sentence. The learning rate determines the size of the weight update at each iteration. A larger learning rate results in larger weight updates, while a smaller learning rate results in smaller weight updates.\n","\n","`setLr` parameter can significantly affect the training performance and the convergence speed of the model. A learning rate that is too high can cause the model to overshoot the optimal weights and fail to converge, while a learning rate that is too low can result in slow convergence or getting stuck in a local minimum.\n","\n","The optimal value for the `setLr` parameter depends on the specific task and the characteristics of the dataset. It is often necessary to experiment with different learning rates to find the optimal value."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"bG-vRCJ9no1v"},"source":["### **`setThreshold`**\n","\n","`setThreshold` is used to set the classification probability threshold for a binary classifier.\n","\n","In text classification, a model is trained to classify input data into one of several possible classes. After training, the model will predict a probability distribution over the classes for each input data point, where the predicted probability for each class represents the model's confidence that the input data point belongs to that class.\n","\n","`setThreshold` is used to set a threshold value for the predicted probabilities. Predicted probabilities below this threshold will be considered as belonging to the negative class, while any probabilities above the threshold will be considered as belonging to the positive class. This threshold is used to convert the probability distribution output by the model into a binary classification result.\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"J4xaxMKXnoy2"},"source":["### **`setMaxEpochs`**\n","\n","`setMaxEpochs` specifies the maximum number of training epochs (iterations) to run during the training process, after which the training will stop regardless of whether the model has converged or not.\n","\n","An epoch is a complete iteration over the training data, which means that the model sees every example in the training data exactly once during that epoch. \n","\n","During training, the model parameters are updated based on the error between the predicted output and the true output for each example in the training data. As the number of epochs increases, the model has more opportunities to adjust its parameters and reduce its error on the training data.\n","\n","Setting a larger number of epochs may improve the performance of the model, but it can also increase the training time and the risk of overfitting the model to the training data. Conversely, setting a smaller number of epochs may result in a faster training time but a suboptimal model performance."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Y0nHsAQcnowF"},"source":["### **`setVerbose`**\n","\n","`setVerbose` controls the amount of information displayed during the training process. This information can include metrics such as loss, accuracy, and other performance indicators that are calculated on the training data during each epoch.\n","\n","When `setVerbose` is set to True, the training log will display more detailed information about the training process, including the loss and accuracy values for each epoch, the training time for each epoch, and other relevant metrics. \n","\n","When `setVerbose` is set to False (which is the default), the training log will be less verbose and will only display a summary of the training process, including the final accuracy value and the total training time."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"dpLAripqnosx"},"source":["### **`setEnableOutputLogs`**\n","\n","`setEnableOutputLogs` allows to enable or disable the logging of various information during the training process.\n","\n","When `setEnableOutputLogs` is `True`, the model will log information about the training progress, such as the number of epochs completed, the current loss value, and the F1 score. \n","\n","This information can be useful for monitoring the training process and evaluating the performance of the model.\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"UEDH8Vsynopi"},"source":["### **`setOutputLogsPath`**\n","\n","`setOutputLogsPath` allows to specify a path to a directory where the model will write the logs during the training process.\n","\n","When `setEnableOutputLogs` is True and `setOutputLogsPath`(\"path/to/logs\") are called, the model will log the training progress information to files in the specified directory. \n","\n","This can be useful for keeping track of the training progress of multiple models, comparing the performance of different models, and identifying potential issues or errors during the training process."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"N7e2AKkXnomm"},"source":["### **`setLabelColumn`**\n","\n","`setLabelColumn` allows to specify the name of the column in the input DataFrame that contains the labels.\n","\n","When `setLabelColumn` is called with the name of a valid column in the input DataFrame, the ClassifierDL will use the values in that column as the labels for the training data. "]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"jbsOCkyYnojT"},"source":["### **`setRandomSeed`**\n","\n","`setRandomSeed` allows to specify the random seed used by the model during training.\n","\n","When you train a model, the initialization of the model's weights and biases can have a significant impact on the model's performance. To ensure that your model's initialization is reproducible, you can set a random seed that is used by the model during training. \n","\n","By setting a random seed, you can ensure that your model is initialized in the same way each time you train it, which can help you to reproduce your results and debug any issues that you may encounter."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"_I5FE0L7qM4u"},"source":["### **`setTestDataset`**\n","\n","`setTestDataset` sets the test dataset for the model. The test dataset is a set of data that is not used during training, but is used to evaluate the performance of the model after training. \n","\n","It is important to evaluate the model on a separate test dataset to ensure that it is able to generalize well to new, unseen data."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"RrXcP2H3qMof"},"source":["### **`setValidationSplit`**\n","\n","`setValidationSplit` allows to specify the fraction of the training dataset that you want to use for validation during model training.\n","\n","`setValidationSplit` allows to split the dataset into a training set and a validation set, where the model is trained on the training set and evaluated on the validation set during each epoch of training."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"7z2G2wz1qMkM"},"source":["### **`setEvaluationLogExtended`**\n","\n","`setEvaluationLogExtended` enables or disables extended evaluation log during training.\n","\n","During training, the performance of the model is evaluated on a validation set after each epoch. By default, the evaluation log contains only basic information such as precision, recall, and F1-score. \n","\n","If `setEvaluationLogExtended` is set to True, the evaluation log will also contain additional information such as per-entity precision, recall, and F1-score."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Uu1OBRKOqMga"},"source":["### **`setConfigProtoBytes`**\n","\n","`setConfigProtoBytes` allows users to set the TensorFlow configuration proto bytes for the underlying neural network used in the model.\n","\n","The TensorFlow configuration proto bytes specify the configuration settings for the TensorFlow runtime, which can include options such as memory allocation, CPU/GPU usage, and other performance-related settings. "]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"vFON3JV0qMcB"},"source":["### **`setDropout`**\n","\n","`setDropout` controls the rate at which randomly selected neurons in the neural network are \"dropped out\" during training. Dropout is a regularization technique used in deep learning to prevent overfitting.\n","\n","A higher dropout rate will drop out more neurons and result in a more regularized model (possibility of underfitting), but it may also reduce the accuracy of the model on the training data.\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"-Z7oA4d3QCh6"},"source":["## **üíª Train a Model with ClassifierDLApproach**\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"USbjqi-eRzrJ"},"source":["`ClassifierDLApproach` is used for training a text classification model.\n","\n","First step is to load the **training** and **test** datasets."]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":2728,"status":"ok","timestamp":1678803837087,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":240},"id":"oC3cekia2XLd"},"outputs":[],"source":["! wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/data/news_category_train.csv\n","! wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/data/news_category_test.csv"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3391,"status":"ok","timestamp":1678803840473,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":240},"id":"GYQJI2hNKrhQ","outputId":"ae752970-7c75-476b-ad95-9e14d960d61f"},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------+----------------------------------------------------------------------------------------------------------------------------------+\n","|category|                                                                                                                       description|\n","+--------+----------------------------------------------------------------------------------------------------------------------------------+\n","|Business|                                              Short sellers, Wall Street's dwindling band of ultra cynics, are seeing green again.|\n","|Business| Private investment firm Carlyle Group, which has a reputation for making well timed and occasionally controversial plays in th...|\n","|Business| Soaring crude prices plus worries about the economy and the outlook for earnings are expected to hang over the stock market ne...|\n","|Business| Authorities have halted oil export flows from the main pipeline in southern Iraq after intelligence showed a rebel militia cou...|\n","|Business| Tearaway world oil prices, toppling records and straining wallets, present a new economic menace barely three months before th...|\n","|Business| Stocks ended slightly higher on Friday but stayed near lows for the year as oil prices surged past  #36;46 a barrel, offsettin...|\n","|Business| Assets of the nation's retail money market mutual funds fell by  #36;1.17 billion in the latest week to  #36;849.98 trillion, ...|\n","|Business| Retail sales bounced back a bit in July, and new claims for jobless benefits fell last week, the government said Thursday, ind...|\n","|Business|\" After earning a PH.D. in Sociology, Danny Bazil Riley started to work as the general manager at a commercial real estate firm...|\n","|Business|                                             Short sellers, Wall Street's dwindling  band of ultra cynics, are seeing green again.|\n","+--------+----------------------------------------------------------------------------------------------------------------------------------+\n","only showing top 10 rows\n","\n"]}],"source":["trainDataset_full = spark.read \\\n","      .option(\"header\", True) \\\n","      .csv(\"news_category_train.csv\")\n","\n","trainDataset_full.show(10, truncate=130)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5747,"status":"ok","timestamp":1676321671392,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":300},"id":"BBXsUa0hLLz-","outputId":"4e98c618-8669-4c58-887c-22020255f3ce"},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------+-----+\n","|category|count|\n","+--------+-----+\n","|   World|30000|\n","|Sci/Tech|30000|\n","|  Sports|30000|\n","|Business|30000|\n","+--------+-----+\n","\n"]}],"source":["trainDataset_full.groupBy('category').count().show()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ywyDxDLXSXhl"},"source":["There will be a total of **120,000** labelled rows of data for training the model.\n","\n","In order to save time, we will slice a portion of the dataset (20,000) and use it for training the models. \n","<br/>"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":233,"status":"ok","timestamp":1678803844411,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":240},"id":"tGAQq-KgG_OZ"},"outputs":[],"source":["trainDataset = trainDataset_full.limit(20000)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":749,"status":"ok","timestamp":1678803846412,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":240},"id":"D3w44vg4G_Ig","outputId":"6e83cc73-9839-4d05-efb8-f101cb632431"},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------+-----+\n","|category|count|\n","+--------+-----+\n","|Business| 4665|\n","|Sci/Tech| 5126|\n","|  Sports| 4982|\n","|   World| 5227|\n","+--------+-----+\n","\n"]}],"source":["trainDataset.groupBy('category').count().show()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"HPNKKL5SH_XM"},"source":["Now, we have a **Training Dataset** of **20,000** rows and the distribution is reasonable, although not perfect.\n","\n","<br/>"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1016,"status":"ok","timestamp":1678803852482,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":240},"id":"fACzrTDM2XC_","outputId":"0cd5a957-d770-4059-fe18-78792dc9264b"},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------+----------------------------------------------------------------------------------------------------------------------------------+\n","|category|                                                                                                                       description|\n","+--------+----------------------------------------------------------------------------------------------------------------------------------+\n","|Business|   Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.|\n","|Sci/Tech| TORONTO, Canada    A second team of rocketeers competing for the  #36;10 million Ansari X Prize, a contest for privately funde...|\n","|Sci/Tech| A company founded by a chemistry researcher at the University of Louisville won a grant to develop a method of producing bette...|\n","|Sci/Tech| It's barely dawn when Mike Fitzpatrick starts his shift with a blur of colorful maps, figures and endless charts, but already ...|\n","|Sci/Tech| Southern California's smog fighting agency went after emissions of the bovine variety Friday, adopting the nation's first rule...|\n","|Sci/Tech|                          \"The British Department for Education and Skills (DfES) recently launched a \"\"Music Manifesto\"\" campaign|\n","|Sci/Tech|\"confessed author of the Netsky and Sasser viruses, is responsible for 70 percent of virus infections in 2004, according to a s...|\n","|Sci/Tech|\\\\FOAF/LOAF  and bloom filters have a lot of interesting properties for social\\network and whitelist distribution.\\\\I think we ...|\n","|Sci/Tech|                                             \"Wiltshire Police warns about \"\"phishing\"\" after its fraud squad chief was targeted.\"|\n","|Sci/Tech|In its first two years, the UK's dedicated card fraud unit, has recovered 36,000 stolen cards and 171 arrests - and estimates i...|\n","+--------+----------------------------------------------------------------------------------------------------------------------------------+\n","only showing top 10 rows\n","\n"]}],"source":["testDataset = spark.read \\\n","      .option(\"header\", True) \\\n","      .csv(\"news_category_test.csv\")\n","\n","testDataset.show(10, truncate=130)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1318,"status":"ok","timestamp":1678803854481,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":240},"id":"W8_2x0b-LYKT","outputId":"2b3487c6-c992-4df0-e4b7-f6680d4ec04c"},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------+-----+\n","|category|count|\n","+--------+-----+\n","|   World| 1900|\n","|Sci/Tech| 1900|\n","|  Sports| 1900|\n","|Business| 1900|\n","+--------+-----+\n","\n"]}],"source":["testDataset.groupBy('category').count().show()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"rANsMZxaSkZ3"},"source":["**7600** labelled text will be used for the testing of the performance of the trained model.\n","\n","<br/>"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"wTczO_dmBOcU"},"source":["### **Pipeline Stages**"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"H0zHjPTnTg5N"},"source":["Text preprocessing has to be performed in order to prepare the text data for the model training. It is the very first step of NLP projects and some of the preprocessing steps are:\n","\n","\n","\n","- [Tokenizer](https://nlp.johnsnowlabs.com/docs/en/annotators#tokenizer): Tokenization is the process of breaking down a text into smaller units called tokens, such as words, phrases, symbols, and other elements.\n","- [Normalizer](https://nlp.johnsnowlabs.com/docs/en/annotators#normalizer): is the annotator that removes all dirty characters from text following a regex pattern and transforms words based on a provided dictionary.\n","- [StopWordsCleaner](https://nlp.johnsnowlabs.com/docs/en/annotators#stopwordscleaner): is the annotator used for the process of removing commonly used words such as \"the\", \"a\", \"an\", and \"is\" from a text in order to improve the accuracy of natural language processing algorithms.\n","- [Lemmatizer](https://nlp.johnsnowlabs.com/docs/en/annotators#lemmatizer): is the annotator that reduces words to their base form, or lemma, in order to improve the accuracy of natural language processing algorithms.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6284,"status":"ok","timestamp":1673445616540,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":300},"id":"2dJmOOiLc_ha","outputId":"1600c283-1648-496b-ad53-80f28a8e1f45"},"outputs":[{"name":"stdout","output_type":"stream","text":["lemma_antbnc download started this may take some time.\n","Approximate size to download 907.6 KB\n","[OK!]\n"]}],"source":["document_assembler = DocumentAssembler() \\\n","            .setInputCol(\"description\") \\\n","            .setOutputCol(\"document\")\n","    \n","tokenizer = Tokenizer() \\\n","            .setInputCols([\"document\"]) \\\n","            .setOutputCol(\"token\")\n","          \n","normalizer = Normalizer() \\\n","            .setInputCols([\"token\"]) \\\n","            .setOutputCol(\"normalized\")\n","\n","stopwords_cleaner = StopWordsCleaner()\\\n","            .setInputCols(\"normalized\")\\\n","            .setOutputCol(\"cleanTokens\")\\\n","            .setCaseSensitive(False)\n","\n","lemma = LemmatizerModel.pretrained('lemma_antbnc') \\\n","            .setInputCols([\"cleanTokens\"]) \\\n","            .setOutputCol(\"lemma\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"XSdsRwR5jApD"},"source":["### **Sentence Embeddings**"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"KKCyo1FRW9Br"},"source":["**Sentence Embeddings** are used for text classification because they capture the semantic meaning of a sentence, allowing for more accurate classification of text.\n","\n","The [SentenceEmbeddings](https://nlp.johnsnowlabs.com/docs/en/annotators#sentenceembeddings) annotator converts the results from WordEmbeddings by either summing up or averaging (`.setPoolingStrategy` was set to **AVERAGE** in this case) all the word embeddings in a sentence or a document."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11671,"status":"ok","timestamp":1673445654261,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":300},"id":"t3szUJvXi6gY","outputId":"e40706cf-3455-4991-a1e1-92e39dc09130"},"outputs":[{"name":"stdout","output_type":"stream","text":["glove_100d download started this may take some time.\n","Approximate size to download 145.3 MB\n","[OK!]\n"]}],"source":["glove_embeddings = WordEmbeddingsModel().pretrained() \\\n","                        .setInputCols([\"document\",'lemma'])\\\n","                        .setOutputCol(\"embeddings\")\\\n","                        .setCaseSensitive(False)\n","\n","embeddingsSentence = SentenceEmbeddings() \\\n","                        .setInputCols([\"document\", \"embeddings\"]) \\\n","                        .setOutputCol(\"sentence_embeddings\") \\\n","                        .setPoolingStrategy(\"AVERAGE\")\n","\n","classsifierdl = ClassifierDLApproach()\\\n","                        .setInputCols([\"sentence_embeddings\"])\\\n","                        .setOutputCol(\"class\")\\\n","                        .setLabelColumn(\"category\")\\\n","                        .setMaxEpochs(10)\\\n","                        .setEnableOutputLogs(True)\n","                      \n","clf_pipeline = Pipeline(\n","    stages=[\n","        document_assembler, \n","        tokenizer,\n","        normalizer,\n","        stopwords_cleaner, \n","        lemma, \n","        glove_embeddings,\n","        embeddingsSentence,\n","        classsifierdl])"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"1rrwu7ZEa00y"},"source":["### **Fit the Model**\n","\n","Next step will be fitting the training dataset to train the model:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":54613,"status":"ok","timestamp":1673445708872,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":300},"id":"E-D0S0kpi6aV","outputId":"384b3fa0-f520-42db-969b-3eb0745af0ed"},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 321 ms, sys: 43.8 ms, total: 365 ms\n","Wall time: 55.1 s\n"]}],"source":["%%time\n","clf_pipelineModel = clf_pipeline.fit(trainDataset)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"C0ZJ4_BCa9CE"},"source":["To get **information about the performance of the model**, including its accuracy and loss, we specify a folder and then observe the improvement of those metrics:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1673445708874,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":300},"id":"Y2U3a-9mi6XS","outputId":"8d0cbefc-e092-4b35-994d-27ba26032a2d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training started - epochs: 10 - learning_rate: 0.005 - batch_size: 64 - training_examples: 20000 - classes: 4\n","Epoch 0/10 - 2.69s - loss: 280.25433 - acc: 0.839994 - batches: 313\n","Epoch 1/10 - 2.35s - loss: 267.71057 - acc: 0.86653644 - batches: 313\n","Epoch 2/10 - 2.36s - loss: 267.09302 - acc: 0.87394834 - batches: 313\n","Epoch 3/10 - 2.34s - loss: 266.17636 - acc: 0.8776042 - batches: 313\n","Epoch 4/10 - 2.46s - loss: 266.2502 - acc: 0.8795573 - batches: 313\n","Epoch 5/10 - 2.39s - loss: 266.58392 - acc: 0.8816106 - batches: 313\n","Epoch 6/10 - 2.31s - loss: 266.3976 - acc: 0.88316303 - batches: 313\n","Epoch 7/10 - 2.34s - loss: 265.8325 - acc: 0.8846655 - batches: 313\n","Epoch 8/10 - 2.33s - loss: 265.06653 - acc: 0.8868189 - batches: 313\n","Epoch 9/10 - 2.27s - loss: 264.38763 - acc: 0.8883714 - batches: 313\n","\n"]}],"source":["import os\n","log_file_name = os.listdir(\"/root/annotator_logs\")[0]\n","\n","with open(\"/root/annotator_logs/\"+log_file_name, \"r\") as log_file :\n","    print(log_file.read())"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"CiWXe5O71Lhd"},"source":["üëç Using the default settings, it was possible to get a final **accuracy** value of **~ 89 %** after 10 epochs. "]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"30DELdeDbb46"},"source":["### **‚ôªÔ∏è Transform & Get Predictions**"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Fuo4SnNMbgWU"},"source":["Now, in order to check the performance of the trained model, we will get predictions on the test dataset and then observe the predictions vs. ground truths."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5QpuH5KFM1jI"},"outputs":[],"source":["preds = clf_pipelineModel.transform(testDataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2082,"status":"ok","timestamp":1673445739856,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":300},"id":"VLAoSHufmP1v","outputId":"43595650-3502-48fa-fefd-41bcd1efde47"},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------+------------------------------------------------------------------------------------------------------------------------+----------+\n","|category|                                                                                                             description|    result|\n","+--------+------------------------------------------------------------------------------------------------------------------------+----------+\n","|Business|Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Fede...|[Business]|\n","|Sci/Tech| TORONTO, Canada    A second team of rocketeers competing for the  #36;10 million Ansari X Prize, a contest for priva...|[Sci/Tech]|\n","|Sci/Tech| A company founded by a chemistry researcher at the University of Louisville won a grant to develop a method of produ...|[Sci/Tech]|\n","|Sci/Tech| It's barely dawn when Mike Fitzpatrick starts his shift with a blur of colorful maps, figures and endless charts, bu...|[Sci/Tech]|\n","|Sci/Tech| Southern California's smog fighting agency went after emissions of the bovine variety Friday, adopting the nation's ...|[Sci/Tech]|\n","|Sci/Tech|                \"The British Department for Education and Skills (DfES) recently launched a \"\"Music Manifesto\"\" campaign|[Sci/Tech]|\n","|Sci/Tech|\"confessed author of the Netsky and Sasser viruses, is responsible for 70 percent of virus infections in 2004, accord...|[Sci/Tech]|\n","|Sci/Tech|\\\\FOAF/LOAF  and bloom filters have a lot of interesting properties for social\\network and whitelist distribution.\\\\I...|[Sci/Tech]|\n","|Sci/Tech|                                   \"Wiltshire Police warns about \"\"phishing\"\" after its fraud squad chief was targeted.\"|   [World]|\n","|Sci/Tech|In its first two years, the UK's dedicated card fraud unit, has recovered 36,000 stolen cards and 171 arrests - and e...|[Sci/Tech]|\n","+--------+------------------------------------------------------------------------------------------------------------------------+----------+\n","only showing top 10 rows\n","\n"]}],"source":["preds.select('category','description',\"class.result\").show(10, truncate=120)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"YWncdds5b0Gm"},"source":["### **Test Set Evaluation**"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"8stt0bxzb4RU"},"source":["The **Classification Report** below shows the quality of predictions of the trained model. "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19517,"status":"ok","timestamp":1673445765636,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":300},"id":"UL6g6Q5nmbPc","outputId":"19725650-3f97-4130-a614-f75d23f8fb26"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","    Business       0.83      0.80      0.81      1900\n","    Sci/Tech       0.80      0.87      0.83      1900\n","      Sports       0.94      0.96      0.95      1900\n","       World       0.90      0.85      0.88      1900\n","\n","    accuracy                           0.87      7600\n","   macro avg       0.87      0.87      0.87      7600\n","weighted avg       0.87      0.87      0.87      7600\n","\n"]}],"source":["from sklearn.metrics import classification_report\n","\n","preds_df = preds.select('category','description',\"class.result\").toPandas()\n","\n","preds_df['result'] = preds_df['result'].apply(lambda x : x[0])\n","\n","print (classification_report(preds_df['category'], preds_df['result']))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1673445765643,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":300},"id":"ePIoVF6dVP_k","outputId":"32b15561-0814-41da-f287-381b985cd145"},"outputs":[{"data":{"text/plain":["{Param(parent='ClassifierDLApproach_085f6c7c0fb1', name='lazyAnnotator', doc='Whether this AnnotatorModel acts as lazy in RecursivePipelines'): False,\n"," Param(parent='ClassifierDLApproach_085f6c7c0fb1', name='maxEpochs', doc='Maximum number of epochs to train'): 10,\n"," Param(parent='ClassifierDLApproach_085f6c7c0fb1', name='lr', doc='Learning Rate'): 0.005,\n"," Param(parent='ClassifierDLApproach_085f6c7c0fb1', name='batchSize', doc='Batch size'): 64,\n"," Param(parent='ClassifierDLApproach_085f6c7c0fb1', name='dropout', doc='Dropout coefficient'): 0.5,\n"," Param(parent='ClassifierDLApproach_085f6c7c0fb1', name='enableOutputLogs', doc='Whether to use stdout in addition to Spark logs.'): True,\n"," Param(parent='ClassifierDLApproach_085f6c7c0fb1', name='evaluationLogExtended', doc='Whether logs for validation to be extended: it displays time and evaluation of each label. Default is False.'): False,\n"," Param(parent='ClassifierDLApproach_085f6c7c0fb1', name='inputCols', doc='previous annotations columns, if renamed'): ['sentence_embeddings'],\n"," Param(parent='ClassifierDLApproach_085f6c7c0fb1', name='outputCol', doc='output annotation column. can be left default.'): 'class',\n"," Param(parent='ClassifierDLApproach_085f6c7c0fb1', name='labelColumn', doc='Column with label per each token'): 'category'}"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["classsifierdl.extractParamMap()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"jxbqs3ls9XEk"},"source":["Those were the **(hyper)parameters** and the default values that the `ClassifierDLApproach`annotator can use.   \n","\n","<br/>\n","\n","Changing those values will have an impact on the accuracy of the **model** and the **time** needed to train a model.\n","\n","<br/>"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"j5WMP-3jyPyG"},"source":["## **üíª Retrain the Model with Different Parameters - 1**\n","\n","The process of retraining a deep learning model involves finding the set of weights and biases that minimize the loss function, which is a measure of how well the model is able to predict the correct output given the input data. As a result, the model's performance and metrics will improve. In practice, finding the optimal set of weights and biases can be a complex and computationally intensive process that requires many iterations.\n","\n","When we retrain a deep learning model with new parameters, we are essentially restarting this process from scratch, using a new set of weights and biases that may be better suited to the problem at hand. For example, we might adjust the learning rate, regularization parameters, or other hyperparameters of the model to improve its performance on a specific task or dataset.\n","\n","\n","Instead of the default values, we will train the model with different parameter values, in order to see the effects of them on the accuracy, loss and time spent for training.\n","\n","In this case, `setMaxEpochs` was increased to **20** and `setBatchSize` was decreased to **16**.\n","\n","\n","- `setMaxEpochs`: 20\n","- `setLr`: 0.005\n","- `setThreshold`: 0.5\n","- `setDropout`: 0.5\n","- `setBatchSize`: 16"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Q54hjG5O895x"},"source":["**Number of Epochs** is an important parameter in deep learning because they represent a single iteration of the training process. Each epoch consists of one or more batches of data, and the model is trained on each batch until the entire dataset has been seen. This allows the model to learn from the data and improve its accuracy over time.\n","\n","<br/>\n","\n","**Batch Size** determines the number of samples that will be processed at once. A larger batch size can lead to faster training times, but can also lead to overfitting if the batch size is too large. A smaller batch size can lead to slower training times, but can also lead to better generalization if the batch size is small enough.\n","\n","<br/>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"psFK43NHyIrh"},"outputs":[],"source":["classsifierdl = ClassifierDLApproach()\\\n","                        .setInputCols([\"sentence_embeddings\"])\\\n","                        .setOutputCol(\"class\")\\\n","                        .setLabelColumn(\"category\")\\\n","                        .setMaxEpochs(20)\\\n","                        .setBatchSize(16)\\\n","                        .setEnableOutputLogs(True)\n","                      \n","clf_pipeline = Pipeline(\n","    stages=[\n","        document_assembler, \n","        tokenizer,\n","        normalizer,\n","        stopwords_cleaner, \n","        lemma, \n","        glove_embeddings,\n","        embeddingsSentence,\n","        classsifierdl])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MH7ixA2H_jsX"},"outputs":[],"source":["! rm -r /root/annotator_logs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":129917,"status":"ok","timestamp":1673445909151,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":300},"id":"7PlYcwgP1tC8","outputId":"2f69347d-caa3-4f55-d145-2bdda727797f"},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 669 ms, sys: 75.4 ms, total: 744 ms\n","Wall time: 2min 9s\n"]}],"source":["%%time\n","clf_pipelineModel = clf_pipeline.fit(trainDataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1673445909153,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":300},"id":"YnzZlY2i2DZc","outputId":"5d337f28-44d9-4214-f30e-7689cb27a6a1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training started - epochs: 20 - learning_rate: 0.005 - batch_size: 16 - training_examples: 20000 - classes: 4\n","Epoch 0/20 - 5.18s - loss: 1149.0548 - acc: 0.8361 - batches: 1250\n","Epoch 1/20 - 4.99s - loss: 1109.0306 - acc: 0.8641 - batches: 1250\n","Epoch 2/20 - 5.06s - loss: 1104.7867 - acc: 0.8707 - batches: 1250\n","Epoch 3/20 - 4.90s - loss: 1095.4418 - acc: 0.87535 - batches: 1250\n","Epoch 4/20 - 4.85s - loss: 1087.351 - acc: 0.8792 - batches: 1250\n","Epoch 5/20 - 5.00s - loss: 1086.1289 - acc: 0.88185 - batches: 1250\n","Epoch 6/20 - 4.94s - loss: 1084.6163 - acc: 0.8839 - batches: 1250\n","Epoch 7/20 - 5.05s - loss: 1082.5717 - acc: 0.88675 - batches: 1250\n","Epoch 8/20 - 5.12s - loss: 1080.0668 - acc: 0.88825 - batches: 1250\n","Epoch 9/20 - 5.06s - loss: 1077.6245 - acc: 0.89045 - batches: 1250\n","Epoch 10/20 - 5.04s - loss: 1075.7123 - acc: 0.8919 - batches: 1250\n","Epoch 11/20 - 4.95s - loss: 1073.9911 - acc: 0.89315 - batches: 1250\n","Epoch 12/20 - 4.92s - loss: 1072.4154 - acc: 0.89415 - batches: 1250\n","Epoch 13/20 - 4.99s - loss: 1071.3416 - acc: 0.8954 - batches: 1250\n","Epoch 14/20 - 4.93s - loss: 1070.277 - acc: 0.89615 - batches: 1250\n","Epoch 15/20 - 4.98s - loss: 1069.3787 - acc: 0.8967 - batches: 1250\n","Epoch 16/20 - 4.87s - loss: 1068.6196 - acc: 0.89755 - batches: 1250\n","Epoch 17/20 - 5.07s - loss: 1067.6573 - acc: 0.898 - batches: 1250\n","Epoch 18/20 - 4.97s - loss: 1067.0114 - acc: 0.8985 - batches: 1250\n","Epoch 19/20 - 5.05s - loss: 1066.8962 - acc: 0.89885 - batches: 1250\n","\n"]}],"source":["import os\n","log_file_name = os.listdir(\"/root/annotator_logs\")[0]\n","\n","with open(\"/root/annotator_logs/\"+log_file_name, \"r\") as log_file :\n","    print(log_file.read())"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Sfa3OA3l2LKs"},"source":["üëç Using the new settings, it was possible to get a final **accuracy** value of **~ 90 %** after 20 epochs.\n","\n","Default parameter values produced an **accuracy** value of **89 %**.\n","\n","<br/>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y9hAc3nX2DWc"},"outputs":[],"source":["preds = clf_pipelineModel.transform(testDataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18900,"status":"ok","timestamp":1673446132442,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":300},"id":"Vi9fP_tk2DT8","outputId":"debaee56-446e-41e4-f57e-47bf56b30ba0"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","    Business       0.83      0.79      0.81      1900\n","    Sci/Tech       0.78      0.89      0.83      1900\n","      Sports       0.95      0.95      0.95      1900\n","       World       0.92      0.83      0.88      1900\n","\n","    accuracy                           0.87      7600\n","   macro avg       0.87      0.87      0.87      7600\n","weighted avg       0.87      0.87      0.87      7600\n","\n"]}],"source":["from sklearn.metrics import classification_report\n","\n","preds_df = preds.select('category','description',\"class.result\").toPandas()\n","\n","preds_df['result'] = preds_df['result'].apply(lambda x : x[0])\n","\n","print (classification_report(preds_df['category'], preds_df['result']))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"vNGVXowBzF45"},"source":["## **üíª Retrain the Model with Different Parameters - 2**\n","\n","In this training, `setMaxEpochs` and `setBatchSize` was kept to the previous value, but `setLr` was used as **0.001**.\n","\n","\n","- `setMaxEpochs`: 20\n","- `setLr`: 0.001\n","- `setThreshold`: 0.5\n","- `setDropout`: 0.5\n","- `setBatchSize`: 16"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"BiClcTw28Opn"},"source":["**Learning rate** is important in deep learning because it determines how quickly the model learns from the data. \n","\n","A higher learning rate can lead to faster training times, but can also lead to overfitting if the learning rate is too high. A lower learning rate can lead to slower training times, but can also lead to better generalization if the learning rate is low enough.\n","\n","<br/>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wnc28aNhzLN2"},"outputs":[],"source":["classsifierdl = ClassifierDLApproach()\\\n","                        .setInputCols([\"sentence_embeddings\"])\\\n","                        .setOutputCol(\"class\")\\\n","                        .setLabelColumn(\"category\")\\\n","                        .setMaxEpochs(20)\\\n","                        .setBatchSize(16)\\\n","                        .setLr(0.001)\\\n","                        .setEnableOutputLogs(True)\n","                      \n","clf_pipeline = Pipeline(\n","    stages=[\n","        document_assembler, \n","        tokenizer,\n","        normalizer,\n","        stopwords_cleaner, \n","        lemma, \n","        glove_embeddings,\n","        embeddingsSentence,\n","        classsifierdl])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"neLCCKF1Cy2-"},"outputs":[],"source":["! rm -r /root/annotator_logs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":126736,"status":"ok","timestamp":1673446264976,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":300},"id":"8Qyzg2RCzLK4","outputId":"f05f1ce0-caf9-42f1-c8e0-f9fa79438d39"},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 637 ms, sys: 87.7 ms, total: 725 ms\n","Wall time: 2min 6s\n"]}],"source":["%%time\n","clf_pipelineModel = clf_pipeline.fit(trainDataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":38,"status":"ok","timestamp":1673446264981,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":300},"id":"TmMvstzmzLIH","outputId":"6e9c4054-9f9e-4030-ce54-3aa56c710b27"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training started - epochs: 20 - learning_rate: 0.001 - batch_size: 16 - training_examples: 20000 - classes: 4\n","Epoch 0/20 - 5.05s - loss: 1130.0118 - acc: 0.8423 - batches: 1250\n","Epoch 1/20 - 4.84s - loss: 1098.1505 - acc: 0.86365 - batches: 1250\n","Epoch 2/20 - 4.81s - loss: 1092.0223 - acc: 0.86915 - batches: 1250\n","Epoch 3/20 - 4.93s - loss: 1088.7266 - acc: 0.87165 - batches: 1250\n","Epoch 4/20 - 4.85s - loss: 1086.5955 - acc: 0.8738 - batches: 1250\n","Epoch 5/20 - 4.80s - loss: 1084.9662 - acc: 0.87565 - batches: 1250\n","Epoch 6/20 - 5.04s - loss: 1083.6718 - acc: 0.8762 - batches: 1250\n","Epoch 7/20 - 4.87s - loss: 1082.6428 - acc: 0.8771 - batches: 1250\n","Epoch 8/20 - 4.81s - loss: 1081.8224 - acc: 0.8777 - batches: 1250\n","Epoch 9/20 - 4.82s - loss: 1081.1245 - acc: 0.8781 - batches: 1250\n","Epoch 10/20 - 4.87s - loss: 1080.5321 - acc: 0.8788 - batches: 1250\n","Epoch 11/20 - 4.69s - loss: 1080.0076 - acc: 0.87955 - batches: 1250\n","Epoch 12/20 - 4.75s - loss: 1079.5336 - acc: 0.8805 - batches: 1250\n","Epoch 13/20 - 4.81s - loss: 1079.1049 - acc: 0.8809 - batches: 1250\n","Epoch 14/20 - 4.86s - loss: 1078.7216 - acc: 0.8813 - batches: 1250\n","Epoch 15/20 - 4.85s - loss: 1078.3745 - acc: 0.8818 - batches: 1250\n","Epoch 16/20 - 4.79s - loss: 1078.0568 - acc: 0.8823 - batches: 1250\n","Epoch 17/20 - 4.82s - loss: 1077.7637 - acc: 0.88275 - batches: 1250\n","Epoch 18/20 - 4.86s - loss: 1077.4875 - acc: 0.88295 - batches: 1250\n","Epoch 19/20 - 4.82s - loss: 1077.2316 - acc: 0.88345 - batches: 1250\n","\n"]}],"source":["import os\n","log_file_name = os.listdir(\"/root/annotator_logs\")[0]\n","\n","with open(\"/root/annotator_logs/\"+log_file_name, \"r\") as log_file :\n","    print(log_file.read())"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"kPwdIvAxRj5A"},"source":["üëé Decreasing the `setLr` to **0.001** (default value is 0.005) caused a drop in the accuracy to **~ 88.3 %**, which was expected."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rh7VTudx5g8U"},"outputs":[],"source":["preds = clf_pipelineModel.transform(testDataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18555,"status":"ok","timestamp":1673446365101,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":300},"id":"jK-MmiwP5g4o","outputId":"8ca1def3-e641-465f-a707-c17ce3ac986e"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","    Business       0.84      0.78      0.81      1900\n","    Sci/Tech       0.79      0.87      0.83      1900\n","      Sports       0.94      0.96      0.95      1900\n","       World       0.90      0.86      0.88      1900\n","\n","    accuracy                           0.87      7600\n","   macro avg       0.87      0.87      0.87      7600\n","weighted avg       0.87      0.87      0.87      7600\n","\n"]}],"source":["from sklearn.metrics import classification_report\n","\n","preds_df = preds.select('category','description',\"class.result\").toPandas()\n","\n","preds_df['result'] = preds_df['result'].apply(lambda x : x[0])\n","\n","print (classification_report(preds_df['category'], preds_df['result']))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Q7aEnLDNmlpl"},"source":["## **üíª Retrain the Model with Bert Embeddings**"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"-moZyZoUjlP7"},"source":["**BERT** (Bidirectional Encoder Representations from Transformers) provides dense vector representations for natural language by using a deep, pre-trained neural network with the Transformer architecture.\n","\n","Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. \n","\n","\n","Reference Academic Paper: [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)\n","\n","<br/>\n","\n","Notice that `SentenceEmbeddings` annotator was used after the BertEmbeddings; because sentence embeddings capture the semantic meaning of a sentence, allowing for more accurate classification of text."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6243,"status":"ok","timestamp":1673446371336,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":300},"id":"BeVoGmOYmeoN","outputId":"04a472ef-5e35-4e97-854d-3cb5eb64b82a"},"outputs":[{"name":"stdout","output_type":"stream","text":["small_bert_L4_256 download started this may take some time.\n","Approximate size to download 40.5 MB\n","[OK!]\n"]}],"source":["document_assembler = DocumentAssembler() \\\n","                .setInputCol(\"description\") \\\n","                .setOutputCol(\"document\")\n","\n","tokenizer = Tokenizer() \\\n","                .setInputCols([\"document\"]) \\\n","                .setOutputCol(\"token\")\n","      \n","bert_embeddings = BertEmbeddings().pretrained(name='small_bert_L4_256', lang='en') \\\n","                .setInputCols([\"document\",'token'])\\\n","                .setOutputCol(\"embeddings\")\n","\n","embeddingsSentence = SentenceEmbeddings() \\\n","                .setInputCols([\"document\", \"embeddings\"]) \\\n","                .setOutputCol(\"sentence_embeddings\") \\\n","                .setPoolingStrategy(\"AVERAGE\")\n","\n","classsifierdl = ClassifierDLApproach()\\\n","                .setInputCols([\"sentence_embeddings\"])\\\n","                .setOutputCol(\"class\")\\\n","                .setLabelColumn(\"category\")\\\n","                .setMaxEpochs(10)\\\n","                .setLr(0.001)\\\n","                .setBatchSize(8)\\\n","                .setEnableOutputLogs(True)\n","                #.setOutputLogsPath('logs')\n","\n","bert_clf_pipeline = Pipeline(stages=[document_assembler,\n","                                     tokenizer,\n","                                     bert_embeddings,\n","                                     embeddingsSentence,\n","                                     classsifierdl])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IS9JrorrmpAS"},"outputs":[],"source":["! rm -r /root/annotator_logs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":394746,"status":"ok","timestamp":1673446766078,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":300},"id":"U9hb_t6UmuzK","outputId":"e288e042-6b0d-4e33-a721-626d3b54a565"},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 1.9 s, sys: 189 ms, total: 2.08 s\n","Wall time: 6min 34s\n"]}],"source":["%%time\n","bert_clf_pipelineModel = bert_clf_pipeline.fit(trainDataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":202,"status":"ok","timestamp":1673446836670,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":300},"id":"1jPrr9hMm1I3","outputId":"418c11ca-5555-429d-8c92-ff9553746ff4"},"outputs":[{"data":{"text/plain":["['ClassifierDLApproach_872276d23607.log']"]},"execution_count":57,"metadata":{},"output_type":"execute_result"}],"source":["log_files = os.listdir(\"/root/annotator_logs\")\n","log_files"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1673446838144,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":300},"id":"h0ODigwkm7bZ","outputId":"1c42c973-b9d1-49c1-fa85-3f64975dfce6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training started - epochs: 10 - learning_rate: 0.001 - batch_size: 8 - training_examples: 20000 - classes: 4\n","Epoch 0/10 - 8.79s - loss: 2284.2507 - acc: 0.8308 - batches: 2500\n","Epoch 1/10 - 8.57s - loss: 2220.583 - acc: 0.85855 - batches: 2500\n","Epoch 2/10 - 8.52s - loss: 2202.462 - acc: 0.86465 - batches: 2500\n","Epoch 3/10 - 8.53s - loss: 2191.5354 - acc: 0.8691 - batches: 2500\n","Epoch 4/10 - 8.56s - loss: 2183.644 - acc: 0.87325 - batches: 2500\n","Epoch 5/10 - 8.52s - loss: 2178.5251 - acc: 0.87545 - batches: 2500\n","Epoch 6/10 - 8.41s - loss: 2174.235 - acc: 0.8778 - batches: 2500\n","Epoch 7/10 - 8.62s - loss: 2170.365 - acc: 0.87995 - batches: 2500\n","Epoch 8/10 - 8.52s - loss: 2167.0063 - acc: 0.8816 - batches: 2500\n","Epoch 9/10 - 8.50s - loss: 2164.0303 - acc: 0.8839 - batches: 2500\n","\n"]}],"source":["log_file_name = os.listdir(\"/root/annotator_logs\")[0]\n","\n","with open(\"/root/annotator_logs/\"+log_file_name, \"r\") as log_file :\n","    print(log_file.read())"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Mzo8_2b2qUUA"},"source":["To save time, we used the [Smaller BERT embeddings](https://nlp.johnsnowlabs.com/2020/08/25/small_bert_L4_256.html), which produce 256-dimensional vectors. \n","\n","Higher-dimensional BERT models may be tried, with a substantial **increase in training time**.\n","\n","<br/>"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":64734,"status":"ok","timestamp":1673446907040,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":300},"id":"EoiypOIsm7Y5","outputId":"9cc4bf1c-88ce-4fed-eaa0-b6f67f3413cc"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","    Business       0.81      0.79      0.80      1900\n","    Sci/Tech       0.80      0.85      0.83      1900\n","      Sports       0.94      0.93      0.93      1900\n","       World       0.88      0.85      0.87      1900\n","\n","    accuracy                           0.86      7600\n","   macro avg       0.86      0.86      0.86      7600\n","weighted avg       0.86      0.86      0.86      7600\n","\n"]}],"source":["from sklearn.metrics import classification_report\n","\n","preds = bert_clf_pipelineModel.transform(testDataset)\n","\n","preds_df = preds.select('category','description',\"class.result\").toPandas()\n","\n","preds_df['result'] = preds_df['result'].apply(lambda x : x[0])\n","\n","print (classification_report(preds_df['category'], preds_df['result']))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"U-ecuBo3fY1B"},"source":["## **üíª Retrain the Model with BertSentenceEmbeddings**\n","\n","BERT sentence embeddings are a type of sentence embeddings that use a deep learning model called BERT (Bidirectional Encoder Representations from Transformers) to generate numerical vectors that represent the meaning of a sentence. These vectors can then be used as input for machine learning algorithms to classify text.\n","\n","- Documentation : [Bert Sentence Embeddings](https://nlp.johnsnowlabs.com/docs/en/transformers#bertsentenceembeddings)\n","\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17964,"status":"ok","timestamp":1678803885149,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":240},"id":"_1MY2R0GfRE0","outputId":"554c26f6-4bdc-4a96-e530-45cbc0fd2564"},"outputs":[{"name":"stdout","output_type":"stream","text":["sent_small_bert_L8_512 download started this may take some time.\n","Approximate size to download 149.1 MB\n","[OK!]\n"]}],"source":["document = DocumentAssembler()\\\n","              .setInputCol(\"description\")\\\n","              .setOutputCol(\"document\")\n","    \n","bert_cmlm = BertSentenceEmbeddings.pretrained('sent_small_bert_L8_512', 'en')\\\n","              .setInputCols([\"document\"])\\\n","              .setOutputCol(\"sentence_embeddings\")\n","\n","classsifierdl = ClassifierDLApproach()\\\n","              .setInputCols([\"sentence_embeddings\"])\\\n","              .setOutputCol(\"class\")\\\n","              .setLabelColumn(\"category\")\\\n","              .setMaxEpochs(3)\\\n","              .setBatchSize(64)\\\n","              .setEnableOutputLogs(True)\\\n","              .setLr(0.001)\n","\n","bert_cmlm_clf_pipeline = Pipeline(stages = [document,\n","                                            bert_cmlm,\n","                                            classsifierdl])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HUeeWBh2fiUN"},"outputs":[],"source":["! rm -r /root/annotator_logs"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":572606,"status":"ok","timestamp":1678804504331,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":240},"id":"2R_-80eEfiQn","outputId":"40973ff6-4737-4f04-da1a-2f128a5b0c92"},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 3.06 s, sys: 390 ms, total: 3.45 s\n","Wall time: 9min 33s\n"]}],"source":["%%time\n","bert_cmlm_pipelineModel = bert_cmlm_clf_pipeline.fit(trainDataset)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":511,"status":"ok","timestamp":1678804619294,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":240},"id":"O5UvkelTfiNI","outputId":"0a3f1536-e53f-4aa8-8425-3dfca48bc2c5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training started - epochs: 3 - learning_rate: 0.001 - batch_size: 64 - training_examples: 20000 - classes: 4\n","Epoch 0/3 - 1.82s - loss: 297.21375 - acc: 0.85026044 - batches: 313\n","Epoch 1/3 - 1.47s - loss: 284.20157 - acc: 0.87479967 - batches: 313\n","Epoch 2/3 - 1.44s - loss: 282.48975 - acc: 0.8808594 - batches: 313\n","\n"]}],"source":["log_files = os.listdir(\"/root/annotator_logs\")\n","\n","with open(\"/root/annotator_logs/\"+log_files[0], \"r\") as log_file :\n","    print(log_file.read())"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":115211,"status":"ok","timestamp":1678804744948,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":240},"id":"vxY2ANdCfiIH","outputId":"e8644857-12dd-4d50-8667-a67bad7bad95"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","    Business       0.83      0.81      0.82      1900\n","    Sci/Tech       0.82      0.87      0.85      1900\n","      Sports       0.94      0.96      0.95      1900\n","       World       0.90      0.85      0.88      1900\n","\n","    accuracy                           0.87      7600\n","   macro avg       0.87      0.87      0.87      7600\n","weighted avg       0.87      0.87      0.87      7600\n","\n"]}],"source":["from sklearn.metrics import classification_report\n","\n","preds = bert_cmlm_pipelineModel.transform(testDataset)\n","\n","preds_df = preds.select('category','description',\"class.result\").toPandas()\n","\n","preds_df['result'] = preds_df['result'].apply(lambda x : x[0])\n","\n","print (classification_report(preds_df['category'], preds_df['result']))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Yz5RsoGgf3lu"},"source":["Training with BERT Sentence Embeddings on large datasets requires some time, so we used only **3 epochs**, but still got a nice accuracy value of **87 %**."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"zxRPeNt6oB0w"},"source":["## **üíª Retrain the Model with Universal Sentence Encoder**\n","\n","The Universal Sentence Encoder encodes text into high dimensional vectors that can be used for text classification, semantic similarity, clustering and other natural language tasks.\n","\n","- Documentation : [Universal Sentence Encoder](https://nlp.johnsnowlabs.com/docs/en/transformers#universalsentenceencoder)\n","\n","- Reference Academic Paper: [Universal Sentence Encoder](https://arxiv.org/abs/1803.11175)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":53989,"status":"ok","timestamp":1676321729762,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":300},"id":"sn5S3022m7Wu","outputId":"b6cc3a56-8e1e-4dda-ae89-68430d6983b6"},"outputs":[{"name":"stdout","output_type":"stream","text":["tfhub_use_lg download started this may take some time.\n","Approximate size to download 753.3 MB\n","[OK!]\n"]}],"source":["document = DocumentAssembler()\\\n","                  .setInputCol(\"description\")\\\n","                  .setOutputCol(\"document\")\n","\n","use = UniversalSentenceEncoder.pretrained(\"tfhub_use_lg\", \"en\") \\\n","                  .setInputCols(\"document\") \\\n","                  .setOutputCol(\"sentence_embeddings\")\n","\n","classsifierdl = ClassifierDLApproach()\\\n","                  .setInputCols([\"sentence_embeddings\"])\\\n","                  .setOutputCol(\"class\")\\\n","                  .setLabelColumn(\"category\")\\\n","                  .setMaxEpochs(5)\\\n","                  .setLr(0.001)\\\n","                  .setBatchSize(16)\\\n","                  .setEnableOutputLogs(True)\n","\n","use_clf_pipeline = Pipeline(stages = [document,\n","                                      use,\n","                                      classsifierdl])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A_NY1hDcm7Tp"},"outputs":[],"source":["! rm -r /root/annotator_logs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":925587,"status":"ok","timestamp":1676322655343,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":300},"id":"sAYcG6usoNQV","outputId":"9325f826-f5aa-4c29-94e7-add6ad83ae8b"},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 5.34 s, sys: 594 ms, total: 5.93 s\n","Wall time: 15min 25s\n"]}],"source":["%%time \n","use_pipelineModel = use_clf_pipeline.fit(trainDataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":291,"status":"ok","timestamp":1676322735805,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":300},"id":"6Myd0gkNoNL1","outputId":"1a5c088f-b26b-48fd-d2c9-406e0cc29f5d"},"outputs":[{"data":{"text/plain":["['ClassifierDLApproach_138fcac69004.log']"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["log_files = os.listdir(\"/root/annotator_logs\")\n","log_files"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":190,"status":"ok","timestamp":1676322740470,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":300},"id":"UMVruXS6oNIB","outputId":"4e230bc3-aabd-46aa-d72e-03a4ca01bff3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training started - epochs: 5 - learning_rate: 0.001 - batch_size: 16 - training_examples: 20000 - classes: 4\n","Epoch 0/5 - 7.22s - loss: 1111.947 - acc: 0.86825 - batches: 1250\n","Epoch 1/5 - 6.41s - loss: 1082.4929 - acc: 0.8898 - batches: 1250\n","Epoch 2/5 - 6.73s - loss: 1078.3021 - acc: 0.8929 - batches: 1250\n","Epoch 3/5 - 6.33s - loss: 1075.4481 - acc: 0.8955 - batches: 1250\n","Epoch 4/5 - 6.62s - loss: 1073.1448 - acc: 0.897 - batches: 1250\n","\n"]}],"source":["with open(\"/root/annotator_logs/\"+log_files[0], \"r\") as log_file :\n","    print(log_file.read())"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Hyo8vpp3lHIC"},"source":["With just **5 Epochs**, a model using Universal Sentence Encoders provided an accuracy value of **~ 90 %**. \n","\n","Considering the loss value, there is still room for improvement of this model. "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":185001,"status":"ok","timestamp":1676322929522,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":300},"id":"zOFIryVrjqJe","outputId":"bfb53075-ce17-4366-eaed-b12817bbd35e"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","    Business       0.84      0.82      0.83      1900\n","    Sci/Tech       0.84      0.89      0.86      1900\n","      Sports       0.95      0.98      0.96      1900\n","       World       0.92      0.87      0.90      1900\n","\n","    accuracy                           0.89      7600\n","   macro avg       0.89      0.89      0.89      7600\n","weighted avg       0.89      0.89      0.89      7600\n","\n"]}],"source":["from sklearn.metrics import classification_report\n","\n","preds = use_pipelineModel.transform(testDataset)\n","\n","preds_df = preds.select('category','description',\"class.result\").toPandas()\n","\n","preds_df['result'] = preds_df['result'].apply(lambda x : x[0])\n","\n","print (classification_report(preds_df['category'], preds_df['result']))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Sg9ca5ioqIUE"},"source":["## **üìä Getting Predictions from  the Trained Model**\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"vbvp1zrF7GFA"},"source":["### **üî¶ Light Pipeline**\n","\n","[LightPipeline](https://nlp.johnsnowlabs.com/docs/en/concepts#using-spark-nlps-lightpipeline) is a Spark NLP specific Pipeline class equivalent to the Spark ML Pipeline. \n","\n","The difference is that its execution does not hold to Spark principles, instead it computes everything locally (but in parallel) in order to achieve **fast results** when dealing with **small amounts of data**."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tQptcEIV6R7X"},"outputs":[],"source":["light_model = LightPipeline(use_pipelineModel)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1686,"status":"ok","timestamp":1673447772103,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":300},"id":"ghcdtfu66R4J","outputId":"c78c8ce2-668b-4e66-be10-aacac2826386"},"outputs":[{"data":{"text/plain":["['Business']"]},"execution_count":66,"metadata":{},"output_type":"execute_result"}],"source":["text='''\n","Fearing the fate of Italy, the centre-right government has threatened to be merciless with those who flout tough restrictions. \n","As of Wednesday it will also include all shops being closed across Greece, with the exception of supermarkets. Banks, pharmacies, pet-stores, mobile phone stores, opticians, bakers, mini-markets, couriers and food delivery outlets are among the few that will also be allowed to remain open.\n","'''\n","result = light_model.annotate(text)\n","\n","result['class']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1673447772106,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":300},"id":"AM2fAP1S6R0_","outputId":"53f90958-4e15-4d4c-af6d-a91db39fc0ba"},"outputs":[{"data":{"text/plain":["['Sports']"]},"execution_count":67,"metadata":{},"output_type":"execute_result"}],"source":["light_model.annotate('the soccer games will be postponed.')['class']"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"TI8xyL2D7kJJ"},"source":["### **‚ôªÔ∏è Transform**\n","\n","In Spark NLP, in order to put all the steps in stages and then retrieve the results, a **pipeline** is used. \n","\n","**fit()** will fit the model to the input training instances while **transform()** will perform predictions on the testing instances, based on the learned parameters during fitting. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jRkzU11aGNkj"},"outputs":[],"source":["text_list=[\"\"\"Fearing the fate of Italy, the centre-right government has threatened to be merciless with those who flout tough restrictions.\"\"\", \n","\"\"\"As of Wednesday it will also include all shops being closed across Greece, with the exception of supermarkets. Banks, pharmacies, pet-stores, mobile phone stores, opticians, bakers, mini-markets, couriers and food delivery outlets are among the few that will also be allowed to remain open.\"\"\",\n","\"\"\"the soccer games will be postponed.\"\"\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IVfUhxz0n_zM"},"outputs":[],"source":["df = spark.createDataFrame(pd.DataFrame({'description':text_list}))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hj0WKdhRn_vY"},"outputs":[],"source":["result = use_pipelineModel.transform(df)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1673447774426,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":300},"id":"qcU2R3bSn_sQ","outputId":"9b95e602-a40b-4d46-d2a7-c0f8542c03c5"},"outputs":[{"name":"stdout","output_type":"stream","text":["+------------------------------------------------------------------------------------------------------------------------------------------------------+--------+\n","|                                                                                                                                              document|   class|\n","+------------------------------------------------------------------------------------------------------------------------------------------------------+--------+\n","|                        Fearing the fate of Italy, the centre-right government has threatened to be merciless with those who flout tough restrictions.|   World|\n","|As of Wednesday it will also include all shops being closed across Greece, with the exception of supermarkets. Banks, pharmacies, pet-stores, mobil...|Business|\n","|                                                                                                                   the soccer games will be postponed.|  Sports|\n","+------------------------------------------------------------------------------------------------------------------------------------------------------+--------+\n","\n"]}],"source":["result.select(F.explode(F.arrays_zip('document.result', 'class.result')).alias(\"cols\")) \\\n",".select(F.expr(\"cols['0']\").alias(\"document\"),\n","        F.expr(\"cols['1']\").alias(\"class\")).show(truncate=150)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"0EfMcksU2BuM"},"source":["## üíæ **Saving & Loading Back the Trained Model**\n","\n","It is possible to save the trained model locally, with the chance to load and get predictions later.\n","\n","<br/>"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":778,"status":"ok","timestamp":1673447778593,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":300},"id":"dQkbsXof2QEr","outputId":"9e06cf7f-f026-491f-a8ee-0d6283af7eb2"},"outputs":[{"data":{"text/plain":["[DocumentAssembler_69248d8ba6cc,\n"," UNIVERSAL_SENTENCE_ENCODER_5e0d8b922c74,\n"," ClassifierDLModel_0142b50a8788]"]},"execution_count":72,"metadata":{},"output_type":"execute_result"}],"source":["use_pipelineModel.stages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"18zs_8v62QA4"},"outputs":[],"source":["# Save the Model\n","use_pipelineModel.stages[2].write().overwrite().save('useClassifierDL')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1u3C2bAL2P95"},"outputs":[],"source":["# Load back the saved Model\n","Classifier_Model = ClassifierDLModel.load('useClassifierDL')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"soRXA05c2fB8"},"outputs":[],"source":["# Generate prediction Pipeline with loaded Model \n","ld_pipeline = Pipeline(stages=[document, use, Classifier_Model])\n","ld_pipeline_model = ld_pipeline.fit(spark.createDataFrame([['']]).toDF(\"description\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PrX6M9H62e_L"},"outputs":[],"source":["# Apply Model Transform to testData\n","ld_preds = ld_pipeline_model.transform(testDataset) "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":922,"status":"ok","timestamp":1673447783517,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":300},"id":"tM7EGDwe8FFy","outputId":"4876b79d-dc10-41a7-e149-b9ed186473ae"},"outputs":[{"name":"stdout","output_type":"stream","text":["+----------------------------------------------------------------------------------------------------------------------------------+--------+----------+\n","|                                                                                                                       description|category|    result|\n","+----------------------------------------------------------------------------------------------------------------------------------+--------+----------+\n","|   Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.|Business|[Business]|\n","| TORONTO, Canada    A second team of rocketeers competing for the  #36;10 million Ansari X Prize, a contest for privately funde...|Sci/Tech|[Sci/Tech]|\n","| A company founded by a chemistry researcher at the University of Louisville won a grant to develop a method of producing bette...|Sci/Tech|[Sci/Tech]|\n","| It's barely dawn when Mike Fitzpatrick starts his shift with a blur of colorful maps, figures and endless charts, but already ...|Sci/Tech|  [Sports]|\n","| Southern California's smog fighting agency went after emissions of the bovine variety Friday, adopting the nation's first rule...|Sci/Tech|[Sci/Tech]|\n","|                          \"The British Department for Education and Skills (DfES) recently launched a \"\"Music Manifesto\"\" campaign|Sci/Tech|[Sci/Tech]|\n","|\"confessed author of the Netsky and Sasser viruses, is responsible for 70 percent of virus infections in 2004, according to a s...|Sci/Tech|[Sci/Tech]|\n","|\\\\FOAF/LOAF  and bloom filters have a lot of interesting properties for social\\network and whitelist distribution.\\\\I think we ...|Sci/Tech|[Sci/Tech]|\n","|                                             \"Wiltshire Police warns about \"\"phishing\"\" after its fraud squad chief was targeted.\"|Sci/Tech|[Sci/Tech]|\n","|In its first two years, the UK's dedicated card fraud unit, has recovered 36,000 stolen cards and 171 arrests - and estimates i...|Sci/Tech|[Business]|\n","+----------------------------------------------------------------------------------------------------------------------------------+--------+----------+\n","only showing top 10 rows\n","\n"]}],"source":["ld_preds.select('description','category',\"class.result\").show(10, truncate = 130)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNN0voKp8uYA9uvxYhto1n9","machine_shape":"hm","provenance":[],"toc_visible":true},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
