{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "_UPkqyygYK3L"
   },
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Open_Source/30.01.MarianTransformer.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "kiOhdfmwYOFQ"
   },
   "source": [
    "# **MarianTransformer**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "9xWjzOICY_Qg"
   },
   "source": [
    "This notebook will cover the different parameters and usages of `MarianTransformer`. \n",
    "\n",
    "**📖 Learning Objectives:**\n",
    "\n",
    "1. Understand how to use the pre-trained `MarianTransformer` model in Spark NLP for machine translation tasks, including loading pre-trained models and configuring the translation pipeline.\n",
    "\n",
    "2. Become familiar with the parameters and options available for the `MarianTransformer` model.\n",
    "\n",
    "\n",
    "**🔗 Helpful Links:**\n",
    "\n",
    "- Documentation : [MarianTransformer](https://nlp.johnsnowlabs.com/docs/en/transformers#mariantransformer)\n",
    "\n",
    "- Python Docs : [MarianTransformer](https://nlp.johnsnowlabs.com/api/python/reference/autosummary/sparknlp/annotator/seq2seq/marian_transformer/index.html#sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer)\n",
    "\n",
    "- Scala Docs : [MarianTransformer](https://nlp.johnsnowlabs.com/api/com/johnsnowlabs/nlp/annotators/seq2seq/MarianTransformer)\n",
    "\n",
    "\n",
    "- For academic reference, see [Marian: Fast Neural Machine Translation in C++](https://aclanthology.org/P18-4020/).\n",
    "\n",
    "- For additional information, see [NMarianNMT at GitHub](https://marian-nmt.github.io/)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "MFjoBaYfwie0"
   },
   "source": [
    "## **📜 Background**\n",
    "`MarianTransformer` is an efficient, free Neural Machine Translation framework written in pure C++ with minimal dependencies. It is mainly being developed by the Microsoft Translator team. Many academic (most notably the University of Edinburgh and in the past the Adam Mickiewicz University in Poznań) and commercial contributors help with its development. `MarianTransformer` uses the models trained by MarianNMT."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "X26HwMdwf-nJ"
   },
   "source": [
    "## **🎬 Colab Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WVrizsjCWebQ",
    "outputId": "9cd7a425-e710-4092-c42d-0e572ba2fd0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.4/212.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m448.4/448.4 KB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.6/198.6 KB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "! pip install -q pyspark==3.1.2  spark-nlp==4.2.4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "qXZPtD6-CSty"
   },
   "source": [
    "## ⚒️ Setup and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "R1AJV_vigF8V",
    "outputId": "0d6b665c-874c-4a0b-8fc3-561441c522e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version 4.2.4\n",
      "Apache Spark version: 3.1.2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://3646911ccad8:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark NLP</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fa50ce1a5b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sparknlp\n",
    "\n",
    "from sparknlp.base import LightPipeline, Pipeline\n",
    "from sparknlp.base import DocumentAssembler\n",
    "from sparknlp.annotator import SentenceDetectorDLModel, MarianTransformer\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "spark = sparknlp.start()\n",
    "\n",
    "print(\"Spark NLP version\", sparknlp.version())\n",
    "print(\"Apache Spark version:\", spark.version)\n",
    "\n",
    "spark"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "mX1qzTKNgLkv"
   },
   "source": [
    "## **🖨️ Input/Output Annotation Types**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "lkY8aHzZgQ_J"
   },
   "source": [
    "- Input: `DOCUMENT`\n",
    "\n",
    "- Output: `DOCUMENT`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "1FXE50gejKTd"
   },
   "source": [
    "## **🔎Parameters**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "PCmnL1oMjVaO"
   },
   "source": [
    "- `batchSize`: Size of every batch, by default 1.\n",
    "- `langId`: The language code (e.g., \"en\", \"fr\", \"pt\",\"tr\" etc.) for the input language of multilanguage models that accepts many languages as input.(Default: \"\")\n",
    "- `configProtoBytes`: `configProto` from Tensorflow, serialized into byte array.\n",
    "- `maxInputLength`: Controls the maximum length for the tokenized input sequence (source language [SentencePieces](https://github.com/google/sentencepiece)), by default 40.\n",
    "- `maxOutputLength`: Controls the maximum length for the output sequence (target language texts), by default 40. If this parameter is smaller than `maxInputLength`, then `maxInputLength` will be used instead, meaning the the maximum output length will be the maximum value between `maxInputLength` and `maxOutputLength` parameters.  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "HzPzooElCwpf"
   },
   "source": [
    "The default model is `\"opus_mt_en_fr\"`, default language is \"xx\" (meaning multi-lingual), if no values are provided. For available pretrained models please see the [Models Hub.](https://nlp.johnsnowlabs.com/models?task=Translation&type=model&q=marian)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "9WVPlcgck9vv"
   },
   "source": [
    "### `setMaxInputLength and setMaxOutputLenght`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "QBuDmRWqhP7x"
   },
   "source": [
    "Setting the parameters to `30`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rZI62kjZgJuR",
    "outputId": "5088e865-7eb6-41b2-971c-84240b92bd79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence_detector_dl download started this may take some time.\n",
      "Approximate size to download 514.9 KB\n",
      "[OK!]\n",
      "opus_mt_en_fr download started this may take some time.\n",
      "Approximate size to download 378.7 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "documentAssembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "sentence = SentenceDetectorDLModel.pretrained(\"sentence_detector_dl\", \"xx\") \\\n",
    "    .setInputCols(\"document\") \\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "marian = MarianTransformer.pretrained() \\\n",
    "    .setInputCols(\"sentence\") \\\n",
    "    .setOutputCol(\"translation\") \\\n",
    "    .setMaxInputLength(30) \\\n",
    "    .setMaxOutputLength(30)\n",
    "    \n",
    "pipeline = Pipeline() \\\n",
    "    .setStages([\n",
    "      documentAssembler,\n",
    "      sentence,\n",
    "      marian\n",
    "    ])\n",
    "\n",
    "data = spark.createDataFrame([[\"What is the capital of France? We should know this in french.\"]]).toDF(\"text\")\n",
    "\n",
    "result = pipeline.fit(data).transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WEXITnzGopHf",
    "outputId": "f378853d-773c-4b3e-de3c-73ad33f822cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------+\n",
      "|result                               |\n",
      "+-------------------------------------+\n",
      "|Quelle est la capitale de la France ?|\n",
      "|On devrait le savoir en français.    |\n",
      "+-------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.selectExpr(\"explode(translation.result) as result\").show(truncate=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "kmqLwPkLhb72"
   },
   "source": [
    "Since the input sentences were small, the output sentences are less than 30 characters long. Limiting the length of input/output texts can speed up inference and save memory. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "w2tNFpj73i-9"
   },
   "source": [
    "**What happens when the input text is longer?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XflIftMNtB8E",
    "outputId": "2769980f-fe81-4956-cc62-85fc59955d1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence length: 147\n"
     ]
    }
   ],
   "source": [
    "french_sentence = \"\"\"La capitale française, célèbre pour ses monuments historiques, ses musées prestigieux et sa cuisine raffinée, attire des visiteurs du monde entier.\"\"\"\n",
    "print(f\"Sentence length: {len(french_sentence)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "l3AMzQJDjOog"
   },
   "source": [
    "Let's send this example to a Spark data frame and add the `DOCUMENT` annotation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "V4H_GndejBOr"
   },
   "outputs": [],
   "source": [
    "spark_df = spark.createDataFrame([[french_sentence]]).toDF(\"text\")\n",
    "\n",
    "documentAssembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "spark_df = documentAssembler.transform(spark_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "eruo3Zfrh-i4"
   },
   "source": [
    "Using a multilanguage (French being one of them) model to translate to English:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z3HpHnPetC3Y",
    "outputId": "af77ab85-003b-4ab1-971f-676127005128"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opus_mt_mul_en download started this may take some time.\n",
      "Approximate size to download 395.3 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "marian = MarianTransformer.pretrained(\"opus_mt_mul_en\", \"xx\") \\\n",
    "    .setInputCols(\"document\") \\\n",
    "    .setOutputCol(\"translation\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "68WUsjFJjxxi"
   },
   "source": [
    "Restricting input length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "stjzN08SkCBH",
    "outputId": "baf76583-11d4-443b-b718-63e25c2faf34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|result                |\n",
      "+----------------------+\n",
      "|[The French capital ,]|\n",
      "+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "marian.setMaxInputLength(10).setMaxOutputLength(200).transform(spark_df).select(\"translation.result\").show(truncate=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "kRPLKHJsBMMX"
   },
   "source": [
    "Restricting output length (input and output to the same value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lga_HxMgBLZG",
    "outputId": "d89c3af5-479d-45e7-fd3c-1430138d21d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|result                                                                                                                                        |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[The French capital, famous for its historical monuments, prestigious museums and refined cuisine, attracts visitors from all over the world.]|\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "marian.setMaxInputLength(100).setMaxOutputLength(100).transform(spark_df).select(\"translation.result\").show(truncate=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "UYn4HWISBTDD"
   },
   "source": [
    "Restricting output to lower than input doesn't change the output length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RF8b5sg3BK1Q",
    "outputId": "c814403a-84a8-4b99-a4b6-4ae254c014e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|result                                                                                                                                        |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[The French capital, famous for its historical monuments, prestigious museums and refined cuisine, attracts visitors from all over the world.]|\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "marian.setMaxInputLength(100).setMaxOutputLength(5).transform(spark_df).select(\"translation.result\").show(truncate=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "DblJ6sXde12U"
   },
   "source": [
    "<br/>\n",
    "\n",
    "We can get the parameters of the `MarianTransformer` in detail by using `extractParamMap`. We will be able to see:\n",
    "\n",
    "*   Definition of the parameter\n",
    "*   Default value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pwVjjfqIziSC",
    "outputId": "5f8f1272-22be-4c86-afb1-9c175e8b9b21"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='MARIAN_TRANSFORMER_139dd9d2ebfc', name='batchSize', doc='Size of every batch'): 1,\n",
       " Param(parent='MARIAN_TRANSFORMER_139dd9d2ebfc', name='engine', doc='Deep Learning engine used for this model'): 'tensorflow',\n",
       " Param(parent='MARIAN_TRANSFORMER_139dd9d2ebfc', name='ignoreTokenIds', doc=\"A list of token ids which are ignored in the decoder's output\"): [],\n",
       " Param(parent='MARIAN_TRANSFORMER_139dd9d2ebfc', name='langId', doc=\"Transformer's task, e.g. summarize>\"): '',\n",
       " Param(parent='MARIAN_TRANSFORMER_139dd9d2ebfc', name='lazyAnnotator', doc='Whether this AnnotatorModel acts as lazy in RecursivePipelines'): False,\n",
       " Param(parent='MARIAN_TRANSFORMER_139dd9d2ebfc', name='maxInputLength', doc='Controls the maximum length for encoder inputs (source language texts)'): 30,\n",
       " Param(parent='MARIAN_TRANSFORMER_139dd9d2ebfc', name='maxOutputLength', doc='Controls the maximum length for decoder outputs (target language texts)'): 30,\n",
       " Param(parent='MARIAN_TRANSFORMER_139dd9d2ebfc', name='inputCols', doc='previous annotations columns, if renamed'): ['sentence'],\n",
       " Param(parent='MARIAN_TRANSFORMER_139dd9d2ebfc', name='outputCol', doc='output annotation column. can be left default.'): 'translation',\n",
       " Param(parent='MARIAN_TRANSFORMER_139dd9d2ebfc', name='vocabulary', doc='Vocabulary used to encode and decode piece words generated by SentencePiece'): ['</s>',\n",
       "  '<unk>',\n",
       "  ',',\n",
       "  '.',\n",
       "  '▁the',\n",
       "  '▁de',\n",
       "  \"'\",\n",
       "  '▁of',\n",
       "  '▁la',\n",
       "  's',\n",
       "  '▁and',\n",
       "  '▁et',\n",
       "  '▁to',\n",
       "  '▁des',\n",
       "  '▁l',\n",
       "  '▁a',\n",
       "  '▁les',\n",
       "  '▁à',\n",
       "  '▁in',\n",
       "  '▁le',\n",
       "  '▁d',\n",
       "  '-',\n",
       "  '▁du',\n",
       "  '▁en',\n",
       "  '▁(',\n",
       "  \"▁'\",\n",
       "  '▁for',\n",
       "  '▁pour',\n",
       "  ')',\n",
       "  '▁que',\n",
       "  '▁on',\n",
       "  '▁dans',\n",
       "  '▁is',\n",
       "  '▁that',\n",
       "  '▁un',\n",
       "  '▁The',\n",
       "  '▁sur',\n",
       "  ':',\n",
       "  '▁une',\n",
       "  '▁au',\n",
       "  '▁par',\n",
       "  '▁-',\n",
       "  '▁with',\n",
       "  '▁est',\n",
       "  '▁qui',\n",
       "  '▁be',\n",
       "  '▁by',\n",
       "  '▁I',\n",
       "  '▁as',\n",
       "  '▁',\n",
       "  ';',\n",
       "  'e',\n",
       "  '▁are',\n",
       "  '▁pas',\n",
       "  '?',\n",
       "  '▁you',\n",
       "  '▁aux',\n",
       "  '▁or',\n",
       "  '▁\"',\n",
       "  '▁ou',\n",
       "  '▁Le',\n",
       "  '▁it',\n",
       "  '▁s',\n",
       "  'a',\n",
       "  '▁from',\n",
       "  '▁plus',\n",
       "  '▁ce',\n",
       "  '▁this',\n",
       "  '▁qu',\n",
       "  '▁was',\n",
       "  '▁sont',\n",
       "  '▁at',\n",
       "  '▁avec',\n",
       "  '▁not',\n",
       "  '/',\n",
       "  't',\n",
       "  '▁ne',\n",
       "  '▁an',\n",
       "  '▁:',\n",
       "  '▁have',\n",
       "  '▁La',\n",
       "  '▁n',\n",
       "  'est',\n",
       "  '▁Les',\n",
       "  '▁A',\n",
       "  '▁which',\n",
       "  '▁will',\n",
       "  '▁L',\n",
       "  '▁vous',\n",
       "  '▁C',\n",
       "  '▁été',\n",
       "  '▁ont',\n",
       "  '▁il',\n",
       "  'un',\n",
       "  '▁has',\n",
       "  '▁se',\n",
       "  '▁its',\n",
       "  '▁In',\n",
       "  '▁all',\n",
       "  '▁?',\n",
       "  '▁être',\n",
       "  'ing',\n",
       "  ').',\n",
       "  '▁their',\n",
       "  '▁Il',\n",
       "  '▁Commission',\n",
       "  '▁Canada',\n",
       "  'il',\n",
       "  'er',\n",
       "  '▁1',\n",
       "  '...',\n",
       "  'd',\n",
       "  'une',\n",
       "  '▁son',\n",
       "  'es',\n",
       "  '▁can',\n",
       "  '▁nous',\n",
       "  '▁your',\n",
       "  '▁been',\n",
       "  '),',\n",
       "  '▁cette',\n",
       "  '▁also',\n",
       "  'm',\n",
       "  '▁we',\n",
       "  'ed',\n",
       "  '▁leur',\n",
       "  '▁other',\n",
       "  '▁comme',\n",
       "  '▁were',\n",
       "  '▁ces',\n",
       "  '▁pays',\n",
       "  '▁Je',\n",
       "  '▁Nations',\n",
       "  'y',\n",
       "  '▁En',\n",
       "  '▁S',\n",
       "  '▁services',\n",
       "  '▁c',\n",
       "  '▁It',\n",
       "  'r',\n",
       "  '▁non',\n",
       "  '▁3',\n",
       "  'S',\n",
       "  '▁me',\n",
       "  '▁2',\n",
       "  '!',\n",
       "  '▁sa',\n",
       "  '▁more',\n",
       "  '▁fait',\n",
       "  '\"',\n",
       "  'A',\n",
       "  '▁one',\n",
       "  '▁but',\n",
       "  '▁«',\n",
       "  '▁they',\n",
       "  '▁information',\n",
       "  '▁M',\n",
       "  '▁je',\n",
       "  're',\n",
       "  '▁had',\n",
       "  '▁This',\n",
       "  '▁should',\n",
       "  'en',\n",
       "  '▁ses',\n",
       "  '▁entre',\n",
       "  '▁would',\n",
       "  'C',\n",
       "  '▁y',\n",
       "  '▁peut',\n",
       "  '▁o',\n",
       "  '▁no',\n",
       "  '▁4',\n",
       "  '▁international',\n",
       "  '▁he',\n",
       "  '▁si',\n",
       "  '▁mais',\n",
       "  '▁out',\n",
       "  '▁5',\n",
       "  '▁tout',\n",
       "  '▁his',\n",
       "  '▁D',\n",
       "  '▁développement',\n",
       "  '▁tous',\n",
       "  '▁faire',\n",
       "  '▁Conseil',\n",
       "  '▁United',\n",
       "  'on',\n",
       "  '▁10',\n",
       "  '▁B',\n",
       "  '▁who',\n",
       "  'in',\n",
       "  '▁new',\n",
       "  '▁our',\n",
       "  '▁votre',\n",
       "  '▁States',\n",
       "  '▁time',\n",
       "  '▁there',\n",
       "  '▁do',\n",
       "  '▁such',\n",
       "  '▁under',\n",
       "  '▁about',\n",
       "  '▁programme',\n",
       "  '▁may',\n",
       "  '▁deux',\n",
       "  '▁Committee',\n",
       "  '▁up',\n",
       "  '▁États',\n",
       "  '▁ainsi',\n",
       "  '▁into',\n",
       "  '▁droits',\n",
       "  '▁national',\n",
       "  'ai',\n",
       "  '▁any',\n",
       "  '▁You',\n",
       "  '▁autres',\n",
       "  '▁travail',\n",
       "  '▁work',\n",
       "  '▁European',\n",
       "  '▁these',\n",
       "  '▁leurs',\n",
       "  '▁Council',\n",
       "  '▁également',\n",
       "  'c',\n",
       "  '▁même',\n",
       "  '▁6',\n",
       "  '▁part',\n",
       "  'b',\n",
       "  '▁public',\n",
       "  '▁shall',\n",
       "  '▁bien',\n",
       "  '▁rapport',\n",
       "  '▁aussi',\n",
       "  '▁than',\n",
       "  '▁On',\n",
       "  '▁J',\n",
       "  '▁if',\n",
       "  '▁E',\n",
       "  '▁We',\n",
       "  '▁P',\n",
       "  '▁so',\n",
       "  '▁my',\n",
       "  '▁membres',\n",
       "  '▁between',\n",
       "  'ment',\n",
       "  'ly',\n",
       "  '▁place',\n",
       "  '▁only',\n",
       "  'o',\n",
       "  '▁development',\n",
       "  '▁No',\n",
       "  '▁.',\n",
       "  '▁m',\n",
       "  '▁cas',\n",
       "  'al',\n",
       "  '▁them',\n",
       "  '▁countries',\n",
       "  '▁use',\n",
       "  '▁protection',\n",
       "  '▁R',\n",
       "  'or',\n",
       "  '▁7',\n",
       "  '▁point',\n",
       "  '▁Comité',\n",
       "  'i',\n",
       "  '▁made',\n",
       "  'z',\n",
       "  '▁sous',\n",
       "  '▁T',\n",
       "  '▁8',\n",
       "  '▁session',\n",
       "  '▁what',\n",
       "  '▁two',\n",
       "  '▁service',\n",
       "  '▁people',\n",
       "  'é',\n",
       "  '▁sécurité',\n",
       "  '▁well',\n",
       "  '▁Dans',\n",
       "  '▁[',\n",
       "  '▁contre',\n",
       "  '▁must',\n",
       "  '▁15',\n",
       "  'ant',\n",
       "  '▁doit',\n",
       "  '▁dont',\n",
       "  '▁Convention',\n",
       "  '▁elle',\n",
       "  '▁some',\n",
       "  '▁when',\n",
       "  '▁those',\n",
       "  '▁18',\n",
       "  '▁!',\n",
       "  '▁report',\n",
       "  '▁first',\n",
       "  '▁sans',\n",
       "  '▁était',\n",
       "  '▁personnes',\n",
       "  '▁droit',\n",
       "  '▁support',\n",
       "  '▁question',\n",
       "  '▁>',\n",
       "  '▁%',\n",
       "  '▁years',\n",
       "  '▁conditions',\n",
       "  '▁F',\n",
       "  '▁programmes',\n",
       "  '▁social',\n",
       "  '▁30',\n",
       "  '▁20',\n",
       "  'g',\n",
       "  '▁mesures',\n",
       "  '▁où',\n",
       "  '▁9',\n",
       "  'nt',\n",
       "  '▁over',\n",
       "  '▁Pour',\n",
       "  '▁lui',\n",
       "  '▁re',\n",
       "  '▁situation',\n",
       "  '▁12',\n",
       "  '▁cours',\n",
       "  '▁through',\n",
       "  '▁possible',\n",
       "  'L',\n",
       "  '▁like',\n",
       "  '▁projet',\n",
       "  '▁Nous',\n",
       "  '▁rights',\n",
       "  ']',\n",
       "  '▁per',\n",
       "  '▁important',\n",
       "  '2',\n",
       "  '▁partie',\n",
       "  '▁De',\n",
       "  'B',\n",
       "  '▁Ce',\n",
       "  '▁including',\n",
       "  'th',\n",
       "  '▁system',\n",
       "  '▁plan',\n",
       "  '▁know',\n",
       "  '▁questions',\n",
       "  '▁–',\n",
       "  '▁He',\n",
       "  '▁Vous',\n",
       "  '▁soit',\n",
       "  '▁where',\n",
       "  '▁year',\n",
       "  '▁activités',\n",
       "  '▁right',\n",
       "  '▁Si',\n",
       "  '▁j',\n",
       "  'le',\n",
       "  '▁Unies',\n",
       "  '▁need',\n",
       "  '▁mise',\n",
       "  '▁compte',\n",
       "  '▁p',\n",
       "  'à',\n",
       "  '▁G',\n",
       "  '▁général',\n",
       "  '▁cadre',\n",
       "  'autres',\n",
       "  '▁toutes',\n",
       "  'n',\n",
       "  '▁number',\n",
       "  '▁très',\n",
       "  'E',\n",
       "  '▁us',\n",
       "  '▁système',\n",
       "  '▁jour',\n",
       "  '▁notre',\n",
       "  '▁données',\n",
       "  '▁could',\n",
       "  '▁afin',\n",
       "  '▁Un',\n",
       "  'l',\n",
       "  '▁parties',\n",
       "  '▁her',\n",
       "  '▁—',\n",
       "  '▁take',\n",
       "  'D',\n",
       "  '▁ans',\n",
       "  '▁b',\n",
       "  '▁nombre',\n",
       "  '▁N',\n",
       "  '▁For',\n",
       "  '▁tu',\n",
       "  '▁peuvent',\n",
       "  '▁order',\n",
       "  '▁produits',\n",
       "  '▁moins',\n",
       "  '▁Member',\n",
       "  '▁enfants',\n",
       "  '▁santé',\n",
       "  'ait',\n",
       "  '▁femmes',\n",
       "  '▁within',\n",
       "  '▁temps',\n",
       "  '▁make',\n",
       "  'h',\n",
       "  '(',\n",
       "  '▁&',\n",
       "  '▁used',\n",
       "  '▁concernant',\n",
       "  '▁And',\n",
       "  '▁11',\n",
       "  '▁State',\n",
       "  '▁human',\n",
       "  '▁long',\n",
       "  '▁À',\n",
       "  '▁most',\n",
       "  'ci',\n",
       "  '▁matière',\n",
       "  '▁site',\n",
       "  '▁article',\n",
       "  '▁»',\n",
       "  '▁application',\n",
       "  '▁ils',\n",
       "  '▁Et',\n",
       "  '▁very',\n",
       "  '▁base',\n",
       "  '▁politique',\n",
       "  '▁avait',\n",
       "  '▁just',\n",
       "  '▁activities',\n",
       "  'article',\n",
       "  '▁Mr',\n",
       "  '▁notamment',\n",
       "  'ce',\n",
       "  '▁What',\n",
       "  'elle',\n",
       "  '▁niveau',\n",
       "  '▁As',\n",
       "  '▁demande',\n",
       "  '▁efforts',\n",
       "  '▁General',\n",
       "  '▁après',\n",
       "  '▁production',\n",
       "  '▁sera',\n",
       "  '▁following',\n",
       "  '▁14',\n",
       "  '▁action',\n",
       "  '▁If',\n",
       "  '▁him',\n",
       "  '▁vie',\n",
       "  'ation',\n",
       "  '▁fois',\n",
       "  '▁women',\n",
       "  '▁being',\n",
       "  '▁Article',\n",
       "  '▁against',\n",
       "  '▁H',\n",
       "  '▁now',\n",
       "  '▁toute',\n",
       "  '▁européenne',\n",
       "  '▁16',\n",
       "  '▁after',\n",
       "  '▁13',\n",
       "  '▁provide',\n",
       "  '▁paragraphe',\n",
       "  '▁V',\n",
       "  '▁date',\n",
       "  '▁ça',\n",
       "  '▁country',\n",
       "  '▁17',\n",
       "  '▁gestion',\n",
       "  '▁children',\n",
       "  'P',\n",
       "  '▁Une',\n",
       "  '▁avant',\n",
       "  '▁each',\n",
       "  '▁respect',\n",
       "  '▁measures',\n",
       "  '▁doivent',\n",
       "  '▁during',\n",
       "  '▁same',\n",
       "  'll',\n",
       "  '▁document',\n",
       "  '▁here',\n",
       "  '▁population',\n",
       "  '▁encore',\n",
       "  '▁many',\n",
       "  'f',\n",
       "  '▁e',\n",
       "  '▁générale',\n",
       "  '▁recherche',\n",
       "  '▁before',\n",
       "  '▁To',\n",
       "  'ils',\n",
       "  '▁health',\n",
       "  '▁Tu',\n",
       "  '▁t',\n",
       "  '▁avoir',\n",
       "  '▁available',\n",
       "  '▁autre',\n",
       "  '▁Au',\n",
       "  '▁cet',\n",
       "  '▁vue',\n",
       "  '▁data',\n",
       "  'an',\n",
       "  'être',\n",
       "  '▁économique',\n",
       "  '▁politiques',\n",
       "  '▁Europe',\n",
       "  '▁mon',\n",
       "  '▁way',\n",
       "  '▁monde',\n",
       "  '▁Elle',\n",
       "  '▁process',\n",
       "  '▁Government',\n",
       "  'de',\n",
       "  '▁total',\n",
       "  '▁law',\n",
       "  'able',\n",
       "  '▁ressources',\n",
       "  '▁25',\n",
       "  've',\n",
       "  '▁level',\n",
       "  '▁formation',\n",
       "  '▁provided',\n",
       "  '▁chaque',\n",
       "  '▁world',\n",
       "  '▁institutions',\n",
       "  '▁dit',\n",
       "  '▁policy',\n",
       "  '▁K',\n",
       "  '▁car',\n",
       "  '▁case',\n",
       "  'p',\n",
       "  '▁Cette',\n",
       "  '▁don',\n",
       "  'T',\n",
       "  '▁both',\n",
       "  '▁economic',\n",
       "  '▁_',\n",
       "  '▁International',\n",
       "  '▁19',\n",
       "  '.\"',\n",
       "  'ont',\n",
       "  '▁depuis',\n",
       "  '▁how',\n",
       "  '▁type',\n",
       "  '▁lieu',\n",
       "  '▁three',\n",
       "  '▁set',\n",
       "  '▁Union',\n",
       "  '▁trois',\n",
       "  '1',\n",
       "  '▁said',\n",
       "  'F',\n",
       "  '▁period',\n",
       "  '▁get',\n",
       "  '▁décision',\n",
       "  '▁implementation',\n",
       "  '▁Canadian',\n",
       "  '▁<',\n",
       "  '▁France',\n",
       "  '▁suis',\n",
       "  'M',\n",
       "  '▁There',\n",
       "  'I',\n",
       "  '▁nos',\n",
       "  '▁personnel',\n",
       "  '▁24',\n",
       "  '▁règlement',\n",
       "  '▁financial',\n",
       "  'it',\n",
       "  '▁because',\n",
       "  '▁loi',\n",
       "  '▁particular',\n",
       "  '▁meeting',\n",
       "  '▁processus',\n",
       "  'ons',\n",
       "  '▁ensure',\n",
       "  '▁internationale',\n",
       "  '▁area',\n",
       "  '▁Par',\n",
       "  '▁gouvernement',\n",
       "  '▁see',\n",
       "  '▁participation',\n",
       "  '▁good',\n",
       "  '▁Des',\n",
       "  '▁/',\n",
       "  'au',\n",
       "  'H',\n",
       "  '▁Programme',\n",
       "  '▁management',\n",
       "  '▁certain',\n",
       "  '▁ma',\n",
       "  'ez',\n",
       "  '▁then',\n",
       "  '▁did',\n",
       "  '▁That',\n",
       "  '▁resolution',\n",
       "  '▁members',\n",
       "  '▁New',\n",
       "  'et',\n",
       "  '▁donc',\n",
       "  '▁she',\n",
       "  '▁résolution',\n",
       "  '▁budget',\n",
       "  '3',\n",
       "  '▁marché',\n",
       "  '▁transport',\n",
       "  '▁selon',\n",
       "  '▁without',\n",
       "  'ent',\n",
       "  '▁high',\n",
       "  '▁local',\n",
       "  '▁coopération',\n",
       "  '▁fin',\n",
       "  'G',\n",
       "  '▁day',\n",
       "  '▁pendant',\n",
       "  'information',\n",
       "  '▁They',\n",
       "  'ur',\n",
       "  '▁assistance',\n",
       "  '▁Assembly',\n",
       "  '▁secteur',\n",
       "  '▁continue',\n",
       "  '▁issues',\n",
       "  'x',\n",
       "  '▁période',\n",
       "  '▁21',\n",
       "  '▁jusqu',\n",
       "  '▁But',\n",
       "  '▁products',\n",
       "  '▁documents',\n",
       "  '▁Community',\n",
       "  '▁go',\n",
       "  '▁life',\n",
       "  '▁areas',\n",
       "  'ca',\n",
       "  'R',\n",
       "  '▁prendre',\n",
       "  '▁résultats',\n",
       "  '▁further',\n",
       "  '▁want',\n",
       "  '▁Act',\n",
       "  '▁informations',\n",
       "  '▁training',\n",
       "  '▁main',\n",
       "  '▁groupe',\n",
       "  '▁At',\n",
       "  '▁All',\n",
       "  '▁page',\n",
       "  '▁31',\n",
       "  '▁access',\n",
       "  '▁even',\n",
       "  '▁decision',\n",
       "  '▁plusieurs',\n",
       "  '▁mesure',\n",
       "  '▁titre',\n",
       "  '▁années',\n",
       "  '▁market',\n",
       "  'N',\n",
       "  '▁personne',\n",
       "  '▁security',\n",
       "  '▁Re',\n",
       "  '▁mois',\n",
       "  '▁présent',\n",
       "  '▁000',\n",
       "  '▁does',\n",
       "  '▁ceux',\n",
       "  '▁nouveau',\n",
       "  '▁help',\n",
       "  '▁position',\n",
       "  '▁section',\n",
       "  'as',\n",
       "  '▁since',\n",
       "  '▁Ces',\n",
       "  'com',\n",
       "  '▁organisations',\n",
       "  '▁particulier',\n",
       "  '▁EU',\n",
       "  '▁première',\n",
       "  '▁dollars',\n",
       "  '▁Mais',\n",
       "  '▁compris',\n",
       "  '▁different',\n",
       "  'vous',\n",
       "  '▁Groupe',\n",
       "  '▁resources',\n",
       "  'us',\n",
       "  '▁façon',\n",
       "  'to',\n",
       "  '▁taken',\n",
       "  '▁nom',\n",
       "  '▁government',\n",
       "  '▁million',\n",
       "  '▁...',\n",
       "  '▁certains',\n",
       "  '▁large',\n",
       "  '▁mettre',\n",
       "  '▁qualité',\n",
       "  '▁devrait',\n",
       "  '▁premier',\n",
       "  '▁cent',\n",
       "  '▁homme',\n",
       "  '▁22',\n",
       "  '▁inter',\n",
       "  '▁end',\n",
       "  'eau',\n",
       "  '▁last',\n",
       "  '▁prix',\n",
       "  'Union',\n",
       "  '▁O',\n",
       "  '▁vers',\n",
       "  '▁dispositions',\n",
       "  '▁note',\n",
       "  '▁tant',\n",
       "  '▁change',\n",
       "  '▁domaine',\n",
       "  '▁projets',\n",
       "  '▁vos',\n",
       "  '▁back',\n",
       "  '▁Development',\n",
       "  '▁entreprises',\n",
       "  'k',\n",
       "  '▁toujours',\n",
       "  '▁exemple',\n",
       "  '▁project',\n",
       "  '▁December',\n",
       "  '▁société',\n",
       "  '▁moment',\n",
       "  '▁cooperation',\n",
       "  '▁23',\n",
       "  '▁peu',\n",
       "  '▁savoir',\n",
       "  '▁based',\n",
       "  '▁relevant',\n",
       "  '▁lors',\n",
       "  '▁Président',\n",
       "  '▁jours',\n",
       "  '▁étaient',\n",
       "  '▁manière',\n",
       "  'age',\n",
       "  '▁50',\n",
       "  '▁va',\n",
       "  '▁Group',\n",
       "  '▁produit',\n",
       "  '▁conformément',\n",
       "  '▁force',\n",
       "  ');',\n",
       "  'up',\n",
       "  '▁0',\n",
       "  '▁research',\n",
       "  '▁Centre',\n",
       "  '▁working',\n",
       "  'K',\n",
       "  '▁So',\n",
       "  '▁nature',\n",
       "  '▁déjà',\n",
       "  '▁œuvre',\n",
       "  'ra',\n",
       "  '▁necessary',\n",
       "  '▁décembre',\n",
       "  '▁own',\n",
       "  '▁view',\n",
       "  '▁down',\n",
       "  '▁paragraph',\n",
       "  '▁II',\n",
       "  'General',\n",
       "  '▁Secretary',\n",
       "  '\".',\n",
       "  '▁contrôle',\n",
       "  '▁grande',\n",
       "  '▁ici',\n",
       "  '▁avons',\n",
       "  '▁President',\n",
       "  'ne',\n",
       "  '▁millions',\n",
       "  'la',\n",
       "  '▁€',\n",
       "  'the',\n",
       "  '▁ci',\n",
       "  'V',\n",
       "  '▁;',\n",
       "  '▁police',\n",
       "  '▁regard',\n",
       "  '▁mis',\n",
       "  '▁points',\n",
       "  '▁nouvelle',\n",
       "  '▁education',\n",
       "  '▁présente',\n",
       "  '▁second',\n",
       "  '▁Regulation',\n",
       "  '▁communication',\n",
       "  '▁National',\n",
       "  '▁while',\n",
       "  'ic',\n",
       "  '▁Ils',\n",
       "  'ers',\n",
       "  '▁État',\n",
       "  '▁Republic',\n",
       "  '▁general',\n",
       "  '▁organizations',\n",
       "  '▁regional',\n",
       "  '▁group',\n",
       "  '▁required',\n",
       "  '▁violence',\n",
       "  '▁water',\n",
       "  '▁justice',\n",
       "  'EC',\n",
       "  '▁co',\n",
       "  '▁faut',\n",
       "  '»',\n",
       "  '▁community',\n",
       "  '▁seulement',\n",
       "  '▁concerne',\n",
       "  '▁legal',\n",
       "  '▁taux',\n",
       "  '▁seront',\n",
       "  '▁paix',\n",
       "  'aient',\n",
       "  '_',\n",
       "  '▁June',\n",
       "  '▁basis',\n",
       "  '▁région',\n",
       "  '▁européen',\n",
       "  '▁Secrétaire',\n",
       "  '▁cela',\n",
       "  '▁accordance',\n",
       "  '▁moi',\n",
       "  '▁100',\n",
       "  '▁full',\n",
       "  '▁nouvelles',\n",
       "  '▁Office',\n",
       "  '▁1.',\n",
       "  '▁DE',\n",
       "  '▁grand',\n",
       "  '▁person',\n",
       "  '▁special',\n",
       "  '▁still',\n",
       "  '▁2006',\n",
       "  '▁business',\n",
       "  '▁think',\n",
       "  'O',\n",
       "  '▁means',\n",
       "  '▁present',\n",
       "  '▁future',\n",
       "  '▁rôle',\n",
       "  '▁account',\n",
       "  '▁chez',\n",
       "  '▁28',\n",
       "  '▁These',\n",
       "  '▁27',\n",
       "  '▁alors',\n",
       "  'W',\n",
       "  '▁besoin',\n",
       "  '▁given',\n",
       "  '▁travaux',\n",
       "  '▁Conference',\n",
       "  '▁suite',\n",
       "  '▁However',\n",
       "  '▁objectifs',\n",
       "  '▁centre',\n",
       "  'les',\n",
       "  '▁political',\n",
       "  '▁juin',\n",
       "  '▁days',\n",
       "  '▁ligne',\n",
       "  'ou',\n",
       "  '▁review',\n",
       "  '▁among',\n",
       "  '▁avez',\n",
       "  '▁specific',\n",
       "  '▁held',\n",
       "  '▁--',\n",
       "  '▁eu',\n",
       "  '▁God',\n",
       "  '▁effective',\n",
       "  '▁h',\n",
       "  '▁adopted',\n",
       "  '▁2005',\n",
       "  '▁best',\n",
       "  '▁26',\n",
       "  '©',\n",
       "  '▁include',\n",
       "  '▁free',\n",
       "  '▁Parties',\n",
       "  'man',\n",
       "  '▁May',\n",
       "  '▁persons',\n",
       "  '▁come',\n",
       "  '▁te',\n",
       "  '▁ayant',\n",
       "  '▁2007',\n",
       "  '▁much',\n",
       "  '▁elles',\n",
       "  '▁renseignements',\n",
       "  '▁voir',\n",
       "  'ie',\n",
       "  '▁needs',\n",
       "  'CE',\n",
       "  '▁trade',\n",
       "  '▁Bureau',\n",
       "  '▁results',\n",
       "  'is',\n",
       "  '▁celui',\n",
       "  '▁Service',\n",
       "  '▁form',\n",
       "  '▁requirements',\n",
       "  '▁actions',\n",
       "  '▁ré',\n",
       "  '▁find',\n",
       "  '▁role',\n",
       "  'The',\n",
       "  '▁cause',\n",
       "  '▁République',\n",
       "  '▁appropriate',\n",
       "  '▁control',\n",
       "  '▁dire',\n",
       "  '▁laquelle',\n",
       "  '▁Rights',\n",
       "  '▁sector',\n",
       "  '▁cases',\n",
       "  '▁relatives',\n",
       "  '▁importance',\n",
       "  '▁related',\n",
       "  '▁groupes',\n",
       "  '▁Security',\n",
       "  '▁beaucoup',\n",
       "  '▁problèmes',\n",
       "  '▁soient',\n",
       "  '▁année',\n",
       "  '▁found',\n",
       "  '▁partir',\n",
       "  '▁nationale',\n",
       "  '▁W',\n",
       "  '▁With',\n",
       "  '▁small',\n",
       "  '▁family',\n",
       "  '▁An',\n",
       "  '▁effet',\n",
       "  '▁1,',\n",
       "  '▁party',\n",
       "  '▁draft',\n",
       "  '▁man',\n",
       "  '▁face',\n",
       "  '▁increase',\n",
       "  '▁example',\n",
       "  '▁established',\n",
       "  '▁2004',\n",
       "  '▁give',\n",
       "  '▁Services',\n",
       "  'J',\n",
       "  '▁raison',\n",
       "  '▁nouveaux',\n",
       "  '▁quelques',\n",
       "  '▁fonction',\n",
       "  '▁là',\n",
       "  '▁g',\n",
       "  '▁discrimination',\n",
       "  '▁Board',\n",
       "  '▁Human',\n",
       "  '▁promotion',\n",
       "  'UE',\n",
       "  '▁pourrait',\n",
       "  '▁coordination',\n",
       "  '▁ex',\n",
       "  '▁every',\n",
       "  '\",',\n",
       "  '▁visant',\n",
       "  'était',\n",
       "  '▁issue',\n",
       "  '▁provisions',\n",
       "  '▁impact',\n",
       "  'at',\n",
       "  '▁contact',\n",
       "  '▁heures',\n",
       "  'v',\n",
       "  '▁quality',\n",
       "  '▁outre',\n",
       "  '°',\n",
       "  '▁29',\n",
       "  '▁traitement',\n",
       "  '▁six',\n",
       "  '▁July',\n",
       "  '▁Dieu',\n",
       "  '▁initiatives',\n",
       "  '▁staff',\n",
       "  '▁40',\n",
       "  'ion',\n",
       "  '▁i',\n",
       "  '▁$',\n",
       "  '▁ni',\n",
       "  '▁Court',\n",
       "  '▁authorities',\n",
       "  '▁better',\n",
       "  '▁2.',\n",
       "  '▁whether',\n",
       "  'homme',\n",
       "  '▁She',\n",
       "  '▁U',\n",
       "  '▁besoins',\n",
       "  '▁March',\n",
       "  '▁World',\n",
       "  ...]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marian.extractParamMap()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "KXUQa58BgeXK"
   },
   "source": [
    "### `setLangId`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "DL7AwT7zxlWL"
   },
   "source": [
    "We use this parameter to inform the multilanguage model which language we are using as input. Let's use `tr` (Turkish) as an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lJ9VvidQholQ",
    "outputId": "5eb6371d-c545-4673-ecfe-559ca15b28f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence_detector_dl download started this may take some time.\n",
      "Approximate size to download 514.9 KB\n",
      "[OK!]\n",
      "opus_mt_mul_en download started this may take some time.\n",
      "Approximate size to download 395.3 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "documentAssembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "sentence = SentenceDetectorDLModel.pretrained(\"sentence_detector_dl\", \"xx\") \\\n",
    "    .setInputCols(\"document\") \\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "marian = MarianTransformer.pretrained(\"opus_mt_mul_en\", \"xx\") \\\n",
    "    .setInputCols([\"sentence\"]) \\\n",
    "    .setOutputCol(\"translation\") \\\n",
    "    .setLangId(\"tr\") \n",
    "        \n",
    "pipeline = Pipeline() \\\n",
    "    .setStages([\n",
    "      documentAssembler,\n",
    "      sentence,\n",
    "      marian\n",
    "    ])\n",
    "\n",
    "data = spark.createDataFrame([[\"Bu adam 50 yaşında ve çok çalışkan\"]]).toDF(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RitNCd7h_EgN",
    "outputId": "dc4bb2d5-08d4-4bef-e385-657565828709"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------+\n",
      "|result                                         |\n",
      "+-----------------------------------------------+\n",
      "|This guy is 50 years old and working very hard.|\n",
      "+-----------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = pipeline.fit(data).transform(data)\n",
    "result.selectExpr(\"explode(translation.result) as result\").show(truncate=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "eLoVo-pXEEZd"
   },
   "source": [
    "Or in French:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V1sUnQMQEBJm",
    "outputId": "4310d0a1-b39c-4a07-a019-21cce6df2cb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+\n",
      "|result                                  |\n",
      "+----------------------------------------+\n",
      "|He's 50 years old and he's very employed|\n",
      "+----------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline() \\\n",
    "    .setStages([\n",
    "      documentAssembler,\n",
    "      sentence,\n",
    "      marian.setLangId(\"fr\")\n",
    "    ])\n",
    "\n",
    "data_fr = spark.createDataFrame([[\"Il a 50 ans et il est très travailleur\"]]).toDF(\"text\")\n",
    "result_fr = pipeline.fit(data_fr).transform(data_fr)\n",
    "result_fr.selectExpr(\"explode(translation.result) as result\").show(truncate=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "MmnLjA6cBOtm"
   },
   "source": [
    "## 🎯 **Usage with LightPipeline**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Mcns1HvQBTew"
   },
   "source": [
    "- **LightPipeline** is a Spark NLP specific Pipeline class equivalent to Spark ML Pipeline. The difference is that its execution does not hold to Spark principles, instead, it computes everything locally (but in parallel) in order to achieve faster inference when dealing with small amounts of data. This means, we don't have to Spark Dataframe, but a string or an array of strings instead, to be annotated. To create Light Pipelines, you need to input an already trained (fit) Spark ML Pipeline.\n",
    "\n",
    "- It’s `transform()` stage is converted into `annotate()` or `fullAnnotate()` instead. <br/>\n",
    "\n",
    "- Let's ceate a pipeline with `MarianTransformer`, and run it with `LightPipeline` and see the results with an example text. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "06d3RdVSBZxy"
   },
   "source": [
    "**A sample text in Italian for demo - we'll translate Italian text to English**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "tVHwGxddBRwi"
   },
   "outputs": [],
   "source": [
    "text = \"\"\"La Gioconda è un dipinto ad olio del XVI secolo creato da Leonardo. Si tiene al Louvre di Parigi.\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Ht04zjn5BeGg"
   },
   "source": [
    "**Define Spark NLP pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wNviBlNhBbuq",
    "outputId": "28488ed0-5b07-461e-8913-e6c5249b40e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence_detector_dl download started this may take some time.\n",
      "Approximate size to download 514.9 KB\n",
      "[OK!]\n",
      "opus_mt_it_en download started this may take some time.\n",
      "Approximate size to download 454.8 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "documentAssembler = DocumentAssembler()\\\n",
    ".setInputCol(\"text\")\\\n",
    ".setOutputCol(\"document\")\n",
    "\n",
    "sentencerDL = SentenceDetectorDLModel()\\\n",
    ".pretrained(\"sentence_detector_dl\", \"xx\")\\\n",
    ".setInputCols([\"document\"])\\\n",
    ".setOutputCol(\"sentences\")\n",
    "\n",
    "marian = MarianTransformer.pretrained(\"opus_mt_it_en\", \"xx\")\\\n",
    ".setInputCols([\"sentences\"])\\\n",
    ".setOutputCol(\"translation\")\n",
    "\n",
    "nlp_pipeline = Pipeline(stages=[\n",
    "    documentAssembler,\n",
    "    sentencerDL, \n",
    "    marian\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "1aF8057HBiAL"
   },
   "source": [
    "**Run the pipeline with `fullAnnotate()` and visualize the result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pOICBKtMBgX3",
    "outputId": "f70c8a4d-2f04-41a3-9455-2602262d4caa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: La Gioconda è un dipinto ad olio del XVI secolo creato da Leonardo. Si tiene al Louvre di Parigi. \n",
      "\n",
      "\n",
      "Translation of sentence 0:\n",
      "\tLa Gioconda is an oil painting of the sixteenth century created by Leonardo.\n",
      "Metadata:\n",
      "\n",
      "\t{'sentence': '0'}\n",
      "Translation of sentence 1:\n",
      "\tIt's held at the Louvre in Paris.\n",
      "Metadata:\n",
      "\n",
      "\t{'sentence': '1'}\n"
     ]
    }
   ],
   "source": [
    "empty_df = spark.createDataFrame([['']]).toDF('text')\n",
    "pipeline_model = nlp_pipeline.fit(empty_df)\n",
    "lmodel = LightPipeline(pipeline_model)\n",
    "res = lmodel.fullAnnotate(text)\n",
    "print ('Original:', text, '\\n\\n')\n",
    "\n",
    "for i, sentence in enumerate(res[0]['translation']):\n",
    "  print(f\"Translation of sentence {i}:\")\n",
    "  print (f\"\\t{sentence.result}\")\n",
    "  print(\"Metadata:\\n\")\n",
    "  print(f\"\\t{sentence.metadata}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "GH_SbLKQBphJ"
   },
   "source": [
    "**Run the pipeline with `annotate()` and visualize the results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LIcziYt0BnyV",
    "outputId": "79e8276a-64ee-4e5e-f1d1-373ba9db262a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: La Gioconda è un dipinto ad olio del XVI secolo creato da Leonardo. Si tiene al Louvre di Parigi. \n",
      "\n",
      "\n",
      "Translated:\n",
      "\n",
      "La Gioconda is an oil painting of the sixteenth century created by Leonardo.\n",
      "It's held at the Louvre in Paris.\n"
     ]
    }
   ],
   "source": [
    "empty_df = spark.createDataFrame([['']]).toDF('text')\n",
    "pipeline_model = nlp_pipeline.fit(empty_df)\n",
    "lmodel = LightPipeline(pipeline_model)\n",
    "res2 = lmodel.annotate(text)\n",
    "print('Original:', text, '\\n\\n')\n",
    "\n",
    "print('Translated:\\n')\n",
    "for sentence in res2['translation']:\n",
    "    print(sentence)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "HGJNA95lY21m"
   },
   "source": [
    "- The LightPipeline in Spark NLP offers two methods, `annotate()` and `fullAnnotate()`, to process input text and obtain pipeline results. \n",
    "\n",
    "- `annotate()` returns a dictionary with keys as output column names and values as lists of annotated strings, providing a simplified output without metadata. \n",
    "\n",
    "- `fullAnnotate()` returns a list of dictionaries, each representing an input document, with keys as output column names and values as lists of Annotation objects, providing a more detailed output with metadata included. \n",
    "\n",
    "- Use `annotate()` for a simple output without metadata, and `fullAnnotate()` for a more detailed output with metadata included.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "MFjoBaYfwie0"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
