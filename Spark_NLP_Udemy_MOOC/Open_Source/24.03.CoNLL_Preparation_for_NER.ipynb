{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"BT9cAnlPKmoN"},"source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Open_Source/24.03.CoNLL_Preparation_for_NER.ipynb)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Y0fJRpNJBslT"},"source":["# **CoNLL Preparation for Named Entity Recognition**"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"EolaHS1rKyT4"},"source":["This notebook will cover the the details of `CoNLL Preparation`. \n","\n","A CoNLL (Conference on Computational Natural Language Learning) file is a type of file format used to represent annotated linguistic data.\n","\n","\n","**ðŸ“– Learning Objectives:**\n","\n","1. Understand the meaning of `CoNLL files`, namely being the process of automatically extracting the most important keywords from a text document.\n","\n","2. Understand how `CoNLL files` are prepared.\n","\n","\n","**ðŸ”— Helpful Links:**\n","\n","- Documentation : [CoNLL Dataset](https://nlp.johnsnowlabs.com/docs/en/training#conll-dataset)\n","\n","\n","- For extended examples of usage, see the [Spark NLP Workshop Public repository](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/4.NERDL_Training.ipynb).\n","\n","- Please check the [Details of CoNLL file preparation](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/1.3.prepare_CoNLL_from_annotations_for_NER.ipynb)\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Gc2WMRwsOjJ7"},"source":["## **ðŸ“œ Background**"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"eQwhH1cfOkNX"},"source":["`CoNLL` (Conference on Computational Natural Language Learning) file is a type of file format used to represent annotated linguistic data, such as part-of-speech tags, syntactic dependencies, and named entities. \n","\n","A typical `CoNLL file` consists of a series of lines, where each line represents a single token in a text document. Each token is annotated with various linguistic features, such as its part-of-speech tag, lemma, and syntactic dependency relation to other tokens in the document.\n","\n","`CoNLL files` are often used to train and evaluate machine learning models in NLP tasks such as named entity recognition, part-of-speech tagging, and dependency parsing."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"QEcClmWnOnJN"},"source":["## **ðŸŽ¬ Colab Setup**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HuLFt0OdBkuo"},"outputs":[],"source":["!pip install -q pyspark==3.1.2  spark-nlp==4.2.4"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":237},"executionInfo":{"elapsed":46456,"status":"ok","timestamp":1679338632184,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":240},"id":"URRyJvTMBtXQ","outputId":"0aad5722-e0bb-4897-e53f-99a473436be1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Spark NLP Version : 4.2.4\n"]},{"data":{"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://d28b1d5bc8d3:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.1.2</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>Spark NLP</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "],"text/plain":["<pyspark.sql.session.SparkSession at 0x7f24fc51c6a0>"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["import json\n","import os\n","\n","import pandas as pd\n","from tqdm import tqdm\n","from collections import Counter\n","import pandas as pd\n","\n","import sparknlp\n","from sparknlp.base import *\n","from sparknlp.common import *\n","from sparknlp.annotator import *\n","from sparknlp.training import CoNLL\n","\n","import pyspark.sql.functions as F\n","from pyspark.ml import Pipeline\n","from pyspark.sql import SparkSession\n","\n","\n","spark = sparknlp.start()\n","\n","print (\"Spark NLP Version :\", sparknlp.version())\n","\n","spark"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"j8yuLYzd1XjL"},"source":["## **ðŸ’» CoNLL Preparation Process**\n","\n","In order to prepare a `CoNLL file`, two files are needed; **entity file** and a **text file**.\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Rv7jEsTblG62"},"source":["### Entity File\n","\n","This dataframe should include those columns in order:\n","<br/>\n","\n","![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAASQAAAAYCAYAAABTNoCOAAAEnklEQVR4Xu1asXLbMAxFviQX9w/0BfHlunTOolWzt0y9eEyuU7ZOGbR6ydyll7O/QHuG2JcvaUmJkEmKoiFatuEzsjmWSOA94BEAffVP/YH8CQKCgCDAAIErESQGLIgJgoAgUCMggiSBIAgIAmwQEEFiQ4UYIggIAiJIEgOCgCDABgERJDZUiCGCgCAggiQxIAgIAmwQEEFiQ4UYIggIAnwFafUIk2IB2XwJb8W1w9RXeQ/Tpwrycg3PtyckMWJjslWHWDPZmHFfZMOb79ZXCffTJ6jyEtZjBRSumc1h+VaAG8Hj4nqS1Q4Up3RBMgaMIgKUtUSQOkJ8ksAbcVMRpBHBPPZSfs76+UnJaYLNZEFaPU5AFSyjVCX7rsUmsA90ShB4O8tH2PAmFdLg+NmVs7u+p25IEiTcrF0US1ssS/ELU56CaamUetUlMAai/lxCUQtbZy3fYi/Z2zWcV5m0bHkOsFhApW2zS/QefHT53usPWK3q5LVuWyHLIKuq7vpUlsd4rs8Xw1Ofjex48/yoRwJ3703LFsK5Jw7rTsFwFfTda9k25kB34mMMXoaukcBjazvupfP6+992pDL7nHo5/QvmHz/hqcpgvnyD4noFj5MCFoT2lSRI2o6uAppNfHGqP98oTZoag2bwOXWNIampHQiYmGYv0vtDiUp5vk3GZk6AQtzMvTYNCSF8LDL1fMzxJyhI7vqjtM2D/I1wbXzBREMMnITlwlvfXMf7f8gHnGU6VV4rSAF+bsxcSifh7BOmTXsx3oxqEH/4cCKPt4H894Taz0nEyRZ8pU47xxDpgoTJ6AMTrJ5QKZuHSYJiOYwKjInIpvT3WzZ7OIqJGsAHq8SgPyFB8irN0KA/KT6pL8W4Rj8DNnLjzUkS+6LEH2oHDsOoIIX48asuQnVApSP5uUQeO4emEiiVxM6lUyenLUyX336rSygw1VLc+mRB6iUX93NKw8sTpIaEKnhL2Hea2FVFnQBeZbgT8+RIjb8Y3ReD/IwEqVNhHlKQQLXbmWq32/blQCQRlk3lMUmQ4Mt0STnk+QIWH7TbRrIgdaqSVnByKNfPoEUTVmpGdKNmRNdojBKi8gf8KXR/vjWIVOFYCvwCD1Zy685It4PjDNgJPPY/0tOy1QGPJTt08bl7b3620Jy6nj8cK6QY15vmpPTnhdo3drztatmwuqeOC7Bli1ZIKu5fAB70jMqOhb0CL/HlRB61IHVyNjZbq8XAnZNSq3qyICm1aWYieqe+obY6DfQQa/La3Mj5Ze62hw6s5WPcUxLajx1/luIZGSqB7TmBP0A0+Ohuwb4oyNQwtVJDa64VkomuZvDbQmCq3ogg2ScrG95iQ+2QIFkHhvYhxFVIjLeDcne+pJJne4An6sper/XF5A4eO/nvzUHj+uB2SDH7BwjSXjDIyxEESBWjICgInB0CplMCWrum3WMgSFa11AJ+4lPkqMTTr0SPapZsJgjsi4Cpxii3a7gVA0Ha1+tzfN8TYQ43MOcIo9jMFoF2JDHwpw4iSGwpFcMEgctDQATp8jgXjwUBtgiIILGlRgwTBC4PARGky+NcPBYE2CLwH9v7ggQC98k+AAAAAElFTkSuQmCC)\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"FMysDwoVmIRG"},"source":["Get the entities file in `csv` format from the John Snow Labs Github, read the file as a Pandas dataframe and select the above-mentioned columns."]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":989,"status":"ok","timestamp":1679345253718,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":240},"id":"qb-kYIP2PUAc","outputId":"de1be5e8-fb8e-4f18-b7b4-74797909a4c8"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-d7964ee5-56f8-4ea2-8f06-b923ec743594\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_id</th>\n","      <th>begin</th>\n","      <th>end</th>\n","      <th>chunk</th>\n","      <th>entity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>11319232</td>\n","      <td>242</td>\n","      <td>250</td>\n","      <td>acyl-CoAs</td>\n","      <td>CHEMICAL</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>11319232</td>\n","      <td>1193</td>\n","      <td>1200</td>\n","      <td>triacsin</td>\n","      <td>CHEMICAL</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>11319232</td>\n","      <td>1441</td>\n","      <td>1447</td>\n","      <td>sucrose</td>\n","      <td>CHEMICAL</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>11319232</td>\n","      <td>1637</td>\n","      <td>1651</td>\n","      <td>triacylglycerol</td>\n","      <td>CHEMICAL</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>11319232</td>\n","      <td>1702</td>\n","      <td>1710</td>\n","      <td>acyl-CoAs</td>\n","      <td>CHEMICAL</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d7964ee5-56f8-4ea2-8f06-b923ec743594')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d7964ee5-56f8-4ea2-8f06-b923ec743594 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d7964ee5-56f8-4ea2-8f06-b923ec743594');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["    text_id  begin   end            chunk    entity\n","0  11319232    242   250        acyl-CoAs  CHEMICAL\n","1  11319232   1193  1200         triacsin  CHEMICAL\n","2  11319232   1441  1447          sucrose  CHEMICAL\n","3  11319232   1637  1651  triacylglycerol  CHEMICAL\n","4  11319232   1702  1710        acyl-CoAs  CHEMICAL"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Healthcare/data/ChemProt/chemprot_train_entities.csv\n","\n","train_entities_df = pd.read_csv('chemprot_train_entities.csv')\n","train_entities_df= train_entities_df[[\"text_id\", \"begin\", \"end\", \"chunk\", \"entity\"]]\n","\n","train_entities_df.head()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"T-47QRgDmfS_"},"source":["### Text File\n","\n","This dataframe should include the columns below:\n","<br/>\n","\n","![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAIsAAAAbCAYAAABMf3y8AAACEElEQVRoQ+2XPXLCMBCFl5Mw+Ag+QdympqF1TZcSl6bMBSjU0lCntU/ADWCGkwRJthz5J8OOkC08PHce1ivx3qfd1eJXPoQHCjAUWAAWhkoI0QoAFoDAVgCwsKVCIGABA2wFAAtbKgQCFjDAVgCwsKVCIGABA2wFAAtbKgS+JizljqL0SHFW0Cldtly6iTUl+Zk24kr7Dxg4pQI8WGrzvBjEyQVYhhngaMelxyEXC5ZyF5E86F5O87O53rmyPKudzZFLroewmKTNQhtBV1X/b4LWSU5n80OcUXFKieo2IcnSccZc9S4o1dD1cnVPQ6eyNDlan75XGwriQ8eXh7Co+D6FJe2ilI5dcPT7SvKSUH6OKSu2dElkXA2Smj5YRNuwRAc9vxj4WN9zS/HM4ib3wQsstZk9rQerjoLmRGZOZZltwbK9JK0WiDZkjQNj++ADFmPY0G1F52+1KMDiq4B1D9roPrjA0jvNDQwbEtc96RtsKWeSlZxJlre/NiQ+6SeVc43VhliVwaos3/Slr8oVmGokUi3Oz7Dty8Sp8kzugwsskoRqRlEf/zfgUlVBokN1czJVxx5w9WA8lOvBgNsb7vQ23mvArSSa2Ac3WKY6O1jnlRVg3YbG+wPWSWkWsVrbeAsjs4MCgWFx2DE+CaYAYAkm/fwWBizz8yzYjgFLMOnntzBgmZ9nwXYMWIJJP7+F707BOc79Bj1bAAAAAElFTkSuQmCC)\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"CL_SI3HdnKnq"},"source":["Get the text file in `csv` format from the John Snow Labs Github and read the file as a Pandas dataframe."]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":559,"status":"ok","timestamp":1679345282034,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":240},"id":"TS2Gp8asPVFf","outputId":"a35398f5-65bd-46a2-bc9d-2a5c0f8e09b3"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-c7bc7402-b2dc-44d9-9de8-b91e21101a92\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_id</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>16357751</td>\n","      <td>Selective costimulation modulators: a novel ap...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>14967461</td>\n","      <td>Emerging role of epidermal growth factor recep...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>23468099</td>\n","      <td>Effects of chronic social defeat stress on beh...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>23293962</td>\n","      <td>Hepatocyte growth factor activator inhibitor t...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>7678677</td>\n","      <td>Alprenolol and bromoacetylalprenololmenthane a...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c7bc7402-b2dc-44d9-9de8-b91e21101a92')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c7bc7402-b2dc-44d9-9de8-b91e21101a92 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c7bc7402-b2dc-44d9-9de8-b91e21101a92');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["    text_id                                               text\n","0  16357751  Selective costimulation modulators: a novel ap...\n","1  14967461  Emerging role of epidermal growth factor recep...\n","2  23468099  Effects of chronic social defeat stress on beh...\n","3  23293962  Hepatocyte growth factor activator inhibitor t...\n","4   7678677  Alprenolol and bromoacetylalprenololmenthane a..."]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Healthcare/data/ChemProt/chemprot_train_text.csv\n","\n","train_text_df = pd.read_csv('chemprot_train_text.csv')\n","train_text_df.head()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"lbWxZlNpnxMK"},"source":["### Define a Function for CoNLL Preparation"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"CRqvVEbmockA"},"source":["A **`make_conll`** function is prepared to create a conll file from the `train_entities_df` and `train_text_df` dataframes defined before. \n","\n","The output file in conll format contains one row per token in the corpus, with each row containing the various annotations associated with that token."]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":327,"status":"ok","timestamp":1679345298303,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":240},"id":"T69zI2y7FckF"},"outputs":[],"source":["def make_conll(text:pd.DataFrame, entity:pd.DataFrame, \n","               save_tag:bool=None, \n","               save_conll:bool=None, \n","               verbose:bool=None, \n","               begin_deviation:int=0, \n","               end_deviation:int=0 )->str:\n","\n","    df_text = text.iloc[:,[0,1]]\n","    df_entity = entity.iloc[:,[0,1,2,3,4]]\n","    df_text.columns = ['text_id','text']\n","    df_entity.columns = ['text_id','begin','end','chunk','entity']\n","    entity_list = list(df_entity.entity.unique())\n","\n","\n","    ########--------------1.tag transformation function------------########\n","\n","    def transform_text(text, entities, verbose=None):\n","\n","        tag_list=[]\n","        for entity in entities.iterrows():\n","\n","            begin = entity[1][1] + begin_deviation \n","            end = entity[1][2] + end_deviation\n","            chunk = entity[1][3]\n","            tag = entity[1][4]\n","            text = text[:end] + f' </END_NER:{tag}> ' + text[end:]\n","            text = text[:begin] + f' <START_NER:{tag}> ' + text[begin:]\n","            tag_list.append(tag)\n","\n","        sum_of_added_entity = Counter(tag_list)\n","        sum_of_entity = Counter(entities['entity'].values)\n","\n","        if verbose:\n","            print(f'Processed text id   : {entities.text_id.values[:1]}')\n","            print(f'Original Entities   : {sum_of_entity}\\nAdded Entities      : {sum_of_added_entity}')\n","            print(f'Number Equality     : {sum_of_added_entity == sum_of_entity}')\n","            print(\"==\"*40)\n","\n","        if not sum_of_entity == sum_of_added_entity:\n","            print(\"There is a problem in text id:\")\n","            print(entities.text_id.values[0])\n","            raise Exception(\"Check this text!\")\n","\n","        return text\n","\n","\n","    ######---------------2.apply_transform_text function ----------------#######\n","\n","    def apply_tag_ner(df_text, df_entity, save=None, verbose=None):\n","\n","        for text_id in tqdm(df_text.text_id):\n","            text  = df_text.loc[df_text['text_id']==text_id]['text'].values[0] \n","            entities  = df_entity.loc[(df_entity['text_id']==text_id)].sort_values(by='begin',ascending=False) \n","\n","            df_text.loc[df_text['text_id']==text_id, 'text'] = transform_text(text, entities, verbose=verbose)\n","\n","        if save:\n","            df_text.to_csv(\"text_with_ner_tag.csv\", index=False, encoding='utf8')\n","\n","        return df_text\n","\n","\n","    ##########----------------3.RUNNING TAG FUNCTION---------------#############\n","    \n","    print(\"Text tagging starting. Applying entities to whole text...\\n\")\n","    df = apply_tag_ner(df_text, df_entity, save=save_tag, verbose=verbose)\n","\n","\n","    ###########---------------4.Spark Pipeline-----------------------###########\n","\n","    def spark_pipeline(df):\n","        spark_df = spark.createDataFrame(df)\n","\n","        documentAssembler = DocumentAssembler()\\\n","            .setInputCol(\"text\")\\\n","            .setOutputCol(\"document\")\\\n","            .setCleanupMode(\"shrink\")\n","\n","        sentenceDetector = SentenceDetector()\\\n","            .setInputCols(['document'])\\\n","            .setOutputCol('sentences')\\\n","            .setExplodeSentences(True)\n","\n","        tokenizer = Tokenizer() \\\n","            .setInputCols([\"sentences\"]) \\\n","            .setOutputCol(\"token\")\n","\n","        nlpPipeline = Pipeline(stages=[documentAssembler, sentenceDetector, tokenizer ])\n","\n","        empty_df = spark.createDataFrame([['']]).toDF(\"text\")\n","        pipelineModel = nlpPipeline.fit(empty_df)\n","\n","        result = pipelineModel.transform(spark_df.select(['text']))\n","\n","\n","        return result.select('token.result').toPandas()\n","    print(\"\\n\\nSpark pipeline is running...\")\n","    df_final = spark_pipeline(df)\n","\n","\n","    #########--------------5.CoNLL Function--------------------#############\n","\n","    def build_conll(df_final, tag_list, save=None):\n","\n","        header = \"-DOCSTART- -X- -X- O\\n\\n\"\n","        conll_text = \"\"\n","        chunks = []\n","        tag_list = tag_list\n","        tag = 'O'      # token tag \n","        ct = 'B'       # chunk tag part B or I\n","\n","        for sentence_tokens in tqdm(df_final.result[:]):\n","            for token in sentence_tokens:\n","                if token.startswith(\"<START_NER:\"):\n","                    tag = token.split(':')[1][:-1]\n","                    if tag not in tag_list:\n","                        tag = 'O'\n","                        conll_text += f'{token} NN NN {tag}\\n'\n","\n","                    continue\n","\n","                if token.startswith(\"</END_NER:\") and tag != 'O':\n","                    for i, chunk in enumerate(chunks):\n","                        ct = 'B' if i == 0 else 'I' \n","                        conll_text += f'{chunk} NNP NNP {ct}-{tag}\\n'\n","                    \n","                    chunks=[]\n","                    tag='O'\n","                    continue\n","\n","                if tag != 'O':    \n","                    chunks.append(token)\n","                    continue\n","\n","                if tag == 'O':\n","                    conll_text += f'{token} NN NN {tag}\\n'             \n","                    continue\n","\n","            conll_text += '\\n'                                         \n","\n","        if save:\n","            with open(\"conll2003_text_file.conll\", \"w+\", encoding='utf8') as f:\n","                f.write(header)\n","                f.write(conll_text)\n","\n","        print(\"\\nDONE!\")    \n","        return conll_text\n","\n","        \n","    ########----------------6.RUNNING CONLL FUNCTION--------------------########\n","\n","    print(\"Conll file is being created...\\n\")\n","    return build_conll(df_final, tag_list=entity_list, save=save_conll)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Oo2IXLhkhUzX"},"source":["### Running the **`make_conll`** Function"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"GpR9PMd2Zqzm"},"source":["Call the `**make_conll**`function and use the two dataframes (created from the entity file and text file).\n","\n","<br/>\n"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31922,"status":"ok","timestamp":1679345348346,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":240},"id":"UxYYVgl_hR7h","outputId":"61988322-b564-4725-fe0e-1d3ca364e45e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Text tagging starting. Applying entities to whole text...\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1020/1020 [00:02<00:00, 349.30it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","Spark pipeline is running...\n","Conll file is being created...\n","\n"]},{"name":"stderr","output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10835/10835 [00:00<00:00, 51724.01it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","DONE!\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["conll_text = make_conll(train_text_df, train_entities_df, save_conll=True)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"7MyDEcOMp__w"},"source":["Check the success of the function by printing the first few characters of the created conll file.\n","\n","<br/>\n"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37,"status":"ok","timestamp":1679345348351,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":240},"id":"T_V7dDjghZfX","outputId":"f01e67e7-6a24-46d5-cb93-a985789ab96b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Selective NN NN O\n","costimulation NN NN O\n","modulators NN NN O\n",": NN NN O\n","a NN NN O\n","novel NN NN O\n","approach NN NN O\n","for NN NN O\n","the NN NN O\n","treatment NN NN O\n","of NN NN O\n","rheumatoid NN NN O\n","arthritis NN NN O\n",". NN NN O\n","\n","T NN NN O\n","cells NN NN O\n","have NN NN O\n","a NN NN O\n","central NN NN O\n","role NN NN O\n","in NN NN O\n","the NN NN O\n","orchestration NN NN O\n","of NN NN O\n","the NN NN O\n","immune NN NN O\n","pathways NN NN O\n","that NN NN O\n","contribute NN NN O\n","to NN NN O\n","the NN NN O\n","inflammation NN NN O\n","and NN NN O\n","joint NN NN O\n","destruction NN NN O\n","characteristic NN NN O\n","\n"]}],"source":["print(conll_text[:532])"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"-zBrdj-oh330"},"source":["### Saving CoNLL File"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"2goRED7zaZlA"},"source":["**Save** the conll file; just add extra two lines (second line is empty) to the top of the text.\n","\n","<br/>\n"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":165,"status":"ok","timestamp":1679345383526,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":240},"id":"9FZ9AAsxhgFz"},"outputs":[],"source":["with open(\"conll2003_text_file.conll\", \"w+\", encoding='utf8') as f:\n","    f.write(\"-DOCSTART- -X- -X- O\\n\\n\")\n","    f.write(conll_text)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Sz659jEBiAud"},"source":["### Reading CoNLL File by Using CoNLL Reader"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Vrnku-w4a3Jt"},"source":["Use **CoNLL()** to read the created file as a Spark dataframe.\n","\n","<br/>\n"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6882,"status":"ok","timestamp":1679345393984,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":240},"id":"eElw0pssh9bj","outputId":"460f08fc-fed3-41ac-96f8-c24f457697f9"},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n","|                text|            document|            sentence|               token|                 pos|               label|\n","+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n","|Selective costimu...|[{document, 0, 96...|[{document, 0, 96...|[{token, 0, 8, Se...|[{pos, 0, 8, NN, ...|[{named_entity, 0...|\n","|T cells have a ce...|[{document, 0, 17...|[{document, 0, 17...|[{token, 0, 0, T,...|[{pos, 0, 0, NN, ...|[{named_entity, 0...|\n","|The requirement f...|[{document, 0, 22...|[{document, 0, 22...|[{token, 0, 2, Th...|[{pos, 0, 2, NN, ...|[{named_entity, 0...|\n","|This approach is ...|[{document, 0, 78...|[{document, 0, 78...|[{token, 0, 3, Th...|[{pos, 0, 3, NN, ...|[{named_entity, 0...|\n","|it targets events...|[{document, 0, 13...|[{document, 0, 13...|[{token, 0, 1, it...|[{pos, 0, 1, NN, ...|[{named_entity, 0...|\n","|The fusion protei...|[{document, 0, 23...|[{document, 0, 23...|[{token, 0, 2, Th...|[{pos, 0, 2, NN, ...|[{named_entity, 0...|\n","|Abatacept dose-de...|[{document, 0, 19...|[{document, 0, 19...|[{token, 0, 8, Ab...|[{pos, 0, 8, NN, ...|[{named_entity, 0...|\n","|Recent studies ha...|[{document, 0, 26...|[{document, 0, 26...|[{token, 0, 5, Re...|[{pos, 0, 5, NN, ...|[{named_entity, 0...|\n","|This efficacy inc...|[{document, 0, 10...|[{document, 0, 10...|[{token, 0, 3, Th...|[{pos, 0, 3, NN, ...|[{named_entity, 0...|\n","|Abatacept has als...|[{document, 0, 72...|[{document, 0, 72...|[{token, 0, 8, Ab...|[{pos, 0, 8, NN, ...|[{named_entity, 0...|\n","+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n","only showing top 10 rows\n","\n"]}],"source":["data = CoNLL().readDataset(spark, \"/content/conll2003_text_file.conll\")\n","data.show(10)"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1143,"status":"ok","timestamp":1679345408362,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"},"user_tz":240},"id":"u_pJ343GZf--","outputId":"78d39597-7790-4880-bb86-9b2ca723f9a8"},"outputs":[{"name":"stdout","output_type":"stream","text":["+------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------+\n","|                                                                                      text|                                                                                    tokens|\n","+------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------+\n","|Selective costimulation modulators : a novel approach for the treatment of rheumatoid a...|[Selective, costimulation, modulators, :, a, novel, approach, for, the, treatment, of, ...|\n","|T cells have a central role in the orchestration of the immune pathways that contribute...|[T, cells, have, a, central, role, in, the, orchestration, of, the, immune, pathways, t...|\n","|The requirement for a dual signal for T-cell activation and the construction of a fusio...|[The, requirement, for, a, dual, signal, for, T-cell, activation, and, the, constructio...|\n","|           This approach is mechanistically distinct from other currently used therapies ;|[This, approach, is, mechanistically, distinct, from, other, currently, used, therapies...|\n","|it targets events early rather than late in the immune cascade , and it results in immu...|[it, targets, events, early, rather, than, late, in, the, immune, cascade, ,, and, it, ...|\n","+------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------+\n","only showing top 5 rows\n","\n"]}],"source":["data.selectExpr(\"text\", \"token.result as tokens\").show(5, truncate = 90)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOBAG0NY0oV1z1py1glWc56","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
