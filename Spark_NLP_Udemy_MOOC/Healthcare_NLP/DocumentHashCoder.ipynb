{"cells":[{"cell_type":"markdown","metadata":{"id":"49w2L5Yz2acq"},"source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"]},{"cell_type":"markdown","source":["# DocumentHashCoder\n","\n","In this notebook, we will examine the `DocumentHashCoder` annotator.\n","\n","`DocumentHashCoder()` annotator is used for determining shifts date information for deidentification purposes.\n","\n","This annotator gets the hash of the specified column and creates a new document column containing day shift information. <br/>\n"],"metadata":{"id":"3pvHVeVqNTNw"}},{"cell_type":"markdown","source":["**📖 Learning Objectives:**\n","\n","1. Understand how to shift days in Deidentification tasks by using `DocumentHashCoder`.\n","\n","2. Become comfortable using the different parameters of the annotator.\n","\n","**🔗 Helpful Links:**\n","\n","- Documentation : [DocumentHashCoder](https://nlp.johnsnowlabs.com/docs/en/licensed_annotators#documenthashcoder)\n","\n","- For extended examples of usage, see the [Spark NLP Workshop](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/4.Clinical_DeIdentification.ipynb)\n","\n","- Python Documentation: [DocumentHashCoder](https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/deid/doccument_hashcoder/index.html#sparknlp_jsl.annotator.deid.doccument_hashcoder.DocumentHashCoder.seed)\n","\n","- Scala Documentation: [DocumentHashCoder](https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/deid/DocumentHashCoder.html)\n"],"metadata":{"id":"daTdSpZ9dz6K"}},{"cell_type":"markdown","source":["## **📜 Background**\n"],"metadata":{"id":"HXgUBncKfnA6"}},{"cell_type":"markdown","source":["This annotator can replace dates in a column of `DOCUMENT` type according with the hash code of any other column. It uses the hash of the specified column and creates a new document column containing the day shift information. In sequence, the `DeIdentification` annotator deidentifies the document with the shifted date information.\n","\n","If the specified column contains strings that can be parsed to integers, use those numbers to make the shift in the data accordingly."],"metadata":{"id":"mtq8-Rrrfu1c"}},{"cell_type":"markdown","source":["## **🎬 Colab Setup**"],"metadata":{"id":"N5ZJ0EthgVOP"}},{"cell_type":"code","source":["# Install the johnsnowlabs library to access Spark-NLP for Healthcare\n","! pip install -q johnsnowlabs"],"metadata":{"id":"WbLu60U6fmxJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718060751446,"user_tz":180,"elapsed":74827,"user":{"displayName":"David Cecchini","userId":"15563969817876100862"}},"outputId":"e53c6a7b-bdc2-40ef-99cd-2b62e663c349"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.2/265.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m565.0/565.0 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m676.2/676.2 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.6/95.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.9/66.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.3/150.3 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["from google.colab import files\n","print('Please Upload your John Snow Labs License using the button below')\n","license_keys = files.upload()"],"metadata":{"id":"hwytACt7gY6N","colab":{"base_uri":"https://localhost:8080/","height":91},"executionInfo":{"status":"ok","timestamp":1718060764846,"user_tz":180,"elapsed":13408,"user":{"displayName":"David Cecchini","userId":"15563969817876100862"}},"outputId":"04f45aeb-c938-460b-a7ac-bf94c488f509"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Please Upload your John Snow Labs License using the button below\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-265caa95-d8ad-4291-8915-7adb4322dd00\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-265caa95-d8ad-4291-8915-7adb4322dd00\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving spark_nlp_for_healthcare_spark_ocr_8734_532.json to spark_nlp_for_healthcare_spark_ocr_8734_532.json\n"]}]},{"cell_type":"code","source":["from johnsnowlabs import nlp, medical\n","\n","# After uploading your license run this to install all licensed Python Wheels and pre-download Jars the Spark Session JVM\n","nlp.install()"],"metadata":{"id":"4kSfTrnsfmri","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718060847448,"user_tz":180,"elapsed":82606,"user":{"displayName":"David Cecchini","userId":"15563969817876100862"}},"outputId":"d0b9c663-3ed5-4d1d-fe9d-256708f88c1d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["👌 Detected license file /content/spark_nlp_for_healthcare_spark_ocr_8734_532.json\n","📋 Stored John Snow Labs License in /root/.johnsnowlabs/licenses/license_number_0_for_Spark-Healthcare_Spark-OCR.json\n","👷 Setting up  John Snow Labs home in /root/.johnsnowlabs, this might take a few minutes.\n","Downloading 🐍+🚀 Python Library spark_nlp-5.3.2-py2.py3-none-any.whl\n","Downloading 🐍+💊 Python Library spark_nlp_jsl-5.3.2-py3-none-any.whl\n","Downloading 🫘+🚀 Java Library spark-nlp-assembly-5.3.2.jar\n","Downloading 🫘+💊 Java Library spark-nlp-jsl-5.3.2.jar\n","🙆 JSL Home setup in /root/.johnsnowlabs\n","👌 Detected license file /content/spark_nlp_for_healthcare_spark_ocr_8734_532.json\n","Installing /root/.johnsnowlabs/py_installs/spark_nlp_jsl-5.3.2-py3-none-any.whl to /usr/bin/python3\n","Installed 1 products:\n","💊 Spark-Healthcare==5.3.2 installed! ✅ Heal the planet with NLP! \n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Automatically load license data and start a session with all jars user has access to\n","spark = nlp.start()"],"metadata":{"id":"q9efx-2JKTDq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718060871559,"user_tz":180,"elapsed":24118,"user":{"displayName":"David Cecchini","userId":"15563969817876100862"}},"outputId":"37f0b2de-085f-4931-d28b-0efe7ab69d1a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["👌 Detected license file /content/spark_nlp_for_healthcare_spark_ocr_8734_532.json\n","👌 Launched \u001b[92mcpu optimized\u001b[39m session with with: 🚀Spark-NLP==5.3.2, 💊Spark-Healthcare==5.3.2, running on ⚡ PySpark==3.4.0\n"]}]},{"cell_type":"code","source":["spark"],"metadata":{"id":"-NycGNEzKVDf","executionInfo":{"status":"ok","timestamp":1718060875512,"user_tz":180,"elapsed":3957,"user":{"displayName":"David Cecchini","userId":"15563969817876100862"}},"colab":{"base_uri":"https://localhost:8080/","height":222},"outputId":"be897be0-19a9-42f9-d4c8-0f21e7aeab32"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<pyspark.sql.session.SparkSession at 0x7e3acc92fac0>"],"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://b389d6e2f4fc:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.4.0</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>John-Snow-Labs-Spark-Session 🚀 with Jars for: 🚀Spark-NLP==5.3.2, 💊Spark-Healthcare==5.3.2, running on ⚡ PySpark==3.4.0</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["## **🖨️ Input/Output Annotation Types**\n","- Input: `DOCUMENT`\n","- Output: `DOCUMENT`"],"metadata":{"id":"KJuds52Dgvtm"}},{"cell_type":"markdown","source":["## **🔎 Parameters**\n"],"metadata":{"id":"gs-wO_iMhE42"}},{"cell_type":"markdown","source":["- `PatientIdColumn` *(String)*: Name of the column containing patient ID.\n","\n","- `setDateShiftColumn` *(String)*: Sets column to be used for hash or predefined shift.\n","\n","- `setNewDateShift` *(String)*: Sets column that has a reference of where chunk begins.\n","\n","- `setRangeDays` *(int)*: Sets the range of dates to be sampled from.\n","\n","- `setSeed` *(int)*: Sets the seed for random number generator."],"metadata":{"id":"LZ5DcZnNhned"}},{"cell_type":"markdown","source":["### DocumentHashCoder with Deidentification"],"metadata":{"id":"9tiNlxkGzmtW"}},{"cell_type":"markdown","source":["We will generate a sample deidentification pipeline with `DocumentHashCoder` to see the capabilities of the annotator."],"metadata":{"id":"3ND588voz02C"}},{"cell_type":"code","source":["data = pd.DataFrame(\n","    {'patientID' : ['A001', 'A001', 'A002', 'A002'],\n","     'text' : ['Chris Brown was discharged on 10/02/2022',\n","               'Mark White was discharged on 02/28/2020',\n","               'John was discharged on 03/15/2022',\n","               'John Moore was discharged on 12/31/2022'\n","              ]\n","    }\n",")\n","\n","my_input_df = spark.createDataFrame(data)\n","\n","my_input_df.show(truncate = False)"],"metadata":{"id":"Tv1yspQczRvX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718060893883,"user_tz":180,"elapsed":18377,"user":{"displayName":"David Cecchini","userId":"15563969817876100862"}},"outputId":"2f4f7e1d-5e5b-461a-a6b4-b5864944b9de"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+----------------------------------------+\n","|patientID|text                                    |\n","+---------+----------------------------------------+\n","|A001     |Chris Brown was discharged on 10/02/2022|\n","|A001     |Mark White was discharged on 02/28/2020 |\n","|A002     |John was discharged on 03/15/2022       |\n","|A002     |John Moore was discharged on 12/31/2022 |\n","+---------+----------------------------------------+\n","\n"]}]},{"cell_type":"markdown","source":["### `setPatientIdColumn`"],"metadata":{"id":"CDDMqg9eBBbp"}},{"cell_type":"markdown","source":["This parameter is set to specify the name of the column containing the patient ID.\n","\n","It is used when we want to shift the days according to the ID column. <br/>"],"metadata":{"id":"bggUpwgFBm0D"}},{"cell_type":"code","source":["documentAssembler = nlp.DocumentAssembler()\\\n","    .setInputCol(\"text\")\\\n","    .setOutputCol(\"document\")\n","\n","documentHasher = medical.DocumentHashCoder()\\\n","    .setInputCols(\"document\")\\\n","    .setOutputCol(\"document2\")\\\n","    .setPatientIdColumn(\"patientID\")\\\n","    .setNewDateShift(\"shift_days\")\n","\n","tokenizer = nlp.Tokenizer()\\\n","    .setInputCols([\"document2\"])\\\n","    .setOutputCol(\"token\")\n","\n","embeddings = nlp.WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n","    .setInputCols([\"document2\", \"token\"])\\\n","    .setOutputCol(\"word_embeddings\")\n","\n","clinical_ner = medical.NerModel\\\n","    .pretrained(\"ner_deid_subentity_augmented\", \"en\", \"clinical/models\")\\\n","    .setInputCols([\"document2\",\"token\", \"word_embeddings\"])\\\n","    .setOutputCol(\"ner\")\n","\n","ner_converter = medical.NerConverterInternal()\\\n","    .setInputCols([\"document2\", \"token\", \"ner\"])\\\n","    .setOutputCol(\"ner_chunk\")\n","\n","de_identification = medical.DeIdentification() \\\n","    .setInputCols([\"ner_chunk\", \"token\", \"document2\"]) \\\n","    .setOutputCol(\"deid_text\") \\\n","    .setMode(\"obfuscate\") \\\n","    .setObfuscateDate(True) \\\n","    .setDateTag(\"DATE\") \\\n","    .setLanguage(\"en\") \\\n","    .setObfuscateRefSource('faker') \\\n","    .setUseShifDays(True)\\\n","    .setRegion('us')\n","\n","pipeline = nlp.Pipeline().setStages([\n","    documentAssembler,\n","    documentHasher,\n","    tokenizer,\n","    embeddings,\n","    clinical_ner,\n","    ner_converter,\n","    de_identification\n","\n","])\n","\n","empty_data = spark.createDataFrame([[\"\", \"\"]]).toDF(\"text\", \"patientID\")\n","\n","pipeline_model = pipeline.fit(empty_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rmY-9H7tAWov","executionInfo":{"status":"ok","timestamp":1718061019809,"user_tz":180,"elapsed":125938,"user":{"displayName":"David Cecchini","userId":"15563969817876100862"}},"outputId":"24ac65da-917d-427a-ac2e-eaef882c1f87"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["embeddings_clinical download started this may take some time.\n","Approximate size to download 1.6 GB\n","[OK!]\n","ner_deid_subentity_augmented download started this may take some time.\n","[OK!]\n"]}]},{"cell_type":"markdown","source":["Checking the results"],"metadata":{"id":"NgBMy2_6CYTS"}},{"cell_type":"code","source":["output = pipeline_model.transform(my_input_df)\n","\n","output.select('patientID','text', 'deid_text.result').show(truncate = False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jDfXLua3CSw0","executionInfo":{"status":"ok","timestamp":1718061029782,"user_tz":180,"elapsed":9988,"user":{"displayName":"David Cecchini","userId":"15563969817876100862"}},"outputId":"782de638-d19c-4562-a13f-88be599bb0bd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+----------------------------------------+--------------------------------------------+\n","|patientID|text                                    |result                                      |\n","+---------+----------------------------------------+--------------------------------------------+\n","|A001     |Chris Brown was discharged on 10/02/2022|[Marinell Siad was discharged on 08/26/2022]|\n","|A001     |Mark White was discharged on 02/28/2020 |[Florance Hun was discharged on 01/22/2020] |\n","|A002     |John was discharged on 03/15/2022       |[Rosaura Comp was discharged on 03/25/2022] |\n","|A002     |John Moore was discharged on 12/31/2022 |[Sammy Crisp was discharged on 01/10/2023]  |\n","+---------+----------------------------------------+--------------------------------------------+\n","\n"]}]},{"cell_type":"markdown","source":["As seen above, we shifted days based on the patient IDs."],"metadata":{"id":"KmPaQ1Z-DtE3"}},{"cell_type":"markdown","source":["### `setNewDateShift`"],"metadata":{"id":"ivddx6M-FZYL"}},{"cell_type":"markdown","source":["In the `DocumentHashCoder`, after transforming, a new column which has the number of days' information is created. `setNewDateShift` parameter is used for specifying the name of the new column."],"metadata":{"id":"SCSs0cruF6-y"}},{"cell_type":"code","source":["documentHasher = medical.DocumentHashCoder()\\\n","    .setInputCols(\"document\")\\\n","    .setOutputCol(\"document2\")\\\n","    .setPatientIdColumn(\"patientID\")\\\n","    .setNewDateShift(\"shift_days\")\n","\n","pipeline = nlp.Pipeline().setStages([\n","    documentAssembler,\n","    documentHasher,\n","    tokenizer,\n","    embeddings,\n","    clinical_ner,\n","    ner_converter,\n","    de_identification\n","\n","])\n","\n","empty_data = spark.createDataFrame([[\"\", \"\"]]).toDF(\"text\", \"patientID\")\n","\n","pipeline_model = pipeline.fit(empty_data)"],"metadata":{"id":"upP8ZpBEFbQ0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Checking the results"],"metadata":{"id":"aCHKYhLDFnmp"}},{"cell_type":"code","source":["output = pipeline_model.transform(my_input_df)\n","\n","output.select('patientID','text', 'deid_text.result', 'shift_days').show(truncate = False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0WjjbeeEFbM3","executionInfo":{"status":"ok","timestamp":1718061034529,"user_tz":180,"elapsed":3957,"user":{"displayName":"David Cecchini","userId":"15563969817876100862"}},"outputId":"cd7e5d69-7511-491e-971b-9924da7f95d0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+----------------------------------------+--------------------------------------------+----------+\n","|patientID|text                                    |result                                      |shift_days|\n","+---------+----------------------------------------+--------------------------------------------+----------+\n","|A001     |Chris Brown was discharged on 10/02/2022|[Marinell Siad was discharged on 02/19/2023]|140       |\n","|A001     |Mark White was discharged on 02/28/2020 |[Florance Hun was discharged on 07/17/2020] |140       |\n","|A002     |John was discharged on 03/15/2022       |[Rosaura Comp was discharged on 08/21/2022] |159       |\n","|A002     |John Moore was discharged on 12/31/2022 |[Sammy Crisp was discharged on 06/08/2023]  |159       |\n","+---------+----------------------------------------+--------------------------------------------+----------+\n","\n"]}]},{"cell_type":"markdown","source":["As seen above, under the \"shift_days\" column, we can see how many days were shifted for the corresponding patient."],"metadata":{"id":"GcY42PTQGk9x"}},{"cell_type":"markdown","source":["### `setRangeDays`"],"metadata":{"id":"euH88suGT6mu"}},{"cell_type":"markdown","source":["This parameter is used in order to set the range of dates to be sampled from.\n","\n","Now, we will set `setRangeDays(60)` and limit the range of the shifted days."],"metadata":{"id":"VZN93eKLUNvT"}},{"cell_type":"code","source":["documentHasher = medical.DocumentHashCoder()\\\n","    .setInputCols(\"document\")\\\n","    .setOutputCol(\"document2\")\\\n","    .setPatientIdColumn(\"patientID\")\\\n","    .setRangeDays(60)\\\n","    .setNewDateShift(\"shift_days\")\n","\n","\n","pipeline = nlp.Pipeline().setStages([\n","    documentAssembler,\n","    documentHasher,\n","    tokenizer,\n","    embeddings,\n","    clinical_ner,\n","    ner_converter,\n","    de_identification\n","\n","])\n","\n","empty_data = spark.createDataFrame([[\"\", \"\"]]).toDF(\"text\", \"patientID\")\n","\n","pipeline_model = pipeline.fit(empty_data)"],"metadata":{"id":"adwQHjyDT2M7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Checking the results"],"metadata":{"id":"TuYzT57LUlZ4"}},{"cell_type":"code","source":["output = pipeline_model.transform(my_input_df)\n","\n","output.select('patientID','text', 'deid_text.result', 'shift_days').show(truncate = False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YjNY7m2fT2Er","executionInfo":{"status":"ok","timestamp":1718061037733,"user_tz":180,"elapsed":1808,"user":{"displayName":"David Cecchini","userId":"15563969817876100862"}},"outputId":"468abc09-3a21-4e85-87fe-391a0d744b69"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+----------------------------------------+--------------------------------------------+----------+\n","|patientID|text                                    |result                                      |shift_days|\n","+---------+----------------------------------------+--------------------------------------------+----------+\n","|A001     |Chris Brown was discharged on 10/02/2022|[Marinell Siad was discharged on 10/11/2022]|9         |\n","|A001     |Mark White was discharged on 02/28/2020 |[Florance Hun was discharged on 03/08/2020] |9         |\n","|A002     |John was discharged on 03/15/2022       |[Rosaura Comp was discharged on 02/16/2022] |-27       |\n","|A002     |John Moore was discharged on 12/31/2022 |[Sammy Crisp was discharged on 12/04/2022]  |-27       |\n","+---------+----------------------------------------+--------------------------------------------+----------+\n","\n"]}]},{"cell_type":"markdown","source":["As seen above, the range of the shifted days is 60."],"metadata":{"id":"rzpTNN2xUrhi"}},{"cell_type":"markdown","source":["### `setSeed`"],"metadata":{"id":"w7RsXQ-HU5Wo"}},{"cell_type":"markdown","source":["This parameter is used in order to set the seed for random number generator."],"metadata":{"id":"mmDVUIU7WlMj"}},{"cell_type":"markdown","source":["Now, we will fit/transform the pipeline with `setSeed(100)` parameter 2 times consecutively in order to see the effect of the parameter."],"metadata":{"id":"HPx-KQfjWrVy"}},{"cell_type":"code","source":["documentHasher = medical.DocumentHashCoder()\\\n","    .setInputCols(\"document\")\\\n","    .setOutputCol(\"document2\")\\\n","    .setPatientIdColumn(\"patientID\")\\\n","    .setRangeDays(100)\\\n","    .setNewDateShift(\"shift_days\")\\\n","    .setSeed(100)\n","\n","\n","pipeline = nlp.Pipeline().setStages([\n","    documentAssembler,\n","    documentHasher,\n","    tokenizer,\n","    embeddings,\n","    clinical_ner,\n","    ner_converter,\n","    de_identification\n","\n","])\n","\n","empty_data = spark.createDataFrame([[\"\", \"\"]]).toDF(\"text\", \"patientID\")\n","\n","pipeline_model = pipeline.fit(empty_data)"],"metadata":{"id":"gbighLV-U5Hw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["output = pipeline_model.transform(my_input_df)\n","\n","output.select('patientID','text', 'deid_text.result', 'shift_days').show(truncate = False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s3KrIDaKU5CA","executionInfo":{"status":"ok","timestamp":1718061040544,"user_tz":180,"elapsed":2156,"user":{"displayName":"David Cecchini","userId":"15563969817876100862"}},"outputId":"b7590851-1079-436f-f01c-56b5a7bfb5e5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+----------------------------------------+--------------------------------------------+----------+\n","|patientID|text                                    |result                                      |shift_days|\n","+---------+----------------------------------------+--------------------------------------------+----------+\n","|A001     |Chris Brown was discharged on 10/02/2022|[Marinell Siad was discharged on 09/27/2022]|-5        |\n","|A001     |Mark White was discharged on 02/28/2020 |[Florance Hun was discharged on 02/23/2020] |-5        |\n","|A002     |John was discharged on 03/15/2022       |[Rosaura Comp was discharged on 04/13/2022] |29        |\n","|A002     |John Moore was discharged on 12/31/2022 |[Sammy Crisp was discharged on 01/29/2023]  |29        |\n","+---------+----------------------------------------+--------------------------------------------+----------+\n","\n"]}]},{"cell_type":"markdown","source":["Now, we will fit/transform the pipeline again and see if the results are consistent."],"metadata":{"id":"7LRP-tgUX3NG"}},{"cell_type":"code","source":["pipeline_model = pipeline.fit(empty_data)\n","\n","output = pipeline_model.transform(my_input_df)\n","output.select('patientID','text', 'deid_text.result', 'shift_days').show(truncate = False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-0YdeYryV67S","executionInfo":{"status":"ok","timestamp":1718061043476,"user_tz":180,"elapsed":2935,"user":{"displayName":"David Cecchini","userId":"15563969817876100862"}},"outputId":"6f17677f-3f79-4000-d515-026a389c1012"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+----------------------------------------+--------------------------------------------+----------+\n","|patientID|text                                    |result                                      |shift_days|\n","+---------+----------------------------------------+--------------------------------------------+----------+\n","|A001     |Chris Brown was discharged on 10/02/2022|[Marinell Siad was discharged on 09/27/2022]|-5        |\n","|A001     |Mark White was discharged on 02/28/2020 |[Florance Hun was discharged on 02/23/2020] |-5        |\n","|A002     |John was discharged on 03/15/2022       |[Rosaura Comp was discharged on 04/13/2022] |29        |\n","|A002     |John Moore was discharged on 12/31/2022 |[Sammy Crisp was discharged on 01/29/2023]  |29        |\n","+---------+----------------------------------------+--------------------------------------------+----------+\n","\n"]}]},{"cell_type":"markdown","source":["As seen above, we shifted the days consistently in the 2 pipelines since we set the `setSeed()` parameter."],"metadata":{"id":"_y6tmJ-hYIqQ"}},{"cell_type":"markdown","source":["### `setDateShiftColumn`"],"metadata":{"id":"jDgFf_hhHFc8"}},{"cell_type":"markdown","source":["So far, we shifted days according to ID column, we can specify shifting values with another column by using `setDateShiftColumn`."],"metadata":{"id":"8Ms6WWJlQS5y"}},{"cell_type":"markdown","source":["Generating a sample dataframe with date shifting column"],"metadata":{"id":"5GR5Q7_rQc-A"}},{"cell_type":"code","source":["data = pd.DataFrame(\n","    {'patientID' : ['A001', 'A001', 'A002', 'A002'],\n","     'text' : ['Chris Brown was discharged on 10/02/2022',\n","               'Mark White was discharged on 02/28/2020',\n","               'John was discharged on 03/15/2022',\n","               'John Moore was discharged on 12/31/2022'\n","              ],\n","     'dateshift' : ['10', '10', '30', '30']\n","    }\n",")\n","\n","my_input_df = spark.createDataFrame(data)\n","\n","my_input_df.show(truncate=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uriLSAhLAWbw","executionInfo":{"status":"ok","timestamp":1718061043941,"user_tz":180,"elapsed":470,"user":{"displayName":"David Cecchini","userId":"15563969817876100862"}},"outputId":"3237fab8-5817-4ae8-a05f-e638e5555235"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+----------------------------------------+---------+\n","|patientID|text                                    |dateshift|\n","+---------+----------------------------------------+---------+\n","|A001     |Chris Brown was discharged on 10/02/2022|10       |\n","|A001     |Mark White was discharged on 02/28/2020 |10       |\n","|A002     |John was discharged on 03/15/2022       |30       |\n","|A002     |John Moore was discharged on 12/31/2022 |30       |\n","+---------+----------------------------------------+---------+\n","\n"]}]},{"cell_type":"markdown","source":["Now, we will set `setNewDateShift(\"dateshift\")`"],"metadata":{"id":"pUndJRI4QoZy"}},{"cell_type":"code","source":["documentHasher = medical.DocumentHashCoder()\\\n","    .setInputCols(\"document\")\\\n","    .setOutputCol(\"document2\")\\\n","    .setDateShiftColumn(\"dateshift\")\n","\n","pipeline = nlp.Pipeline().setStages([\n","    documentAssembler,\n","    documentHasher,\n","    tokenizer,\n","    embeddings,\n","    clinical_ner,\n","    ner_converter,\n","    de_identification\n","\n","])\n","\n","empty_data = spark.createDataFrame([[\"\", \"\", \"\"]]).toDF(\"patientID\",\"text\", \"dateshift\")\n","\n","pipeline_col_model = pipeline.fit(empty_data)"],"metadata":{"id":"HSwSbgTjQjvo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Checking results"],"metadata":{"id":"LAWYr3l4RRfQ"}},{"cell_type":"code","source":["output = pipeline_col_model.transform(my_input_df)\n","\n","output.select('text', 'dateshift', 'deid_text.result').show(truncate = False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hNFqG18RRB-H","executionInfo":{"status":"ok","timestamp":1718061048212,"user_tz":180,"elapsed":3373,"user":{"displayName":"David Cecchini","userId":"15563969817876100862"}},"outputId":"907bf408-0941-4e6d-bbed-2660fc5a678e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------------------------------------+---------+--------------------------------------------+\n","|text                                    |dateshift|result                                      |\n","+----------------------------------------+---------+--------------------------------------------+\n","|Chris Brown was discharged on 10/02/2022|10       |[Marinell Siad was discharged on 10/12/2022]|\n","|Mark White was discharged on 02/28/2020 |10       |[Florance Hun was discharged on 03/09/2020] |\n","|John was discharged on 03/15/2022       |30       |[Rosaura Comp was discharged on 04/14/2022] |\n","|John Moore was discharged on 12/31/2022 |30       |[Sammy Crisp was discharged on 01/30/2023]  |\n","+----------------------------------------+---------+--------------------------------------------+\n","\n"]}]},{"cell_type":"markdown","source":["As seen above, we shifted days according to the \"dateshift\" column."],"metadata":{"id":"V92EwadHRoJt"}}],"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}