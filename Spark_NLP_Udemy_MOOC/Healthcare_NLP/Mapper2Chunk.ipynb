{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wAEGx0xMKi0I"
   },
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZVgVsFdhK38c"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/Mapper2Chunk.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jThnbMmqK-AV"
   },
   "source": [
    "# **üìú Mapper2Chunk**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yJmmdeF4LCy_"
   },
   "source": [
    "This notebook will cover the different parameters and usages of `Mapper2Chunk`.\n",
    "\n",
    "**üìñ Learning Objectives:**\n",
    "\n",
    "1. Understand how this annotator converts 'LABELED_DEPENDENCY' type annotations\n",
    "into 'CHUNK' type.\n",
    "\n",
    "2. Learn how to create a new chunk-type column compatible with annotators that use chunk type as input.\n",
    "\n",
    "3. Customize your chunk-type annotations by using the different parameters of the annotator.\n",
    "\n",
    "**üîó Helpful Links:**\n",
    "\n",
    "- Reference Documentation: [Mapper2Chunk](https://nlp.johnsnowlabs.com/docs/en/licensed_annotators#mapper2chunk)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YumFISpeG2RE"
   },
   "source": [
    "## **üé¨ Colab Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2_8athQEKfXE"
   },
   "outputs": [],
   "source": [
    "# Install the johnsnowlabs library to access Spark-NLP for Healthcare\n",
    "! pip install -q johnsnowlabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7T3Uk4oxG9Ay"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "print('Please Upload your John Snow Labs License using the button below')\n",
    "license_keys = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 83454,
     "status": "ok",
     "timestamp": 1724179832285,
     "user": {
      "displayName": "Akar √ñzt√ºrk",
      "userId": "07602883577262601067"
     },
     "user_tz": -120
    },
    "id": "jj-Uf8p_Hwyn",
    "outputId": "2aed087f-cf1c-4878-cabf-224c5a92269e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üëå Detected license file /content/license_keys.json\n",
      "üö® Outdated Medical Secrets in license file. Version=5.4.0.PR but should be Version=5.4.0\n",
      "üö® Outdated OCR Secrets in license file. Version=5.3.2 but should be Version=5.4.0\n",
      "üìã Stored John Snow Labs License in /root/.johnsnowlabs/licenses/license_number_0_for_Spark-Healthcare_Spark-OCR.json\n",
      "üë∑ Setting up  John Snow Labs home in /root/.johnsnowlabs, this might take a few minutes.\n",
      "Downloading üêç+üöÄ Python Library spark_nlp-5.4.0-py2.py3-none-any.whl\n",
      "Downloading üêç+üíä Python Library spark_nlp_jsl-5.4.0-py3-none-any.whl\n",
      "Downloading ü´ò+üöÄ Java Library spark-nlp-assembly-5.4.0.jar\n",
      "Downloading ü´ò+üíä Java Library spark-nlp-jsl-5.4.0.jar\n",
      "üôÜ JSL Home setup in /root/.johnsnowlabs\n",
      "Running \"/usr/bin/python3 -m pip install https://pypi.johnsnowlabs.com/[LIB_SECRET]/spark-nlp-jsl/spark_nlp_jsl-5.4.0-py3-none-any.whl --force-reinstall\"\n",
      "Installed 1 products:\n",
      "üíä Spark-Healthcare==5.4.0 installed! ‚úÖ Heal the planet with NLP! \n"
     ]
    }
   ],
   "source": [
    "from johnsnowlabs import nlp, medical\n",
    "\n",
    "# After uploading your license run this to install all licensed Python Wheels and pre-download Jars the Spark Session JVM\n",
    "nlp.settings.enforce_versions=False\n",
    "nlp.install(refresh_install=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8704,
     "status": "ok",
     "timestamp": 1724179856789,
     "user": {
      "displayName": "Akar √ñzt√ºrk",
      "userId": "07602883577262601067"
     },
     "user_tz": -120
    },
    "id": "lmc6gblCH1O-",
    "outputId": "1968aa69-de06-4842-da93-7425471c4ae7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üëå Detected license file /content/license_keys.json\n",
      "üëå Launched \u001b[92mcpu optimized\u001b[39m session with with: üöÄSpark-NLP==5.4.0, üíäSpark-Healthcare==5.4.0, running on ‚ö° PySpark==3.4.0\n"
     ]
    }
   ],
   "source": [
    "# Automatically load license data and start a session with all jars user has access to\n",
    "spark = nlp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "executionInfo": {
     "elapsed": 1384,
     "status": "ok",
     "timestamp": 1724179862195,
     "user": {
      "displayName": "Akar √ñzt√ºrk",
      "userId": "07602883577262601067"
     },
     "user_tz": -120
    },
    "id": "C6LVDlqbH22z",
    "outputId": "00b246d9-d189-4ad0-c9a7-15fe773166af"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://1061b887e2d5:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>John-Snow-Labs-Spark-Session üöÄ with Jars for: üöÄSpark-NLP==5.4.0, üíäSpark-Healthcare==5.4.0, running on ‚ö° PySpark==3.4.0</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f0f1d96b6a0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CzXezgtWH5lM"
   },
   "source": [
    "## **üñ®Ô∏è Input/Output Annotation Types**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MaEWIpCOH7Rw"
   },
   "source": [
    "- Input: `LABELED_DEPENDENCY`\n",
    "\n",
    "- Output: `CHUNK`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JLmGxyE1IAIS"
   },
   "source": [
    "## **üîé Parameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65LskbRqIFDP"
   },
   "source": [
    "**Parameters**:\n",
    "\n",
    "- **inputCols**: Input annotation columns, typically `[\"relations\"]`, containing `LABELED_DEPENDENCY` type annotations from `ChunkMapper`.\n",
    "\n",
    "- **outputCol**: Name of the output column that will store the resulting `CHUNK` annotations.\n",
    "\n",
    "- **filterNoneValues**: Whether to filter out `NONE` or empty values when converting labeled dependencies to chunks. Default: `False`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uhwe9UlhIIYU"
   },
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DTqY3aF3M2M5"
   },
   "outputs": [],
   "source": [
    "text = \"Patient resting in bed. Patient given azithromycin without any difficulty. Patient denies nausea at this time. Zofran declined. Patient is also having intermittent sweating\"\n",
    "data = spark.createDataFrame([[text]]).toDF(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8140,
     "status": "ok",
     "timestamp": 1724181526771,
     "user": {
      "displayName": "Akar √ñzt√ºrk",
      "userId": "07602883577262601067"
     },
     "user_tz": -120
    },
    "id": "SUcNYIk9H93W",
    "outputId": "03e51e56-0096-4616-b06d-635efd1ce557"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings_clinical download started this may take some time.\n",
      "Approximate size to download 1.6 GB\n",
      "[OK!]\n",
      "ner_jsl download started this may take some time.\n",
      "[OK!]\n",
      "drug_action_treatment_mapper download started this may take some time.\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "documentAssembler = nlp.DocumentAssembler() \\\n",
    "  .setInputCol(\"text\") \\\n",
    "  .setOutputCol(\"document\")\n",
    "\n",
    "sentenceDetector = nlp.SentenceDetector() \\\n",
    "  .setInputCols([\"document\"]) \\\n",
    "  .setOutputCol(\"sentence\")\n",
    "\n",
    "tokenizer = nlp.Tokenizer() \\\n",
    "  .setInputCols([\"sentence\"]) \\\n",
    "  .setOutputCol(\"token\")\n",
    "\n",
    "word_embeddings = nlp.WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\") \\\n",
    "  .setInputCols([\"sentence\", \"token\"]) \\\n",
    "  .setOutputCol(\"embeddings\")\n",
    "\n",
    "clinical_ner = medical.NerModel.pretrained(\"ner_jsl\", \"en\", \"clinical/models\") \\\n",
    "  .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "  .setOutputCol(\"ner\")\n",
    "\n",
    "ner_converter = medical.NerConverterInternal() \\\n",
    "  .setInputCols([\"sentence\", \"token\", \"ner\"]) \\\n",
    "  .setOutputCol(\"ner_chunk\")\n",
    "\n",
    "chunkMapper = medical.ChunkMapperModel.pretrained(\"drug_action_treatment_mapper\", \"en\", \"clinical/models\") \\\n",
    "  .setInputCols([\"ner_chunk\"]) \\\n",
    "  .setOutputCol(\"relations\") \\\n",
    "  .setRels([\"action\"])\n",
    "\n",
    "pipeline = nlp.Pipeline(\n",
    "    stages=[\n",
    "      documentAssembler,\n",
    "      sentenceDetector,\n",
    "      tokenizer,\n",
    "      word_embeddings,\n",
    "      clinical_ner,\n",
    "      ner_converter,\n",
    "      chunkMapper\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RqWSvHTYM9v5"
   },
   "outputs": [],
   "source": [
    "result = pipeline.fit(data).transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 995,
     "status": "ok",
     "timestamp": 1724181528410,
     "user": {
      "displayName": "Akar √ñzt√ºrk",
      "userId": "07602883577262601067"
     },
     "user_tz": -120
    },
    "id": "e8mniLnqNN-B",
    "outputId": "4cc7bc7c-5cb8-487f-c763-47c7bde4719b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------+----------------------------------------------------------------------------------------------------+\n",
      "|result                                                 |annotatorType                                                                                       |\n",
      "+-------------------------------------------------------+----------------------------------------------------------------------------------------------------+\n",
      "|[bactericidal, antiemetic, anti-abstinence, NONE, NONE]|[labeled_dependency, labeled_dependency, labeled_dependency, labeled_dependency, labeled_dependency]|\n",
      "+-------------------------------------------------------+----------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.selectExpr(\"relations.result\", \"relations.annotatorType\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CXSD3K9mNSVY"
   },
   "source": [
    "### `setFilterNoneValues`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2mFQuDhvM9uG"
   },
   "outputs": [],
   "source": [
    "mapper2chunk = medical.Mapper2Chunk() \\\n",
    "  .setInputCols([\"relations\"]) \\\n",
    "  .setOutputCol(\"chunk\") \\\n",
    "  .setFilterNoneValues(True)\n",
    "\n",
    "pipeline = nlp.Pipeline(\n",
    "    stages=[\n",
    "      documentAssembler,\n",
    "      sentenceDetector,\n",
    "      tokenizer,\n",
    "      word_embeddings,\n",
    "      clinical_ner,\n",
    "      ner_converter,\n",
    "      chunkMapper,\n",
    "      mapper2chunk\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8uXcCvUnL7QI"
   },
   "outputs": [],
   "source": [
    "result = pipeline.fit(data).transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1454,
     "status": "ok",
     "timestamp": 1724181309089,
     "user": {
      "displayName": "Akar √ñzt√ºrk",
      "userId": "07602883577262601067"
     },
     "user_tz": -120
    },
    "id": "sZ5BWzkUH6Ki",
    "outputId": "0e8679b3-3652-436b-d657-bad303b295a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------+---------------------+\n",
      "|result                                     |annotatorType        |\n",
      "+-------------------------------------------+---------------------+\n",
      "|[bactericidal, antiemetic, anti-abstinence]|[chunk, chunk, chunk]|\n",
      "+-------------------------------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.selectExpr(\"chunk.result\", \"chunk.annotatorType\").show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
