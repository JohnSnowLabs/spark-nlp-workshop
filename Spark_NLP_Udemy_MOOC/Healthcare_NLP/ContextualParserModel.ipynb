{"cells":[{"cell_type":"markdown","metadata":{"id":"sXatvRX899i0"},"source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"]},{"cell_type":"markdown","metadata":{},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/ContextualParserModel.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"AOn8d1tcBkK3"},"source":["# **ContextualParserModel**"]},{"cell_type":"markdown","metadata":{"id":"WimihSwD3vtH"},"source":["This notebook will cover the different parameters and usages of `ContextualParserModel` annotator.\n","\n","**ğŸ“– Learning Objectives:**\n","\n","1. Understand how to use `ContextualParserModel`.\n","\n","2. Become comfortable using the different parameters of the annotator.\n","\n","3. Train a `ContextualParserApproach` annotator and use that model with `ContextualParserModel` in the future.\n","\n","\n","**ğŸ”— Helpful Links:**\n","\n","- Documentation : [ContextualParserModel](https://nlp.johnsnowlabs.com/docs/en/licensed_annotators#contextualparser)\n","\n","- Python Docs : [ContextualParserModel](https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/context/contextual_parser/index.html#sparknlp_jsl.annotator.context.contextual_parser.ContextualParserModel)\n","\n","- Scala Docs : [ContextualParserModel](https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/context/ContextualParserModel.html)\n","\n","- For extended examples of usage, see the [Spark NLP Workshop repository](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/healthcare-nlp/01.5.Contextual_Parser_Rule_Based_NER.ipynb)."]},{"cell_type":"markdown","metadata":{"id":"qL9lcISyFSLv"},"source":["## **ğŸ“œ Background**\n"]},{"cell_type":"markdown","metadata":{"id":"TjDKOoZ4Fc8G"},"source":["`ContextualParser` annotator extracts entities from texts based on pattern matching. It provides more functionality than its open-source counterpart `EntityRuler` by allowing users to customize specific characteristics for pattern matching.\n","\n","It allows setting regex rules for full and partial matches, a dictionary with normalizing options, and context parameters to take into account specific conditions such as token distances.\n","\n","`ContextualParserApproach` annotator learns the patterns given by JSON/TSV/CSV file to define a new `ContextualParserModel`."]},{"cell_type":"markdown","metadata":{"id":"MfkkKkbVF309"},"source":["## **ğŸ¬ Colab Setup**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":67111,"status":"ok","timestamp":1718057635676,"user":{"displayName":"David Cecchini","userId":"15563969817876100862"},"user_tz":180},"id":"iMkMQtZNF2n-","outputId":"24bfe1d7-bd4f-429d-d17e-83ef937b912d"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m265.2/265.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m565.0/565.0 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m676.2/676.2 kB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m95.6/95.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.9/66.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m150.3/150.3 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install -q johnsnowlabs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":91},"executionInfo":{"elapsed":7067,"status":"ok","timestamp":1718057642736,"user":{"displayName":"David Cecchini","userId":"15563969817876100862"},"user_tz":180},"id":"zbUfCKmmiVCG","outputId":"710c0e06-5997-4e56-8859-16d52822a481"},"outputs":[{"name":"stdout","output_type":"stream","text":["Please Upload your John Snow Labs License using the button below\n"]},{"data":{"text/html":["\n","     <input type=\"file\" id=\"files-8f817fb1-43f7-4333-81d6-bc6f0810cc13\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-8f817fb1-43f7-4333-81d6-bc6f0810cc13\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Saving spark_nlp_for_healthcare_spark_ocr_8734_532.json to spark_nlp_for_healthcare_spark_ocr_8734_532.json\n"]}],"source":["from google.colab import files\n","print('Please Upload your John Snow Labs License using the button below')\n","license_keys = files.upload()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"NulWi4_f4GN5","outputId":"d306dae0-6d93-424e-855f-ff3d6fcd864a"},"outputs":[{"name":"stdout","output_type":"stream","text":["ğŸ‘Œ Detected license file /content/spark_nlp_for_healthcare_spark_ocr_8734_532.json\n","ğŸ“‹ Stored John Snow Labs License in /root/.johnsnowlabs/licenses/license_number_0_for_Spark-Healthcare_Spark-OCR.json\n","ğŸ‘· Setting up  John Snow Labs home in /root/.johnsnowlabs, this might take a few minutes.\n","Downloading ğŸ+ğŸš€ Python Library spark_nlp-5.3.2-py2.py3-none-any.whl\n","Downloading ğŸ+ğŸ’Š Python Library spark_nlp_jsl-5.3.2-py3-none-any.whl\n","Downloading ğŸ«˜+ğŸš€ Java Library spark-nlp-assembly-5.3.2.jar\n","Downloading ğŸ«˜+ğŸ’Š Java Library spark-nlp-jsl-5.3.2.jar\n","ğŸ™† JSL Home setup in /root/.johnsnowlabs\n","ğŸ‘Œ Detected license file /content/spark_nlp_for_healthcare_spark_ocr_8734_532.json\n","Installing /root/.johnsnowlabs/py_installs/spark_nlp_jsl-5.3.2-py3-none-any.whl to /usr/bin/python3\n","Installed 1 products:\n","ğŸ’Š Spark-Healthcare==5.3.2 installed! âœ… Heal the planet with NLP! \n"]}],"source":["from johnsnowlabs import nlp, medical\n","\n","nlp.install()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"2GLXxe1Q0Iln","outputId":"eb9d9799-c063-490a-807a-fe97dbecb184"},"outputs":[{"name":"stdout","output_type":"stream","text":["ğŸ‘Œ Detected license file /content/spark_nlp_for_healthcare_spark_ocr_8734_532.json\n","ğŸ‘Œ Launched \u001b[92mcpu optimized\u001b[39m session with with: ğŸš€Spark-NLP==5.3.2, ğŸ’ŠSpark-Healthcare==5.3.2, running on âš¡ PySpark==3.4.0\n"]}],"source":["spark = nlp.start()\n","spark"]},{"cell_type":"markdown","metadata":{"id":"9Fbbk1bqcuA5"},"source":["## **ğŸ–¨ï¸ Input/Output Annotation Types**"]},{"cell_type":"markdown","metadata":{"id":"0yFIrr5acsiU"},"source":["- Input: `DOCUMENT`, `TOKEN`\n","\n","- Output: `CHUNK`"]},{"cell_type":"markdown","metadata":{"id":"b2YJehUKMhb0"},"source":["## **ğŸ” Parameters**\n"]},{"cell_type":"markdown","metadata":{"id":"obbNJPdw2-sP"},"source":["The parameters below are the shared parameters with `ContextualParserApproach`. So you can use them as in `ContextualParserApproach`."]},{"cell_type":"markdown","metadata":{"id":"oidLDoS94asU"},"source":["- `inputCols`: The name of the columns containing the input annotations. It can read either a String column or an Array.\n","- `outputCol`: The name of the column in Document type that is generated. We can specify only one column here.\n","- `caseSensitive`: Whether to use case sensitive when matching values.\n","- `prefixAndSuffixMatch`: Whether to match both prefix and suffix to annotate the match.\n","- `optionalContextRules`: When set to true, it will output a regex match regardless of context matches.\n","- `shortestContextMatch`: When set to true, it will stop finding matches when prefix/suffix data is found in the text.\n","- `setDoExceptionHandling` : When set True, exceptions are handled. Processing continues with the next one. This comes with a performance penalty.\n","\n","All the parameters can be set using the corresponding set method in the camel case. For example, `.setInputcols()`."]},{"cell_type":"markdown","metadata":{"id":"f3JnKer_hWkb"},"source":["## Build a ContextualParser pipeline using `ContextualParserApproach` and save a `ContextualParserModel`"]},{"cell_type":"markdown","metadata":{"id":"thaF2bObwDXd"},"source":["Let's build a pipeline ContextualParser, then save the model to be used in `ContextualParserModel`"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Y4Ipms-4PwoN","outputId":"f500053d-ba2d-49c7-cebc-e4aa63f4010e"},"outputs":[{"name":"stdout","output_type":"stream","text":["City\n","New York\n","Gotham City\n","San Antonio\n","Salt Lake City"]}],"source":["# Create a dictionary to detect cities\n","cities = \"\"\"City\\nNew York\\nGotham City\\nSan Antonio\\nSalt Lake City\"\"\"\n","\n","with open('cities.tsv', 'w') as f:\n","    f.write(cities)\n","\n","# Check what dictionary looks like\n","!cat cities.tsv"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Jvi1mbqY_LeA"},"outputs":[],"source":["# Create JSON file\n","context_rules = {\n","  \"entity\": \"City\",\n","  \"ruleScope\": \"document\",\n","  \"matchScope\":\"sub-token\",\n","  \"completeMatchRegex\": \"false\",\n","  \"regex\": \"([A-Z]{1}[a-z]+ [A-Z]{1}[a-z]+)\" # Find two consecutive words in title case.\n","}\n","\n","import json\n","with open('context_rules.json', 'w') as f:\n","    json.dump(context_rules, f)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"yjQmEjWNQHvx"},"outputs":[],"source":["# Build pipeline\n","document_assembler = nlp.DocumentAssembler() \\\n","    .setInputCol(\"text\") \\\n","    .setOutputCol(\"document\")\n","\n","sentence_detector = nlp.SentenceDetector() \\\n","    .setInputCols([\"document\"]) \\\n","    .setOutputCol(\"sentence\")\n","\n","tokenizer = nlp.Tokenizer() \\\n","    .setInputCols([\"sentence\"]) \\\n","    .setOutputCol(\"token\")\n","\n","contextual_parser = medical.ContextualParserApproach() \\\n","    .setInputCols([\"sentence\", \"token\"])\\\n","    .setOutputCol(\"entity\")\\\n","    .setJsonPath(\"context_rules.json\")\\\n","    .setCaseSensitive(True)\\\n","    .setDictionary('cities.tsv', options={\"orientation\":\"vertical\"})\n","\n","chunk_converter = medical.ChunkConverter() \\\n","    .setInputCols([\"entity\"]) \\\n","    .setOutputCol(\"ner_chunk\")\n","\n","pipeline = nlp.Pipeline(stages=[\n","        document_assembler,\n","        sentence_detector,\n","        tokenizer,\n","        contextual_parser,\n","        chunk_converter,\n","        ])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HxPVaa4fYCb5"},"outputs":[],"source":["# Create a lightpipeline model\n","empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n","\n","model = pipeline.fit(empty_data)\n","\n","light_model = nlp.LightPipeline(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"tmoR-Qh5alXt"},"outputs":[],"source":["sample_text = \"Peter Parker is a nice guy and lives in New York. Bruce Wayne is also a nice guy and lives in San Antonio and Gotham City. They met at salt lake city.\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SQRRZ4mIiLTl"},"outputs":[],"source":["# Annotate the sample text\n","annotations = light_model.fullAnnotate(sample_text)[0]\n","\n","[item.result for item in annotations[\"entity\"]]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mE_OFNVaiUYM"},"outputs":[],"source":["visualiser = nlp.viz.NerVisualizer()\n","\n","visualiser.display(annotations, label_col='ner_chunk', document_col='document')"]},{"cell_type":"markdown","metadata":{"id":"0nOSvWMa5iEB"},"source":["Now let's save the `ContextualParserApproach` model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u_lC_FgJ5Mkj"},"outputs":[],"source":["model.stages[-2].write().overwrite().save('models/custom_parser_model')"]},{"cell_type":"markdown","metadata":{"id":"FGUoconq56zQ"},"source":["Now re-use the saved model in another pipeline with the `ContextualParserModel`  annotator and load function."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J29l9q3S55Vx"},"outputs":[],"source":["custom_parser = medical.ContextualParserModel.load('models/custom_parser_model')\\\n","    # .setInputCols([\"sentence\", \"token\"])\\\n","    # .setOutputCol(\"entity\")\\\n","\n","parser_pipeline = nlp.Pipeline(stages=[\n","        document_assembler,\n","        sentence_detector,\n","        tokenizer,\n","        custom_parser, # load saved model\n","        chunk_converter,\n","        ])\n","\n","# Create a lightpipeline model\n","empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n","\n","parser_model = parser_pipeline.fit(empty_data)\n","\n","light_parser_model = nlp.LightPipeline(parser_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"geQSGxMr6j75","outputId":"ae2494a7-a131-4fc9-c52e-227f3fb83c4d"},"outputs":[{"data":{"text/html":["\n","<style>\n","    @import url('https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700&display=swap');\n","    @import url('https://fonts.googleapis.com/css2?family=Vistol Regular:wght@300;400;500;600;700&display=swap');\n","    \n","    .spark-nlp-display-scroll-entities {\n","        border: 1px solid #E7EDF0;\n","        border-radius: 3px;\n","        text-align: justify;\n","        \n","    }\n","    .spark-nlp-display-scroll-entities span {  \n","        font-size: 14px;\n","        line-height: 24px;\n","        color: #536B76;\n","        font-family: 'Montserrat', sans-serif !important;\n","    }\n","    \n","    .spark-nlp-display-entity-wrapper{\n","    \n","        display: inline-grid;\n","        text-align: center;\n","        border-radius: 4px;\n","        margin: 0 2px 5px 2px;\n","        padding: 1px\n","    }\n","    .spark-nlp-display-entity-name{\n","        font-size: 14px;\n","        line-height: 24px;\n","        font-family: 'Montserrat', sans-serif !important;\n","        \n","        background: #f1f2f3;\n","        border-width: medium;\n","        text-align: center;\n","        \n","        font-weight: 400;\n","        \n","        border-radius: 5px;\n","        padding: 2px 5px;\n","        display: block;\n","        margin: 3px 2px;\n","    \n","    }\n","    .spark-nlp-display-entity-type{\n","        font-size: 14px;\n","        line-height: 24px;\n","        color: #ffffff;\n","        font-family: 'Montserrat', sans-serif !important;\n","        \n","        text-transform: uppercase;\n","        \n","        font-weight: 500;\n","\n","        display: block;\n","        padding: 3px 5px;\n","    }\n","    \n","    .spark-nlp-display-entity-resolution{\n","        font-size: 14px;\n","        line-height: 24px;\n","        color: #ffffff;\n","        font-family: 'Vistol Regular', sans-serif !important;\n","        \n","        text-transform: uppercase;\n","        \n","        font-weight: 500;\n","\n","        display: block;\n","        padding: 3px 5px;\n","    }\n","    \n","    .spark-nlp-display-others{\n","        font-size: 14px;\n","        line-height: 24px;\n","        font-family: 'Montserrat', sans-serif !important;\n","        \n","        font-weight: 400;\n","    }\n","\n","</style>\n"," <span class=\"spark-nlp-display-others\" style=\"background-color: white\">Peter Parker is a nice guy and lives in </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #C5B719\"><span class=\"spark-nlp-display-entity-name\">New York </span><span class=\"spark-nlp-display-entity-type\">City</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">. Bruce Wayne is also a nice guy and lives in </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #C5B719\"><span class=\"spark-nlp-display-entity-name\">San Antonio </span><span class=\"spark-nlp-display-entity-type\">City</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> and </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #C5B719\"><span class=\"spark-nlp-display-entity-name\">Gotham City </span><span class=\"spark-nlp-display-entity-type\">City</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\">. They met at salt lake city.</span></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["annotations_parser = light_parser_model.fullAnnotate(sample_text)[0]\n","visualiser.display(annotations_parser, label_col='ner_chunk', document_col='document')\n"]},{"cell_type":"markdown","metadata":{"id":"SPQG28K78ZP_"},"source":["We get the same result as the previous model. Here, with saving the model, we all saved model parameters, settings, JSON, and dictionary files. In `ContextualParserModel`, we only loaded the saved model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uxP2RAmB4luz"},"outputs":[],"source":["[item.result for item in annotations_parser[\"entity\"]]"]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[{"file_id":"1uRpqjOSXr26Fl9fZCVUJpGxLInZ0Icbi","timestamp":1684556881706},{"file_id":"1L8GdQ-yorjVk_V8Um6Rw6aEzFVT31OCO","timestamp":1683516961200},{"file_id":"1VVV4jTagH47UZiKFqXoP-Abq5ozZM1BV","timestamp":1672918708428},{"file_id":"https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/2.Text_Preprocessing_with_SparkNLP_Annotators_Transformers.ipynb","timestamp":1671914287039}],"toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":0}
