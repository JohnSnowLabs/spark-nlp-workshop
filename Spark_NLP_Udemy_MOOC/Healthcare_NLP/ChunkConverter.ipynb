{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n"],"metadata":{"id":"Dm9w05ifTEnq"}},{"cell_type":"markdown","source":["# **ChunkConverter**"],"metadata":{"id":"bewC1SWN-6jB"}},{"cell_type":"markdown","source":["This notebook will cover the different parameters and usages of `ChunkConverter` annotator.\n","\n","**ðŸ“– Learning Objectives:**\n","\n","1. Understand how to use `ChunkConverter`.\n","\n","2. Become comfortable using the different parameters of the annotator.\n","\n","\n","**ðŸ”— Helpful Links:**\n","\n","- Documentation : [ChunkConverter](https://nlp.johnsnowlabs.com/docs/en/licensed_annotators#chunkconverter)\n","\n","- Python Docs : [ChunkConverter](https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/chunker/chunk_converter/index.html#sparknlp_jsl.annotator.chunker.chunk_converter.ChunkConverter)\n","\n","- Scala Docs : [ChunkConverter](https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/chunker/ChunkConverter.html)\n","\n"],"metadata":{"id":"m048uDkB69Rv"}},{"cell_type":"markdown","source":["## **ðŸ“œ Background**\n"],"metadata":{"id":"B9Wo54MT8jKU"}},{"cell_type":"markdown","source":["`ChunkConverter` convert chunks from regexMatcher to chunks with an entity in the metadata. Use the identifier or field as a entity.\n","\n","This annotator is important when the user wants to merge entities identified by NER models together with rules-based matching used by the RegexMathcer annotator. In the following steps of the pipeline, all the identified entities can be treated in a unified field.\n"],"metadata":{"id":"yaDBNKJsAovm"}},{"cell_type":"markdown","source":["## **ðŸŽ¬ Colab Setup**"],"metadata":{"id":"A4hMnkhd_ik9"}},{"cell_type":"code","source":["# Install the johnsnowlabs library to access Spark-NLP for Healthcare\n","! pip install -q johnsnowlabs"],"metadata":{"id":"xrdvNxjD_yQI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import files\n","print('Please Upload your John Snow Labs License using the button below')\n","license_keys = files.upload()"],"metadata":{"id":"3WU-z_e8jYpO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from johnsnowlabs import nlp, medical\n","\n","# After uploading your license run this to install all licensed Python Wheels and pre-download Jars the Spark Session JVM\n","nlp.install()"],"metadata":{"id":"bUDfeNzUjaO-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from johnsnowlabs import nlp, medical\n","import pandas as pd\n","\n","# Automatically load license data and start a session with all jars user has access to\n","spark = nlp.start()"],"metadata":{"id":"19b2mPsZjbI3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["spark"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":237},"id":"aFMD5KCS9Xih","executionInfo":{"status":"ok","timestamp":1684857290585,"user_tz":-180,"elapsed":6,"user":{"displayName":"Monster C","userId":"08787989274818793476"}},"outputId":"5f2b1b71-9128-4a59-f8ce-c092b47dd9b4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<pyspark.sql.session.SparkSession at 0x7f4992e6df00>"],"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://7e9dc8315314:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.1.2</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>John-Snow-Labs-Spark-Session ðŸš€ with Jars for: ðŸš€Spark-NLP==4.4.1, ðŸ’ŠSpark-Healthcare==4.4.1, running on âš¡ PySpark==3.1.2</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["from pyspark.sql import DataFrame\n","import pyspark.sql.functions as F\n","import pyspark.sql.types as T"],"metadata":{"id":"1SquZfvA_OAX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **ðŸ–¨ï¸ Input/Output Annotation Types**"],"metadata":{"id":"fdTHvykf8wni"}},{"cell_type":"markdown","source":["- Input: `DOCUMENT`, `CHUNK`\n","\n","- Output: `CHUNK`"],"metadata":{"id":"ejYVNcX98y5j"}},{"cell_type":"markdown","source":["## **ðŸ”Ž Parameters**\n"],"metadata":{"id":"YVa72oJd9Bk_"}},{"cell_type":"markdown","source":["- `inputCols`: The name of the columns containing the input annotations. It can read either a String column or an Array.\n","- `outputCol`: The name of the column in Document type that is generated. We can specify only one column here.\n","\n","\n","All the parameters can be set using the corresponding set method in camel case. For example, `.setInputcols()`."],"metadata":{"id":"AUbv3YL59D8Q"}},{"cell_type":"markdown","source":["### `inputCols` and `outputCol`"],"metadata":{"id":"EpBqGk7oNc3C"}},{"cell_type":"markdown","source":["Define the column names containing the `DOCUMENT` and `CHUNK` annotations needed as input to the `ChunkConverter ` and the name of the new column containg the identified entities.\n","\n","Let's define a pipeline to process raw texts into `DOCUMENT` and `CHUNK` annotations:"],"metadata":{"id":"wOGfzMDiOAXE"}},{"cell_type":"code","source":["rules = '''\n","\\b[A-Z]+(\\s+[A-Z]+)*:\\b, SECTION_HEADER\n","'''\n","\n","with open('regex_rules.txt', 'w') as f:\n","    f.write(rules)"],"metadata":{"id":"71wEG861X0U1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["document_assembler = nlp.DocumentAssembler()\\\n","    .setInputCol(\"text\")\\\n","    .setOutputCol(\"document\")\n","\n","sentence_detector =  nlp.SentenceDetector()\\\n","    .setInputCols([\"document\"])\\\n","    .setOutputCol(\"sentence\")\n","\n","regex_matcher = nlp.RegexMatcher()\\\n","    .setInputCols(\"sentence\")\\\n","    .setOutputCol(\"regex\")\\\n","    .setExternalRules(path=\"./regex_rules.txt\", delimiter=\",\"  )\n","\n","chunkConverter = medical.ChunkConverter()\\\n","    .setInputCols(\"regex\")\\\n","    .setOutputCol(\"chunk\")\n","\n","pipeline = nlp.Pipeline(\n","    stages=[\n","        document_assembler,\n","        sentence_detector,\n","        regex_matcher,\n","        regex_matcher,\n","        chunkConverter,\n","    ])\n"],"metadata":{"id":"c23AbFZ7OV6B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text = \"\"\"\n","POSTOPERATIVE DIAGNOSIS: Cervical lymphadenopathy.\n","PROCEDURE:  Excisional biopsy of right cervical lymph node.\n","ANESTHESIA:  General endotracheal anesthesia.\n","Specimen:  Right cervical lymph node.\n","EBL: 10 cc.\n","COMPLICATIONS:  None.\n","FINDINGS: Enlarged level 2 lymph node was identified and removed and sent for pathologic examination.\n","FLUIDS:  Please see anesthesia report.\n","URINE OUTPUT:  None recorded during the case.\n","INDICATIONS FOR PROCEDURE:  This is a 43-year-old female with a several-year history of persistent cervical lymphadenopathy. She reports that it is painful to palpation on the right and has had multiple CT scans as well as an FNA which were all nondiagnostic. After risks and benefits of surgery were discussed with the patient, an informed consent was obtained. She was scheduled for an excisional biopsy of the right cervical lymph node.\n","PROCEDURE IN DETAIL:  The patient was taken to the operating room and placed in the supine position. She was anesthetized with general endotracheal anesthesia. The neck was then prepped and draped in the sterile fashion. Again, noted on palpation there was an enlarged level 2 cervical lymph node.A 3-cm horizontal incision was made over this lymph node. Dissection was carried down until the sternocleidomastoid muscle was identified. The enlarged lymph node that measured approximately 2 cm in diameter was identified and was removed and sent to Pathology for touch prep evaluation. The area was then explored for any other enlarged lymph nodes. None were identified, and hemostasis was achieved with electrocautery. A quarter-inch Penrose drain was placed in the wound.The wound was then irrigated and closed with 3-0 interrupted Vicryl sutures for a deep closure followed by a running 4-0 Prolene subcuticular suture. Mastisol and Steri-Strip were placed over the incision, and sterile bandage was applied. The patient tolerated this procedure well and was extubated without complications and transported to the recovery room in stable condition. She will return to the office tomorrow in followup to have the Penrose drain removed.\n","\"\"\"\n","\n","data = spark.createDataFrame([[text]]).toDF(\"text\")\n","\n","result = pipeline.fit(data).transform(data)\n"],"metadata":{"id":"KB0WFZo5Esw4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result_df = result.select(F.explode(F.arrays_zip(result.regex.result,\n","                                                 result.regex.metadata)).alias(\"cols\"))\\\n","                  .select(F.expr(\"cols['0']\").alias(\"regex\"),\n","                          F.expr(\"cols['1']\").alias(\"metadata\"))\n","\n","result_df.show(50, truncate=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x6VIMgc7kCRc","executionInfo":{"status":"ok","timestamp":1684858605628,"user_tz":-180,"elapsed":3262,"user":{"displayName":"Monster C","userId":"08787989274818793476"}},"outputId":"d2579a94-2be4-4dda-b2d1-ebd3d837a0a1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------------+----------------------------------------------------------+\n","|regex                     |metadata                                                  |\n","+--------------------------+----------------------------------------------------------+\n","|POSTOPERATIVE DIAGNOSIS:  |{identifier -> SECTION_HEADER, sentence -> 0, chunk -> 0} |\n","|PROCEDURE:                |{identifier -> SECTION_HEADER, sentence -> 1, chunk -> 0} |\n","|ANESTHESIA:               |{identifier -> SECTION_HEADER, sentence -> 2, chunk -> 0} |\n","|EBL:                      |{identifier -> SECTION_HEADER, sentence -> 4, chunk -> 0} |\n","|COMPLICATIONS:            |{identifier -> SECTION_HEADER, sentence -> 5, chunk -> 0} |\n","|FINDINGS:                 |{identifier -> SECTION_HEADER, sentence -> 6, chunk -> 0} |\n","|FLUIDS:                   |{identifier -> SECTION_HEADER, sentence -> 7, chunk -> 0} |\n","|URINE OUTPUT:             |{identifier -> SECTION_HEADER, sentence -> 8, chunk -> 0} |\n","|INDICATIONS FOR PROCEDURE:|{identifier -> SECTION_HEADER, sentence -> 9, chunk -> 0} |\n","|PROCEDURE IN DETAIL:      |{identifier -> SECTION_HEADER, sentence -> 13, chunk -> 0}|\n","+--------------------------+----------------------------------------------------------+\n","\n"]}]},{"cell_type":"code","source":["result_df = result.select(F.explode(F.arrays_zip(result.chunk.result,\n","                                                 result.chunk.metadata)).alias(\"cols\"))\\\n","                  .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n","                          F.expr(\"cols['1']\").alias(\"metadata\"))\n","\n","result_df.show(50, truncate=False)"],"metadata":{"id":"KfueJP-rALU_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684858522903,"user_tz":-180,"elapsed":7714,"user":{"displayName":"Monster C","userId":"08787989274818793476"}},"outputId":"8704bdd0-b2c2-4f66-d519-70d1ce4d0cca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------------+---------------------------------------------------------------------------------------------------------+\n","|chunk                     |metadata                                                                                                 |\n","+--------------------------+---------------------------------------------------------------------------------------------------------+\n","|POSTOPERATIVE DIAGNOSIS:  |{chunk -> 0, identifier -> SECTION_HEADER, ner_source -> chunk, entity -> SECTION_HEADER, sentence -> 0} |\n","|PROCEDURE:                |{chunk -> 0, identifier -> SECTION_HEADER, ner_source -> chunk, entity -> SECTION_HEADER, sentence -> 1} |\n","|ANESTHESIA:               |{chunk -> 0, identifier -> SECTION_HEADER, ner_source -> chunk, entity -> SECTION_HEADER, sentence -> 2} |\n","|EBL:                      |{chunk -> 0, identifier -> SECTION_HEADER, ner_source -> chunk, entity -> SECTION_HEADER, sentence -> 4} |\n","|COMPLICATIONS:            |{chunk -> 0, identifier -> SECTION_HEADER, ner_source -> chunk, entity -> SECTION_HEADER, sentence -> 5} |\n","|FINDINGS:                 |{chunk -> 0, identifier -> SECTION_HEADER, ner_source -> chunk, entity -> SECTION_HEADER, sentence -> 6} |\n","|FLUIDS:                   |{chunk -> 0, identifier -> SECTION_HEADER, ner_source -> chunk, entity -> SECTION_HEADER, sentence -> 7} |\n","|URINE OUTPUT:             |{chunk -> 0, identifier -> SECTION_HEADER, ner_source -> chunk, entity -> SECTION_HEADER, sentence -> 8} |\n","|INDICATIONS FOR PROCEDURE:|{chunk -> 0, identifier -> SECTION_HEADER, ner_source -> chunk, entity -> SECTION_HEADER, sentence -> 9} |\n","|PROCEDURE IN DETAIL:      |{chunk -> 0, identifier -> SECTION_HEADER, ner_source -> chunk, entity -> SECTION_HEADER, sentence -> 13}|\n","+--------------------------+---------------------------------------------------------------------------------------------------------+\n","\n"]}]},{"cell_type":"code","source":["chunkConverter.extractParamMap()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vg44awUQrv0Q","executionInfo":{"status":"ok","timestamp":1684858569829,"user_tz":-180,"elapsed":4,"user":{"displayName":"Monster C","userId":"08787989274818793476"}},"outputId":"d838bbf7-a0e7-46c9-c36d-4664d796f4da"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{Param(parent='ChunkConverter_f60ed650117b', name='lazyAnnotator', doc='Whether this AnnotatorModel acts as lazy in RecursivePipelines'): False,\n"," Param(parent='ChunkConverter_f60ed650117b', name='inputCols', doc='previous annotations columns, if renamed'): ['regex'],\n"," Param(parent='ChunkConverter_f60ed650117b', name='outputCol', doc='output annotation column. can be left default.'): 'chunk'}"]},"metadata":{},"execution_count":20}]}]}