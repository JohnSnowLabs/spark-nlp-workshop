{"cells":[{"cell_type":"markdown","metadata":{"id":"6Wfq4tie-OVj"},"source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"]},{"cell_type":"markdown","metadata":{"id":"Js6EFUIFUQlO"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/REChunkMerger.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"aQ2JWggt-UYX"},"source":["#   **ðŸ“œ REChunkMerger**\n"]},{"cell_type":"markdown","source":["The **`REChunkMerger`** annotator merges related entities into cohesive phrases, using a customizable separator."],"metadata":{"id":"7hzwkXPoKY5I"}},{"cell_type":"markdown","metadata":{"id":"e726rKETuJJr"},"source":["**ðŸ“– Learning Objectives:**\n","\n","1. Understand how to use the annotator.\n","\n","2. Become comfortable using the different parameters of the annotator.\n","\n","**ðŸ”— Helpful Links:**\n","\n","- Reference Documentation: [REChunkMerger](https://nlp.johnsnowlabs.com/docs/en/licensed_annotators)\n"]},{"cell_type":"markdown","metadata":{"id":"okhT7AcXxben"},"source":["## **ðŸŽ¬ Colab Setup**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xrdvNxjD_yQI"},"outputs":[],"source":["# Install the johnsnowlabs library to access Spark-NLP for Healthcare\n","! pip install -q johnsnowlabs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3WU-z_e8jYpO"},"outputs":[],"source":["from google.colab import files\n","print('Please Upload your John Snow Labs License using the button below')\n","license_keys = files.upload()"]},{"cell_type":"code","source":["from johnsnowlabs import nlp, medical\n","\n","# After uploading your license run this to install all licensed Python Wheels and pre-download Jars the Spark Session JVM\n","nlp.settings.enforce_versions=False\n","nlp.install(refresh_install=True)"],"metadata":{"id":"D-9lbtfHjvm7"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"19b2mPsZjbI3"},"outputs":[],"source":["# Automatically load license data and start a session with all jars user has access to\n","spark = nlp.start()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":221},"id":"aFMD5KCS9Xih","outputId":"37e7d961-3c51-422e-efc5-25f6a0892de3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<pyspark.sql.session.SparkSession at 0x7edc0ad8d750>"],"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://1a1b4b71666e:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.4.0</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>John-Snow-Labs-Spark-Session ðŸš€ with Jars for: ðŸš€Spark-NLP==5.4.1, ðŸ’ŠSpark-Healthcare==5.4.1, running on âš¡ PySpark==3.4.0</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "]},"metadata":{},"execution_count":5}],"source":["spark"]},{"cell_type":"markdown","metadata":{"id":"FBTuAaNIaE-n"},"source":["## **ðŸ–¨ï¸ Input/Output Annotation Types**"]},{"cell_type":"markdown","metadata":{"id":"wnFxBtrjaJyP"},"source":["- Input: `CHUNK`\n","\n","- Output: `CHUNK`"]},{"cell_type":"markdown","metadata":{"id":"RLbYplk2a30Z"},"source":["## **ðŸ”Ž Parameters**\n"]},{"cell_type":"markdown","metadata":{"id":"uzlkaWUZa7KN"},"source":["**Parameters**:\n","\n","- `setSeparator`: The **`setSeparator`** parameter allows users to define a custom string that will be used to separate merged entities within the output phrase.\n","\n","      \n","  "]},{"cell_type":"markdown","metadata":{"id":"ICcnDujCGv5G"},"source":["### Pipeline"]},{"cell_type":"code","source":["documenter = nlp.DocumentAssembler() \\\n","    .setInputCol(\"sentence\") \\\n","    .setOutputCol(\"document\")\n","\n","tokenizer = nlp.Tokenizer() \\\n","    .setInputCols([\"document\"]) \\\n","    .setOutputCol(\"tokens\") \\\n","\n","words_embedder = nlp.WordEmbeddingsModel() \\\n","    .pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\") \\\n","    .setInputCols([\"document\", \"tokens\"]) \\\n","    .setOutputCol(\"embeddings\")\n","\n","pos_tagger = nlp.PerceptronModel() \\\n","    .pretrained(\"pos_clinical\", \"en\", \"clinical/models\") \\\n","    .setInputCols([\"document\", \"tokens\"]) \\\n","    .setOutputCol(\"pos_tags\")\n","\n","ner_tagger = medical.NerModel() \\\n","    .pretrained(\"ner_clinical\", \"en\", \"clinical/models\") \\\n","    .setInputCols([\"document\", \"tokens\", \"embeddings\"]) \\\n","    .setOutputCol(\"ner_tags\")\n","\n","ner_converter = medical.NerConverter() \\\n","    .setInputCols([\"document\", \"tokens\", \"ner_tags\"]) \\\n","    .setOutputCol(\"ner_chunks\")\n","\n","depency_parser = nlp.DependencyParserModel() \\\n","    .pretrained(\"dependency_conllu\", \"en\") \\\n","    .setInputCols([\"document\", \"pos_tags\", \"tokens\"]) \\\n","    .setOutputCol(\"dependencies\")\n","\n","re_model = medical.RelationExtractionModel \\\n","    .pretrained(\"re_clinical\", \"en\", \"clinical/models\") \\\n","    .setCustomLabels({\"TeRP\": \"CustomLabel_TeRP\", \"TrWP\": \"CustomLabel_TeWP\"}) \\\n","    .setInputCols([\"embeddings\", \"pos_tags\", \"ner_chunks\", \"dependencies\"]) \\\n","    .setOutputCol(\"re_chunk\")\n","\n","re_chunk_merger = medical.REChunkMerger() \\\n","    .setInputCols([\"re_chunk\"]) \\\n","    .setOutputCol(\"relation_chunks\") \\\n","    .setSeparator(\" && \")\n","\n","nlpPipeline = nlp.Pipeline(\n","    stages=[\n","        documenter,\n","        tokenizer,\n","        words_embedder,\n","        pos_tagger,\n","        ner_tagger,\n","        ner_converter,\n","        depency_parser,\n","        re_model,\n","        re_chunk_merger\n","    ])\n","\n","empty_data = spark.createDataFrame([[\"\"]]).toDF(\"sentence\")\n","\n","model = nlpPipeline.fit(empty_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lR_dzXU9ZiSJ","outputId":"3ca30e25-3931-4425-9cba-20a30502b60c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["embeddings_clinical download started this may take some time.\n","Approximate size to download 1.6 GB\n","[OK!]\n","pos_clinical download started this may take some time.\n","Approximate size to download 1.5 MB\n","[OK!]\n","ner_clinical download started this may take some time.\n","[OK!]\n","dependency_conllu download started this may take some time.\n","Approximate size to download 16.7 MB\n","[OK!]\n","re_clinical download started this may take some time.\n","[OK!]\n"]}]},{"cell_type":"code","source":["text =''' 28-year-old female with a history of gestational diabetes mellitus diagnosed eight years prior to \" +\n","        \"presentation and subsequent type two diabetes mellitus ( T2DM ). '''\n","\n","result = model.transform(spark.createDataFrame([[text]]).toDF(\"sentence\"))"],"metadata":{"id":"tsxRoBcMzgp_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result.selectExpr(\"explode(relation_chunks.result) result\").show(truncate=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_cAY5c6azIZH","outputId":"2e52dcd0-6631-4eb3-b5a2-f17cd60febf4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------------------------------------------------------------------+\n","|result                                                                |\n","+----------------------------------------------------------------------+\n","|gestational diabetes mellitus && subsequent type two diabetes mellitus|\n","|gestational diabetes mellitus && T2DM                                 |\n","|subsequent type two diabetes mellitus && T2DM                         |\n","+----------------------------------------------------------------------+\n","\n"]}]},{"cell_type":"markdown","source":["**Experimenting with different separators for the same sample sentence.**"],"metadata":{"id":"kLDevg_6Oc3C"}},{"cell_type":"code","source":["re_chunk_merger = medical.REChunkMerger() \\\n","    .setInputCols([\"re_chunk\"]) \\\n","    .setOutputCol(\"relation_chunks_2\") \\\n","    .setSeparator(\" >>> \")\n","\n","nlpPipeline = nlp.Pipeline(\n","    stages=[\n","        documenter,\n","        tokenizer,\n","        words_embedder,\n","        pos_tagger,\n","        ner_tagger,\n","        ner_converter,\n","        depency_parser,\n","        re_model,\n","        re_chunk_merger\n","    ])\n","\n","empty_data = spark.createDataFrame([[\"\"]]).toDF(\"sentence\")\n","\n","model = nlpPipeline.fit(empty_data)"],"metadata":{"id":"ZV7WeRKNzKba"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result = model.transform(spark.createDataFrame([[text]]).toDF(\"sentence\"))\n","\n","result.selectExpr(\"explode(relation_chunks_2.result) result\").show(truncate=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ixDaWpaDzKY8","outputId":"ba01fe5d-046f-477a-e699-6b95001a1c46"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------------------------------------------------------------------+\n","|result                                                                 |\n","+-----------------------------------------------------------------------+\n","|gestational diabetes mellitus >>> subsequent type two diabetes mellitus|\n","|gestational diabetes mellitus >>> T2DM                                 |\n","|subsequent type two diabetes mellitus >>> T2DM                         |\n","+-----------------------------------------------------------------------+\n","\n"]}]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}