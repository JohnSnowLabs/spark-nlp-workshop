{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Wfq4tie-OVj"
      },
      "source": [
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Js6EFUIFUQlO"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/ContextualEntityFilterer.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ2JWggt-UYX"
      },
      "source": [
        "#   **ðŸ“œ ContextualEntityFilterer**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The  **`ContextualEntityFilterer`** annotator was developed to prevent certain entities from causing interference. It can be used to filter out specific entities, ensuring accurate results are preserved."
      ],
      "metadata": {
        "id": "7hzwkXPoKY5I"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e726rKETuJJr"
      },
      "source": [
        "**ðŸ“– Learning Objectives:**\n",
        "\n",
        "1. Understand how to use the annotator.\n",
        "\n",
        "2. Become comfortable using the different parameters of the annotator.\n",
        "\n",
        "**ðŸ”— Helpful Links:**\n",
        "\n",
        "- Reference Documentation: [ContextualEntityFilterer](https://nlp.johnsnowlabs.com/docs/en/licensed_annotators)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okhT7AcXxben"
      },
      "source": [
        "## **ðŸŽ¬ Colab Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xrdvNxjD_yQI"
      },
      "outputs": [],
      "source": [
        "# Install the johnsnowlabs library to access Spark-NLP for Healthcare\n",
        "! pip install -q johnsnowlabs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3WU-z_e8jYpO"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "print('Please Upload your John Snow Labs License using the button below')\n",
        "license_keys = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from johnsnowlabs import nlp, medical\n",
        "\n",
        "# After uploading your license run this to install all licensed Python Wheels and pre-download Jars the Spark Session JVM\n",
        "nlp.settings.enforce_versions=False\n",
        "nlp.install(refresh_install=True)"
      ],
      "metadata": {
        "id": "D-9lbtfHjvm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "19b2mPsZjbI3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba62bd84-7a48-4c31-ab23-c9e2a3e3778d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ‘Œ Detected license file /content/spark_nlp_for_healthcare_spark_ocr_9596 (5).json\n",
            "ðŸ‘Œ Launched \u001b[92mcpu optimized\u001b[39m session with with: ðŸš€Spark-NLP==5.5.1, ðŸ’ŠSpark-Healthcare==5.5.2, running on âš¡ PySpark==3.4.0\n"
          ]
        }
      ],
      "source": [
        "# Automatically load license data and start a session with all jars user has access to\n",
        "spark = nlp.start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "aFMD5KCS9Xih",
        "outputId": "496b12d8-2f07-4a37-bc59-b15e2ccbc8b0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7c97e215d490>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://e71a897f0d5c:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.4.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>John-Snow-Labs-Spark-Session ðŸš€ with Jars for: ðŸš€Spark-NLP==5.5.1, ðŸ’ŠSpark-Healthcare==5.5.2, running on âš¡ PySpark==3.4.0</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBTuAaNIaE-n"
      },
      "source": [
        "## **ðŸ–¨ï¸ Input/Output Annotation Types**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnFxBtrjaJyP"
      },
      "source": [
        "- Input: `DOCUMENT`, `CHUNK`, `TOKEN`\n",
        "\n",
        "- Output: `CHUNK`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLbYplk2a30Z"
      },
      "source": [
        "## **ðŸ”Ž Parameters**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzlkaWUZa7KN"
      },
      "source": [
        "**Parameters**:\n",
        "\n",
        "- `ruleScope`: The rule scope to apply the filter. Options: sentence, document.(str)\n",
        "- `rules`: list[dict]\n",
        "         \n",
        "        - `entity`: The target entity field for filtering.\n",
        "        - `scopeWindow`: A list of two integers [before, after], specifying how many tokens/chunks before and after the target to consider.\n",
        "        - `whiteListEntities`: The white list of entities. If one of the entity from this list appears within the scope window, the chunk will be kept. Only one element is enough to keep the chunk.\n",
        "        - `blackListEntities`: The black list of entities. If an entity from this list appears within the scope window, the chunk will be filtered out. All elements must be absent to keep the chunk.\n",
        "        - `scopeWindowLevel`: Determines whether the `scopeWindow` is applied at the token or chunk level. Options: `token`, `chunk`.\n",
        "        - `blackListWords`: The black list of words. If a word from this list appears within the scope window, the chunk will be filtered out.\n",
        "        - `whiteListWords`: The white list of words. If a word from this list appears within the scope window, the chunk will be kept.\n",
        "        - `confidenceThreshold`: The confidence threshold to filter the chunks. Filtering is only applied if the confidence of the chunk is below the threshold.\n",
        "        - `possibleRegexContext`: The possible regex context to filter the chunks. If the regex is found in the context(chunk), the chunk is kept.\n",
        "        - `impossibleRegexContext`:The impossible regex context to filter the chunks. If the regex is found in the context(chunk), the chunk is removed.When defining regex patterns in code, use double escape characters (e.g., \\) to ensure proper handling of special characters.\n",
        "\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICcnDujCGv5G"
      },
      "source": [
        "### Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documentAssembler = nlp.DocumentAssembler()\\\n",
        "      .setInputCol(\"text\")\\\n",
        "      .setOutputCol(\"document\")\n",
        "\n",
        "tokenizer = nlp.Tokenizer()\\\n",
        "      .setInputCols([\"document\"])\\\n",
        "      .setOutputCol(\"token\")\n",
        "\n",
        "word_embeddings = nlp.WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\") \\\n",
        "      .setInputCols([\"document\", \"token\"])\\\n",
        "      .setOutputCol(\"embeddings\")\n",
        "\n",
        "ner_deid = medical.NerModel.pretrained(\"ner_deid_subentity_docwise\", \"en\", \"clinical/models\")  \\\n",
        "      .setInputCols([\"document\", \"token\", \"embeddings\"]) \\\n",
        "      .setOutputCol(\"ner_deid_subentity_docwise\")\n",
        "\n",
        "ner_deid_converter = medical.NerConverterInternal()\\\n",
        "      .setInputCols([\"document\", \"token\", \"ner_deid_subentity_docwise\"])\\\n",
        "      .setOutputCol(\"ner_chunk_subentity_docwise\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lR_dzXU9ZiSJ",
        "outputId": "1e7f4a7a-d0c7-49fe-8b70-e14559d5d75c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embeddings_clinical download started this may take some time.\n",
            "Approximate size to download 1.6 GB\n",
            "[OK!]\n",
            "ner_deid_subentity_docwise download started this may take some time.\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `setRules`"
      ],
      "metadata": {
        "id": "DyLDA_mgPm1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rules =[{       \"entity\": \"STATE\",\n",
        "                \"scopeWindow\": [2, 2],\n",
        "                \"whiteList\": [\"CITY\"],\n",
        "                \"blackList\": [\"NAME\"],\n",
        "                \"scopeWindowLevel\": \"token\"\n",
        "            }]"
      ],
      "metadata": {
        "id": "gPHYVVi_MRv-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contextual_entity_filterer = medical.ContextualEntityFilterer() \\\n",
        "    .setInputCols(\"document\", \"token\", \"ner_chunk_subentity_docwise\") \\\n",
        "    .setOutputCol(\"filtered_ner_chunks\") \\\n",
        "    .setRules(rules)\\\n",
        "    .setRuleScope(\"sentence\") # document\n",
        "\n",
        "nlpPipeline = nlp.Pipeline(stages=[\n",
        "      documentAssembler,\n",
        "      tokenizer,\n",
        "      word_embeddings,\n",
        "      ner_deid,\n",
        "      ner_deid_converter,\n",
        "      contextual_entity_filterer\n",
        "      ])"
      ],
      "metadata": {
        "id": "suphq7YWNPWQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"NY, a 34-year-old woman, Dr. Michael Johnson cares wit her, at CarePlus Clinic, located at 456 Elm Street, NewYork, NY has recommended starting insulin therapy.\"\n",
        "df = spark.createDataFrame([[text]]).toDF(\"text\")\n",
        "result = nlpPipeline.fit(df).transform(df).cache()"
      ],
      "metadata": {
        "id": "1jl19lvvNVk3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47RDOgRuNXGG",
        "outputId": "3af56f20-06b5-4cc4-f72e-46aee94654b4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------------+---------------------------+--------------------+\n",
            "|                text|            document|               token|          embeddings|ner_deid_subentity_docwise|ner_chunk_subentity_docwise| filtered_ner_chunks|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------------+---------------------------+--------------------+\n",
            "|NY, a 34-year-old...|[{document, 0, 15...|[{token, 0, 1, NY...|[{word_embeddings...|      [{named_entity, 0...|       [{chunk, 0, 1, NY...|[{chunk, 0, 1, NY...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------------+---------------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.selectExpr(\"explode(ner_chunk_subentity_docwise) as ner_chunk\").show(50,truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFzxjCmvNXDm",
        "outputId": "7cc5d893-2fba-4eac-e92d-c82ae5c14f1f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|ner_chunk                                                                                                                                              |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|{chunk, 0, 1, NY, {entity -> STATE, confidence -> 0.9299, ner_source -> ner_chunk_subentity_docwise, chunk -> 0, sentence -> 0}, []}                   |\n",
            "|{chunk, 6, 16, 34-year-old, {entity -> AGE, confidence -> 0.7687, ner_source -> ner_chunk_subentity_docwise, chunk -> 1, sentence -> 0}, []}           |\n",
            "|{chunk, 29, 43, Michael Johnson, {entity -> DOCTOR, confidence -> 0.89965, ner_source -> ner_chunk_subentity_docwise, chunk -> 2, sentence -> 0}, []}  |\n",
            "|{chunk, 63, 77, CarePlus Clinic, {entity -> HOSPITAL, confidence -> 0.9661, ner_source -> ner_chunk_subentity_docwise, chunk -> 3, sentence -> 0}, []} |\n",
            "|{chunk, 91, 104, 456 Elm Street, {entity -> STREET, confidence -> 0.7733667, ner_source -> ner_chunk_subentity_docwise, chunk -> 4, sentence -> 0}, []}|\n",
            "|{chunk, 107, 113, NewYork, {entity -> CITY, confidence -> 0.9302, ner_source -> ner_chunk_subentity_docwise, chunk -> 5, sentence -> 0}, []}           |\n",
            "|{chunk, 116, 117, NY, {entity -> STATE, confidence -> 0.9991, ner_source -> ner_chunk_subentity_docwise, chunk -> 6, sentence -> 0}, []}               |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.selectExpr(\"explode(filtered_ner_chunks) as filtered_chunks\").show(50,truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-yLAZ2nNXBK",
        "outputId": "96fde4fe-c38f-4fb8-c963-c5fe371c1199"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|filtered_chunks                                                                                                                                        |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|{chunk, 0, 1, NY, {chunk -> 0, confidence -> 0.9299, ner_source -> ner_chunk_subentity_docwise, entity -> STATE, sentence -> 0}, []}                   |\n",
            "|{chunk, 6, 16, 34-year-old, {chunk -> 1, confidence -> 0.7687, ner_source -> ner_chunk_subentity_docwise, entity -> AGE, sentence -> 0}, []}           |\n",
            "|{chunk, 29, 43, Michael Johnson, {chunk -> 2, confidence -> 0.89965, ner_source -> ner_chunk_subentity_docwise, entity -> DOCTOR, sentence -> 0}, []}  |\n",
            "|{chunk, 63, 77, CarePlus Clinic, {chunk -> 3, confidence -> 0.9661, ner_source -> ner_chunk_subentity_docwise, entity -> HOSPITAL, sentence -> 0}, []} |\n",
            "|{chunk, 91, 104, 456 Elm Street, {chunk -> 4, confidence -> 0.7733667, ner_source -> ner_chunk_subentity_docwise, entity -> STREET, sentence -> 0}, []}|\n",
            "|{chunk, 107, 113, NewYork, {chunk -> 5, confidence -> 0.9302, ner_source -> ner_chunk_subentity_docwise, entity -> CITY, sentence -> 0}, []}           |\n",
            "|{chunk, 116, 117, NY, {chunk -> 6, confidence -> 0.9991, ner_source -> ner_chunk_subentity_docwise, entity -> STATE, sentence -> 0}, []}               |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flattener = medical.Flattener()\\\n",
        "    .setInputCols(\"ner_chunk_subentity_docwise\") \\\n",
        "    .setExplodeSelectedFields({\"ner_chunk_subentity_docwise\": [\"result as chunk\",\n",
        "                                                                \"begin as begin\",\n",
        "                                                                \"end as end\",\n",
        "                                                                \"metadata.entity as ner_label\",\n",
        "                                                                \"metadata.confidence as confidence\"]})"
      ],
      "metadata": {
        "id": "sgzCKk5LNW-y"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flattener.transform(result).show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMvFozQDlKWN",
        "outputId": "e7922ae9-a860-4c2f-b764-7f3fedeaeb10"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+-----+---+---------+----------+\n",
            "|chunk          |begin|end|ner_label|confidence|\n",
            "+---------------+-----+---+---------+----------+\n",
            "|NY             |0    |1  |STATE    |0.9299    |\n",
            "|34-year-old    |6    |16 |AGE      |0.7687    |\n",
            "|Michael Johnson|29   |43 |DOCTOR   |0.89965   |\n",
            "|CarePlus Clinic|63   |77 |HOSPITAL |0.9661    |\n",
            "|456 Elm Street |91   |104|STREET   |0.7733667 |\n",
            "|NewYork        |107  |113|CITY     |0.9302    |\n",
            "|NY             |116  |117|STATE    |0.9991    |\n",
            "+---------------+-----+---+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flattener = medical.Flattener()\\\n",
        "    .setInputCols(\"filtered_ner_chunks\") \\\n",
        "    .setExplodeSelectedFields({\"filtered_ner_chunks\": [\"result as chunk\",\n",
        "                                                       \"begin as begin\",\n",
        "                                                       \"end as end\",\n",
        "                                                       \"metadata.entity as ner_label\",\n",
        "                                                       \"metadata.confidence as confidence\"]})\n",
        "flattener.transform(result).show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74cP2RDileHq",
        "outputId": "a719efcf-836c-4094-a529-1c62303cf1b6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+-----+---+---------+----------+\n",
            "|chunk          |begin|end|ner_label|confidence|\n",
            "+---------------+-----+---+---------+----------+\n",
            "|NY             |0    |1  |STATE    |0.9299    |\n",
            "|34-year-old    |6    |16 |AGE      |0.7687    |\n",
            "|Michael Johnson|29   |43 |DOCTOR   |0.89965   |\n",
            "|CarePlus Clinic|63   |77 |HOSPITAL |0.9661    |\n",
            "|456 Elm Street |91   |104|STREET   |0.7733667 |\n",
            "|NewYork        |107  |113|CITY     |0.9302    |\n",
            "|NY             |116  |117|STATE    |0.9991    |\n",
            "+---------------+-----+---+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `possibleRegexContext` and `impossibleRegexContext` Paramaters"
      ],
      "metadata": {
        "id": "e-Q1g871MGZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documentAssembler = nlp.DocumentAssembler() \\\n",
        "    .setInputCol(\"text\") \\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "sentenceDetector = nlp.SentenceDetector() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"sentence\")\n",
        "\n",
        "tokenizer = nlp.Tokenizer() \\\n",
        "    .setInputCols([\"sentence\"]) \\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "word_embeddings = nlp.WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\") \\\n",
        "    .setInputCols([\"sentence\", \"token\"]) \\\n",
        "    .setOutputCol(\"embeddings\")\n",
        "\n",
        "clinical_ner = medical.NerModel.pretrained(\"ner_deid_generic_augmented\", \"en\", \"clinical/models\") \\\n",
        "    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
        "    .setOutputCol(\"ner\") \\\n",
        "\n",
        "ner_converter = medical.NerConverterInternal() \\\n",
        "    .setInputCols([\"sentence\", \"token\", \"ner\"]) \\\n",
        "    .setOutputCol(\"ner_chunks\") \\\n",
        "\n",
        "rules =[{\n",
        "    \"entity\": \"AGE\",\n",
        "    \"scopeWindow\": [3, 3],\n",
        "    \"scopeWindowLevel\": \"token\",\n",
        "    \"impossibleRegexContext\" : \"\\\\b(1[2-9]\\\\d|[2-9]\\\\d{2,}|\\\\d{4,})\\\\b\"\n",
        "}]\n",
        "\n",
        "contextual_entity_filterer = medical.ContextualEntityFilterer() \\\n",
        "    .setInputCols(\"sentence\", \"token\", \"ner_chunks\") \\\n",
        "    .setOutputCol(\"filtered_ner_chunks\") \\\n",
        "    .setRules(rules)\\\n",
        "    .setRuleScope(\"sentence\")\n",
        "\n",
        "nlpPipeline = nlp.Pipeline(stages=[\n",
        "    documentAssembler,\n",
        "    sentenceDetector,\n",
        "    tokenizer,\n",
        "    word_embeddings,\n",
        "    clinical_ner,\n",
        "    ner_converter,\n",
        "    contextual_entity_filterer,\n",
        "])\n",
        "empty_df = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
        "model = nlpPipeline.fit(empty_df)\n",
        "result = model.transform(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0_Mc8YCMUhr",
        "outputId": "18ba4953-038b-4e7e-884c-aa3717973c6f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embeddings_clinical download started this may take some time.\n",
            "Approximate size to download 1.6 GB\n",
            "[OK!]\n",
            "ner_deid_generic_augmented download started this may take some time.\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"California, known for its beautiful beaches,and he is 366 years old. \" \\\n",
        "        \"The Grand Canyon in Arizona,  where the age is 37, is a stunning natural landmark.\" \\\n",
        "        \"It was founded on September 9, 1850, and Arizona on February 14, 1912.\"\n",
        "df = spark.createDataFrame([[text]]).toDF(\"text\")\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w47JRiX2NK__",
        "outputId": "f458f35d-f5d1-4922-a99c-c67925491984"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|                text|\n",
            "+--------------------+\n",
            "|California, known...|\n",
            "+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark.sql.functions as F"
      ],
      "metadata": {
        "id": "9yXRdBKLNTe5"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ner_chunk_df = result.select(F.explode(F.arrays_zip(\n",
        "                          result.ner_chunks.result,\n",
        "                          result.ner_chunks.begin,\n",
        "                          result.ner_chunks.end,\n",
        "                          result.ner_chunks.metadata)).alias(\"cols\"))\\\n",
        "                  .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
        "                          F.expr(\"cols['1']\").alias(\"begin\"),\n",
        "                          F.expr(\"cols['2']\").alias(\"end\"),\n",
        "                          F.expr(\"cols['3']['entity']\").alias(\"ner_label\"),\n",
        "                          F.expr(\"cols['3']['confidence']\").alias(\"confidence\"))\n",
        "\n",
        "ner_chunk_df.show(50, truncate=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRqSEwQYNN0q",
        "outputId": "b17289d3-32ad-45ee-e421-605c9ac47209"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----+---+---------+----------+\n",
            "|            chunk|begin|end|ner_label|confidence|\n",
            "+-----------------+-----+---+---------+----------+\n",
            "|       California|    0|  9| LOCATION|    0.9895|\n",
            "|              366|   54| 56|      AGE|    0.9998|\n",
            "|     Grand Canyon|   73| 84| LOCATION|    0.7097|\n",
            "|          Arizona|   89| 95| LOCATION|    0.9987|\n",
            "|               37|  116|117|      AGE|     0.992|\n",
            "|September 9, 1850|  169|185|     DATE|  0.977525|\n",
            "|February 14, 1912|  203|219|     DATE|0.95484996|\n",
            "+-----------------+-----+---+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ner_chunk_df = result.select(F.explode(F.arrays_zip(\n",
        "                          result.filtered_ner_chunks.result,\n",
        "                          result.filtered_ner_chunks.begin,\n",
        "                          result.filtered_ner_chunks.end,\n",
        "                          result.filtered_ner_chunks.metadata)).alias(\"cols\"))\\\n",
        "                  .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
        "                          F.expr(\"cols['1']\").alias(\"begin\"),\n",
        "                          F.expr(\"cols['2']\").alias(\"end\"),\n",
        "                          F.expr(\"cols['3']['entity']\").alias(\"ner_label\"),\n",
        "                          F.expr(\"cols['3']['confidence']\").alias(\"confidence\"))\n",
        "\n",
        "ner_chunk_df.show(50, truncate=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VTivsjEQ0oD",
        "outputId": "ef637ec0-83a8-419a-fb5c-168a3d754837"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----+---+---------+----------+\n",
            "|            chunk|begin|end|ner_label|confidence|\n",
            "+-----------------+-----+---+---------+----------+\n",
            "|       California|    0|  9| LOCATION|    0.9895|\n",
            "|     Grand Canyon|   73| 84| LOCATION|    0.7097|\n",
            "|          Arizona|   89| 95| LOCATION|    0.9987|\n",
            "|               37|  116|117|      AGE|     0.992|\n",
            "|September 9, 1850|  169|185|     DATE|  0.977525|\n",
            "|February 14, 1912|  203|219|     DATE|0.95484996|\n",
            "+-----------------+-----+---+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As seen above, regex is found in the context(chunk) (366) , and the chunk is removed."
      ],
      "metadata": {
        "id": "OT_1KGU7SGC4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rules =[{\n",
        "    \"entity\": \"AGE\",\n",
        "    \"possibleRegexContext\" : \"\\\\b(1[2-9]\\\\d|[2-9]\\\\d{2,}|\\\\d{4,})\\\\b\"\n",
        "}]\n",
        "\n",
        "contextual_entity_filterer = medical.ContextualEntityFilterer() \\\n",
        "    .setInputCols(\"sentence\", \"token\", \"ner_chunks\") \\\n",
        "    .setOutputCol(\"filtered_ner_chunks\") \\\n",
        "    .setRules(rules)\\\n",
        "    .setRuleScope(\"sentence\")\n",
        "\n",
        "nlpPipeline = nlp.Pipeline(stages=[\n",
        "    documentAssembler,\n",
        "    sentenceDetector,\n",
        "    tokenizer,\n",
        "    word_embeddings,\n",
        "    clinical_ner,\n",
        "    ner_converter,\n",
        "    contextual_entity_filterer,\n",
        "])\n",
        "\n",
        "empty_df = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
        "model = nlpPipeline.fit(empty_df)\n",
        "result = model.transform(df)"
      ],
      "metadata": {
        "id": "lbRpZ_y1NwpM"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ner_chunk_df = result.select(F.explode(F.arrays_zip(\n",
        "                          result.ner_chunks.result,\n",
        "                          result.ner_chunks.begin,\n",
        "                          result.ner_chunks.end,\n",
        "                          result.ner_chunks.metadata)).alias(\"cols\"))\\\n",
        "                  .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
        "                          F.expr(\"cols['1']\").alias(\"begin\"),\n",
        "                          F.expr(\"cols['2']\").alias(\"end\"),\n",
        "                          F.expr(\"cols['3']['entity']\").alias(\"ner_label\"),\n",
        "                          F.expr(\"cols['3']['confidence']\").alias(\"confidence\"))\n",
        "\n",
        "ner_chunk_df.show(50, truncate=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaM98BWINwlf",
        "outputId": "2484eb8a-730a-4aa1-dcab-44a21cca68b6"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----+---+---------+----------+\n",
            "|            chunk|begin|end|ner_label|confidence|\n",
            "+-----------------+-----+---+---------+----------+\n",
            "|       California|    0|  9| LOCATION|    0.9895|\n",
            "|              366|   54| 56|      AGE|    0.9998|\n",
            "|     Grand Canyon|   73| 84| LOCATION|    0.7097|\n",
            "|          Arizona|   89| 95| LOCATION|    0.9987|\n",
            "|               37|  116|117|      AGE|     0.992|\n",
            "|September 9, 1850|  169|185|     DATE|  0.977525|\n",
            "|February 14, 1912|  203|219|     DATE|0.95484996|\n",
            "+-----------------+-----+---+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ner_chunk_df = result.select(F.explode(F.arrays_zip(\n",
        "                          result.filtered_ner_chunks.result,\n",
        "                          result.filtered_ner_chunks.begin,\n",
        "                          result.filtered_ner_chunks.end,\n",
        "                          result.filtered_ner_chunks.metadata)).alias(\"cols\"))\\\n",
        "                  .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
        "                          F.expr(\"cols['1']\").alias(\"begin\"),\n",
        "                          F.expr(\"cols['2']\").alias(\"end\"),\n",
        "                          F.expr(\"cols['3']['entity']\").alias(\"ner_label\"),\n",
        "                          F.expr(\"cols['3']['confidence']\").alias(\"confidence\"))\n",
        "\n",
        "ner_chunk_df.show(50, truncate=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWvsiUtBNwh5",
        "outputId": "21ed8457-2d64-4365-8e5d-a0f1c7c5f0fa"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----+---+---------+----------+\n",
            "|            chunk|begin|end|ner_label|confidence|\n",
            "+-----------------+-----+---+---------+----------+\n",
            "|       California|    0|  9| LOCATION|    0.9895|\n",
            "|              366|   54| 56|      AGE|    0.9998|\n",
            "|     Grand Canyon|   73| 84| LOCATION|    0.7097|\n",
            "|          Arizona|   89| 95| LOCATION|    0.9987|\n",
            "|September 9, 1850|  169|185|     DATE|  0.977525|\n",
            "|February 14, 1912|  203|219|     DATE|0.95484996|\n",
            "+-----------------+-----+---+---------+----------+\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}