{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "uFIrUnOrC9kH",
        "w-6AmiZK5peg",
        "bLbxGHhI7cgK"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
      ],
      "metadata": {
        "id": "8V_Ow3cAVEYe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MedicalTextGenerator**"
      ],
      "metadata": {
        "id": "Y0fJRpNJBslT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook will cover the different parameters and usages of `MedicalTextGenerator`.\n",
        "\n",
        "**ðŸ“– Learning Objectives:**\n",
        "\n",
        "1. Background: Understand the `MedicalTextGenerator` annotator.\n",
        "\n",
        "2. Colab setup.\n",
        "\n",
        "3. Become comfortable with using the different parameters of the annotator.\n",
        "\n",
        "**ðŸ”— Helpful Links:**\n",
        "\n",
        "- Python Docs : [MedicalTextGenerator](https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/seq2seq/medical_text_generator/index.html#)\n",
        "\n",
        "- Scala Docs: [MedicalTextGenerator](https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/seq2seq/MedicalTextGenerator.html)\n",
        "\n",
        "- For extended examples of usage, see [Spark NLP Workshop repository](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/healthcare-nlp/25.1.Medical_Text_Generation.ipynb).\n"
      ],
      "metadata": {
        "id": "qeclGJmrVLjX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ðŸ“œ Background**"
      ],
      "metadata": {
        "id": "OV0hPSCWXslc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`MedicalTextGenerator` uses the basic **BioGPT** model to perform various tasks related to medical text abstraction.\n",
        "\n",
        "With the help of this annotator, a user can provide a `prompt` and `context` and instruct the system to perform a specific task, such as explaining why a patient may have a particular disease or paraphrasing the context more directly.\n",
        "\n",
        "In addition, this annotator can create a clinical note for a cancer patient using the given keywords or write medical texts based on introductory sentences.\n",
        "\n",
        "The `BioGPT model` is trained on a large volume of medical data allowing it to identify and extract the most relevant information from the text provided."
      ],
      "metadata": {
        "id": "_-hGkZ7_cAZE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ðŸŽ¬ Colab Setup**"
      ],
      "metadata": {
        "id": "E8qy2MI2XySv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "if 'spark_jsl.json' not in os.listdir():\n",
        "  license_keys = files.upload()\n",
        "  os.rename(list(license_keys.keys())[0], 'spark_jsl.json')\n",
        "\n",
        "with open('spark_jsl.json') as f:\n",
        "    license_keys = json.load(f)\n",
        "\n",
        "locals().update(license_keys)\n",
        "os.environ.update(license_keys)\n"
      ],
      "metadata": {
        "id": "GPzfC_C3_X5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q johnsnowlabs"
      ],
      "metadata": {
        "id": "7yDYnU9Nif8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from johnsnowlabs import nlp, medical\n",
        "nlp.install()\n"
      ],
      "metadata": {
        "id": "tse6lDbfioTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from johnsnowlabs import nlp, medical\n",
        "\n",
        "spark = nlp.start()"
      ],
      "metadata": {
        "id": "pcyD12Fpi5WW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "u347_J7XGRSn",
        "outputId": "f1e94881-8f0f-41b4-b257-d4a02788015c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x794759150a00>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://92bdf222e436:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>John-Snow-Labs-Spark-Session ðŸš€ with Jars for: ðŸš€Spark-NLP==5.2.0, ðŸ’ŠSpark-Healthcare==5.2.0, running on âš¡ PySpark==3.1.2</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def f(text):\n",
        "  import textwrap\n",
        "  text = textwrap.fill(text, width=120)\n",
        "  return  '\\n'+text"
      ],
      "metadata": {
        "id": "eDhNz-K0ZGkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ðŸ–¨ï¸ Input/Output Annotation Types**\n",
        "\n"
      ],
      "metadata": {
        "id": "f_4conOIYj6D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Input:  `DOCUMENT`  \n",
        "\n",
        "- Output:  `CHUNK`  "
      ],
      "metadata": {
        "id": "0Fc_3iRwYk8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ðŸ”Ž Parameters**"
      ],
      "metadata": {
        "id": "IO7xgW6Znobb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`caseSensitive`: whether to ignore case in tokens for embeddings matching; default: True.\n",
        "\n",
        "`maxNewTokens`: maximum number of new tokens to be generated; default: 30.\n",
        "\n",
        "`doSample`: whether or not to use sampling; use greedy decoding otherwise; default: False.\n",
        "\n",
        "`topK`: the number of highest probability vocabulary tokens to consider; default: 1.\n",
        "\n",
        "`stopAtEos`: Stop text generation when the end-of-sentence token is encountered; default: True.\n",
        "\n",
        "`maxContextLength`: maximum length of the context text; default: 1024.\n",
        "\n",
        "`maxTextLength`: maximum text length to process; default:512.\n",
        "\n",
        "`noRepeatNgramSize`: if set to int > 0, all ngrams of that size can only occur once; default: 0.\n",
        "\n",
        "`customPrompt`: different formats may be assigned like \"question: {DOCUMENT} answer:\" or \"INPUT: {DOCUMENT} OUTPUT:\" or else."
      ],
      "metadata": {
        "id": "2Vv-dsM2njQT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# âœ  Explaining medical.TextGenerator with an Example"
      ],
      "metadata": {
        "id": "g9zdtP-D5spx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ðŸ’»nlp.Pipeline**"
      ],
      "metadata": {
        "id": "pagXc73HWidS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "document_assembler = nlp.DocumentAssembler()\\\n",
        "    .setInputCol(\"prompt\")\\\n",
        "    .setOutputCol(\"document_prompt\")\n",
        "\n",
        "med_text_generator  = medical.TextGenerator.pretrained(\"text_generator_biomedical_biogpt_base\", \"en\", \"clinical/models\")\\\n",
        "    .setInputCols(\"document_prompt\")\\\n",
        "    .setOutputCol(\"answer\")\\\n",
        "    .setCaseSensitive(True)\\\n",
        "    .setMaxNewTokens(256)\\\n",
        "    .setDoSample(True)\\\n",
        "    .setTopK(3)\\\n",
        "    .setRandomSeed(40)\\\n",
        "    .setStopAtEos(True)\n",
        "\n",
        "pipeline = nlp.Pipeline(stages=[document_assembler, med_text_generator])\n",
        "data = spark.createDataFrame([['Covid 19 is']]).toDF(\"prompt\")\n",
        "\n",
        "result = pipeline.fit(data).transform(data)"
      ],
      "metadata": {
        "id": "EFVK8wWODWjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's see the quick result\n",
        "\n",
        "res = result.select(\"answer.result\").toPandas().iloc[0][0]\n",
        "res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Zhiplw3j-A5",
        "outputId": "603be6a1-0589-40df-c72a-724ec2a7f610"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Covid 19 is an emerging pandemic with an unprecedented number and variety. ( 1,2 &#93; The pandemic is caused mainly due the SARS CoV 2 ( SARS CoV 2, the virus causing the coronavirus ), a virus which is a novel member in Coronaviral family and is responsible of a highly transmissible and lethal respiratory illness known to cause severe acute and critical illnesses in human beings &#91; 1 - 4, 1 - 6, 7 &#93;, which has resulted into the global health crisis of COVID - 2019 &#91; 8 - 11, 1 - 4 &#93;, which is currently spreading across all countries in Asia and Africa. ( 1,2 - 5 ) In the current study we report a novel case in which the COVID 19 was confirmed in an Indian male, aged 25, with no past history or clinical evidence for other viral or autoimmune disease, and the case is presented here for the rarity. ( 6 - 9, 10 )']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = [\"COVID-19\",\n",
        "        \"SARS-CoV-2\",\n",
        "        \"Asthma is a chronic respiratory disease characterized by\"]\n",
        "model = pipeline.fit(data)\n",
        "\n",
        "light_model = nlp.LightPipeline(model)\n",
        "light_result = light_model.annotate(text)\n",
        "\n",
        "for i in range(len(text)):\n",
        "  print(f\"document_prompt âž¤ {f(light_result[i]['document_prompt'][0])}\\n answer âž¤ {f(light_result[i]['answer'][0])} \\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6RZByPbaxCf",
        "outputId": "8b2f7a53-544f-4e7b-e72b-cf4cac630615"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "document_prompt âž¤ \n",
            "COVID-19\n",
            " answer âž¤ \n",
            "COVID - 19 and diabetes: a review of current literature and implications. ( 1 - 4. \n",
            "\n",
            "\n",
            "document_prompt âž¤ \n",
            "SARS-CoV-2\n",
            " answer âž¤ \n",
            "SARS - CoV - 2 is the cause for COVID 19. ( ABSTRACT \n",
            "\n",
            "\n",
            "document_prompt âž¤ \n",
            "Asthma is a chronic respiratory disease characterized by\n",
            " answer âž¤ \n",
            "Asthma is a chronic respiratory disease characterized by airway hyperresponsiveness, airway remodeling and airway\n",
            "inflammation. ( ABSTRACT \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "med_text_generator.extractParamMap()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KH43eMHpKVkH",
        "outputId": "0dfc0cfe-4d27-478c-fdab-914b1398be5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{Param(parent='MedicalTextGenerator_9430e26a418f', name='batchSize', doc='Size of every batch'): 4,\n",
              " Param(parent='MedicalTextGenerator_9430e26a418f', name='customPrompt', doc='Custom prompt template'): '',\n",
              " Param(parent='MedicalTextGenerator_9430e26a418f', name='doSample', doc='Whether or not to use sampling; use greedy decoding otherwise'): True,\n",
              " Param(parent='MedicalTextGenerator_9430e26a418f', name='ignoreTokenIds', doc=\"A list of token ids which are ignored in the decoder's output\"): JavaObject id=o90,\n",
              " Param(parent='MedicalTextGenerator_9430e26a418f', name='lazyAnnotator', doc='Whether this AnnotatorModel acts as lazy in RecursivePipelines'): False,\n",
              " Param(parent='MedicalTextGenerator_9430e26a418f', name='maxContextLength', doc='Maximum length of the context text'): 1024,\n",
              " Param(parent='MedicalTextGenerator_9430e26a418f', name='maxNewTokens', doc='Maximum number of new tokens to be generated'): 256,\n",
              " Param(parent='MedicalTextGenerator_9430e26a418f', name='maxTextLength', doc='Max text length to process'): 512,\n",
              " Param(parent='MedicalTextGenerator_9430e26a418f', name='mlFrameworkType', doc='ML framework type'): 'tensorflow',\n",
              " Param(parent='MedicalTextGenerator_9430e26a418f', name='noRepeatNgramSize', doc='If set to int > 0, all ngrams of that size can only occur once'): 0,\n",
              " Param(parent='MedicalTextGenerator_9430e26a418f', name='stopAtEos', doc='Stop text generation when the end-of-sentence token is encountered.'): True,\n",
              " Param(parent='MedicalTextGenerator_9430e26a418f', name='topK', doc='The number of highest probability vocabulary tokens to consider'): 3,\n",
              " Param(parent='MedicalTextGenerator_9430e26a418f', name='useCache', doc='Cache internal state of the model to improve performance'): True,\n",
              " Param(parent='MedicalTextGenerator_9430e26a418f', name='caseSensitive', doc='whether to ignore case in tokens for embeddings matching'): True,\n",
              " Param(parent='MedicalTextGenerator_9430e26a418f', name='modelType', doc='Model type'): 'BioGPT',\n",
              " Param(parent='MedicalTextGenerator_9430e26a418f', name='engine', doc='Deep Learning engine used for this model'): 'tensorflow',\n",
              " Param(parent='MedicalTextGenerator_9430e26a418f', name='inputCols', doc='previous annotations columns, if renamed'): ['document_prompt'],\n",
              " Param(parent='MedicalTextGenerator_9430e26a418f', name='outputCol', doc='output annotation column. can be left default.'): 'answer'}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### â–¶ `caseSensitive` :\n",
        "\n",
        "Whether to ignore case sensitivity in tokens."
      ],
      "metadata": {
        "id": "Rq8TxfhQYkhJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "CaseSensitive = [False, True]\n",
        "text = [\"Asthma is a chronic respiratory disease characterized by\"]\n",
        "\n",
        "for cs in CaseSensitive:\n",
        "  med_text_generator  = medical.TextGenerator.pretrained(\"text_generator_biomedical_biogpt_base\", \"en\", \"clinical/models\")\\\n",
        "    .setInputCols(\"document_prompt\")\\\n",
        "    .setOutputCol(\"answer\")\\\n",
        "    .setCaseSensitive(cs)\n",
        "\n",
        "  pipeline = nlp.Pipeline(stages=[document_assembler, med_text_generator])\n",
        "\n",
        "  model = pipeline.fit(data)\n",
        "\n",
        "  light_model = nlp.LightPipeline(model)\n",
        "  light_result = light_model.annotate(text)\n",
        "\n",
        "  print('â– '*120)\n",
        "  print('CaseSensitive = ',cs)\n",
        "  for i in range(len(text)):\n",
        "    print(f\"document_prompt âž¤ {f(light_result[i]['document_prompt'][0])}\\n answer âž¤ {f(light_result[i]['answer'][0])} \\n\\n\")"
      ],
      "metadata": {
        "id": "AKhh_emSiMXE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a1d2e9a-3168-4284-b1cc-669a10ad8bb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_generator_biomedical_biogpt_base download started this may take some time.\n",
            "[OK!]\n",
            "â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– \n",
            "CaseSensitive =  False\n",
            "document_prompt âž¤ \n",
            "Asthma is a chronic respiratory disease characterized by\n",
            " answer âž¤ \n",
            "asthma is a chronic respiratory disease characterized by airway hyperresponsiveness, airway remodeling and airway\n",
            "hyperresponsiveness ( AHT, airway hyperresponsiveness to non specific bronchoconstrictor agents such methacholine and\n",
            "bradykinin, which are thought by many investigators as the main factors in asthma ), which are the hallmarks for asthma\n",
            "pathogenesis and progression to asthma. ( ABSTRACT \n",
            "\n",
            "\n",
            "text_generator_biomedical_biogpt_base download started this may take some time.\n",
            "[OK!]\n",
            "â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– \n",
            "CaseSensitive =  True\n",
            "document_prompt âž¤ \n",
            "Asthma is a chronic respiratory disease characterized by\n",
            " answer âž¤ \n",
            "Asthma is a chronic respiratory disease characterized by airway hyperresponsiveness, airway remodeling and airway\n",
            "obstruction, and it has a significant negative effect in quality - adjusted survival and health care expenditure in\n",
            "patients. ( ABSTRACT \n",
            "\n",
            "\n",
            "CPU times: user 158 ms, sys: 17.1 ms, total: 175 ms\n",
            "Wall time: 18.2 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### â–¶ `maxNewTokens`:\n",
        "Maximum number of new tokens to be generated.\n"
      ],
      "metadata": {
        "id": "jgpqckYPvX2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenNumber = [1,30]\n",
        "text = [\"Asthma is a chronic respiratory disease characterized by\"]\n",
        "for tn in  tokenNumber:\n",
        "  med_text_generator  = medical.TextGenerator.pretrained(\"text_generator_biomedical_biogpt_base\", \"en\", \"clinical/models\")\\\n",
        "      .setInputCols(\"document_prompt\")\\\n",
        "      .setOutputCol(\"answer\")\\\n",
        "      .setCaseSensitive(True)\\\n",
        "      .setMaxNewTokens(tn)\n",
        "\n",
        "  pipeline = nlp.Pipeline(stages=[document_assembler, med_text_generator])\n",
        "  model = pipeline.fit(data)\n",
        "\n",
        "  light_model = nlp.LightPipeline(model)\n",
        "  light_result = light_model.annotate(text)\n",
        "\n",
        "  print('â– '*120)\n",
        "  print('setMaxNewTokens = ', tn)\n",
        "\n",
        "  for i in range(len(text)):\n",
        "    print(f\"document_prompt âž¤ {f(light_result[i]['document_prompt'][0])}\\n answer âž¤ {f(light_result[i]['answer'][0])} \\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvnkPiQJvYTy",
        "outputId": "8c77b467-4fbc-4ed5-addb-4a81b55de9ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_generator_biomedical_biogpt_base download started this may take some time.\n",
            "[OK!]\n",
            "â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– \n",
            "setMaxNewTokens =  1\n",
            "document_prompt âž¤ \n",
            "Asthma is a chronic respiratory disease characterized by\n",
            " answer âž¤ \n",
            "Asthma is a chronic respiratory disease characterized by airway \n",
            "\n",
            "\n",
            "text_generator_biomedical_biogpt_base download started this may take some time.\n",
            "[OK!]\n",
            "â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– \n",
            "setMaxNewTokens =  30\n",
            "document_prompt âž¤ \n",
            "Asthma is a chronic respiratory disease characterized by\n",
            " answer âž¤ \n",
            "Asthma is a chronic respiratory disease characterized by airway hyperresponsiveness, airway remodeling and airway\n",
            "obstruction, and it has a significant negative effect in quality - adjusted survival and health care expenditure in\n",
            "patients. ( ABSTRACT \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### â–¶ `doSample`:\n",
        "Sets whether or not to use sampling."
      ],
      "metadata": {
        "id": "ULLN5h1q6z6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "setDoSample = [True, False]\n",
        "text = [\"Asthma is a chronic respiratory disease characterized by\"]\n",
        "med_text_generator  = medical.TextGenerator.pretrained(\"text_generator_biomedical_biogpt_base\", \"en\", \"clinical/models\")\\\n",
        "      .setInputCols(\"document_prompt\")\\\n",
        "      .setOutputCol(\"answer\")\\\n",
        "      .setCaseSensitive(True)\\\n",
        "      .setMaxNewTokens(50)\n",
        "\n",
        "for ds in setDoSample:\n",
        "  med_text_generator  = med_text_generator.setDoSample(ds)\n",
        "\n",
        "  pipeline = nlp.Pipeline(stages=[document_assembler, med_text_generator])\n",
        "  model = pipeline.fit(data)\n",
        "\n",
        "  light_model = nlp.LightPipeline(model)\n",
        "  light_result = light_model.annotate(text)\n",
        "\n",
        "  print('â– '*120)\n",
        "  print('setDoSample = ', ds)\n",
        "\n",
        "  for i in range(len(text)):\n",
        "    print(f\"document_prompt âž¤ {f(light_result[i]['document_prompt'][0])}\\n\\n\\n answer âž¤ {f(light_result[i]['answer'][0])} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awiaBGmL6zeE",
        "outputId": "e80ab66d-7e39-4301-e730-c6a5e797f90c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_generator_biomedical_biogpt_base download started this may take some time.\n",
            "[OK!]\n",
            "â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– \n",
            "setDoSample =  True\n",
            "document_prompt âž¤ \n",
            "Asthma is a chronic respiratory disease characterized by\n",
            "\n",
            "\n",
            " answer âž¤ \n",
            "Asthma is a chronic respiratory disease characterized by airway hyperresponsiveness, airway remodeling and airway\n",
            "obstruction, and it has a significant negative effect in quality - adjusted survival and health care expenditure in\n",
            "patients. ( ABSTRACT \n",
            "\n",
            "â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– \n",
            "setDoSample =  False\n",
            "document_prompt âž¤ \n",
            "Asthma is a chronic respiratory disease characterized by\n",
            "\n",
            "\n",
            " answer âž¤ \n",
            "Asthma is a chronic respiratory disease characterized by reversible airway obstruction. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### â–¶`topK`:\n",
        "Number of highest probability vocabulary tokens to consider.\n",
        "\n"
      ],
      "metadata": {
        "id": "W_nEjtQDBTyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = [\"The commont treatment method for diabetes are\", \"COVID-19 is\"]\n",
        "med_text_generator  = medical.TextGenerator.pretrained(\"text_generator_biomedical_biogpt_base\", \"en\", \"clinical/models\")\\\n",
        "    .setInputCols(\"document_prompt\")\\\n",
        "    .setOutputCol(\"answer\")\\\n",
        "    .setCaseSensitive(True)\\\n",
        "    .setMaxNewTokens(25)\\\n",
        "    .setDoSample(True)\n",
        "\n",
        "for topk in [1,5]:\n",
        "  med_text_generator = med_text_generator.setTopK(topk)\n",
        "\n",
        "  pipeline = nlp.Pipeline(stages=[document_assembler, med_text_generator])\n",
        "  model = pipeline.fit(data)\n",
        "\n",
        "\n",
        "  light_model = nlp.LightPipeline(model)\n",
        "  light_result = light_model.annotate(text)\n",
        "\n",
        "  print('â– '*120)\n",
        "  print('setTopK = ', topk)\n",
        "\n",
        "  for i in range(len(text)):\n",
        "    print(f\"document_prompt âž¤ {f(light_result[i]['document_prompt'][0])}\\n\\n\\n answer âž¤ {f(light_result[i]['answer'][0])} \\n\")\n",
        "    print('-'*120)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdKsppXhBVCA",
        "outputId": "8a9713ca-91a7-4fa8-e35d-027fad2cb92b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_generator_biomedical_biogpt_base download started this may take some time.\n",
            "[OK!]\n",
            "â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– \n",
            "setTopK =  1\n",
            "document_prompt âž¤ \n",
            "The commont treatment method for diabetes are\n",
            "\n",
            "\n",
            " answer âž¤ \n",
            "The commont treatment method for diabetes are insulin injections and oral hypoglycemic agents. \n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "document_prompt âž¤ \n",
            "COVID-19 is\n",
            "\n",
            "\n",
            " answer âž¤ \n",
            "COVID - 19 is a global pandemic. \n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– \n",
            "setTopK =  5\n",
            "document_prompt âž¤ \n",
            "The commont treatment method for diabetes are\n",
            "\n",
            "\n",
            " answer âž¤ \n",
            "The commont treatment method for diabetes are oral medications and lifestyle modification; insulin and other injectable\n",
            "agents, including human growth hormones ( GH - I, human insulin--INS \n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "document_prompt âž¤ \n",
            "COVID-19 is\n",
            "\n",
            "\n",
            " answer âž¤ \n",
            "COVID - 19 is caused mainly through SARS CoV  CoV and Middle CoVa CoV ( CoV2, now named as CoV3 or CoV4 \n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### â–¶`stopAtEos`:\n",
        "Stop text generation when the end-of-sentence token is encountered."
      ],
      "metadata": {
        "id": "uFIrUnOrC9kH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = [\"COVID-19 is\"]\n",
        "med_text_generator  = medical.TextGenerator.pretrained(\"text_generator_biomedical_biogpt_base\", \"en\", \"clinical/models\")\\\n",
        "  .setInputCols(\"document_prompt\")\\\n",
        "  .setOutputCol(\"answer\")\\\n",
        "  .setCaseSensitive(True)\\\n",
        "  .setMaxNewTokens(25)\\\n",
        "  .setDoSample(False)\\\n",
        "  .setTopK(5)\n",
        "\n",
        "for opt in [True, False]:\n",
        "  med_text_generator = med_text_generator.setStopAtEos(opt)\n",
        "  pipeline = nlp.Pipeline(stages=[document_assembler, med_text_generator])\n",
        "  model = pipeline.fit(data)\n",
        "\n",
        "  light_model = nlp.LightPipeline(model)\n",
        "  light_result = light_model.annotate(text)\n",
        "\n",
        "  print('â– '*120)\n",
        "  print('setStopAtEos = ', opt)\n",
        "\n",
        "  for i in range(len(text)):\n",
        "    print(f\"document_prompt âž¤ {f(light_result[i]['document_prompt'][0])}\\n\\n\\n answer âž¤ {f(light_result[i]['answer'][0])} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubUaIswJC-6y",
        "outputId": "25445e2a-6e5a-495d-8775-82fb8f02e485"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_generator_biomedical_biogpt_base download started this may take some time.\n",
            "[OK!]\n",
            "â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– \n",
            "setStopAtEos =  True\n",
            "document_prompt âž¤ \n",
            "COVID-19 is\n",
            "\n",
            "\n",
            " answer âž¤ \n",
            "COVID - 19 is a global pandemic. \n",
            "\n",
            "â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– \n",
            "setStopAtEos =  False\n",
            "document_prompt âž¤ \n",
            "COVID-19 is\n",
            "\n",
            "\n",
            " answer âž¤ \n",
            "COVID - 19 is a global pandemic. The World Health Organization declared COVID - 19 a pandemic on March 11, 2020. The\n",
            "disease is \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### â–¶`maxContextLength`:\n",
        "Maximum length of the context text; default: 1024."
      ],
      "metadata": {
        "id": "w-6AmiZK5peg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = [\"Asthma is a chronic respiratory disease characterized by\"]\n",
        "\n",
        "med_text_generator  = medical.TextGenerator.pretrained(\"text_generator_biomedical_biogpt_base\", \"en\", \"clinical/models\")\\\n",
        "  .setInputCols(\"document_prompt\")\\\n",
        "  .setOutputCol(\"answer\")\\\n",
        "  .setCaseSensitive(True)\\\n",
        "  .setMaxNewTokens(512)\\\n",
        "  .setDoSample(True)\\\n",
        "  .setTopK(50)\\\n",
        "  .setStopAtEos(True)\n",
        "\n",
        "for opt in [2, 50]:\n",
        "  med_text_generator = med_text_generator.setMaxContextLength(opt)\n",
        "  pipeline = nlp.Pipeline(stages=[document_assembler, med_text_generator])\n",
        "  model = pipeline.fit(data)\n",
        "\n",
        "  light_model = nlp.LightPipeline(model)\n",
        "  light_result = light_model.annotate(text)\n",
        "\n",
        "  print('â– '*120)\n",
        "  print('setMaxContextLength = ', opt)\n",
        "\n",
        "  for i in range(len(text)):\n",
        "    print(f\"document_prompt âž¤ {f(light_result[i]['document_prompt'][0])}\\n\\n\\n answer âž¤ {f(light_result[i]['answer'][0])} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec6edcf1-60de-47c8-de20-1b5eb27bad0f",
        "id": "bHecsYyV5pen"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_generator_biomedical_biogpt_base download started this may take some time.\n",
            "[OK!]\n",
            "â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– \n",
            "setMaxContextLength =  2\n",
            "document_prompt âž¤ \n",
            "Asthma is a chronic respiratory disease characterized by\n",
            "\n",
            "\n",
            " answer âž¤ \n",
            "Asthma is a chronic respiratory disease characterized by inflammatory reaction due airway mucosa that mainly targets on\n",
            "large smooth pulmonary arterioles due changes during gestation such inflammation has different inflammatory reactions\n",
            "among its exacerbations due gestational periods as birth ( labor stage B &#91; N group was  29 w.o in B. We aim with\n",
            "finding possible predictive biomarker such with biomarkers with changes as different clinical outcomes between antenatal\n",
            "exacerbations vs postpartum visits at our Institute as birth, or first - day hospitalization / other postpartum relapses\n",
            "as in preeclampsia vs pregnancy / parturition complicated asthmatics from previous publications using R 2.3.2 based gene\n",
            "/ pathways databases which in fact provide prediction with asthma phenotypes or their subtypes through which there need\n",
            "different types as of diagnostic ( based diagnosis; test sensitivity: 70 per 95 Conclusions We tried, finding novel\n",
            "association such for any disease through pathway network or association studies such us association to understand\n",
            "mechanisms responsible such events by taking them with and using available datasets with genes like Gas1069a43401 like (\n",
            "CXCL10R1 - \n",
            "\n",
            "â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– \n",
            "setMaxContextLength =  50\n",
            "document_prompt âž¤ \n",
            "Asthma is a chronic respiratory disease characterized by\n",
            "\n",
            "\n",
            " answer âž¤ \n",
            "Asthma is a chronic respiratory disease characterized by inflammatory reaction due airway mucosa that mainly targets on\n",
            "large smooth pulmonary arterioles due changes during gestation such inflammation has different inflammatory reactions\n",
            "among its exacerbations due gestational periods as birth ( labor stage B &#91; N group was  29 w.o in B. We aim with\n",
            "finding possible predictive biomarker such with biomarkers with changes as different clinical outcomes between antenatal\n",
            "exacerbations vs postpartum visits at our Institute as birth, or first - day hospitalization / other postpartum relapses\n",
            "as in preeclampsia vs pregnancy / parturition complicated asthmatics from previous publications using R 2.3.2 based gene\n",
            "/ pathways databases which in fact provide prediction with asthma phenotypes or their subtypes through which there need\n",
            "different types as of diagnostic ( based diagnosis; test sensitivity: 70 per 95 Conclusions We tried, finding novel\n",
            "association such for any disease through pathway network or association studies such us association to understand\n",
            "mechanisms responsible such events by taking them with and using available datasets with genes like Gas1069a43401 like (\n",
            "CXCL10R1 - \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### â–¶`maxTextLength`\n",
        "Maximum text length to process; default:512."
      ],
      "metadata": {
        "id": "bLbxGHhI7cgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = [\"Asthma is a chronic respiratory disease characterized by\"]\n",
        "\n",
        "med_text_generator  = medical.TextGenerator.pretrained(\"text_generator_biomedical_biogpt_base\", \"en\", \"clinical/models\")\\\n",
        "  .setInputCols(\"document_prompt\")\\\n",
        "  .setOutputCol(\"answer\")\\\n",
        "  .setCaseSensitive(True)\\\n",
        "  .setMaxNewTokens(512)\\\n",
        "  .setDoSample(False)\\\n",
        "  .setTopK(1)\\\n",
        "  .setStopAtEos(True)\n",
        "\n",
        "for opt in [2, 50]:\n",
        "  med_text_generator = med_text_generator.setMaxTextLength(opt)\n",
        "  pipeline = nlp.Pipeline(stages=[document_assembler, med_text_generator])\n",
        "  model = pipeline.fit(data)\n",
        "\n",
        "  light_model = nlp.LightPipeline(model)\n",
        "  light_result = light_model.annotate(text)\n",
        "\n",
        "  print('â– '*120)\n",
        "  print('setMaxTextLength = ', opt,'\\n')\n",
        "\n",
        "  for i in range(len(text)):\n",
        "    print(f\"document_prompt âž¤ {f(light_result[i]['document_prompt'][0])}\\n answer âž¤ {f(light_result[i]['answer'][0])} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22b4956d-e0e5-49af-def0-36f106303d32",
        "id": "W9Ma25tf7cgR"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_generator_biomedical_biogpt_base download started this may take some time.\n",
            "[OK!]\n",
            "â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– \n",
            "setMaxTextLength =  2 \n",
            "\n",
            "document_prompt âž¤ \n",
            "Asthma is a chronic respiratory disease characterized by\n",
            " answer âž¤ \n",
            "Asthma is a chronic respiratory disease characterized by reversible \n",
            "\n",
            "â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– \n",
            "setMaxTextLength =  50 \n",
            "\n",
            "document_prompt âž¤ \n",
            "Asthma is a chronic respiratory disease characterized by\n",
            " answer âž¤ \n",
            "Asthma is a chronic respiratory disease characterized by reversible airway obstruction. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### â–¶`noRepeatNgramSize`\n",
        "\n",
        "If set to int > 0, all ngrams of that size can only occur once, Default: 0\n",
        "\n"
      ],
      "metadata": {
        "id": "a0Fm0i409jLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = [\"Asthma is a chronic respiratory disease characterized by\"]\n",
        "\n",
        "med_text_generator  = medical.TextGenerator.pretrained(\"text_generator_biomedical_biogpt_base\", \"en\", \"clinical/models\")\\\n",
        "  .setInputCols(\"document_prompt\")\\\n",
        "  .setOutputCol(\"answer\")\\\n",
        "  .setCaseSensitive(True)\\\n",
        "  .setMaxNewTokens(512)\\\n",
        "  .setDoSample(False)\\\n",
        "  .setTopK(1)\\\n",
        "  .setStopAtEos(True)\n",
        "\n",
        "for opt in [0,1 ]:\n",
        "  med_text_generator = med_text_generator.setNoRepeatNgramSize(opt)\n",
        "  pipeline = nlp.Pipeline(stages=[document_assembler, med_text_generator])\n",
        "  model = pipeline.fit(data)\n",
        "\n",
        "  light_model = nlp.LightPipeline(model)\n",
        "  light_result = light_model.annotate(text)\n",
        "\n",
        "  print('â– '*120)\n",
        "  print('setNoRepeatNgramSize = ', opt,'\\n')\n",
        "\n",
        "  for i in range(len(text)):\n",
        "    print(f\"document_prompt âž¤ {f(light_result[i]['document_prompt'][0])}\\n answer âž¤ {f(light_result[i]['answer'][0])} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99ca319f-9f0d-4434-89fe-c1545de7b0e8",
        "id": "j39bDip_9jLU"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_generator_biomedical_biogpt_base download started this may take some time.\n",
            "[OK!]\n",
            "â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– \n",
            "setNoRepeatNgramSize =  0 \n",
            "\n",
            "document_prompt âž¤ \n",
            "Asthma is a chronic respiratory disease characterized by\n",
            " answer âž¤ \n",
            "Asthma is a chronic respiratory disease characterized by reversible airway obstruction. \n",
            "\n",
            "â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– \n",
            "setNoRepeatNgramSize =  1 \n",
            "\n",
            "document_prompt âž¤ \n",
            "Asthma is a chronic respiratory disease characterized by\n",
            " answer âž¤ \n",
            "Asthma is a chronic respiratory disease characterized by reversible airway obstruction. ( ABSTRACT TRUNCATED AT 250\n",
            "WORDS ) The pathogenesis of asthma involves both immunologic and nonimmune mechanisms, including the release or action\n",
            "on inflammatory cells such as mast cell tryptase from activated eosinophils in response to \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### â–¶`customPrompt`\n",
        "\n",
        "\n",
        "Different formats may be assigned like \"question: {DOCUMENT} answer:\" or \"INPUT: {DOCUMENT} OUTPUT:\" or else.\n"
      ],
      "metadata": {
        "id": "iLKolTDk-K1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = [\"What is the difference between melanoma and sarcoma?\"]\n",
        "\n",
        "med_text_generator  = medical.TextGenerator.pretrained(\"text_generator_biomedical_biogpt_base\", \"en\", \"clinical/models\")\\\n",
        "  .setInputCols(\"document_prompt\")\\\n",
        "  .setOutputCol(\"answer\")\\\n",
        "  .setCaseSensitive(True)\\\n",
        "  .setMaxNewTokens(512)\\\n",
        "  .setDoSample(False)\\\n",
        "  .setTopK(1)\\\n",
        "  .setStopAtEos(True)\\\n",
        "  .setNoRepeatNgramSize(1)\n",
        "\n",
        "for opt in [\"question: {DOCUMENT} answer:\", \"INPUT: {DOCUMENT} OUTPUT:\",\"\"]:\n",
        "\n",
        "  med_text_generator = med_text_generator.setCustomPrompt(opt)\n",
        "  pipeline = nlp.Pipeline(stages=[document_assembler, med_text_generator])\n",
        "  model = pipeline.fit(data)\n",
        "\n",
        "  light_model = nlp.LightPipeline(model)\n",
        "  light_result = light_model.annotate(text)\n",
        "\n",
        "  print('â– '*120)\n",
        "\n",
        "  for i in range(len(text)):\n",
        "    print(f\"{f(light_result[i]['answer'][0])} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70b36297-d6ca-452c-9648-f3e46c41af48",
        "id": "XbpCQ0T1-K1J"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_generator_biomedical_biogpt_base download started this may take some time.\n",
            "[OK!]\n",
            "â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– \n",
            "\n",
            "question: What is the difference between melanoma and sarcoma? answer: A systematic review. ( 1 ) The authors searched\n",
            "MEDLINE, EMBASE Classic + Embase databases from inception to June 2017 for studies comparing survival outcomes of\n",
            "patients with malignant melanomas versus sarcomas in adults \n",
            "\n",
            "â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– \n",
            "\n",
            "input: What is the difference between melanoma and sarcoma? output: A review of current literature. ( 1 ) Melanoma, a\n",
            "rare cancer with an incidence rate that has been increasing over time in many countries worldwide; however it remains\n",
            "one which accounts for approximately \n",
            "\n",
            "â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– \n",
            "\n",
            "What is the difference between melanoma and sarcoma? A review of current literature. ( ABSTRACT TRUNCATED AT 250 WORDS )\n",
            "BACKGROUND: The purpose was to compare clinical, pathologic features as well survival data in patients with malignant\n",
            "melanomas versus sarcomas at a single institution over an \n",
            "\n"
          ]
        }
      ]
    }
  ]
}