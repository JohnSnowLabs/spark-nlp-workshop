{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
      ],
      "metadata": {
        "id": "q6PjvJts1YhY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TextMatcherInternal\n",
        "\n",
        "In this notebook, we will examine the `TextMatcherInternal` annotator and its model version `TextMatcherInternalModel`.\n",
        "\n",
        "This annotator match exact phrases provided in a file against a\n",
        "Document.\n"
      ],
      "metadata": {
        "id": "UkZcGEDW4adm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**üìñ Learning Objectives:**\n",
        "\n",
        "1. Understand how to match exact phrases by using pre-defined dictionary.\n",
        "\n",
        "2. Become comfortable using the different parameters of the annotator.\n",
        "\n",
        "**üîó Helpful Links:**\n",
        "\n",
        "For extended examples of usage, see the [Spark NLP Workshop Repository](https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/42.TextMatcher.ipynb)\n",
        "\n",
        "Reference Documentation: [TextMatcherInternal](https://nlp.johnsnowlabs.com/docs/en/licensed_annotators#textmatcherinternal)\n"
      ],
      "metadata": {
        "id": "P0YPIJYgK6FA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **üé¨ Colab Setup**"
      ],
      "metadata": {
        "id": "gi7eVUQwL5uY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "license_keys = files.upload()\n",
        "\n",
        "with open(list(license_keys.keys())[0]) as f:\n",
        "    license_keys = json.load(f)\n",
        "\n",
        "# Defining license key-value pairs as local variables\n",
        "locals().update(license_keys)\n",
        "\n",
        "# Adding license key-value pairs to environment variables\n",
        "os.environ.update(license_keys)"
      ],
      "metadata": {
        "id": "LX0yW66AFMRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing pyspark and spark-nlp\n",
        "! pip install --upgrade -q pyspark==3.4.1\n",
        "\n",
        "# Installing Spark NLP Healthcare\n",
        "! pip install --upgrade -q spark-nlp-jsl==$JSL_VERSION  --extra-index-url https://pypi.johnsnowlabs.com/$SECRET\n",
        "\n",
        "# Installing Spark NLP Display Library for visualization\n",
        "! pip install -q spark-nlp-display"
      ],
      "metadata": {
        "id": "QmuGKHy_G3ZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "from pyspark.ml import Pipeline, PipelineModel\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "import sparknlp\n",
        "import sparknlp_jsl\n",
        "\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp_jsl.annotator import *\n",
        "from sparknlp.base import *\n",
        "from sparknlp.util import *\n",
        "from sparknlp.pretrained import ResourceDownloader\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.expand_frame_repr', False)\n",
        "pd.set_option('max_colwidth', None)\n",
        "\n",
        "import string\n",
        "import numpy as np\n",
        "\n",
        "params = {\"spark.driver.memory\":\"16G\",\n",
        "          \"spark.kryoserializer.buffer.max\":\"2000M\",\n",
        "          \"spark.driver.maxResultSize\":\"2000M\"}\n",
        "\n",
        "spark = sparknlp_jsl.start(secret = license_keys[\"SECRET\"], params=params)\n",
        "\n",
        "print (\"Spark NLP Version :\", sparknlp.version())\n",
        "print (\"Spark NLP_JSL Version :\", sparknlp_jsl.version())\n",
        "\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "uUO6IE2bG3Ny",
        "outputId": "905cd131-b917-4bce-c0d2-f056b472c947"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP Version : 5.3.0\n",
            "Spark NLP_JSL Version : 5.3.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x78de9883cf10>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://9abef15578f9:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.4.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark NLP Licensed</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **üñ®Ô∏è Input/Output Annotation Types**\n",
        "- Input: ``DOCUMENT`` , ``TOKEN``    \n",
        "- Output: ``CHUNK``"
      ],
      "metadata": {
        "id": "42ldvpMD4-oM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **üîé Parameters**\n"
      ],
      "metadata": {
        "id": "pKZ66I1D5aMQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `setEntities` *(str)*: Sets the external resource for the entities.\n",
        "        path : str\n",
        "            Path to the external resource\n",
        "        read_as : str, optional\n",
        "            How to read the resource, by default ReadAs.TEXT\n",
        "        options : dict, optional\n",
        "            Options for reading the resource, by default {\"format\": \"text\"}\n",
        "- `setCaseSensitive` *(Boolean)*: Sets whether to match regardless of case. (Default: True)\n",
        "\n",
        "- `setMergeOverlapping` *(Boolean)*:Sets whether to merge overlapping matched chunks. (Default: False)\n",
        "\n",
        "- `setEntityValue` *(str)*: Sets the value for the entity metadata field. If any entity value isn't set in the file, we need to set it for the entity value.\n",
        "\n",
        "- `setBuildFromTokens` *(Boolean)*:  Sets whether the TextMatcherInternal should take the CHUNK from TOKEN.\n",
        "\n",
        "- `setDelimiter` *(str)*:  Sets Value for the delimiter between Phrase, Entity.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "N8dYRLbiMj2b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to Use `TextMatcherInternal`"
      ],
      "metadata": {
        "id": "WZ9o6caf5dwY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First of all, we should create a source file that includes all the chunks or tokens we need to capture. In the example below, we use `#` as a delimiter to separate the label and entity. So we need to set parameter like this `setDelimiter('#')`."
      ],
      "metadata": {
        "id": "k_PfxcyZ2HHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matcher_drug = \"\"\"\n",
        "Aspirin 100mg#Drug\n",
        "aspirin#Drug\n",
        "paracetamol#Drug\n",
        "amoxicillin#Drug\n",
        "ibuprofen#Drug\n",
        "lansoprazole#Drug\n",
        "\"\"\"\n",
        "\n",
        "with open ('matcher_drug.csv', 'w') as f:\n",
        "  f.write(matcher_drug)"
      ],
      "metadata": {
        "id": "SA_clVXRLGMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documentAssembler = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "tokenizer = Tokenizer()\\\n",
        "    .setInputCols([\"document\"])\\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "entityExtractor = TextMatcherInternal()\\\n",
        "    .setInputCols([\"document\", \"token\"])\\\n",
        "    .setEntities(\"matcher_drug.csv\")\\\n",
        "    .setOutputCol(\"matched_text\")\\\n",
        "    .setCaseSensitive(False)\\\n",
        "    .setDelimiter(\"#\")\\\n",
        "    .setMergeOverlapping(True)\n",
        "\n",
        "mathcer_pipeline = Pipeline().setStages([\n",
        "                  documentAssembler,\n",
        "                  tokenizer,\n",
        "                  entityExtractor])\n",
        "\n",
        "data = spark.createDataFrame([[\"John's doctor prescribed aspirin 100mg for his heart condition, along with paracetamol for his fever, amoxicillin for his tonsilitis, ibuprofen for his inflammation, and lansoprazole for his GORD.\"]]).toDF(\"text\")\n",
        "\n",
        "matcher_model = mathcer_pipeline.fit(data)\n",
        "result = matcher_model.transform(data)"
      ],
      "metadata": {
        "id": "BAulAfjcE8cJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.select(F.explode(F.arrays_zip(\n",
        "              result.matched_text.result,\n",
        "              result.matched_text.begin,\n",
        "              result.matched_text.end,\n",
        "              result.matched_text.metadata,)).alias(\"cols\"))\\\n",
        "      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
        "              F.expr(\"cols['1']\").alias(\"begin\"),\n",
        "              F.expr(\"cols['2']\").alias(\"end\"),\n",
        "              F.expr(\"cols['3']['entity']\").alias('label')).show(truncate=70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zw1BcEqoNYMM",
        "outputId": "696cd909-810f-47ce-a630-d1753c6a556d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+-----+---+-----+\n",
            "|        chunk|begin|end|label|\n",
            "+-------------+-----+---+-----+\n",
            "|aspirin 100mg|   25| 37| Drug|\n",
            "|  paracetamol|   75| 85| Drug|\n",
            "|  amoxicillin|  102|112| Drug|\n",
            "|    ibuprofen|  134|142| Drug|\n",
            "| lansoprazole|  170|181| Drug|\n",
            "+-------------+-----+---+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you see above mather_drug file includes 2 similar entities aspirin and aspirin 100mg and our text includes both of them. So if you want to see both of them you need to set `MergeOverlapping` parameter as `False`. You can look at the below example."
      ],
      "metadata": {
        "id": "1ke9q2i9OKB_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "entityExtractor = TextMatcherInternal()\\\n",
        "    .setInputCols([\"document\", \"token\"])\\\n",
        "    .setEntities(\"matcher_drug.csv\") \\\n",
        "    .setOutputCol(\"matched_text\")\\\n",
        "    .setCaseSensitive(False)\\\n",
        "    .setDelimiter(\"#\")\\\n",
        "    .setMergeOverlapping(False)\n",
        "\n",
        "mathcer_pipeline = Pipeline().setStages([\n",
        "                  documentAssembler,\n",
        "                  tokenizer,\n",
        "                  entityExtractor])\n",
        "\n",
        "matcher_model = mathcer_pipeline.fit(data)\n",
        "result = matcher_model.transform(data)"
      ],
      "metadata": {
        "id": "fhOx17lxPzam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.select(F.explode(F.arrays_zip(\n",
        "              result.matched_text.result,\n",
        "              result.matched_text.begin,\n",
        "              result.matched_text.end,\n",
        "              result.matched_text.metadata,)).alias(\"cols\"))\\\n",
        "      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
        "              F.expr(\"cols['1']\").alias(\"begin\"),\n",
        "              F.expr(\"cols['2']\").alias(\"end\"),\n",
        "              F.expr(\"cols['3']['entity']\").alias('label')).show(truncate=70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mir6p73EPzX7",
        "outputId": "e2b5605a-1706-46a9-be08-0eba1fbd8d4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+-----+---+-----+\n",
            "|        chunk|begin|end|label|\n",
            "+-------------+-----+---+-----+\n",
            "|      aspirin|   25| 31| Drug|\n",
            "|aspirin 100mg|   25| 37| Drug|\n",
            "|  paracetamol|   75| 85| Drug|\n",
            "|  amoxicillin|  102|112| Drug|\n",
            "|    ibuprofen|  134|142| Drug|\n",
            "| lansoprazole|  170|181| Drug|\n",
            "+-------------+-----+---+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we set the `CaseSensitive` parameter to `True`, it means we're considering the case sensitivity of chunks in the source file. Consequently, some chunks may not be visible due to differences in their case compared to the source file."
      ],
      "metadata": {
        "id": "5lJR9TF-KjnX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "entityExtractor = TextMatcherInternal()\\\n",
        "    .setInputCols([\"document\", \"token\"])\\\n",
        "    .setEntities(\"matcher_drug.csv\") \\\n",
        "    .setOutputCol(\"matched_text\")\\\n",
        "    .setCaseSensitive(True)\\\n",
        "    .setDelimiter(\"#\")\\\n",
        "    .setMergeOverlapping(False)\n",
        "\n",
        "mathcer_pipeline = Pipeline().setStages([\n",
        "                  documentAssembler,\n",
        "                  tokenizer,\n",
        "                  entityExtractor])\n",
        "\n",
        "matcher_model = mathcer_pipeline.fit(data)\n",
        "result = matcher_model.transform(data)"
      ],
      "metadata": {
        "id": "1kO64pNcRSns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.select(F.explode(F.arrays_zip(\n",
        "              result.matched_text.result,\n",
        "              result.matched_text.begin,\n",
        "              result.matched_text.end,\n",
        "              result.matched_text.metadata,)).alias(\"cols\"))\\\n",
        "      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
        "              F.expr(\"cols['1']\").alias(\"begin\"),\n",
        "              F.expr(\"cols['2']\").alias(\"end\"),\n",
        "              F.expr(\"cols['3']['entity']\").alias('label')).show(truncate=70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2du_Gl_MRX5e",
        "outputId": "be51fa50-b2fa-416f-9555-6eb4f99d3e75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----+---+-----+\n",
            "|       chunk|begin|end|label|\n",
            "+------------+-----+---+-----+\n",
            "|     aspirin|   25| 31| Drug|\n",
            "| paracetamol|   75| 85| Drug|\n",
            "| amoxicillin|  102|112| Drug|\n",
            "|   ibuprofen|  134|142| Drug|\n",
            "|lansoprazole|  170|181| Drug|\n",
            "+------------+-----+---+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multiple Entities"
      ],
      "metadata": {
        "id": "JRK3oFxTeu3G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can set multiple entities in the same file."
      ],
      "metadata": {
        "id": "MqYZzaJcRvLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "multiple_entites= \"\"\"\n",
        "Aspirin 100mg#Drug\n",
        "paracetamol#Drug\n",
        "amoxicillin#Drug\n",
        "ibuprofen#Drug\n",
        "lansoprazole#Drug\n",
        "fever#Symptom\n",
        "headache#Symptom\n",
        "tonsilitis#Disease\n",
        "GORD#Disease\n",
        "heart condition#Disease\n",
        "\"\"\"\n",
        "\n",
        "with open ('multiple_entities.csv', 'w') as f:\n",
        "  f.write(multiple_entites)"
      ],
      "metadata": {
        "id": "UMyFcexzRo_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documentAssembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"text\") \\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "tokenizer = Tokenizer() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "entityExtractor = TextMatcherInternal() \\\n",
        "    .setInputCols([\"document\", \"token\"]) \\\n",
        "    .setEntities(\"multiple_entities.csv\") \\\n",
        "    .setOutputCol(\"matched_text\")\\\n",
        "    .setCaseSensitive(False)\\\n",
        "    .setDelimiter(\"#\")\n",
        "\n",
        "mathcer_pipeline = Pipeline().setStages([\n",
        "                  documentAssembler,\n",
        "                  tokenizer,\n",
        "                  entityExtractor])\n",
        "\n",
        "data = spark.createDataFrame([[\"John's doctor prescribed aspirin 100mg for his heart condition, along with paracetamol for his fever and headache, amoxicillin for his tonsilitis, ibuprofen for his inflammation, and lansoprazole for his GORD.\"]]).toDF(\"text\")\n",
        "\n",
        "matcher_model = mathcer_pipeline.fit(data)\n",
        "result = matcher_model.transform(data)"
      ],
      "metadata": {
        "id": "F9OYfKPA5bM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.select(F.explode(F.arrays_zip(\n",
        "              result.matched_text.result,\n",
        "              result.matched_text.begin,\n",
        "              result.matched_text.end,\n",
        "              result.matched_text.metadata,)).alias(\"cols\"))\\\n",
        "      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
        "              F.expr(\"cols['1']\").alias(\"begin\"),\n",
        "              F.expr(\"cols['2']\").alias(\"end\"),\n",
        "              F.expr(\"cols['3']['entity']\").alias('label')).show(truncate=70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8ocoyTFQx0Q",
        "outputId": "44ad4c8c-5a61-42d3-d1d8-033f834140de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+-----+---+-------+\n",
            "|          chunk|begin|end|  label|\n",
            "+---------------+-----+---+-------+\n",
            "|heart condition|   47| 61|Disease|\n",
            "|     tonsilitis|  135|144|Disease|\n",
            "|           GORD|  204|207|Disease|\n",
            "|          fever|   95| 99|Symptom|\n",
            "|       headache|  105|112|Symptom|\n",
            "|  aspirin 100mg|   25| 37|   Drug|\n",
            "|    paracetamol|   75| 85|   Drug|\n",
            "|    amoxicillin|  115|125|   Drug|\n",
            "|      ibuprofen|  147|155|   Drug|\n",
            "|   lansoprazole|  183|194|   Drug|\n",
            "+---------------+-----+---+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `TextMatcherInternalModel`"
      ],
      "metadata": {
        "id": "-2xjtXx1Hpk_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This annotator is an instantiated model of the `TextMatcherInternal`. Once you build an `TextMatcherInternal()`, you can save it and use it with `TextMatcherInternalModel()` via `load()` function. <br/>\n",
        "\n",
        "Let's re-build one of examples that we have done before and save it."
      ],
      "metadata": {
        "id": "xR38CLdnHsff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "entityExtractor = TextMatcherInternal() \\\n",
        "    .setInputCols([\"document\", \"token\"]) \\\n",
        "    .setEntities(\"matcher_drug.csv\") \\\n",
        "    .setOutputCol(\"matched_text\")\\\n",
        "    .setCaseSensitive(False)\\\n",
        "    .setDelimiter(\"#\")\n",
        "\n",
        "mathcer_pipeline = Pipeline().setStages([\n",
        "                  documentAssembler,\n",
        "                  tokenizer,\n",
        "                  entityExtractor])\n",
        "\n",
        "data = spark.createDataFrame([[\"John's doctor prescribed aspirin 100mg for his heart condition, along with paracetamol for his fever and headache, amoxicillin for his tonsilitis, ibuprofen for his inflammation, and lansoprazole for his GORD.\"]]).toDF(\"text\")\n",
        "\n",
        "matcher_model = mathcer_pipeline.fit(data)\n",
        "result = matcher_model.transform(data)"
      ],
      "metadata": {
        "id": "6QYSvWToIA-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the approach to disk."
      ],
      "metadata": {
        "id": "bC_plUPNIBkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matcher_model.stages[-1].write().overwrite().save(\"matcher_internal_model\")"
      ],
      "metadata": {
        "id": "nVy8-fN-GNlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the saved model and using it with the `TextMatcherInternalModel()` via `load`."
      ],
      "metadata": {
        "id": "Y0n3vq6XIprS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "entity_ruler = TextMatcherInternalModel.load('/content/matcher_internal_model') \\\n",
        "    .setInputCols([\"document\", \"token\"]) \\\n",
        "    .setOutputCol(\"matched_text\")\\\n",
        "    .setCaseSensitive(False)\\\n",
        "    .setDelimiter(\"#\")\n",
        "\n",
        "pipeline = Pipeline(stages=[documentAssembler,\n",
        "                            tokenizer,\n",
        "                            entity_ruler])\n",
        "\n",
        "pipeline_model = pipeline.fit(data)\n",
        "result = pipeline_model.transform(data)"
      ],
      "metadata": {
        "id": "8b6I0h5ZGNiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the result"
      ],
      "metadata": {
        "id": "sDWKIe2qJD-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result.select(F.explode(F.arrays_zip(\n",
        "              result.matched_text.result,\n",
        "              result.matched_text.begin,\n",
        "              result.matched_text.end,\n",
        "              result.matched_text.metadata,)).alias(\"cols\"))\\\n",
        "      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
        "              F.expr(\"cols['1']\").alias(\"begin\"),\n",
        "              F.expr(\"cols['2']\").alias(\"end\"),\n",
        "              F.expr(\"cols['3']['entity']\").alias('label')).show(truncate=70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6NEIyG1GNf7",
        "outputId": "a4527e3a-ce7c-428f-8303-eea34bcd4e72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+-----+---+-----+\n",
            "|        chunk|begin|end|label|\n",
            "+-------------+-----+---+-----+\n",
            "|      aspirin|   25| 31| Drug|\n",
            "|aspirin 100mg|   25| 37| Drug|\n",
            "|  paracetamol|   75| 85| Drug|\n",
            "|  amoxicillin|  115|125| Drug|\n",
            "|    ibuprofen|  147|155| Drug|\n",
            "| lansoprazole|  183|194| Drug|\n",
            "+-------------+-----+---+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As seen above, we built an `TextMatcherInternal`, saved it and used the saved model with `TextMatcherInternalModel`."
      ],
      "metadata": {
        "id": "JtuNVf4YJS0o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using LightPipeline"
      ],
      "metadata": {
        "id": "uuN7dw05_AlD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The TextMatcherInternal annotator can also be applied by using LightPipeline:"
      ],
      "metadata": {
        "id": "f3IXo3vO_H0s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IS8fN6lh_AlD"
      },
      "outputs": [],
      "source": [
        "light_pipeline = LightPipeline(pipeline_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddda5607-614d-4249-d1c6-105124186049",
        "id": "qpM8ed-G_AlD"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['document', 'token', 'matched_text'])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "annotations = light_pipeline.fullAnnotate(\"John's doctor prescribed aspirin 100mg for his heart condition, along with paracetamol for his fever and headache, amoxicillin for his tonsilitis, ibuprofen for his inflammation, and lansoprazole for his GORD.\")[0]\n",
        "annotations.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f92631af-6338-4c44-c3b3-2f5f560ee7dc",
        "id": "BuvodYEI_AlE"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Annotation(chunk, 25, 31, aspirin, {'entity': 'Drug', 'sentence': '0', 'chunk': '0'}, []),\n",
              " Annotation(chunk, 25, 37, aspirin 100mg, {'entity': 'Drug', 'sentence': '0', 'chunk': '1'}, []),\n",
              " Annotation(chunk, 75, 85, paracetamol, {'entity': 'Drug', 'sentence': '0', 'chunk': '2'}, []),\n",
              " Annotation(chunk, 115, 125, amoxicillin, {'entity': 'Drug', 'sentence': '0', 'chunk': '3'}, []),\n",
              " Annotation(chunk, 147, 155, ibuprofen, {'entity': 'Drug', 'sentence': '0', 'chunk': '4'}, []),\n",
              " Annotation(chunk, 183, 194, lansoprazole, {'entity': 'Drug', 'sentence': '0', 'chunk': '5'}, [])]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "annotations.get('matched_text')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display the result with `spark-nlp-display`."
      ],
      "metadata": {
        "id": "mgxllC3b4b2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sparknlp_display import NerVisualizer\n",
        "\n",
        "visualiser = NerVisualizer()\n",
        "\n",
        "visualiser.display(annotations, label_col='matched_text')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "lz8ondRb4aDE",
        "outputId": "e88dafb2-1c5c-446a-f3b9-87671065ab82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    @import url('https://fonts.googleapis.com/css2?family=Montserrat:wght@300;400;500;600;700&display=swap');\n",
              "    @import url('https://fonts.googleapis.com/css2?family=Vistol Regular:wght@300;400;500;600;700&display=swap');\n",
              "    \n",
              "    .spark-nlp-display-scroll-entities {\n",
              "        border: 1px solid #E7EDF0;\n",
              "        border-radius: 3px;\n",
              "        text-align: justify;\n",
              "        \n",
              "    }\n",
              "    .spark-nlp-display-scroll-entities span {  \n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        color: #536B76;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "    }\n",
              "    \n",
              "    .spark-nlp-display-entity-wrapper{\n",
              "    \n",
              "        display: inline-grid;\n",
              "        text-align: center;\n",
              "        border-radius: 4px;\n",
              "        margin: 0 2px 5px 2px;\n",
              "        padding: 1px\n",
              "    }\n",
              "    .spark-nlp-display-entity-name{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "        \n",
              "        background: #f1f2f3;\n",
              "        border-width: medium;\n",
              "        text-align: center;\n",
              "        \n",
              "        font-weight: 400;\n",
              "        \n",
              "        border-radius: 5px;\n",
              "        padding: 2px 5px;\n",
              "        display: block;\n",
              "        margin: 3px 2px;\n",
              "    \n",
              "    }\n",
              "    .spark-nlp-display-entity-type{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        color: #ffffff;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "        \n",
              "        text-transform: uppercase;\n",
              "        \n",
              "        font-weight: 500;\n",
              "\n",
              "        display: block;\n",
              "        padding: 3px 5px;\n",
              "    }\n",
              "    \n",
              "    .spark-nlp-display-entity-resolution{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        color: #ffffff;\n",
              "        font-family: 'Vistol Regular', sans-serif !important;\n",
              "        \n",
              "        text-transform: uppercase;\n",
              "        \n",
              "        font-weight: 500;\n",
              "\n",
              "        display: block;\n",
              "        padding: 3px 5px;\n",
              "    }\n",
              "    \n",
              "    .spark-nlp-display-others{\n",
              "        font-size: 14px;\n",
              "        line-height: 24px;\n",
              "        font-family: 'Montserrat', sans-serif !important;\n",
              "        \n",
              "        font-weight: 400;\n",
              "    }\n",
              "\n",
              "</style>\n",
              " <span class=\"spark-nlp-display-others\" style=\"background-color: white\">John's doctor prescribed </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #8B668B\"><span class=\"spark-nlp-display-entity-name\">aspirin </span><span class=\"spark-nlp-display-entity-type\">Drug</span></span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #8B668B\"><span class=\"spark-nlp-display-entity-name\">aspirin 100mg </span><span class=\"spark-nlp-display-entity-type\">Drug</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> for his heart condition, along with </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #8B668B\"><span class=\"spark-nlp-display-entity-name\">paracetamol </span><span class=\"spark-nlp-display-entity-type\">Drug</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> for his fever and headache, </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #8B668B\"><span class=\"spark-nlp-display-entity-name\">amoxicillin </span><span class=\"spark-nlp-display-entity-type\">Drug</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> for his tonsilitis, </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #8B668B\"><span class=\"spark-nlp-display-entity-name\">ibuprofen </span><span class=\"spark-nlp-display-entity-type\">Drug</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> for his inflammation, and </span><span class=\"spark-nlp-display-entity-wrapper\" style=\"background-color: #8B668B\"><span class=\"spark-nlp-display-entity-name\">lansoprazole </span><span class=\"spark-nlp-display-entity-type\">Drug</span></span><span class=\"spark-nlp-display-others\" style=\"background-color: white\"> for his GORD.</span></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}