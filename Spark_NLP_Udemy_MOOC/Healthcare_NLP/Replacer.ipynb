{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMbGD0aDUJSZGPedSaCBDoG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"],"metadata":{"id":"8V_Ow3cAVEYe"}},{"cell_type":"markdown","source":["# **Replacer**"],"metadata":{"id":"Y0fJRpNJBslT"}},{"cell_type":"markdown","source":["\n","This notebook will cover the `Replacer` annotator. \n","\n","`Replacer` allows to replace entities in the original text with the ones extracted by the annotators `NameChunkObfuscatorApproach` or `DateNormalizer`. \n","\n","\n","\n","\n","**üìñ Learning Objectives:**\n","\n","1. Understand how `Replacer` works.\n","\n","2. Understand how `Replacer` can be used to with the `DateNormalizer` annotator and in the deintification process.\n","\n","3. Become comfortable using the `setUseReplacement` parameter of the annotator.\n","\n","\n","**üîó Helpful Links:**\n","\n","\n","- Python Docs : [Replacer](https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/deid/replacer/index.html#sparknlp_jsl.annotator.deid.replacer.Replacer)\n","\n","- Scala Docs : [Replacer](https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/deid/Replacer.html)\n","\n","- For extended examples of usage, see the [Clinical Deidentification](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/4.Clinical_DeIdentification.ipynb#scrollTo=9alThnhZeOvn) and [Date Normalizer](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/healthcare-nlp/13.0.Date_Normalizer.ipynb#scrollTo=yX57W_6SLiWz) notebooks.\n"],"metadata":{"id":"qeclGJmrVLjX"}},{"cell_type":"markdown","source":["## **üìú Background**"],"metadata":{"id":"OV0hPSCWXslc"}},{"cell_type":"markdown","source":["`Replacer` is most often used in conjunction with the `DateNormalizer` annotator or in deidentification pipelines.\n","\n","With the dates, the `Replacer` annotator is used to replace specific tokens in a text with another token or string. The `DateNormalizer` annotator, on the other hand, is used to normalize dates and times to a standardized format.\n","\n","Obfuscation in healthcare is the act of making healthcare data difficult to understand or use without authorization. This can be done by replacing or removing identifying information, such as names, dates of birth, and Social Security numbers. Obfuscation can also be used to hide the contents of healthcare records, such as diagnoses, medications, and treatment plans.\n","\n","In the **deidentification** process, the `Replacer` annotator is used to replace certain tokens or patterns in the text with specified values. For example, it can be used to replace all instances of a person's name with a placeholder like \"PERSON\".\n","\n","The `NameChunkObfuscatorApproach` annotator is used to identify and obfuscate sensitive named entities in the text, such as people's names, addresses, dates of birth, SSNs etc. \n"],"metadata":{"id":"ms9xwzYACPtU"}},{"cell_type":"markdown","source":["## **üé¨ Colab Setup**"],"metadata":{"id":"E8qy2MI2XySv"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"HuLFt0OdBkuo"},"outputs":[],"source":["# Install the johnsnowlabs library to access Spark-OCR and Spark-NLP for Healthcare, Finance, and Legal.\n","! pip install -q johnsnowlabs "]},{"cell_type":"code","source":["from google.colab import files\n","print('Please Upload your John Snow Labs License using the button below')\n","license_keys = files.upload()"],"metadata":{"id":"URRyJvTMBtXQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from johnsnowlabs import nlp, medical, visual\n","\n","# After uploading your license run this to install all licensed Python Wheels and pre-download Jars the Spark Session JVM\n","nlp.install()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8OocQcx0I7ky","executionInfo":{"status":"ok","timestamp":1684502275116,"user_tz":240,"elapsed":80461,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"}},"outputId":"e2ce93b2-30c8-4680-efbd-0d1e92cb708e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üëå Detected license file /content/4.4.1.spark_nlp_for_healthcare.json\n","üìã Stored John Snow Labs License in /root/.johnsnowlabs/licenses/license_number_0_for_Spark-Healthcare_Spark-OCR.json\n","üë∑ Setting up  John Snow Labs home in /root/.johnsnowlabs, this might take a few minutes.\n","Downloading üêç+üöÄ Python Library spark_nlp-4.4.1-py2.py3-none-any.whl\n","Downloading üêç+üíä Python Library spark_nlp_jsl-4.4.1-py3-none-any.whl\n","Downloading ü´ò+üöÄ Java Library spark-nlp-assembly-4.4.1.jar\n","Downloading ü´ò+üíä Java Library spark-nlp-jsl-4.4.1.jar\n","üôÜ JSL Home setup in /root/.johnsnowlabs\n","üëå Detected license file /content/4.4.1.spark_nlp_for_healthcare.json\n","Installing /root/.johnsnowlabs/py_installs/spark_nlp_jsl-4.4.1-py3-none-any.whl to /usr/bin/python3\n","Installed 1 products:\n","üíä Spark-Healthcare==4.4.1 installed! ‚úÖ Heal the planet with NLP! \n"]}]},{"cell_type":"code","source":["from johnsnowlabs import nlp, medical, visual\n","import pandas as pd\n","import json\n","import string\n","import numpy as np\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Automatically load license data and start a session with all jars user has access to\n","spark = nlp.start()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ua2KKPdVI7iB","executionInfo":{"status":"ok","timestamp":1684502293817,"user_tz":240,"elapsed":18714,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"}},"outputId":"ae02b1f1-3e48-4f09-b3a1-1f082438d0d2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["üëå Detected license file /content/4.4.1.spark_nlp_for_healthcare.json\n","üëå Launched \u001b[92mcpu optimized\u001b[39m session with with: üöÄSpark-NLP==4.4.1, üíäSpark-Healthcare==4.4.1, running on ‚ö° PySpark==3.1.2\n"]}]},{"cell_type":"code","source":["from pyspark.sql import DataFrame\n","import pyspark.sql.functions as F\n","import pyspark.sql.types as T\n","import pyspark.sql as SQL\n","from pyspark import keyword_only\n","from pyspark.sql.types import StructType, IntegerType, StringType"],"metadata":{"id":"wqpXWxoQI7fd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **üñ®Ô∏è Input/Output Annotation Types**"],"metadata":{"id":"f_4conOIYj6D"}},{"cell_type":"markdown","source":["- Input: `DOCUMENT`, `CHUNK`\n","\n","- Output: `DOCUMENT`"],"metadata":{"id":"0Fc_3iRwYk8N"}},{"cell_type":"markdown","source":["## **üîé Parameters**"],"metadata":{"id":"rgCCuKLdepW9"}},{"cell_type":"markdown","source":["- `setUseReplacement`: (Boolean) Select what output format should be used. By default it will use the current day.   \n","\n"],"metadata":{"id":"Y4tqQGMsj1BQ"}},{"cell_type":"markdown","source":["## **üíª Deidentification Pipeline**"],"metadata":{"id":"LW_kZcwMeK2h"}},{"cell_type":"markdown","source":["`Obfuscation` refers to the process of making data unclear, confusing, or difficult to understand or interpret. The goal of obfuscation is to hide or protect **sensitive information** by altering it in a way that makes it challenging for unauthorized parties to access or comprehend.\n","\n","\n","\n","\n","The `NameChunkObfuscatorApproach` annotator contains all the methods for training a NameChunkObfuscator model. This module can replace name entities with consistent fakers. "],"metadata":{"id":"xX16Jq-fyRuZ"}},{"cell_type":"code","source":["names = \"\"\"Mitchell#NAME\n","Clifford#NAME\n","Jeremiah#NAME\n","Lawrence#NAME\n","Brittany#NAME\n","Patricia#NAME\n","Samantha#NAME\n","Jennifer#NAME\n","Jackson#NAME\n","Leonard#NAME\n","Randall#NAME\n","Camacho#NAME\n","Ferrell#NAME\n","Mueller#NAME\n","Bowman#NAME\n","Hansen#NAME\n","Acosta#NAME\n","Gillespie#NAME\n","Zimmerman#NAME\n","Gillespie#NAME\n","Chandler#NAME\n","Bradshaw#NAME\n","Ferguson#NAME\n","Jacobson#NAME\n","Figueroa#NAME\n","Chandler#NAME\n","Schaefer#NAME\n","Matthews#NAME\n","Ferguson#NAME\n","Bradshaw#NAME\n","Figueroa#NAME\n","Delacruz#NAME\n","Gallegos#NAME\n","Villarreal#NAME\n","Williamson#NAME\n","Montgomery#NAME\n","Mclaughlin#NAME\n","Blankenship#NAME\n","Fitzpatrick#NAME\n","\"\"\"\n","\n","with open('names_test.txt', 'w') as file:\n","    file.write(names)"],"metadata":{"id":"A2jHRADpwjR-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### `setUseReplacement`\n","\n","<br/>\n","\n","This parameter is used to enable or disable replacement of entities. \n","\n","True is for Replacing, False for otherwise."],"metadata":{"id":"AQqfGttI17lp"}},{"cell_type":"code","source":["# Annotator that transforms a text column from dataframe into an Annotation ready for NLP\n","documentAssembler = nlp.DocumentAssembler()\\\n","  .setInputCol(\"text\")\\\n","  .setOutputCol(\"sentence\")\\\n","\n","# Tokenizer splits words in a relevant format for NLP\n","tokenizer = nlp.Tokenizer()\\\n","  .setInputCols(\"sentence\")\\\n","  .setOutputCol(\"token\")\\\n","\n","# Clinical word embeddings trained on PubMED dataset\n","word_embeddings = nlp.WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n","    .setInputCols([\"sentence\", \"token\"])\\\n","    .setOutputCol(\"embeddings\")\n","\n","# NER model trained on n2c2 (de-identification and Heart Disease Risk Factors Challenge) datasets)\n","clinical_ner = medical.NerModel.pretrained(\"ner_deid_generic_augmented\", \"en\", \"clinical/models\") \\\n","    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n","    .setOutputCol(\"ner\")\n","\n","ner_converter_name = medical.NerConverterInternal()\\\n","    .setInputCols([\"sentence\",\"token\",\"ner\"])\\\n","    .setOutputCol(\"ner_chunk\")\n","\n","nameChunkObfuscator = medical.NameChunkObfuscatorApproach()\\\n","  .setInputCols(\"ner_chunk\")\\\n","  .setOutputCol(\"replacement\")\\\n","  .setRefFileFormat(\"csv\")\\\n","  .setObfuscateRefFile(\"names_test.txt\")\\\n","  .setRefSep(\"#\")\\\n","\n","replacer_name = medical.Replacer()\\\n","  .setInputCols(\"replacement\",\"sentence\")\\\n","  .setOutputCol(\"obfuscated_document_name\")\\\n","  .setUseReplacement(True)\n","\n","nlpPipeline = nlp.Pipeline(stages=[\n","    documentAssembler, \n","    tokenizer,\n","    word_embeddings,\n","    clinical_ner,\n","    ner_converter_name,\n","    nameChunkObfuscator,\n","    replacer_name,\n","    ])\n","\n","empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n","\n","model = nlpPipeline.fit(empty_data)\n","\n","result = model.transform(empty_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eaN4PazxUuLN","executionInfo":{"status":"ok","timestamp":1684502402469,"user_tz":240,"elapsed":108660,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"}},"outputId":"572574fd-0c5b-4d7a-98ef-89f2af430398"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["embeddings_clinical download started this may take some time.\n","Approximate size to download 1.6 GB\n","[OK!]\n","ner_deid_generic_augmented download started this may take some time.\n","[OK!]\n"]}]},{"cell_type":"markdown","source":["Let‚Äôs use LightPipeline here to extract the entities and make the replacements.\n","\n","[LightPipeline](https://nlp.johnsnowlabs.com/docs/en/concepts#using-spark-nlps-lightpipeline) is a Spark NLP specific Pipeline class equivalent to the Spark ML Pipeline, which achieves fast results when dealing with small amounts of data."],"metadata":{"id":"8Y8jLywKIoG2"}},{"cell_type":"code","source":["sample_text = \"John Davies is a 62 y.o. patient admitted. Mr. Davies was seen by attending physician Dr. Lorand and was scheduled for emergency assessment.\"\n","\n","lmodel = nlp.LightPipeline(model)\n","\n","res = lmodel.fullAnnotate(sample_text)"],"metadata":{"id":"xESKA6nXv3wQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The original text and the output of the `Replacer` annotator is shown below. All the names were replaced with values defined in the `names_test.txt` file."],"metadata":{"id":"Eqgco_PTMdhM"}},{"cell_type":"code","source":["print(\"Original text.  : \", res[0]['sentence'][0].result)\n","print(\"Obfuscated text : \", res[0]['obfuscated_document_name'][0].result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jpr8THxIxrFT","executionInfo":{"status":"ok","timestamp":1684502448479,"user_tz":240,"elapsed":195,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"}},"outputId":"ee395e34-c69b-4a7d-f504-36a4ed6c80f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Original text.  :  John Davies is a 62 y.o. patient admitted. Mr. Davies was seen by attending physician Dr. Lorand and was scheduled for emergency assessment.\n","Obfuscated text :  Joseeduardo is a 62 y.o. patient admitted. Mr. Teigan was seen by attending physician Dr. Mayson and was scheduled for emergency assessment.\n"]}]},{"cell_type":"markdown","source":["This time, change the `setUseReplacement` parameter setting to **False** and see the difference. "],"metadata":{"id":"n9DMErh6KVdS"}},{"cell_type":"code","source":["replacer_name = medical.Replacer()\\\n","  .setInputCols(\"replacement\",\"sentence\")\\\n","  .setOutputCol(\"obfuscated_document_name\")\\\n","  .setUseReplacement(False)\n","\n","nlpPipeline = nlp.Pipeline(stages=[\n","    documentAssembler, \n","    tokenizer,\n","    word_embeddings,\n","    clinical_ner,\n","    ner_converter_name,\n","    nameChunkObfuscator,\n","    replacer_name,\n","    ])\n","\n","model = nlpPipeline.fit(empty_data)\n","\n","result = model.transform(empty_data)"],"metadata":{"id":"PFg_YbgFzqfF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lmodel = nlp.LightPipeline(model)\n","\n","res = lmodel.fullAnnotate(sample_text)"],"metadata":{"id":"raEvepICzqcG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Original text.  : \", res[0]['sentence'][0].result)\n","print(\"Obfuscated text : \", res[0]['obfuscated_document_name'][0].result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SbuuW99xzqZp","executionInfo":{"status":"ok","timestamp":1684502564733,"user_tz":240,"elapsed":7,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"}},"outputId":"d13a8b87-a93c-45d1-e05e-e2129646ab8e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Original text.  :  John Davies is a 62 y.o. patient admitted. Mr. Davies was seen by attending physician Dr. Lorand and was scheduled for emergency assessment.\n","Obfuscated text :  John Davies is a 62 y.o. patient admitted. Mr. Davies was seen by attending physician Dr. Lorand and was scheduled for emergency assessment.\n"]}]},{"cell_type":"markdown","source":["As you can see, the names in the text are unaffected because of the change in the setting. "],"metadata":{"id":"6W9_SqmDNAX6"}},{"cell_type":"markdown","source":["## **üíª Date Normalizer Pipeline**\n","\n","\n","The `DateNormalizer` annotator transforms date mentions to a common standard format: YYYY/MM/DD. It is useful when using data from different sources, sometimes from different countries that has different formats to represent dates.\n","\n","For the relative dates (next year, past month, etc.), it is possible to define an anchor date to create the normalized date by setting the parameters anchorDateYear, anchorDateMonth, and anchorDateDay.\n","\n","The `Replacer` annotator will use the output of the `DateNormalizer` annotator, which replaced the extracted date entity by the standard date format, and provide a new text by replacing the original date entity with this value. "],"metadata":{"id":"btb7vPf4K4oQ"}},{"cell_type":"code","source":["# Annotator that transforms a text column from dataframe into an Annotation ready for NLP\n","documentAssembler = nlp.DocumentAssembler()\\\n","    .setInputCol(\"text\")\\\n","    .setOutputCol(\"document\")\n","\n","# Sentence Detector annotator, processes various sentences per line\n","sentenceDetector = nlp.SentenceDetector()\\\n","    .setInputCols([\"document\"])\\\n","    .setOutputCol(\"sentence\")\n","\n","# Tokenizer splits words in a relevant format for NLP\n","tokenizer = nlp.Tokenizer()\\\n","    .setInputCols([\"sentence\"])\\\n","    .setOutputCol(\"token\")\n","\n","# Clinical word embeddings trained on PubMED dataset\n","word_embeddings = nlp.WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n","    .setInputCols([\"sentence\", \"token\"])\\\n","    .setOutputCol(\"embeddings\")\n","\n","# NER model trained on n2c2 (de-identification and Heart Disease Risk Factors Challenge) datasets)\n","clinical_ner = medical.NerModel.pretrained(\"ner_deid_generic_augmented\", \"en\", \"clinical/models\") \\\n","    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n","    .setOutputCol(\"ner\")\n","\n","ner_converter = medical.NerConverterInternal()\\\n","    .setInputCols([\"sentence\", \"token\", \"ner\"])\\\n","    .setOutputCol(\"date_chunk\")\\\n","    .setWhiteList([\"DATE\"])\n","\n","date_normalizer = medical.DateNormalizer()\\\n","    .setInputCols('date_chunk')\\\n","    .setOutputCol('normalized_date')\n","\n","replacer = medical.Replacer()\\\n","    .setInputCols([\"normalized_date\",\"document\"])\\\n","    .setOutputCol(\"replaced_document\")\\\n","    .setUseReplacement(True)\n","\n","nlpPipeline = nlp.Pipeline(stages=[\n","      documentAssembler, \n","      sentenceDetector,\n","      tokenizer,\n","      word_embeddings,\n","      clinical_ner,\n","      ner_converter,\n","      date_normalizer,\n","      replacer])\n","\n","empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n","\n","model = nlpPipeline.fit(empty_data)\n"],"metadata":{"id":"oEObt46_wPwu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684503943976,"user_tz":240,"elapsed":6217,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"}},"outputId":"7c525111-dd1c-43d5-b3a9-d19488db6399"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["embeddings_clinical download started this may take some time.\n","Approximate size to download 1.6 GB\n","[OK!]\n","ner_deid_generic_augmented download started this may take some time.\n","[OK!]\n"]}]},{"cell_type":"markdown","source":["Let's define 7 texts; normalize the date entities and then replace the normalized entities with the original dates in the document by using the `Replacer` annotator."],"metadata":{"id":"bnKbW3ZDRcIm"}},{"cell_type":"code","source":["dates = [\n","'She has a history of pericarditis and pericardectomy on 08/02/2018 and developed a cough with right-sided chest pain.' ,\n","'She has been receiving gemcitabine and she receives three cycles of this with the last one being given on 11/2018. ',\n","'She was last seen in the clinic on 11/01/2018by Dr. Y.',\n","'Chris Brown was discharged on 12Mar2021',\n","'Last INR was on Tuesday, Jan 30, 2018, and her INR was 2.3. 2. Amiodarone 100 mg p.o. daily. ',\n","'We reviewed the pathology obtained from the pericardectomy on 13.04.1999, which was diagnostic of mesothelioma', \n","'A review of her CT scan on 3 April2020 prior to her pericardectomy, already shows bilateral plural effusions. ',\n","]\n","\n","df_dates = spark.createDataFrame(dates,StringType()).toDF('text')\n","\n","df_dates.show(truncate=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1f1r2RdjwUzL","executionInfo":{"status":"ok","timestamp":1684504372505,"user_tz":240,"elapsed":1637,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"}},"outputId":"8ab42a67-b84a-48c4-8b4c-ff5dbbdf3285"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+---------------------------------------------------------------------------------------------------------------------+\n","|text                                                                                                                 |\n","+---------------------------------------------------------------------------------------------------------------------+\n","|She has a history of pericarditis and pericardectomy on 08/02/2018 and developed a cough with right-sided chest pain.|\n","|She has been receiving gemcitabine and she receives three cycles of this with the last one being given on 11/2018.   |\n","|She was last seen in the clinic on 11/01/2018by Dr. Y.                                                               |\n","|Chris Brown was discharged on 12Mar2021                                                                              |\n","|Last INR was on Tuesday, Jan 30, 2018, and her INR was 2.3. 2. Amiodarone 100 mg p.o. daily.                         |\n","|We reviewed the pathology obtained from the pericardectomy on 13.04.1999, which was diagnostic of mesothelioma       |\n","|A review of her CT scan on 3 April2020 prior to her pericardectomy, already shows bilateral plural effusions.        |\n","+---------------------------------------------------------------------------------------------------------------------+\n","\n"]}]},{"cell_type":"code","source":["result = model.transform(df_dates)\n","\n","result_df = result.select(\"text\",F.explode(F.arrays_zip(result.date_chunk.result, \n","                                                        result.normalized_date.result,\n","                                                        result.replaced_document.result)).alias(\"cols\")) \\\n","                  .select(\"text\",F.expr(\"cols['1']\").alias(\"normalized_date\"),\n","                                 F.expr(\"cols['2']\").alias(\"replaced_document\"))\n","                  \n","result_df.show(truncate=100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UVdefBtoLi9t","executionInfo":{"status":"ok","timestamp":1684504300093,"user_tz":240,"elapsed":1964,"user":{"displayName":"Gursev Pirge","userId":"01579888832874245157"}},"outputId":"c2c27313-99ab-4dec-98ef-e0ad7985631c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+----------------------------------------------------------------------------------------------------+---------------+----------------------------------------------------------------------------------------------------+\n","|                                                                                                text|normalized_date|                                                                                   replaced_document|\n","+----------------------------------------------------------------------------------------------------+---------------+----------------------------------------------------------------------------------------------------+\n","|She has a history of pericarditis and pericardectomy on 08/02/2018 and developed a cough with rig...|     2018/08/02|She has a history of pericarditis and pericardectomy on 2018/08/02 and developed a cough with rig...|\n","|She has been receiving gemcitabine and she receives three cycles of this with the last one being ...|     2018/11/15|She has been receiving gemcitabine and she receives three cycles of this with the last one being ...|\n","|                                              She was last seen in the clinic on 11/01/2018by Dr. Y.|     2018/11/01|                                                She was last seen in the clinic on 2018/11/01 Dr. Y.|\n","|                                                             Chris Brown was discharged on 12Mar2021|     2021/03/12|                                                            Chris Brown was discharged on 2021/03/12|\n","|       Last INR was on Tuesday, Jan 30, 2018, and her INR was 2.3. 2. Amiodarone 100 mg p.o. daily. |     2018/01/30|                  Last INR was on 2018/01/30, and her INR was 2.3. 2. Amiodarone 100 mg p.o. daily. |\n","|We reviewed the pathology obtained from the pericardectomy on 13.04.1999, which was diagnostic of...|     1999/04/13|We reviewed the pathology obtained from the pericardectomy on 1999/04/13, which was diagnostic of...|\n","|A review of her CT scan on 3 April2020 prior to her pericardectomy, already shows bilateral plura...|     2020/04/03|A review of her CT scan on 2020/04/03 prior to her pericardectomy, already shows bilateral plural...|\n","+----------------------------------------------------------------------------------------------------+---------------+----------------------------------------------------------------------------------------------------+\n","\n"]}]},{"cell_type":"markdown","source":["The dataframe above shows the original texts, normalized dates and `replaced_document` involving the normalized dates. "],"metadata":{"id":"axbEolr6Q8pT"}}]}