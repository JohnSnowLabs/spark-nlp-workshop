{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8V_Ow3cAVEYe"
      },
      "source": [
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oxciDi-gq7m"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/Spark_NLP_Udemy_MOOC/Healthcare_NLP/Replacer.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0fJRpNJBslT"
      },
      "source": [
        "# **Replacer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeclGJmrVLjX"
      },
      "source": [
        "\n",
        "This notebook will cover the `Replacer` annotator.\n",
        "\n",
        "`Replacer` allows to replace entities in the original text with the ones extracted by the annotators `NameChunkObfuscatorApproach` or `DateNormalizer`.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**üìñ Learning Objectives:**\n",
        "\n",
        "1. Understand how `Replacer` works.\n",
        "\n",
        "2. Understand how `Replacer` can be used to with the `DateNormalizer` annotator and in the deintification process.\n",
        "\n",
        "3. Become comfortable using the `setUseReplacement` parameter of the annotator.\n",
        "\n",
        "\n",
        "**üîó Helpful Links:**\n",
        "\n",
        "- Documentation : [Replacer](https://nlp.johnsnowlabs.com/docs/en/licensed_annotators#replacer)\n",
        "\n",
        "- Python Docs : [Replacer](https://nlp.johnsnowlabs.com/licensed/api/python/reference/autosummary/sparknlp_jsl/annotator/deid/replacer/index.html#sparknlp_jsl.annotator.deid.replacer.Replacer)\n",
        "\n",
        "- Scala Docs : [Replacer](https://nlp.johnsnowlabs.com/licensed/api/com/johnsnowlabs/nlp/annotators/deid/Replacer.html)\n",
        "\n",
        "- For extended examples of usage, see the [Clinical Deidentification](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Healthcare/4.Clinical_DeIdentification.ipynb#scrollTo=9alThnhZeOvn) and [Date Normalizer](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/healthcare-nlp/13.0.Date_Normalizer.ipynb#scrollTo=yX57W_6SLiWz) notebooks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OV0hPSCWXslc"
      },
      "source": [
        "## **üìú Background**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ms9xwzYACPtU"
      },
      "source": [
        "`Replacer` is most often used in conjunction with the `DateNormalizer` annotator or in deidentification pipelines.\n",
        "\n",
        "With the dates, the `Replacer` annotator is used to replace specific tokens in a text with another token or string. The `DateNormalizer` annotator, on the other hand, is used to normalize dates and times to a standardized format.\n",
        "\n",
        "Obfuscation in healthcare is the act of making healthcare data difficult to understand or use without authorization. This can be done by replacing or removing identifying information, such as names, dates of birth, and Social Security numbers. Obfuscation can also be used to hide the contents of healthcare records, such as diagnoses, medications, and treatment plans.\n",
        "\n",
        "In the **deidentification** process, the `Replacer` annotator is used to replace certain tokens or patterns in the text with specified values. For example, it can be used to replace all instances of a person's name with a placeholder like \"PERSON\".\n",
        "\n",
        "The `NameChunkObfuscatorApproach` annotator is used to identify and obfuscate sensitive named entities in the text, such as people's names, addresses, dates of birth, SSNs etc.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8qy2MI2XySv"
      },
      "source": [
        "## **üé¨ Colab Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HuLFt0OdBkuo"
      },
      "outputs": [],
      "source": [
        "# Install the johnsnowlabs library to access Spark-OCR and Spark-NLP for Healthcare, Finance, and Legal.\n",
        "! pip install -q johnsnowlabs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URRyJvTMBtXQ"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "print('Please Upload your John Snow Labs License using the button below')\n",
        "license_keys = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OocQcx0I7ky"
      },
      "outputs": [],
      "source": [
        "from johnsnowlabs import nlp, medical\n",
        "\n",
        "# After uploading your license run this to install all licensed Python Wheels and pre-download Jars the Spark Session JVM\n",
        "nlp.settings.enforce_versions=False\n",
        "nlp.install()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ua2KKPdVI7iB"
      },
      "outputs": [],
      "source": [
        "import pyspark.sql.functions as F\n",
        "\n",
        "# Automatically load license data and start a session with all jars user has access to\n",
        "spark = nlp.start()\n",
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_4conOIYj6D"
      },
      "source": [
        "## **üñ®Ô∏è Input/Output Annotation Types**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Fc_3iRwYk8N"
      },
      "source": [
        "- Input: `DOCUMENT`, `CHUNK`\n",
        "\n",
        "- Output: `DOCUMENT`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgCCuKLdepW9"
      },
      "source": [
        "## **üîé Parameters**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4tqQGMsj1BQ"
      },
      "source": [
        "- `setUseReplacement`: (Boolean) Specifies whether to use the replacement field from the metadata of chunk if it exists. Default: True.\n",
        "\n",
        "\n",
        "- `setNoneValuesTo`: (String)\n",
        "Determines the action to take when encountering a value of 'NONE' in the annotation. This parameter can take one of the following string values:\n",
        "   * \"entity\": Replaces 'NONE' values with the entity field extracted from the annotation, if available. If the entity field is not available, it uses the string \"NONE\" wrapped by the specified delimiters.\n",
        "   * \"place_holder\": Replaces 'NONE' values with a placeholder string wrapped by the specified delimiters.\n",
        "   * \"skip\": Retains the original target_text from the annotation's metadata if available. If not available, it retains the original annotation result.\n",
        "   * \"prioritize_static_entity\": If a static entity mapping is available for the entity type, it will use this value for mapping.\n",
        "\n",
        "- `setPlaceHolder`: (String) Sets the placeholder string to use when noneValuesTo is set to \"place_holder\". This placeholder string will be wrapped by the delimiters defined in placeHolderDelimiters.\n",
        "\n",
        "- `setPlaceHolderDelimiters`: (String) Sets an array of two strings used as delimiters to wrap the placeholder, prioritize_static_entity or entity field when noneValuesTo is set to \"place_holder\", \"prioritize_static_entity\" or \"entity\". The first element of the array is the prefix delimiter, and the second element is the suffix delimiter.\n",
        "\n",
        "- `setReturnEntityMappings`: (Boolean) With this property you select if you want to return mapping column. True for returning mapping column, False otherwise.\n",
        "\n",
        "- `setMappingsColumn`: (String) Sets column name for mapping. This column maps the annotations to their corresponding chunks before the entities are replaced.\n",
        "\n",
        "- `setStaticEntityMappings`: (Dict) Static entity mappings. A dictionary with entity types as keys and replacement values as values.\n",
        "\n",
        "- `setStaticEntityMappingsFallback`: (String) Fallback option for static entity mappings. Allowed values: 'entity', 'place_holder', 'skip', 'error'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LW_kZcwMeK2h"
      },
      "source": [
        "## **üíª Deidentification Pipeline**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xX16Jq-fyRuZ"
      },
      "source": [
        "`Obfuscation` refers to the process of making data unclear, confusing, or difficult to understand or interpret. The goal of obfuscation is to hide or protect **sensitive information** by altering it in a way that makes it challenging for unauthorized parties to access or comprehend.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "The `NameChunkObfuscatorApproach` annotator contains all the methods for training a NameChunkObfuscator model. This module can replace name entities with consistent fakers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2jHRADpwjR-"
      },
      "outputs": [],
      "source": [
        "names = \"\"\"Mitchell#NAME\n",
        "Clifford#NAME\n",
        "Jeremiah#NAME\n",
        "Lawrence#NAME\n",
        "Brittany#NAME\n",
        "Patricia#NAME\n",
        "Samantha#NAME\n",
        "Jennifer#NAME\n",
        "Jackson#NAME\n",
        "Leonard#NAME\n",
        "Randall#NAME\n",
        "Camacho#NAME\n",
        "Ferrell#NAME\n",
        "Mueller#NAME\n",
        "Bowman#NAME\n",
        "Hansen#NAME\n",
        "Acosta#NAME\n",
        "Gillespie#NAME\n",
        "Zimmerman#NAME\n",
        "Gillespie#NAME\n",
        "Chandler#NAME\n",
        "Bradshaw#NAME\n",
        "Ferguson#NAME\n",
        "Jacobson#NAME\n",
        "Figueroa#NAME\n",
        "Chandler#NAME\n",
        "Schaefer#NAME\n",
        "Matthews#NAME\n",
        "Ferguson#NAME\n",
        "Bradshaw#NAME\n",
        "Figueroa#NAME\n",
        "Delacruz#NAME\n",
        "Gallegos#NAME\n",
        "Villarreal#NAME\n",
        "Williamson#NAME\n",
        "Montgomery#NAME\n",
        "Mclaughlin#NAME\n",
        "Blankenship#NAME\n",
        "Fitzpatrick#NAME\n",
        "\"\"\"\n",
        "\n",
        "with open('names_test.txt', 'w') as file:\n",
        "    file.write(names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQqfGttI17lp"
      },
      "source": [
        "### `setUseReplacement`\n",
        "\n",
        "<br/>\n",
        "\n",
        "This parameter is used to enable or disable replacement of entities.\n",
        "\n",
        "True is for Replacing, False for otherwise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaN4PazxUuLN"
      },
      "outputs": [],
      "source": [
        "# Annotator that transforms a text column from dataframe into an Annotation ready for NLP\n",
        "documentAssembler = nlp.DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"sentence\")\\\n",
        "\n",
        "# Tokenizer splits words in a relevant format for NLP\n",
        "tokenizer = nlp.Tokenizer()\\\n",
        "    .setInputCols(\"sentence\")\\\n",
        "    .setOutputCol(\"token\")\\\n",
        "\n",
        "# Clinical word embeddings trained on PubMED dataset\n",
        "word_embeddings = nlp.WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n",
        "    .setInputCols([\"sentence\", \"token\"])\\\n",
        "    .setOutputCol(\"embeddings\")\n",
        "\n",
        "# NER model trained on n2c2 (de-identification and Heart Disease Risk Factors Challenge) datasets)\n",
        "clinical_ner = medical.NerModel.pretrained(\"ner_deid_generic_augmented\", \"en\", \"clinical/models\") \\\n",
        "    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
        "    .setOutputCol(\"ner\")\n",
        "\n",
        "ner_converter_name = medical.NerConverterInternal()\\\n",
        "    .setInputCols([\"sentence\",\"token\",\"ner\"])\\\n",
        "    .setOutputCol(\"ner_chunk\")\n",
        "\n",
        "nameChunkObfuscator = medical.NameChunkObfuscatorApproach()\\\n",
        "    .setInputCols(\"ner_chunk\")\\\n",
        "    .setOutputCol(\"replacement\")\\\n",
        "    .setRefFileFormat(\"csv\")\\\n",
        "    .setObfuscateRefFile(\"names_test.txt\")\\\n",
        "    .setRefSep(\"#\")\\\n",
        "\n",
        "replacer_name = medical.Replacer()\\\n",
        "    .setInputCols(\"replacement\",\"sentence\")\\\n",
        "    .setOutputCol(\"obfuscated_document_name\")\\\n",
        "    .setUseReplacement(True)\n",
        "\n",
        "nlpPipeline = nlp.Pipeline(stages=[\n",
        "    documentAssembler,\n",
        "    tokenizer,\n",
        "    word_embeddings,\n",
        "    clinical_ner,\n",
        "    ner_converter_name,\n",
        "    nameChunkObfuscator,\n",
        "    replacer_name,\n",
        "    ])\n",
        "\n",
        "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
        "\n",
        "model = nlpPipeline.fit(empty_data)\n",
        "\n",
        "result = model.transform(empty_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Y8jLywKIoG2"
      },
      "source": [
        "Let‚Äôs use LightPipeline here to extract the entities and make the replacements.\n",
        "\n",
        "[LightPipeline](https://nlp.johnsnowlabs.com/docs/en/concepts#using-spark-nlps-lightpipeline) is a Spark NLP specific Pipeline class equivalent to the Spark ML Pipeline, which achieves fast results when dealing with small amounts of data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xESKA6nXv3wQ"
      },
      "outputs": [],
      "source": [
        "sample_text = \"John Davies is a 62 y.o. patient admitted. Mr. Davies was seen by attending physician Dr. Lorand and was scheduled for emergency assessment.\"\n",
        "\n",
        "lmodel = nlp.LightPipeline(model)\n",
        "\n",
        "res = lmodel.fullAnnotate(sample_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eqgco_PTMdhM"
      },
      "source": [
        "The original text and the output of the `Replacer` annotator is shown below. All the names were replaced with values defined in the `names_test.txt` file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpr8THxIxrFT",
        "outputId": "db7ee7d7-dd79-4525-fd48-a4d3dfacc024"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text.  :  John Davies is a 62 y.o. patient admitted. Mr. Davies was seen by attending physician Dr. Lorand and was scheduled for emergency assessment.\n",
            "Obfuscated text :  Patriciaann is a 62 y.o. patient admitted. Mr. Noella was seen by attending physician Dr. Genice and was scheduled for emergency assessment.\n"
          ]
        }
      ],
      "source": [
        "print(\"Original text.  : \", res[0]['sentence'][0].result)\n",
        "print(\"Obfuscated text : \", res[0]['obfuscated_document_name'][0].result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9DMErh6KVdS"
      },
      "source": [
        "This time, change the `setUseReplacement` parameter setting to **False** and see the difference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFg_YbgFzqfF"
      },
      "outputs": [],
      "source": [
        "replacer_name = medical.Replacer()\\\n",
        "  .setInputCols(\"replacement\",\"sentence\")\\\n",
        "  .setOutputCol(\"obfuscated_document_name\")\\\n",
        "  .setUseReplacement(False)\n",
        "\n",
        "nlpPipeline = nlp.Pipeline(stages=[\n",
        "    documentAssembler,\n",
        "    tokenizer,\n",
        "    word_embeddings,\n",
        "    clinical_ner,\n",
        "    ner_converter_name,\n",
        "    nameChunkObfuscator,\n",
        "    replacer_name,\n",
        "    ])\n",
        "\n",
        "model = nlpPipeline.fit(empty_data)\n",
        "\n",
        "result = model.transform(empty_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "raEvepICzqcG"
      },
      "outputs": [],
      "source": [
        "lmodel = nlp.LightPipeline(model)\n",
        "\n",
        "res = lmodel.fullAnnotate(sample_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbuuW99xzqZp",
        "outputId": "f0042cbd-d62f-4b5e-f9c7-74a6cf09c653"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text.  :  John Davies is a 62 y.o. patient admitted. Mr. Davies was seen by attending physician Dr. Lorand and was scheduled for emergency assessment.\n",
            "Obfuscated text :  John Davies is a 62 y.o. patient admitted. Mr. Davies was seen by attending physician Dr. Lorand and was scheduled for emergency assessment.\n"
          ]
        }
      ],
      "source": [
        "print(\"Original text.  : \", res[0]['sentence'][0].result)\n",
        "print(\"Obfuscated text : \", res[0]['obfuscated_document_name'][0].result)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `setNoneValuesTo`\n",
        "\n",
        "<br/>\n",
        "\n",
        "Determines the action to take when encountering a value of 'NONE' in the annotation.This parameter can take one of the following string values:\n",
        "\n",
        "- **\"entity\"**: Replaces 'NONE' values with the entity field extracted from the annotation, if available. If the entity field is not available, it uses the string \"NONE\" wrapped by the specified delimiters.\n",
        "  \n",
        "- **\"place_holder\"**: Replaces 'NONE' values with a placeholder string wrapped by the specified delimiters.\n",
        "  \n",
        "- **\"skip\"**: Retains the original annotation result or uses the `target_text` from the annotation's metadata if available.\n",
        "  \n",
        "- **\"prioritize_static_entity\"**: If a static entity mapping is available for the entity type, it will use this value for mapping.\n",
        "\n",
        "Error Handling:\n",
        "If an unrecognized value is provided, an `IllegalArgumentException` will be thrown.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZKqeVjTJh3X1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = \"Patient resting in bed. Patient given azithromycin without any difficulty. Patient denies nausea at this time. zofran declined. Patient is also having intermittent sweating\"\n",
        "\n",
        "data = spark.createDataFrame([[sample_text]]).toDF(\"text\")"
      ],
      "metadata": {
        "id": "0VgOSm9XDEPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clinical_ner = medical.NerModel.pretrained(\"ner_jsl\", \"en\", \"clinical/models\") \\\n",
        "    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
        "    .setOutputCol(\"ner\") \\\n",
        "\n",
        "ner_converter = medical.NerConverterInternal() \\\n",
        "    .setInputCols([\"sentence\", \"token\", \"ner\"]) \\\n",
        "    .setOutputCol(\"ner_chunk\")\n",
        "\n",
        "chunkMapper = medical.ChunkMapperModel.pretrained(\"drug_action_treatment_mapper\", \"en\", \"clinical/models\") \\\n",
        "    .setInputCols([\"ner_chunk\"]) \\\n",
        "    .setOutputCol(\"relations\") \\\n",
        "    .setRels([\"action\"]) \\\n",
        "\n",
        "mapper2chunk = medical.Mapper2Chunk() \\\n",
        "    .setInputCols([\"relations\"]) \\\n",
        "    .setOutputCol(\"chunk\") \\\n",
        "\n",
        "replacer_name = medical.Replacer()\\\n",
        "    .setInputCols(\"chunk\",\"sentence\")\\\n",
        "    .setOutputCol(\"obfuscated_document_name\")\\\n",
        "    .setUseReplacement(False)\\\n",
        "    .setNoneValuesTo(\"entity\")\n",
        "\n",
        "nlpPipeline = nlp.Pipeline(stages=[\n",
        "    documentAssembler,\n",
        "    tokenizer,\n",
        "    word_embeddings,\n",
        "    clinical_ner,\n",
        "    ner_converter,\n",
        "    chunkMapper,\n",
        "    mapper2chunk,\n",
        "    replacer_name,\n",
        "    ])"
      ],
      "metadata": {
        "id": "BPvvkntAiGUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = nlpPipeline.fit(data).transform(data)"
      ],
      "metadata": {
        "id": "YYV1GlV-iGRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.selectExpr(\"obfuscated_document_name.result\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsEY9k32D0Lv",
        "outputId": "0a995a0e-e1cc-4fd5-eac6-f47e76bd1129"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|result                                                                                                                                                                           |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|[Patient resting in bed. Patient given bactericidal without any difficulty. Patient denies antiemetic at this time. zofran declined. Patient is also having <Modifier> <Symptom>]|\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `setPlaceHolder`\n",
        "\n",
        "<br/>\n",
        "\n",
        "Specifies the placeholder string to use when `noneValuesTo` is set to \"place_holder\".\n",
        "            This placeholder string will be wrapped by the delimiters if `placeHolderDelimiters` are defined.\n",
        "\n"
      ],
      "metadata": {
        "id": "5WnBRinB_CJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "replacer_name = medical.Replacer()\\\n",
        "  .setInputCols(\"chunk\",\"sentence\")\\\n",
        "  .setOutputCol(\"obfuscated_document_name\")\\\n",
        "  .setUseReplacement(False)\\\n",
        "  .setNoneValuesTo(\"place_holder\")\\\n",
        "  .setPlaceHolder(\"******\")\n",
        "\n",
        "\n",
        "nlpPipeline = nlp.Pipeline(stages=[\n",
        "    documentAssembler,\n",
        "    tokenizer,\n",
        "    word_embeddings,\n",
        "    clinical_ner,\n",
        "    ner_converter,\n",
        "    chunkMapper,\n",
        "    mapper2chunk,\n",
        "    replacer_name,\n",
        "    ])"
      ],
      "metadata": {
        "id": "ybdHCTnM_TLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = nlpPipeline.fit(data).transform(data)"
      ],
      "metadata": {
        "id": "JOkIioOqD_Kj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.selectExpr(\"obfuscated_document_name.result\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCeeiKBuEBwc",
        "outputId": "97e42ccf-3967-47dd-e615-181751b73501"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|result                                                                                                                                                                        |\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|[Patient resting in bed. Patient given bactericidal without any difficulty. Patient denies antiemetic at this time. zofran declined. Patient is also having <******> <******>]|\n",
            "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `setPlaceHolderDelimiters`\n",
        "\n",
        "<br/>\n",
        "\n",
        "An array of two strings used as delimiters to wrap the placeholder or entity field\n",
        "            when noneValuesTo is set to \"place_holder\" or \"entity\". The first element of the array\n",
        "            is the prefix delimiter,and the second element is the suffix delimiter.\n",
        "            Default is ['<', '>']\n",
        "\n"
      ],
      "metadata": {
        "id": "2tiMVXVW_iqe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "replacer_name = medical.Replacer()\\\n",
        "  .setInputCols(\"chunk\",\"sentence\")\\\n",
        "  .setOutputCol(\"obfuscated_document_name\")\\\n",
        "  .setUseReplacement(False)\\\n",
        "  .setNoneValuesTo(\"place_holder\")\\\n",
        "  .setPlaceHolder(\"IGNORE\")\\\n",
        "  .setPlaceHolderDelimiters([\"<<<\", \">>>\"])\n",
        "\n",
        "nlpPipeline = nlp.Pipeline(stages=[\n",
        "    documentAssembler,\n",
        "    tokenizer,\n",
        "    word_embeddings,\n",
        "    clinical_ner,\n",
        "    ner_converter,\n",
        "    chunkMapper,\n",
        "    mapper2chunk,\n",
        "    replacer_name,\n",
        "    ])"
      ],
      "metadata": {
        "id": "E62dky5r_vZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = nlpPipeline.fit(data).transform(data)"
      ],
      "metadata": {
        "id": "0BMZaexnEItG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.selectExpr(\"obfuscated_document_name.result\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MP_fINbGEIOW",
        "outputId": "823815c1-c3cf-43b8-dff1-3a840e32c4db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|result                                                                                                                                                                                |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|[Patient resting in bed. Patient given bactericidal without any difficulty. Patient denies antiemetic at this time. zofran declined. Patient is also having <<<IGNORE>>> <<<IGNORE>>>]|\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **üíª Mapper Pipeline**"
      ],
      "metadata": {
        "id": "1Ni9K3B1-Msd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `setReturnEntityMappings`\n",
        "\n",
        "<br/>\n",
        "\n",
        "With this property you select if you want to return mapping column. True for returning mapping column, False otherwise.\n",
        "\n",
        "You can track which operation was applied during the replacement process by referring to the `process` in the `metadata` within the mapping column, to see which specific rule was used for each replacement.\n"
      ],
      "metadata": {
        "id": "VX1vx3Jv9H0v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Annotator that transforms a text column from dataframe into an Annotation ready for NLP\n",
        "documentAssembler = nlp.DocumentAssembler()\\\n",
        "      .setInputCol(\"text\")\\\n",
        "      .setOutputCol(\"document\")\n",
        "\n",
        "sentenceDetector = nlp.SentenceDetector()\\\n",
        "      .setInputCols(\"document\")\\\n",
        "      .setOutputCol(\"sentence\")\n",
        "\n",
        "tokenizer = nlp.Tokenizer()\\\n",
        "  .setInputCols(\"sentence\")\\\n",
        "  .setOutputCol(\"token\")\\\n",
        "\n",
        "word_embeddings = nlp.WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n",
        "    .setInputCols([\"sentence\", \"token\"])\\\n",
        "    .setOutputCol(\"embeddings\")\n",
        "\n",
        "clinical_ner = medical.NerModel.pretrained(\"ner_jsl\", \"en\", \"clinical/models\") \\\n",
        "    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
        "    .setOutputCol(\"ner\") \\\n",
        "\n",
        "ner_converter = medical.NerConverterInternal() \\\n",
        "    .setInputCols([\"sentence\", \"token\", \"ner\"]) \\\n",
        "    .setOutputCol(\"ner_chunk\")\n",
        "\n",
        "chunkMapper = medical.ChunkMapperModel.pretrained(\"drug_action_treatment_mapper\", \"en\", \"clinical/models\") \\\n",
        "    .setInputCols([\"ner_chunk\"]) \\\n",
        "    .setOutputCol(\"relations\") \\\n",
        "    .setRels([\"action\"]) \\\n",
        "\n",
        "mapper2Chunk = medical.Mapper2Chunk() \\\n",
        "    .setInputCols([\"relations\"]) \\\n",
        "    .setOutputCol(\"chunk\") \\\n",
        "\n",
        "replacer = medical.Replacer() \\\n",
        "      .setInputCols(\"chunk\", \"sentence\")\\\n",
        "      .setOutputCol(\"doc\")\\\n",
        "      .setUseReplacement(True)\\\n",
        "      .setNoneValuesTo(\"entity\") \\\n",
        "      .setReturnEntityMappings(True)\n",
        "\n",
        "\n",
        "nlpPipeline = nlp.Pipeline(stages=[\n",
        "    documentAssembler,\n",
        "    sentenceDetector,\n",
        "    tokenizer,\n",
        "    word_embeddings,\n",
        "    clinical_ner,\n",
        "    ner_converter,\n",
        "    chunkMapper,\n",
        "    mapper2Chunk,\n",
        "    replacer\n",
        "    ])\n",
        "\n",
        "sample_text = \"Patient resting in bed. Patient given azithromycin without any difficulty. Patient denies nausea at this time. zofran declined. Patient is also having intermittent sweating\"\n",
        "\n",
        "data = spark.createDataFrame([[sample_text]]).toDF(\"text\")\n",
        "result = nlpPipeline.fit(data).transform(data)"
      ],
      "metadata": {
        "id": "8N6-9eVw9Rs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.selectExpr(\"explode(replacer_mappings) mappings\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZV3Fw_Z--ald",
        "outputId": "7216dc09-bc4d-464e-8838-101ca58514aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|mappings                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
            "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|{chunk, 38, 49, bactericidal, {originalChunk -> bactericidal, chunk -> 0, __trained__ -> azithromycin, relation -> action, process -> do_nothing, all_k_distances -> 0.0:::0.0, beginOriginalChunk -> 38, __distance_function__ -> levenshtein, confidence -> 0.9956, all_k_resolutions -> bactericidal:::ophthalmologicals, target_text -> azithromycin, ner_source -> ner_chunk, ops -> 0.0, all_relations -> ophthalmologicals, entity -> Drug_Ingredient, endOriginalChunk -> 49, resolved_text -> bactericidal, distance -> 0.0, sentence -> 1, __relation_name__ -> action}, []}                                |\n",
            "|{chunk, 89, 98, antiemetic, {originalChunk -> antiemetic, chunk -> 1, __trained__ -> nausea, relation -> action, process -> do_nothing, all_k_distances -> 0.0:::0.0, beginOriginalChunk -> 90, __distance_function__ -> levenshtein, confidence -> 0.9979, all_k_resolutions -> antiemetic:::drugs for functional gastrointestinal disorders, target_text -> nausea, ner_source -> ner_chunk, ops -> 0.0, all_relations -> drugs for functional gastrointestinal disorders, entity -> Symptom, endOriginalChunk -> 95, resolved_text -> antiemetic, distance -> 0.0, sentence -> 2, __relation_name__ -> action}, []}|\n",
            "|{chunk, 113, 121, <Symptom>, {originalChunk -> NONE, chunk -> 2, process -> entity, beginOriginalChunk -> 111, confidence -> 0.31055, target_text -> zofran declined, ner_source -> ner_chunk, entity -> Symptom, endOriginalChunk -> 125, sentence -> 3}, []}                                                                                                                                                                                                                                                                                                                                                        |\n",
            "|{chunk, 146, 155, <Modifier>, {originalChunk -> NONE, chunk -> 3, process -> entity, beginOriginalChunk -> 151, confidence -> 0.9117, target_text -> intermittent, ner_source -> ner_chunk, entity -> Modifier, endOriginalChunk -> 162, sentence -> 4}, []}                                                                                                                                                                                                                                                                                                                                                          |\n",
            "|{chunk, 157, 165, <Symptom>, {originalChunk -> NONE, chunk -> 4, process -> entity, beginOriginalChunk -> 164, confidence -> 0.806, target_text -> sweating, ner_source -> ner_chunk, entity -> Symptom, endOriginalChunk -> 171, sentence -> 4}, []}                                                                                                                                                                                                                                                                                                                                                                 |\n",
            "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `setMappingsColumn`\n",
        "\n",
        "<br/>\n",
        "\n",
        "Sets column name for mapping. This column maps the annotations to their corresponding chunks before the entities are replaced.\n"
      ],
      "metadata": {
        "id": "-dS37vT0-ToP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "replacer = medical.Replacer() \\\n",
        "      .setInputCols(\"chunk\", \"sentence\")\\\n",
        "      .setOutputCol(\"doc\")\\\n",
        "      .setUseReplacement(True)\\\n",
        "      .setNoneValuesTo(\"skip\") \\\n",
        "      .setReturnEntityMappings(True) \\\n",
        "      .setMappingsColumn(\"mappings\")\n",
        "\n",
        "\n",
        "nlpPipeline = nlp.Pipeline(stages=[\n",
        "    documentAssembler,\n",
        "    sentenceDetector,\n",
        "    tokenizer,\n",
        "    word_embeddings,\n",
        "    clinical_ner,\n",
        "    ner_converter,\n",
        "    chunkMapper,\n",
        "    mapper2Chunk,\n",
        "    replacer\n",
        "    ])\n",
        "\n",
        "sample_text = \"Patient resting in bed. Patient given azithromycin without any difficulty. Patient denies nausea at this time. zofran declined. Patient is also having intermittent sweating\"\n",
        "\n",
        "data = spark.createDataFrame([[sample_text]]).toDF(\"text\")\n",
        "result = nlpPipeline.fit(data).transform(data)"
      ],
      "metadata": {
        "id": "WaRkwwXE-e3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.selectExpr(\"explode(mappings) as mappings\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loN2Yc_GAZ4e",
        "outputId": "931a23cc-cb83-4e9e-d8fa-63d0e41c4b75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|mappings                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
            "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|{chunk, 38, 49, bactericidal, {originalChunk -> bactericidal, chunk -> 0, __trained__ -> azithromycin, relation -> action, process -> do_nothing, all_k_distances -> 0.0:::0.0, beginOriginalChunk -> 38, __distance_function__ -> levenshtein, confidence -> 0.9956, all_k_resolutions -> bactericidal:::ophthalmologicals, target_text -> azithromycin, ner_source -> ner_chunk, ops -> 0.0, all_relations -> ophthalmologicals, entity -> Drug_Ingredient, endOriginalChunk -> 49, resolved_text -> bactericidal, distance -> 0.0, sentence -> 1, __relation_name__ -> action}, []}                                |\n",
            "|{chunk, 89, 98, antiemetic, {originalChunk -> antiemetic, chunk -> 1, __trained__ -> nausea, relation -> action, process -> do_nothing, all_k_distances -> 0.0:::0.0, beginOriginalChunk -> 90, __distance_function__ -> levenshtein, confidence -> 0.9979, all_k_resolutions -> antiemetic:::drugs for functional gastrointestinal disorders, target_text -> nausea, ner_source -> ner_chunk, ops -> 0.0, all_relations -> drugs for functional gastrointestinal disorders, entity -> Symptom, endOriginalChunk -> 95, resolved_text -> antiemetic, distance -> 0.0, sentence -> 2, __relation_name__ -> action}, []}|\n",
            "|{chunk, 113, 127, zofran declined, {originalChunk -> NONE, chunk -> 2, process -> skip, beginOriginalChunk -> 111, confidence -> 0.31055, target_text -> zofran declined, ner_source -> ner_chunk, entity -> Symptom, endOriginalChunk -> 125, sentence -> 3}, []}                                                                                                                                                                                                                                                                                                                                                    |\n",
            "|{chunk, 152, 163, intermittent, {originalChunk -> NONE, chunk -> 3, process -> skip, beginOriginalChunk -> 151, confidence -> 0.9117, target_text -> intermittent, ner_source -> ner_chunk, entity -> Modifier, endOriginalChunk -> 162, sentence -> 4}, []}                                                                                                                                                                                                                                                                                                                                                          |\n",
            "|{chunk, 165, 172, sweating, {originalChunk -> NONE, chunk -> 4, process -> skip, beginOriginalChunk -> 164, confidence -> 0.806, target_text -> sweating, ner_source -> ner_chunk, entity -> Symptom, endOriginalChunk -> 171, sentence -> 4}, []}                                                                                                                                                                                                                                                                                                                                                                    |\n",
            "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `setStaticEntityMappings`\n",
        "\n",
        "<br/>\n",
        "\n",
        "A dictionary with entity types as keys and replacement values as values.Static entity mappings. A dictionary with entity types as keys and replacement values as values.\n",
        "\n",
        "The number of times each operation was applied can be viewed in the `statistics` section of the `metadata`, which provides detailed insights into the frequency of each process.\n"
      ],
      "metadata": {
        "id": "JI5tFkpN-xF9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documentAssembler = nlp.DocumentAssembler()\\\n",
        "      .setInputCol(\"text\")\\\n",
        "      .setOutputCol(\"document\")\n",
        "\n",
        "sentenceDetector = nlp.SentenceDetector()\\\n",
        "      .setInputCols(\"document\")\\\n",
        "      .setOutputCol(\"sentence\")\n",
        "\n",
        "tokenizer = nlp.Tokenizer()\\\n",
        "    .setInputCols(\"sentence\")\\\n",
        "    .setOutputCol(\"token\")\\\n",
        "\n",
        "word_embeddings = nlp.WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n",
        "    .setInputCols([\"sentence\", \"token\"])\\\n",
        "    .setOutputCol(\"embeddings\")\n",
        "\n",
        "clinical_ner = medical.NerModel.pretrained(\"ner_clinical\", \"en\", \"clinical/models\") \\\n",
        "    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
        "    .setOutputCol(\"ner\") \\\n",
        "\n",
        "ner_converter = medical.NerConverterInternal() \\\n",
        "    .setInputCols([\"sentence\", \"token\", \"ner\"]) \\\n",
        "    .setOutputCol(\"ner_chunk\")\n",
        "\n",
        "replacer = medical.Replacer() \\\n",
        "    .setInputCols(\"ner_chunk\", \"sentence\")\\\n",
        "    .setOutputCol(\"doc\")\\\n",
        "    .setUseReplacement(True)\\\n",
        "    .setNoneValuesTo(\"prioritize_static_entity\")\\\n",
        "    .setReturnEntityMappings(True) \\\n",
        "    .setMappingsColumn(\"mappings\") \\\n",
        "    .setStaticEntityMappings({\"TREATMENT\": \"MEDICATION\", \"PROBLEM\": \"NEED TO HANDLE\"})\n",
        "\n",
        "\n",
        "nlpPipeline = nlp.Pipeline(stages=[\n",
        "    documentAssembler,\n",
        "    sentenceDetector,\n",
        "    tokenizer,\n",
        "    word_embeddings,\n",
        "    clinical_ner,\n",
        "    ner_converter,\n",
        "    replacer\n",
        "    ])\n",
        "\n",
        "sample_text = \"Patient resting in bed. Patient given azithromycin without any difficulty. Patient denies nausea at this time. zofran declined. Patient is also having intermittent sweating\"\n",
        "\n",
        "data = spark.createDataFrame([[sample_text]]).toDF(\"text\")\n",
        "result = nlpPipeline.fit(data).transform(data)"
      ],
      "metadata": {
        "id": "YHUOKce_-wk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.selectExpr(\"explode(mappings) as mappings\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4kjhzfqV1iZ",
        "outputId": "dc082c88-b55d-4e52-f602-d52101c79b2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|mappings                                                                                                                                                                                                                                                         |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|{chunk, 38, 47, MEDICATION, {originalChunk -> azithromycin, chunk -> 0, process -> StaticEntityMapping, beginOriginalChunk -> 38, confidence -> 0.9998, ner_source -> ner_chunk, entity -> TREATMENT, endOriginalChunk -> 49, sentence -> 1}, []}                |\n",
            "|{chunk, 57, 70, NEED TO HANDLE, {originalChunk -> any difficulty, chunk -> 1, process -> StaticEntityMapping, beginOriginalChunk -> 59, confidence -> 0.81130004, ner_source -> ner_chunk, entity -> PROBLEM, endOriginalChunk -> 72, sentence -> 1}, []}        |\n",
            "|{chunk, 87, 100, NEED TO HANDLE, {originalChunk -> nausea, chunk -> 2, process -> StaticEntityMapping, beginOriginalChunk -> 90, confidence -> 0.9991, ner_source -> ner_chunk, entity -> PROBLEM, endOriginalChunk -> 95, sentence -> 2}, []}                   |\n",
            "|{chunk, 115, 124, MEDICATION, {originalChunk -> zofran, chunk -> 3, process -> StaticEntityMapping, beginOriginalChunk -> 111, confidence -> 0.9986, ner_source -> ner_chunk, entity -> TREATMENT, endOriginalChunk -> 116, sentence -> 3}, []}                  |\n",
            "|{chunk, 158, 171, NEED TO HANDLE, {originalChunk -> intermittent sweating, chunk -> 4, process -> StaticEntityMapping, beginOriginalChunk -> 151, confidence -> 0.94355, ner_source -> ner_chunk, entity -> PROBLEM, endOriginalChunk -> 171, sentence -> 4}, []}|\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.select(\"doc\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOmzMzIy_Fys",
        "outputId": "0079ffc2-c74c-472e-800d-22110e039105"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|doc                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|[{document, 0, 22, Patient resting in bed., {sentence -> 0, statistics -> {}}, []}, {document, 23, 70, Patient given MEDICATION without NEED TO HANDLE., {sentence -> 1, statistics -> {\"StaticEntityMapping\":2}}, []}, {document, 71, 113, Patient denies NEED TO HANDLE at this time., {sentence -> 2, statistics -> {\"StaticEntityMapping\":1}}, []}, {document, 114, 133, MEDICATION declined., {sentence -> 3, statistics -> {\"StaticEntityMapping\":1}}, []}, {document, 134, 170, Patient is also having NEED TO HANDLE, {sentence -> 4, statistics -> {\"StaticEntityMapping\":1}}, []}]|\n",
            "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `setStaticEntityMappingsFallback`\n",
        "\n",
        "<br/>\n",
        "\n",
        "Fallback option for static entity mappings.\n",
        "#### Allowed Values:\n",
        "- `\"entity\"`\n",
        "- `\"place_holder\"`\n",
        "- `\"skip\"`\n",
        "- `\"prioritize_static_entity\"`\n"
      ],
      "metadata": {
        "id": "CBuLs6Mk_NCW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "replacer = medical.Replacer() \\\n",
        "      .setInputCols(\"chunk\", \"sentence\")\\\n",
        "      .setOutputCol(\"doc\")\\\n",
        "      .setUseReplacement(False)\\\n",
        "      .setNoneValuesTo(\"prioritize_static_entity\") \\\n",
        "      .setPlaceHolder(\"******\") \\\n",
        "      .setPlaceHolderDelimiters([\"<\", \">\"]) \\\n",
        "      .setReturnEntityMappings(True) \\\n",
        "      .setMappingsColumn(\"mappings\") \\\n",
        "      .setStaticEntityMappings({\"TREATMENT\": \"MEDICATION\", \"TEST\": \"ACTIVITY\"}) \\\n",
        "      .setStaticEntityMappingsFallback(\"entity\")\n",
        "\n",
        "nlpPipeline = nlp.Pipeline(stages=[\n",
        "    documentAssembler,\n",
        "    sentenceDetector,\n",
        "    tokenizer,\n",
        "    word_embeddings,\n",
        "    clinical_ner,\n",
        "    ner_converter,\n",
        "    chunkMapper,\n",
        "    mapper2Chunk,\n",
        "    replacer\n",
        "    ])\n",
        "\n",
        "sample_text = \"Patient resting in bed. Patient given azithromycin without any difficulty. Patient denies nausea at this time. zofran declined. Patient is also having intermittent sweating\"\n",
        "\n",
        "data = spark.createDataFrame([[sample_text]]).toDF(\"text\")\n",
        "result = nlpPipeline.fit(data).transform(data)"
      ],
      "metadata": {
        "id": "Y2yj-zMD_LXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.selectExpr(\"explode(mappings) as mappings\").show(truncate= False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfYsTl_0Px_0",
        "outputId": "1eea2a53-8e61-4971-bfdd-354a36770773"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|mappings                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|{chunk, 38, 47, MEDICATION, {originalChunk -> bactericidal, chunk -> 0, __trained__ -> azithromycin, relation -> action, process -> StaticEntityMapping, all_k_distances -> 0.0:::0.0, beginOriginalChunk -> 38, __distance_function__ -> levenshtein, confidence -> 0.9998, all_k_resolutions -> bactericidal:::ophthalmologicals, target_text -> azithromycin, ner_source -> ner_chunk, ops -> 0.0, all_relations -> ophthalmologicals, entity -> TREATMENT, endOriginalChunk -> 49, resolved_text -> bactericidal, distance -> 0.0, sentence -> 1, __relation_name__ -> action}, []}                          |\n",
            "|{chunk, 57, 65, <PROBLEM>, {originalChunk -> NONE, chunk -> 1, process -> entity, beginOriginalChunk -> 59, confidence -> 0.81130004, target_text -> any difficulty, ner_source -> ner_chunk, entity -> PROBLEM, endOriginalChunk -> 72, sentence -> 1}, []}                                                                                                                                                                                                                                                                                                                                                     |\n",
            "|{chunk, 82, 90, <PROBLEM>, {originalChunk -> antiemetic, chunk -> 2, __trained__ -> nausea, relation -> action, process -> entity, all_k_distances -> 0.0:::0.0, beginOriginalChunk -> 90, __distance_function__ -> levenshtein, confidence -> 0.9991, all_k_resolutions -> antiemetic:::drugs for functional gastrointestinal disorders, target_text -> nausea, ner_source -> ner_chunk, ops -> 0.0, all_relations -> drugs for functional gastrointestinal disorders, entity -> PROBLEM, endOriginalChunk -> 95, resolved_text -> antiemetic, distance -> 0.0, sentence -> 2, __relation_name__ -> action}, []}|\n",
            "|{chunk, 105, 114, MEDICATION, {originalChunk -> anti-abstinence, chunk -> 3, __trained__ -> zofran, relation -> action, process -> StaticEntityMapping, all_k_distances -> 0.0:::0.0, beginOriginalChunk -> 111, __distance_function__ -> levenshtein, confidence -> 0.9986, all_k_resolutions -> anti-abstinence:::antiemetic, target_text -> zofran, ner_source -> ner_chunk, ops -> 0.0, all_relations -> antiemetic, entity -> TREATMENT, endOriginalChunk -> 116, resolved_text -> anti-abstinence, distance -> 0.0, sentence -> 3, __relation_name__ -> action}, []}                                       |\n",
            "|{chunk, 148, 156, <PROBLEM>, {originalChunk -> NONE, chunk -> 4, process -> entity, beginOriginalChunk -> 151, confidence -> 0.94355, target_text -> intermittent sweating, ner_source -> ner_chunk, entity -> PROBLEM, endOriginalChunk -> 171, sentence -> 4}, []}                                                                                                                                                                                                                                                                                                                                             |\n",
            "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.select(\"doc.result\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmgfALHL_eDR",
        "outputId": "29d80489-1f84-43f1-f7b4-7a7eb3aac5da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|result                                                                                                                                                                |\n",
            "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|[Patient resting in bed., Patient given MEDICATION without <PROBLEM>., Patient denies <PROBLEM> at this time., MEDICATION declined., Patient is also having <PROBLEM>]|\n",
            "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btb7vPf4K4oQ"
      },
      "source": [
        "## **üíª Date Normalizer Pipeline**\n",
        "\n",
        "\n",
        "The `DateNormalizer` annotator transforms date mentions to a common standard format: YYYY/MM/DD. It is useful when using data from different sources, sometimes from different countries that has different formats to represent dates.\n",
        "\n",
        "For the relative dates (next year, past month, etc.), it is possible to define an anchor date to create the normalized date by setting the parameters anchorDateYear, anchorDateMonth, and anchorDateDay.\n",
        "\n",
        "The `Replacer` annotator will use the output of the `DateNormalizer` annotator, which replaced the extracted date entity by the standard date format, and provide a new text by replacing the original date entity with this value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEObt46_wPwu"
      },
      "outputs": [],
      "source": [
        "# Annotator that transforms a text column from dataframe into an Annotation ready for NLP\n",
        "documentAssembler = nlp.DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "# Sentence Detector annotator, processes various sentences per line\n",
        "sentenceDetector = nlp.SentenceDetector()\\\n",
        "    .setInputCols([\"document\"])\\\n",
        "    .setOutputCol(\"sentence\")\n",
        "\n",
        "# Tokenizer splits words in a relevant format for NLP\n",
        "tokenizer = nlp.Tokenizer()\\\n",
        "    .setInputCols([\"sentence\"])\\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "# Clinical word embeddings trained on PubMED dataset\n",
        "word_embeddings = nlp.WordEmbeddingsModel.pretrained(\"embeddings_clinical\", \"en\", \"clinical/models\")\\\n",
        "    .setInputCols([\"sentence\", \"token\"])\\\n",
        "    .setOutputCol(\"embeddings\")\n",
        "\n",
        "# NER model trained on n2c2 (de-identification and Heart Disease Risk Factors Challenge) datasets)\n",
        "clinical_ner = medical.NerModel.pretrained(\"ner_deid_generic_augmented\", \"en\", \"clinical/models\") \\\n",
        "    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
        "    .setOutputCol(\"ner\")\n",
        "\n",
        "ner_converter = medical.NerConverterInternal()\\\n",
        "    .setInputCols([\"sentence\", \"token\", \"ner\"])\\\n",
        "    .setOutputCol(\"date_chunk\")\\\n",
        "    .setWhiteList([\"DATE\"])\n",
        "\n",
        "date_normalizer = medical.DateNormalizer()\\\n",
        "    .setInputCols('date_chunk')\\\n",
        "    .setOutputCol('normalized_date')\n",
        "\n",
        "replacer = medical.Replacer()\\\n",
        "    .setInputCols([\"normalized_date\",\"document\"])\\\n",
        "    .setOutputCol(\"replaced_document\")\\\n",
        "    .setUseReplacement(True)\n",
        "\n",
        "nlpPipeline = nlp.Pipeline(stages=[\n",
        "      documentAssembler,\n",
        "      sentenceDetector,\n",
        "      tokenizer,\n",
        "      word_embeddings,\n",
        "      clinical_ner,\n",
        "      ner_converter,\n",
        "      date_normalizer,\n",
        "      replacer])\n",
        "\n",
        "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
        "\n",
        "model = nlpPipeline.fit(empty_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnKbW3ZDRcIm"
      },
      "source": [
        "Let's define 7 texts; normalize the date entities and then replace the normalized entities with the original dates in the document by using the `Replacer` annotator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1f1r2RdjwUzL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20625ea0-ec3d-42a3-9275-db7ddd4ad99a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------------------------------------------------------------------------+\n",
            "|text                                                                                                                 |\n",
            "+---------------------------------------------------------------------------------------------------------------------+\n",
            "|She has a history of pericarditis and pericardectomy on 08/02/2018 and developed a cough with right-sided chest pain.|\n",
            "|She has been receiving gemcitabine and she receives three cycles of this with the last one being given on 11/2018.   |\n",
            "|She was last seen in the clinic on 11/01/2018by Dr. Y.                                                               |\n",
            "|Chris Brown was discharged on 12Mar2021                                                                              |\n",
            "|Last INR was on Tuesday, Jan 30, 2018, and her INR was 2.3. 2. Amiodarone 100 mg p.o. daily.                         |\n",
            "|We reviewed the pathology obtained from the pericardectomy on 13.04.1999, which was diagnostic of mesothelioma       |\n",
            "|A review of her CT scan on 3 April2020 prior to her pericardectomy, already shows bilateral plural effusions.        |\n",
            "+---------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.types import StringType\n",
        "\n",
        "dates = [\n",
        "'She has a history of pericarditis and pericardectomy on 08/02/2018 and developed a cough with right-sided chest pain.' ,\n",
        "'She has been receiving gemcitabine and she receives three cycles of this with the last one being given on 11/2018. ',\n",
        "'She was last seen in the clinic on 11/01/2018by Dr. Y.',\n",
        "'Chris Brown was discharged on 12Mar2021',\n",
        "'Last INR was on Tuesday, Jan 30, 2018, and her INR was 2.3. 2. Amiodarone 100 mg p.o. daily. ',\n",
        "'We reviewed the pathology obtained from the pericardectomy on 13.04.1999, which was diagnostic of mesothelioma',\n",
        "'A review of her CT scan on 3 April2020 prior to her pericardectomy, already shows bilateral plural effusions. ',\n",
        "]\n",
        "\n",
        "df_dates = spark.createDataFrame(dates,StringType()).toDF('text')\n",
        "\n",
        "df_dates.show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVdefBtoLi9t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d069e00a-4c1c-442c-e72a-61c4e74fca23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------------------------------------------------------------------------+---------------+----------------------------------------------------------------------------------------------------+\n",
            "|                                                                                                text|normalized_date|                                                                                   replaced_document|\n",
            "+----------------------------------------------------------------------------------------------------+---------------+----------------------------------------------------------------------------------------------------+\n",
            "|She has a history of pericarditis and pericardectomy on 08/02/2018 and developed a cough with rig...|     2018/08/02|She has a history of pericarditis and pericardectomy on 2018/08/02 and developed a cough with rig...|\n",
            "|She has been receiving gemcitabine and she receives three cycles of this with the last one being ...|     2018/11/15|She has been receiving gemcitabine and she receives three cycles of this with the last one being ...|\n",
            "|                                              She was last seen in the clinic on 11/01/2018by Dr. Y.|     2018/11/01|                                                She was last seen in the clinic on 2018/11/01 Dr. Y.|\n",
            "|                                                             Chris Brown was discharged on 12Mar2021|     2021/03/12|                                                            Chris Brown was discharged on 2021/03/12|\n",
            "|       Last INR was on Tuesday, Jan 30, 2018, and her INR was 2.3. 2. Amiodarone 100 mg p.o. daily. |     2018/01/30|                  Last INR was on 2018/01/30, and her INR was 2.3. 2. Amiodarone 100 mg p.o. daily. |\n",
            "|We reviewed the pathology obtained from the pericardectomy on 13.04.1999, which was diagnostic of...|     1999/04/13|We reviewed the pathology obtained from the pericardectomy on 1999/04/13, which was diagnostic of...|\n",
            "|A review of her CT scan on 3 April2020 prior to her pericardectomy, already shows bilateral plura...|     2020/04/03|A review of her CT scan on 2020/04/03 prior to her pericardectomy, already shows bilateral plural...|\n",
            "+----------------------------------------------------------------------------------------------------+---------------+----------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "result = model.transform(df_dates)\n",
        "\n",
        "result_df = result.select(\"text\",F.explode(F.arrays_zip(result.date_chunk.result,\n",
        "                                                        result.normalized_date.result,\n",
        "                                                        result.replaced_document.result)).alias(\"cols\")) \\\n",
        "                  .select(\"text\",F.expr(\"cols['1']\").alias(\"normalized_date\"),\n",
        "                                 F.expr(\"cols['2']\").alias(\"replaced_document\"))\n",
        "\n",
        "result_df.show(truncate=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axbEolr6Q8pT"
      },
      "source": [
        "The dataframe above shows the original texts, normalized dates and `replaced_document` involving the normalized dates."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}