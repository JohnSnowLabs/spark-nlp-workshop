{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "045e5ed6",
   "metadata": {},
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f38be6",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/visual-nlp/1.4.Handwritten_Text_Recognition.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3795dc3e",
   "metadata": {},
   "source": [
    "## Blogposts and videos\n",
    "\n",
    "- [Text Detection in Spark OCR](https://medium.com/spark-nlp/text-detection-in-spark-ocr-dcd8002bdc97)\n",
    "\n",
    "- [Table Detection & Extraction in Spark OCR](https://medium.com/spark-nlp/table-detection-extraction-in-spark-ocr-50765c6cedc9)\n",
    "\n",
    "- [Extract Tabular Data from PDF in Spark OCR](https://medium.com/spark-nlp/extract-tabular-data-from-pdf-in-spark-ocr-b02136bc0fcb)\n",
    "\n",
    "- [Signature Detection in Spark OCR](https://medium.com/spark-nlp/signature-detection-in-spark-ocr-32f9e6f91e3c)\n",
    "\n",
    "- [GPU image pre-processing in Spark OCR](https://medium.com/spark-nlp/gpu-image-pre-processing-in-spark-ocr-3-1-0-6fc27560a9bb)\n",
    "\n",
    "- [How to Setup Spark OCR on UBUNTU - Video](https://www.youtube.com/watch?v=cmt4WIcL0nI)\n",
    "\n",
    "\n",
    "**More examples here**\n",
    "\n",
    "https://github.com/JohnSnowLabs/spark-ocr-workshop\n",
    "\n",
    "For get the trial license please go to:\n",
    "\n",
    "https://www.johnsnowlabs.com/install/\n",
    "\n",
    "Please choose GPU runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7584f75",
   "metadata": {},
   "source": [
    "### Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1832d8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the johnsnowlabs library to access Spark-OCR and Spark-NLP for Healthcare, Finance, and Legal.\n",
    "!pip install -q johnsnowlabs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4b8f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "print('Please Upload your John Snow Labs License using the button below')\n",
    "license_keys = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aab583f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from johnsnowlabs import nlp, visual\n",
    "\n",
    "# After uploading your license run this to install all licensed Python Wheels and pre-download Jars the Spark Session JVM\n",
    "nlp.install(refresh_install=True, visual=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a427b7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkg_resources\n",
    "\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6392f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from johnsnowlabs import nlp, visual\n",
    "import pandas as pd\n",
    "\n",
    "# Automatically load license data and start a session with all jars user has access to\n",
    "spark = nlp.start(visual=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b41a984",
   "metadata": {},
   "source": [
    "## Read image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef257a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://github.com/JohnSnowLabs/spark-nlp-workshop/raw/master/visual-nlp/data/handwritten_example.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3dab87",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_example_df = spark.read.format(\"binaryFile\").load(\"handwritten_example.jpg\")\n",
    "image_df = visual.BinaryToImage().transform(image_example_df).cache()\n",
    "\n",
    "visual.display_images(image_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e71ebb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparkocr.optimized import ImageToTextV2 # --> hack!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad072573",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_to_image = visual.BinaryToImage() \n",
    "#binary_to_image.setImageType(ImageType.TYPE_3BYTE_BGR)\n",
    "\n",
    "text_detector = visual.ImageTextDetectorV2 \\\n",
    "    .pretrained(\"image_text_detector_v2\", \"en\", \"clinical/ocr\") \\\n",
    "    .setInputCol(\"image\") \\\n",
    "    .setOutputCol(\"text_regions\") \\\n",
    "    .setWithRefiner(True) \\\n",
    "    .setSizeThreshold(10) \\\n",
    "    .setScoreThreshold(0.2) \\\n",
    "    .setTextThreshold(0.2) \\\n",
    "    .setLinkThreshold(0.3) \\\n",
    "    .setWidth(500)\n",
    "\n",
    "ocr = ImageToTextV2.pretrained(\"ocr_base_handwritten_v2_opt\", \"en\", \"clinical/ocr\") \\\n",
    "    .setRegionsColumn(\"text_regions\")\\\n",
    "    .setInputCols([\"image\"]) \\\n",
    "    .setGroupImages(True) \\\n",
    "    .setOutputCol(\"text\")\n",
    "\n",
    "draw_regions = visual.ImageDrawRegions() \\\n",
    "    .setInputCol(\"image\") \\\n",
    "    .setInputRegionsCol(\"text_regions\") \\\n",
    "    .setOutputCol(\"image_with_regions\") \\\n",
    "    .setRectColor(visual.Color.green) \\\n",
    "    .setRotated(True)\n",
    "\n",
    "pipeline = PipelineModel(stages=[\n",
    "    binary_to_image,\n",
    "    text_detector,\n",
    "    ocr,\n",
    "    draw_regions\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62788c29",
   "metadata": {},
   "source": [
    "## Run pipeline and show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5cee08",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pipeline.transform(image_example_df).cache()\n",
    "visual.display_images(result, \"image_with_regions\")\n",
    "print((\"\").join([x.text for x in result.select(\"text\").collect()]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}