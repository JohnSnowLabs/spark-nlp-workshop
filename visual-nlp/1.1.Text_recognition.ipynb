{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17e679a0",
   "metadata": {},
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7198ab82",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/visual-nlp/1.1.Text_recognition.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d54d0c",
   "metadata": {},
   "source": [
    "## Blogposts and videos\n",
    "\n",
    "- [Text Detection in Spark OCR](https://medium.com/spark-nlp/text-detection-in-spark-ocr-dcd8002bdc97)\n",
    "\n",
    "- [Table Detection & Extraction in Spark OCR](https://medium.com/spark-nlp/table-detection-extraction-in-spark-ocr-50765c6cedc9)\n",
    "\n",
    "- [Extract Tabular Data from PDF in Spark OCR](https://medium.com/spark-nlp/extract-tabular-data-from-pdf-in-spark-ocr-b02136bc0fcb)\n",
    "\n",
    "- [Signature Detection in Spark OCR](https://medium.com/spark-nlp/signature-detection-in-spark-ocr-32f9e6f91e3c)\n",
    "\n",
    "- [GPU image pre-processing in Spark OCR](https://medium.com/spark-nlp/gpu-image-pre-processing-in-spark-ocr-3-1-0-6fc27560a9bb)\n",
    "\n",
    "- [How to Setup Spark OCR on UBUNTU - Video](https://www.youtube.com/watch?v=cmt4WIcL0nI)\n",
    "\n",
    "\n",
    "**More examples here**\n",
    "\n",
    "https://github.com/JohnSnowLabs/spark-ocr-workshop\n",
    "\n",
    "For get the trial license please go to:\n",
    "\n",
    "https://www.johnsnowlabs.com/install/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7898c593",
   "metadata": {},
   "source": [
    "### Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b205587b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the johnsnowlabs library to access Spark-OCR and Spark-NLP for Healthcare, Finance, and Legal.\n",
    "!pip install -q johnsnowlabs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede7715e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "print('Please Upload your John Snow Labs License using the button below')\n",
    "license_keys = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d17ef6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from johnsnowlabs import nlp, visual\n",
    "\n",
    "# After uploading your license run this to install all licensed Python Wheels and pre-download Jars the Spark Session JVM\n",
    "nlp.install(refresh_install=True, visual=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae691e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from johnsnowlabs import nlp, visual\n",
    "import pandas as pd\n",
    "\n",
    "# Automatically load license data and start a session with all jars user has access to\n",
    "spark = nlp.start(visual=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84cc6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkg_resources\n",
    "\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a180cedc",
   "metadata": {},
   "source": [
    "## Image to Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54537d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = pkg_resources.resource_filename('sparkocr', 'resources/ocr/images/check.jpg')\n",
    "image_example_df = spark.read.format(\"binaryFile\").load(image_path).cache()\n",
    "\n",
    "visual.display_images(visual.BinaryToImage().transform(image_example_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2610f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_to_image = visual.BinaryToImage()\\\n",
    "      .setInputCol(\"content\")\\\n",
    "      .setOutputCol(\"image\")\n",
    "\n",
    "# Run OCR\n",
    "ocr = visual.ImageToText()\\\n",
    "      .setInputCol(\"image\")\\\n",
    "      .setOutputCol(\"text\")\\\n",
    "      .setConfidenceThreshold(65)\n",
    "      #.setKeepLayout(True) # to preserve the layout of the input\n",
    "\n",
    "image_to_text_pipeline = PipelineModel(stages=[\n",
    "    binary_to_image,\n",
    "    ocr\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0954dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = image_to_text_pipeline.transform(image_example_df).cache()\n",
    "result.select(\"pagenum\", \"text\", \"confidence\").show()\n",
    "\n",
    "result.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db3e900",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\".join([row.text for row in result.select(\"text\").collect()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b790f593",
   "metadata": {},
   "source": [
    "## Image to HOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5651c4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline():\n",
    "    \n",
    "    # Transforrm PDF document to images per page\n",
    "    binary_to_image = visual.BinaryToImage() \\\n",
    "        .setInputCol(\"content\") \\\n",
    "        .setOutputCol(\"image\") \\\n",
    "        .setImageType(visual.ImageType.TYPE_3BYTE_BGR)\n",
    "\n",
    "    # Run OCR\n",
    "    ocr = visual.ImageToHocr() \\\n",
    "        .setInputCol(\"image\") \\\n",
    "        .setOutputCol(\"hocr\") \\\n",
    "        .setIgnoreResolution(False)\n",
    "    \n",
    "    document_assembler = visual.HocrDocumentAssembler() \\\n",
    "        .setInputCol(\"hocr\") \\\n",
    "        .setOutputCol(\"document\")\n",
    "\n",
    "    tokenizer = visual.HocrTokenizer() \\\n",
    "        .setInputCol(\"hocr\") \\\n",
    "        .setOutputCol(\"token\") \\\n",
    "\n",
    "    draw_annotations = visual.ImageDrawAnnotations() \\\n",
    "        .setInputCol(\"image\") \\\n",
    "        .setInputChunksCol(\"token\") \\\n",
    "        .setOutputCol(\"image_with_annotations\") \\\n",
    "        .setFilledRect(False) \\\n",
    "        .setFontSize(10) \\\n",
    "        .setRectColor(visual.Color.red)\n",
    "    \n",
    "    pipeline = PipelineModel(stages=[\n",
    "        binary_to_image,\n",
    "        ocr,\n",
    "        document_assembler,\n",
    "        tokenizer,\n",
    "        draw_annotations\n",
    "    ])\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe0aa9c",
   "metadata": {},
   "source": [
    "### Run pipeline and show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88822211",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result = pipeline().transform(image_example_df).cache()\n",
    "print(result.select(\"hocr\").collect()[0].hocr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da89766f",
   "metadata": {},
   "source": [
    "### Display recognized text on original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a543e7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "visual.display_images(result, \"image_with_annotations\", width=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fd6b9b",
   "metadata": {},
   "source": [
    "## Pdf to Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7145b718",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = pkg_resources.resource_filename('sparkocr', 'resources/ocr/pdfs/test_document.pdf')\n",
    "pdf_example_df = spark.read.format(\"binaryFile\").load(pdf_path).cache()\n",
    "\n",
    "visual.display_pdf(pdf_example_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af669b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform PDF document to images per page\n",
    "pdf_to_image = visual.PdfToImage()\\\n",
    "      .setInputCol(\"content\")\\\n",
    "      .setOutputCol(\"image\")\n",
    "\n",
    "# Run OCR\n",
    "ocr = visual.ImageToText()\\\n",
    "      .setInputCol(\"image\")\\\n",
    "      .setOutputCol(\"text\")\\\n",
    "      .setConfidenceThreshold(65)\n",
    "\n",
    "pdf_to_text_pipeline = PipelineModel(stages=[\n",
    "    pdf_to_image,\n",
    "    ocr\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552d60b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pdf_to_text_pipeline.transform(pdf_example_df).cache()\n",
    "result.select(\"pagenum\", \"text\", \"confidence\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aac7889",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\".join([row.text for row in result.select(\"text\").collect()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc640708",
   "metadata": {},
   "source": [
    "## Skew correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4cbb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = pkg_resources.resource_filename('sparkocr', 'resources/ocr/pdfs/rotated/400/400_rot.pdf')\n",
    "pdf_rotated_df = spark.read.format(\"binaryFile\").load(pdf_path).cache()\n",
    "\n",
    "visual.display_pdf(pdf_rotated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6f0232",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_pipeline(skew_correction=False):\n",
    "    \n",
    "    # Transforrm PDF document to images per page\n",
    "    pdf_to_image = visual.PdfToImage()\\\n",
    "          .setInputCol(\"content\")\\\n",
    "          .setOutputCol(\"image\")\n",
    "\n",
    "    # Image skew corrector \n",
    "    skew_corrector = visual.ImageSkewCorrector()\\\n",
    "          .setInputCol(\"image\")\\\n",
    "          .setOutputCol(\"corrected_image\")\\\n",
    "          .setAutomaticSkewCorrection(skew_correction)\n",
    "\n",
    "    # Run OCR\n",
    "    ocr = visual.ImageToText()\\\n",
    "          .setInputCol(\"corrected_image\")\\\n",
    "          .setOutputCol(\"text\")\n",
    "    \n",
    "    pipeline_ocr = PipelineModel(stages=[\n",
    "        pdf_to_image,\n",
    "        skew_corrector,\n",
    "        ocr\n",
    "    ])\n",
    "    \n",
    "    return pipeline_ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b82267d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ocr_pipeline(False).transform(pdf_rotated_df).cache()\n",
    "print(\"\\n\".join([row.text for row in result.select(\"text\").collect()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1793873f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_result = ocr_pipeline(True).transform(pdf_rotated_df).cache()\n",
    "print(\"\\n\".join([row.text for row in corrected_result.select(\"text\").collect()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8025d308",
   "metadata": {},
   "outputs": [],
   "source": [
    "visual.display_images(corrected_result, \"corrected_image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1ad1ed",
   "metadata": {},
   "source": [
    "### Calculate scores for showing improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a392af80",
   "metadata": {},
   "outputs": [],
   "source": [
    "detected = \"\\n\".join([row.text for row in result.collect()])\n",
    "corrected_detected = \"\\n\".join([row.text for row in corrected_result.collect()])\n",
    "\n",
    "# read original text\n",
    "path_to_pdf_rotated_text = pkg_resources.resource_filename('sparkocr', 'resources/ocr/pdfs/rotated/400.txt')\n",
    "\n",
    "pdf_rotated_text = open(path_to_pdf_rotated_text, \"r\").read()\n",
    "\n",
    "# compute scores\n",
    "detected_score = visual.score(pdf_rotated_text, detected)\n",
    "corrected_score = visual.score(pdf_rotated_text, corrected_detected)\n",
    "\n",
    "#  print scores\n",
    "print(\"Score without skew correction: {0}\".format(detected_score))\n",
    "print(\"Score with skew correction: {0}\".format(corrected_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12590138",
   "metadata": {},
   "source": [
    "## Image Text Cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa84d206",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/jupyter/data/pdfs/noised.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c05ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_noised_df = spark.read.format(\"binaryFile\").load('noised.pdf').cache()\n",
    "\n",
    "visual.display_pdf(pdf_noised_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0ff79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_to_image = visual.PdfToImage() \\\n",
    "    .setInputCol(\"content\") \\\n",
    "    .setOutputCol(\"image\") \\\n",
    "    .setResolution(150)\n",
    "\n",
    "ocr = visual.ImageToText() \\\n",
    "    .setInputCol(\"image\") \\\n",
    "    .setOutputCol(\"text\") \\\n",
    "    .setConfidenceThreshold(70) \\\n",
    "    .setIgnoreResolution(False)\n",
    "\n",
    "cleaner = visual.ImageTextCleaner \\\n",
    "    .pretrained(\"text_cleaner_v1\", \"en\", \"clinical/ocr\") \\\n",
    "    .setInputCol(\"image\") \\\n",
    "    .setOutputCol(\"corrected_image\") \\\n",
    "    .setMedianBlur(0) \\\n",
    "    .setSizeThreshold(10) \\\n",
    "    .setTextThreshold(0.3) \\\n",
    "    .setLinkThreshold(0.2) \\\n",
    "    .setPadding(5) \\\n",
    "    .setBinarize(False)\n",
    "\n",
    "ocr_corrected = visual.ImageToText() \\\n",
    "    .setInputCol(\"corrected_image\") \\\n",
    "    .setOutputCol(\"corrected_text\") \\\n",
    "    .setConfidenceThreshold(70) \\\n",
    "    .setIgnoreResolution(False)\n",
    "\n",
    "pipeline = PipelineModel(stages=[\n",
    "    pdf_to_image,\n",
    "    ocr,\n",
    "    cleaner,\n",
    "    ocr_corrected\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d702c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pipeline.transform(pdf_noised_df).cache()\n",
    "\n",
    "print(f\"Detected text:\\n{results.select('text').collect()[0].text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79003d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "visual.display_images(results, \"corrected_image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf4fb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Detected text from corrected image:\\n{results.select('corrected_text').collect()[0].corrected_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac86b51e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visual.display_images_horizontal(results, \"image,corrected_image\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}