{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "woOy-vR3L0Bj"
   },
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1UprvQWGLWbo"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/visual-nlp/7.2.SparkOcrPretrainedPipelines.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lS_nUbuJKS-S"
   },
   "source": [
    "# Example of Pretrained Pipelines\n",
    "Pretrained Pipelines can be considered predefined recipes in the form of Visual NLP pipelines, these recipes come with a set of stages and parameters that help to accomplish specific tasks.\n",
    "\n",
    "## Blogposts and videos\n",
    "\n",
    "- [Text Detection in Spark OCR](https://medium.com/spark-nlp/text-detection-in-spark-ocr-dcd8002bdc97)\n",
    "\n",
    "- [Table Detection & Extraction in Spark OCR](https://medium.com/spark-nlp/table-detection-extraction-in-spark-ocr-50765c6cedc9)\n",
    "\n",
    "- [Extract Tabular Data from PDF in Spark OCR](https://medium.com/spark-nlp/extract-tabular-data-from-pdf-in-spark-ocr-b02136bc0fcb)\n",
    "\n",
    "- [Signature Detection in Spark OCR](https://medium.com/spark-nlp/signature-detection-in-spark-ocr-32f9e6f91e3c)\n",
    "\n",
    "- [GPU image pre-processing in Spark OCR](https://medium.com/spark-nlp/gpu-image-pre-processing-in-spark-ocr-3-1-0-6fc27560a9bb)\n",
    "\n",
    "- [How to Setup Spark OCR on UBUNTU - Video](https://www.youtube.com/watch?v=cmt4WIcL0nI)\n",
    "\n",
    "\n",
    "**More examples here**\n",
    "\n",
    "https://github.com/JohnSnowLabs/spark-ocr-workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S2nT7ciiMY36"
   },
   "source": [
    "### Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "kOHh-vRRLWbo"
   },
   "outputs": [],
   "source": [
    "# Install the johnsnowlabs library to access Spark-OCR and Spark-NLP for Healthcare, Finance, and Legal.\n",
    "!pip install -q johnsnowlabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "id": "u_AdphBFLWbp",
    "outputId": "6985f118-6ab0-4b52-ffa4-fac6d49e5c0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please Upload your John Snow Labs License using the button below\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-db33ecd7-3a16-4aae-96f5-925a08e699a4\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-db33ecd7-3a16-4aae-96f5-925a08e699a4\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving OCT_23_Visual_NLP.json to OCT_23_Visual_NLP (1).json\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "print('Please Upload your John Snow Labs License using the button below')\n",
    "license_keys = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS0T76pBMjcd",
    "outputId": "603a38ee-3053-406c-bcaf-a49121e8d338"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Cleaning up old JSL Home in  /root/.johnsnowlabs\n",
      "üëå Detected license file /content/OCT_23_Visual_NLP.json\n",
      "üìã Stored John Snow Labs License in /root/.johnsnowlabs/licenses/license_number_0_for_Spark-OCR.json\n",
      "üë∑ Setting up  John Snow Labs home in /root/.johnsnowlabs, this might take a few minutes.\n",
      "Downloading üêç+üöÄ Python Library spark_nlp-5.1.1-py2.py3-none-any.whl\n",
      "Downloading üêç+üï∂ Python Library spark_ocr-5.0.2-py3-none-any.whl\n",
      "Downloading ü´ò+üöÄ Java Library spark-nlp-assembly-5.1.1.jar\n",
      "Downloading ü´ò+üï∂ Java Library spark-ocr-assembly-5.0.2.jar\n",
      "üôÜ JSL Home setup in /root/.johnsnowlabs\n",
      "üëå Detected license file /content/OCT_23_Visual_NLP.json\n",
      "Installed 1 products:\n",
      "üíä Spark-Healthcare not installed! ‚ùå\n"
     ]
    }
   ],
   "source": [
    "from johnsnowlabs import nlp, visual, medical\n",
    "\n",
    "# After uploading your license run this to install all licensed Python Wheels and pre-download Jars the Spark Session JVM\n",
    "nlp.install(refresh_install=True, visual=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w0gU3CNqMoBL"
   },
   "source": [
    "### Initialize Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5HiwMe81LWbp",
    "outputId": "8f612ebc-c26e-4d28-b868-53c7e74c6998"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Session already created, some configs may not take.\n",
      "üëå Detected license file /content/OCT_23_Visual_NLP.json\n"
     ]
    }
   ],
   "source": [
    "from johnsnowlabs import visual, nlp\n",
    "\n",
    "# Automatically load license data and start a session with all jars user has access to\n",
    "spark = nlp.start(visual=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-XtrWSDKS-X"
   },
   "source": [
    "## Load Pretrained Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QWOHzaVILWbq"
   },
   "source": [
    "### mixed_scanned_digital_pdf\n",
    "In this simple pipeline we can use the predefined pipeline to handle a mix of scanned(containing images) and digital PDFs(containing digital text). The output is going to be returned in a Dataframe column, and it will contain texts coming from both sources.</br>\n",
    "You could even have a single PDF file with a mix of digital and scanned pages.</br>\n",
    "Other Options:</br>\n",
    "* __mixed_scanned_digital_pdf_image_cleaner__: same as above but cleaning noise from images.</br>\n",
    "* __mixed_scanned_digital_pdf_skew_correction__: same as above but with page rotation correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J1Css1dlKS-Y",
    "outputId": "03596474-ed00-467c-8958-bff817e75878"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mixed_scanned_digital_pdf download started this may take some time.\n",
      "Approx size to download 6.7 KB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "mixed_pdf_pipeline = nlp.PretrainedPipeline('mixed_scanned_digital_pdf', 'en', 'clinical/ocr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RRlw0XvRKS-Y"
   },
   "source": [
    "### Call the pipeline\n",
    "We are listing the 'mixed_pdfs' folder, that one contains two PDF files, one is scanned and the other is digital. You can open them yourself and verify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RYShFpzILWbr",
    "outputId": "1bae4820-c9ea-4362-b376-aa67487a43eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "immortal_image.pdf  immortal_text.pdf\n"
     ]
    }
   ],
   "source": [
    "pdf_path = '/content/mixed'\n",
    "!ls /content/mixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k0pYXFcALWbr"
   },
   "source": [
    "We will display using the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "id": "pTwlFOQCKS-Y",
    "outputId": "ca4f8c62-bd9f-4837-b79f-b31092b11629"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>path</th><th>modificationTime</th><th>length</th><th>text</th><th>positions</th><th>height_dimension</th><th>width_dimension</th><th>content</th><th>image</th><th>total_pages</th><th>pagenum</th><th>documentnum</th><th>confidence</th><th>exception</th></tr>\n",
       "<tr><td>file:/content/mix...</td><td>2023-10-12 23:28:...</td><td>243543</td><td>                 ...</td><td>[{[{w, 14.4, 25.2...</td><td>383</td><td>284</td><td>[25 50 44 46 2D 3...</td><td>null</td><td>0</td><td>0</td><td>0</td><td>-1.79769313486231...</td><td>null</td></tr>\n",
       "<tr><td>file:/content/mix...</td><td>2023-10-12 23:28:...</td><td>90047</td><td>would have been a...</td><td>[{[{would have be...</td><td>841</td><td>595</td><td>[25 50 44 46 2D 3...</td><td>{file:/content/mi...</td><td>1</td><td>0</td><td>0</td><td>95.63247501148896</td><td>null</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------------------+--------------------+------+--------------------+--------------------+----------------+---------------+--------------------+--------------------+-----------+-------+-----------+--------------------+---------+\n",
       "|                path|    modificationTime|length|                text|           positions|height_dimension|width_dimension|             content|               image|total_pages|pagenum|documentnum|          confidence|exception|\n",
       "+--------------------+--------------------+------+--------------------+--------------------+----------------+---------------+--------------------+--------------------+-----------+-------+-----------+--------------------+---------+\n",
       "|file:/content/mix...|2023-10-12 23:28:...|243543|                 ...|[{[{w, 14.4, 25.2...|             383|            284|[25 50 44 46 2D 3...|                null|          0|      0|          0|-1.79769313486231...|     null|\n",
       "|file:/content/mix...|2023-10-12 23:28:...| 90047|would have been a...|[{[{would have be...|             841|            595|[25 50 44 46 2D 3...|{file:/content/mi...|          1|      0|          0|   95.63247501148896|     null|\n",
       "+--------------------+--------------------+------+--------------------+--------------------+----------------+---------------+--------------------+--------------------+-----------+-------+-----------+--------------------+---------+"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_example_df = spark.read.format(\"binaryFile\").load(pdf_path).cache()\n",
    "result = mixed_pdf_pipeline.transform(pdf_example_df)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WoAcrGAULWbr"
   },
   "source": [
    "And to avoid truncation, using collect() on just the text column,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "lTc0uL0hLWbr"
   },
   "outputs": [],
   "source": [
    "r = result.select(\"text\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IbqKBgsIPZ3N",
    "outputId": "767d95b6-1c43-41b6-993e-f52c27084302"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(text='would have been a liberation, a joy, and a fiesta.\\n\\nHe sensed that had he been able to choose or\\n\\ndream his death that night, this is the death he\\n\\nwould have dreamed or chosen.\\n\\nDahlmann firmly grips the knife, which he\\n\\nmay have no idea how to manage, and steps out\\n\\ninto the plains.\\n\\nThe Aleph\\n\\n(1949)\\n\\nThe Immortal\\n\\nSolomon saith: There is no new thing upon\\n\\nthe earth. So that as Plato had an imagination,\\n\\nthat all knowledge was but remembrance; so\\n\\nSolomon giveth his sentence, that all novelty is\\n\\nbut oblivion.\\n\\nFrancis Bacon: Essays, LVIII\\n\\nIn London, in early June of the year 1929,\\n')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8W4QhtZ1LWbs"
   },
   "source": [
    "### image_handwritten_transformer_extraction\n",
    "Let's use another example, this time for doing transformer based OCR on handwritten texts. </br>\n",
    "Other similar options are,\n",
    "\n",
    "* __image_printed_transformer_extraction__: OCR printed texts contained on images.\n",
    "* __pdf_printed_transformer_extraction__: OCR printed texts contained in PDFs.\n",
    "* __pdf_handwritten_transformer_extraction__: OCR handwritten texts contained in PDFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-o-veBwOLWbs",
    "outputId": "63149b43-23e0-460e-ce98-6a9a04484d12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_handwritten_transformer_extraction download started this may take some time.\n",
      "Approx size to download 496 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "image_handwritten_transformer_extraction = nlp.PretrainedPipeline('image_handwritten_transformer_extraction', 'en', 'clinical/ocr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QTK_8YP1LWbs"
   },
   "source": [
    "### Load image and display it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uAsfoWlELWbs"
   },
   "outputs": [],
   "source": [
    "imagePath = \"/content/handwritten_example.jpg\"\n",
    "image_df = spark.read.format(\"binaryFile\").load(imagePath)\n",
    "visual.display_images(BinaryToImage().transform(image_df), \"image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1t0rs1doLWbs"
   },
   "source": [
    "### display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8JIP12tvLWbs",
    "outputId": "5913c2b4-bbd2-4853-caab-5acab333b1e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an example of handwritten\n",
      "sex .\n",
      "Let's # check the performance ?\n",
      "I hope it will be awesome .\n"
     ]
    }
   ],
   "source": [
    "result = image_handwritten_transformer_extraction.transform(image_df).cache()\n",
    "print((\"\").join([x.text for x in result.select(\"text\").collect()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0-s40395Rw8s"
   },
   "source": [
    "### Visualize intermediate results\n",
    "Let's take a look at the detected text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "57A6OB6ILWbs"
   },
   "outputs": [],
   "source": [
    "draw_regions = visual.ImageDrawRegions() \\\n",
    "    .setInputCol(\"image\") \\\n",
    "    .setInputRegionsCol(\"text_regions\") \\\n",
    "    .setOutputCol(\"image_with_regions\") \\\n",
    "    .setRectColor(Color.green) \\\n",
    "    .setRotated(True)\n",
    "\n",
    "visual.display_images(draw_regions.transform(result), \"image_with_regions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "afxa4C4SR8pJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "7.2 SparkOcrPretrainedPipelines",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
